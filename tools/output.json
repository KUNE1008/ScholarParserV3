[
  {
    "title": "neuralrecon: real-time coherent 3d reconstruction from monocular video",
    "id": 3,
    "valid_pdf_number": "233/257",
    "matched_pdf_number": "0/233",
    "matched_rate": 0.0,
    "citations": {
      "Nice-slam: Neural implicit scalable encoding for slam": {
        "authors": [
          "Zihan Zhu",
          "Songyou Peng",
          "Viktor Larsson",
          "Weiwei Xu",
          "Hujun Bao",
          "Zhaopeng Cui",
          "Martin R. Oswald",
          "Marc Pollefeys"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2022/papers/Zhu_NICE-SLAM_Neural_Implicit_Scalable_Encoding_for_SLAM_CVPR_2022_paper.pdf",
        "ref_texts": "[47] Edgar Sucar, Kentaro Wada, and Andrew Davison. Nodeslam: Neural object descriptors for multi-view shape reconstruction. In 3DV, 2020. 1, 2[48] Jiaming Sun, Yiming Xie, Linghao Chen, Xiaowei Zhou, and Hujun Bao. Neuralrecon: Real-time coherent 3d reconstruction from monocular video. In CVPR , 2021. 1, 2",
        "ref_ids": [
          "47",
          "48"
        ]
      },
      "Surroundocc: Multi-camera 3d occupancy prediction for autonomous driving": {
        "authors": [
          "Yi Wei",
          "Linqing Zhao",
          "Wenzhao Zheng",
          "Zheng Zhu",
          "Jie Zhou",
          "Jiwen Lu"
        ],
        "url": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wei_SurroundOcc_Multi-camera_3D_Occupancy_Prediction_for_Autonomous_Driving_ICCV_2023_paper.pdf",
        "ref_texts": "[50] Jiaming Sun, Yiming Xie, Linghao Chen, Xiaowei Zhou, and Hujun Bao. Neuralrecon: Real-time coherent 3d reconstruction from monocular video. In CVPR , pages 15598\u201315607, 2021.",
        "ref_ids": [
          "50"
        ]
      },
      "Bundlesdf: Neural 6-dof tracking and 3d reconstruction of unknown objects": {
        "authors": [
          "Bowen Wen",
          "Jonathan Tremblay",
          "Valts Blukis",
          "Stephen Tyree",
          "Thomas Muller",
          "Alex Evans",
          "Dieter Fox",
          "Jan Kautz",
          "Stan Birchfield"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Wen_BundleSDF_Neural_6-DoF_Tracking_and_3D_Reconstruction_of_Unknown_Objects_CVPR_2023_paper.pdf",
        "ref_texts": "[59] Jiaming Sun, Yiming Xie, Linghao Chen, Xiaowei Zhou, and Hujun Bao. Neuralrecon: Real-time coherent 3d reconstruction from monocular video. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 15598\u201315607, 2021. 1, 2[60] Martin Sundermeyer, Zoltan-Csaba Marton, Maximilian Durner, Manuel Brucker, and Rudolph Triebel. Implicit 3D orientation learning for 6D object detection from RGB images. In Proceedings of the European Conference on Computer Vision (ECCV) , pages 699\u2013715, 2018. 2",
        "ref_ids": [
          "59",
          "60"
        ]
      },
      "Time will tell: New outlooks and a baseline for temporal multi-view 3d object detection": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2210.02443",
        "ref_texts": "12 Kiriakos N Kutulakos and Steven M Seitz. A theory of shape by space carving. International journal of computer vision , 38(3):199\u2013218, 2000. Yanwei Li, Yilun Chen, Xiaojuan Qi, Zeming Li, Jian Sun, and Jiaya Jia. Unifying voxel-based representation with transformer for 3d object detection. arXiv preprint arXiv:2206.00630 , 2022a. Yinhao Li, Han Bao, Zheng Ge, Jinrong Yang, Jianjian Sun, and Zeming Li. Bevstereo: Enhancing depth estimation in multi-view 3d object detection with dynamic temporal stereo. arXiv preprint arXiv:2209.10248 , 2022b. Yinhao Li, Zheng Ge, Guanyi Yu, Jinrong Yang, Zengran Wang, Yukang Shi, Jianjian Sun, and Zeming Li. Bevdepth: Acquisition of reliable depth for multi-view 3d object detection. arXiv preprint arXiv:2206.10092 , 2022c. Zhiqi Li, Wenhai Wang, Hongyang Li, Enze Xie, Chonghao Sima, Tong Lu, Qiao Yu, and Jifeng Dai. Bevformer: Learning bird\u2019s-eye-view representation from multi-camera images via spatiotemporal transformers. arXiv preprint arXiv:2203.17270 , 2022d. Zhuoling Li, Z. Qu, Yang Zhou, Jianzhuang Liu, Haoqian Wang, and Lihui Jiang. Diversity matters: Fully exploiting depth clues for reliable monocular 3d object detection. ArXiv , abs/2205.09373, 2022e. Yingfei Liu, Tiancai Wang, Xiangyu Zhang, and Jian Sun. Petr: Position embedding transformation for multi-view 3d object detection. arXiv preprint arXiv:2203.05625 , 2022a. Yingfei Liu, Junjie Yan, Fan Jia, Shuailin Li, Qi Gao, Tiancai Wang, Xiangyu Zhang, and Jian Sun. Petrv2: A unified framework for 3d perception from multi-camera images. arXiv preprint arXiv:2206.01256 , 2022b. Zhijian Liu, Haotian Tang, Alexander Amini, Xinyu Yang, Huizi Mao, Daniela Rus, and Song Han. Bevfusion: Multi-task multi-sensor fusion with unified bird\u2019s-eye view representation. ArXiv , abs/2205.13542, 2022c. Zongdai Liu, Dingfu Zhou, Feixiang Lu, Jin Fang, and Liangjun Zhang. Autoshape: Real-time shape-aware monocular 3d object detection. In ICCV , 2021. Fabian Manhardt, Wadim Kehl, and Adrien Gaidon. Roi-10d: Monocular lifting of 2d detection to 6d pose and metric shape. 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) , pp. 2064\u20132073, 2019. Arsalan Mousavian, Dragomir Anguelov, John Flynn, and Jana Kosecka. 3d bounding box estimation using deep learning and geometry. In CVPR , 2017. Jonah Philion and Sanja Fidler. Lift, splat, shoot: Encoding images from arbitrary camera rigs by implicitly unprojecting to 3d. In European Conference on Computer Vision , pp. 194\u2013210. Springer, 2020. Zengyi Qin, Jinglu Wang, and Yan Lu. Monogrnet: A geometric reasoning network for monocular 3d object localization. In AAAI , 2019. Cody Reading, Ali Harakeh, Julia Chae, and Steven L. Waslander. Categorical depth distributionnetwork for monocular 3d object detection. In CVPR , 2021. Andrea Simonelli, Samuel Rota Bul `o, Lorenzo Porzi, Manuel L \u00b4opez-Antequera, and Peter Kontschieder. Disentangling monocular 3d object detection. 2019 IEEE/CVF International Conference on Computer Vision (ICCV) , pp. 1991\u20131999, 2019. Jiaming Sun, Yiming Xie, Linghao Chen, Xiaowei Zhou, and Hujun Bao. Neuralrecon: Real-time coherent 3d reconstruction from monocular video. 2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) , pp. 15593\u201315602, 2021. Tai Wang, Xinge Zhu, Jiangmiao Pang, and Dahua Lin. FCOS3D: Fully convolutional one-stage monocular 3d object detection. In ICCV Workshops , 2021."
      },
      "Sparseneus: Fast generalizable neural surface reconstruction from sparse views": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2206.05737",
        "ref_texts": "40. Sun, J., Xie, Y., Chen, L., Zhou, X., Bao, H.: Neuralrecon: Real-time coherent 3d reconstruction from monocular video. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 15598\u201315607 (2021)",
        "ref_ids": [
          "40"
        ]
      },
      "Neural 3d scene reconstruction with the manhattan-world assumption": {
        "authors": [
          "Haoyu Guo",
          "Sida Peng",
          "Haotong Lin",
          "Qianqian Wang",
          "Guofeng Zhang",
          "Hujun Bao",
          "Xiaowei Zhou"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2022/papers/Guo_Neural_3D_Scene_Reconstruction_With_the_Manhattan-World_Assumption_CVPR_2022_paper.pdf",
        "ref_texts": "[47] Jiaming Sun, Yiming Xie, Linghao Chen, Xiaowei Zhou, and Hujun Bao. NeuralRecon: Real-time coherent 3D reconstruction from monocular video. In CVPR , 2021. 2, 5",
        "ref_ids": [
          "47"
        ]
      },
      "Neural rgb-d surface reconstruction": {
        "authors": [
          "Dejan Azinovic",
          "Ricardo Martin",
          "Dan B",
          "Matthias Niessner",
          "Justus Thies"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2022/papers/Azinovic_Neural_RGB-D_Surface_Reconstruction_CVPR_2022_paper.pdf",
        "ref_texts": "[70] Cheng Sun, Min Sun, and Hwann-Tzong Chen. Direct voxel grid optimization: Super-fast convergence for radiance fields reconstruction. arXiv preprint arXiv:2111.11215 , 2021. 8[71] Jiaming Sun, Yiming Xie, Linghao Chen, Xiaowei Zhou, and Hujun Bao. NeuralRecon: Real-time coherent 3D reconstruction from monocular video. CVPR , 2021. 2",
        "ref_ids": [
          "70",
          "71"
        ]
      },
      "Neumesh: Learning disentangled neural mesh-based implicit field for geometry and texture editing": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2207.11911",
        "ref_texts": "49. Sun, J., Xie, Y., Chen, L., Zhou, X., Bao, H.: NeuralRecon: Real-time Coherent 3D Reconstruction from Monocular Video. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 15598\u201315607 (2021)",
        "ref_ids": [
          "49"
        ]
      },
      "Eslam: Efficient dense slam system based on hybrid representation of signed distance fields": {
        "authors": [
          "Mohammad Mahdi",
          "Camilla Carta",
          "Francois Fleuret"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Johari_ESLAM_Efficient_Dense_SLAM_System_Based_on_Hybrid_Representation_of_CVPR_2023_paper.pdf",
        "ref_texts": "[63] Jiaming Sun, Yiming Xie, Linghao Chen, Xiaowei Zhou, and Hujun Bao. Neuralrecon: Real-time coherent 3d reconstruc-tion from monocular video. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 15598\u201315607, 2021. 2",
        "ref_ids": [
          "63"
        ]
      },
      "Neural radiance fields in the industrial and robotics domain: applications, research opportunities and use cases": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2308.07118",
        "ref_texts": "[75] J. Sun, Y . Xie, L. Chen, X. Zhou, and H. Bao, \u201cNeuralRecon: Real-time coherent 3D reconstruction from monocular video,\u201d in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2021, pp. 15 598\u201315 607.",
        "ref_ids": [
          "75"
        ]
      },
      "Point-slam: Dense neural point cloud-based slam": {
        "authors": [
          "Erik Sandstrom",
          "Yue Li",
          "Luc Van",
          "Martin R. Oswald"
        ],
        "url": "https://openaccess.thecvf.com/content/ICCV2023/papers/Sandstrom_Point-SLAM_Dense_Neural_Point_Cloud-based_SLAM_ICCV_2023_paper.pdf",
        "ref_texts": "[54] Jiaming Sun, Yiming Xie, Linghao Chen, Xiaowei Zhou, and Hujun Bao. Neuralrecon: Real-time coherent 3d reconstruction from monocular video. In IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 15598\u2013",
        "ref_ids": [
          "54"
        ]
      },
      "Nerf-det: Learning geometry-aware volumetric representation for multi-view 3d object detection": {
        "authors": [
          "Chenfeng Xu",
          "Bichen Wu",
          "Ji Hou",
          "Sam Tsai",
          "Ruilong Li",
          "Jialiang Wang",
          "Wei Zhan",
          "Zijian He",
          "Peter Vajda",
          "Kurt Keutzer",
          "Masayoshi Tomizuka"
        ],
        "url": "http://openaccess.thecvf.com/content/ICCV2023/papers/Xu_NeRF-Det_Learning_Geometry-Aware_Volumetric_Representation_for_Multi-View_3D_Object_Detection_ICCV_2023_paper.pdf",
        "ref_texts": "[35] Jiaming Sun, Yiming Xie, Linghao Chen, Xiaowei Zhou, and Hujun Bao. NeuralRecon: Real-time coherent 3D reconstruction from monocular video. CVPR , 2021. 7",
        "ref_ids": [
          "35"
        ]
      },
      "Simplerecon: 3d reconstruction without 3d convolutions": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2208.14743",
        "ref_texts": "65. Sun, J., Xie, Y., Chen, L., Zhou, X., Bao, H.: NeuralRecon: Real-time coherent 3D reconstruction from monocular video. In: CVPR (2021)",
        "ref_ids": [
          "65"
        ]
      },
      "Transformerfusion: Monocular rgb scene reconstruction using transformers": {
        "authors": [],
        "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/0a87257e5308197df43230edf4ad1dae-Paper.pdf",
        "ref_texts": "[39] J. Sun, Y . Xie, L. Chen, X. Zhou, and H. Bao. NeuralRecon: Real-time coherent 3D reconstruction from monocular video. CVPR , 2021.",
        "ref_ids": [
          "39"
        ]
      },
      "Nerfusion: Fusing radiance fields for large-scale scene reconstruction": {
        "authors": [
          "Xiaoshuai Zhang",
          "Sai Bi",
          "Kalyan Sunkavalli",
          "Hao Su",
          "Zexiang Xu"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_NeRFusion_Fusing_Radiance_Fields_for_Large-Scale_Scene_Reconstruction_CVPR_2022_paper.pdf",
        "ref_texts": "[39] Jiaming Sun, Yiming Xie, Linghao Chen, Xiaowei Zhou, and Hujun Bao. NeuralRecon: Real-time coherent 3D reconstruction from monocular video. CVPR , 2021. 2, 5",
        "ref_ids": [
          "39"
        ]
      },
      "Neo 360: Neural fields for sparse view synthesis of outdoor scenes": {
        "authors": [
          "Muhammad Zubair",
          "Sergey Zakharov",
          "Katherine Liu",
          "Vitor Guizilini",
          "Thomas Kollar",
          "Adrien Gaidon",
          "Zsolt Kira",
          "Rares Ambrus"
        ],
        "url": "https://openaccess.thecvf.com/content/ICCV2023/papers/Irshad_NeO_360_Neural_Fields_for_Sparse_View_Synthesis_of_Outdoor_ICCV_2023_paper.pdf",
        "ref_texts": "[54] Jiaming Sun, Yiming Xie, Linghao Chen, Xiaowei Zhou, and Hujun Bao. Neuralrecon: Real-time coherent 3d reconstruction from monocular video. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 15598\u201315607, 2021. 3, 4",
        "ref_ids": [
          "54"
        ]
      },
      "Viewdiff: 3d-consistent image generation with text-to-image models": {
        "authors": [
          "Lukas Hollein",
          "Aljaz Bozi",
          "Norman Muller",
          "David Novotny",
          "Yu Tseng",
          "Christian Richardt",
          "Michael Zollhofer",
          "Matthias Niessner"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Hollein_ViewDiff_3D-Consistent_Image_Generation_with_Text-to-Image_Models_CVPR_2024_paper.pdf",
        "ref_texts": "[37] Jiaming Sun, Yiming Xie, Linghao Chen, Xiaowei Zhou, and Hujun Bao. NeuralRecon: Real-time coherent 3D reconstruction from monocular video. In CVPR , 2021. 4",
        "ref_ids": [
          "37"
        ]
      },
      "Neuraludf: Learning unsigned distance fields for multi-view reconstruction of surfaces with arbitrary topologies": {
        "authors": [
          "Xiaoxiao Long",
          "Cheng Lin",
          "Lingjie Liu",
          "Yuan Liu",
          "Peng Wang",
          "Christian Theobalt",
          "Taku Komura",
          "Wenping Wang"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2023/papers/Long_NeuralUDF_Learning_Unsigned_Distance_Fields_for_Multi-View_Reconstruction_of_Surfaces_CVPR_2023_paper.pdf",
        "ref_texts": "[44] Jiaming Sun, Yiming Xie, Linghao Chen, Xiaowei Zhou, and Hujun Bao. Neuralrecon: Real-time coherent 3d reconstruction from monocular video. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 15598\u201315607, 2021. 1, 2",
        "ref_ids": [
          "44"
        ]
      },
      "Neural map prior for autonomous driving": {
        "authors": [
          "Xuan Xiong",
          "Yicheng Liu",
          "Tianyuan Yuan",
          "Yue Wang",
          "Yilun Wang",
          "Hang Zhao"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2023/papers/Xiong_Neural_Map_Prior_for_Autonomous_Driving_CVPR_2023_paper.pdf",
        "ref_texts": "[31] Jiaming Sun, Yiming Xie, Linghao Chen, Xiaowei Zhou, and Hujun Bao. Neuralrecon: Real-time coherent 3d reconstruction from monocular video. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 15598\u201315607, 2021. 3",
        "ref_ids": [
          "31"
        ]
      },
      "Neuris: Neural reconstruction of indoor scenes using normal priors": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2206.13597",
        "ref_texts": "31. Sun, J., Xie, Y., Chen, L., Zhou, X., Bao, H.: NeuralRecon: Real-time coherent 3D reconstruction from monocular video. CVPR (2021)",
        "ref_ids": [
          "31"
        ]
      },
      "Plgslam: Progressive neural scene represenation with local to global bundle adjustment": {
        "authors": [
          "Tianchen Deng",
          "Guole Shen",
          "Tong Qin",
          "Jianyu Wang",
          "Wentao Zhao",
          "Jingchuan Wang",
          "Danwei Wang",
          "Weidong Chen"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Deng_PLGSLAM_Progressive_Neural_Scene_Represenation_with_Local_to_Global_Bundle_CVPR_2024_paper.pdf",
        "ref_texts": "[28] Jiaming Sun, Yiming Xie, Linghao Chen, Xiaowei Zhou, and Hujun Bao. Neuralrecon: Real-time coherent 3d reconstruction from monocular video. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) , pages 15598\u201315607, June 2021. 2",
        "ref_ids": [
          "28"
        ]
      },
      "RayMVSNet++: learning ray-based 1D implicit fields for accurate multi-view stereo": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2307.10233",
        "ref_texts": "[55] Jiaming Sun, Yiming Xie, Linghao Chen, Xiaowei Zhou, and Hujun Bao. Neuralrecon: Real-time coherent 3d reconstruction from monocular video. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 15598\u201315607, 2021.",
        "ref_ids": [
          "55"
        ]
      },
      "Volrecon: Volume rendering of signed ray distance functions for generalizable multi-view reconstruction": {
        "authors": [
          "Yufan Ren",
          "Tong Zhang",
          "Marc Pollefeys",
          "Sabine Susstrunk",
          "Fangjinhua Wang"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2023/papers/Ren_VolRecon_Volume_Rendering_of_Signed_Ray_Distance_Functions_for_Generalizable_CVPR_2023_paper.pdf",
        "ref_texts": "[42] Jiaming Sun, Yiming Xie, Linghao Chen, Xiaowei Zhou, and Hujun Bao. NeuralRecon: Real-time coherent 3d reconstruction from monocular video. In CVPR , pages 15598\u201315607, 2021. 2, 3, 8",
        "ref_ids": [
          "42"
        ]
      },
      "Multi-modal neural radiance field for monocular dense slam with a light-weight tof sensor": {
        "authors": [
          "Xinyang Liu",
          "Yijin Li",
          "Yanbin Teng",
          "Hujun Bao",
          "Guofeng Zhang",
          "Yinda Zhang",
          "Zhaopeng Cui"
        ],
        "url": "http://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Multi-Modal_Neural_Radiance_Field_for_Monocular_Dense_SLAM_with_a_ICCV_2023_paper.pdf",
        "ref_texts": "[32] Jiaming Sun, Yiming Xie, Linghao Chen, Xiaowei Zhou, and Hujun Bao. NeuralRecon: Real-Time Coherent 3D Reconstruction from Monocular Video. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 15593\u201315602, Nashville, TN, USA, 2021. IEEE.",
        "ref_ids": [
          "32"
        ]
      },
      "Loopy-slam: Dense neural slam with loop closures": {
        "authors": [
          "Lorenzo Liso",
          "Erik Sandstrom",
          "Vladimir Yugay",
          "Luc Van",
          "Martin R. Oswald"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Liso_Loopy-SLAM_Dense_Neural_SLAM_with_Loop_Closures_CVPR_2024_paper.pdf",
        "ref_texts": "[53] Jiaming Sun, Yiming Xie, Linghao Chen, Xiaowei Zhou, and Hujun Bao. Neuralrecon: Real-time coherent 3d recon-struction from monocular video. In IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 15598\u2013",
        "ref_ids": [
          "53"
        ]
      },
      "Fmgs: Foundation model embedded 3d gaussian splatting for holistic 3d scene understanding": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2401.01970",
        "ref_texts": "[50] Jiaming Sun, Yiming Xie, Linghao Chen, Xiaowei Zhou, and Hujun Bao. Neuralrecon: Real-time coherent 3d reconstruction from monocular video. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 15598\u201315607, 2021.",
        "ref_ids": [
          "50"
        ]
      },
      "Dp-nerf: Deblurred neural radiance field with physical scene priors": {
        "authors": [
          "Dogyoon Lee",
          "Minhyeok Lee",
          "Chajin Shin",
          "Sangyoun Lee"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Lee_DP-NeRF_Deblurred_Neural_Radiance_Field_With_Physical_Scene_Priors_CVPR_2023_paper.pdf",
        "ref_texts": "[47] Jiaming Sun, Yiming Xie, Linghao Chen, Xiaowei Zhou, and Hujun Bao. Neuralrecon: Real-time coherent 3d reconstruction from monocular video. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 15598\u201315607, 2021. 2",
        "ref_ids": [
          "47"
        ]
      },
      "Go-surf: Neural feature grid optimization for fast, high-fidelity rgb-d surface reconstruction": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2206.14735",
        "ref_texts": "[31] Jiaming Sun, Yiming Xie, Linghao Chen, Xiaowei Zhou, and Hujun Bao. Neuralrecon: Real-time coherent 3d reconstruction from monocular video. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 15598\u201315607, 2021. 2",
        "ref_ids": [
          "31"
        ]
      },
      "Gaussian-slam: Photo-realistic dense slam with gaussian splatting": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2312.10070",
        "ref_texts": "64. Sun, J., Xie, Y., Chen, L., Zhou, X., Bao, H.: Neuralrecon: Real-time coherent 3d reconstruction from monocular video. In: IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 15598\u201315607 (2021) 3",
        "ref_ids": [
          "64"
        ]
      },
      "Surfelnerf: Neural surfel radiance fields for online photorealistic reconstruction of indoor scenes": {
        "authors": [
          "Yiming Gao",
          "Pei Cao",
          "Ying Shan"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2023/papers/Gao_SurfelNeRF_Neural_Surfel_Radiance_Fields_for_Online_Photorealistic_Reconstruction_of_CVPR_2023_paper.pdf",
        "ref_texts": "[34] Jiaming Sun, Yiming Xie, Linghao Chen, Xiaowei Zhou, and Hujun Bao. Neuralrecon: Real-time coherent 3d reconstruction from monocular video. In IEEE CVPR , pages 15598\u2013",
        "ref_ids": [
          "34"
        ]
      },
      "Gnesf: Generalizable neural semantic fields": {
        "authors": [],
        "url": "https://proceedings.neurips.cc/paper_files/paper/2023/file/72d32f4fe0b7af03732bd227bf1c4a5f-Paper-Conference.pdf",
        "ref_texts": "[40] Jiaming Sun, Yiming Xie, Linghao Chen, Xiaowei Zhou, and Hujun Bao. Neuralrecon: Realtime coherent 3d reconstruction from monocular video. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 15598\u201315607, 2021.",
        "ref_ids": [
          "40"
        ]
      },
      "Shine-mapping: Large-scale 3d mapping using sparse hierarchical implicit neural representations": {
        "authors": [],
        "url": "https://www.ipb.uni-bonn.de/wp-content/papercite-data/pdf/zhong2023icra.pdf",
        "ref_texts": "[33] J. Sun, Y . Xie, L. Chen, X. Zhou, and H. Bao. NeuralRecon: Realtime coherent 3D reconstruction from monocular video. In Proc. of the IEEE/CVF Conf. on Computer Vision and Pattern Recognition (CVPR) , 2021.",
        "ref_ids": [
          "33"
        ]
      },
      "Pixel-aligned recurrent queries for multi-view 3d object detection": {
        "authors": [
          "Yiming Xie",
          "Huaizu Jiang",
          "Georgia Gkioxari",
          "Julian Straub"
        ],
        "url": "http://openaccess.thecvf.com/content/ICCV2023/papers/Xie_Pixel-Aligned_Recurrent_Queries_for_Multi-View_3D_Object_Detection_ICCV_2023_paper.pdf",
        "ref_texts": "[38] Jiaming Sun, Yiming Xie, Linghao Chen, Xiaowei Zhou, and Hujun Bao. Neuralrecon: Real-time coherent 3d reconstruction from monocular video. In CVPR , 2021. 5",
        "ref_ids": [
          "38"
        ]
      },
      "Volumefusion: Deep depth fusion for 3d scene reconstruction": {
        "authors": [
          "Jaesung Choe",
          "Sunghoon Im",
          "Francois Rameau",
          "Minjun Kang",
          "In So"
        ],
        "url": "https://openaccess.thecvf.com/content/ICCV2021/papers/Choe_VolumeFusion_Deep_Depth_Fusion_for_3D_Scene_Reconstruction_ICCV_2021_paper.pdf",
        "ref_texts": "[38] Jiaming Sun, Yiming Xie, Linghao Chen, Xiaowei Zhou, and Hujun Bao. Neuralrecon: Real-time coherent 3d reconstruction from monocular video. In IEEE Conf. Comput. Vis. Pattern Recog. , 2021. 1",
        "ref_ids": [
          "38"
        ]
      },
      "I2-sdf: Intrinsic indoor scene reconstruction and editing via raytracing in neural sdfs": {
        "authors": [
          "Jingsen Zhu",
          "Yuchi Huo",
          "Qi Ye",
          "Fujun Luan",
          "Jifan Li",
          "Dianbing Xi",
          "Lisha Wang",
          "Rui Tang",
          "Wei Hua",
          "Hujun Bao",
          "Rui Wang"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Zhu_I2-SDF_Intrinsic_Indoor_Scene_Reconstruction_and_Editing_via_Raytracing_in_CVPR_2023_paper.pdf",
        "ref_texts": "[31] Jiaming Sun, Yiming Xie, Linghao Chen, Xiaowei Zhou, and Hujun Bao. NeuralRecon: Real-time coherent 3D reconstruction from monocular video. In CVPR , 2021. 2",
        "ref_ids": [
          "31"
        ]
      },
      "Real acoustic fields: An audio-visual room acoustics dataset and benchmark": {
        "authors": [
          "Ziyang Chen",
          "Israel D. Gebru",
          "Christian Richardt",
          "Anurag Kumar",
          "William Laney",
          "Andrew Owens",
          "Alexander Richard"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Chen_Real_Acoustic_Fields_An_Audio-Visual_Room_Acoustics_Dataset_and_Benchmark_CVPR_2024_paper.pdf",
        "ref_texts": "[59] Jiaming Sun, Yiming Xie, Linghao Chen, Xiaowei Zhou, and Hujun Bao. NeuralRecon: Real-time coherent 3D reconstruction from monocular video. In CVPR , 2021. 3",
        "ref_ids": [
          "59"
        ]
      },
      "Planemvs: 3d plane reconstruction from multi-view stereo": {
        "authors": [
          "Jiachen Liu",
          "Pan Ji",
          "Nitin Bansal",
          "Changjiang Cai",
          "Qingan Yan",
          "Xiaolei Huang",
          "Yi Xu"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_PlaneMVS_3D_Plane_Reconstruction_From_Multi-View_Stereo_CVPR_2022_paper.pdf",
        "ref_texts": "[45] Jiaming Sun, Yiming Xie, Linghao Chen, Xiaowei Zhou, and Hujun Bao. Neuralrecon: Real-time coherent 3d reconstruction from monocular video. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 15598\u201315607, 2021. 3",
        "ref_ids": [
          "45"
        ]
      },
      "Vortx: Volumetric 3d reconstruction with transformers for voxelwise view selection and fusion": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2112.00236",
        "ref_texts": "[36] Jian Sun, Yin Li, Sing Bing Kang, and Heung-Yeung Shum. Symmetric stereo matching for occlusion handling. In 2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR\u201905) , volume 2, pages 399\u2013406. IEEE, 2005. 3[37] Jiaming Sun, Yiming Xie, Linghao Chen, Xiaowei Zhou, and Hujun Bao. NeuralRecon: Real-time coherent 3D reconstruction from monocular video. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 15598\u201315607, 2021. 1, 2, 3, 6, 7",
        "ref_ids": [
          "36",
          "37"
        ]
      },
      "Learning neural implicit through volume rendering with attentive depth fusion priors": {
        "authors": [],
        "url": "https://proceedings.neurips.cc/paper_files/paper/2023/file/68637ee6b30276f900bc67320466b69f-Paper-Conference.pdf",
        "ref_texts": "[67] Jiaming Sun, Yiming Xie, Linghao Chen, Xiaowei Zhou, and Hujun Bao. NeuralRecon: Real-time coherent 3D reconstruction from monocular video. IEEE Conference on Computer Vision and Pattern Recognition , 2021.",
        "ref_ids": [
          "67"
        ]
      },
      "Mvpsnet: Fast generalizable multi-view photometric stereo": {
        "authors": [
          "Dongxu Zhao",
          "Daniel Lichy",
          "Nicolas Perrin",
          "Michael Frahm",
          "Soumyadip Sengupta"
        ],
        "url": "http://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_MVPSNet_Fast_Generalizable_Multi-view_Photometric_Stereo_ICCV_2023_paper.pdf",
        "ref_texts": "[56] Jiaming Sun, Yiming Xie, Linghao Chen, Xiaowei Zhou, and Hujun Bao. NeuralRecon: Real-time coherent 3D reconstruction from monocular video. CVPR , 2021.",
        "ref_ids": [
          "56"
        ]
      },
      "Spacetime surface regularization for neural dynamic scene reconstruction": {
        "authors": [
          "Jaesung Choe",
          "Christopher Choy",
          "Jaesik Park",
          "In So",
          "Anima Anandkumar"
        ],
        "url": "https://openaccess.thecvf.com/content/ICCV2023/papers/Choe_Spacetime_Surface_Regularization_for_Neural_Dynamic_Scene_Reconstruction_ICCV_2023_paper.pdf",
        "ref_texts": "[64] Jiaming Sun, Yiming Xie, Linghao Chen, Xiaowei Zhou, and Hujun Bao. Neuralrecon: Real-time coherent 3d reconstruction from monocular video. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 15598\u201315607, 2021.",
        "ref_ids": [
          "64"
        ]
      },
      "Dg-recon: Depth-guided neural 3d scene reconstruction": {
        "authors": [
          "Jihong Ju",
          "Ching Wei",
          "Oleksandr Bailo",
          "Georgi Dikov",
          "Mohsen Ghafoorian"
        ],
        "url": "http://openaccess.thecvf.com/content/ICCV2023/papers/Ju_DG-Recon_Depth-Guided_Neural_3D_Scene_Reconstruction_ICCV_2023_paper.pdf",
        "ref_texts": "[42] Jiaming Sun, Yiming Xie, Linghao Chen, Xiaowei Zhou, and Hujun Bao. Neuralrecon: Real-time coherent 3d reconstruction from monocular video. In CVPR , 2021. 1, 2, 3, 4, 5, 6, 7, 8",
        "ref_ids": [
          "42"
        ]
      },
      "Finerecon: Depth-aware feed-forward network for detailed 3d reconstruction": {
        "authors": [
          "Noah Stier",
          "Anurag Ranjan",
          "Alex Colburn",
          "Yajie Yan",
          "Liang Yang",
          "Fangchang Ma",
          "Baptiste Angles"
        ],
        "url": "http://openaccess.thecvf.com/content/ICCV2023/papers/Stier_FineRecon_Depth-aware_Feed-forward_Network_for_Detailed_3D_Reconstruction_ICCV_2023_paper.pdf",
        "ref_texts": "[24] Jiaming Sun, Yiming Xie, Linghao Chen, Xiaowei Zhou, and Hujun Bao. Neuralrecon: Real-time coherent 3d reconstruction from monocular video. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 15598\u201315607, 2021. 1, 2, 3, 5, 6",
        "ref_ids": [
          "24"
        ]
      },
      "Fast learning radiance fields by shooting much fewer rays": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2208.06821",
        "ref_texts": "[59] Jiaming Sun, Yiming Xie, Linghao Chen, Xiaowei Zhou, and Hujun Bao. NeuralRecon: Real-time coherent 3D reconstruction from monocular video. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 15598\u201315607, 2021.",
        "ref_ids": [
          "59"
        ]
      },
      "Asynchronous hybrid reinforcement learning for latency and reliability optimization in the metaverse over wireless communications": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2212.14749",
        "ref_texts": "[5] J. Sun, Y . Xie, L. Chen, X. Zhou, and H. Bao, \u201cNeuralrecon: Real-time coherent 3D reconstruction from monocular video,\u201d in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , 2021, pp. 15 598\u201315 607.",
        "ref_ids": [
          "5"
        ]
      },
      "Sgaligner: 3d scene alignment with scene graphs": {
        "authors": [
          "Sayan Deb",
          "Ondrej Miksik",
          "Marc Pollefeys",
          "Daniel Barath",
          "Iro Armeni"
        ],
        "url": "https://openaccess.thecvf.com/content/ICCV2023/papers/Sarkar_SGAligner_3D_Scene_Alignment_with_Scene_Graphs_ICCV_2023_paper.pdf",
        "ref_texts": "[37] Jiaming Sun, Yiming Xie, Linghao Chen, Xiaowei Zhou, and Hujun Bao. NeuralRecon: Real-time coherent 3D reconstruction from monocular video. CVPR , 2021. 9",
        "ref_ids": [
          "37"
        ]
      },
      "Activermap: Radiance field for active mapping and planning": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2211.12656",
        "ref_texts": "[60] Jiaming Sun, Yiming Xie, Linghao Chen, Xiaowei Zhou, and Hujun Bao. Neuralrecon: Real-time coherent 3d reconstruction from monocular video. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 15598\u201315607, 2021. 2, 3",
        "ref_ids": [
          "60"
        ]
      },
      "Rgbd2: Generative scene synthesis via incremental view inpainting using rgbd diffusion models": {
        "authors": [
          "Jiabao Lei",
          "Jiapeng Tang",
          "Kui Jia"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2023/papers/Lei_RGBD2_Generative_Scene_Synthesis_via_Incremental_View_Inpainting_Using_RGBD_CVPR_2023_paper.pdf",
        "ref_texts": "[69] Jiaming Sun, Yiming Xie, Linghao Chen, Xiaowei Zhou, and Hujun Bao. Neuralrecon: Real-time coherent 3d reconstruc-tion from monocular video. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition(CVPR) , pages 15598\u201315607, June 2021. 5",
        "ref_ids": [
          "69"
        ]
      },
      "CVRecon: Rethinking 3d geometric feature learning for neural reconstruction": {
        "authors": [
          "Ziyue Feng",
          "Liang Yang",
          "Pengsheng Guo",
          "Bing Li"
        ],
        "url": "https://openaccess.thecvf.com/content/ICCV2023/papers/Feng_CVRecon_Rethinking_3D_Geometric_Feature_Learning_For_Neural_Reconstruction_ICCV_2023_paper.pdf",
        "ref_texts": "[31] Jiaming Sun, Yiming Xie, Linghao Chen, Xiaowei Zhou, and Hujun Bao. Neuralrecon: Real-time coherent 3d reconstruction from monocular video. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 15598\u201315607, 2021.",
        "ref_ids": [
          "31"
        ]
      },
      "Neural scene representation for locomotion on structured terrain": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2206.08077",
        "ref_texts": "[28] J. Sun, Y . Xie, L. Chen, X. Zhou, and H. Bao, \u201cNeuralrecon: Real-time coherent 3d reconstruction from monocular video,\u201d in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , 2021, pp. 15 598\u201315 607.",
        "ref_ids": [
          "28"
        ]
      },
      "Planarrecon: Real-time 3d plane detection and reconstruction from posed monocular videos": {
        "authors": [
          "Yiming Xie",
          "Matheus Gadelha",
          "Fengting Yang",
          "Xiaowei Zhou",
          "Huaizu Jiang"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2022/papers/Xie_PlanarRecon_Real-Time_3D_Plane_Detection_and_Reconstruction_From_Posed_Monocular_CVPR_2022_paper.pdf",
        "ref_texts": "[37] Jiaming Sun, Yiming Xie, Linghao Chen, Xiaowei Zhou, and Hujun Bao. Neuralrecon: Real-time coherent 3d reconstruction from monocular video. In CVPR , 2021. 1, 3, 4, 6, 7",
        "ref_ids": [
          "37"
        ]
      },
      "Input-level inductive biases for 3d reconstruction": {
        "authors": [
          "Wang Yifan",
          "Carl Doersch",
          "Relja Arandjelovic",
          "Joao Carreira",
          "Andrew Zisserman"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2022/papers/Yifan_Input-Level_Inductive_Biases_for_3D_Reconstruction_CVPR_2022_paper.pdf",
        "ref_texts": "[52] Jiaming Sun, Yiming Xie, Linghao Chen, Xiaowei Zhou, and Hujun Bao. NeuralRecon: Real-time coherent 3D reconstruction from monocular video. In CVPR , pages 15598\u2013",
        "ref_ids": [
          "52"
        ]
      },
      "Snap: Self-supervised neural maps for visual positioning and semantic understanding": {
        "authors": [],
        "url": "https://proceedings.neurips.cc/paper_files/paper/2023/file/182c433412b33c14e32a7c4fc2c3e290-Paper-Conference.pdf",
        "ref_texts": "[92] Jiaming Sun, Yiming Xie, Linghao Chen, Xiaowei Zhou, and Hujun Bao. NeuralRecon: Real-Time Coherent 3D Reconstruction from Monocular Video. CVPR , 2021. 7",
        "ref_ids": [
          "92"
        ]
      },
      "Fast monocular scene reconstruction with global-sparse local-dense grids": {
        "authors": [
          "Wei Dong",
          "Christopher Choy",
          "Charles Loop",
          "Or Litany",
          "Yuke Zhu",
          "Anima Anandkumar"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Dong_Fast_Monocular_Scene_Reconstruction_With_Global-Sparse_Local-Dense_Grids_CVPR_2023_paper.pdf",
        "ref_texts": "[38] Jiaming Sun, Yiming Xie, Linghao Chen, Xiaowei Zhou, and Hujun Bao. Neuralrecon: Real-time coherent 3d reconstruction from monocular video. In CVPR, pages 15598\u201315607, 2021. 1,3",
        "ref_ids": [
          "38"
        ]
      },
      "Planeformers: From sparse view planes to 3d reconstruction": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2208.04307",
        "ref_texts": "50. Sun, J., Xie, Y., Chen, L., Zhou, X., Bao, H.: Neuralrecon: Real-time coherent 3d reconstruction from monocular video. In: CVPR (2021) 3",
        "ref_ids": [
          "50"
        ]
      },
      "Depthcrafter: Generating consistent long depth sequences for open-world videos": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2409.02095",
        "ref_texts": "[56] Jiaming Sun, Yiming Xie, Linghao Chen, Xiaowei Zhou, and Hujun Bao. Neuralrecon: Real-time coherent 3d reconstruction from monocular video. In CVPR , 2021. 2",
        "ref_ids": [
          "56"
        ]
      },
      "Newton: Neural view-centric mapping for on-the-fly large-scale slam": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2303.13654",
        "ref_texts": "[25] Jiaming Sun, Yiming Xie, Linghao Chen, Xiaowei Zhou, and Hujun Bao. NeuralRecon: Real-time coherent 3D reconstruction from monocular video. Proc. IEEE Conf. on Computer Vision and Pattern Recognition (CVPR) , 2021. 2",
        "ref_ids": [
          "25"
        ]
      },
      "MonoIndoor++: Towards better practice of self-supervised monocular depth estimation for indoor environments": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2207.08951",
        "ref_texts": "[77] J. Sun, Y . Xie, L. Chen, X. Zhou, and H. Bao, \u201cNeuralRecon: Real-time coherent 3D reconstruction from monocular video,\u201d CVPR , 2021.",
        "ref_ids": [
          "77"
        ]
      },
      "Self-supervised super-plane for neural 3d reconstruction": {
        "authors": [
          "Botao Ye",
          "Sifei Liu",
          "Xueting Li",
          "Hsuan Yang"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2023/papers/Ye_Self-Supervised_Super-Plane_for_Neural_3D_Reconstruction_CVPR_2023_paper.pdf",
        "ref_texts": "[34] Jiaming Sun, Yiming Xie, Linghao Chen, Xiaowei Zhou, and Hujun Bao. Neuralrecon: Real-time coherent 3d reconstruction from monocular video. In CVPR , 2021. 1, 2, 6",
        "ref_ids": [
          "34"
        ]
      },
      "Depth field networks for generalizable multi-view scene representation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2207.14287",
        "ref_texts": "45. Sun, J., Xie, Y., Chen, L., Zhou, X., Bao, H.: NeuralRecon: Real-time coherent 3D reconstruction from monocular video. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR). pp. 15598\u201315607 (June 2021)",
        "ref_ids": [
          "45"
        ]
      },
      "Learning a room with the occ-sdf hybrid: Signed distance function mingled with occupancy aids scene representation": {
        "authors": [
          "Xiaoyang Lyu",
          "Peng Dai",
          "Zizhang Li",
          "Dongyu Yan",
          "Yi Lin",
          "Yifan Peng",
          "Xiaojuan Qi"
        ],
        "url": "https://openaccess.thecvf.com/content/ICCV2023/papers/Lyu_Learning_a_Room_with_the_Occ-SDF_Hybrid_Signed_Distance_Function_ICCV_2023_paper.pdf",
        "ref_texts": "[28] Jiaming Sun, Yiming Xie, Linghao Chen, Xiaowei Zhou, and Hujun Bao. Neuralrecon: Real-time coherent 3d reconstruc-tion from monocular video. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 15598\u201315607, 2021. 3",
        "ref_ids": [
          "28"
        ]
      },
      "Nerfvs: Neural radiance fields for free view synthesis via geometry scaffolds": {
        "authors": [
          "Chen Yang",
          "Peihao Li",
          "Zanwei Zhou",
          "Shanxin Yuan",
          "Bingbing Liu",
          "Xiaokang Yang",
          "Weichao Qiu",
          "Wei Shen"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Yang_NeRFVS_Neural_Radiance_Fields_for_Free_View_Synthesis_via_Geometry_CVPR_2023_paper.pdf",
        "ref_texts": "[22] Jiaming Sun, Yiming Xie, Linghao Chen, Xiaowei Zhou, and Hujun Bao. Neuralrecon: Real-time coherent 3d reconstruction from monocular video. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 15598\u201315607, 2021. 2",
        "ref_ids": [
          "22"
        ]
      },
      "Neslam: Neural implicit mapping and self-supervised feature tracking with depth completion and denoising": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2403.20034",
        "ref_texts": "[38] J. Sun, Y . Xie, L. Chen, X. Zhou, and H. Bao, \u201cNeuralrecon: Real-time coherent 3d reconstruction from monocular video,\u201d in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , June 2021, pp. 15 598\u201315 607.",
        "ref_ids": [
          "38"
        ]
      },
      "Neuralroom: Geometry-constrained neural implicit surfaces for indoor scene reconstruction": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2210.06853",
        "ref_texts": "(CVPR\u201906) , Vol. 1. IEEE, 519\u2013528. Jiaming Sun, Yiming Xie, Linghao Chen, Xiaowei Zhou, and Hujun Bao. 2021a. NeuralRecon: Real-time coherent 3D reconstruction from monocular video. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition . 15598\u201315607. Shang Sun, Yunan Zheng, Xuelei Shi, Zhenyu Xu, and Yiguang Liu. 2021b. PHI-MVS: Plane Hypothesis Inference Multi-view Stereo for Large-Scale Scene Reconstruction. arXiv preprint arXiv:2104.06165 (2021). Matthew Tancik, Vincent Casser, Xinchen Yan, Sabeek Pradhan, Ben Mildenhall, Pratul P Srinivasan, Jonathan T Barron, and Henrik Kretzschmar. 2022. Block-NeRF: Scalable Large Scene Neural View Synthesis. arXiv preprint arXiv:2202.05263 (2022). Zachary Teed and Jia Deng. 2018. Deepv2d: Video to depth with differentiable structure from motion. arXiv preprint arXiv:1812.04605 (2018). Julien Valentin, Angela Dai, Matthias Nie\u00dfner, Pushmeet Kohli, Philip Torr, Shahram Izadi, and Cem Keskin. 2016. Learning to Navigate the Energy Landscape. arXiv preprint arXiv:1603.05772 (2016). Fangjinhua Wang, Silvano Galliani, Christoph Vogel, Pablo Speciale, and Marc Pollefeys."
      },
      "Reality3dsketch: Rapid 3d modeling of objects from single freehand sketches": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2310.18148",
        "ref_texts": "[51] J. Sun, Y . Xie, L. Chen, X. Zhou, and H. Bao, \u201cNeuralrecon: Real-time coherent 3d reconstruction from monocular video,\u201d in CVPR , 2021, pp.",
        "ref_ids": [
          "51"
        ]
      },
      "Parf: Primitive-aware radiance fusion for indoor scene novel view synthesis": {
        "authors": [
          "Haiyang Ying",
          "Baowei Jiang",
          "Jinzhi Zhang",
          "Di Xu",
          "Tao Yu",
          "Qionghai Dai",
          "Lu Fang"
        ],
        "url": "http://openaccess.thecvf.com/content/ICCV2023/papers/Ying_PARF_Primitive-Aware_Radiance_Fusion_for_Indoor_Scene_Novel_View_Synthesis_ICCV_2023_paper.pdf",
        "ref_texts": "[34] Jiaming Sun, Yiming Xie, Linghao Chen, Xiaowei Zhou, and Hujun Bao. Neuralrecon: Real-time coherent 3d reconstruction from monocular video. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 15598\u201315607, 2021. 2,3",
        "ref_ids": [
          "34"
        ]
      },
      "3dvnet: Multi-view depth prediction and volumetric refinement": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2112.00202",
        "ref_texts": "[24] Jiaming Sun, Yiming Xie, Linghao Chen, Xiaowei Zhou, and Hujun Bao. NeuralRecon: Real-time coherent 3D reconstruction from monocular video. In Conference on Computer Vision and Pattern Recognition (CVPR) , 2021. 1, 3, 6",
        "ref_ids": [
          "24"
        ]
      },
      "Mononeuralfusion: Online monocular neural 3d reconstruction with geometric priors": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2209.15153",
        "ref_texts": "[22] J. Sun, Y. Xie, L. Chen, X. Zhou, and H. Bao, \u201cNeuralrecon: Realtime coherent 3d reconstruction from monocular video,\u201d in IEEE CVPR , 2021, pp. 15 598\u201315 607.",
        "ref_ids": [
          "22"
        ]
      },
      "Efficient implicit neural reconstruction using lidar": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2302.14363",
        "ref_texts": "[25] J. Sun, Y . Xie, L. Chen, X. Zhou, and H. Bao, \u201cNeuralrecon: Real-time coherent 3d reconstruction from monocular video,\u201d in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2021, pp. 15 598\u201315 607.",
        "ref_ids": [
          "25"
        ]
      },
      "Immesh: An immediate lidar localization and meshing framework": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2301.05206",
        "ref_texts": "[80] J. Sun, Y . Xie, L. Chen, X. Zhou, and H. Bao, \u201cNeuralrecon: Real-time coherent 3d reconstruction from monocular video,\u201d in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , 2021, pp. 15 598\u201315 607.",
        "ref_ids": [
          "80"
        ]
      },
      "Debsdf: Delving into the details and bias of neural indoor scene reconstruction": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2308.15536",
        "ref_texts": "[31] J. Sun, Y. Xie, L. Chen, X. Zhou, and H. Bao, \u201cNeuralRecon: Real-Time Coherent 3D Reconstruction from Monocular Video,\u201d in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pp. 15598\u201315607, 2021. 3",
        "ref_ids": [
          "31"
        ]
      },
      "Fully sparse 3d occupancy prediction": {
        "authors": [],
        "url": "https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/03570.pdf",
        "ref_texts": "47. Sun, J., Xie, Y., Chen, L., Zhou, X., Bao, H.: Neuralrecon: Real-time coherent 3d reconstruction from monocular video. In: CVPR (2021)",
        "ref_ids": [
          "47"
        ]
      },
      "Joint depth prediction and semantic segmentation with multi-view sam": {
        "authors": [
          "Mykhailo Shvets",
          "Dongxu Zhao",
          "Marc Niethammer",
          "Roni Sengupta",
          "Alexander C. Berg"
        ],
        "url": "https://openaccess.thecvf.com/content/WACV2024/papers/Shvets_Joint_Depth_Prediction_and_Semantic_Segmentation_With_Multi-View_SAM_WACV_2024_paper.pdf",
        "ref_texts": "[43] Jiaming Sun, Yiming Xie, Linghao Chen, Xiaowei Zhou, and Hujun Bao. Neuralrecon: Real-time coherent 3d reconstruction from monocular video. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 15598\u201315607, 2021. 1, 3",
        "ref_ids": [
          "43"
        ]
      },
      "Volumetric bundle adjustment for online photorealistic scene capture": {
        "authors": [
          "Ronald Clark"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2022/papers/Clark_Volumetric_Bundle_Adjustment_for_Online_Photorealistic_Scene_Capture_CVPR_2022_paper.pdf",
        "ref_texts": "[18] Jiaming Sun, Yiming Xie, Linghao Chen, Xiaowei Zhou, and Hujun Bao. Neuralrecon: Real-time coherent 3d reconstruction from monocular video. In IEEE Conf. Comput. Vis. Pattern Recog. , 2021. 2, 5",
        "ref_ids": [
          "18"
        ]
      },
      "Fully sparse 3d panoptic occupancy prediction": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2312.17118",
        "ref_texts": "[47] Sun, J., Xie, Y ., Chen, L., Zhou, X., Bao, H.: Neuralrecon: Real-time coherent 3d reconstruction from monocular video. In: CVPR (2021)",
        "ref_ids": [
          "47"
        ]
      },
      "Cross-dimensional refined learning for real-time 3d visual perception from monocular video": {
        "authors": [
          "Ziyang Hong",
          "Patrick Yue"
        ],
        "url": "https://openaccess.thecvf.com/content/ICCV2023W/JRDB/papers/Hong_Cross-Dimensional_Refined_Learning_for_Real-Time_3D_Visual_Perception_from_Monocular_ICCVW_2023_paper.pdf",
        "ref_texts": "[39] Jiaming Sun, Yiming Xie, Linghao Chen, Xiaowei Zhou, and Hujun Bao. Neuralrecon: Real-time coherent 3d reconstruction from monocular video. In CVPR , pages 15598\u201315607, 2021. 1,2,3,4,5,6,7,8",
        "ref_ids": [
          "39"
        ]
      },
      "Real-time dense 3d mapping of underwater environments": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2304.02704",
        "ref_texts": "[33] J. Sun, Y . Xie, L. Chen, X. Zhou, and H. Bao, \u201cNeuralRecon: Real-time coherent 3D reconstruction from monocular video,\u201d in CVPR , 2021, pp. 15 598\u201315 607.",
        "ref_ids": [
          "33"
        ]
      },
      "What's the Situation With Intelligent Mesh Generation: A Survey and Perspectives": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2211.06009",
        "ref_texts": "[90] J. Sun, Y. Xie, L. Chen, X. Zhou, and H. Bao, \u201cNeuralrecon: Real-time coherent 3d reconstruction from monocular video,\u201d in CVPR , 2021, pp. 15 598\u201315 607.",
        "ref_ids": [
          "90"
        ]
      },
      "Nis-slam: Neural implicit semantic rgb-d slam for 3d consistent scene understanding": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2407.20853",
        "ref_texts": "[59] J. Sun, Y . Xie, L. Chen, X. Zhou, and H. Bao. NeuralRecon: Realtime coherent 3D reconstruction from monocular video. In IEEE/CVF Conference on Computer Vision and Pattern Recognition , 2021. 2",
        "ref_ids": [
          "59"
        ]
      },
      "Time-Distributed Framework for 3D Reconstruction Integrating Fringe Projection with Deep Learning": {
        "authors": [
          "Hieu Nguyen",
          "Zhaoyang Wang"
        ],
        "url": "https://www.mdpi.com/1424-8220/23/16/7284/pdf",
        "ref_texts": "26. Sun, J.; Xie, Y.; Chen, L.; Zhou, X.; Bao, H. NeuralRecon: Real-Time Coherent 3D Reconstruction from Monocular Video. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), Nashville, TN, USA, 20\u201325 June 2021; pp. 15593\u201315602. [CrossRef]",
        "ref_ids": [
          "26"
        ]
      },
      "Applications of 3D Reconstruction in Virtual Reality-Based Teleoperation: A Review in the Mining Industry": {
        "authors": [
          "Alireza Kamran",
          "Amin Moniri",
          "Javad Sattarvand"
        ],
        "url": "https://www.mdpi.com/2227-7080/12/3/40/pdf",
        "ref_texts": "114. Sun, J.; Xie, Y.; Chen, L.; Zhou, X.; Bao, H. NeuralRecon: Real-Time Coherent 3D Reconstruction from Monocular Video. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), Virtual, 19\u201325 June 2021; pp. 15598\u201315607.",
        "ref_ids": [
          "114"
        ]
      },
      "Implicit ray transformers for multiview remote sensing image segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2303.08401",
        "ref_texts": "[15] J. Sun, Y . Xie, L. Chen, X. Zhou, and H. Bao, \u201cNeuralrecon: Real-time coherent 3d reconstruction from monocular video,\u201d in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , 2021, pp.",
        "ref_ids": [
          "15"
        ]
      },
      "Multi-view 3D object reconstruction and uncertainty modelling with neural shape prior": {
        "authors": [
          "Ziwei Liao",
          "Steven L. Waslander"
        ],
        "url": "https://openaccess.thecvf.com/content/WACV2024/papers/Liao_Multi-View_3D_Object_Reconstruction_and_Uncertainty_Modelling_With_Neural_Shape_WACV_2024_paper.pdf",
        "ref_texts": "[44] Jiaming Sun, Yiming Xie, Linghao Chen, Xiaowei Zhou, and Hujun Bao. Neuralrecon: Real-time coherent 3d reconstruction from monocular video. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 15598\u201315607, 2021.",
        "ref_ids": [
          "44"
        ]
      },
      "Visfusion: Visibility-aware online 3d scene reconstruction from videos": {
        "authors": [
          "Huiyu Gao",
          "Wei Mao",
          "Miaomiao Liu"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2023/papers/Gao_VisFusion_Visibility-Aware_Online_3D_Scene_Reconstruction_From_Videos_CVPR_2023_paper.pdf",
        "ref_texts": "[26] Jiaming Sun, Yiming Xie, Linghao Chen, Xiaowei Zhou, and Hujun Bao. Neuralrecon: Real-time coherent 3d reconstruction from monocular video. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 15598\u201315607, 2021. 1, 2, 3, 4, 5, 6, 7, 8",
        "ref_ids": [
          "26"
        ]
      },
      "3D reconstruction of remote sensing mountain areas with TSDF-based neural networks": {
        "authors": [
          "Zipeng Qi",
          "Zhengxia Zou",
          "Hao Chen",
          "Zhenwei Shi"
        ],
        "url": "https://www.mdpi.com/2072-4292/14/17/4333/pdf",
        "ref_texts": "13. Sun, J.; Xie, Y.; Chen, L.; Zhou, X.; Bao, H. NeuralRecon: Real-Time Coherent 3D Reconstruction from Monocular Video. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, Nashville, TN, USA, 20\u201325 June 2021; pp. 15598\u201315607.",
        "ref_ids": [
          "13"
        ]
      },
      "Svr-net: A sparse voxelized recurrent network for robust monocular slam with direct tsdf mapping": {
        "authors": [
          "Rongling Lang",
          "Ya Fan",
          "Qing Chang"
        ],
        "url": "https://www.mdpi.com/1424-8220/23/8/3942/pdf",
        "ref_texts": "18. Sun, J.; Xie, Y.; Chen, L.; Zhou, X.; Bao, H. NeuralRecon: Real-Time Coherent 3D Reconstruction from Monocular Video. arXiv 2021 , arXiv:2104.00681.",
        "ref_ids": [
          "18"
        ]
      },
      "Geometry-guided Feature Learning and Fusion for Indoor Scene Reconstruction": {
        "authors": [
          "Ruihong Yin",
          "Sezer Karaoglu",
          "Theo Gevers"
        ],
        "url": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yin_Geometry-guided_Feature_Learning_and_Fusion_for_Indoor_Scene_Reconstruction_ICCV_2023_paper.pdf",
        "ref_texts": "[30] Jiaming Sun, Yiming Xie, Linghao Chen, Xiaowei Zhou, and Hujun Bao. Neuralrecon: Real-time coherent 3d reconstruction from monocular video. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 15598\u201315607, 2021.",
        "ref_ids": [
          "30"
        ]
      },
      "Intraoperative margin assessment for basal cell carcinoma with deep learning and histologic tumor mapping to surgical site": {
        "authors": [
          "Joshua J"
        ],
        "url": "https://www.nature.com/articles/s41698-023-00477-7.pdf",
        "ref_texts": "91. Sun, J., Xie, Y., Chen, L., Zhou, X. & Bao, H. NeuralRecon: Real-time coherent 3D reconstruction from monocular video. in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition 15598 \u201315607 (2021).",
        "ref_ids": [
          "91"
        ]
      },
      "GenNBV: Generalizable Next-Best-View Policy for Active 3D Reconstruction": {
        "authors": [
          "Xiao Chen",
          "Quanyi Li",
          "Tai Wang",
          "Tianfan Xue",
          "Jiangmiao Pang"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Chen_GenNBV_Generalizable_Next-Best-View_Policy_for_Active_3D_Reconstruction_CVPR_2024_paper.pdf",
        "ref_texts": "[38] Jiaming Sun, Yiming Xie, Linghao Chen, Xiaowei Zhou, and Hujun Bao. NeuralRecon: Real-time coherent 3d reconstruction from monocular video. In Proceedings of the IEEE/CVFConference on Computer Vision and Pattern Recognition , pages 15598\u201315607, 2021. 1",
        "ref_ids": [
          "38"
        ]
      },
      "GOV-NeSF: Generalizable Open-Vocabulary Neural Semantic Fields": {
        "authors": [
          "Yunsong Wang",
          "Hanlin Chen",
          "Gim Hee"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Wang_GOV-NeSF_Generalizable_Open-Vocabulary_Neural_Semantic_Fields_CVPR_2024_paper.pdf",
        "ref_texts": "[36] Jiaming Sun, Yiming Xie, Linghao Chen, Xiaowei Zhou, and Hujun Bao. NeuralRecon: Real-time coherent 3D reconstruction from monocular video. CVPR , 2021. 5",
        "ref_ids": [
          "36"
        ]
      },
      "AirPlanes: Accurate Plane Estimation via 3D-Consistent Embeddings": {
        "authors": [
          "Jamie Watson",
          "Filippo Aleotti",
          "Mohamed Sayed",
          "Zawar Qureshi",
          "Oisin Mac",
          "Gabriel Brostow",
          "Michael Firman",
          "Sara Vicente"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Watson_AirPlanes_Accurate_Plane_Estimation_via_3D-Consistent_Embeddings_CVPR_2024_paper.pdf",
        "ref_texts": "[70] Jiaming Sun, Yiming Xie, Linghao Chen, Xiaowei Zhou, and Hujun Bao. NeuralRecon: Real-time coherent 3D reconstruction from monocular video. In CVPR , 2021. 3, 6",
        "ref_ids": [
          "70"
        ]
      },
      "Neural 3D reconstruction from sparse views using geometric priors": {
        "authors": [],
        "url": "https://link.springer.com/content/pdf/10.1007/s41095-023-0337-5.pdf",
        "ref_texts": "[7]Sun, J. M.; Xie, Y. M.; Chen, L. H.; Zhou, X. W.; Bao, H. J. NeuralRecon: Real-time coherent 3D reconstruction from monocular video. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 15593\u201315602, 2021.",
        "ref_ids": [
          "7"
        ]
      },
      "3d reconstruction with generalizable neural fields using scene priors": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2309.15164",
        "ref_texts": "4104\u20134113, 2016. 3 Johannes L Sch \u00a8onberger, Enliang Zheng, Jan-Michael Frahm, and Marc Pollefeys. Pixelwise view selection for unstructured multi-view stereo. In ECCV , pp. 501\u2013518. Springer, 2016. 3, 8 Vincent Sitzmann, Julien Martel, Alexander Bergman, David Lindell, and Gordon Wetzstein. Implicit neural representations with periodic activation functions. Advances in Neural Information Processing Systems , 33:7462\u20137473, 2020. 8 Jan Smisek, Michal Jancosek, and Tomas Pajdla. 3d with kinect. In Consumer depth cameras for computer vision , pp. 3\u201325. Springer, 2013. 2 Edgar Sucar, Shikun Liu, Joseph Ortiz, and Andrew J Davison. imap: Implicit mapping and positioning in real-time. In Proceedings of the IEEE/CVF International Conference on Computer Vision , pp. 6229\u20136238, 2021. 3 Cheng Sun, Min Sun, and Hwann-Tzong Chen. Direct voxel grid optimization: Super-fast convergence for radiance fields reconstruction. In CVPR , 2022a. 3 Cheng Sun, Min Sun, and Hwann-Tzong Chen. Direct voxel grid optimization: Super-fast convergence for radiance fields reconstruction. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pp. 5459\u20135469, 2022b. 2 Jiaming Sun, Yiming Xie, Linghao Chen, Xiaowei Zhou, and Hujun Bao. Neuralrecon: Real-time coherent 3d reconstruction from monocular video. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pp. 15598\u201315607, 2021. 3 Towaki Takikawa, Joey Litalien, Kangxue Yin, Karsten Kreis, Charles Loop, Derek Nowrouzezahrai, Alec Jacobson, Morgan McGuire, and Sanja Fidler. Neural geometric level of detail: Real-time rendering with implicit 3d shapes. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pp. 11358\u201311367, 2021. 2 Jiepeng Wang, Peng Wang, Xiaoxiao Long, Christian Theobalt, Taku Komura, Lingjie Liu, and Wenping Wang. Neuris: Neural reconstruction of indoor scenes using normal priors. In European Conference on Computer Vision , pp. 139\u2013155. Springer, 2022a. 8"
      },
      "Learning to predict scene-level implicit 3d from posed rgbd data": {
        "authors": [
          "Nilesh Kulkarni",
          "Linyi Jin",
          "Justin Johnson",
          "David F. Fouhey"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Kulkarni_Learning_To_Predict_Scene-Level_Implicit_3D_From_Posed_RGBD_Data_CVPR_2023_paper.pdf",
        "ref_texts": "[51] Jiaming Sun, Yiming Xie, Linghao Chen, Xiaowei Zhou, and Hujun Bao. Neuralrecon: Real-time coherent 3d reconstruction from monocular video. In CVPR , 2021. 2",
        "ref_ids": [
          "51"
        ]
      },
      "SuperPrimitive: Scene Reconstruction at a Primitive Level": {
        "authors": [
          "Kirill Mazur",
          "Gwangbin Bae",
          "Andrew J. Davison"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Mazur_SuperPrimitive_Scene_Reconstruction_at_a_Primitive_Level_CVPR_2024_paper.pdf",
        "ref_texts": "[48] Jiaming Sun, Yiming Xie, Linghao Chen, Xiaowei Zhou, and Hujun Bao. NeuralRecon: Real-time coherent 3D reconstruction from monocular video. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2021. 2",
        "ref_ids": [
          "48"
        ]
      },
      "ICON: Incremental CONfidence for Joint Pose and Radiance Field Optimization": {
        "authors": [
          "Weiyao Wang",
          "Pierre Gleize",
          "Hao Tang",
          "Xingyu Chen",
          "Kevin J",
          "Matt Feiszli"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Wang_ICON_Incremental_CONfidence_for_Joint_Pose_and_Radiance_Field_Optimization_CVPR_2024_paper.pdf",
        "ref_texts": "[53] Jiaming Sun, Yiming Xie, Linghao Chen, Xiaowei Zhou, and Hujun Bao. NeuralRecon: Real-time coherent 3D reconstruction from monocular video. CVPR , 2021. 1",
        "ref_ids": [
          "53"
        ]
      },
      "IPoD: Implicit Field Learning with Point Diffusion for Generalizable 3D Object Reconstruction from Single RGB-D Images": {
        "authors": [
          "Yushuang Wu",
          "Luyue Shi",
          "Junhao Cai",
          "Weihao Yuan",
          "Lingteng Qiu",
          "Zilong Dong",
          "Liefeng Bo",
          "Shuguang Cui",
          "Xiaoguang Han"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Wu_IPoD_Implicit_Field_Learning_with_Point_Diffusion_for_Generalizable_3D_CVPR_2024_paper.pdf",
        "ref_texts": "[56] Jiaming Sun, Yiming Xie, Linghao Chen, Xiaowei Zhou, and Hujun Bao. Neuralrecon: Real-time coherent 3d reconstruction from monocular video. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) , pages 15598\u201315607, 2021. 5",
        "ref_ids": [
          "56"
        ]
      },
      "Retr: Modeling rendering via transformer for generalizable neural surface reconstruction": {
        "authors": [],
        "url": "https://proceedings.neurips.cc/paper_files/paper/2023/file/c47ec10bc135be5c3663ba344d29a6a5-Paper-Conference.pdf",
        "ref_texts": "[50] J. Sun, Y . Xie, L. Chen, X. Zhou, and H. Bao, \u201cNeuralrecon: Real-time coherent 3d reconstruction from monocular video,\u201d in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , 2021, pp. 15 598\u201315 607.",
        "ref_ids": [
          "50"
        ]
      },
      "PanoRecon: Real-Time Panoptic 3D Reconstruction from Monocular Video": {
        "authors": [
          "Dong Wu",
          "Zike Yan",
          "Hongbin Zha"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Wu_PanoRecon_Real-Time_Panoptic_3D_Reconstruction_from_Monocular_Video_CVPR_2024_paper.pdf",
        "ref_texts": "[7] Jiaming Sun, Yiming Xie, Linghao Chen, Xiaowei Zhou, and Hujun Bao. Neuralrecon: Real-time coherent 3d reconstruc-tion from monocular video. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 15598\u201315607, 2021. 3,4,5,6",
        "ref_ids": [
          "7"
        ]
      },
      "Gated Fields: Learning Scene Reconstruction from Gated Videos": {
        "authors": [
          "Andrea Ramazzina",
          "Stefanie Walz",
          "Pragyan Dahal",
          "Mario Bijelic",
          "Felix Heide"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Ramazzina_Gated_Fields_Learning_Scene_Reconstruction_from_Gated_Videos_CVPR_2024_paper.pdf",
        "ref_texts": "[79] Jiaming Sun, Yiming Xie, Linghao Chen, Xiaowei Zhou, and Hujun Bao. Neuralrecon: Real-time coherent 3d reconstruction from monocular video. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 15598\u201315607, 2021. 1",
        "ref_ids": [
          "79"
        ]
      },
      "Roboscript: Code generation for free-form manipulation tasks across real and simulation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2402.14623",
        "ref_texts": "[54] Jiaming Sun, Yiming Xie, Linghao Chen, Xiaowei Zhou, and Hujun Bao. Neuralrecon: Real-time coherent 3d reconstruction from monocular video. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 15598\u201315607, 2021. 5",
        "ref_ids": [
          "54"
        ]
      },
      "Human body shape completion with implicit shape and flow learning": {
        "authors": [
          "Boyao Zhou",
          "Di Meng",
          "Sebastien Franco",
          "Edmond Boyer"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2023/papers/Zhou_Human_Body_Shape_Completion_With_Implicit_Shape_and_Flow_Learning_CVPR_2023_paper.pdf",
        "ref_texts": "[43] Jiaming Sun, Yiming Xie, Linghao Chen, Xiaowei Zhou, and Hujun Bao. NeuralRecon: Real-time coherent 3D reconstruction from monocular video. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2021. 3",
        "ref_ids": [
          "43"
        ]
      },
      "Sparse Convolutional Networks for Surface Reconstruction from Noisy Point Clouds": {
        "authors": [
          "Tao Wang",
          "Jing Wu",
          "Ze Ji",
          "Kun Lai"
        ],
        "url": "https://openaccess.thecvf.com/content/WACV2024/papers/Wang_Sparse_Convolutional_Networks_for_Surface_Reconstruction_From_Noisy_Point_Clouds_WACV_2024_paper.pdf",
        "ref_texts": "[39] Jiaming Sun, Yiming Xie, Linghao Chen, Xiaowei Zhou, and Hujun Bao. Neuralrecon: Real-time coherent 3d reconstruction from monocular video. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 15598\u201315607, 2021. 3",
        "ref_ids": [
          "39"
        ]
      },
      "ObjectFusion: Accurate object-level SLAM with neural object priors": {
        "authors": [
          "Xin Zou"
        ],
        "url": "https://shishenghuang.github.io/index/Papers/objectfusion/objectfusion.pdf",
        "ref_texts": "[48] J. Sun, Y. Xie, L. Chen, X. Zhou, H. Bao, NeuralRecon: Real-time coherent 3D reconstruction from monocular video, in: IEEE CVPR, 2021, pp. 15598\u201315607.",
        "ref_ids": [
          "48"
        ]
      },
      "Glorie-slam: Globally optimized rgb-only implicit encoding point cloud slam": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2403.19549",
        "ref_texts": "63. Sun, J., Xie, Y., Chen, L., Zhou, X., Bao, H.: Neuralrecon: Real-time coherent 3d reconstruction from monocular video. In: IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 15598\u201315607 (2021)",
        "ref_ids": [
          "63"
        ]
      },
      "3DFIRES: Few Image 3D REconstruction for Scenes with Hidden Surfaces": {
        "authors": [
          "Linyi Jin",
          "Nilesh Kulkarni",
          "David F. Fouhey"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Jin_3DFIRES_Few_Image_3D_REconstruction_for_Scenes_with_Hidden_Surfaces_CVPR_2024_paper.pdf",
        "ref_texts": "[38] Jiaming Sun, Yiming Xie, Linghao Chen, Xiaowei Zhou, and Hujun Bao. Neuralrecon: Real-time coherent 3d reconstruction from monocular video. In CVPR , 2021. 2,5",
        "ref_ids": [
          "38"
        ]
      },
      "Temporally consistent online depth estimation using point-based fusion": {
        "authors": [
          "Numair Khan",
          "Eric Penner",
          "Douglas Lanman",
          "Lei Xiao"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Khan_Temporally_Consistent_Online_Depth_Estimation_Using_Point-Based_Fusion_CVPR_2023_paper.pdf",
        "ref_texts": "[38] Jiaming Sun, Yiming Xie, Linghao Chen, Xiaowei Zhou, and Hujun Bao. Neuralrecon: Real-time coherent 3d reconstruction from monocular video. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 15598\u201315607, 2021. 5",
        "ref_ids": [
          "38"
        ]
      },
      "Multi-view reconstruction using signed ray distance functions (srdf)": {
        "authors": [
          "Pierre Zins",
          "Yuanlu Xu",
          "Edmond Boyer",
          "Stefanie Wuhrer",
          "Tony Tung"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2023/papers/Zins_Multi-View_Reconstruction_Using_Signed_Ray_Distance_Functions_SRDF_CVPR_2023_paper.pdf",
        "ref_texts": "[61] Jiaming Sun, Yiming Xie, Linghao Chen, Xiaowei Zhou, and Hujun Bao. Neuralrecon: Real-time coherent 3d reconstruction from monocular video. In IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 15598\u2013",
        "ref_ids": [
          "61"
        ]
      },
      "ShapeMatcher: Self-Supervised Joint Shape Canonicalization Segmentation Retrieval and Deformation": {
        "authors": [
          "Yan Di",
          "Chenyangguang Zhang",
          "Chaowei Wang",
          "Ruida Zhang",
          "Guangyao Zhai",
          "Yanyan Li",
          "Bowen Fu",
          "Xiangyang Ji",
          "Shan Gao"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Di_ShapeMatcher_Self-Supervised_Joint_Shape_Canonicalization_Segmentation_Retrieval_and_Deformation_CVPR_2024_paper.pdf",
        "ref_texts": "[49] Jiaming Sun, Yiming Xie, Linghao Chen, Xiaowei Zhou, and Hujun Bao. Neuralrecon: Real-time coherent 3d reconstruc-tion from monocular video. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 15598\u201315607, 2021. 1",
        "ref_ids": [
          "49"
        ]
      },
      "Long-lrm: Long-sequence large reconstruction model for wide-coverage gaussian splats": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2410.12781?",
        "ref_texts": "501\u2013518. Springer, 2016. Noah Stier, Alexander Rich, Pradeep Sen, and Tobias H \u00a8ollerer. V ortx: V olumetric 3d reconstruction with transformers for voxelwise view selection and fusion. In 2021 International Conference on 3D Vision (3DV) , pp. 320\u2013330. IEEE, 2021. Mohammed Suhail, Carlos Esteves, Leonid Sigal, and Ameesh Makadia. Generalizable patch-based neural rendering. In European Conference on Computer Vision , pp. 156\u2013174. Springer, 2022. Jiaming Sun, Yiming Xie, Linghao Chen, Xiaowei Zhou, and Hujun Bao. Neuralrecon: Real-time coherent 3d reconstruction from monocular video. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pp. 15598\u201315607, 2021. Stanislaw Szymanowicz, Christian Rupprecht, and Andrea Vedaldi. Splatter image: Ultra-fast single-view 3d reconstruction. arXiv preprint arXiv:2312.13150 , 2023. Matthew Tancik, Ethan Weber, Evonne Ng, Ruilong Li, Brent Yi, Terrance Wang, Alexander Kristoffersen, Jake Austin, Kamyar Salahi, Abhik Ahuja, et al. Nerfstudio: A modular framework for neural radiance field development. In ACM SIGGRAPH 2023 Conference Proceedings , pp."
      },
      "Multi-scale hash encoding based neural geometry representation": {
        "authors": [],
        "url": "https://link.springer.com/content/pdf/10.1007/s41095-023-0340-x.pdf",
        "ref_texts": "[57]Sun, J. M.; Xie, Y. M.; Chen, L. H.; Zhou, X. W.; Bao, H. J. NeuralRecon: Real-time coherent 3D reconstruction from monocular video. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 15593\u201315602, 2021.",
        "ref_ids": [
          "57"
        ]
      },
      "PMVC: Promoting Multi-View Consistency for 3D Scene Reconstruction": {
        "authors": [
          "Chushan Zhang",
          "Jinguang Tong",
          "Tao Jun",
          "Chuong Nguyen",
          "Hongdong Li"
        ],
        "url": "https://openaccess.thecvf.com/content/WACV2024/papers/Zhang_PMVC_Promoting_Multi-View_Consistency_for_3D_Scene_Reconstruction_WACV_2024_paper.pdf",
        "ref_texts": "[45] Jiaming Sun, Yiming Xie, Linghao Chen, Xiaowei Zhou, and Hujun Bao. NeuralRecon: Real-time coherent 3D reconstruction from monocular video. CVPR , 2021. 7",
        "ref_ids": [
          "45"
        ]
      },
      "RadarCam-Depth: Radar-Camera Fusion for Depth Estimation with Learned Metric Scale": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2401.04325",
        "ref_texts": "[36] J. Sun, Y . Xie, L. Chen, X. Zhou, and H. Bao. \u201cNeuralRecon: Real-time coherent 3D reconstruction from monocular video\u201d. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition . 2021, pp. 15598\u2013",
        "ref_ids": [
          "36"
        ]
      },
      "Hybridocc: Nerf enhanced transformer-based multi-camera 3d occupancy prediction": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2408.09104",
        "ref_texts": "[34] J. Sun, Y . Xie, L. Chen, X. Zhou, and H. Bao, \u201cNeuralrecon: Realtime coherent 3d reconstruction from monocular video,\u201d 2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) , pp.",
        "ref_ids": [
          "34"
        ]
      },
      "Incremental dense reconstruction from monocular video with guided sparse feature volume fusion": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2305.14918",
        "ref_texts": "[2] J. Sun, Y . Xie, L. Chen, X. Zhou, and H. Bao. \u201cNeuralRecon: Real-Time Coherent 3D Reconstruction from Monocular Video\u201d. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition . 2021, pp. 15598\u201315607.",
        "ref_ids": [
          "2"
        ]
      },
      "Sst: Real-time end-to-end monocular 3d reconstruction via sparse spatial-temporal guidance": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2212.06524",
        "ref_texts": "[3] J. Sun, Y . Xie, L. Chen et al. , \u201cNeuralrecon: Real-time coherent 3d reconstruction from monocular video,\u201d in CVPR , 2021, pp. 15 598\u2013",
        "ref_ids": [
          "3"
        ]
      },
      "UNIKD: UNcertainty-Filtered Incremental Knowledge Distillation for Neural Implicit Representation": {
        "authors": [],
        "url": "https://fq.pkwyx.com/default/https/www.ecva.net/papers/eccv_2024/papers_ECCV/papers/06561.pdf",
        "ref_texts": "47.Sun, J., Xie, Y., Chen, L., Zhou, X., Bao, H.: Neuralrecon: Real-time coherent 3d reconstruction from monocular video. In: CVPR (2021)",
        "ref_ids": [
          "47"
        ]
      },
      "Surf-D: Generating High-Quality Surfaces of Arbitrary Topologies Using Diffusion Models": {
        "authors": [],
        "url": "https://fq.pkwyx.com/default/https/www.ecva.net/papers/eccv_2024/papers_ECCV/papers/05619-supp.pdf",
        "ref_texts": ""
      },
      "Multi-sensor large-scale dataset for multi-view 3D reconstruction": {
        "authors": [
          "Oleg Voynov",
          "Gleb Bobrovskikh",
          "Pavel Karpyshev",
          "Saveliy Galochkin",
          "Timotei Ardelean",
          "Arseniy Bozhenko",
          "Ekaterina Karmanova",
          "Pavel Kopanev",
          "Yaroslav Labutin",
          "Ruslan Rakhimov",
          "Aleksandr Safin",
          "Valerii Serpiva",
          "Alexey Artemov",
          "Evgeny Burnaev",
          "Dzmitry Tsetserukou",
          "Denis Zorin"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2023/papers/Voynov_Multi-Sensor_Large-Scale_Dataset_for_Multi-View_3D_Reconstruction_CVPR_2023_paper.pdf",
        "ref_texts": "[67] Jiaming Sun, Yiming Xie, Linghao Chen, Xiaowei Zhou, and Hujun Bao. Neuralrecon: Real-time coherent 3d reconstruction from monocular video. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) , pages 15598\u201315607, June 2021. 3",
        "ref_ids": [
          "67"
        ]
      },
      "2S-UDF: A Novel Two-stage UDF Learning Method for Robust Non-watertight Model Reconstruction from Multi-view Images": {
        "authors": [
          "Junkai Deng",
          "Fei Hou",
          "Xuhui Chen",
          "Wencheng Wang",
          "Ying He"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Deng_2S-UDF_A_Novel_Two-stage_UDF_Learning_Method_for_Robust_Non-watertight_CVPR_2024_paper.pdf",
        "ref_texts": "[33] Jiaming Sun, Yiming Xie, Linghao Chen, Xiaowei Zhou, and Hujun Bao. NeuralRecon: Real-Time Coherent 3D Reconstruction from Monocular Video. In IEEE Conf. Comput. Vis. Pattern Recog. , pages 15593\u201315602, 2021. 2",
        "ref_ids": [
          "33"
        ]
      },
      "MonoSelfRecon: Purely Self-Supervised Explicit Generalizable 3D Reconstruction of Indoor Scenes from Monocular RGB Views": {
        "authors": [
          "Runfa Li",
          "Upal Mahbub",
          "Vasudev Bhaskaran",
          "Truong Nguyen"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024W/3DMV/papers/Li_MonoSelfRecon_Purely_Self-Supervised_Explicit_Generalizable_3D_Reconstruction_of_Indoor_Scenes_CVPRW_2024_paper.pdf",
        "ref_texts": "[35] Jiaming Sun, Yiming Xie, Linghao Chen, Xiaowei Zhou, and Hujun Bao. NeuralRecon: Real-time coherent 3D reconstruction from monocular video. CVPR, 2021. 1,2,3,5,6, 7",
        "ref_ids": [
          "35"
        ]
      },
      "U-RED: Unsupervised 3D Shape Retrieval and Deformation for Partial Point Clouds": {
        "authors": [
          "Yan Di",
          "Chenyangguang Zhang",
          "Ruida Zhang",
          "Fabian Manhardt",
          "Yongzhi Su",
          "Jason Rambach",
          "Didier Stricker",
          "Xiangyang Ji",
          "Federico Tombari"
        ],
        "url": "http://openaccess.thecvf.com/content/ICCV2023/papers/Di_U-RED_Unsupervised_3D_Shape_Retrieval_and_Deformation_for_Partial_Point_ICCV_2023_paper.pdf",
        "ref_texts": "[42] Jiaming Sun, Yiming Xie, Linghao Chen, Xiaowei Zhou, and Hujun Bao. Neuralrecon: Real-time coherent 3d reconstruction from monocular video. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 15598\u201315607, 2021. 1",
        "ref_ids": [
          "42"
        ]
      },
      "Mesh2NeRF: Direct Mesh Supervision for Neural Radiance Field Representation and Generation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2403.19319",
        "ref_texts": "59. Sun, J., Xie, Y., Chen, L., Zhou, X., Bao, H.: Neuralrecon: Real-time coherent 3d reconstruction from monocular video. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 15598\u201315607 (2021) 2",
        "ref_ids": [
          "59"
        ]
      },
      "Benchmarking Neural Radiance Fields for Autonomous Robots: An Overview": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2405.05526",
        "ref_texts": "[38] J. Sun, Y. Xie, L. Chen, X. Zhou, H. Bao, NeuralRecon: Real-time coherent 3D reconstruction from monocular video, CVPR (2021).",
        "ref_ids": [
          "38"
        ]
      },
      "Object slam-based active mapping and robotic grasping": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2012.01788",
        "ref_texts": "[26] Jiaming Sun, Yiming Xie, Linghao Chen, Xiaowei Zhou, and Hujun Bao. Neuralrecon: Real-time coherent 3d reconstruction from monocular video. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 15598\u201315607, 2021. 8",
        "ref_ids": [
          "26"
        ]
      },
      "On the Problem of Restoring and Classifying a 3D Object in Creating a Simulator of a Realistic Urban Environment": {
        "authors": [
          "Mikhail Gorodnichev",
          "Sergey Erokhin",
          "Ksenia Polyantseva",
          "Marina Moseva"
        ],
        "url": "https://www.mdpi.com/1424-8220/22/14/5199/pdf",
        "ref_texts": "16. Sun, J.; Xie, Y.; Chen, L.; Zhou, X.; Bao, H. NeuralRecon: Real-time coherent 3D reconstruction from monocular video. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, Nashville, TN, USA, 20\u201325 June 2021; pp. 15598\u201315607.",
        "ref_ids": [
          "16"
        ]
      },
      "Temporalstereo: Efficient spatial-temporal stereo matching network": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2211.13755",
        "ref_texts": "[41] Jiaming Sun, Yiming Xie, Linghao Chen, Xiaowei Zhou, and Hujun Bao. Neuralrecon: Real-time coherent 3d reconstruction from monocular video. In CVPR , pages 15598\u201315607, 2021. 5",
        "ref_ids": [
          "41"
        ]
      },
      "PlanarNeRF: Online Learning of Planar Primitives with Neural Radiance Fields": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2401.00871",
        "ref_texts": "[35] Jiaming Sun, Yiming Xie, Linghao Chen, Xiaowei Zhou, and Hujun Bao. Neuralrecon: Real-time coherent 3d reconstruction from monocular video. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 15598\u201315607, 2021. 5",
        "ref_ids": [
          "35"
        ]
      },
      "NC-SDF: Enhancing Indoor Scene Reconstruction Using Neural SDFs with View-Dependent Normal Compensation": {
        "authors": [
          "Ziyi Chen",
          "Xiaolong Wu",
          "Yu Zhang"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Chen_NC-SDF_Enhancing_Indoor_Scene_Reconstruction_Using_Neural_SDFs_with_View-Dependent_CVPR_2024_paper.pdf",
        "ref_texts": "[41] Jiaming Sun, Yiming Xie, Linghao Chen, Xiaowei Zhou, and Hujun Bao. Neuralrecon: Real-time coherent 3d reconstruction from monocular video. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 15598\u201315607, 2021. 1, 2",
        "ref_ids": [
          "41"
        ]
      },
      "Heightfields for efficient scene reconstruction for AR": {
        "authors": [
          "Jamie Watson",
          "Sara Vicente",
          "Oisin Mac",
          "Clement Godard",
          "Gabriel Brostow",
          "Michael Firman"
        ],
        "url": "https://openaccess.thecvf.com/content/WACV2023/papers/Watson_Heightfields_for_Efficient_Scene_Reconstruction_for_AR_WACV_2023_paper.pdf",
        "ref_texts": "[48] Sun, J., Xie, Y ., Chen, L., Zhou, X., Bao, H.: NeuralRecon: Real-time coherent 3d reconstruction from monocular video. In: CVPR (2021)",
        "ref_ids": [
          "48"
        ]
      },
      "Don't Look Now: Audio/Haptic Guidance for 3D Scanning of Landmarks": {
        "authors": [],
        "url": "https://discovery.ucl.ac.uk/id/eprint/10194975/1/Don%27t%20Look%20Now.pdf",
        "ref_texts": "[96] Jiaming Sun, Yiming Xie, Linghao Chen, Xiaowei Zhou, and Hujun Bao. 2021. NeuralRecon: Real-time coherent 3D reconstruction from monocular video. In CHI \u201924, May 11\u201316, 2024, Honolulu, HI, USA Van Brummelen et al. Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 15598\u201315607.",
        "ref_ids": [
          "96"
        ]
      },
      "Circle: Convolutional implicit reconstruction and completion for large-scale indoor scene": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2111.12905",
        "ref_texts": ""
      },
      "CN-RMA: Combined Network with Ray Marching Aggregation for 3D Indoor Object Detection from Multi-view Images": {
        "authors": [
          "Guanlin Shen",
          "Jingwei Huang",
          "Zhihua Hu",
          "Bin Wang"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Shen_CN-RMA_Combined_Network_with_Ray_Marching_Aggregation_for_3D_Indoor_CVPR_2024_paper.pdf",
        "ref_texts": ""
      },
      "Surf-D: High-Quality Surface Generation for Arbitrary Topologies using Diffusion Models": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2311.17050",
        "ref_texts": "71. Sun, J., Xie, Y., Chen, L., Zhou, X., Bao, H.: Neuralrecon: Real-time coherent 3d reconstruction from monocular video. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 15598\u201315607 (2021)",
        "ref_ids": [
          "71"
        ]
      },
      "Inner-outer aware reconstruction model for monocular 3D scene reconstruction": {
        "authors": [],
        "url": "https://proceedings.neurips.cc/paper_files/paper/2023/file/27c852e9d6c76890ca633f111c556a4f-Paper-Conference.pdf",
        "ref_texts": "[9]J. Sun, Y . Xie, L. Chen, X. Zhou, and H. Bao, \u201cNeuralrecon: Real-time coherent 3d reconstruction from monocular video,\u201d in Conference on Computer Vision and Pattern Recognition , pp. 15598\u201315607, IEEE, 2021.",
        "ref_ids": [
          "9"
        ]
      },
      "Depth on Demand: Streaming Dense Depth from a Low Frame Rate Active Sensor": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2409.08277",
        "ref_texts": "48. Sun, J., Xie, Y., Chen, L., Zhou, X., Bao, H.: NeuralRecon: Real-time coherent 3D reconstruction from monocular video. In: CVPR (2021)",
        "ref_ids": [
          "48"
        ]
      },
      "CRiM-GS: Continuous Rigid Motion-Aware Gaussian Splatting from Motion Blur Images": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2407.03923",
        "ref_texts": "[48] Sun, J., Xie, Y ., Chen, L., Zhou, X., Bao, H.: Neuralrecon: Real-time coherent 3d reconstruction from monocular video. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 15598\u201315607 (2021)",
        "ref_ids": [
          "48"
        ]
      },
      "VIDAR: Data Quality Improvement for Monocular 3D Reconstruction through In-situ Visual Interaction": {
        "authors": [],
        "url": "https://hackhao.github.io/publications/ICRA24_VIDAR.pdf",
        "ref_texts": "[8] J. Sun, Y . Xie, L. Chen, X. Zhou, and H. Bao, \u201cNeuralrecon: Realtime coherent 3d reconstruction from monocular video,\u201d in IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) , 2021, pp. 15 598\u201315 607.",
        "ref_ids": [
          "8"
        ]
      },
      "Unsupervised Style-based Explicit 3D Face Reconstruction from Single Image": {
        "authors": [
          "Heng Yu",
          "Zoltan A. Milacski",
          "Laszlo A. Jeni"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2023W/GCV/papers/Yu_Unsupervised_Style-Based_Explicit_3D_Face_Reconstruction_From_Single_Image_CVPRW_2023_paper.pdf",
        "ref_texts": "[54] Jiaming Sun, Yiming Xie, Linghao Chen, Xiaowei Zhou, and Hujun Bao. Neuralrecon: Real-time coherent 3d reconstruction from monocular video. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 15598\u201315607, 2021. 2",
        "ref_ids": [
          "54"
        ]
      },
      "Object-aware 3d scene reconstruction from single 2d images of indoor scenes": {
        "authors": [
          "Mingyun Wen",
          "Kyungeun Cho"
        ],
        "url": "https://www.mdpi.com/2227-7390/11/2/403/pdf",
        "ref_texts": "8. Sun, J.; Xie, Y.; Chen, L.; Zhou, X.; Bao, H. NeuralRecon: Real-time coherent 3D reconstruction from monocular video. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, Nashville, TN, USA, 20\u201325 June 2021; pp. 15598\u201315607.",
        "ref_ids": [
          "8"
        ]
      },
      "MultiDepth: Multi-Sample Priors for Refining Monocular Metric Depth Estimations in Indoor Scenes": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2411.01048",
        "ref_texts": "[44] J. Sun, Y . Xie, L. Chen, X. Zhou, and H. Bao, \u201cNeuralRecon: Realtime coherent 3D reconstruction from monocular video,\u201d CVPR , 2021.",
        "ref_ids": [
          "44"
        ]
      },
      "ArcticAI: a deep learning platform for rapid and accurate histological assessment of intraoperative tumor margins": {
        "authors": [],
        "url": "https://www.medrxiv.org/content/10.1101/2022.05.06.22274781.full.pdf",
        "ref_texts": "74. Sun, J., Xie, Y., Chen, L., Zhou, X. & Bao, H. NeuralRecon: Real -Time Coherent 3D Reconstruction from Monocular Video. in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition 15598 \u201315607 (2021). ",
        "ref_ids": [
          "74"
        ]
      },
      "Indoor Scene Reconstruction with Fine-Grained Details Using Hybrid Representation and Normal Prior Enhancement": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2309.07640",
        "ref_texts": "[32] J. Sun, Y. Xie, L. Chen, X. Zhou, and H. Bao, \u201cNeuralrecon: Realtime coherent 3d reconstruction from monocular video,\u201d in IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2021, virtual, June 19-25, 2021 . Computer Vision Foundation / IEEE, 2021, pp. 15 598\u201315 607.",
        "ref_ids": [
          "32"
        ]
      },
      "An Improved Matting-SfM Algorithm for 3D Reconstruction of Self-Rotating Objects": {
        "authors": [
          "Zinuo Li",
          "Zhen Zhang",
          "Shenghong Luo",
          "Yuxing Cai",
          "Shuna Guo"
        ],
        "url": "https://www.mdpi.com/2227-7390/10/16/2892/pdf",
        "ref_texts": "20. Sun, J.; Xie, Y.; Chen, L.; Zhou, X.; Bao, H. NeuralRecon: Real-time coherent 3D reconstruction from monocular video. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, Nashville, TN, USA, 20\u201325 June 2021; pp. 15598\u201315607.",
        "ref_ids": [
          "20"
        ]
      },
      "Learning online multi-sensor depth fusion": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2204.03353",
        "ref_texts": "56. Sun, J., Xie, Y., Chen, L., Zhou, X., Bao, H.: Neuralrecon: Real-time coherent 3d reconstruction from monocular video. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 15598\u201315607 (2021)",
        "ref_ids": [
          "56"
        ]
      },
      "NTPP-MVSNet: Multi-View Stereo Network Based on Neighboring Tangent Plane Propagation": {
        "authors": [
          "Qi Zhao",
          "Yangyan Deng",
          "Yifan Yang",
          "Yawei Li",
          "Ding Yuan"
        ],
        "url": "https://www.mdpi.com/2076-3417/13/14/8388/pdf",
        "ref_texts": "10. Sun, J.; Xie, Y.; Chen, L.; Zhou, X.; Bao, H. NeuralRecon: Real-time coherent 3D reconstruction from monocular video. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, Montreal, BC, Canada, 11\u201317 October 2021; pp. 15598\u201315607.",
        "ref_ids": [
          "10"
        ]
      },
      "Deep Cost Ray Fusion for Sparse Depth Video Completion": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2409.14935",
        "ref_texts": "45. Sun, J., Xie, Y., Chen, L., Zhou, X., Bao, H.: NeuralRecon: Real-time coherent 3D reconstruction from monocular video. CVPR (2021)",
        "ref_ids": [
          "45"
        ]
      },
      "SimpleMapping: Real-time visual-inertial dense mapping with deep multi-view stereo": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2306.08648",
        "ref_texts": "[51] J. Sun, Y . Xie, L. Chen, X. Zhou, and H. Bao. NeuralRecon: Real-time coherent 3D reconstruction from monocular video. In CVPR , 2021.",
        "ref_ids": [
          "51"
        ]
      },
      "Livepose: Online 3d reconstruction from monocular video with dynamic camera poses": {
        "authors": [
          "Noah Stier",
          "Baptiste Angles",
          "Liang Yang",
          "Yajie Yan",
          "Alex Colburn",
          "Ming Chuang"
        ],
        "url": "https://openaccess.thecvf.com/content/ICCV2023/papers/Stier_LivePose_Online_3D_Reconstruction_from_Monocular_Video_with_Dynamic_Camera_ICCV_2023_paper.pdf",
        "ref_texts": "[24] Jiaming Sun, Yiming Xie, Linghao Chen, Xiaowei Zhou, and Hujun Bao. Neuralrecon: Real-time coherent 3d reconstruction from monocular video. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 15598\u201315607, 2021. zju3dv.github.io/neuralrecon. 2, 3, 4, 5, 8",
        "ref_ids": [
          "24"
        ]
      },
      "Dionysus: Recovering Scene Structures by Dividing into Semantic Pieces": {
        "authors": [
          "Likang Wang",
          "Lei Chen"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_Dionysus_Recovering_Scene_Structures_by_Dividing_Into_Semantic_Pieces_CVPR_2023_paper.pdf",
        "ref_texts": "[57] Jiaming Sun, Yiming Xie, Linghao Chen, Xiaowei Zhou, and Hujun Bao. Neuralrecon: Real-time coherent 3d reconstruction from monocular video. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 15598\u201315607, 2021. 1, 3, 5, 8",
        "ref_ids": [
          "57"
        ]
      },
      "H2O-SDF: Two-phase Learning for 3D Indoor Reconstruction using Object Surface Fields": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2402.08138",
        "ref_texts": "10 Published as a conference paper at ICLR 2024 Jamie Shotton, Ben Glocker, Christopher Zach, Shahram Izadi, Antonio Criminisi, and Andrew Fitzgibbon. Scene coordinate regression forests for camera relocalization in rgb-d images. In Proceedings of the IEEE conference on computer vision and pattern recognition , pp. 2930\u20132937, 2013. Julian Straub, Thomas Whelan, Lingni Ma, Yufan Chen, Erik Wijmans, Simon Green, Jakob J. Engel, Raul Mur-Artal, Carl Ren, Shobhit Verma, Anton Clarkson, Mingfei Yan, Brian Budge, Yajie Yan, Xiaqing Pan, June Yon, Yuyang Zou, Kimberly Leon, Nigel Carter, Jesus Briales, Tyler Gillingham, Elias Mueggler, Luis Pesqueira, Manolis Savva, Dhruv Batra, Hauke M. Strasdat, Renzo De Nardi, Michael Goesele, Steven Lovegrove, and Richard Newcombe. The Replica dataset: A digital replica of indoor spaces. arXiv preprint arXiv:1906.05797 , 2019. Jiaming Sun, Yiming Xie, Linghao Chen, Xiaowei Zhou, and Hujun Bao. Neuralrecon: Real-time coherent 3d reconstruction from monocular video. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pp. 15598\u201315607, 2021. Matthew Tancik, Pratul Srinivasan, Ben Mildenhall, Sara Fridovich-Keil, Nithin Raghavan, Utkarsh Singhal, Ravi Ramamoorthi, Jonathan Barron, and Ren Ng. Fourier features let networks learn high frequency functions in low dimensional domains. Advances in Neural Information Processing Systems , 33:7537\u20137547, 2020. Jiepeng Wang, Peng Wang, Xiaoxiao Long, Christian Theobalt, Taku Komura, Lingjie Liu, and Wenping Wang. Neuris: Neural reconstruction of indoor scenes using normal priors. In European Conference on Computer Vision , pp. 139\u2013155. Springer, 2022a. Peng Wang, Lingjie Liu, Yuan Liu, Christian Theobalt, Taku Komura, and Wenping Wang. Neus: Learning neural implicit surfaces by volume rendering for multi-view reconstruction. NeurIPS , 2021. Yiqun Wang, Ivan Skorokhodov, and Peter Wonka. Hf-neus: Improved surface reconstruction using high-frequency details. Advances in Neural Information Processing Systems , 35:1966\u20131978, 2022b. Yi Wei, Shaohui Liu, Yongming Rao, Wang Zhao, Jiwen Lu, and Jie Zhou. Nerfingmvs: Guided optimization of neural radiance fields for indoor multi-view stereo. In Proceedings of the IEEE/CVF International Conference on Computer Vision , pp. 5610\u20135619, 2021. Qianyi Wu, Xian Liu, Yuedong Chen, Kejie Li, Chuanxia Zheng, Jianfei Cai, and Jianmin Zheng. Object-compositional neural implicit surfaces. In Computer Vision\u2013ECCV 2022: 17th European Conference, Tel Aviv, Israel, October 23\u201327, 2022, Proceedings, Part XXVII , pp. 197\u2013213. Springer, 2022. Lior Yariv, Jiatao Gu, Yoni Kasten, and Yaron Lipman. V olume rendering of neural implicit surfaces. Advances in Neural Information Processing Systems , 34:4805\u20134815, 2021. Zehao Yu, Songyou Peng, Michael Niemeyer, Torsten Sattler, and Andreas Geiger. Monosdf: Exploring monocular geometric cues for neural implicit surface reconstruction. Advances in neural information processing systems , 35:25018\u201325032, 2022. Jingsen Zhu, Yuchi Huo, Qi Ye, Fujun Luan, Jifan Li, Dianbing Xi, Lisha Wang, Rui Tang, Wei Hua, Hujun Bao, et al. I2-sdf: Intrinsic indoor scene reconstruction and editing via raytracing in neural sdfs. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pp. 12489\u201312498, 2023."
      },
      "Depth completion with multiple balanced bases and confidence for dense monocular slam": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2309.04145",
        "ref_texts": "[12] Jiaming Sun, Yiming Xie, Linghao Chen, Xiaowei Zhou, and Hujun Bao. NeuralRecon: Real-time coherent 3d reconstruction from monocular video. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 15598\u201315607, 2021.",
        "ref_ids": [
          "12"
        ]
      },
      "Large-scale mussel farm reconstruction with GPS auxiliary": {
        "authors": [],
        "url": "https://openaccess.wgtn.ac.nz/articles/conference_contribution/Large-Scale_Mussel_Farm_Reconstruction_with_GPS_Auxiliary/24633795/1/files/43285662.pdf",
        "ref_texts": "[11] Sun, J., Xie, Y ., Chen, L., et al. (2021) \u201cNeuralRecon: real-time coherent 3D reconstruction from monocular video.\u201d In: Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pp. 15,598\u201315,607.",
        "ref_ids": [
          "11"
        ]
      },
      "GS2-GNeSF: Geometry-Semantics Synergy for Generalizable Neural Semantic Fields": {
        "authors": [
          "Chengshun Wang"
        ],
        "url": "https://dl.acm.org/doi/pdf/10.1145/3664647.3681156",
        "ref_texts": ""
      },
      "Virtual Agent Positioning Driven by Personal Characteristics": {
        "authors": [],
        "url": "https://openreview.net/pdf?id=mUPwlZGnUs",
        "ref_texts": "[37] Jiaming Sun, Yiming Xie, Linghao Chen, Xiaowei Zhou, and Hujun Bao. 2021. Neuralrecon: Real-time coherent 3d reconstruction from monocular video. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition .",
        "ref_ids": [
          "37"
        ]
      },
      "Globally consistent video depth and pose estimation with efficient test-time training": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2208.02709",
        "ref_texts": "(IROS) . Sun, J.; Xie, Y .; Chen, L.; Zhou, X.; and Bao, H. 2021. NeuralRecon: Real-Time Coherent 3D Reconstruction from Monocular Video. In CVPR . Teed, Z.; and Deng, J. 2019. DeepV2D: Video to Depth with Differentiable Structure from Motion. In International Conference on Learning Representations . Teed, Z.; and Deng, J. 2020. Raft: Recurrent all-pairs field transforms for optical flow. In ECCV . Teed, Z.; and Deng, J. 2021. Droid-slam: Deep visual slam for monocular, stereo, and rgb-d cameras. NeurIPS . Triggs, B.; McLauchlan, P. F.; Hartley, R. I.; and Fitzgibbon, A. W. 1999. Bundle adjustment\u2014a modern synthesis. In International workshop on vision algorithms . Springer. Ummenhofer, B.; Zhou, H.; Uhrig, J.; Mayer, N.; Ilg, E.; Dosovitskiy, A.; and Brox, T. 2017. Demon: Depth and motion network for learning monocular stereo. In CVPR . Vaswani, A.; Shazeer, N.; Parmar, N.; Uszkoreit, J.; Jones, L.; Gomez, A. N.; Kaiser, \u0141.; and Polosukhin, I. 2017. Attention is all you need. In NeurIPS . Wang, J.; Zhong, Y .; Dai, Y .; Birchfield, S.; Zhang, K.; Smolyanskiy, N.; and Li, H. 2021. Deep Two-View Structure-from-Motion Revisited. In CVPR . Wang, Z.; Bovik, A. C.; Sheikh, H. R.; and Simoncelli, E. P."
      },
      "SCube: Instant Large-Scale Scene Reconstruction using VoxSplats": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2410.20030",
        "ref_texts": "[51] J. Sun, Y . Xie, L. Chen, X. Zhou, and H. Bao. Neuralrecon: Real-time coherent 3d reconstruction from monocular video. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , pages 15598\u201315607, 2021.",
        "ref_ids": [
          "51"
        ]
      },
      "AiSDF: Structure-aware Neural Signed Distance Fields in Indoor Scenes": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2403.01861",
        "ref_texts": "[28] J. Sun, Y . Xie, L. Chen, X. Zhou, and H. Bao, \u201cNeuralrecon: Real-time coherent 3d reconstruction from monocular video,\u201d in CVPR , 2021.",
        "ref_ids": [
          "28"
        ]
      },
      "From Transparent to Opaque: Rethinking Neural Implicit Surfaces with -NeuS": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2411.05362",
        "ref_texts": "[16] Jiaming Sun, Yiming Xie, Linghao Chen, Xiaowei Zhou, and Hujun Bao. NeuralRecon: Real-Time Coherent 3D Reconstruction from Monocular Video. In 2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) , pages 15593\u201315602, 2021. doi: 10.1109/CVPR46437.2021.01534.",
        "ref_ids": [
          "16"
        ]
      },
      "VF-NeRF: Learning Neural Vector Fields for Indoor Scene Reconstruction": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2408.08766?",
        "ref_texts": "[48] Jiaming Sun, Yiming Xie, Linghao Chen, Xiaowei Zhou, and Hujun Bao. Neuralrecon: Real-time coherent 3d reconstruction from monocular video. CVPR , 2021. 6",
        "ref_ids": [
          "48"
        ]
      },
      "Unified Scene Representation and Reconstruction for 3D Large Language Models": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2404.13044",
        "ref_texts": "38. Sun, J., Xie, Y., Chen, L., Zhou, X., Bao, H.: NeuralRecon: Real-time coherent 3d reconstruction from monocular video. In: CVPR (2021) 4, 6, 9, 10",
        "ref_ids": [
          "38"
        ]
      },
      "Splat-SLAM: Globally Optimized RGB-only SLAM with 3D Gaussians": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2405.16544",
        "ref_texts": "[58] Sun, J., Xie, Y ., Chen, L., Zhou, X., Bao, H.: Neuralrecon: Real-time coherent 3d reconstruction from monocular video. In: IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 15598\u2013",
        "ref_ids": [
          "58"
        ]
      },
      "FreeSplat: Generalizable 3D Gaussian Splatting Towards Free-View Synthesis of Indoor Scenes": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2405.17958",
        "ref_texts": "[31] Jiaming Sun, Yiming Xie, Linghao Chen, Xiaowei Zhou, and Hujun Bao. Neuralrecon: Realtime coherent 3d reconstruction from monocular video. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , pages 15598\u201315607, 2021.",
        "ref_ids": [
          "31"
        ]
      },
      "Multi-view monocular depth and uncertainty prediction with deep sfm in dynamic environments": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2201.08633",
        "ref_texts": "68. Sun, J., Xie, Y ., Chen, L., Zhou, X., Bao, H.: Neuralrecon: Real-time coherent 3d reconstruction from monocular video. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 15598\u201315607 (2021) 4",
        "ref_ids": [
          "68"
        ]
      },
      "3d semantic label transfer in human-robot collaboration": {
        "authors": [
          "David Rozenberszki",
          "Gabor Soros",
          "Szilvia Szeier",
          "Andras Lorincz"
        ],
        "url": "https://openaccess.thecvf.com/content/ICCV2021W/CVinHRC/papers/Rozenberszki_3D_Semantic_Label_Transfer_in_Human-Robot_Collaboration_ICCVW_2021_paper.pdf",
        "ref_texts": "[39] Jiaming Sun, Yiming Xie, Linghao Chen, Xiaowei Zhou, and Hujun Bao. NeuralRecon: Real-time coherent 3D reconstruction from monocular video. Conference on Computer Vision and Pattern Recognition , 2021.",
        "ref_ids": [
          "39"
        ]
      },
      "Learning 3D Robotics Perception using Inductive Priors": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2405.20364",
        "ref_texts": "[247] J. Sun, Y . Xie, L. Chen, X. Zhou, and H. Bao, \u201cNeuralrecon: Real-time coherent 3d reconstruction from monocular video,\u201d in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , 2021, pp. 15 598\u201315 607.",
        "ref_ids": [
          "247"
        ]
      },
      "Omni-Recon: Towards General-Purpose Neural Radiance Fields for Versatile 3D Applications": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2403.11131",
        "ref_texts": "63. Sun, J., Xie, Y., Chen, L., Zhou, X., Bao, H.: Neuralrecon: Real-time coherent 3d reconstruction from monocular video. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 15598\u201315607 (2021)",
        "ref_ids": [
          "63"
        ]
      },
      "Range-Agnostic Multi-View Depth Estimation with Keyframe Selection": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2401.14401",
        "ref_texts": "[28] Jiaming Sun, Yiming Xie, Linghao Chen, Xiaowei Zhou, and Hujun Bao. NeuralRecon: Real-time coherent 3D reconstruction from monocular video. In CVPR , 2021. 3",
        "ref_ids": [
          "28"
        ]
      },
      "WaterMono: Teacher-Guided Anomaly Masking and Enhancement Boosting for Robust Underwater Self-Supervised Monocular Depth Estimation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2406.13344",
        "ref_texts": "[2] J. Sun, Y . Xie, L. Chen, X. Zhou, and H. Bao, \u201cNeuralRecon: Real-time coherent 3d reconstruction from monocular video,\u201d in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , 2021, pp. 15 598\u201315 607.",
        "ref_ids": [
          "2"
        ]
      },
      "From Sora What We Can See: A Survey of Text-to-Video Generation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2405.10674",
        "ref_texts": "[149] J. Sun, Y. Xie, L. Chen, X. Zhou, and H. Bao, \u201cNeuralrecon: Real-time coherent 3d reconstruction from monocular video,\u201d in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pp. 15598\u201315607, 2021.",
        "ref_ids": [
          "149"
        ]
      },
      "DoubleTake: Geometry Guided Depth Estimation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2406.18387?",
        "ref_texts": "61. Sun, J., Xie, Y., Chen, L., Zhou, X., Bao, H.: NeuralRecon: Real-time coherent 3D reconstruction from monocular video. In: CVPR (2021)",
        "ref_ids": [
          "61"
        ]
      },
      "Learning-based Multi-View Stereo: A Survey": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2408.15235",
        "ref_texts": "[48] J. Sun, Y . Xie, L. Chen, X. Zhou, and H. Bao, \u201cNeuralrecon: Real-time coherent 3d reconstruction from monocular video,\u201d in CVPR , 2021.",
        "ref_ids": [
          "48"
        ]
      },
      "NeB-SLAM: Neural Blocks-based Salable RGB-D SLAM for Unknown Scenes": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2405.15151",
        "ref_texts": "[8] J. Sun, Y . Xie, L. Chen, X. Zhou, and H. Bao, \u201cNeuralrecon: Real-time coherent 3d reconstruction from monocular video,\u201d in Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , 2021, pp. 15 598\u201315 607.",
        "ref_ids": [
          "8"
        ]
      },
      "Differentiable gradient sampling for learning implicit 3d scene reconstructions from a single image": {
        "authors": [],
        "url": "https://openreview.net/pdf?id=U8pbd00cCWB",
        "ref_texts": "11 Published as a conference paper at ICLR 2022 Vincent Sitzmann, Michael Zollh \u00a8ofer, and Gordon Wetzstein. Scene representation networks: Continuous 3d-structure-aware neural scene representations. arXiv preprint arXiv:1906.01618 , 2019. Vincent Sitzmann, Julien Martel, Alexander Bergman, David Lindell, and Gordon Wetzstein. Implicit neural representations with periodic activation functions. Advances in Neural Information Processing Systems , 33, 2020. Shuran Song, Fisher Yu, Andy Zeng, Angel X Chang, Manolis Savva, and Thomas Funkhouser. Semantic scene completion from a single depth image. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pp. 1746\u20131754, 2017. Julian Straub, Thomas Whelan, Lingni Ma, Yufan Chen, Erik Wijmans, Simon Green, Jakob J. Engel, Raul Mur-Artal, Carl Ren, Shobhit Verma, Anton Clarkson, Mingfei Yan, Brian Budge, Yajie Yan, Xiaqing Pan, June Yon, Yuyang Zou, Kimberly Leon, Nigel Carter, Jesus Briales, Tyler Gillingham, Elias Mueggler, Luis Pesqueira, Manolis Savva, Dhruv Batra, Hauke M. Strasdat, Renzo De Nardi, Michael Goesele, Steven Lovegrove, and Richard Newcombe. The Replica dataset: A digital replica of indoor spaces. arXiv preprint arXiv:1906.05797 , 2019. Jiaming Sun, Yiming Xie, Linghao Chen, Xiaowei Zhou, and Hujun Bao. Neuralrecon: Real-time coherent 3d reconstruction from monocular video. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pp. 15598\u201315607, 2021. Xingyuan Sun, Jiajun Wu, Xiuming Zhang, Zhoutong Zhang, Chengkai Zhang, Tianfan Xue, Joshua B Tenenbaum, and William T Freeman. Pix3d: Dataset and methods for single-image 3d shape modeling. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pp. 2974\u20132983, 2018. Shubham Tulsiani, Tinghui Zhou, Alexei A Efros, and Jitendra Malik. Multi-view supervision for single-view reconstruction via differentiable ray consistency. In Proceedings of the IEEE conference on computer vision and pattern recognition , pp. 2626\u20132634, 2017. Peng Wang, Lingjie Liu, Yuan Liu, Christian Theobalt, Taku Komura, and Wenping Wang. Neus: Learning neural implicit surfaces by volume rendering for multi-view reconstruction. arXiv preprint arXiv:2106.10689 , 2021. Olivia Wiles, Georgia Gkioxari, Richard Szeliski, and Justin Johnson. Synsin: End-to-end view synthesis from a single image. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pp. 7467\u20137477, 2020. Saining Xie, Ross Girshick, Piotr Doll \u00b4ar, Zhuowen Tu, and Kaiming He. Aggregated residual transformations for deep neural networks. In Proceedings of the IEEE conference on computer vision and pattern recognition , pp. 1492\u20131500, 2017. Qiangeng Xu, Weiyue Wang, Duygu Ceylan, Radomir Mech, and Ulrich Neumann. Disn: Deep implicit surface network for high-quality single-view 3d reconstruction. In Advances in Neural Information Processing Systems , pp. 490\u2013500, 2019. Lior Yariv, Yoni Kasten, Dror Moran, Meirav Galun, Matan Atzmon, Ronen Basri, and Yaron Lipman. Multiview neural surface reconstruction by disentangling geometry and appearance. arXiv preprint arXiv:2003.09852 , 2020. Lior Yariv, Jiatao Gu, Yoni Kasten, and Yaron Lipman. V olume rendering of neural implicit surfaces. arXiv preprint arXiv:2106.12052 , 2021. Wang Yifan, Felice Serena, Shihao Wu, Cengiz \u00a8Oztireli, and Olga Sorkine-Hornung. Differentiable surface splatting for point-based geometry processing. ACM Transactions on Graphics (TOG) , 38(6):1\u201314, 2019. Wei Yin, Jianming Zhang, Oliver Wang, Simon Niklaus, Long Mai, Simon Chen, and Chunhua Shen. Learning to recover 3d scene shape from a single image. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pp. 204\u2013213, 2021. Alex Yu, Vickie Ye, Matthew Tancik, and Angjoo Kanazawa. pixelnerf: Neural radiance fields from one or few images. arXiv preprint arXiv:2012.02190 , 2020."
      },
      "UniPlane: Unified Plane Detection and Reconstruction from Posed Monocular Videos": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2407.03594",
        "ref_texts": "[33] Jiaming Sun, Yiming Xie, Linghao Chen, Xiaowei Zhou, and Hujun Bao. NeuralRecon: Real-time coherent 3D reconstruction from monocular video. CVPR , 2021.",
        "ref_ids": [
          "33"
        ]
      },
      "A Comprehensive Review of Vision-Based 3D Reconstruction Methods": {
        "authors": [
          "Linglong Zhou",
          "Guoxin Wu",
          "Yunbo Zuo",
          "Xuanyu Chen",
          "Hongle Hu"
        ],
        "url": "https://www.mdpi.com/1424-8220/24/7/2314/pdf",
        "ref_texts": "217. Sun, J.; Xie, Y.; Chen, L.; Zhou, X.; Bao, H. Neuralrecon: Real-time coherent 3d reconstruction from monocular video. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, Nashville, TN, USA, 20\u201325 June 2021; pp. 15598\u201315607.",
        "ref_ids": [
          "217"
        ]
      },
      "Ray-Distance Volume Rendering for Neural Scene Reconstruction": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2408.15524",
        "ref_texts": "37. Sun, J., Xie, Y., Chen, L., Zhou, X., Bao, H.: Neuralrecon: Real-time coherent 3d reconstruction from monocular video. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 15598\u201315607 (2021)",
        "ref_ids": [
          "37"
        ]
      },
      "PointRecon: Online Point-based 3D Reconstruction via Ray-based 2D-3D Matching": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2410.23245?",
        "ref_texts": "501\u2013518. Springer, 2016. Noah Stier, Alexander Rich, Pradeep Sen, and Tobias H \u00a8ollerer. V ortx: V olumetric 3d reconstruction with transformers for voxelwise view selection and fusion. In 2021 International Conference on 3D Vision (3DV) , pp. 320\u2013330. IEEE, 2021. Noah Stier, Anurag Ranjan, Alex Colburn, Yajie Yan, Liang Yang, Fangchang Ma, and Baptiste Angles. Finerecon: Depth-aware feed-forward network for detailed 3d reconstruction. arXiv preprint arXiv:2304.01480 , 2023. Jiaming Sun, Yiming Xie, Linghao Chen, Xiaowei Zhou, and Hujun Bao. Neuralrecon: Real-time coherent 3d reconstruction from monocular video. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pp. 15598\u201315607, 2021. Jiaxiang Tang, Zhaoxi Chen, Xiaokang Chen, Tengfei Wang, Gang Zeng, and Ziwei Liu. Lgm: Large multi-view gaussian model for high-resolution 3d content creation. arXiv preprint arXiv:2402.05054 , 2024. Zachary Teed and Jia Deng. Droid-slam: Deep visual slam for monocular, stereo, and rgb-d cameras. Advances in neural information processing systems , 34:16558\u201316569, 2021. Kaixuan Wang and Shaojie Shen. Mvdepthnet: Real-time multiview depth estimation neural network. In2018 International conference on 3d vision (3DV) , pp. 248\u2013257. IEEE, 2018."
      },
      "Neural Mesh Fusion: Unsupervised 3D Planar Surface Understanding": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2402.16739",
        "ref_texts": "[27] Jiaming Sun, Yiming Xie, Linghao Chen, Xiaowei Zhou, and Hujun Bao, \u201cNeuralRecon: Real-time coherent 3D reconstruction from monocular video,\u201d in Proc. of the IEEE/CVF Conf. on Computer Vision and Pattern Recognition , 2021, pp. 15598\u201315607.",
        "ref_ids": [
          "27"
        ]
      },
      "GeoBench: Benchmarking and Analyzing Monocular Geometry Estimation Models": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2406.12671",
        "ref_texts": "[SXC+21]Jiaming Sun, Yiming Xie, Linghao Chen, Xiaowei Zhou, and Hujun Bao. NeuralRecon: Real-time coherent 3d reconstruction from monocular video. In IEEE Conf. Comput. Vis. Pattern Recog. , pages 15598\u201315607, 2021.",
        "ref_ids": [
          "SXC\\+21"
        ]
      },
      "FAWN: Floor-And-Walls Normal Regularization for Direct Neural TSDF Reconstruction": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2406.12054",
        "ref_texts": "[3] Jiaming Sun, Yiming Xie, Linghao Chen, Xiaowei Zhou, and Hujun Bao, \u201cNeuralRecon: Real-time coherent 3D reconstruction from monocular video,\u201d in CVPR , 2021.",
        "ref_ids": [
          "3"
        ]
      },
      "Toward Cooperative 3D Object Reconstruction with Multi-agent": {
        "authors": [],
        "url": "http://www.zhenyu.info/papers/ICRA.pdf",
        "ref_texts": "[30] Jiaming Sun, Yiming Xie, Linghao Chen, Xiaowei Zhou, and Hujun Bao. Neuralrecon: Real-time coherent 3d reconstruction from monocular video. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 15598\u201315607, 2021.",
        "ref_ids": [
          "30"
        ]
      },
      "3D Reconstruction Based on Iterative Optimization of Moving Least-Squares Function": {
        "authors": [
          "Saiya Li",
          "Jinhe Su",
          "Guoqing Jiang",
          "Ziyu Huang",
          "Xiaorong Zhang"
        ],
        "url": "https://www.mdpi.com/1999-4893/17/6/263/pdf",
        "ref_texts": "32. Sun, J.; Xie, Y.; Chen, L.; Zhou, X.; Bao, H. NeuralRecon: Real-time coherent 3D reconstruction from monocular video. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, Nashville, TN, USA, 20\u201325 June 2021; pp. 15598\u201315607.",
        "ref_ids": [
          "32"
        ]
      },
      "DISORF: A Distributed Online NeRF Training and Rendering Framework for Mobile Robots": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2403.00228",
        "ref_texts": "[16] J. Sun, Y . Xie, L. Chen, X. Zhou, and H. Bao, \u201cNeuralrecon: Real-time coherent 3d reconstruction from monocular video,\u201d in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2021, pp. 15 598\u201315 607. 2",
        "ref_ids": [
          "16"
        ]
      },
      "Dynamic voxel grid optimization for high-fidelity rgb-d supervised surface reconstruction": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2304.06178",
        "ref_texts": "[34] Jiaming Sun, Yiming Xie, Linghao Chen, Xiaowei Zhou, and Hujun Bao. Neuralrecon: Real-time coherent 3d reconstruction from monocular video. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 15598\u201315607, 2021. 2",
        "ref_ids": [
          "34"
        ]
      },
      "RIDERS: Radar-Infrared Depth Estimation for Robust Sensing": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2402.02067",
        "ref_texts": "[41] J. Sun, Y . Xie, L. Chen, X. Zhou, and H. Bao. \u201cNeuralRecon: Real-time coherent 3D reconstruction from monocular video\u201d. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition . 2021, pp. 15598\u201315607.",
        "ref_ids": [
          "41"
        ]
      },
      "Pano2Room: Novel View Synthesis from a Single Indoor Panorama": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2408.11413",
        "ref_texts": "(2024). Yuan Liu, Cheng Lin, Zijiao Zeng, Xiaoxiao Long, Lingjie Liu, Taku Komura, and Wenping Wang. 2023. SyncDreamer: Generating Multiview-consistent Images from a Single-view Image. arXiv preprint arXiv:2309.03453 (2023). Luke Melas-Kyriazi, Iro Laina, Christian Rupprecht, and Andrea Vedaldi. 2023. RealFusion: 360deg reconstruction of any object from a single image. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition . 8446\u20138455. Ben Mildenhall, Pratul P Srinivasan, Matthew Tancik, Jonathan T Barron, Ravi Ramamoorthi, and Ren Ng. 2021. Nerf: Representing scenes as neural radiance fields for view synthesis. Commun. ACM 65, 1 (2021), 99\u2013106. Guo Pu, Peng-Shuai Wang, and Zhouhui Lian. 2023. SinMPI: Novel View Synthesis from a Single Image with Expanded Multiplane Images. In SIGGRAPH Asia 2023 Conference Papers . 1\u201310. Ren\u00e9 Ranftl, Alexey Bochkovskiy, and Vladlen Koltun. 2021. Vision transformers for dense prediction. In Proceedings of the IEEE/CVF International Conference on Computer Vision . 12179\u201312188. Manuel Rey-Area, Mingze Yuan, and Christian Richardt. 2022. 360MonoDepth: Highresolution 360deg monocular depth estimation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition . 3762\u20133772. Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Bj\u00f6rn Ommer. 2021. High-Resolution Image Synthesis with Latent Diffusion Models. arXiv:2112.10752 [cs.CV] Grant Schindler and Frank Dellaert. 2004. Atlanta world: An expectation maximization framework for simultaneous low-level edge grouping and camera calibration incomplex man-made environments. In Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2004. CVPR 2004. , Vol. 1. IEEE, I\u2013I. Jonas Schult, Sam Tsai, Lukas H\u00f6llein, Bichen Wu, Jialiang Wang, Chih-Yao Ma, Kunpeng Li, Xiaofang Wang, Felix Wimbauer, Zijian He, et al .2024. ControlRoom3D: Room generation using semantic proxy rooms. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition . 6201\u20136210. Meng-Li Shih, Shih-Yang Su, Johannes Kopf, and Jia-Bin Huang. 2020. 3D photography using context-aware layered depth inpainting. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition . 8028\u20138038. Jaidev Shriram, Alex Trevithick, Lingjie Liu, and Ravi Ramamoorthi. 2024. RealmDreamer: Text-driven 3d scene generation with inpainting and depth diffusion. arXiv preprint arXiv:2404.07199 (2024). Liangchen Song, Liangliang Cao, Hongyu Xu, Kai Kang, Feng Tang, Junsong Yuan, and Zhao Yang. 2023. RoomDreamer: Text-Driven 3D Indoor Scene Synthesis with Coherent Geometry and Texture. In Proceedings of the 31st ACM International Conference on Multimedia . 6898\u20136906. Jiaming Sun, Yiming Xie, Linghao Chen, Xiaowei Zhou, and Hujun Bao. 2021. NeuralRecon: Real-time coherent 3D reconstruction from monocular video. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition . 15598\u201315607. Jiaxiang Tang, Jiawei Ren, Hang Zhou, Ziwei Liu, and Gang Zeng. 2023. DreamGaussian: Generative gaussian splatting for efficient 3d content creation. arXiv preprint arXiv:2309.16653 (2023). Guangcong Wang, Peng Wang, Zhaoxi Chen, Wenping Wang, Chen Change Loy, and Ziwei Liu. 2024. PERF: Panoramic Neural Radiance Field from a Single Panorama. IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI) (2024). Olivia Wiles, Georgia Gkioxari, Richard Szeliski, and Justin Johnson. 2020. SynSin: End-to-end view synthesis from a single image. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition . 7467\u20137477. Dejia Xu, Yifan Jiang, Peihao Wang, Zhiwen Fan, Humphrey Shi, and Zhangyang Wang."
      },
      "DiffInDScene: Diffusion-based High-Quality 3D Indoor Scene Generation": {
        "authors": [
          "Xiaoliang Ju",
          "Zhaoyang Huang",
          "Yijin Li",
          "Guofeng Zhang",
          "Yu Qiao",
          "Hongsheng Li"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Ju_DiffInDScene_Diffusion-based_High-Quality_3D_Indoor_Scene_Generation_CVPR_2024_paper.pdf",
        "ref_texts": "[41] Jiaming Sun, Yiming Xie, Linghao Chen, Xiaowei Zhou, and Hujun Bao. Neuralrecon: Real-time coherent 3d reconstruction from monocular video. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 15598\u201315607, 2021. 1,2,5,8",
        "ref_ids": [
          "41"
        ]
      },
      "Improving Neural Indoor Surface Reconstruction with Mask-Guided Adaptive Consistency Constraints": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2309.09739",
        "ref_texts": "[14] J. Sun, Y . Xie, L. Chen, X. Zhou, and H. Bao, \u201cNeuralrecon: Real-time coherent 3d reconstruction from monocular video,\u201d in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2021, pp. 15 598\u201315 607.",
        "ref_ids": [
          "14"
        ]
      },
      "EPRecon: An Efficient Framework for Real-Time Panoptic 3D Reconstruction from Monocular Video": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2409.01807"
      },
      "InFusionSurf: Refining neural RGB-D surface reconstruction using per-frame intrinsic refinement and TSDF fusion prior learning": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2303.04508",
        "ref_texts": ""
      },
      "P2CADNet: An End-to-End Reconstruction Network for Parametric 3D CAD Model from Point Clouds": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2310.02638",
        "ref_texts": "946. Stamati, V .; and Fudos, I. 2010. Building editable B-Rep models from unorganized point clouds. Jul, 7: 1\u201310. Sun, J.; Xie, Y .; Chen, L.; Zhou, X.; and Bao, H. 2021. NeuralRecon: Real-time coherent 3D reconstruction from monocular video. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , 15598\u2013",
        "ref_ids": [
          "946"
        ]
      },
      "Neural 3D Scene Reconstruction from Multi-view Images without 3D Supervision": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2306.17643",
        "ref_texts": "[33] Jiaming Sun, Yiming Xie, Linghao Chen, Xiaowei Zhou, and Hujun Bao. NeuralRecon: Real-time coherent 3D reconstruction from monocular video. In CVPR , pages 15598\u201315607, 2021. 1, 2, 6",
        "ref_ids": [
          "33"
        ]
      },
      "Fine-detailed Neural Indoor Scene Reconstruction using multi-level importance sampling and multi-view consistency": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2410.07597",
        "ref_texts": "[4]Jiaming Sun, Yiming Xie, Linghao Chen, Xiaowei Zhou, and Hujun Bao, \u201cNeuralrecon: Real-time coherent 3d reconstruction from monocular video,\u201d in CVPR , 2021, pp. 15598\u201315607. 1, 2, 4, 5",
        "ref_ids": [
          "4"
        ]
      },
      "XRDSLAM: A Flexible and Modular Framework for Deep Learning based SLAM": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2410.23690",
        "ref_texts": "[29] Jiaming Sun, Yiming Xie, Linghao Chen, Xiaowei Zhou, and Hujun Bao. Neuralrecon: Real-time coherent 3d reconstruction from monocular video. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , pages 15598\u201315607, 2021.",
        "ref_ids": [
          "29"
        ]
      },
      "WildFusion: Multimodal Implicit 3D Reconstructions in the Wild": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2409.19904",
        "ref_texts": "[32] J. Sun, Y . Xie, L. Chen, X. Zhou, and H. Bao, \u201cNeuralrecon: Real-time coherent 3d reconstruction from monocular video,\u201d in Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , 2021, pp. 15 598\u201315 607.",
        "ref_ids": [
          "32"
        ]
      },
      "Leveraging 360 camera in 3D reconstruction: A visionbased approach": {
        "authors": [
          "Hoi Chuen",
          "Babar Hussain",
          "Ziyang Hong",
          "Patrick Yue"
        ],
        "url": "https://www.ijsps.com/vol12/IJSPS-V12-1.pdf",
        "ref_texts": "[17] J. Sun, Y. Xie, L. Chen, X. Zhou, and H. Bao, \u201cNeuralrecon: Real time coherent 3D reconstructio n from monocular video,\u201d in Proc . the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pp. 15598 \u201315607, 2021. ",
        "ref_ids": [
          "17"
        ]
      },
      "Real-time hybrid mapping of populated indoor scenes using a low-cost monocular uav": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2203.02453",
        "ref_texts": "[14] J. Sun*, Y . Xie*, L. Chen, X. Zhou, and H. Bao, \u201cNeuralRecon: RealTime Coherent 3D Reconstruction from Monocular Video,\u201d in CVPR , 2021.",
        "ref_ids": [
          "14"
        ]
      },
      "Pyramidal Signed Distance Learning for Spatio-Temporal Human Shape Completion": {
        "authors": [
          "Boyao Zhou",
          "Sebastien Franco",
          "Edmond Boyer"
        ],
        "url": "https://openaccess.thecvf.com/content/ACCV2022/papers/Zhou_Pyramidal_Signed_Distance_Learning_for_Spatio-Temporal_Human_Shape_Completion_ACCV_2022_paper.pdf",
        "ref_texts": "45. Sun, J., Xie, Y., Chen, L., Zhou, X., Bao, H.: NeuralRecon: Real-time coherent 3D reconstruction from monocular video. Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (2021)",
        "ref_ids": [
          "45"
        ]
      },
      "Incremental Neural Implicit Representation with Uncertainty-Filtered Knowledge Distillation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2212.10950",
        "ref_texts": "53.Sun, J., Xie, Y., Chen, L., Zhou, X., Bao, H.: Neuralrecon: Real-time coherent 3d reconstruction from monocular video. In: CVPR (2021)",
        "ref_ids": [
          "53"
        ]
      },
      "LISNeRF Mapping: LiDAR-based Implicit Mapping via Semantic Neural Fields for Large-Scale 3D Scenes": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2311.02313",
        "ref_texts": "[20] J. Sun, Y . Xie, L. Chen, X. Zhou, and H. Bao, \u201cNeuralrecon: Real-time coherent 3d reconstruction from monocular video,\u201d in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2021, pp. 15 598\u201315 607.",
        "ref_ids": [
          "20"
        ]
      },
      "MuSR: Multi-Scale 3D Scenes Reconstruction based on Monocular Video": {
        "authors": [],
        "url": "https://hackhao.github.io/publications/ICASSP2024_MuSR.pdf",
        "ref_texts": "[2] Jiaming Sun, Yiming Xie, Linghao Chen, Xiaowei Zhou, and Hujun Bao, \u201cNeuralrecon: Real-time coherent 3d reconstruction from monocular video,\u201d in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , 2021, pp. 15598\u201315607.",
        "ref_ids": [
          "2"
        ]
      },
      "Neural Camera Models": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2208.12903",
        "ref_texts": "[/one.osf/seven.osf/nine.osf] Jiaming Sun, Yiming Xie, Linghao Chen, Xiaowei Zhou, and Hujun Bao. NeuralRecon: Real-time coherent /three.osfD reconstruction from monocular video. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , pages /one.osf/five.osf/five.osf/nine.osf/eight.osf\u2013/one.osf/five.osf/six.osf/zero.osf/seven.osf, June /two.osf/zero.osf/two.osf/one.osf.",
        "ref_ids": [
          "/one\\.osf/seven\\.osf/nine\\.osf"
        ]
      },
      "SMURF: Continuous Dynamics for Motion-Deblurring Radiance Fields": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2403.07547",
        "ref_texts": "51. Sun, J., Xie, Y., Chen, L., Zhou, X., Bao, H.: Neuralrecon: Real-time coherent 3d reconstruction from monocular video. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 15598\u201315607 (2021)",
        "ref_ids": [
          "51"
        ]
      },
      "A survey on deep learning approaches for data integration in autonomous driving system": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2306.11740",
        "ref_texts": "[209] J. Sun, Y . Xie, L. Chen, X. Zhou, and H. Bao, \u201cNeuralrecon: Real-time coherent 3d reconstruction from monocular video,\u201d in IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2021, virtual, June 19-25, 2021 . Computer Vision Foundation / IEEE, 2021, pp. 15 598\u201315 607. [Online]. Available: https://openaccess.thecvf.com/ content/CVPR2021/html/Sun_NeuralRecon_Real-Time_Coherent_",
        "ref_ids": [
          "209",
          "Online"
        ]
      },
      "PSDF for Neural Indoor Scene Reconstruction": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2303.00236",
        "ref_texts": "[31] J. Sun, Y. Xie, L. Chen, X. Zhou, and H. Bao, \u201cNeuralrecon: Real-time coherent 3d reconstruction from monocular video,\u201d in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , 2021, pp. 15 598\u201315 607.",
        "ref_ids": [
          "31"
        ]
      },
      "Infrastructureless unmanned aerial vehicle localization": {
        "authors": [
          "Jouko Kinnari"
        ],
        "url": "https://aaltodoc.aalto.fi/bitstreams/42171661-0add-4288-bbb6-79f6eae79477/download",
        "ref_texts": "[113] Jiaming Sun, Yiming Xie, Linghao Chen, Xiaowei Zhou, and Hujun Bao. NeuralRecon: Real-time coherent 3d reconstruction from monocular video. InProceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 15598\u201315607, 2021.",
        "ref_ids": [
          "113"
        ]
      },
      "Robot Mapping with 3D LiDARs": {
        "authors": [
          "Ignacio Martin"
        ],
        "url": "https://bonndoc.ulb.uni-bonn.de/xmlui/bitstream/handle/20.500.11811/11536/7604.pdf?sequence=2",
        "ref_texts": "[177] J. Sun, Y. Xie, L. Chen, X. Zhou, and H. Bao. NeuralRecon: RealTime Coherent 3D Reconstruction From Monocular Video. In Proc. of the IEEE/CVF Conf. on Computer Vision and Pattern Recognition (CVPR) , 2021.",
        "ref_ids": [
          "177"
        ]
      },
      "Multi-View Image-Based 3D Reconstruction in Indoor Scenes: A Survey": {
        "authors": [],
        "url": "https://zte.magtechjournal.com/CN/article/downloadArticleFile.do?attachType=PDF&id=854",
        "ref_texts": "[12] SUN J M , XIE Y M , CHEN L H , et al . NeuralRecon : real -time coherent 3D reconstruction from monocular video [C]//Proc . IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR ). IEEE , 2021 : 15593\u2013",
        "ref_ids": [
          "12",
          "C"
        ]
      },
      "HIVE: HIerarchical Volume Encoding for Neural Implicit Surface Reconstruction": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2408.01677",
        "ref_texts": "[4] J. Sun, Y . Xie, L. Chen, X. Zhou, and H. Bao, \u201cNeuralrecon: Real-time coherent 3d reconstruction from monocular video,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , 2021, pp.",
        "ref_ids": [
          "4"
        ]
      },
      "Back2Future-SIM: Creating Real-Time Interactable Immersive Virtual World For Robot Teleoperation": {
        "authors": [],
        "url": "https://era.library.ualberta.ca/items/72cb0e47-601b-4065-98a4-d2fc0b19b8d8/download/78dd0f29-6cc9-40be-82da-36ef9230328c",
        "ref_texts": "[48] J. Sun, Y. Xie, L. Chen, X. Zhou, and H. Bao, \u201cNeuralRecon: Real-time coherent 3D reconstruction from monocular video,\u201d CVPR , 2021.",
        "ref_ids": [
          "48"
        ]
      },
      "Inferring Dense Human Representation from Sparse or Incomplete Point Clouds": {
        "authors": [],
        "url": "https://inria.hal.science/tel-03880124/file/ZHOU_2022_archivage.pdf",
        "ref_texts": "69386f6bb1dfed68692a24c8686939b9-Paper.pdf . Tsung-Yi Lin, Piotr Doll\u00e1r, Ross Girshick, Kaiming He, Bharath Hariharan, and Serge Belongie. Feature pyramid networks for object detection. In IEEE Conference on Computer Vision and Pattern Recognition , pages 936\u2013944, 2017. Jiaming Sun, Yiming Xie, Linghao Chen, Xiaowei Zhou, and Hujun Bao. NeuralRecon: Real-time coherent 3D reconstruction from monocular video. Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2021b. Hao Zhu, Xinxin Zuo, Haotian Yang, Sen Wang, Xun Cao, and Ruigang Yang. Detailed avatar recovery from single image. IEEE Transactions on Pattern Analysis and Machine Intelligence , 2021. Zerong Zheng, Tao Yu, Yebin Liu, and Qionghai Dai. Pamir: Parametric modelconditioned implicit representation for image-based human reconstruction. IEEE transactions on pattern analysis and machine intelligence , 2021a."
      },
      "3D Reconstruction of Indoor Scenes Based on Neural Implicit": {
        "authors": [],
        "url": "https://www.preprints.org/manuscript/202408.2075/download/final_file",
        "ref_texts": "11. SUN J, XIE Y, CHEN L, et al. Neuralrecon: Real-time coherent 3d reconstruction from monocular video[C]. Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. 2021 . 15598-15607. ",
        "ref_ids": [
          "11"
        ]
      },
      "Unsupervised Visual Entity Abstraction towards 2D and 3D Compositional Models": {
        "authors": [],
        "url": "https://infoscience.epfl.ch/record/298424/files/EPFL_TH8166.pdf",
        "ref_texts": ""
      },
      "Deep Models for Image Analysis, Synthesis and Scene Perception": {
        "authors": [],
        "url": "https://escholarship.org/content/qt9mv3v66d/qt9mv3v66d_noSplash_f478edeff0e57716fd68f6fcd95877b1.pdf",
        "ref_texts": "[386] Jiaming Sun, Yiming Xie, Linghao Chen, Xiaowei Zhou, and Hujun Bao. NeuralRecon: Real-time coherent 3D reconstruction from monocular video. CVPR , 2021.",
        "ref_ids": [
          "386"
        ]
      },
      "CNN-based Scene Modeling: From Depth Estimation to 3D Reconstruction": {
        "authors": [],
        "url": "https://naist.repo.nii.ac.jp/record/10969/files/R018015.pdf",
        "ref_texts": "[100] Sun, J., Xie, Y., Chen, L., Zhou, X., and Bao, H. NeuralRecon: Real-time coherent 3D reconstruction from monocular video. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (2021), pp. 15598\u201315607.",
        "ref_ids": [
          "100"
        ]
      },
      "A robust inlier identification algorithm for point cloud registration via -minimization": {
        "authors": [],
        "url": "https://openreview.net/pdf?id=BJrBaLoDRJ",
        "ref_texts": "[29] Sun, J., Xie, Y ., Chen, L., Zhou, X., Bao, H., 2021. Neuralrecon: Real-time coherent 3d reconstruction from monocular video, in: Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pp. 15598\u201315607.",
        "ref_ids": [
          "29"
        ]
      },
      "Benchmarking and Analyzing Monocular Geometry Estimation Models": {
        "authors": [],
        "url": "https://openreview.net/pdf?id=jGGylopiO8",
        "ref_texts": "755Under review as a conference paper at ICLR 2025 Nathan Silberman, Derek Hoiem, Pushmeet Kohli, and Rob Fergus. Indoor segmentation and support inference from rgbd images. In Proceedings of the European Conference on Computer Vision (ECCV), Part V , pp. 746\u2013760, 2012. Jiaming Sun, Yiming Xie, Linghao Chen, Xiaowei Zhou, and Hujun Bao. NeuralRecon: Real-time coherent 3d reconstruction from monocular video. In CVPR , pp. 15598\u201315607, 2021. Libo Sun, Wei Yin, Enze Xie, Zhengrong Li, Changming Sun, and Chunhua Shen. Improving monocular visual odometry using learned depth. 38(5):3173\u20133186, 2022. Mingxing Tan and Quoc Le. Efficientnet: Rethinking model scaling for convolutional neural networks. InInternational conference on machine learning , pp. 6105\u20136114. PMLR, 2019. Keisuke Tateno, Federico Tombari, Iro Laina, and Nassir Navab. CNN-SLAM: Real-time dense monocular slam with learned depth prediction. In CVPR , pp. 6243\u20136252, 2017. Igor Vasiljevic, Nick Kolkin, Shanyi Zhang, Ruotian Luo, Haochen Wang, Falcon Z. Dai, Andrea F. Daniele, Mohammadreza Mostajabi, Steven Basart, Matthew R. Walter, and Gregory Shakhnarovich. DIODE: A Dense Indoor and Outdoor DEpth Dataset. CoRR , 2019. Wenshan Wang, Delong Zhu, Xiangwei Wang, Yaoyu Hu, Yuheng Qiu, Chen Wang, Yafei Hu, Ashish Kapoor, and Sebastian Scherer. Tartanair: A dataset to push the limits of visual slam. In 2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) , pp. 4909\u20134916. IEEE, 2020a. Xiaolong Wang, David Fouhey, and Abhinav Gupta. Designing deep networks for surface normal estimation. In CVPR , pp. 539\u2013547, 2015. Xinlong Wang, Wei Yin, Tao Kong, Yuning Jiang, Lei Li, and Chunhua Shen. Task-aware monocular depth estimation for 3D object detection. In AAAI , volume 34, pp. 12257\u201312264, 2020b. Sanghyun Woo, Shoubhik Debnath, Ronghang Hu, Xinlei Chen, Zhuang Liu, In So Kweon, and Saining Xie. Convnext v2: Co-designing and scaling convnets with masked autoencoders. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pp."
      },
      "GNeSF: Generalizable Neural Semantic Fields Supplementary Material": {
        "authors": [],
        "url": "https://proceedings.neurips.cc/paper_files/paper/2023/file/72d32f4fe0b7af03732bd227bf1c4a5f-Supplemental-Conference.pdf",
        "ref_texts": "[8]Jiaming Sun, Yiming Xie, Linghao Chen, Xiaowei Zhou, and Hujun Bao. Neuralrecon: Realtime coherent 3d reconstruction from monocular video. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 15598\u201315607, 2021.",
        "ref_ids": [
          "8"
        ]
      },
      "Diffusion Models for 3D Generation: A Survey": {
        "authors": [],
        "url": "https://cwchenwang.github.io/data/survey.pdf",
        "ref_texts": "[138] Sun J, Xie Y, Chen L, Zhou X, Bao H. Neuralrecon: Realtime coherent 3d reconstruction from monocular video. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , 2021, 15598\u201315607.",
        "ref_ids": [
          "138"
        ]
      },
      "Supplementary Material for Cross-Dimensional Refined Learning for Real-Time 3D Visual Perception from Monocular Video": {
        "authors": [],
        "url": "https://openaccess.thecvf.com/content/ICCV2023W/JRDB/supplemental/Hong_Cross-Dimensional_Refined_Learning_ICCVW_2023_supplemental.pdf",
        "ref_texts": "[15] Jiaming Sun, Yiming Xie, Linghao Chen, Xiaowei Zhou, and Hujun Bao. Neuralrecon: Real-time coherent 3d reconstruction from monocular video. In CVPR , pages 15598\u201315607, 2021. 4, 5",
        "ref_ids": [
          "15"
        ]
      },
      "Monocular 3D Reconstruction in Poorly Visible Environments": {
        "authors": [],
        "url": "http://192.248.104.6/bitstream/handle/345/7636/IJRC31_27_34.pdf?sequence=1&isAllowed=y",
        "ref_texts": "[14] J. Sun, Y. Xie, L. Chen, X. Zhou and H. Bao, \"NeuralRecon: Real-Time Coherent 3D Reconstruction from Monocular Video,\" CVPR, 2021. ",
        "ref_ids": [
          "14"
        ]
      },
      "A Probability-guided Sampler for Neural Implicit Surface Rendering": {
        "authors": [],
        "url": "https://fq.pkwyx.com/default/https/www.ecva.net/papers/eccv_2024/papers_ECCV/papers/05407.pdf",
        "ref_texts": "44. Sun, J., Xie, Y., Chen, L., Zhou, X., Bao, H.: Neuralrecon: Real-time coherent 3d reconstruction from monocular video. In: IEEE/CVF Conf. Computer Vision and Pattern Recognition (CVPR). pp. 15598\u201315607 (2021)",
        "ref_ids": [
          "44"
        ]
      },
      "Sketch2Vox: Learning 3D Reconstruction from a Single Monocular Sketch": {
        "authors": [],
        "url": "https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/09384.pdf",
        "ref_texts": "26. Sun, J., Xie, Y., Chen, L., Zhou, X., Bao, H.: Neuralrecon: Real-time coherent 3d reconstruction from monocular video. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 15598\u201315607 (2021)",
        "ref_ids": [
          "26"
        ]
      },
      "ScanToVR: An RGB-D to VR Reconstruction Framework": {
        "authors": [],
        "url": "https://cs.utdallas.edu/files/2023/03/final_draft_withnames.pdf",
        "ref_texts": "[17] Xu, Yabin, et al. \u2018HRBF -Fusion: Accurate 3D Reconstruction from RGB -D Data Usin g on -the-Fly Implicits\u2019. ACM Transactions on Graphics, vol. 41, no. 3, Association for Computing Machinery (ACM), June 2022, pp. 1 \u201319, https://doi.org10.1145/3516521. [18] Sun, Jiaming, et al. \u2018NeuralRecon: Real -Time Coherent 3D Reconstruction from Monocular Vi deo\u2019. ArXiv [Cs.CV], 1 Apr. 2021, http://arxiv.org/abs/2104.00681. arXiv. ",
        "ref_ids": [
          "17",
          "18",
          "Cs\\.CV"
        ]
      },
      "Geometry and learning for efficient 3D perception": {
        "authors": [],
        "url": "https://www.repository.unipr.it/bitstream/1889/5572/4/tesi.pdf",
        "ref_texts": "[56] J. Sun, Y. Xie, L. Chen, X. Zhou, and H. Bao, \u201cNeuralRecon: Real-time coherent 3D reconstruction from monocular video,\u201d CVPR , 2021.",
        "ref_ids": [
          "56"
        ]
      },
      "LONG-LRM: LONG-SEQUENCE LARGE RECONSTRUC-TION MODEL FOR WIDE-COVERAGE GAUSSIAN SPLATS": {
        "authors": [],
        "url": "https://openreview.net/pdf?id=meOELl7HRf",
        "ref_texts": "701Under review as a conference paper at ICLR 2025 Jiaming Sun, Yiming Xie, Linghao Chen, Xiaowei Zhou, and Hujun Bao. Neuralrecon: Real-time coherent 3d reconstruction from monocular video. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pp. 15598\u201315607, 2021. Stanislaw Szymanowicz, Christian Rupprecht, and Andrea Vedaldi. Splatter image: Ultra-fast single-view 3d reconstruction. arXiv preprint arXiv:2312.13150 , 2023. Matthew Tancik, Ethan Weber, Evonne Ng, Ruilong Li, Brent Yi, Terrance Wang, Alexander Kristoffersen, Jake Austin, Kamyar Salahi, Abhik Ahuja, et al. Nerfstudio: A modular framework for neural radiance field development. In ACM SIGGRAPH 2023 Conference Proceedings , pp."
      },
      "Supplementary: Directed Ray Distance Functions for 3D Scene Reconstruction": {
        "authors": [],
        "url": "https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136620193-supp.pdf",
        "ref_texts": "12. Sun, J., Xie, Y., Chen, L., Zhou, X., Bao, H.: Neuralrecon: Real-time coherent 3d reconstruction from monocular video. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 15598{15607 (2021) 5",
        "ref_ids": [
          "12"
        ]
      },
      "Supplementary of NeuRIS": {
        "authors": [],
        "url": "https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136920139-supp.pdf",
        "ref_texts": "13. Sun, J., Xie, Y., Chen, L., Zhou, X., Bao, H.: NeuralRecon: Real-time coherent 3D reconstruction from monocular video. CVPR (2021)",
        "ref_ids": [
          "13"
        ]
      },
      "End-to-End Learned Multi-View Stereo Reconstruction with Transformers": {
        "authors": [],
        "url": "https://dylanorange.github.io/files/mvs.pdf",
        "ref_texts": "[10] Jiaming Sun, Yiming Xie, Linghao Chen, Xiaowei Zhou, and Hujun Bao. Neuralrecon: Real-time coherent 3d reconstruction from monocular video. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 15598\u201315607, 2021. 2",
        "ref_ids": [
          "10"
        ]
      },
      "EE381V: Active 3D Reconstruction by Using Ego-centric Camera": {
        "authors": [],
        "url": "https://zhou-spec.github.io/files/EE381V_mseo_zfang.pdf",
        "ref_texts": "[23] Jiaming Sun, Yiming Xie, Linghao Chen, Xiaowei Zhou, and Hujun Bao. Neuralrecon: Real-time coherent 3d reconstruction from monocular video. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 15598\u201315607, 2021. 2, 3, 5",
        "ref_ids": [
          "23"
        ]
      },
      "TerrainMesh: Metric-Semantic Terrain Reconstruction from Aerial Images Using Joint 2D-3D Learning": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2204.10993",
        "ref_texts": "[37] J. Sun, Y . Xie, L. Chen, X. Zhou, and H. Bao, \u201cNeuralRecon: Real-Time Coherent 3D Reconstruction From Monocular Video,\u201d in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) , June 2021, pp. 15 598\u201315 607.",
        "ref_ids": [
          "37"
        ]
      },
      "Point Cloud \uc758 \uc2dc\uac01\ud654\ub97c \uc704\ud55c Mesh Reconstruction": {
        "authors": [],
        "url": "https://www.kibme.org/resources/journal/20231110110055481.pdf",
        "ref_texts": "[5]\t\tJ.\tSun,\tY.\tXie,\tL.\tChen,\tX.\tZhou\tand\tH.\tBao,\t \u201cNeuralRecon:\t Real-Time\t Coherent\t 3D\tReconstruction\t from\tMonocular\t Video,\u201d\tin\t2021\tIEEE/ CVF\tConference\ton\tComputer\tVision\tand\tPattern\tRecognition\t(CVPR),\tNashville,\tTN,\tUSA,\t2021\tpp.\t15593-15602.",
        "ref_ids": [
          "5"
        ]
      }
    }
  },
  {
    "title": "hierarchical saliency detection",
    "id": 0,
    "valid_pdf_number": "665/1004",
    "matched_pdf_number": "0/665",
    "matched_rate": 0.0,
    "citations": {
      "DVSOD: RGB-D video salient object detection": {
        "authors": [],
        "url": "https://proceedings.neurips.cc/paper_files/paper/2023/file/1b88e65f737256d437e56764d39ba06d-Paper-Datasets_and_Benchmarks.pdf",
        "ref_texts": ""
      },
      "Capsule networks with residual pose routing": {
        "authors": [],
        "url": "https://eprints.whiterose.ac.uk/208071/1/FINAL%20VERSION.pdf",
        "ref_texts": ""
      },
      "VSCode: General Visual Salient and Camouflaged Object Detection with 2D Prompt Learning": {
        "authors": [
          "Ziyang Luo",
          "Nian Liu",
          "Wangbo Zhao",
          "Xuguang Yang",
          "Dingwen Zhang",
          "Ping Fan",
          "Fahad Khan",
          "Junwei Han"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Luo_VSCode_General_Visual_Salient_and_Camouflaged_Object_Detection_with_2D_CVPR_2024_paper.pdf"
      },
      "Weakly-supervised contrastive learning for unsupervised object discovery": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2307.03376",
        "ref_texts": ""
      },
      "Unsupervised object localization in the era of self-supervised vits: A survey": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2310.12904",
        "ref_texts": ""
      },
      "VST++: Efficient and Stronger Visual Saliency Transformer": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2310.11725"
      },
      "Task-Adaptive Saliency Guidance for Exemplar-free Class Incremental Learning": {
        "authors": [
          "Xialei Liu",
          "Tian Zhai",
          "Andrew D. Bagdanov",
          "Ke Li",
          "Ming Cheng"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Liu_Task-Adaptive_Saliency_Guidance_for_Exemplar-free_Class_Incremental_Learning_CVPR_2024_paper.pdf",
        "ref_texts": ""
      },
      "Generative transformer for accurate and reliable salient object detection": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2104.10127",
        "ref_texts": ""
      },
      "Self-Calibrating Vicinal Risk Minimisation for Model Calibration": {
        "authors": [
          "Jiawei Liu",
          "Changkun Ye",
          "Ruikai Cui",
          "Nick Barnes"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Liu_Self-Calibrating_Vicinal_Risk_Minimisation_for_Model_Calibration_CVPR_2024_paper.pdf",
        "ref_texts": ""
      },
      "Advancing Saliency Ranking with Human Fixations: Dataset Models and Benchmarks": {
        "authors": [
          "Bowen Deng",
          "Siyang Song",
          "Andrew P. French",
          "Denis Schluppeck",
          "Michael P. Pound"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Deng_Advancing_Saliency_Ranking_with_Human_Fixations_Dataset_Models_and_Benchmarks_CVPR_2024_paper.pdf",
        "ref_texts": ""
      },
      "Salient Object-Aware Background Generation using Text-Guided Diffusion Models": {
        "authors": [
          "Amir Erfan",
          "Joao V",
          "Kapil Thadani",
          "Shaunak Mishra",
          "Mikhail Kuznetsov",
          "Ning Ku",
          "Paloma De"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024W/GCV/papers/Eshratifar_Salient_Object-Aware_Background_Generation_using_Text-Guided_Diffusion_Models_CVPRW_2024_paper.pdf",
        "ref_texts": ""
      },
      "Hierarchical Histogram Threshold Segmentation-Auto-terminating High-detail Oversegmentation": {
        "authors": [
          "Thomas V. Chang",
          "Simon Seibt",
          "Rymon Lipinski"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Chang_Hierarchical_Histogram_Threshold_Segmentation_-_Auto-terminating_High-detail_Oversegmentation_CVPR_2024_paper.pdf",
        "ref_texts": ""
      },
      "SAM2-UNet: Segment Anything 2 Makes Strong Encoder for Natural and Medical Image Segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2408.08870",
        "ref_texts": ""
      },
      "Glass segmentation with multi scales and primary prediction guiding": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2402.08571",
        "ref_texts": ""
      },
      "PEEKABOO: Hiding parts of an image for unsupervised object localization": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2407.17628",
        "ref_texts": ""
      },
      "Benchmarking deep models on salient object detection": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2202.02925",
        "ref_texts": ""
      },
      "Inferring Attention Shifts for Salient Instance Ranking": {
        "authors": [
          "Avishek Siris"
        ],
        "url": "https://link.springer.com/content/pdf/10.1007/s11263-023-01906-7.pdf",
        "ref_texts": ""
      },
      "Robust detection and refinement of saliency identification": {
        "authors": [
          "Abram W. Makram"
        ],
        "url": "https://www.nature.com/articles/s41598-024-61105-3.pdf",
        "ref_texts": ""
      },
      "Salient object detection for images taken by people with vision impairments": {
        "authors": [
          "Jarek Reynolds",
          "Chandra Kanth",
          "Danna Gurari"
        ],
        "url": "https://openaccess.thecvf.com/content/WACV2024/papers/Reynolds_Salient_Object_Detection_for_Images_Taken_by_People_With_Vision_WACV_2024_paper.pdf",
        "ref_texts": ""
      },
      "Alignment-Free RGBT Salient Object Detection: Semantics-guided Asymmetric Correlation Network and A Unified Benchmark": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2406.00917",
        "ref_texts": ""
      },
      "United Domain Cognition Network for Salient Object Detection in Optical Remote Sensing Images": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2411.06703",
        "ref_texts": ""
      },
      "SSFam: Scribble Supervised Salient Object Detection Family": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2409.04817",
        "ref_texts": ""
      },
      "Multi-Scale and Detail-Enhanced Segment Anything Model for Salient Object Detection": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2408.04326",
        "ref_texts": ""
      },
      "Size-invariance Matters: Rethinking Metrics and Losses for Imbalanced Multi-object Salient Object Detection": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2405.09782",
        "ref_texts": ""
      },
      "Salient object detection: a mini review": {
        "authors": [],
        "url": "https://www.frontiersin.org/articles/10.3389/frsip.2024.1356793/pdf",
        "ref_texts": ""
      },
      "3SD: Self-supervised saliency detection with no labels": {
        "authors": [
          "Rajeev Yasarla",
          "Renliang Weng",
          "Wongun Choi",
          "Vishal M. Patel",
          "Amir Sadeghian"
        ],
        "url": "https://openaccess.thecvf.com/content/WACV2024/papers/Yasarla_3SD_Self-Supervised_Saliency_Detection_With_No_Labels_WACV_2024_paper.pdf",
        "ref_texts": ""
      },
      "Robust Salient Object Detection on Compressed Images Using Convolutional Neural Networks": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2409.13464",
        "ref_texts": ""
      },
      "Masked Multi-Query Slot Attention for Unsupervised Object Discovery": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2404.19654",
        "ref_texts": ""
      },
      "Spatial Coherence Loss for Salient and Camouflaged Object Detection and Beyond": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2402.18698",
        "ref_texts": ""
      },
      "Semantic-Consistency-guided Learning on Deep Features for Unsupervised Salient Object Detection": {
        "authors": [],
        "url": "https://scholar.archive.org/work/3popqrvwszddhbfle7eugvzrq4/access/wayback/https://dl.acm.org/doi/pdf/10.1145/3640816"
      },
      "Unified Unsupervised Salient Object Detection via Knowledge Transfer": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2404.14759",
        "ref_texts": ""
      },
      "PGNeXt: High-Resolution Salient Object Detection via Pyramid Grafting Network": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2408.01137",
        "ref_texts": ""
      },
      "Seg-HGNN: Unsupervised and Light-Weight Image Segmentation with Hyperbolic Graph Neural Networks": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2409.06589?",
        "ref_texts": ""
      },
      "Category-Aware Saliency Enhance Learning Based on CLIP for Weakly Supervised Salient Object Detection": {
        "authors": [
          "Yunde Zhang"
        ],
        "url": "https://link.springer.com/content/pdf/10.1007/s11063-024-11530-2.pdf",
        "ref_texts": ""
      },
      "Frequency-Guided Spatial Adaptation for Camouflaged Object Detection": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2409.12421",
        "ref_texts": ""
      },
      "Salient Object Detection via Fusion of Multi-Visual Perception": {
        "authors": [
          "Wenjun Zhou",
          "Tianfei Wang",
          "Xiaoqin Wu",
          "Chenglin Zuo",
          "Yifan Wang",
          "Quan Zhang",
          "Bo Peng"
        ],
        "url": "https://www.mdpi.com/2076-3417/14/8/3433/pdf",
        "ref_texts": ""
      },
      "Weakly supervised salient object detection via bounding-box annotation and SAM model": {
        "authors": [
          "Xiangquan Liu",
          "Xiaoming Huang"
        ],
        "url": "https://www.aimspress.com/aimspress-data/era/2024/3/PDF/era-32-03-074.pdf",
        "ref_texts": ""
      },
      "Space\u2013time recurrent memory network": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2109.06474",
        "ref_texts": ""
      },
      "SalFAU-Net: Saliency Fusion Attention U-Net for Salient Object Detection": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2405.02906",
        "ref_texts": ""
      },
      "Enhancing Salient Object Detection with Supervised Learning and Multi-prior Integration": {
        "authors": [
          "Gayathri Dhara",
          "Ravi Kant"
        ],
        "url": "https://www.joig.net/2024/JOIG-V12N2-186.pdf",
        "ref_texts": ""
      },
      "FIPGNet: Pyramid grafting network with feature interaction strategies": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2407.04085",
        "ref_texts": ""
      },
      "CPDR: Towards Highly-Efficient Salient Object Detection via Crossed Post-decoder Refinement": {
        "authors": [],
        "url": "https://yijie-li2022.github.io/assets/pdf/2024BMVC_CPDR.pdf",
        "ref_texts": ""
      },
      "Supplementary Material: VSCode: General Visual Salient and Camouflaged Object Detection with 2D Prompt Learning": {
        "authors": [],
        "url": "https://openaccess.thecvf.com/content/CVPR2024/supplemental/Luo_VSCode_General_Visual_CVPR_2024_supplemental.pdf",
        "ref_texts": ""
      },
      "Task-Adaptive Saliency Guidance for Exemplar-free Class Incremental Learning\u2013Supplementary Material\u2013": {
        "authors": [],
        "url": "https://openaccess.thecvf.com/content/CVPR2024/supplemental/Liu_Task-Adaptive_Saliency_Guidance_CVPR_2024_supplemental.pdf",
        "ref_texts": ""
      },
      "Frequency-Spatial Entanglement Learning for Camouflaged Object Detection Supplementary Materials": {
        "authors": [],
        "url": "https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/01001-supp.pdf",
        "ref_texts": ""
      },
      "DESIGN THINKING APPROACH FOR DEEP VISUAL SALIENCY ON STEREOSCOPIC USING IMAGE PROCESSING": {
        "authors": [],
        "url": "https://ijgst.com/admin/uploadss/5%20ijgst%20(current%20issue).pdf",
        "ref_texts": ""
      },
      "Data-driven single image deraining: A comprehensive review and new perspectives": {
        "authors": [],
        "url": "https://hammer.purdue.edu/articles/preprint/Data-Driven_Single_Image_Deraining_A_Comprehensive_Review_and_New_Perspectives/14944752/4/files/38686356.pdf",
        "ref_texts": ""
      },
      "Pixels, regions, and objects: Multiple enhancement for salient object detection": {
        "authors": [
          "Yi Wang",
          "Ruili Wang",
          "Xin Fan",
          "Tianzhu Wang",
          "Xiangjian He"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2023/papers/Wang_Pixels_Regions_and_Objects_Multiple_Enhancement_for_Salient_Object_Detection_CVPR_2023_paper.pdf",
        "ref_texts": ""
      },
      "Tokencut: Segmenting objects in images and videos with self-supervised transformer and normalized cut": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2209.00383",
        "ref_texts": ""
      },
      "Unsupervised object localization: Observing the background to discover objects": {
        "authors": [
          "Oriane Simeoni",
          "Chloe Sekkat",
          "Gilles Puy",
          "Antonin Vobecky",
          "Eloi Zablocki",
          "Patrick Perez"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2023/papers/Simeoni_Unsupervised_Object_Localization_Observing_the_Background_To_Discover_Objects_CVPR_2023_paper.pdf",
        "ref_texts": ""
      },
      "Sketch2Saliency: learning to detect salient objects from human drawings": {
        "authors": [
          "Ayan Kumar",
          "Subhadeep Koley",
          "Amandeep Kumar",
          "Aneeshan Sain",
          "Pinaki Nath",
          "Tao Xiang",
          "Zhe Song"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Bhunia_Sketch2Saliency_Learning_To_Detect_Salient_Objects_From_Human_Drawings_CVPR_2023_paper.pdf",
        "ref_texts": ""
      },
      "Texture-guided saliency distilling for unsupervised salient object detection": {
        "authors": [
          "Huajun Zhou",
          "Bo Qiao",
          "Lingxiao Yang",
          "Jianhuang Lai",
          "Xiaohua Xie"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2023/papers/Zhou_Texture-Guided_Saliency_Distilling_for_Unsupervised_Salient_Object_Detection_CVPR_2023_paper.pdf",
        "ref_texts": ""
      },
      "Glass segmentation with RGB-thermal image pairs": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2204.05453",
        "ref_texts": ""
      },
      "Tcgnet: Type-correlation guidance for salient object detection": {
        "authors": [],
        "url": "https://eprints.whiterose.ac.uk/206631/1/Manuscript_T-ITS.pdf",
        "ref_texts": ""
      },
      "Modeling the distributional uncertainty for salient object detection models": {
        "authors": [
          "Xinyu Tian",
          "Jing Zhang",
          "Mochu Xiang",
          "Yuchao Dai"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2023/papers/Tian_Modeling_the_Distributional_Uncertainty_for_Salient_Object_Detection_Models_CVPR_2023_paper.pdf",
        "ref_texts": ""
      },
      "Visual dependency transformers: Dependency tree emerges from reversed attention": {
        "authors": [
          "Mingyu Ding",
          "Yikang Shen",
          "Lijie Fan",
          "Zhenfang Chen",
          "Zitian Chen",
          "Ping Luo",
          "Joshua B. Tenenbaum",
          "Chuang Gan"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Ding_Visual_Dependency_Transformers_Dependency_Tree_Emerges_From_Reversed_Attention_CVPR_2023_paper.pdf",
        "ref_texts": ""
      },
      "Deepcut: Unsupervised segmentation using graph neural networks clustering": {
        "authors": [
          "Amit Aflalo",
          "Shai Bagon",
          "Tamar Kashti",
          "Yonina Eldar"
        ],
        "url": "https://openaccess.thecvf.com/content/ICCV2023W/SG2RL/papers/Aflalo_DeepCut_Unsupervised_Segmentation_Using_Graph_Neural_Networks_Clustering_ICCVW_2023_paper.pdf",
        "ref_texts": ""
      },
      "Mffn: Multi-view feature fusion network for camouflaged object detection": {
        "authors": [
          "Dehua Zheng",
          "Xiaochen Zheng",
          "Laurence T. Yang",
          "Yuan Gao",
          "Chenlu Zhu",
          "Yiheng Ruan"
        ],
        "url": "https://openaccess.thecvf.com/content/WACV2023/papers/Zheng_MFFN_Multi-View_Feature_Fusion_Network_for_Camouflaged_Object_Detection_WACV_2023_paper.pdf",
        "ref_texts": ""
      },
      "Model calibration in dense classification with adaptive label perturbation": {
        "authors": [
          "Jiawei Liu",
          "Changkun Ye",
          "Shan Wang",
          "Ruikai Cui",
          "Jing Zhang",
          "Kaihao Zhang",
          "Nick Barnes"
        ],
        "url": "http://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Model_Calibration_in_Dense_Classification_with_Adaptive_Label_Perturbation_ICCV_2023_paper.pdf",
        "ref_texts": ""
      },
      "A novel seminar learning framework for weakly supervised salient object detection": {
        "authors": [],
        "url": "https://pure.ulster.ac.uk/files/126751214/EAAI-22-4887_R2_1_.pdf",
        "ref_texts": ""
      },
      "Boosting salient object detection with transformer-based asymmetric bilateral U-Net": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2108.07851",
        "ref_texts": ""
      },
      "Rethinking lightweight salient object detection via network depth-width tradeoff": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2301.06679",
        "ref_texts": ""
      },
      "MNet: Multilevel, Mixed and Multistage Attention Network for Salient Object Detection": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2309.08365",
        "ref_texts": ""
      },
      "Test time adaptation with regularized loss for weakly supervised salient object detection": {
        "authors": [
          "Olga Veksler"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Veksler_Test_Time_Adaptation_With_Regularized_Loss_for_Weakly_Supervised_Salient_CVPR_2023_paper.pdf",
        "ref_texts": ""
      },
      "Towards End-to-End Unsupervised Saliency Detection with Self-Supervised Top-Down Context": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2310.09533",
        "ref_texts": ""
      },
      "Multiple attention mechanism enhanced YOLOX for remote sensing object detection": {
        "authors": [
          "Chao Shen",
          "Caiwen Ma",
          "Wei Gao"
        ],
        "url": "https://www.mdpi.com/1424-8220/23/3/1261/pdf",
        "ref_texts": ""
      },
      "SU2GE-Net: a saliency-based approach for non-specific class foreground segmentation": {
        "authors": [
          "Xiaochun Lei"
        ],
        "url": "https://www.nature.com/articles/s41598-023-40175-9.pdf",
        "ref_texts": ""
      },
      "Joint salient object detection and camouflaged object detection via uncertainty-aware learning": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2307.04651",
        "ref_texts": ""
      },
      "Depth-aided camouflaged object detection": {
        "authors": [
          "Qingwei Wang"
        ],
        "url": "https://scholar.archive.org/work/m74p6s6wuneuzmj472ke7gzjnu/access/wayback/https://dl.acm.org/doi/pdf/10.1145/3581783.3611874",
        "ref_texts": ""
      },
      "Unified-modal salient object detection via adaptive prompt learning": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2311.16835",
        "ref_texts": ""
      },
      "A visual representation-guided framework with global affinity for weakly supervised salient object detection": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2302.10697",
        "ref_texts": ""
      },
      "Guided multi-scale refinement network for camouflaged object detection": {
        "authors": [
          "Xiuqi Xu"
        ],
        "url": "https://link.springer.com/content/pdf/10.1007/s11042-022-13274-4.pdf",
        "ref_texts": ""
      },
      "Multi-guidance CNNs for salient object detection": {
        "authors": [],
        "url": "https://dl.acm.org/doi/pdf/10.1145/3570507",
        "ref_texts": ""
      },
      "Semantic-constraint matching transformer for weakly supervised object localization": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2309.01331",
        "ref_texts": ""
      },
      "Adaptive low rank adaptation of segment anything to salient object detection": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2308.05426",
        "ref_texts": ""
      },
      "All in one: Rgb, rgb-d, and rgb-t salient object detection": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2311.14746",
        "ref_texts": ""
      },
      "Multi-difference image fusion change detection using a visual attention model on VHR satellite data": {
        "authors": [
          "Jianhui Luo",
          "Qiang Chen",
          "Lei Wang",
          "Yixiao Huang"
        ],
        "url": "https://www.mdpi.com/2072-4292/15/15/3799/pdf",
        "ref_texts": ""
      },
      "QCNet: query context network for salient object detection of automatic surface inspection": {
        "authors": [
          "Jie Sun"
        ],
        "url": "https://link.springer.com/content/pdf/10.1007/s00371-022-02597-w.pdf",
        "ref_texts": ""
      },
      "Synthesize boundaries: A boundary-aware self-consistent framework for weakly supervised salient object detection": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2212.01764",
        "ref_texts": ""
      },
      "Segmix: Co-occurrence driven mixup for semantic segmentation and adversarial robustness": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2108.09929",
        "ref_texts": ""
      },
      "Salient-centeredness and saliency size in computational aesthetics": {
        "authors": [
          "Weng Khuan"
        ],
        "url": "https://openaccess.wgtn.ac.nz/articles/journal_contribution/Salient-Centeredness_and_Saliency_Size_in_Computational_Aesthetics/25856824/1/files/46412686.pdf",
        "ref_texts": ""
      },
      "WUSL\u2013SOD: Joint weakly supervised, unsupervised and supervised learning for salient object detection": {
        "authors": [],
        "url": "https://pure.ulster.ac.uk/files/126748580/NCAA_Ulster-2.pdf",
        "ref_texts": ""
      },
      "SqueezeSAM: User friendly mobile interactive segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2312.06736",
        "ref_texts": ""
      },
      "Lightweight saliency detection method for real-time localization of livestock meat bones": {
        "authors": [
          "Tao Xu"
        ],
        "url": "https://www.nature.com/articles/s41598-023-31551-6.pdf",
        "ref_texts": ""
      },
      "Robust seed selection of foreground and background priors based on directional blocks for saliency-detection system": {
        "authors": [
          "Muwei Jian"
        ],
        "url": "https://researchportal.port.ac.uk/files/55493024/Robust_seed_selection_of_foreground_and_background_pp.pdf",
        "ref_texts": ""
      },
      "Saliency Map Estimation Using a Pixel-Pairwise-Based Unsupervised Markov Random Field Model": {
        "authors": [
          "Max Mignotte"
        ],
        "url": "https://www.mdpi.com/2227-7390/11/4/986/pdf",
        "ref_texts": ""
      },
      "Sharp eyes: A salient object detector working the same way as human visual characteristics": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2301.07431",
        "ref_texts": ""
      },
      "Disentangle saliency detection into cascaded detail modeling and body filling": {
        "authors": [],
        "url": "https://dl.acm.org/doi/pdf/10.1145/3513134",
        "ref_texts": ""
      },
      "FESNet: Frequency-Enhanced Saliency Detection Network for Grain Pest Segmentation": {
        "authors": [
          "Junwei Yu",
          "Fupin Zhai",
          "Nan Liu",
          "Yi Shen",
          "Quan Pan"
        ],
        "url": "https://www.mdpi.com/2075-4450/14/2/99/pdf",
        "ref_texts": ""
      },
      "(MARGOT) Monocular Camera-Based Robot Grasping Strategy for Metallic Objects": {
        "authors": [],
        "url": "https://www.mdpi.com/1424-8220/23/11/5344/pdf",
        "ref_texts": ""
      },
      "LARNet: Towards Lightweight, Accurate and Real-time Salient Object Detection": {
        "authors": [],
        "url": "https://pure.ulster.ac.uk/files/132578508/LARNetTowards_Lightweight_Accurate_and_Real-time_Salient_Object_Detection.pdf",
        "ref_texts": ""
      },
      "Joint Gaze-Location and Gaze-Object Detection": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2308.13857",
        "ref_texts": ""
      },
      "Self-Improved Learning for Salient Object Detection": {
        "authors": [
          "Songyuan Li",
          "Hao Zeng",
          "Huanyu Wang",
          "Xi Li"
        ],
        "url": "https://www.mdpi.com/2076-3417/13/23/12966/pdf",
        "ref_texts": ""
      },
      "A Novel Edge-Inspired Depth Quality Evaluation Network for RGB-D Salient Object Detection": {
        "authors": [],
        "url": "https://scholar.archive.org/work/76zgkhxmlzf2jm4ekbexesyhdu/access/wayback/https://assets.researchsquare.com/files/rs-2425669/v1_covered.pdf?c=1675165292",
        "ref_texts": ""
      },
      "Alignment Integration Network for Salient Object Detection and Its Application for Optical Remote Sensing Images": {
        "authors": [
          "Xiaoning Zhang",
          "Yi Yu",
          "Yuqing Wang",
          "Xiaolin Chen",
          "Chenglong Wang"
        ],
        "url": "https://www.mdpi.com/1424-8220/23/14/6562/pdf",
        "ref_texts": ""
      },
      "An energy-based prior for generative saliency": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2204.08803",
        "ref_texts": ""
      },
      "An Adaptive Multi-Content Complementary Network for Salient Object Detection": {
        "authors": [
          "Lina Huo",
          "Kaidi Guo",
          "Wei Wang"
        ],
        "url": "https://www.mdpi.com/2079-9292/12/22/4600/pdf",
        "ref_texts": ""
      },
      "MFDANet: Multi-Scale Feature Dual-Stream Aggregation Network for Salient Object Detection": {
        "authors": [
          "Bin Ge",
          "Jiajia Pei",
          "Chenxing Xia",
          "Taolin Wu"
        ],
        "url": "https://www.mdpi.com/2079-9292/12/13/2880/pdf",
        "ref_texts": ""
      },
      "Fast and accurate light field saliency detection through deep encoding": {
        "authors": [
          "Sahan Hemachandra",
          "Ranga Rodrigo",
          "Chamira U. S"
        ],
        "url": "https://arxiv.org/pdf/2010.13073",
        "ref_texts": ""
      },
      "Weakly supervised salient object detection via image category annotation": {
        "authors": [
          "Ruoqi Zhang"
        ],
        "url": "https://www.aimspress.com/aimspress-data/mbe/2023/12/PDF/mbe-20-12-945.pdf",
        "ref_texts": ""
      },
      "Improved High-Resolution Salient Object Detection Algorithm Based on Enhanced PGNet.": {
        "authors": [],
        "url": "https://www.engineeringletters.com/issues_v31/issue_4/EL_31_4_24.pdf",
        "ref_texts": ""
      },
      "Cascaded Interaction with Eroded Deep Supervision for Salient Object Detection": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2311.18675",
        "ref_texts": ""
      },
      "Saliency Detection Algorithm for Foggy Images Based on Deep Learning": {
        "authors": [],
        "url": "https://www.itc.ktu.lt/index.php/ITC/article/download/32258/16041",
        "ref_texts": ""
      },
      "Multi-stream Temporally Enhanced Network for Video Salient Object Detection": {
        "authors": [],
        "url": "https://cdn.techscience.cn/files/cmc/2024/TSP_CMC-78-1/TSP_CMC_45258/TSP_CMC_45258.pdf",
        "ref_texts": ""
      },
      "Hybrid Attention Asynchronous Cascade Network for Salient Object Detection": {
        "authors": [
          "Haiyan Yang",
          "Yongxin Chen",
          "Rui Chen",
          "Shuning Liu"
        ],
        "url": "https://www.mdpi.com/2227-7390/11/6/1389/pdf",
        "ref_texts": ""
      },
      "Adaptive Graph Convolution Module for Salient Object Detection": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2303.09801",
        "ref_texts": ""
      },
      "ORNet: Object Refinement Network Based on Dual-Branch and Multi-Feature Enhancement for Saliency Detection": {
        "authors": [],
        "url": "https://www.researchsquare.com/article/rs-3737457/latest.pdf",
        "ref_texts": ""
      },
      "Saliency-Assisted Collaborative Learning Network for Road Scene Semantic Segmentation.": {
        "authors": [],
        "url": "https://koreascience.kr/article/JAKO202311737505446.pdf",
        "ref_texts": ""
      },
      "LBP inspired efficient deep convolutional neural networks for visual representation learning": {
        "authors": [],
        "url": "https://oulurepo.oulu.fi/bitstream/handle/10024/46390/isbn978-952-62-3809-8.pdf?sequence=1",
        "ref_texts": ""
      },
      "Passive Visual Underwater Surveillance: A Survey": {
        "authors": [],
        "url": "https://www.researchsquare.com/article/rs-2585848/latest.pdf",
        "ref_texts": ""
      },
      "Supplementary Materials for Texture-guided Saliency Distilling for Unsupervised Salient Object Detection": {
        "authors": [],
        "url": "https://openaccess.thecvf.com/content/CVPR2023/supplemental/Zhou_Texture-Guided_Saliency_Distilling_CVPR_2023_supplemental.pdf",
        "ref_texts": ""
      },
      "SuperFormer: Superpixel-based Transformers for Salient Object Detection": {
        "authors": [],
        "url": "https://openreview.net/pdf?id=8phE9BVRWS",
        "ref_texts": ""
      },
      "Efficient Unsupervised Knowledge Distillation with Space Similarity": {
        "authors": [],
        "url": "https://openreview.net/pdf?id=QHVTxso1Is",
        "ref_texts": ""
      },
      "T\u00e9cnicas de detecci\u00f3n de \u00e1reas de inter\u00e9s para el espectador orientadas a la compresi\u00f3n de v\u00eddeo": {
        "authors": [
          "Ricardo Imbert"
        ],
        "url": "https://oa.upm.es/75538/1/TFG_PABLO_SANCHEZ_SANCHEZ.pdf",
        "ref_texts": ""
      },
      "Adaptace b\u011bhem testov\u00e1n\u00ed pro \u00falohu segmentace": {
        "authors": [],
        "url": "https://dspace.cvut.cz/bitstream/handle/10467/109284/F3-DP-2023-Janouskova-Klara-test_time_adaptation_for_segmentation.pdf?sequence=-1",
        "ref_texts": ""
      },
      "\u7ed3\u5408 Transformer \u7684\u663e\u8457\u6027\u76ee\u6807\u68c0\u6d4b.": {
        "authors": [],
        "url": "https://xk.sia.cn/cn/article/pdf/preview/10.13976/j.cnki.xk.2023.2119.pdf",
        "ref_texts": ""
      },
      "\u57fa\u4e8e\u6df1\u76d1\u7763\u975e\u7ebf\u6027\u878d\u5408\u7684\u663e\u8457\u6027\u7269\u4f53\u68c0\u6d4b": {
        "authors": [],
        "url": "https://yun-liu.github.io/materials/TCYB2021_DNA_CN.pdf",
        "ref_texts": ""
      },
      "\u878d\u5408\u6846\u67b6\u8868\u793a\u7684\u6c49\u8bed\u6846\u67b6\u7f51\u8bcd\u5143\u6269\u5145": {
        "authors": [],
        "url": "http://www.shcas.net/jsjyup/pdf/2023/4/%E8%9E%8D%E5%90%88%E6%A1%86%E6%9E%B6%E8%A1%A8%E7%A4%BA%E7%9A%84%E6%B1%89%E8%AF%AD%E6%A1%86%E6%9E%B6%E7%BD%91%E8%AF%8D%E5%85%83%E6%89%A9%E5%85%85.pdf",
        "ref_texts": ""
      },
      "\u041c\u0435\u0442\u043e\u0434 \u043f\u043e\u0438\u0441\u043a\u0430 \u043e\u0431\u043b\u0430\u0441\u0442\u0435\u0439 \u0440\u0430\u0437\u043c\u044b\u0442\u0438\u044f \u043d\u0430 \u0433\u0438\u0441\u0442\u043e\u043b\u043e\u0433\u0438\u0447\u0435\u0441\u043a\u0438\u0445 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f\u0445": {
        "authors": [],
        "url": "https://www.graphicon.ru/html/2023/papers/paper_064.pdf",
        "ref_texts": ""
      },
      "\u8fb9\u7f18\u4fe1\u606f\u5f15\u5bfc\u591a\u7ea7\u5c3a\u5ea6\u7279\u5f81\u878d\u5408\u7684\u663e\u8457\u6027\u76ee\u6807\u68c0\u6d4b\u65b9\u6cd5": {
        "authors": [],
        "url": "https://www.researching.cn/ArticlePdf/m00018/2023/52/1/20220344.pdf",
        "ref_texts": ""
      },
      "Zoom in and out: A mixed-scale triplet network for camouflaged object detection": {
        "authors": [
          "Youwei Pang",
          "Xiaoqi Zhao",
          "Zhu Xiang",
          "Lihe Zhang",
          "Huchuan Lu"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2022/papers/Pang_Zoom_in_and_Out_A_Mixed-Scale_Triplet_Network_for_Camouflaged_CVPR_2022_paper.pdf",
        "ref_texts": ""
      },
      "Salient object detection via integrity learning": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2101.07663",
        "ref_texts": ""
      },
      "A survey on deep learning technique for video segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2107.01153",
        "ref_texts": ""
      },
      "Pyramid grafting network for one-stage high resolution saliency detection": {
        "authors": [
          "Chenxi Xie",
          "Changqun Xia",
          "Mingcan Ma",
          "Zhirui Zhao",
          "Xiaowu Chen",
          "Jia Li"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2022/papers/Xie_Pyramid_Grafting_Network_for_One-Stage_High_Resolution_Saliency_Detection_CVPR_2022_paper.pdf",
        "ref_texts": ""
      },
      "Highly accurate dichotomous image segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2203.03041",
        "ref_texts": ""
      },
      "EDN: Salient object detection via extremely-downsampled network": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2012.13093",
        "ref_texts": ""
      },
      "A weakly supervised learning framework for salient object detection via hybrid labels": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2209.02957",
        "ref_texts": ""
      },
      "Unsupervised salient object detection with spectral cluster voting": {
        "authors": [
          "Gyungin Shin",
          "Samuel Albanie",
          "Weidi Xie"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2022W/L3D-IVU/papers/Shin_Unsupervised_Salient_Object_Detection_With_Spectral_Cluster_Voting_CVPRW_2022_paper.pdf",
        "ref_texts": ""
      },
      "Selfreformer: Self-refined network with transformer for salient object detection": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2205.11283",
        "ref_texts": ""
      },
      "Multi-source uncertainty mining for deep unsupervised saliency detection": {
        "authors": [
          "Yifan Wang",
          "Wenbo Zhang",
          "Lijun Wang",
          "Ting Liu",
          "Huchuan Lu"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Multi-Source_Uncertainty_Mining_for_Deep_Unsupervised_Saliency_Detection_CVPR_2022_paper.pdf",
        "ref_texts": ""
      },
      "Recursive contour-saliency blending network for accurate salient object detection": {
        "authors": [
          "Yun Yi",
          "Takahiro Tsubono"
        ],
        "url": "https://openaccess.thecvf.com/content/WACV2022/papers/Ke_Recursive_Contour-Saliency_Blending_Network_for_Accurate_Salient_Object_Detection_WACV_2022_paper.pdf",
        "ref_texts": ""
      },
      "Disentangled capsule routing for fast part-object relational saliency": {
        "authors": [],
        "url": "https://pure.aber.ac.uk/portal/files/56167938/Disentangled_Capsule_Routing_for_Fast_Part_Object.pdf",
        "ref_texts": ""
      },
      "Salient object detection via dynamic scale routing": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2210.13821",
        "ref_texts": ""
      },
      "Densely nested top-down flows for salient object detection": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2102.09133",
        "ref_texts": ""
      },
      "Move: Unsupervised movable object segmentation and detection": {
        "authors": [],
        "url": "https://proceedings.neurips.cc/paper_files/paper/2022/file/d7eb232f196124894f2e65b9010a5c57-Paper-Conference.pdf",
        "ref_texts": ""
      },
      "Self-supervised transformers for unsupervised object discovery using normalized cut": {
        "authors": [
          "Yangtao Wang",
          "Xi Shen",
          "Shell Xu",
          "Yuan Yuan",
          "James L. Crowley",
          "Dominique Vaufreydaz"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Self-Supervised_Transformers_for_Unsupervised_Object_Discovery_Using_Normalized_Cut_CVPR_2022_paper.pdf",
        "ref_texts": ""
      },
      "Salient objects in clutter": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2105.03053",
        "ref_texts": ""
      },
      "Synthetic data supervised salient object detection": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2210.13835",
        "ref_texts": ""
      },
      "Large-field contextual feature learning for glass detection": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2209.04639",
        "ref_texts": ""
      },
      "Semi-supervised video salient object detection based on uncertainty-guided pseudo labels": {
        "authors": [],
        "url": "https://proceedings.neurips.cc/paper_files/paper/2022/file/24f7b98aef14fcd68acf3c941af1b59e-Paper-Conference.pdf",
        "ref_texts": ""
      },
      "A2SPPNet: Attentive atrous spatial pyramid pooling network for salient object detection": {
        "authors": [],
        "url": "https://yun-liu.github.io/papers/(TMM'2022)A2SPPNet%20-%20Attentive%20Atrous%20Spatial%20Pyramid%20Pooling%20Network%20for%20Salient%20Object%20Detection.pdf",
        "ref_texts": ""
      },
      "Pyramidal attention for saliency detection": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2204.06788",
        "ref_texts": ""
      },
      "TF-SOD: a novel transformer framework for salient object detection": {
        "authors": [],
        "url": "https://pure.ulster.ac.uk/files/99735269/TF_SOD_A_Novel_Transformer_Framework_for_Salient_Object_Detection_4_Ulster.pdf",
        "ref_texts": ""
      },
      "Joint learning of salient object detection, depth estimation and contour extraction": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2203.04895",
        "ref_texts": ""
      },
      "SiaTrans: Siamese transformer network for RGB-D salient object detection with depth image classification": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2207.04224",
        "ref_texts": ""
      },
      "View-Aware Salient Object Detection for  Omnidirectional Image": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2209.13222",
        "ref_texts": ""
      },
      "Visual saliency detection via combining center prior and U-Net": {
        "authors": [],
        "url": "https://researchportal.port.ac.uk/files/52837050/Visual_saliency_detection_via_combining_center_prior_and_U_net_pp.pdf",
        "ref_texts": ""
      },
      "Saliency hierarchy modeling via generative kernels for salient object detection": {
        "authors": [],
        "url": "https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136880564.pdf",
        "ref_texts": ""
      },
      "Multilayer graph spectral analysis for hyperspectral images": {
        "authors": [
          "Songyang Zhang"
        ],
        "url": "https://link.springer.com/content/pdf/10.1186/s13634-022-00926-8.pdf",
        "ref_texts": ""
      },
      "LC3Net: Ladder context correlation complementary network for salient object detection": {
        "authors": [
          "Xian Fang",
          "Jinchao Zhu",
          "Xiuli Shao",
          "Hongpeng Wang"
        ],
        "url": "https://arxiv.org/pdf/2110.10869",
        "ref_texts": ""
      },
      "DFTR: Depth-supervised fusion transformer for salient object detection": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2203.06429",
        "ref_texts": ""
      },
      "Learning co-segmentation by segment swapping for retrieval and discovery": {
        "authors": [
          "Xi Shen",
          "Alexei A. Efros",
          "Armand Joulin",
          "Mathieu Aubry"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2022W/IMW/papers/Shen_Learning_Co-Segmentation_by_Segment_Swapping_for_Retrieval_and_Discovery_CVPRW_2022_paper.pdf",
        "ref_texts": ""
      },
      "Complementary characteristics fusion network for weakly supervised salient object detection": {
        "authors": [],
        "url": "https://pure.ulster.ac.uk/files/107378215/paper.pdf",
        "ref_texts": ""
      },
      "AWANet: Attentive-aware wide-kernels asymmetrical network with blended contour information for salient object detection": {
        "authors": [
          "Firstname Lastname",
          "Firstname Lastname",
          "Firstname Lastname"
        ],
        "url": "https://www.mdpi.com/1424-8220/22/24/9667/pdf",
        "ref_texts": ""
      },
      "Deep multi-scale feature learning for defocus blur estimation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2009.11939",
        "ref_texts": ""
      },
      "An attention nested u-structure suitable for salient ship detection in complex maritime environment": {
        "authors": [],
        "url": "https://www.jstage.jst.go.jp/article/transinf/E105.D/6/E105.D_2021EDP7181/_pdf",
        "ref_texts": ""
      },
      "Recursive multi-model complementary deep fusion for robust salient object detection via parallel sub-networks": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2008.04158",
        "ref_texts": ""
      },
      "Substantial phase exploration for intuiting COVID using form expedient with variance sensor": {
        "authors": [],
        "url": "https://www.univagora.ro/jour/index.php/ijccc/article/download/4539/1810",
        "ref_texts": ""
      },
      "Target detection and segmentation in circular-scan synthetic aperture sonar images using semisupervised convolutional encoder\u2013decoders": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2101.03603",
        "ref_texts": ""
      },
      "Performance evaluation of salient object detection techniques": {
        "authors": [
          "Kareem Ahmed"
        ],
        "url": "https://link.springer.com/content/pdf/10.1007/s11042-022-12567-y.pdf",
        "ref_texts": ""
      },
      "Towards complex backgrounds: A unified difference-aware decoder for binary segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2210.15156",
        "ref_texts": ""
      },
      "Salient object detection by ltp texture characterization on opposing color pairs under slico superpixel constraint": {
        "authors": [
          "Didier Ndayikengurukiye",
          "Max Mignotte"
        ],
        "url": "https://www.mdpi.com/2313-433X/8/4/110/pdf",
        "ref_texts": ""
      },
      "Ps-net: progressive selection network for salient object detection": {
        "authors": [
          "George Bray"
        ],
        "url": "https://rgu-repository.worktribe.com/preview/1694900/REN%202022%20PS-net%20%28AAM%29.pdf",
        "ref_texts": ""
      },
      "GSCINet: Gradual shrinkage and cyclic interaction network for salient object detection": {
        "authors": [
          "Yanguang Sun",
          "Xiuju Gao",
          "Chenxing Xia",
          "Bin Ge",
          "Songsong Duan"
        ],
        "url": "https://www.mdpi.com/2079-9292/11/13/1964/pdf",
        "ref_texts": ""
      },
      "Multiscale cascaded attention network for saliency detection based on resnet": {
        "authors": [
          "Muwei Jian",
          "Haodong Jin",
          "Xiangyu Liu",
          "Linsong Zhang"
        ],
        "url": "https://www.mdpi.com/1424-8220/22/24/9950/pdf",
        "ref_texts": ""
      },
      "Sparse non-local CRF": {
        "authors": [
          "Olga Veksler",
          "Yuri Boykov"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2022/papers/Veksler_Sparse_Non-Local_CRF_CVPR_2022_paper.pdf",
        "ref_texts": ""
      },
      "Learning video salient object detection progressively from unlabeled videos": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2204.02008",
        "ref_texts": ""
      },
      "Perception-and-Regulation Network for Salient Object Detection": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2107.12560",
        "ref_texts": ""
      },
      "Saliency detection via global context enhanced feature fusion and edge weighted loss": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2110.06550",
        "ref_texts": ""
      },
      "Feature Refine Network for Salient Object Detection": {
        "authors": [
          "Jiejun Yang",
          "Liejun Wang",
          "Yongming Li"
        ],
        "url": "https://www.mdpi.com/1424-8220/22/12/4490/pdf",
        "ref_texts": ""
      },
      "Multiscale Balanced-Attention Interactive Network for Salient Object Detection": {
        "authors": [
          "Haiyan Yang",
          "Rui Chen",
          "Dexiang Deng"
        ],
        "url": "https://www.mdpi.com/2227-7390/10/3/512/pdf",
        "ref_texts": ""
      },
      "Semantic distillation guided salient object detection": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2203.04076",
        "ref_texts": ""
      },
      "Robust Saliency Guidance for Data-free Class Incremental Learning": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2212.08251",
        "ref_texts": ""
      },
      "Complementary Segmentation of Primary Video Objects with Reversible Flows": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1811.09521",
        "ref_texts": ""
      },
      "Salient object detection via bounding-box supervision": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2205.05245",
        "ref_texts": ""
      },
      "Image Retrieval Based on the Weighted and Regional Integration of CNN Features": {
        "authors": [],
        "url": "https://koreascience.kr/article/JAKO202211563857035.pdf",
        "ref_texts": ""
      },
      "PAANet: Visual Perception based Four-stage Framework for Salient Object Detection using High-order Contrast Operator": {
        "authors": [
          "Yanbo Yuan",
          "Hua Zhong",
          "Haixiong Li",
          "Xiao Cheng",
          "Linmei Xia"
        ],
        "url": "https://arxiv.org/pdf/2211.08724",
        "ref_texts": ""
      },
      "Local and Global Feature Aggregation-Aware Network for Salient Object Detection": {
        "authors": [
          "Firstname Lastname",
          "Firstname Lastname",
          "Firstname Lastname",
          "Firstname Lastname",
          "Firstname Lastname"
        ],
        "url": "https://www.mdpi.com/2079-9292/11/2/231/pdf",
        "ref_texts": ""
      },
      "Multistep feature aggregation framework for salient object detection": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2211.06697",
        "ref_texts": ""
      },
      "Video Saliency Detection by using an Enhance Methodology Involving a Combination of 3DCNN with Histograms": {
        "authors": [],
        "url": "https://univagora.ro/jour/index.php/ijccc/article/download/4299/1793",
        "ref_texts": ""
      },
      "Progressive Hologram Generation Based on Object Saliency": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2211.09938",
        "ref_texts": ""
      },
      "A General Divergence Modeling Strategy for Salient Object Detection": {
        "authors": [
          "Xinyu Tian",
          "Jing Zhang",
          "Yuchao Dai"
        ],
        "url": "https://openaccess.thecvf.com/content/ACCV2022/papers/Tian_A_General_Divergence_Modeling_Strategy_for_Salient_Object_Detection_ACCV_2022_paper.pdf",
        "ref_texts": ""
      },
      "MEAN: Multi-Edge Adaptation Network for Salient Object Detection Refinement": {
        "authors": [
          "Ming Guo",
          "Herleeyandi Markoni"
        ],
        "url": "https://www.mdpi.com/2079-9292/11/12/1855/pdf",
        "ref_texts": ""
      },
      "ImageSubject: A Large-scale Dataset for Subject Detection": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2201.03101",
        "ref_texts": ""
      },
      "Salient object detection and segmentation in video surveillance": {
        "authors": [],
        "url": "https://livrepository.liverpool.ac.uk/3164778/1/Siyue%20Yu_201113751.pdf",
        "ref_texts": ""
      },
      "Dual-Branch Feature Fusion Network for Salient Object Detection": {
        "authors": [
          "Zhehan Song",
          "Zhihai Xu",
          "Jing Wang",
          "Huajun Feng",
          "Qi Li"
        ],
        "url": "https://www.mdpi.com/2304-6732/9/1/44/pdf",
        "ref_texts": ""
      },
      "Salient Object Segmentation in 360\u00b0 images/videos and light field": {
        "authors": [],
        "url": "https://theses.hal.science/tel-04529731/document",
        "ref_texts": ""
      },
      "A Multi-task Model to Detect Saliency and Edge using Hybrid Cost Function": {
        "authors": [],
        "url": "https://modelling.semnan.ac.ir/article_6978_212904b42f7ad2aaf466db15479729e5.pdf",
        "ref_texts": ""
      },
      "A hierarchy superpixel algorithm dealing with stripe": {
        "authors": [],
        "url": "https://iopscience.iop.org/article/10.1088/1742-6596/2258/1/012015/pdf",
        "ref_texts": ""
      },
      "Understanding, Interpreting and Learning Representations in Deep Neural Networks": {
        "authors": [
          "Md Amirul"
        ],
        "url": "https://rshare.library.torontomu.ca/ndownloader/files/45047560",
        "ref_texts": ""
      },
      "Supplementary Material: Zoom In and Out: A Mixed-scale Triplet Network for Camouflaged Object Detection": {
        "authors": [],
        "url": "http://openaccess.thecvf.com/content/CVPR2022/supplemental/Pang_Zoom_in_and_CVPR_2022_supplemental.pdf",
        "ref_texts": ""
      },
      "Rethinking Saliency in Data-free Class Incremental Learning": {
        "authors": [],
        "url": "https://openreview.net/pdf?id=gc0HvlDPyA",
        "ref_texts": ""
      },
      "Hibrit yapay ar\u0131 kolonisi-ate\u015f b\u00f6ce\u011fi optimizasyon y\u00f6ntemi ile g\u00f6r\u00fcnt\u00fclerde belirginlik tespiti= Saliency detection based on hybrid artif\u0131cial bee colony and firefly \u2026": {
        "authors": [],
        "url": "https://acikerisim.sakarya.edu.tr/bitstream/handle/20.500.12619/98457/T10066.pdf?sequence=1",
        "ref_texts": ""
      },
      "\u57fa\u4e8e\u9c81\u68d2\u80cc\u666f\u4f30\u8ba1\u7684\u8239\u8236\u663e\u8457\u6027\u68c0\u6d4b": {
        "authors": [],
        "url": "https://www.researching.cn/ArticlePdf/m00002/2022/59/8/0810008.pdf",
        "ref_texts": ""
      },
      "RGB-D salient object detection: A survey": {
        "authors": [],
        "url": "https://link.springer.com/content/pdf/10.1007/s41095-020-0199-z.pdf",
        "ref_texts": ""
      },
      "Visual saliency transformer": {
        "authors": [
          "Nian Liu",
          "Ni Zhang",
          "Kaiyuan Wan",
          "Ling Shao",
          "Junwei Han"
        ],
        "url": "http://openaccess.thecvf.com/content/ICCV2021/papers/Liu_Visual_Saliency_Transformer_ICCV_2021_paper.pdf",
        "ref_texts": ""
      },
      "Unsupervised semantic segmentation by contrasting object mask proposals": {
        "authors": [
          "Wouter Van",
          "Simon Vandenhende",
          "Stamatios Georgoulis",
          "Luc Van"
        ],
        "url": "http://openaccess.thecvf.com/content/ICCV2021/papers/Van_Gansbeke_Unsupervised_Semantic_Segmentation_by_Contrasting_Object_Mask_Proposals_ICCV_2021_paper.pdf",
        "ref_texts": ""
      },
      "Uncertainty-aware joint salient object and camouflaged object detection": {
        "authors": [
          "Aixuan Li",
          "Jing Zhang",
          "Yunqiu Lv",
          "Bowen Liu",
          "Tong Zhang",
          "Yuchao Dai"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2021/papers/Li_Uncertainty-Aware_Joint_Salient_Object_and_Camouflaged_Object_Detection_CVPR_2021_paper.pdf",
        "ref_texts": ""
      },
      "Learning generative vision transformer with energy-based latent space for saliency prediction": {
        "authors": [],
        "url": "https://proceedings.neurips.cc/paper/2021/file/8289889263db4a40463e3f358bb7c7a1-Paper.pdf",
        "ref_texts": ""
      },
      "Uncertainty inspired RGB-D saliency detection": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2009.03075",
        "ref_texts": ""
      },
      "Re-thinking co-salient object detection": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2007.03380",
        "ref_texts": ""
      },
      "Boundary-aware segmentation network for mobile and web applications": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2101.04704",
        "ref_texts": ""
      },
      "MFNet: Multi-filter directive network for weakly supervised salient object detection": {
        "authors": [
          "Yongri Piao",
          "Jian Wang",
          "Miao Zhang",
          "Huchuan Lu"
        ],
        "url": "http://openaccess.thecvf.com/content/ICCV2021/papers/Piao_MFNet_Multi-Filter_Directive_Network_for_Weakly_Supervised_Salient_Object_Detection_ICCV_2021_paper.pdf",
        "ref_texts": ""
      },
      "Scene context-aware salient object detection": {
        "authors": [
          "Avishek Siris",
          "Jianbo Jiao",
          "Gary K",
          "Xianghua Xie",
          "Rynson W"
        ],
        "url": "http://openaccess.thecvf.com/content/ICCV2021/papers/Siris_Scene_Context-Aware_Salient_Object_Detection_ICCV_2021_paper.pdf",
        "ref_texts": ""
      },
      "Exploring image enhancement for salient object detection in low light images": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2007.16124",
        "ref_texts": ""
      },
      "RGB-D salient object detection with ubiquitous target awareness": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2109.03425",
        "ref_texts": ""
      },
      "DNA: Deeply supervised nonlinear aggregation for salient object detection": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1903.12476",
        "ref_texts": ""
      },
      "Dystab: Unsupervised object segmentation via dynamic-static bootstrapping": {
        "authors": [
          "Yanchao Yang",
          "Brian Lai",
          "Stefano Soatto"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2021/papers/Yang_DyStaB_Unsupervised_Object_Segmentation_via_Dynamic-Static_Bootstrapping_CVPR_2021_paper.pdf",
        "ref_texts": ""
      },
      "Revise-net: exploiting reverse attention mechanism for salient object detection": {
        "authors": [],
        "url": "https://www.mdpi.com/2072-4292/13/23/4941/pdf",
        "ref_texts": ""
      },
      "Salient object detection with purificatory mechanism and structural similarity loss": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1912.08393",
        "ref_texts": ""
      },
      "DPNet: Detail-preserving network for high quality monocular depth estimation": {
        "authors": [
          "Xinchen Ye"
        ],
        "url": "http://faculty.dlut.edu.cn/_resources/group1/M00/00/60/ynZMg2BRX_2AENZSABA5GmHtCrk104.pdf",
        "ref_texts": ""
      },
      "Cross-layer feature pyramid network for salient object detection": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2002.10864",
        "ref_texts": ""
      },
      "Integrating part-object relationship and contrast for camouflaged object detection": {
        "authors": [],
        "url": "https://research.aber.ac.uk/files/48901103/Manuscript.pdf",
        "ref_texts": ""
      },
      "Object segmentation without labels with large-scale generative models": {
        "authors": [
          "Andrey Voynov",
          "Stanislav Morozov",
          "Artem Babenko"
        ],
        "url": "http://proceedings.mlr.press/v139/voynov21a/voynov21a.pdf",
        "ref_texts": ""
      },
      "Instance-level relative saliency ranking with graph reasoning": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2107.03824",
        "ref_texts": ""
      },
      "Self-generated defocus blur detection via dual adversarial discriminators": {
        "authors": [
          "Wenda Zhao",
          "Cai Shang",
          "Huchuan Lu"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2021/papers/Zhao_Self-Generated_Defocus_Blur_Detection_via_Dual_Adversarial_Discriminators_CVPR_2021_paper.pdf",
        "ref_texts": ""
      },
      "Robust visual saliency optimization based on bidirectional Markov chains": {
        "authors": [],
        "url": "https://dspace.stir.ac.uk/bitstream/1893/31322/1/FnalSubmission.pdf",
        "ref_texts": ""
      },
      "Context-aware saliency detection for image retargeting using convolutional neural networks": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1910.08071",
        "ref_texts": ""
      },
      "Engaging part-whole hierarchies and contrast cues for salient object detection": {
        "authors": [],
        "url": "https://research.aber.ac.uk/files/43387577/TCSVT_06173_2021.R1_Engaging_part_whole_hierarchies_and_contrast_cues_for_salient_object_detection.pdf",
        "ref_texts": ""
      },
      "AWkS: adaptive, weighted k-means-based superpixels for improved saliency detection": {
        "authors": [
          "Ashish Kumar"
        ],
        "url": "https://ntnuopen.ntnu.no/ntnu-xmlui/bitstream/handle/11250/2729156/AWKS.pdf?sequence=1",
        "ref_texts": ""
      },
      "CNN-based RGB-D salient object detection: Learn, select, and fuse": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1909.09309",
        "ref_texts": ""
      },
      "Automatic ladybird beetle detection using deep-learning models": {
        "authors": [],
        "url": "https://journals.plos.org/plosone/article/file?id=10.1371/journal.pone.0253027&type=printable",
        "ref_texts": ""
      },
      "Inas: integral nas for device-aware salient object detection": {
        "authors": [
          "Chao Gu",
          "Hua Gao",
          "Sheng Cao",
          "Peng Du",
          "Ping Lu",
          "Ming Cheng"
        ],
        "url": "http://openaccess.thecvf.com/content/ICCV2021/papers/Gu_iNAS_Integral_NAS_for_Device-Aware_Salient_Object_Detection_ICCV_2021_paper.pdf",
        "ref_texts": ""
      },
      "Contrast-weighted dictionary learning based saliency detection for VHR optical remote sensing images": {
        "authors": [
          "Zhou Huang",
          "Xin Chen",
          "Tao Zhou",
          "Zhi Yang",
          "Yin Wang",
          "Yuan Liu"
        ],
        "url": "https://arxiv.org/pdf/2004.02428",
        "ref_texts": ""
      },
      "Deep RGB-D saliency detection without depth": {
        "authors": [],
        "url": "https://opus.lib.uts.edu.au/bitstream/10453/148403/3/2-s2.0-85101745317%20am.pdf",
        "ref_texts": ""
      },
      "Region-based depth feature descriptor for saliency detection on light field": {
        "authors": [
          "Xue Wang"
        ],
        "url": "https://qzhang-cv.github.io/data/MTA2021.pdf",
        "ref_texts": ""
      },
      "Fast pixel-matching for video object segmentation": {
        "authors": [
          "Siyue Yu",
          "Jimin Xiao",
          "Bingfeng Zhang"
        ],
        "url": "https://arxiv.org/pdf/2107.04279",
        "ref_texts": ""
      },
      "Ranking-based salient object detection and depth prediction for shallow depth-of-field": {
        "authors": [
          "Ke Xian",
          "Juewen Peng",
          "Chao Zhang",
          "Hao Lu",
          "Zhiguo Cao"
        ],
        "url": "https://www.mdpi.com/1424-8220/21/5/1815/pdf",
        "ref_texts": ""
      },
      "Asod60k: An audio-induced salient object detection dataset for panoramic videos": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2107.11629",
        "ref_texts": ""
      },
      "Learning background invariance improves generalization and robustness in self-supervised learning on imagenet and beyond": {
        "authors": [],
        "url": "https://openreview.net/pdf?id=zZnOG9ehfoO",
        "ref_texts": ""
      },
      "3MNet: Multi-task, multi-level and multi-channel feature aggregation network for salient object detection": {
        "authors": [
          "Xinghe Yan"
        ],
        "url": "https://link.springer.com/content/pdf/10.1007/s00138-021-01172-y.pdf",
        "ref_texts": ""
      },
      "To be critical: Self-calibrated weakly supervised learning for salient object detection": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2109.01770",
        "ref_texts": ""
      },
      "Unsupervised learning for salient object detection via minimization of bilinear factor matrix norm": {
        "authors": [
          "Min Li",
          "Yao Zhang",
          "Mingqing Xiao",
          "Weiqiang Zhang",
          "Xiaoli Sun"
        ],
        "url": "https://zhims.github.io/doc/jour/21TNNLS.pdf",
        "ref_texts": ""
      },
      "Cascaded hourglass feature fusing network for saliency detection": {
        "authors": [
          "Huiyuan Luo"
        ],
        "url": "http://ir.ciomp.ac.cn/bitstream/181722/65085/1/Cascaded%20hourglass%20feature%20fusing%20network%20for.pdf",
        "ref_texts": ""
      },
      "Different application areas of object detection with deep learning": {
        "authors": [],
        "url": "https://dergipark.org.tr/en/download/article-file/1842634",
        "ref_texts": ""
      },
      "Characterizing and improving the robustness of self-supervised learning through background augmentations": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2103.12719",
        "ref_texts": ""
      },
      "DSFMA: Deeply supervised fully convolutional neural networks based on multi-level aggregation for saliency detection": {
        "authors": [],
        "url": "https://researchportal.port.ac.uk/files/23306137/DSFMA_Deeply_supervised_fully_convolutional_neural_networks_pp.pdf",
        "ref_texts": ""
      },
      "DSAL-GAN: Denoising based saliency prediction with generative adversarial networks": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1904.01215",
        "ref_texts": ""
      },
      "Semi-supervised salient object detection with effective confidence estimation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2112.14019",
        "ref_texts": ""
      },
      "Local-binarized very deep residual network for visual categorization": {
        "authors": [
          "Xuejing Liu"
        ],
        "url": "https://vipl.ict.ac.cn/en/research/media/jour/202211/W020221102588812359569.pdf",
        "ref_texts": ""
      },
      "Heterogeneous grid convolution for adaptive, efficient, and controllable computation": {
        "authors": [
          "Ryuhei Hamaguchi",
          "Yasutaka Furukawa",
          "Masaki Onishi",
          "Ken Sakurada"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2021/papers/Hamaguchi_Heterogeneous_Grid_Convolution_for_Adaptive_Efficient_and_Controllable_Computation_CVPR_2021_paper.pdf",
        "ref_texts": ""
      },
      "A deep attention mechanism method for maritime salient ship detection in complex sea background": {
        "authors": [],
        "url": "https://www.researching.cn/ArticlePdf/m00050/2021/17/7/OEL-2021-07-0438.pdf",
        "ref_texts": ""
      },
      "LF3Net: Leader-follower feature fusing network for fast saliency detection": {
        "authors": [
          "Huiyuan Luo"
        ],
        "url": "http://ir.ciomp.ac.cn/bitstream/181722/65376/1/LF3Net_%20Leader-follower%20feature%20fusing%20network.pdf",
        "ref_texts": ""
      },
      "Deep green function convolution for improving saliency in convolutional neural networks": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1908.08331",
        "ref_texts": ""
      },
      "Eight-channel multispectral image database for saliency prediction": {
        "authors": [],
        "url": "https://www.mdpi.com/1424-8220/21/3/970/pdf",
        "ref_texts": ""
      },
      "CNet: Contextual Compression and Complementary Combination Network for Salient Object Detection": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2110.11887",
        "ref_texts": ""
      },
      "Hyperspectral image segmentation based on graph processing over multilayer networks": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2111.15018",
        "ref_texts": ""
      },
      "Receptive field broadening and boosting for salient object detection": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2110.07859",
        "ref_texts": ""
      },
      "A multi-cues based approach for visual saliency detection": {
        "authors": [],
        "url": "http://www.ijicic.org/ijicic-170421.pdf",
        "ref_texts": ""
      },
      "Class-agnostic segmentation loss and its application to salient object detection and segmentation": {
        "authors": [
          "Angira Sharma",
          "Naeemullah Khan",
          "Muhammad Mubashar",
          "Ganesh Sundaramoorthi",
          "Philip Torr"
        ],
        "url": "https://openaccess.thecvf.com/content/ICCV2021W/ILDAV/papers/Sharma_Class-Agnostic_Segmentation_Loss_and_Its_Application_to_Salient_Object_Detection_ICCVW_2021_paper.pdf",
        "ref_texts": ""
      },
      "Exploring driving-aware salient object detection via knowledge transfer": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2105.08286",
        "ref_texts": ""
      },
      "Residential Tenants Classification: A Test of Performance of Five Selected Artificial Neural Networks training Algorithms": {
        "authors": [],
        "url": "https://ijojournals.com/index.php/bm/article/download/461/223",
        "ref_texts": ""
      },
      "a novel attention-based network for fast salient object detection": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2112.10481",
        "ref_texts": ""
      },
      "Weakly supervised salient object detection based on image semantics": {
        "authors": [],
        "url": "https://www.jcad.cn/en/article/pdf/preview/10.3724/SP.J.1089.2021.18318.pdf",
        "ref_texts": ""
      },
      "Recursive contour saliency blending network for accurate salient object detection": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2105.13865",
        "ref_texts": ""
      },
      "Saliency detection via manifold ranking based on robust foreground": {
        "authors": [],
        "url": "https://www.mi-research.net/en/article/pdf/preview/10.1007/s11633-020-1246-z.pdf",
        "ref_texts": ""
      },
      "Real-time saliency detection for greyscale and colour images": {
        "authors": [
          "Feng Shi"
        ],
        "url": "http://www.carleton.ca/spacecraft/wp-content/uploads/TVC-2021.pdf",
        "ref_texts": ""
      },
      "External-Memory Networks for Low-Shot Learning of Targets in Forward-Looking-Sonar Imagery": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2107.10504",
        "ref_texts": ""
      },
      "Activation to Saliency: Forming High-Quality Labels for Completely Unsupervised Salient Object Detection": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2112.03650",
        "ref_texts": ""
      },
      "Fixation guided network for salient object detection": {
        "authors": [
          "Zhe Cui",
          "Li Su",
          "Weigang Zhang",
          "Qingming Huang"
        ],
        "url": "https://dl.acm.org/doi/pdf/10.1145/3444685.3446288",
        "ref_texts": ""
      },
      "An algorithm of object detection based on regression learning for remote sensing images": {
        "authors": [],
        "url": "https://iopscience.iop.org/article/10.1088/1742-6596/1903/1/012039/pdf",
        "ref_texts": ""
      },
      "Image saliency detection via two-stream feature fusion and adversarial learning": {
        "authors": [],
        "url": "https://www.jcad.cn/en/article/pdf/preview/10.3724/SP.J.1089.2021.18438.pdf",
        "ref_texts": ""
      },
      "Salient Object Detection on Matrix Disintegration using Convolutional Neural Network": {
        "authors": [
          "Scopus Journal",
          "C Journal"
        ],
        "url": "https://www.ijvlsi.latticescipub.com/wp-content/uploads/papers/v1i1/A1003031121.pdf",
        "ref_texts": ""
      },
      "Weakly-supervised Semantic Segmentation with Regularized Loss Hyperparameter Search": {
        "authors": [
          "Zongliang Ji"
        ],
        "url": "https://uwspace.uwaterloo.ca/bitstream/handle/10012/17430/Ji_Zongliang.pdf?sequence=3",
        "ref_texts": ""
      },
      "Accelerated computational methods in image processing using gpu computing: variational saliency detection and mri-ct synthesis": {
        "authors": [],
        "url": "https://burjcdigital.urjc.es/bitstream/handle/10115/18276/Thesis_Eduardo_Alcain_Ballesteros_2021.pdf?sequence=2&isAllowed=y",
        "ref_texts": ""
      },
      "Uncertainty-aware Salient Object Detection": {
        "authors": [
          "Xi Yang"
        ],
        "url": "https://openresearch-repository.anu.edu.au/bitstream/1885/250427/1/PhD_Thesis_Jing_revision.pdf",
        "ref_texts": ""
      },
      "\u7ed3\u5408\u53cc\u6d41\u7279\u5f81\u878d\u5408\u53ca\u5bf9\u6297\u5b66\u4e60\u7684\u56fe\u50cf\u663e\u8457\u6027\u68c0\u6d4b": {
        "authors": [],
        "url": "https://www.jcad.cn/cn/article/pdf/preview/10.3724/SP.J.1089.2021.18438.pdf",
        "ref_texts": ""
      },
      "SHD360: A Benchmark Dataset for Salient Human Detection in 360 {\\deg} Videos": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2105.11578",
        "ref_texts": ""
      },
      "Hierarchical Image Peeling: A Flexible Scale-space Filtering Framework": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2104.01534",
        "ref_texts": ""
      },
      "Saliency-based Trimap Generation for Image Matting": {
        "authors": [],
        "url": "https://tsukuba.repo.nii.ac.jp/record/2001802/files/M044951.pdf",
        "ref_texts": ""
      },
      "Shape-Tailored Deep Neural Networks": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2102.08497",
        "ref_texts": ""
      },
      "Monocular visual scene analysis: saliency detection and 3D face reconstruction using GAN.": {
        "authors": [],
        "url": "https://pure.port.ac.uk/ws/portalfiles/portal/94529641/Thesis_Xiaoxu_Cai_UP836242_.pdf",
        "ref_texts": ""
      },
      "\u57fa\u4e8e\u56fe\u50cf\u8bed\u4e49\u7684\u5f31\u76d1\u7763\u663e\u8457\u6027\u7269\u4f53\u68c0\u6d4b": {
        "authors": [],
        "url": "https://www.jcad.cn/cn/article/pdf/preview/10.3724/SP.J.1089.2021.18318.pdf",
        "ref_texts": ""
      },
      "Visual saliency computation and quality evaluation via deep learning": {
        "authors": [],
        "url": "https://dr.ntu.edu.sg/bitstream/10356/145826/2/ysthesis-20210110.pdf",
        "ref_texts": ""
      },
      "Defining and Assessing a Novel Spatio-Chromatic Basis for Unsupervised, Class-Agnostic Scene Segmentation": {
        "authors": [
          "Terry Hodgson"
        ],
        "url": "https://uh-ir.tdl.org/bitstream/handle/10657/9325/HODGSON-THESIS-2021.pdf?sequence=1&isAllowed=n",
        "ref_texts": ""
      },
      "\u57fa\u4e8e\u6700\u5c0f\u4f4d\u79fb\u53ef\u89c6\u5dee\u7684\u8fde\u7eed Seam Carving \u7b97\u6cd5\u5728\u56fe\u50cf\u7f29\u653e\u4e2d\u7684\u7814\u7a76": {
        "authors": [],
        "url": "https://jeit.ac.cn/article/exportPdf?id=8446c219-60d6-46d2-bac0-8b53561a2070",
        "ref_texts": ""
      },
      "D\u00e9tection d'objets saillants sur les images naturelles par filtrage p-Laplacien.": {
        "authors": [],
        "url": "http://dspace.univ-jijel.dz:8080/xmlui/bitstream/handle/123456789/10763/M-ELE.SY.EM-2021-09.pdf?sequence=1&isAllowed=y",
        "ref_texts": ""
      },
      "\u57fa\u4e8e\u591a\u8def\u5f84\u9012\u5f52\u589e\u5f3a\u7684\u663e\u8457\u6027\u76ee\u6807\u68c0\u6d4b\u65b9\u6cd5": {
        "authors": [],
        "url": "http://ir.ciomp.ac.cn/bitstream/181722/66025/1/%E5%9F%BA%E4%BA%8E%E5%A4%9A%E8%B7%AF%E5%BE%84%E9%80%92%E5%BD%92%E5%A2%9E%E5%BC%BA%E7%9A%84%E6%98%BE%E8%91%97%E6%80%A7%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E6%96%B9%E6%B3%95.pdf",
        "ref_texts": ""
      },
      "\u57fa\u4e8e\u533a\u57df\u5bf9\u6bd4\u4fe1\u606f\u6df7\u5408\u7f16\u7801\u7684\u56fe\u50cf\u663e\u8457\u6027\u68c0\u6d4b\u65b9\u6cd5": {
        "authors": [],
        "url": "http://www.shcas.net/jsjyup/pdf/2021/4/%E5%9F%BA%E4%BA%8E%E5%8C%BA%E5%9F%9F%E5%AF%B9%E6%AF%94%E4%BF%A1%E6%81%AF%E6%B7%B7%E5%90%88%E7%BC%96%E7%A0%81%E7%9A%84%E5%9B%BE%E5%83%8F%E6%98%BE%E8%91%97%E6%80%A7%E6%A3%80%E6%B5%8B%E6%96%B9%E6%B3%95.pdf",
        "ref_texts": ""
      },
      "Salient object detection: A survey": {
        "authors": [],
        "url": "https://link.springer.com/content/pdf/10.1007/s41095-019-0149-9.pdf",
        "ref_texts": ""
      },
      "Res2net: A new multi-scale backbone architecture": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1904.01169",
        "ref_texts": ""
      },
      "Basnet: Boundary-aware salient object detection": {
        "authors": [
          "Xuebin Qin",
          "Zichen Zhang",
          "Chenyang Huang",
          "Chao Gao",
          "Masood Dehghan",
          "Martin Jagersand"
        ],
        "url": "https://openaccess.thecvf.com/content_CVPR_2019/papers/Qin_BASNet_Boundary-Aware_Salient_Object_Detection_CVPR_2019_paper.pdf",
        "ref_texts": ""
      },
      "EGNet: Edge guidance network for salient object detection": {
        "authors": [
          "Xing Zhao",
          "Jiang Liu",
          "Ping Fan",
          "Yang Cao",
          "Jufeng Yang",
          "Ming Cheng"
        ],
        "url": "https://openaccess.thecvf.com/content_ICCV_2019/papers/Zhao_EGNet_Edge_Guidance_Network_for_Salient_Object_Detection_ICCV_2019_paper.pdf",
        "ref_texts": ""
      },
      "A simple pooling-based design for real-time salient object detection": {
        "authors": [
          "Jiang Liu",
          "Qibin Hou",
          "Ming Cheng",
          "Jiashi Feng",
          "Jianmin Jiang"
        ],
        "url": "https://openaccess.thecvf.com/content_CVPR_2019/papers/Liu_A_Simple_Pooling-Based_Design_for_Real-Time_Salient_Object_Detection_CVPR_2019_paper.pdf",
        "ref_texts": ""
      },
      "Cascaded partial decoder for fast and accurate salient object detection": {
        "authors": [
          "Zhe Wu",
          "Li Su",
          "Qingming Huang"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPR_2019/papers/Wu_Cascaded_Partial_Decoder_for_Fast_and_Accurate_Salient_Object_Detection_CVPR_2019_paper.pdf",
        "ref_texts": ""
      },
      "Pyramid feature attention network for saliency detection": {
        "authors": [
          "Ting Zhao",
          "Xiangqian Wu"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPR_2019/papers/Zhao_Pyramid_Feature_Attention_Network_for_Saliency_Detection_CVPR_2019_paper.pdf",
        "ref_texts": ""
      },
      "Stacked cross refinement network for edge-aware salient object detection": {
        "authors": [
          "Zhe Wu",
          "Li Su",
          "Qingming Huang"
        ],
        "url": "http://openaccess.thecvf.com/content_ICCV_2019/papers/Wu_Stacked_Cross_Refinement_Network_for_Edge-Aware_Salient_Object_Detection_ICCV_2019_paper.pdf",
        "ref_texts": ""
      },
      "Salient object detection with pyramid attention and salient edges": {
        "authors": [
          "Wenguan Wang",
          "Shuyang Zhao",
          "Jianbing Shen",
          "Steven C. H",
          "Ali Borji"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPR_2019/papers/Wang_Salient_Object_Detection_With_Pyramid_Attention_and_Salient_Edges_CVPR_2019_paper.pdf",
        "ref_texts": ""
      },
      "Attentive feedback network for boundary-aware salient object detection": {
        "authors": [
          "Mengyang Feng",
          "Huchuan Lu",
          "Errui Ding"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPR_2019/papers/Feng_Attentive_Feedback_Network_for_Boundary-Aware_Salient_Object_Detection_CVPR_2019_paper.pdf",
        "ref_texts": ""
      },
      "Ranet: Ranking attention network for fast video object segmentation": {
        "authors": [
          "Ziqin Wang",
          "Jun Xu",
          "Li Liu",
          "Fan Zhu",
          "Ling Shao"
        ],
        "url": "https://openaccess.thecvf.com/content_ICCV_2019/papers/Wang_RANet_Ranking_Attention_Network_for_Fast_Video_Object_Segmentation_ICCV_2019_paper.pdf",
        "ref_texts": ""
      },
      "A mutual learning method for salient object detection with intertwined multi-supervision": {
        "authors": [
          "Runmin Wu",
          "Mengyang Feng",
          "Wenlong Guan",
          "Dong Wang",
          "Huchuan Lu",
          "Errui Ding"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPR_2019/papers/Wu_A_Mutual_Learning_Method_for_Salient_Object_Detection_With_Intertwined_CVPR_2019_paper.pdf",
        "ref_texts": ""
      },
      "Towards high-resolution salient object detection": {
        "authors": [
          "Yi Zeng",
          "Pingping Zhang",
          "Jianming Zhang",
          "Zhe Lin",
          "Huchuan Lu"
        ],
        "url": "https://openaccess.thecvf.com/content_ICCV_2019/papers/Zeng_Towards_High-Resolution_Salient_Object_Detection_ICCV_2019_paper.pdf",
        "ref_texts": ""
      },
      "Joint learning of saliency detection and weakly supervised semantic segmentation": {
        "authors": [
          "Yu Zeng",
          "Yunzhi Zhuge",
          "Huchuan Lu",
          "Lihe Zhang"
        ],
        "url": "http://openaccess.thecvf.com/content_ICCV_2019/papers/Zeng_Joint_Learning_of_Saliency_Detection_and_Weakly_Supervised_Semantic_Segmentation_ICCV_2019_paper.pdf",
        "ref_texts": ""
      },
      "An iterative and cooperative top-down and bottom-up inference network for salient object detection": {
        "authors": [
          "Wenguan Wang",
          "Jianbing Shen",
          "Ming Cheng",
          "Ling Shao"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPR_2019/papers/Wang_An_Iterative_and_Cooperative_Top-Down_and_Bottom-Up_Inference_Network_for_CVPR_2019_paper.pdf",
        "ref_texts": ""
      },
      "Interactive image segmentation via backpropagating refinement scheme": {
        "authors": [
          "Dong Jang",
          "Su Kim"
        ],
        "url": "https://openaccess.thecvf.com/content_CVPR_2019/papers/Jang_Interactive_Image_Segmentation_via_Backpropagating_Refinement_Scheme_CVPR_2019_paper.pdf",
        "ref_texts": ""
      },
      "Selectivity or invariance: Boundary-aware salient object detection": {
        "authors": [
          "Jinming Su",
          "Jia Li",
          "Yu Zhang",
          "Changqun Xia",
          "Yonghong Tian"
        ],
        "url": "http://openaccess.thecvf.com/content_ICCV_2019/papers/Su_Selectivity_or_Invariance_Boundary-Aware_Salient_Object_Detection_ICCV_2019_paper.pdf",
        "ref_texts": ""
      },
      "Multi-source weak supervision for saliency detection": {
        "authors": [
          "Yu Zeng",
          "Yunzhi Zhuge",
          "Huchuan Lu",
          "Lihe Zhang",
          "Mingyang Qian",
          "Yizhou Yu"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPR_2019/papers/Zeng_Multi-Source_Weak_Supervision_for_Saliency_Detection_CVPR_2019_paper.pdf",
        "ref_texts": ""
      },
      "Deepusps: Deep robust unsupervised saliency prediction via self-supervision": {
        "authors": [
          "Tam Nguyen",
          "Maximilian Dax",
          "Chaithanya Kumar",
          "Nhung Ngo",
          "Thi Hoai",
          "Phuong Nguyen",
          "Zhongyu Lou",
          "Thomas Brox"
        ],
        "url": "https://proceedings.neurips.cc/paper/2019/file/54229abfcfa5649e7003b83dd4755294-Paper.pdf",
        "ref_texts": ""
      },
      "RGB-T image saliency detection via collaborative graph learning": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1905.06741",
        "ref_texts": ""
      },
      "A dilated inception network for visual saliency prediction": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1904.03571",
        "ref_texts": ""
      },
      "Employing deep part-object relationships for salient object detection": {
        "authors": [
          "Yi Liu",
          "Qiang Zhang",
          "Dingwen Zhang",
          "Jungong Han"
        ],
        "url": "https://openaccess.thecvf.com/content_ICCV_2019/papers/Liu_Employing_Deep_Part-Object_Relationships_for_Salient_Object_Detection_ICCV_2019_paper.pdf",
        "ref_texts": ""
      },
      "SaliencyGAN: Deep learning semisupervised salient object detection in the fog of IoT": {
        "authors": [],
        "url": "https://repository.essex.ac.uk/28150/1/ALL_TII-19-2654.pdf",
        "ref_texts": ""
      },
      "Capsal: Leveraging captioning to boost semantics for salient object detection": {
        "authors": [
          "Lu Zhang",
          "Jianming Zhang",
          "Zhe Lin",
          "Huchuan Lu",
          "You He"
        ],
        "url": "https://openaccess.thecvf.com/content_CVPR_2019/papers/Zhang_CapSal_Leveraging_Captioning_to_Boost_Semantics_for_Salient_Object_Detection_CVPR_2019_paper.pdf",
        "ref_texts": ""
      },
      "Deep salient object detection with contextual information guidance": {
        "authors": [],
        "url": "https://wrap.warwick.ac.uk/123588/1/WRAP-deep-salient-object-detection-contextual-guidance-Han-2019.pdf",
        "ref_texts": ""
      },
      "Learning instance activation maps for weakly supervised instance segmentation": {
        "authors": [
          "Yi Zhu",
          "Yanzhao Zhou",
          "Huijuan Xu",
          "Qixiang Ye",
          "David Doermann",
          "Jianbin Jiao"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPR_2019/papers/Zhu_Learning_Instance_Activation_Maps_for_Weakly_Supervised_Instance_Segmentation_CVPR_2019_paper.pdf",
        "ref_texts": ""
      },
      "Optimizing the F-measure for threshold-free salient object detection": {
        "authors": [
          "Kai Zhao",
          "Shanghua Gao",
          "Wenguan Wang",
          "Ming Cheng"
        ],
        "url": "http://openaccess.thecvf.com/content_ICCV_2019/papers/Zhao_Optimizing_the_F-Measure_for_Threshold-Free_Salient_Object_Detection_ICCV_2019_paper.pdf",
        "ref_texts": ""
      },
      "Structured modeling of joint deep feature and prediction refinement for salient object detection": {
        "authors": [
          "Yingyue Xu",
          "Dan Xu",
          "Xiaopeng Hong",
          "Wanli Ouyang",
          "Rongrong Ji",
          "Min Xu",
          "Guoying Zhao"
        ],
        "url": "http://openaccess.thecvf.com/content_ICCV_2019/papers/Xu_Structured_Modeling_of_Joint_Deep_Feature_and_Prediction_Refinement_for_ICCV_2019_paper.pdf",
        "ref_texts": ""
      },
      "Salient object detection via multiple instance joint re-learning": {
        "authors": [],
        "url": "https://par.nsf.gov/servlets/purl/10297819",
        "ref_texts": ""
      },
      "Unsupervised saliency model with color Markov chain for oil tank detection": {
        "authors": [],
        "url": "https://www.mdpi.com/2072-4292/11/9/1089/pdf",
        "ref_texts": ""
      },
      "Saliency driven image manipulation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1612.02184",
        "ref_texts": ""
      },
      "Distortion-Adaptive Salient Object Detection in 360 Omnidirectional Images": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1909.04913",
        "ref_texts": ""
      },
      "BING: Binarized normed gradients for objectness estimation at 300fps": {
        "authors": [],
        "url": "https://openaccess.thecvf.com/content_cvpr_2014/papers/Cheng_BING_Binarized_Normed_2014_CVPR_paper.pdf",
        "ref_texts": ""
      },
      "Spectral-spatial hyperspectral image classification with superpixel pattern and extreme learning machine": {
        "authors": [],
        "url": "https://www.mdpi.com/2072-4292/11/17/1983/pdf",
        "ref_texts": ""
      },
      "Transformation-aware similarity measurement for image retargeting quality assessment via bidirectional rewarping": {
        "authors": [],
        "url": "https://zhenqifu.github.io/personal_page/TRASIM_2019.pdf",
        "ref_texts": ""
      },
      "Semantic prior analysis for salient object detection": {
        "authors": [],
        "url": "https://livrepository.liverpool.ac.uk/3042544/1/TIP-salient-object-detection-2019.pdf",
        "ref_texts": ""
      },
      "Deep reasoning with multi-scale context for salient object detection": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1901.08362",
        "ref_texts": ""
      },
      "Quality-aware dual-modal saliency detection via deep reinforcement learning": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1811.10763",
        "ref_texts": ""
      },
      "Super diffusion for salient object detection": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1811.09038",
        "ref_texts": ""
      },
      "Se2net: Siamese edge-enhancement network for salient object detection": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1904.00048",
        "ref_texts": ""
      },
      "Relative saliency and ranking: Models, metrics, data and benchmarks": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1810.02426",
        "ref_texts": ""
      },
      "Salient object detection in low contrast images via global convolution and boundary refinement": {
        "authors": [
          "Nan Mu",
          "Xin Xu",
          "Xiaolong Zhang"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPRW_2019/papers/CEFRL/Mu_Salient_Object_Detection_in_Low_Contrast_Images_via_Global_Convolution_CVPRW_2019_paper.pdf",
        "ref_texts": ""
      },
      "Semantic instance meets salient object: Study on video semantic salient instance segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1807.01452",
        "ref_texts": ""
      },
      "Real-time object detection in remote sensing images based on visual perception and memory reasoning": {
        "authors": [],
        "url": "https://www.mdpi.com/2079-9292/8/10/1151/pdf",
        "ref_texts": ""
      },
      "Orthogonal decomposition network for pixel-wise binary classification": {
        "authors": [
          "Chang Liu",
          "Fang Wan",
          "Wei Ke",
          "Zhuowei Xiao",
          "Yuan Yao",
          "Xiaosong Zhang",
          "Qixiang Ye"
        ],
        "url": "https://openaccess.thecvf.com/content_CVPR_2019/papers/Liu_Orthogonal_Decomposition_Network_for_Pixel-Wise_Binary_Classification_CVPR_2019_paper.pdf",
        "ref_texts": ""
      },
      "Salient object detection on hyperspectral images using features learned from unsupervised segmentation task": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1902.10993",
        "ref_texts": ""
      },
      "Accurate salient object detection via dense recurrent connections and residual-based hierarchical feature integration": {
        "authors": [],
        "url": "https://ris.utwente.nl/ws/files/213650639/1_s2.0_S0923596518310750_main.pdf",
        "ref_texts": ""
      },
      "Enhancing Salient Object Segmentation Through Attention.": {
        "authors": [
          "Anuj Pahuja",
          "Avishek Majumder",
          "Anirban Chakraborty",
          "Venkatesh Babu"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPRW_2019/papers/Deep%20Vision%20Workshop/Pahuja_Enhancing_Salient_Object_Segmentation_Through_Attention_CVPRW_2019_paper.pdf",
        "ref_texts": ""
      },
      "Saliency detection based on improved manifold ranking via convex hull": {
        "authors": [],
        "url": "https://www.jcad.cn/en/article/pdf/preview/10.3724/SP.J.1089.2019.17376.pdf",
        "ref_texts": ""
      },
      "Neural odes for image segmentation with level sets": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1912.11683",
        "ref_texts": ""
      },
      "Deep learning architectures for automated image segmentation": {
        "authors": [
          "Debleena Sengupta"
        ],
        "url": "https://arxiv.org/pdf/1909.10333",
        "ref_texts": ""
      },
      "Salient object detection with multiscale context enhanced fully convolutional network": {
        "authors": [],
        "url": "https://www.jcad.cn/en/article/pdf/preview/10.3724/SP.J.1089.2019.17738.pdf",
        "ref_texts": ""
      },
      "Fusi\u00f3n temprana de descriptores extra\u00eddos de mapas de prominencia multi-nivel para clasificar im\u00e1genes": {
        "authors": [],
        "url": "https://riunet.upv.es/bitstream/handle/10251/122352/10640-47078-1-PB.pdf?sequence=4",
        "ref_texts": ""
      },
      "OGNet: Salient object detection with output-guided attention module": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1907.07449",
        "ref_texts": ""
      },
      "Gestalt-grouping based on path analysis for saliency detection": {
        "authors": [],
        "url": "http://dspace.uvic.cat/xmlui/bitstream/handle/10854/7787/artconlli_a2019_dempere_laura_gestalt_grouping.pdf?sequence=1&isAllowed=y",
        "ref_texts": ""
      },
      "Multi information fusion network for saliency quality assessment": {
        "authors": [],
        "url": "https://www.jstage.jst.go.jp/article/transinf/E102.D/5/E102.D_2019EDL8002/_pdf",
        "ref_texts": ""
      },
      "Boundary-aware salient object detection via recurrent two-stream guided refinement network": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1912.05236",
        "ref_texts": ""
      },
      "Spatial-aware global contrast representation for saliency detection": {
        "authors": [
          "N X",
          "G H",
          "N Z"
        ],
        "url": "https://journals.tubitak.gov.tr/cgi/viewcontent.cgi?article=1562&context=elektrik",
        "ref_texts": ""
      },
      "Instance of Interest Detection": {
        "authors": [
          "Fan Yu",
          "Haonan Wang",
          "Tongwei Ren",
          "Jinhui Tang",
          "Gangshan Wu"
        ],
        "url": "https://mcg.nju.edu.cn/publication/2019/multimedia19_yf.pdf",
        "ref_texts": ""
      },
      "\u591a\u5c3a\u5ea6\u4e0a\u4e0b\u6587\u4fe1\u606f\u589e\u5f3a\u7684\u663e\u8457\u76ee\u6807\u68c0\u6d4b\u5168\u5377\u79ef\u7f51\u7edc.": {
        "authors": [],
        "url": "https://www.jcad.cn/cn/article/pdf/preview/10.3724/SP.J.1089.2019.17738.pdf",
        "ref_texts": ""
      },
      "Exploring reciprocal attention for salient object detection by cooperative learning": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1909.08269",
        "ref_texts": ""
      },
      "\u57fa\u4e8e\u591a\u5c3a\u5ea6\u5148\u9a8c\u6df1\u5ea6\u7279\u5f81\u7684\u591a\u76ee\u6807\u663e\u8457\u6027\u68c0\u6d4b\u65b9\u6cd5": {
        "authors": [],
        "url": "http://www.aas.net.cn/fileZDHXB/journal/article/zdhxb/2019/11/PDF/zdhxb-45-11-2058.pdf",
        "ref_texts": ""
      },
      "Salient region detection through salient and non-salient dictionaries": {
        "authors": [
          "Mian Muhammad",
          "Sadiq Fareed",
          "Qi Chun",
          "Gulnaz Ahmed",
          "Adil Murtaza",
          "Muhammad Rizwan",
          "Muhammad Zeeshan"
        ],
        "url": "https://journals.plos.org/plosone/article/file?id=10.1371/journal.pone.0213433&type=printable",
        "ref_texts": ""
      },
      "\u57fa\u4e8e\u51f8\u5305\u6539\u8fdb\u7684\u6d41\u884c\u6392\u5e8f\u663e\u8457\u6027\u68c0\u6d4b": {
        "authors": [],
        "url": "https://www.jcad.cn/cn/article/pdf/preview/10.3724/SP.J.1089.2019.17376.pdf",
        "ref_texts": ""
      },
      "Appearance-Based Salient Regions Detection Using Side-Specific Dictionaries": {
        "authors": [],
        "url": "https://www.mdpi.com/1424-8220/19/2/421/pdf",
        "ref_texts": ""
      },
      "\u57fa\u4e8e\u591a\u56fe\u6d41\u5f62\u6392\u5e8f\u7684\u56fe\u50cf\u663e\u8457\u6027\u68c0\u6d4b": {
        "authors": [],
        "url": "http://www.aas.net.cn/fileZDHXB/journal/article/zdhxb/2019/3/PDF/zdhxb-45-3-577.pdf",
        "ref_texts": ""
      },
      "\u57fa\u4e8e\u80cc\u666f\u8fde\u7eed\u6027\u5148\u9a8c\u77e5\u8bc6\u7684\u663e\u8457\u6027\u68c0\u6d4b": {
        "authors": [],
        "url": "https://www.researching.cn/ArticlePdf/m00002/2019/56/12/121006.pdf",
        "ref_texts": ""
      },
      "Improved salient object detection via boundary components affinity": {
        "authors": [],
        "url": "http://psasir.upm.edu.my/id/eprint/76320/1/17%20JST-1475-2018.pdf",
        "ref_texts": ""
      },
      "Salient Object Detection with CNNs and Multi-scale CRFs": {
        "authors": [],
        "url": "https://oulurepo.oulu.fi/bitstream/handle/10024/28836/nbnfi-fe2020042322153.pdf?sequence=1",
        "ref_texts": ""
      },
      "Homography estimation: From geometry to deep learning": {
        "authors": [],
        "url": "https://eprints.qut.edu.au/134132/1/Rui_Zeng_Thesis.pdf",
        "ref_texts": ""
      },
      "Tensor Decomposition for Salient Object Detection in Images": {
        "authors": [],
        "url": "https://www.mdpi.com/2504-2289/3/2/33/pdf",
        "ref_texts": ""
      },
      "\u53cc\u6ce8\u610f\u529b\u5faa\u73af\u5377\u79ef\u663e\u8457\u6027\u76ee\u6807\u68c0\u6d4b\u7b97\u6cd5": {
        "authors": [],
        "url": "https://www.researching.cn/ArticlePdf/m00006/2019/39/9/0915005.pdf",
        "ref_texts": ""
      },
      "\u89c6\u89c9\u548c\u7269\u4f53\u663e\u8457\u6027\u68c0\u6d4b\u65b9\u6cd5": {
        "authors": [],
        "url": "http://lxbwk.njournal.sdu.edu.cn/CN/article/downloadArticleFile.do?attachType=PDF&id=3045",
        "ref_texts": ""
      },
      "Region Refinement Network for Salient Object Detection": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1906.11443",
        "ref_texts": ""
      },
      "Line Drawings of Natural Scenes Guide Visual Attention": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1912.09581",
        "ref_texts": ""
      },
      "Detection of Salient Objects in Images Using Frequency Domain and Deep Convolutional Features": {
        "authors": [],
        "url": "https://spectrum.library.concordia.ca/id/eprint/985786/1/Rezaei%20Abkenar_PhD_F2019.pdf",
        "ref_texts": ""
      },
      "\u534a\u81ea\u52a8\u6784\u5efa\u6276\u8d2b\u9886\u57df\u77e5\u8bc6\u56fe\u8c31\u5de5\u5177\u7684\u7814\u7a76": {
        "authors": [],
        "url": "http://jsj.journal.cssc709.net/CN/article/downloadArticleFile.do?attachType=PDF&id=1539",
        "ref_texts": ""
      },
      "Green Function and Electromagnetic Potential for Computer Vision and Convolutional Neural Network Applications": {
        "authors": [],
        "url": "https://publications.polymtl.ca/3982/1/2019_DominiqueBeaini.pdf",
        "ref_texts": ""
      },
      "A Novel Method for Scanpath Comparison Based on Levenshtein Distance": {
        "authors": [],
        "url": "https://www.ijsps.com/uploadfile/2019/0625/20190625053555588.pdf",
        "ref_texts": ""
      },
      "Integrated Bidirectional Attention Salient Region Detection Based on Full Convolution and Encoder-Decoder": {
        "authors": [],
        "url": "https://www.jcad.cn/en/article/pdf/preview/10.3724/SP.J.1089.2019.17512.pdf",
        "ref_texts": ""
      },
      "An investigation of gradient as a feature cue for saliency detection": {
        "authors": [
          "Christopher Cooley"
        ],
        "url": "https://pure.ulster.ac.uk/files/77293492/SingleScaleSaliency_Cooley.pdf",
        "ref_texts": ""
      },
      "Multi-scale saliency using local gradient and global colour features": {
        "authors": [
          "Christopher Cooley"
        ],
        "url": "https://pure.ulster.ac.uk/files/77293548/MultiScaleSaliency_Cooley.pdf",
        "ref_texts": ""
      },
      "BASNet: Boundary-Aware Salient Object Detection\u2013Supplementary Material": {
        "authors": [],
        "url": "https://openaccess.thecvf.com/content_CVPR_2019/supplemental/Qin_BASNet_Boundary-Aware_Salient_CVPR_2019_supplemental.pdf",
        "ref_texts": ""
      },
      "Automatic Description and Annotation of Complex Scenes": {
        "authors": [],
        "url": "https://boa.unimib.it/bitstream/10281/241287/2/phd_unimib_718057.pdf",
        "ref_texts": ""
      },
      "\u7ed3\u5408\u7eb9\u7406\u7279\u5f81\u8d85\u50cf\u7d20\u5206\u5272\u7684\u663e\u8457\u6027\u68c0\u6d4b": {
        "authors": [],
        "url": "http://jsj.journal.cssc709.net/CN/article/downloadArticleFile.do?attachType=PDF&id=1558",
        "ref_texts": ""
      },
      "\u878d\u5408\u53cc\u5411\u6ce8\u610f\u7684\u5168\u5377\u79ef\u7f16\u89e3\u7801\u663e\u8457\u533a\u57df\u68c0\u6d4b": {
        "authors": [],
        "url": "https://www.jcad.cn/cn/article/pdf/preview/10.3724/SP.J.1089.2019.17512.pdf",
        "ref_texts": ""
      },
      "Picanet: Learning pixel-wise contextual attention for saliency detection": {
        "authors": [
          "Nian Liu",
          "Junwei Han",
          "Hsuan Yang"
        ],
        "url": "https://openaccess.thecvf.com/content_cvpr_2018/papers/Liu_PiCANet_Learning_Pixel-Wise_CVPR_2018_paper.pdf",
        "ref_texts": ""
      },
      "Progressive attention guided recurrent network for salient object detection": {
        "authors": [
          "Xiaoning Zhang",
          "Tiantian Wang",
          "Jinqing Qi",
          "Huchuan Lu",
          "Gang Wang"
        ],
        "url": "https://openaccess.thecvf.com/content_cvpr_2018/papers/Zhang_Progressive_Attention_Guided_CVPR_2018_paper.pdf",
        "ref_texts": ""
      },
      "R3net: Recurrent residual refinement network for saliency detection": {
        "authors": [
          "Zijun Deng",
          "Xiaowei Hu",
          "Lei Zhu",
          "Xuemiao Xu",
          "Jing Qin",
          "Guoqiang Han",
          "Ann Heng"
        ],
        "url": "https://www.ijcai.org/proceedings/2018/0095.pdf",
        "ref_texts": ""
      },
      "A bi-directional message passing model for salient object detection": {
        "authors": [
          "Lu Zhang",
          "Ju Dai",
          "Huchuan Lu",
          "You He",
          "Gang Wang"
        ],
        "url": "https://openaccess.thecvf.com/content_cvpr_2018/papers/Zhang_A_Bi-Directional_Message_CVPR_2018_paper.pdf"
      },
      "Detect globally, refine locally: A novel approach to saliency detection": {
        "authors": [
          "Tiantian Wang",
          "Lihe Zhang",
          "Shuo Wang",
          "Huchuan Lu",
          "Gang Yang",
          "Xiang Ruan",
          "Ali Borji"
        ],
        "url": "http://openaccess.thecvf.com/content_cvpr_2018/papers/Wang_Detect_Globally_Refine_CVPR_2018_paper.pdf",
        "ref_texts": ""
      },
      "Salient objects in clutter: Bringing salient object detection to the foreground": {
        "authors": [
          "Ping Fan",
          "Jiang Liu",
          "Shanghua Gao",
          "Qibin Hou",
          "Ming Cheng",
          "Ali Borji"
        ],
        "url": "https://openaccess.thecvf.com/content_ECCV_2018/papers/Deng-Ping_Fan_Salient_Objects_in_ECCV_2018_paper.pdf",
        "ref_texts": ""
      },
      "SuperPCA: A superpixelwise PCA approach for unsupervised feature extraction of hyperspectral imagery": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1806.09807",
        "ref_texts": ""
      },
      "Salient object detection driven by fixation prediction": {
        "authors": [
          "Wenguan Wang",
          "Jianbing Shen",
          "Xingping Dong",
          "Ali Borji"
        ],
        "url": "http://openaccess.thecvf.com/content_cvpr_2018/papers/Wang_Salient_Object_Detection_CVPR_2018_paper.pdf",
        "ref_texts": ""
      },
      "Deep unsupervised saliency detection: A multiple noisy labeling perspective": {
        "authors": [
          "Jing Zhang",
          "Tong Zhang",
          "Yuchao Dai",
          "Mehrtash Harandi",
          "Richard Hartley"
        ],
        "url": "http://openaccess.thecvf.com/content_cvpr_2018/papers/Zhang_Deep_Unsupervised_Saliency_CVPR_2018_paper.pdf",
        "ref_texts": ""
      },
      "Unsupervised image saliency detection with Gestalt-laws guided optimization and visual attention based refinement": {
        "authors": [
          "George Bray"
        ],
        "url": "https://rgu-repository.worktribe.com/preview/1481395/YAN%202018%20Unsupervised%20image%20%28AAM%29.pdf",
        "ref_texts": ""
      },
      "Revisiting salient object detection: Simultaneous detection, ranking, and subitizing of multiple salient objects": {
        "authors": [
          "Md Amirul",
          "Mahmoud Kalash",
          "Neil D. B"
        ],
        "url": "https://openaccess.thecvf.com/content_cvpr_2018/papers/Islam_Revisiting_Salient_Object_CVPR_2018_paper.pdf",
        "ref_texts": ""
      },
      "Contrast-oriented deep neural networks for salient object detection": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1803.11395",
        "ref_texts": ""
      },
      "ConnNet: A long-range relation-aware pixel-connectivity network for salient segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1804.07836",
        "ref_texts": ""
      },
      "Attentive systems: A survey": {
        "authors": [
          "Tam V. Nguyen"
        ],
        "url": "https://www-users.cse.umn.edu/~qzhao/publications/pdf/survey_ijcv2018.pdf",
        "ref_texts": ""
      },
      "Learning to promote saliency detectors": {
        "authors": [
          "Yu Zeng",
          "Huchuan Lu",
          "Lihe Zhang",
          "Mengyang Feng",
          "Ali Borji"
        ],
        "url": "https://openaccess.thecvf.com/content_cvpr_2018/papers/Zeng_Learning_to_Promote_CVPR_2018_paper.pdf",
        "ref_texts": ""
      },
      "Hierarchical cellular automata for visual saliency": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1705.09425",
        "ref_texts": ""
      },
      "Analysis of blur measure operators for single image blur segmentation": {
        "authors": [],
        "url": "https://www.mdpi.com/2076-3417/8/5/807/pdf",
        "ref_texts": ""
      },
      "Efficiently learning mixtures of mallows models": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1808.05731",
        "ref_texts": ""
      },
      "An unsupervised game-theoretic approach to saliency detection": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1708.02476",
        "ref_texts": ""
      },
      "Three birds one stone: A general architecture for salient object segmentation, edge detection and skeleton extraction": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1803.09860",
        "ref_texts": ""
      },
      "Saliency detection via multi-scale global cues": {
        "authors": [],
        "url": "https://cszjwang.github.io/sub_pages/pps/TMM19.pdf",
        "ref_texts": ""
      },
      "Agile amulet: Real-time salient object detection with contextual attention": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1802.06960",
        "ref_texts": ""
      },
      "Sequential clique optimization for video object segmentation": {
        "authors": [
          "Yeong Jun",
          "Yoon Lee",
          "Su Kim"
        ],
        "url": "https://openaccess.thecvf.com/content_ECCV_2018/papers/Yeong_Jun_Koh_Sequential_Clique_Optimization_ECCV_2018_paper.pdf",
        "ref_texts": ""
      },
      "Salience guided depth calibration for perceptually optimized compressive light field 3D display": {
        "authors": [
          "Shizheng Wang",
          "Wenjuan Liao",
          "Phil Surman",
          "Zhigang Tu",
          "Yuanjin Zheng",
          "Junsong Yuan"
        ],
        "url": "https://openaccess.thecvf.com/content_cvpr_2018/papers/Wang_Salience_Guided_Depth_CVPR_2018_paper.pdf",
        "ref_texts": ""
      },
      "Direction selective contour detection for salient objects": {
        "authors": [],
        "url": "https://eprints.sztaki.hu/9808/1/Manno_375_3419087_ny.pdf",
        "ref_texts": ""
      },
      "Probabilistic saliency estimation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1609.03868",
        "ref_texts": ""
      },
      "Location augmentation for cnn": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1807.07044",
        "ref_texts": ""
      },
      "Extended non-local feature for visual saliency detection in low contrast images": {
        "authors": [
          "Xin Xu",
          "Jie Wang"
        ],
        "url": "http://openaccess.thecvf.com/content_ECCVW_2018/papers/11132/Xu_Extended_non-local_feature_for_visual_saliency_detection_in_low_contrast_ECCVW_2018_paper.pdf",
        "ref_texts": ""
      },
      "Context proposals for saliency detection": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1806.10359",
        "ref_texts": ""
      },
      "Salient region extraction based on global contrast enhancement and saliency cut for image information recognition of the visually impaired": {
        "authors": [],
        "url": "https://koreascience.kr/article/JAKO201818564287762.pdf",
        "ref_texts": ""
      },
      "Saliency integration: An arbitrator model": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1608.01536",
        "ref_texts": ""
      },
      "Salient object detection via recursive sparse representation": {
        "authors": [],
        "url": "https://www.mdpi.com/2072-4292/10/4/652/pdf",
        "ref_texts": ""
      },
      "Ro-SOS: Metric Expression Network (MEnet) for Robust Salient Object Segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1805.05638",
        "ref_texts": ""
      },
      "Numerical analysis near singularities in RBF networks": {
        "authors": [],
        "url": "https://www.jmlr.org/papers/volume19/16-210/16-210.pdf",
        "ref_texts": ""
      },
      "Image retargeting using blur based depth saliency descriptor": {
        "authors": [],
        "url": "https://www.jcad.cn/en/article/pdf/preview/10.3724/SP.J.1089.2018.16405.pdf",
        "ref_texts": ""
      },
      "Saliency detection via bi-directional propagation": {
        "authors": [],
        "url": "https://oulurepo.oulu.fi/bitstream/handle/10024/27631/nbnfi-fe201902266253.pdf?sequence=1",
        "ref_texts": ""
      },
      "Where's your focus: Personalized attention": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1802.07931",
        "ref_texts": ""
      },
      "Common statement kind changes to inform automatic program repair": {
        "authors": [],
        "url": "https://par.nsf.gov/servlets/purl/10082070",
        "ref_texts": ""
      },
      "ViS-HuD: Using visual saliency to improve human detection with convolutional neural networks": {
        "authors": [
          "Vandit Gajjar",
          "Yash Khandhediya",
          "Ayesha Gurnani",
          "Viraj Mavani",
          "Mehul S. Raval"
        ],
        "url": "http://openaccess.thecvf.com/content_cvpr_2018_workshops/papers/w39/Gajjar_ViS-HuD_Using_Visual_CVPR_2018_paper.pdf"
      },
      "Semantics meet saliency: Exploring domain affinity and models for dual-task prediction": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1807.09430",
        "ref_texts": ""
      },
      "Saliency object detection based on domain transform and contour detection": {
        "authors": [],
        "url": "https://www.jcad.cn/en/article/pdf/preview/10.3724/SP.J.1089.2018.16778.pdf",
        "ref_texts": ""
      },
      "An improved boosting learning saliency method for built-up areas extraction in Sentinel-2 images": {
        "authors": [],
        "url": "https://www.mdpi.com/2072-4292/10/12/1863/pdf",
        "ref_texts": ""
      },
      "Salient region detection using diffusion process with nonlocal connections": {
        "authors": [],
        "url": "https://www.mdpi.com/2076-3417/8/12/2526/pdf",
        "ref_texts": ""
      },
      "Benchmark 3D eye-tracking dataset for visual saliency prediction on stereoscopic 3D video": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1803.04845",
        "ref_texts": ""
      },
      "Fast content-aware resizing of multi-layer information visualization via adaptive triangulation": {
        "authors": [
          "Chenhui Li"
        ],
        "url": "http://chenhui.li/documents/VisResizing_JVLC_2018.pdf",
        "ref_texts": ""
      },
      "A prior regularized multi-layer graph ranking model for image saliency computation": {
        "authors": [],
        "url": "http://gala.gre.ac.uk/id/eprint/24364/1/24364%20MA_Prior_Regularized_Multi-layer_Graph_Model_For_Image_Saliency_Computation_%28AAM%29_2018.pdf",
        "ref_texts": ""
      },
      "Saliency fusion via sparse and double low rank decomposition": {
        "authors": [
          "Junxia Li"
        ],
        "url": "https://gcatnjust.github.io/ChenGong/paper/li_prl17.pdf",
        "ref_texts": ""
      },
      "Salient Object Detection with Convex Hull Overlap": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1612.03284",
        "ref_texts": ""
      },
      "Advancing Segmentation and Unsupervised Learning Within the Field of Deep Learning": {
        "authors": [
          "Michael Kampffmeyer",
          "T Machine",
          "Learning Group"
        ],
        "url": "https://munin.uit.no/bitstream/handle/10037/14264/thesis.pdf?sequence=2&isAllowed=y"
      },
      "Understanding of the convolutional neural networks with relative learning algorithms": {
        "authors": [],
        "url": "https://pdfs.semanticscholar.org/0c8b/24ca0ff032a5d41ebe03c87bd9a8ad88f0e5.pdf",
        "ref_texts": ""
      },
      "Saliency detection via bidirectional absorbing markov chain": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1808.08393",
        "ref_texts": ""
      },
      "High precision detection of salient objects based on deep convolutional networks with proper combinations of shallow and deep connections": {
        "authors": [],
        "url": "https://www.mdpi.com/2073-8994/11/1/5/pdf",
        "ref_texts": ""
      },
      "Saliency detection using boundary aware regional contrast based seam-map": {
        "authors": [],
        "url": "https://kyutech.repo.nii.ac.jp/?action=repository_uri&item_id=5793&file_id=17&file_no=1",
        "ref_texts": ""
      },
      "Background prior-based salient object detection via adaptive figure-ground classification": {
        "authors": [],
        "url": "https://koreascience.kr/article/JAKO201818564288318.pdf",
        "ref_texts": ""
      },
      "Memory-efficient deep salient object segmentation networks on gridized superpixels": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1712.09558",
        "ref_texts": ""
      },
      "3D Video Quality Assessment": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1803.04836",
        "ref_texts": ""
      },
      "Personalization of saliency estimation": {
        "authors": [],
        "url": "https://escholarship.mcgill.ca/downloads/5425kd097",
        "ref_texts": ""
      },
      "Adding value to sensor data of civil engineering structures: automatic outlier detection": {
        "authors": [],
        "url": "https://repositorio.iscte-iul.pt/bitstream/10071/16894/1/iisa2018_final_paper_65.pdf",
        "ref_texts": ""
      },
      "\u7ed3\u5408\u8fb9\u7f18\u6a21\u7cca\u7684\u666f\u6df1\u663e\u8457\u6027\u5728\u56fe\u50cf\u7f29\u653e\u4e2d\u7684\u7814\u7a76": {
        "authors": [],
        "url": "https://www.jcad.cn/cn/article/pdf/preview/10.3724/SP.J.1089.2018.16405.pdf",
        "ref_texts": ""
      },
      "\u57fa\u4e8e\u591a\u7279\u5f81\u6269\u6563\u65b9\u6cd5\u7684\u663e\u8457\u6027\u7269\u4f53\u68c0\u6d4b": {
        "authors": [],
        "url": "https://jeit.ac.cn/cn/article/pdf/preview/10.11999/JEIT170827.pdf",
        "ref_texts": ""
      },
      "\u7ed3\u5408\u57df\u53d8\u6362\u548c\u8f6e\u5ed3\u68c0\u6d4b\u7684\u663e\u8457\u6027\u76ee\u6807\u68c0\u6d4b": {
        "authors": [],
        "url": "https://www.jcad.cn/cn/article/pdf/preview/10.3724/SP.J.1089.2018.16778.pdf",
        "ref_texts": ""
      },
      "Multi-scale Diffusion-based Salient Object Detection with Background and Objectness Seeds": {
        "authors": [],
        "url": "https://koreascience.kr/article/JAKO201835372300438.pdf",
        "ref_texts": ""
      },
      "Learning Regularization Weight for CRF Optimization": {
        "authors": [
          "Jiaxiao Wu"
        ],
        "url": "https://ir.lib.uwo.ca/cgi/viewcontent.cgi?article=7494&context=etd",
        "ref_texts": ""
      },
      "Predicting Visual Saliency: Where Do People Look?": {
        "authors": [],
        "url": "http://www.cs.princeton.edu/courses/archive/spring18/cos598B/public/projects/LiteratureReview/COS598B_spr2018_Saliency.pdf",
        "ref_texts": ""
      },
      "Improvement and Innovation of Accounting Major's Education Method": {
        "authors": [],
        "url": "https://webofproceedings.org/proceedings_series/ESSP/SSAH%202018/SSAH_0611184.pdf",
        "ref_texts": ""
      },
      "Linking videos and languages: Representations and Their Applications": {
        "authors": [],
        "url": "https://naist.repo.nii.ac.jp/record/10860/files/R014247.pdf",
        "ref_texts": ""
      },
      "Information visualization of large data streaming": {
        "authors": [],
        "url": "https://theses.lib.polyu.edu.hk/bitstream/200/9326/1/991022067458303411.pdf",
        "ref_texts": ""
      },
      "Optimum Space-Frequency Partition in Subband Image Coding with Human Visual Sensitivity and Region-of-Interest": {
        "authors": [
          "Haruhiko Miyazaki",
          "Masashi Kameda"
        ],
        "url": "https://library.imaging.org/admin/apis/public/api/ist/website/downloadArticle/ei/30/14/art00019",
        "ref_texts": ""
      },
      "Saliency region detection based on improved Nonlocal Mean filter algorithm": {
        "authors": [],
        "url": "http://www.yndxxb.ynu.edu.cn/yndxxbzrkxb/en/article/pdf/preview/10.7540/j.ynu.20170351.pdf",
        "ref_texts": ""
      },
      "Cognitive feature fusion for effective pattern recognition in multi-modal images and videos": {
        "authors": [
          "Yijun Yan"
        ],
        "url": "http://stax.strath.ac.uk/downloads/rb68xc25z",
        "ref_texts": ""
      },
      "Backward-compatible high dynamic range imaging: acquisition, display and compression": {
        "authors": [],
        "url": "https://dr.ntu.edu.sg/bitstream/10356/75404/1/thesis_final.pdf",
        "ref_texts": ""
      },
      "\u9762\u5411\u793e\u4ea4\u5a92\u4f53\u56fe\u50cf\u7684\u663e\u8457\u6027\u6570\u636e\u96c6": {
        "authors": [],
        "url": "https://jdxb.bjtu.edu.cn/CN/article/downloadArticleFile.do?attachType=PDF&id=3391",
        "ref_texts": ""
      },
      "\u57fa\u4e8e\u8ff9\u8868\u793a\u548c\u6b63\u5219\u5316\u7684\u663e\u8457\u76ee\u6807\u68c0\u6d4b\u7b97\u6cd5": {
        "authors": [],
        "url": "https://www.jcad.cn/cn/article/pdf/preview/10.3724/SP.J.1089.2018.17113.pdf",
        "ref_texts": ""
      },
      "\u57fa\u4e8e\u6539\u8fdb\u975e\u5c40\u90e8\u5747\u503c\u6ee4\u6ce2\u7b97\u6cd5\u7684\u663e\u8457\u6027\u533a\u57df\u68c0\u6d4b": {
        "authors": [],
        "url": "http://www.yndxxb.ynu.edu.cn/yndxxbzrkxb/cn/article/pdf/preview/10.7540/j.ynu.20170351.pdf",
        "ref_texts": ""
      },
      "ANALYSE DE TRAFIC ROUTIER \u00c0 PARTIR DE VID\u00c9OS \u00c0 FAIBLE D\u00c9BIT": {
        "authors": [],
        "url": "http://savoirs.usherbrooke.ca/bitstream/handle/11143/11854/Luo_Zhiming_PhD_2018.pdf?sequence=11",
        "ref_texts": ""
      },
      "Detecci\u00f3n de regiones salientes en im\u00e1genes en el espacio de los quaternions": {
        "authors": [],
        "url": "http://scielo.sld.cu/pdf/rcci/v12n4/rcci11418.pdf",
        "ref_texts": ""
      },
      "D\u00e9tection d'objet bas\u00e9 sur l'estimation de la saillance": {
        "authors": [],
        "url": "https://dspace.ummto.dz/bitstreams/17a2243c-e81e-48e9-a0f6-021065db8651/download",
        "ref_texts": ""
      },
      "Deeply supervised salient object detection with short connections": {
        "authors": [
          "Qibin Hou",
          "Ming Cheng",
          "Xiaowei Hu",
          "Ali Borji",
          "Zhuowen Tu",
          "Philip H. S"
        ],
        "url": "http://openaccess.thecvf.com/content_cvpr_2017/papers/Hou_Deeply_Supervised_Salient_CVPR_2017_paper.pdf",
        "ref_texts": ""
      },
      "Learning to detect salient objects with image-level supervision": {
        "authors": [
          "Lijun Wang",
          "Huchuan Lu",
          "Yifan Wang",
          "Mengyang Feng",
          "Dong Wang",
          "Baocai Yin",
          "Xiang Ruan"
        ],
        "url": "http://openaccess.thecvf.com/content_cvpr_2017/papers/Wang_Learning_to_Detect_CVPR_2017_paper.pdf",
        "ref_texts": ""
      },
      "Amulet: Aggregating multi-level convolutional features for salient object detection": {
        "authors": [
          "Pingping Zhang",
          "Dong Wang",
          "Huchuan Lu",
          "Hongyu Wang",
          "Xiang Ruan"
        ],
        "url": "http://openaccess.thecvf.com/content_ICCV_2017/papers/Zhang_Amulet_Aggregating_Multi-Level_ICCV_2017_paper.pdf",
        "ref_texts": ""
      },
      "Non-local deep features for salient object detection": {
        "authors": [
          "Zhiming Luo",
          "Akshaya Mishra",
          "Andrew Achkar",
          "Justin Eichel",
          "Shaozi Li",
          "Marc Jodoin"
        ],
        "url": "http://openaccess.thecvf.com/content_cvpr_2017/papers/Luo_Non-Local_Deep_Features_CVPR_2017_paper.pdf",
        "ref_texts": ""
      },
      "Learning uncertain convolutional features for accurate saliency detection": {
        "authors": [
          "Pingping Zhang",
          "Dong Wang",
          "Huchuan Lu",
          "Hongyu Wang",
          "Baocai Yin"
        ],
        "url": "http://openaccess.thecvf.com/content_ICCV_2017/papers/Zhang_Learning_Uncertain_Convolutional_ICCV_2017_paper.pdf",
        "ref_texts": ""
      },
      "A stagewise refinement model for detecting salient objects in images": {
        "authors": [
          "Tiantian Wang",
          "Ali Borji",
          "Lihe Zhang",
          "Pingping Zhang",
          "Huchuan Lu"
        ],
        "url": "https://openaccess.thecvf.com/content_ICCV_2017/papers/Wang_A_Stagewise_Refinement_ICCV_2017_paper.pdf"
      },
      "Joint bi-layer optimization for single-image rain streak removal": {
        "authors": [
          "Lei Zhu",
          "Wing Fu",
          "Dani Lischinski",
          "Ann Heng"
        ],
        "url": "https://openaccess.thecvf.com/content_ICCV_2017/papers/Zhu_Joint_Bi-Layer_Optimization_ICCV_2017_paper.pdf",
        "ref_texts": ""
      },
      "RGBD salient object detection via deep fusion": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1607.03333",
        "ref_texts": ""
      },
      "Instance-level salient object segmentation": {
        "authors": [
          "Guanbin Li",
          "Yuan Xie",
          "Liang Lin",
          "Yizhou Yu"
        ],
        "url": "https://openaccess.thecvf.com/content_cvpr_2017/papers/Li_Instance-Level_Salient_Object_CVPR_2017_paper.pdf"
      },
      "Deep level sets for salient object detection": {
        "authors": [
          "Ping Hu",
          "Bing Shuai",
          "Jun Liu",
          "Gang Wang"
        ],
        "url": "http://openaccess.thecvf.com/content_cvpr_2017/papers/Hu_Deep_Level_Sets_CVPR_2017_paper.pdf"
      },
      "Supervision by fusion: Towards unsupervised learning of deep salient object detector": {
        "authors": [
          "Dingwen Zhang",
          "Junwei Han",
          "Yu Zhang"
        ],
        "url": "https://openaccess.thecvf.com/content_ICCV_2017/papers/Zhang_Supervision_by_Fusion_ICCV_2017_paper.pdf",
        "ref_texts": ""
      },
      "A benchmark dataset and saliency-guided stacked autoencoders for video-based salient object detection": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1611.00135",
        "ref_texts": ""
      },
      "Spatially-varying blur detection based on multiscale fused and sorted transform coefficients of gradient magnitudes": {
        "authors": [
          "Alireza Golestaneh",
          "Lina J. Karam"
        ],
        "url": "https://openaccess.thecvf.com/content_cvpr_2017/papers/Golestaneh_Spatially-Varying_Blur_Detection_CVPR_2017_paper.pdf",
        "ref_texts": ""
      },
      "Edge preserving and multi-scale contextual neural network for salient object detection": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1608.08029",
        "ref_texts": ""
      },
      "What is and what is not a salient object? learning salient object detector by ensembling linear exemplar regressors": {
        "authors": [
          "Changqun Xia",
          "Jia Li",
          "Xiaowu Chen",
          "Anlin Zheng",
          "Yu Zhang"
        ],
        "url": "http://openaccess.thecvf.com/content_cvpr_2017/papers/Xia_What_Is_and_CVPR_2017_paper.pdf",
        "ref_texts": ""
      },
      "Look, perceive and segment: Finding the salient objects in images via two-stream fixation-semantic cnns": {
        "authors": [
          "Xiaowu Chen",
          "Anlin Zheng",
          "Jia Li",
          "Feng Lu"
        ],
        "url": "http://openaccess.thecvf.com/content_ICCV_2017/papers/Chen_Look_Perceive_and_ICCV_2017_paper.pdf",
        "ref_texts": ""
      },
      "Delving into salient object subitizing and detection": {
        "authors": [
          "Shengfeng He",
          "Jianbo Jiao",
          "Xiaodan Zhang",
          "Guoqiang Han",
          "Rynson W"
        ],
        "url": "http://openaccess.thecvf.com/content_ICCV_2017/papers/He_Delving_Into_Salient_ICCV_2017_paper.pdf",
        "ref_texts": ""
      },
      "Evaluation of hierarchical watersheds": {
        "authors": [],
        "url": "https://hal.science/hal-01430865/document",
        "ref_texts": ""
      },
      "Unsupervised simplification of image hierarchies via evolution analysis in scale-sets framework": {
        "authors": [],
        "url": "http://mvr.whu.edu.cn/pubs/2017-tip.pdf",
        "ref_texts": ""
      },
      "Bayes saliency-based object proposal generator for nighttime traffic images": {
        "authors": [],
        "url": "https://www.neuro.uestc.edu.cn/vccl/papers/2018-Kuang-TITS.pdf",
        "ref_texts": ""
      },
      "Unsupervised salient object detection via inferring from imperfect saliency models": {
        "authors": [],
        "url": "http://www.smiles-xjtu.com/html/Our%20Paper/Unsupervised%20Salient%20Object.pdf",
        "ref_texts": ""
      },
      "Hierarchical contour closure-based holistic salient object detection": {
        "authors": [],
        "url": "https://oulurepo.oulu.fi/bitstream/handle/10024/24537/nbnfi-fe201903057132.pdf?sequence=1",
        "ref_texts": ""
      },
      "Salient Object Detection using a Context-Aware Refinement Network.": {
        "authors": [],
        "url": "https://bmva-archive.org.uk/bmvc/2017/papers/paper061/paper061.pdf",
        "ref_texts": ""
      },
      "Primary video object segmentation via complementary CNNs and neighborhood reversible flow": {
        "authors": [
          "Jia Li",
          "Anlin Zheng",
          "Xiaowu Chen",
          "Bin Zhou"
        ],
        "url": "http://openaccess.thecvf.com/content_ICCV_2017/papers/Li_Primary_Video_Object_ICCV_2017_paper.pdf",
        "ref_texts": ""
      },
      "Deep salient object detection by integrating multi-level cues": {
        "authors": [],
        "url": "https://porikli.com/mysite/pdfs/porikli%202017%20-%20Deep%20salient%20object%20detection%20by%20integrating%20multi-level%20cues.pdf",
        "ref_texts": ""
      },
      "Animated construction of Chinese brush paintings": {
        "authors": [],
        "url": "https://kops.uni-konstanz.de/bitstream/handle/123456789/41114/Fan_2-th8lv046ebp26.pdf?sequence=1",
        "ref_texts": ""
      },
      "Deep edge-aware saliency detection": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1708.04366",
        "ref_texts": ""
      },
      "Contour-constrained superpixels for image and video processing": {
        "authors": [
          "Ho Lee",
          "Dong Jang",
          "Su Kim"
        ],
        "url": "https://openaccess.thecvf.com/content_cvpr_2017/papers/Lee_Contour-Constrained_Superpixels_for_CVPR_2017_paper.pdf"
      },
      "Multi-scale salient object detection with pyramid spatial pooling": {
        "authors": [],
        "url": "http://www.apsipa.org/proceedings/2017/CONTENTS/papers2017/14DecThursday/Poster%204/TP-P4.16.pdf",
        "ref_texts": ""
      },
      "Salient object detection with semantic priors": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1705.08207",
        "ref_texts": ""
      },
      "A unified RGB-T saliency detection benchmark: dataset, baselines, analysis and a novel approach": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1701.02829",
        "ref_texts": ""
      },
      "Hierarchical co-salient object detection via color names": {
        "authors": [],
        "url": "https://www.loujing.com/wp-content/uploads/research/p2017-hcn-co-sod/HCN_ACPR2017.pdf",
        "ref_texts": ""
      },
      "Integrated deep and shallow networks for salient object detection": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1706.00530",
        "ref_texts": ""
      },
      "Temporal superpixels based on proximity-weighted patch matching": {
        "authors": [
          "Ho Lee",
          "Dong Jang",
          "Su Kim"
        ],
        "url": "https://openaccess.thecvf.com/content_ICCV_2017/papers/Lee_Temporal_Superpixels_Based_ICCV_2017_paper.pdf"
      },
      "Hierarchical salient object detection for assisted grasping": {
        "authors": [
          "Dominik Alexander",
          "Boris Illing",
          "Bastian Gaspers",
          "Dirk Schulz",
          "Armin Bernd"
        ],
        "url": "https://arxiv.org/pdf/1701.04284",
        "ref_texts": ""
      },
      "Co-saliency detection based on superpixel matching and cellular automata": {
        "authors": [],
        "url": "https://koreascience.kr/article/JAKO201720861204118.pdf",
        "ref_texts": ""
      },
      "A fast and compact saliency score regression network based on fully convolutional network": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1702.00615",
        "ref_texts": ""
      },
      "Training deep networks to be spatially sensitive": {
        "authors": [
          "Nicholas Kolkin",
          "Eli Shechtman",
          "Gregory Shakhnarovich"
        ],
        "url": "http://openaccess.thecvf.com/content_ICCV_2017/papers/Kolkin_Training_Deep_Networks_ICCV_2017_paper.pdf",
        "ref_texts": ""
      },
      "Texture features for object salience": {
        "authors": [],
        "url": "https://research-repository.st-andrews.ac.uk/bitstream/handle/10023/16065/Terzic_2017_IVC_ObjectSalience_AAM.pdf?sequence=1&isAllowed=y",
        "ref_texts": ""
      },
      "Region-Based multiscale spatiotemporal saliency for video": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1708.01589",
        "ref_texts": ""
      },
      "Salient Region Detection by Integrating Intrinsic and Extrinsic Cues without Prior Information.": {
        "authors": [],
        "url": "http://jestr.org/downloads/Volume10Issue3/fulltext241032017.pdf",
        "ref_texts": ""
      },
      "\u5168\u5c40\u6a21\u578b\u548c\u5c40\u90e8\u4f18\u5316\u7684\u6df1\u5ea6\u7f51\u7edc\u663e\u8457\u6027\u68c0\u6d4b": {
        "authors": [],
        "url": "https://www.researching.cn/ArticlePdf/m00006/2017/37/12/1215005.pdf",
        "ref_texts": ""
      },
      "Moving target detection based on dynamic background of cellular automaton": {
        "authors": [],
        "url": "http://ir.ciomp.ac.cn/bitstream/181722/59116/1/Moving%20target.pdf",
        "ref_texts": ""
      },
      "Can Image Retrieval help Visual Saliency Detection?": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1709.08172",
        "ref_texts": ""
      },
      "Co-saliency based visual object co-segmentation and co-localization": {
        "authors": [],
        "url": "https://dr.ntu.edu.sg/bitstream/10356/72465/1/KOTESWAR_PhD_thesis_with_cover.pdf",
        "ref_texts": ""
      },
      "Adaptive Genetic Algorithm on Saliency Detection": {
        "authors": [],
        "url": "https://www.jcad.cn/en/article/pdf/preview/a73a41b6-b883-4bef-8e2e-98f9c7f242a7.pdf",
        "ref_texts": ""
      },
      "Saliency detection based on foreground and background extraction": {
        "authors": [],
        "url": "https://www.jcad.cn/en/article/pdf/preview/d39d0e38-8294-453e-bd96-c194e4ee19fc.pdf",
        "ref_texts": ""
      },
      "A salient region detection model combining background distribution measure for indoor robots": {
        "authors": [
          "Na Li",
          "Hui Xu",
          "Zhenhua Wang",
          "Lining Sun",
          "Guodong Chen"
        ],
        "url": "https://journals.plos.org/plosone/article/file?id=10.1371/journal.pone.0180519&type=printable",
        "ref_texts": ""
      },
      "A novel graph structure for salient object detection based on divergence background and compact foreground": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1711.11266",
        "ref_texts": ""
      },
      "Probabilistic background modelling for sports video segmentation": {
        "authors": [],
        "url": "https://www.scitepress.org/PublishedPapers/2017/61355/61355.pdf",
        "ref_texts": ""
      },
      "Salient object detection using array images": {
        "authors": [],
        "url": "https://ira.lib.polyu.edu.hk/bitstream/10397/94792/1/EIE-0612_Li_Salient_Object_Detection.pdf",
        "ref_texts": ""
      },
      "Saliency detection by aggregating complementary background template with optimization framework": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1706.04285",
        "ref_texts": ""
      },
      "Improved Salient Object Extraction using Structured Matrix Decomposition and Contour Based Spatial Prior": {
        "authors": [
          "Ramesh Bhandari",
          "Sharad Kumar"
        ],
        "url": "http://conference.ioe.edu.np/publications/ioegc2017/IOEGC-2017-05.pdf",
        "ref_texts": ""
      },
      "Saliency Detection Via Dense Convolution Network": {
        "authors": [],
        "url": "https://www.intelcomp-design.com/paper/ISCSAI/ISCSAI010.pdf",
        "ref_texts": ""
      },
      "Saliency detection using texture and local cues": {
        "authors": [],
        "url": "https://researchportal.port.ac.uk/files/8797899/Saliency_detection_using_texture_and_local_cues.pdf",
        "ref_texts": ""
      },
      "Discovering visual saliency for image analysis": {
        "authors": [],
        "url": "https://rucore.libraries.rutgers.edu/rutgers-lib/52218/PDF/1/play/",
        "ref_texts": ""
      },
      "Impacts of contour saliency map transformations": {
        "authors": [],
        "url": "http://sibgrapi.sid.inpe.br/attachment.cgi/sid.inpe.br/sibgrapi/2017/09.12.20.54/doc/2017_SIBGRAPI_WUW.pdf",
        "ref_texts": ""
      },
      "Supplementary Document for Amulet": {
        "authors": [],
        "url": "https://openaccess.thecvf.com/content_ICCV_2017/supplemental/Zhang_Amulet_Aggregating_Multi-Level_ICCV_2017_supplemental.pdf",
        "ref_texts": ""
      },
      "Focusness guided salient object detection": {
        "authors": [
          "Xiaolin Xiao",
          "Yicong Zhou"
        ],
        "url": "https://viplab.cis.um.edu.mo/publications/conference/Focusness%20Guided%20Salient%20Object%20Detection.pdf",
        "ref_texts": ""
      },
      "Exploiting saliency information in discriminant subspace learning": {
        "authors": [],
        "url": "https://trepo.tuni.fi/bitstream/handle/123456789/25091/Xu.pdf?sequence=4",
        "ref_texts": ""
      },
      "Dense image labeling using deep learning": {
        "authors": [],
        "url": "https://mspace.lib.umanitoba.ca/bitstream/handle/1993/32395/islam_mdamirul.pdf",
        "ref_texts": ""
      },
      "Focus detection and sharpness evaluation in keyframes containing faces": {
        "authors": [
          "Montserrat Calero"
        ],
        "url": "https://upcommons.upc.edu/bitstream/handle/2117/106375/memoria.pdf?sequence=1",
        "ref_texts": ""
      },
      "Salient Detection via Sparse Representation and Label Propagation": {
        "authors": [],
        "url": "https://www.jcad.cn/en/article/pdf/preview/7f7aa0be-c500-4f30-bf4d-b0f18d4cbaad.pdf",
        "ref_texts": ""
      },
      "Randomly-connected Non-Local Conditional Random Fields": {
        "authors": [],
        "url": "https://uwspace.uwaterloo.ca/bitstream/handle/10012/11319/Shafiee_Mohammad-Javad.pdf?sequence=5&isAllowed=y",
        "ref_texts": ""
      },
      "\u57fa\u4e8e\u81ea\u9002\u5e94\u9057\u4f20\u7b97\u6cd5\u7684\u663e\u8457\u6027\u68c0\u6d4b": {
        "authors": [],
        "url": "https://www.jcad.cn/cn/article/pdf/preview/a73a41b6-b883-4bef-8e2e-98f9c7f242a7.pdf",
        "ref_texts": ""
      },
      "Human attention simulation on nature scenes in computer vision": {
        "authors": [
          "Nianyi Li"
        ],
        "url": "https://udspace.udel.edu/bitstreams/62e29126-61ba-42ec-afaa-da11c4eb7b81/download",
        "ref_texts": ""
      },
      "Human age estimation based on facial images": {
        "authors": [],
        "url": "https://dr.ntu.edu.sg/bitstream/10356/72826/1/Thesis_ZHAO%20WEI_G1203421K.pdf",
        "ref_texts": ""
      },
      "\u57fa\u4e8e\u7a00\u758f\u8868\u793a\u548c\u6807\u7b7e\u4f20\u64ad\u7684\u663e\u8457\u6027\u68c0\u6d4b\u7b97\u6cd5": {
        "authors": [],
        "url": "https://www.jcad.cn/cn/article/pdf/preview/7f7aa0be-c500-4f30-bf4d-b0f18d4cbaad.pdf",
        "ref_texts": ""
      },
      "Interpretable feature maps for robot attention": {
        "authors": [],
        "url": "https://research-repository.st-andrews.ac.uk/bitstream/handle/10023/15948/Terzic_2017_Interpretable_feature_UAHCI_AAM.pdf?sequence=1",
        "ref_texts": ""
      },
      "\u57fa\u4e8e\u81ea\u9002\u5e94\u80cc\u666f\u6a21\u677f\u4e0e\u7a7a\u95f4\u5148\u9a8c\u7684\u663e\u8457\u6027\u7269\u4f53\u68c0\u6d4b\u65b9\u6cd5": {
        "authors": [],
        "url": "http://www.aas.net.cn/fileZDHXB/journal/article/zdhxb/2017/10/PDF/zdhxb-43-10-1736.pdf",
        "ref_texts": ""
      },
      "\u57fa\u4e8e\u9c81\u68d2\u524d\u666f\u9009\u62e9\u7684\u663e\u8457\u6027\u68c0\u6d4b": {
        "authors": [],
        "url": "http://edit.jeit.ac.cn/CN/article/downloadArticleFile.do?attachType=PDF&id=18464",
        "ref_texts": ""
      },
      "\u4e00\u79cd\u524d\u666f\u548c\u80cc\u666f\u63d0\u53d6\u76f8\u7ed3\u5408\u7684\u56fe\u50cf\u663e\u8457\u6027\u68c0\u6d4b": {
        "authors": [],
        "url": "https://www.jcad.cn/cn/article/pdf/preview/d39d0e38-8294-453e-bd96-c194e4ee19fc.pdf",
        "ref_texts": ""
      },
      "Dhsnet: Deep hierarchical saliency network for salient object detection": {
        "authors": [
          "Nian Liu",
          "Junwei Han"
        ],
        "url": "http://openaccess.thecvf.com/content_cvpr_2016/papers/Liu_DHSNet_Deep_Hierarchical_CVPR_2016_paper.pdf",
        "ref_texts": ""
      },
      "Deepsaliency: Multi-task deep neural network model for salient object detection": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1510.05484",
        "ref_texts": ""
      },
      "Deep saliency with encoded low level distance map and high level features": {
        "authors": [
          "Gayoung Lee",
          "Wing Tai",
          "Junmo Kim"
        ],
        "url": "https://openaccess.thecvf.com/content_cvpr_2016/papers/Lee_Deep_Saliency_With_CVPR_2016_paper.pdf",
        "ref_texts": ""
      },
      "Visual saliency detection based on multiscale deep CNN features": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1609.02077",
        "ref_texts": ""
      },
      "A deep multi-level network for saliency prediction": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1609.01064",
        "ref_texts": ""
      },
      "Real-time salient object detection with a minimum spanning tree": {
        "authors": [
          "Chih Tu",
          "Shengfeng He",
          "Qingxiong Yang",
          "Yi Chien"
        ],
        "url": "http://openaccess.thecvf.com/content_cvpr_2016/papers/Tu_Real-Time_Salient_Object_CVPR_2016_paper.pdf",
        "ref_texts": ""
      },
      "Saliency unified: A deep architecture for simultaneous eye fixation prediction and salient object segmentation": {
        "authors": [
          "Srinivas S. S",
          "Vennela Gudisa",
          "Jaley H. Dholakiya",
          "Venkatesh Babu"
        ],
        "url": "http://openaccess.thecvf.com/content_cvpr_2016/papers/Kruthiventi_Saliency_Unified_A_CVPR_2016_paper.pdf",
        "ref_texts": ""
      },
      "DISC: Deep image saliency computing via progressive representation learning": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1511.04192",
        "ref_texts": ""
      },
      "Image co-segmentation via saliency co-fusion": {
        "authors": [
          "Koteswar Rao",
          "Jianfei Cai",
          "Junsong Yuan"
        ],
        "url": "https://www.iitk.ac.in/new/data/cv/Image_Co-segmentation_via_Saliency_Co-fusion_Koteswar.pdf",
        "ref_texts": ""
      },
      "Correspondence driven saliency transfer": {
        "authors": [
          "Constance Roberts"
        ],
        "url": "https://ueaeprints.uea.ac.uk/id/eprint/62909/1/Accepted_manuscript.pdf",
        "ref_texts": ""
      },
      "Unconstrained salient object detection via proposal subset optimization": {
        "authors": [
          "Jianming Zhang",
          "Stan Sclaroff",
          "Zhe Lin",
          "Xiaohui Shen",
          "Brian Price",
          "Radomir Mech"
        ],
        "url": "http://openaccess.thecvf.com/content_cvpr_2016/papers/Zhang_Unconstrained_Salient_Object_CVPR_2016_paper.pdf",
        "ref_texts": ""
      },
      "Deep learning in object recognition, detection, and segmentation": {
        "authors": [],
        "url": "https://www.nowpublishers.com/article/DownloadSummary/SIG-071",
        "ref_texts": ""
      },
      "Grab: Visual saliency via novel graph model and background priors": {
        "authors": [
          "Qiaosong Wang",
          "Wen Zheng",
          "Robinson Piramuthu"
        ],
        "url": "https://openaccess.thecvf.com/content_cvpr_2016/papers/Wang_GraB_Visual_Saliency_CVPR_2016_paper.pdf",
        "ref_texts": ""
      },
      "Saliency detection via combining region-level and pixel-level predictions with CNNs": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1608.05186",
        "ref_texts": ""
      },
      "HFS: Hierarchical feature selection for efficient image segmentation": {
        "authors": [],
        "url": "https://ora.ox.ac.uk/objects/uuid:d891dd96-3040-40cc-98f5-31a594f60c61/download_file?file_format=application%2Fpdf&safe_filename=0682.pdf&type_of_work=Conference+item",
        "ref_texts": ""
      },
      "Deeply-supervised recurrent convolutional neural network for saliency detection": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1608.05177",
        "ref_texts": ""
      },
      "Salient object detection via fast R-CNN and low-level cues": {
        "authors": [],
        "url": "https://wangxiang10.github.io/papers/ICIP16_XiangWang.pdf",
        "ref_texts": ""
      },
      "A unified framework for salient structure detection by contour-guided visual search": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1505.04364",
        "ref_texts": ""
      },
      "Learning to diffuse: A new perspective to design pdes for visual analysis": {
        "authors": [],
        "url": "http://irc.cs.sdu.edu.cn/973project/result/download/2016/7.Liu%20et%20al-2016.pdf",
        "ref_texts": ""
      },
      "Semantic filtering": {
        "authors": [
          "Qingxiong Yang"
        ],
        "url": "https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Yang_Semantic_Filtering_CVPR_2016_paper.pdf",
        "ref_texts": ""
      },
      "A hybrid of local and global saliencies for detecting image salient region and appearance": {
        "authors": [],
        "url": "http://www.comp.hkbu.edu.hk/~ymc/papers/journal/SMCA-15-11-0931_publication_version.pdf",
        "ref_texts": ""
      },
      "Depth incorporating with color improves salient object detection": {
        "authors": [
          "Yanlong Tang"
        ],
        "url": "http://zhangyunnet.cn/academic/Papers/stereoSaliency/Depth%20incorporating%20with%20color%20improves%20salient%20object%20detection.pdf",
        "ref_texts": ""
      },
      "Discriminative saliency propagation with sink points": {
        "authors": [
          "Shuhan Chen"
        ],
        "url": "http://shuhanchen.net/papers/PR16.pdf",
        "ref_texts": ""
      },
      "Saliency transfer: An example-based method for salient object detection.": {
        "authors": [
          "Xin Li",
          "Fan Yang",
          "Leiting Chen",
          "Hongbin Cai"
        ],
        "url": "https://www.ijcai.org/Proceedings/16/Papers/482.pdf",
        "ref_texts": ""
      },
      "A shape preserving approach for salient object detection using convolutional neural networks": {
        "authors": [
          "Jongpil Kim",
          "Vladimir Pavlovic"
        ],
        "url": "https://projet.liris.cnrs.fr/imagine/pub/proceedings/ICPR-2016/media/files/0731.pdf",
        "ref_texts": ""
      },
      "Saliency detection with spaces of background-based distribution": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1603.05335",
        "ref_texts": ""
      },
      "Joint multi-image saliency analysis for region of interest detection in optical multispectral remote sensing images": {
        "authors": [],
        "url": "https://www.mdpi.com/2072-4292/8/6/461/pdf",
        "ref_texts": ""
      },
      "Gradient-based global features for seam carving": {
        "authors": [
          "Izumi Ito"
        ],
        "url": "https://link.springer.com/content/pdf/10.1186/s13640-016-0130-9.pdf",
        "ref_texts": ""
      },
      "Unsupervised saliency estimation based on robust hypotheses": {
        "authors": [],
        "url": "https://digitalcommons.usu.edu/cgi/viewcontent.cgi?article=1000&context=computer_science_facpubs",
        "ref_texts": ""
      },
      "Adaptive growing and merging algorithm for image segmentation": {
        "authors": [],
        "url": "http://www.apsipa.org/proceedings_2016/HTML/paper2016/205.pdf",
        "ref_texts": ""
      },
      "Image saliency detection via graph representation with fusing low-level and high-level features": {
        "authors": [],
        "url": "https://www.jcad.cn/en/article/pdf/preview/0abde615-1c84-459c-9fc0-d9c8fa3a0ef8.pdf",
        "ref_texts": ""
      },
      "A Salient Based Bag of Visual Word model (SBBoVW): improvements toward difficult object recognition and object location in image retrieval": {
        "authors": [
          "Leila Mansourian"
        ],
        "url": "https://koreascience.kr/article/JAKO201616534187600.pdf",
        "ref_texts": ""
      },
      "Image saliency detection based on region merging": {
        "authors": [],
        "url": "https://www.jcad.cn/en/article/pdf/preview/5a46d072-10ca-45ad-9d85-922c96e930a1.pdf",
        "ref_texts": ""
      },
      "Salient object detection via region contrast and graph regularization": {
        "authors": [],
        "url": "http://scis.scichina.com/en/2016/032104.pdf",
        "ref_texts": ""
      },
      "\u57fa\u4e8e KL \u6563\u5ea6\u53ca\u591a\u5c3a\u5ea6\u878d\u5408\u7684\u663e\u8457\u6027\u533a\u57df\u68c0\u6d4b\u7b97\u6cd5": {
        "authors": [],
        "url": "https://jeit.ac.cn/cn/article/pdf/preview/10.11999/JEIT151145.pdf",
        "ref_texts": ""
      },
      "Multi-image saliency analysis via histogram and spectral feature clustering for satellite images": {
        "authors": [],
        "url": "https://jiechensite.wordpress.com/wp-content/uploads/2016/12/icip_multi.pdf",
        "ref_texts": ""
      },
      "A comparison of decision trees for ingredient classification": {
        "authors": [],
        "url": "https://staff.fnwi.uva.nl/b.bredeweg/pdf/BSc/20152016/Bakker.pdf",
        "ref_texts": ""
      },
      "A novel saliency detection method via manifold ranking and compactness prior": {
        "authors": [],
        "url": "https://isrc.iscas.ac.cn/zhanglibo/pdfs/2016/BIBM_2016_03.pdf",
        "ref_texts": ""
      },
      "\u9762\u5411\u8fd0\u52a8\u76ee\u6807\u68c0\u6d4b\u7684\u7c92\u5b50\u6ee4\u6ce2\u89c6\u89c9\u6ce8\u610f\u529b\u6a21\u578b": {
        "authors": [],
        "url": "https://www.ejournal.org.cn/CN/article/downloadArticleFile.do?attachType=PDF&id=9829",
        "ref_texts": ""
      },
      "Comparing Color Descriptors between Image Segments for Saliency Detection.": {
        "authors": [],
        "url": "https://www.scitepress.org/papers/2016/56677/56677.pdf",
        "ref_texts": ""
      },
      "Object segmentation by saliency-seeded and spatial-weighted region merging": {
        "authors": [
          "Junxia Li"
        ],
        "url": "https://link.springer.com/content/pdf/10.1186/s40535-016-0024-z.pdf",
        "ref_texts": ""
      },
      "Multi-scale saliency detection using dictionary learning": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1611.06307",
        "ref_texts": ""
      },
      "Learning Feature Selection and Combination Strategies for Generic Salient Object Detection": {
        "authors": [],
        "url": "https://openaccess.wgtn.ac.nz/articles/thesis/Learning_Feature_Selection_and_Combination_Strategies_for_Generic_Salient_Object_Detection/17013953/2/files/31469423.pdf",
        "ref_texts": ""
      },
      "Salient Object Detection via Adaptive Region Merging": {
        "authors": [],
        "url": "https://koreascience.kr/article/JAKO201634864513668.pdf",
        "ref_texts": ""
      },
      "Nerd: A neural response divergence approach to visual saliency detection": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1602.01728",
        "ref_texts": ""
      },
      "Saliency detection using secondary quantization in DCT domain": {
        "authors": [
          "A A"
        ],
        "url": "http://www.apsipa.org/proceedings_2016/HTML/paper2016/59.pdf",
        "ref_texts": ""
      },
      "SALIENCY CLASSIFICATION OBJECT AND REGION DETECTION USING HDCT METHOD": {
        "authors": [],
        "url": "https://scholar.archive.org/work/dxpfqsupnndshl3psihom6nlx4/access/wayback/http://www.jrret.com/paper/2016/Oct/jrret16Oct1.pdf",
        "ref_texts": ""
      },
      "Saliency Detection Based on Adaptive Boundary": {
        "authors": [],
        "url": "https://www.atlantis-press.com/article/25859514.pdf",
        "ref_texts": ""
      },
      "Saliency Based Spatial Partitioning for Global Image Representations": {
        "authors": [],
        "url": "https://poster.fel.cvut.cz/poster2016/proceedings/Section_C/C_041_Jose.pdf",
        "ref_texts": ""
      },
      "Efficient Saliency Aggregation via Soft-Voting Evolution": {
        "authors": [],
        "url": "https://pdfs.semanticscholar.org/cf35/fb774e475fc4845eae2bebccc528d34fff44.pdf",
        "ref_texts": ""
      },
      "Robust graph transduction": {
        "authors": [
          "Chen Gong"
        ],
        "url": "https://opus.lib.uts.edu.au/bitstream/10453/102708/2/02whole.pdf",
        "ref_texts": ""
      },
      "Saliency Detection based on Global Color Distribution and Active Contour Analysis": {
        "authors": [],
        "url": "https://koreascience.kr/article/JAKO201607959403780.pdf",
        "ref_texts": ""
      },
      "\u5c42\u6b21\u56fe\u878d\u5408\u7684\u663e\u8457\u6027\u68c0\u6d4b": {
        "authors": [],
        "url": "http://give.zju.edu.cn/select/cengcitu.pdf",
        "ref_texts": ""
      },
      "Smoothness \u52a0\u5f3a\u7684\u5168\u5c40\u548c\u5c40\u90e8\u663e\u8457\u76ee\u6807\u68c0\u6d4b": {
        "authors": [],
        "url": "http://www.shcas.net/jsjyup/pdf/2016/12/Smoothness%E5%8A%A0%E5%BC%BA%E7%9A%84%E5%85%A8%E5%B1%80%E5%92%8C%E5%B1%80%E9%83%A8%E6%98%BE%E8%91%97%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B.pdf",
        "ref_texts": ""
      },
      "\u57fa\u4e8e\u533a\u57df\u5408\u5e76\u7684\u56fe\u50cf\u663e\u8457\u6027\u68c0\u6d4b": {
        "authors": [],
        "url": "https://www.jcad.cn/cn/article/pdf/preview/5a46d072-10ca-45ad-9d85-922c96e930a1.pdf",
        "ref_texts": ""
      },
      "\u878d\u5408\u80cc\u666f\u611f\u77e5\u548c\u989c\u8272\u5bf9\u6bd4\u7684\u663e\u8457\u6027\u68c0\u6d4b\u65b9\u6cd5": {
        "authors": [],
        "url": "https://www.jcad.cn/cn/article/pdf/preview/bd4bd609-7910-44f0-91f6-4c6c88c16fd9.pdf",
        "ref_texts": ""
      },
      "\u57fa\u4e8e\u591a\u5c3a\u5ea6\u5f20\u91cf\u7a7a\u95f4\u7684\u6539\u8fdb Itti \u89c6\u89c9\u663e\u8457\u6027\u68c0\u6d4b": {
        "authors": [],
        "url": "https://www.china-simulation.com/CN/article/downloadArticleFile.do?attachType=PDF&id=2123",
        "ref_texts": ""
      },
      "\u878d\u5408\u4f4e\u5c42\u548c\u9ad8\u5c42\u7279\u5f81\u56fe\u8868\u793a\u7684\u56fe\u50cf\u663e\u8457\u6027\u68c0\u6d4b\u7b97\u6cd5": {
        "authors": [],
        "url": "https://www.jcad.cn/cn/article/pdf/preview/0abde615-1c84-459c-9fc0-d9c8fa3a0ef8.pdf",
        "ref_texts": ""
      },
      "\u4eee\u60f3\u8d85\u753b\u7d20\u3068\u5927\u57df\u7684\u7279\u5fb4\u306b\u3088\u308b\u9818\u57df\u5206\u5272\u3068\u80cc\u666f\u3068\u76ee\u7acb\u5bfe\u8c61\u7269\u306e\u62bd\u51fa": {
        "authors": [],
        "url": "https://www.jstage.jst.go.jp/article/ieejeiss/136/2/136_180/_pdf",
        "ref_texts": ""
      },
      "Visual saliency based on multiscale deep features": {
        "authors": [],
        "url": "https://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Li_Visual_Saliency_Based_2015_CVPR_paper.pdf",
        "ref_texts": ""
      },
      "Salient object detection: A benchmark": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1501.02741",
        "ref_texts": ""
      },
      "Saliency detection by multi-context deep learning": {
        "authors": [],
        "url": "https://openaccess.thecvf.com/content_cvpr_2015/papers/Zhao_Saliency_Detection_by_2015_CVPR_paper.pdf",
        "ref_texts": ""
      },
      "Deep networks for saliency detection via local estimation and global search": {
        "authors": [],
        "url": "https://openaccess.thecvf.com/content_cvpr_2015/papers/Wang_Deep_Networks_for_2015_CVPR_paper.pdf",
        "ref_texts": ""
      },
      "Hierarchical image saliency detection on extended CSSD": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1408.5418",
        "ref_texts": ""
      },
      "Saliency detection via cellular automata": {
        "authors": [],
        "url": "https://openaccess.thecvf.com/content_cvpr_2015/papers/Qin_Saliency_Detection_via_2015_CVPR_paper.pdf",
        "ref_texts": ""
      },
      "Minimum barrier salient object detection at 80 fps": {
        "authors": [
          "Jianming Zhang",
          "Stan Sclaroff",
          "Zhe Lin",
          "Xiaohui Shen",
          "Brian Price",
          "Radomir Mech"
        ],
        "url": "http://openaccess.thecvf.com/content_iccv_2015/papers/Zhang_Minimum_Barrier_Salient_ICCV_2015_paper.pdf",
        "ref_texts": ""
      },
      "Salient object detection via bootstrap learning": {
        "authors": [],
        "url": "https://openaccess.thecvf.com/content_cvpr_2015/papers/Tong_Salient_Object_Detection_2015_CVPR_paper.pdf",
        "ref_texts": ""
      },
      "Exploiting global priors for RGB-D saliency detection": {
        "authors": [],
        "url": "https://www.cv-foundation.org/openaccess/content_cvpr_workshops_2015/W14/papers/Ren_Exploiting_Global_Priors_2015_CVPR_paper.pdf",
        "ref_texts": ""
      },
      "Inner and inter label propagation: salient object detection in the wild": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1505.07192",
        "ref_texts": ""
      },
      "Salient region detection via high-dimensional color transform and local spatial support": {
        "authors": [],
        "url": "http://www.kresttechnology.com/krest-academic-projects/krest-mtech-projects/ECE/M-TECH%20DSPDIP%202019-20/M-TECH%20DSP%20-BP-2019-2020/40%20basepaper.pdf",
        "ref_texts": ""
      },
      "Cosaliency detection based on intrasaliency prior transfer and deep intersaliency mining": {
        "authors": [
          "Constance Roberts"
        ],
        "url": "https://ueaeprints.uea.ac.uk/id/eprint/62880/1/Accepted_manuscript.pdf",
        "ref_texts": ""
      },
      "Visual search at pinterest": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1505.07647",
        "ref_texts": ""
      },
      "Saliency propagation from simple to difficult": {
        "authors": [],
        "url": "https://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Gong_Saliency_Propagation_From_2015_CVPR_paper.pdf",
        "ref_texts": ""
      },
      "A weighted sparse coding framework for saliency detection": {
        "authors": [],
        "url": "https://openaccess.thecvf.com/content_cvpr_2015/papers/Li_A_Weighted_Sparse_2015_CVPR_paper.pdf",
        "ref_texts": ""
      },
      "Depth-aware salient object detection using anisotropic center-surround difference": {
        "authors": [],
        "url": "https://mcg.nju.edu.cn/publication/2015/spic15-jur.pdf",
        "ref_texts": ""
      },
      "Traditional saliency reloaded: A good old model in new shape": {
        "authors": [],
        "url": "https://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Frintrop_Traditional_Saliency_Reloaded_2015_CVPR_paper.pdf",
        "ref_texts": ""
      },
      "PISA: Pixelwise image saliency by aggregating complementary appearance contrast measures with edge-preserving coherence": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1505.03227",
        "ref_texts": ""
      },
      "Harf: Hierarchy-associated rich features for salient object detection": {
        "authors": [
          "Wenbin Zou",
          "Nikos Komodakis"
        ],
        "url": "https://openaccess.thecvf.com/content_iccv_2015/papers/Zou_HARF_Hierarchy-Associated_Rich_ICCV_2015_paper.pdf",
        "ref_texts": ""
      },
      "Generic promotion of diffusion-based salient object detection": {
        "authors": [
          "Peng Jiang",
          "Nuno Vasconcelos",
          "Jingliang Peng"
        ],
        "url": "https://openaccess.thecvf.com/content_iccv_2015/papers/Jiang_Generic_Promotion_of_ICCV_2015_paper.pdf",
        "ref_texts": ""
      },
      "Normalized cut-based saliency detection by adaptive multi-level region merging": {
        "authors": [],
        "url": "https://gcatnjust.github.io/ChenGong/paper/fu_tip15.pdf",
        "ref_texts": ""
      },
      "Salient object detection via objectness measure": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1506.07363",
        "ref_texts": ""
      },
      "Sparsity-guided saliency detection for remote sensing images": {
        "authors": [],
        "url": "https://www.spiedigitallibrary.org/journalArticle/Download?fullDOI=10.1117/1.JRS.9.095055",
        "ref_texts": ""
      },
      "Encoding based saliency detection for videos and images": {
        "authors": [],
        "url": "https://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Mauthner_Encoding_Based_Saliency_2015_CVPR_paper.pdf",
        "ref_texts": ""
      },
      "SaliencyRank: Two-stage manifold ranking for salient object detection": {
        "authors": [],
        "url": "https://link.springer.com/content/pdf/10.1007/s41095-015-0028-y.pdf",
        "ref_texts": ""
      },
      "Dynamically encoded actions based on spacetime saliency": {
        "authors": [],
        "url": "http://openaccess.thecvf.com/content_cvpr_2015/papers/Feichtenhofer_Dynamically_Encoded_Actions_2015_CVPR_paper.pdf",
        "ref_texts": ""
      },
      "Integrating multi-features fusion and gestalt principles for pavement crack detection": {
        "authors": [],
        "url": "https://www.jcad.cn/en/article/pdf/preview/11f3ecb9-28a0-4a8f-b7f1-1be8e734307d.pdf",
        "ref_texts": ""
      },
      "Visual attention model based on statistical properties of neuron responses": {
        "authors": [],
        "url": "https://www.nature.com/articles/srep08873.pdf",
        "ref_texts": ""
      },
      "\u57fa\u4e8e\u6761\u4ef6\u968f\u673a\u573a\u548c\u56fe\u50cf\u5206\u5272\u7684\u663e\u8457\u6027\u68c0\u6d4b": {
        "authors": [],
        "url": "http://www.aas.net.cn/fileZDHXB/journal/article/zdhxb/2015/4/PDF/2015-4-711.pdf",
        "ref_texts": ""
      },
      "A site entropy rate and degree centrality based algorithm for image co-segmentation": {
        "authors": [
          "Souradeep Chakraborty"
        ],
        "url": "http://cse.iitkgp.ac.in/~pabitra/paper/jvcir15.pdf",
        "ref_texts": ""
      },
      "Discovering salient objects from videos using spatiotemporal salient region detection": {
        "authors": [
          "Gerry Murray"
        ],
        "url": "https://bura.brunel.ac.uk/bitstream/2438/11462/1/Fulltext.pdf",
        "ref_texts": ""
      },
      "Visual salience learning via low rank matrix recovery": {
        "authors": [],
        "url": "https://projet.liris.cnrs.fr/imagine/pub/proceedings/ACCV-2014/pages/PDF/263.pdf",
        "ref_texts": ""
      },
      "Saliency maps on image hierarchies": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1508.04586",
        "ref_texts": ""
      },
      "\u878d\u5408\u591a\u7279\u5f81\u4e0e\u683c\u5f0f\u5854\u7406\u8bba\u7684\u8def\u9762\u88c2\u7f1d\u68c0\u6d4b": {
        "authors": [],
        "url": "https://www.jcad.cn/cn/article/pdf/preview/11f3ecb9-28a0-4a8f-b7f1-1be8e734307d.pdf",
        "ref_texts": ""
      },
      "A parametric spectral model for texture-based salience": {
        "authors": [],
        "url": "https://research-repository.st-andrews.ac.uk/bitstream/handle/10023/15957/gcprfinal_106.pdf?sequence=1&isAllowed=y",
        "ref_texts": ""
      },
      "Weakly supervised learning for salient object detection": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1501.07492",
        "ref_texts": ""
      },
      "Salient object detection via background contrast": {
        "authors": [],
        "url": "https://cis.temple.edu/~latecki/Papers/ZhouICIP2014.pdf",
        "ref_texts": ""
      },
      "Preliminary Study Towards a Fuzzy Model for Visual Attention.": {
        "authors": [
          "Anca Ralescu",
          "Isabelle Bloch",
          "Roberto Cesar"
        ],
        "url": "https://perso.telecom-paristech.fr/bloch/papers/proceedings/IJCAI-FLinAI-2015.pdf",
        "ref_texts": ""
      },
      "Salient object detection using window mask transferring with multi-layer background contrast": {
        "authors": [],
        "url": "https://projet.liris.cnrs.fr/imagine/pub/proceedings/ACCV-2014/pages/PDF/304.pdf",
        "ref_texts": ""
      },
      "Improved Bayesian saliency detection based on bing and graph model": {
        "authors": [],
        "url": "https://benthamopen.com/contents/pdf/TOCSJ/TOCSJ-9-648.pdf",
        "ref_texts": ""
      },
      "Visual saliency estimation A pre-attentive cognitive and context-aware approach": {
        "authors": [
          "Amanda Shannon"
        ],
        "url": "https://scholarsarchive.library.albany.edu/cgi/viewcontent.cgi?article=2367&context=legacy-etd",
        "ref_texts": ""
      },
      "A comparative study of saliency aggregation for salient object detection": {
        "authors": [],
        "url": "http://shuhanchen.net/papers/ICIG2015.pdf",
        "ref_texts": ""
      },
      "Visual utility: A framework for focusing computer vision algorithms": {
        "authors": [
          "Mark Desnoyer"
        ],
        "url": "https://kilthub.cmu.edu/ndownloader/files/12259826",
        "ref_texts": ""
      },
      "Attentional Scene-Exploration and Object Discovery in Image and RGB-D Data": {
        "authors": [],
        "url": "https://www.inf.uni-hamburg.de/en/inst/ab/cv/media/frintrop-paper-bonn/gmg-etal-ki2015.pdf",
        "ref_texts": ""
      },
      "Extraction of Salient Object Regions by Virtual Super Pixel and Global Feature": {
        "authors": [],
        "url": "http://avestia.com/EECSS2015_Proceedings/files/papers/MVML326.pdf",
        "ref_texts": ""
      },
      "3D video quality assessment": {
        "authors": [],
        "url": "https://open.library.ubc.ca/media/download/pdf/24/1.0166613/1",
        "ref_texts": ""
      },
      "Image Patch Selection Using A Novel Discriminative Saliency Calculation Model.": {
        "authors": [],
        "url": "https://www.metaljournal.com.ua/assets/Journal/english-edition/MMI_2015_9/006_Xiuming-Zou.pdf",
        "ref_texts": ""
      },
      "Saliency Detection via Cellular Automata Supplementary Materials": {
        "authors": [],
        "url": "http://openaccess.thecvf.com/content_cvpr_2015/supplemental/Qin_Saliency_Detection_via_2015_CVPR_supplemental.pdf",
        "ref_texts": ""
      },
      "Supplementary Material for submission 2147: Traditional Saliency Reloaded: A Good Old Model in New Shape": {
        "authors": [],
        "url": "http://openaccess.thecvf.com/content_cvpr_2015/supplemental/Frintrop_Traditional_Saliency_Reloaded_2015_CVPR_supplemental.pdf",
        "ref_texts": ""
      },
      "Forming A Random Field via Stochastic Cliques: From Random Graphs to Fully Connected Random Fields": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1506.09110",
        "ref_texts": ""
      },
      "Deep Networks for Saliency Detection via Local Estimation and Global Search Supplementary Material": {
        "authors": [],
        "url": "http://openaccess.thecvf.com/content_cvpr_2015/supplemental/Wang_Deep_Networks_for_2015_CVPR_supplemental.pdf",
        "ref_texts": ""
      },
      "Saliency Detection Based on Semi-Supervised Learning": {
        "authors": [],
        "url": "https://koreascience.kr/article/CFKO201536257095891.pdf",
        "ref_texts": ""
      },
      "\u57fa\u4e8e\u773c\u52a8\u5b9e\u9a8c\u7684\u663e\u8457\u76ee\u6807\u68c0\u6d4b\u56fe\u50cf\u5e93\u6784\u5efa": {
        "authors": [],
        "url": "http://cjbme.csbme.org/CN/article/downloadArticleFile.do?attachType=PDF&id=313",
        "ref_texts": ""
      },
      "\ub79c\ub364 \uc6cc\ud06c\ub97c \uc774\uc6a9\ud55c \uc601\uc0c1 \uba40\ud2f0\ubbf8\ub514\uc5b4 \ub370\uc774\ud130\uc758 \uc911\uc694\ub3c4 \uac80\ucd9c \uc5f0\uad6c": {
        "authors": [],
        "url": "https://koreascience.kr/article/JAKO201520165686792.pdf",
        "ref_texts": ""
      },
      "D\u00e9tection d'objets saillants dans des images en couleurs.": {
        "authors": [],
        "url": "https://dspace.ummto.dz/bitstreams/a719d4f3-500e-4daf-a8d9-f5f14677cebd/download",
        "ref_texts": ""
      },
      "Saliency optimization from robust background detection": {
        "authors": [],
        "url": "https://openaccess.thecvf.com/content_cvpr_2014/papers/Zhu_Saliency_Optimization_from_2014_CVPR_paper.pdf",
        "ref_texts": ""
      },
      "Rolling guidance filter": {
        "authors": [],
        "url": "https://jiaya.me/file/papers/[ECCV2014]RollingGuidanceFilter_5M.pdf",
        "ref_texts": ""
      },
      "RGBD salient object detection: A benchmark and algorithms": {
        "authors": [
          "Houwen Peng",
          "Bing Li",
          "Weihua Xiong",
          "Weiming Hu",
          "Rongrong Ji"
        ],
        "url": "https://projet.liris.cnrs.fr/imagine/pub/proceedings/ECCV-2014/papers/8691/86910092.pdf",
        "ref_texts": ""
      },
      "Saliency detection on light field": {
        "authors": [],
        "url": "https://openaccess.thecvf.com/content_cvpr_2014/papers/Li_Saliency_Detection_on_2014_CVPR_paper.pdf",
        "ref_texts": ""
      },
      "Discriminative blur detection features": {
        "authors": [],
        "url": "https://openaccess.thecvf.com/content_cvpr_2014/papers/Shi_Discriminative_Blur_Detection_2014_CVPR_paper.pdf",
        "ref_texts": ""
      },
      "Salient region detection via high-dimensional color transform": {
        "authors": [],
        "url": "https://www.cv-foundation.org/openaccess/content_cvpr_2014/papers/Kim_Salient_Region_Detection_2014_CVPR_paper.pdf",
        "ref_texts": ""
      },
      "Saliency tree: A novel saliency detection framework": {
        "authors": [],
        "url": "https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=86ed470a36af7d69ba39f121e1cbebf9508262fb",
        "ref_texts": ""
      },
      "What is a salient object? A dataset and a baseline model for salient object detection": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1412.5027",
        "ref_texts": ""
      },
      "Deep joint task learning for generic object extraction": {
        "authors": [
          "Xiaolong Wang",
          "Liliang Zhang",
          "Liang Lin",
          "Zhujin Liang",
          "Wangmeng Zuo"
        ],
        "url": "https://proceedings.neurips.cc/paper_files/paper/2014/file/d81f9c1be2e08964bf9f24b15f0e4900-Paper.pdf",
        "ref_texts": ""
      },
      "Co-saliency detection based on region-level fusion and pixel-level refinement": {
        "authors": [],
        "url": "https://scholar.archive.org/work/wjkysss4djejthmtblqfm7ibaq/access/wayback/http://www.wzou.eu:80/papers/2014ICME.pdf",
        "ref_texts": ""
      },
      "Regional principal color based saliency detection": {
        "authors": [],
        "url": "https://journals.plos.org/plosone/article/file?id=10.1371/journal.pone.0112475&type=printable",
        "ref_texts": ""
      },
      "Comparing salient object detection results without ground truth": {
        "authors": [
          "Long Mai",
          "Feng Liu"
        ],
        "url": "https://projet.liris.cnrs.fr/imagine/pub/proceedings/ECCV-2014/papers/8691/86910076.pdf",
        "ref_texts": ""
      },
      "A cognitive approach for object discovery": {
        "authors": [],
        "url": "https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=6845cc4e9ceb13e8204cfe8ec818c91b0cc21f52",
        "ref_texts": ""
      },
      "Saliency detection within a deep convolutional architecture": {
        "authors": [
          "Yuetan Lin",
          "Shu Kong",
          "Donghui Wang",
          "Yueting Zhuang"
        ],
        "url": "https://cdn.aaai.org/ocs/ws/ws1159/8725-38085-1-PB.pdf",
        "ref_texts": ""
      },
      "A prior-based graph for salient object detection": {
        "authors": [],
        "url": "http://kehinger.com/pdf/ICIP2014_Zhang.pdf",
        "ref_texts": ""
      },
      "Semantic object selection": {
        "authors": [],
        "url": "http://openaccess.thecvf.com/content_cvpr_2014/papers/Ahmed_Semantic_Object_Selection_2014_CVPR_paper.pdf",
        "ref_texts": ""
      },
      "A closer look at context: From coxels to the contextual emergence of object saliency": {
        "authors": [
          "Rotem Mairon",
          "Ohad Ben"
        ],
        "url": "https://projet.liris.cnrs.fr/imagine/pub/proceedings/ECCV-2014/papers/8693/86930708.pdf",
        "ref_texts": ""
      },
      "Automatic image segmentation using salient key point extraction and star shape prior": {
        "authors": [
          "Xiangli Liao"
        ],
        "url": "https://viplab.cis.um.edu.mo/publications/journal/Automatic%20image%20segmentation%20using%20salient%20key%20point%20extraction%20and%20star%20shape%20prior.pdf",
        "ref_texts": ""
      },
      "Journal of visual communication and image representation": {
        "authors": [
          "Chenyou Fan"
        ],
        "url": "https://earbmc.sitehost.iu.edu/pubs/Crandall_deepdiary.pdf",
        "ref_texts": ""
      },
      "Saliency detection via nonlocal minimization": {
        "authors": [],
        "url": "https://projet.liris.cnrs.fr/imagine/pub/proceedings/ACCV-2014/pages/PDF/202.pdf",
        "ref_texts": ""
      },
      "A reverse hierarchy model for predicting eye fixations": {
        "authors": [],
        "url": "http://openaccess.thecvf.com/content_cvpr_2014/papers/Shi_A_Reverse_Hierarchy_2014_CVPR_paper.pdf",
        "ref_texts": ""
      },
      "Saliency detection using regression trees on hierarchical image segments": {
        "authors": [],
        "url": "https://infoscience.epfl.ch/record/201936/files/SALIENCY%20DETECTION%20USING%20REGRESSION%20TREES%20ON%20HIERARCHICAL%20IMAGE%20SEGMENTS.pdf",
        "ref_texts": ""
      },
      "Salient object detection using bipartite dictionary": {
        "authors": [],
        "url": "https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=f0b8872f98613fe1a1e631842b12b6a72e61e2c3",
        "ref_texts": ""
      },
      "Information divergence based saliency detection with a global center-surround mechanism": {
        "authors": [
          "Ibrahim M",
          "Christopher Hollitt",
          "Mengjie Zhang"
        ],
        "url": "https://projet.liris.cnrs.fr/imagine/pub/proceedings/ICPR-2014/data/5209d428.pdf",
        "ref_texts": ""
      },
      "Image retargeting by content-aware synthesis": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1403.6566",
        "ref_texts": ""
      },
      "Enhancement of Salient Image Regions for Visual Object Detection": {
        "authors": [],
        "url": "https://publications.lib.chalmers.se/records/fulltext/205180/205180.pdf",
        "ref_texts": ""
      },
      "Salient-region detection in a multi-level framework of image smoothing with over-segmentation": {
        "authors": [],
        "url": "https://projet.liris.cnrs.fr/imagine/pub/proceedings/ICIP-2014/Papers/1569914653.pdf",
        "ref_texts": ""
      },
      "Sequence Level Salient Object Proposals for Generic Object Detection in Video": {
        "authors": [],
        "url": "https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=8e1527d2eb1f38bd2a2e3c7eb2b1151f5d1f0aac",
        "ref_texts": ""
      },
      "Semantic-oriented Object Segmentation": {
        "authors": [],
        "url": "https://theses.hal.science/tel-01127132/file/2014ISAR0007.pdf",
        "ref_texts": ""
      },
      "\u4eee\u60f3\u8d85\u753b\u7d20\u3068\u5927\u57df\u7684\u7279\u5fb4\u306b\u3088\u308b\u9818\u57df\u5206\u5272\u3068\u76ee\u7acb\u5bfe\u8c61\u7269\u306e\u62bd\u51fa": {
        "authors": [],
        "url": "https://www.jstage.jst.go.jp/article/fss/30/0/30_224/_pdf",
        "ref_texts": ""
      },
      "Salient object detection: A discriminative regional feature integration approach": {
        "authors": [
          "Huaizu Jiang",
          "Jingdong Wang",
          "Zejian Yuan",
          "Yang Wu",
          "Nanning Zheng",
          "Shipeng Li"
        ],
        "url": "https://openaccess.thecvf.com/content_cvpr_2013/papers/Jiang_Salient_Object_Detection_2013_CVPR_paper.pdf",
        "ref_texts": ""
      },
      "Saliency detection: A boolean map approach": {
        "authors": [
          "Jianming Zhang",
          "Stan Sclaroff"
        ],
        "url": "https://www.cv-foundation.org/openaccess/content_iccv_2013/papers/Zhang_Saliency_Detection_A_2013_ICCV_paper.pdf",
        "ref_texts": ""
      },
      "Efficient salient region detection with soft image abstraction": {
        "authors": [
          "Ming Cheng",
          "Jonathan Warrell",
          "Yan Lin",
          "Shuai Zheng",
          "Vibhav Vineet",
          "Nigel Crook"
        ],
        "url": "https://openaccess.thecvf.com/content_iccv_2013/papers/Cheng_Efficient_Salient_Region_2013_ICCV_paper.pdf",
        "ref_texts": ""
      },
      "Salient region detection by ufo: Uniqueness, focusness and objectness": {
        "authors": [
          "Peng Jiang",
          "Haibin Ling",
          "Jingyi Yu",
          "Jingliang Peng"
        ],
        "url": "https://www.cv-foundation.org/openaccess/content_iccv_2013/papers/Jiang_Salient_Region_Detection_2013_ICCV_paper.pdf",
        "ref_texts": ""
      },
      "ITI-CERTH participation to TRECVID 2013.": {
        "authors": [],
        "url": "https://npit.github.io/pdfs/publications/trecvid15.pdf",
        "ref_texts": ""
      },
      "Salient object detection based on regional contrast and relative spatial compactness": {
        "authors": [],
        "url": "https://koreascience.kr/article/JAKO201304163995942.pdf",
        "ref_texts": ""
      },
      "Saliency Detection: A Boolean Map Approach Supplementary Materials": {
        "authors": [],
        "url": "https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=99949108ac4b1a058d38dd1bfe8981e08ba643a5",
        "ref_texts": ""
      }
    }
  },
  {
    "title": "pvnet: pixel-wise voting network for 6dof pose estimation",
    "id": 5,
    "valid_pdf_number": "621/777",
    "matched_pdf_number": "0/621",
    "matched_rate": 0.0,
    "citations": {
      "A survey of 6dof object pose estimation methods for different application scenarios": {
        "authors": [
          "Jian Guan",
          "Yingming Hao",
          "Qingxiao Wu",
          "Sicong Li",
          "Yingjian Fang"
        ],
        "url": "https://www.mdpi.com/1424-8220/24/4/1076/pdf",
        "ref_texts": "46. Peng, S.; Liu, Y.; Huang, Q.; Zhou, X.; Bao, H. Pvnet: Pixel-wise voting network for 6Dof pose estimation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, Long Beach, CA, USA, 15\u201320 June 2019; pp. 4561\u20134570.",
        "ref_ids": [
          "46"
        ]
      },
      "Challenges for monocular 6d object pose estimation in robotics": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2307.12172",
        "ref_texts": "[28] S. Peng, X. Zhou, Y . Liu, H. Lin, Q. Huang, and H. Bao, \u201cPvnet: Pixel-wise voting network for 6dof object pose estimation,\u201d IEEE Transactions on Pattern Analysis and Machine Intelligence , vol. 44, no. 6, pp. 3212\u20133223, 2022.",
        "ref_ids": [
          "28"
        ]
      },
      "Se (3) diffusion model-based point cloud registration for robust 6d object pose estimation": {
        "authors": [],
        "url": "https://proceedings.neurips.cc/paper_files/paper/2023/file/43069caa6776eac8bca4bfd74d4a476d-Paper-Conference.pdf",
        "ref_texts": "[41] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In CVPR , 2019.",
        "ref_ids": [
          "41"
        ]
      },
      "POPE: 6-DoF Promptable Pose Estimation of Any Object in Any Scene with One Reference": {
        "authors": [
          "Zhiwen Fan",
          "Panwang Pan",
          "Peihao Wang",
          "Yifan Jiang",
          "Dejia Xu",
          "Zhangyang Wang"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024W/LIMIT/papers/Fan_POPE_6-DoF_Promptable_Pose_Estimation_of_Any_Object_in_Any_CVPRW_2024_paper.pdf",
        "ref_texts": "[46] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 4561\u20134570, 2019. 1",
        "ref_ids": [
          "46"
        ]
      },
      "Sg-bot: Object rearrangement via coarse-to-fine robotic imagination on scene graphs": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2309.12188",
        "ref_texts": "[43] S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao, \u201cPvnet: Pixel-wise voting network for 6dof pose estimation,\u201d in CVPR , 2019.",
        "ref_ids": [
          "43"
        ]
      },
      "6d-diff: A keypoint diffusion framework for 6d object pose estimation": {
        "authors": [
          "Li Xu",
          "Haoxuan Qu",
          "Yujun Cai",
          "Jun Liu"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Xu_6D-Diff_A_Keypoint_Diffusion_Framework_for_6D_Object_Pose_Estimation_CVPR_2024_paper.pdf",
        "ref_texts": "[44] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 4561\u2013",
        "ref_ids": [
          "44"
        ]
      },
      "Secondpose: Se (3)-consistent dual-stream feature fusion for category-level pose estimation": {
        "authors": [
          "Yamei Chen",
          "Yan Di",
          "Guangyao Zhai",
          "Fabian Manhardt",
          "Chenyangguang Zhang",
          "Ruida Zhang",
          "Federico Tombari",
          "Nassir Navab",
          "Benjamin Busam"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Chen_SecondPose_SE3-Consistent_Dual-Stream_Feature_Fusion_for_Category-Level_Pose_Estimation_CVPR_2024_paper.pdf",
        "ref_texts": "[33] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) , June 2019. 2",
        "ref_ids": [
          "33"
        ]
      },
      "Hipose: Hierarchical binary surface encoding and correspondence pruning for rgb-d 6dof object pose estimation": {
        "authors": [
          "Yongliang Lin",
          "Yongzhi Su",
          "Praveen Nathan",
          "Sandeep Inuganti",
          "Yan Di",
          "Martin Sundermeyer",
          "Fabian Manhardt",
          "Didier Stricker",
          "Jason Rambach",
          "Yu Zhang"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Lin_HiPose_Hierarchical_Binary_Surface_Encoding_and_Correspondence_Pruning_for_RGB-D_CVPR_2024_paper.pdf",
        "ref_texts": "[42] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 4561\u2013",
        "ref_ids": [
          "42"
        ]
      },
      "Joint Reconstruction of 3D Human and Object via Contact-Based Refinement Transformer": {
        "authors": [
          "Hyeongjin Nam",
          "Daniel Sungho",
          "Gyeongsik Moon",
          "Kyoung Mu"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Nam_Joint_Reconstruction_of_3D_Human_and_Object_via_Contact-Based_Refinement_CVPR_2024_paper.pdf",
        "ref_texts": "[32] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. PVNet: Pixel-wise voting network for 6DoF pose estimation. In CVPR , 2019. 3",
        "ref_ids": [
          "32"
        ]
      },
      "Instance-adaptive and geometric-aware keypoint learning for category-level 6d object pose estimation": {
        "authors": [
          "Xiao Lin",
          "Wenfei Yang",
          "Yuan Gao",
          "Tianzhu Zhang"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Lin_Instance-Adaptive_and_Geometric-Aware_Keypoint_Learning_for_Category-Level_6D_Object_Pose_CVPR_2024_paper.pdf",
        "ref_texts": "[27] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In IEEE/CVF Conference onComputer Vision and Pattern Recognition (CVPR), 2019. 1, 2, 3",
        "ref_ids": [
          "27"
        ]
      },
      "Object pose estimation via the aggregation of diffusion features": {
        "authors": [
          "Tianfu Wang",
          "Guosheng Hu",
          "Hongguang Wang"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Wang_Object_Pose_Estimation_via_the_Aggregation_of_Diffusion_Features_CVPR_2024_paper.pdf",
        "ref_texts": "[28] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 4561\u2013",
        "ref_ids": [
          "28"
        ]
      },
      "Mrc-net: 6-dof pose estimation with multiscale residual correlation": {
        "authors": [
          "Yuelong Li",
          "Yafei Mao",
          "Raja Bala",
          "Sunil Hadap"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Li_MRC-Net_6-DoF_Pose_Estimation_with_MultiScale_Residual_Correlation_CVPR_2024_paper.pdf",
        "ref_texts": "[40] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. PVNet: Pixel-wise voting network for 6dof pose estimation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 4561\u20134570, 2019. 2, 6, 7",
        "ref_ids": [
          "40"
        ]
      },
      "Learning to estimate 6dof pose from limited data: A few-shot, generalizable approach using rgb images": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2306.07598",
        "ref_texts": "[74] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 4561\u2013",
        "ref_ids": [
          "74"
        ]
      },
      "FocalPose++: Focal Length and Object Pose Estimation via Render and Compare": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2312.02985",
        "ref_texts": "[15] S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao, \u201cPVNet: Pixel-wise voting network for 6DoF pose estimation,\u201d in CVPR , 2019.",
        "ref_ids": [
          "15"
        ]
      },
      "Ar overlay: Training image pose estimation on curved surface in a synthetic way": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2409.14577",
        "ref_texts": "[34] S. Peng, Y. Liu, Q. Huang, H. Bao, and X. Zhou, \u201cPVNet: Pixel-wise Voting Network for 6DoF Pose Estimation,\u201d Dec. 2018, arXiv:1812.11788 [cs].",
        "ref_ids": [
          "34",
          "cs"
        ]
      },
      "Acr-pose: Adversarial canonical representation reconstruction network for category level 6d object pose estimation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2111.10524",
        "ref_texts": "[29] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 4561\u2013",
        "ref_ids": [
          "29"
        ]
      },
      "Transpose: 6d object pose estimation with geometry-aware transformer": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2310.16279",
        "ref_texts": "[32] Peng, S., Liu, Y., Huang, Q., Zhou, X., Bao, H., 2019. Pvnet: Pixelwise voting network for 6dof pose estimation, in: Proceedings of the IEEE/CVFConferenceonComputerVisionandPatternRecognition, pp. 4561\u20134570.",
        "ref_ids": [
          "32"
        ]
      },
      "Towards Co-Evaluation of Cameras HDR and Algorithms for Industrial-Grade 6DoF Pose Estimation": {
        "authors": [
          "Agastya Kalra",
          "Guy Stoppi",
          "Dmitrii Marin",
          "Vage Taamazyan",
          "Aarrushi Shandilya",
          "Rishav Agarwal",
          "Anton Boykov",
          "Tze Hao",
          "Michael Stark"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Kalra_Towards_Co-Evaluation_of_Cameras_HDR_and_Algorithms_for_Industrial-Grade_6DoF_CVPR_2024_paper.pdf",
        "ref_texts": "[53] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 4561\u2013",
        "ref_ids": [
          "53"
        ]
      },
      "Robust Category-Level 3D Pose Estimation from Diffusion-Enhanced Synthetic Data": {
        "authors": [
          "Jiahao Yang",
          "Wufei Ma",
          "Angtian Wang",
          "Xiaoding Yuan",
          "Alan Yuille",
          "Adam Kortylewski"
        ],
        "url": "https://openaccess.thecvf.com/content/WACV2024/papers/Yang_Robust_Category-Level_3D_Pose_Estimation_From_Diffusion-Enhanced_Synthetic_Data_WACV_2024_paper.pdf",
        "ref_texts": "[25] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) , June 2019. 1",
        "ref_ids": [
          "25"
        ]
      },
      "Hoisdf: Constraining 3d hand-object pose estimation with global signed distance fields": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2402.17062",
        "ref_texts": "[41] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 4561\u2013",
        "ref_ids": [
          "41"
        ]
      },
      "DVMNet: Computing Relative Pose for Unseen Objects Beyond Hypotheses": {
        "authors": [
          "Chen Zhao",
          "Tong Zhang",
          "Zheng Dang",
          "Mathieu Salzmann"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Zhao_DVMNet_Computing_Relative_Pose_for_Unseen_Objects_Beyond_Hypotheses_CVPR_2024_paper.pdf",
        "ref_texts": "[24] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 4561\u20134570, 2019. 2",
        "ref_ids": [
          "24"
        ]
      },
      "Confronting ambiguity in 6d object pose estimation via score-based diffusion on se (3)": {
        "authors": [
          "Ching Hsiao",
          "Wei Chen",
          "Kung Yang",
          "Yi Lee"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Hsiao_Confronting_Ambiguity_in_6D_Object_Pose_Estimation_via_Score-Based_Diffusion_CVPR_2024_paper.pdf",
        "ref_texts": "[44] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In Proc. IEEE Conf. on Computer Vision and Pattern Recognition (CVPR) , pages 4561\u20134570, 2019. 3",
        "ref_ids": [
          "44"
        ]
      },
      "Locposenet: Robust location prior for unseen object pose estimation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2211.16290",
        "ref_texts": "[25] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 4561\u20134570, 2019. 2, 7",
        "ref_ids": [
          "25"
        ]
      },
      "GBOT: graph-based 3D object tracking for augmented reality-assisted assembly guidance": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2402.07677",
        "ref_texts": "[36] S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao. Pvnet: Pixelwise voting network for 6dof pose estimation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pp. 4561\u20134570, 2019.",
        "ref_ids": [
          "36"
        ]
      },
      "Learning Better Keypoints for Multi-Object 6DoF Pose Estimation": {
        "authors": [
          "Yangzheng Wu",
          "Michael Greenspan"
        ],
        "url": "https://openaccess.thecvf.com/content/WACV2024/papers/Wu_Learning_Better_Keypoints_for_Multi-Object_6DoF_Pose_Estimation_WACV_2024_paper.pdf",
        "ref_texts": "[40] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 4561\u2013",
        "ref_ids": [
          "40"
        ]
      },
      "Bridging Domain Gap for Flight-Ready Spaceborne Vision": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2409.11661",
        "ref_texts": "[99]Peng, S., Liu, Y., Huang, Q., Zhou, X., and Bao, H.,\u201cPVNet: Pixel-Wise Voting Network for 6DoFPose Estimation,\u201d 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) , 2019, pp. 4556\u20134565. https://doi.org/10.1109/ CVPR.2019.00469.",
        "ref_ids": [
          "99"
        ]
      },
      "Clipose: Category-level object pose estimation with pre-trained vision-language knowledge": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2402.15726",
        "ref_texts": "[5] S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao, \u201cPvnet: Pixelwise voting network for 6dof pose estimation,\u201d in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , 2019, pp. 4561\u20134570. 1",
        "ref_ids": [
          "5"
        ]
      },
      "An analysis of precision: occlusion and perspective geometry's role in 6D pose estimation": {
        "authors": [
          "Jeffrey Choate"
        ],
        "url": "https://link.springer.com/content/pdf/10.1007/s00521-023-09094-8.pdf",
        "ref_texts": "33. Parry Jonathon, Hubbard Sarah (2023) Review of sensor technology to support automated air-to-air refueling of a probe configured uncrewed aircraft. Sensors 23(2):99534. Peng S, Liu Y, Huang Q, Zhou X, Bao H (2019) Pvnet: pixelwise voting network for 6dof pose estimation. In: Proceedings of the IEEE/CVF Conference on Computer Vision and PatternRecognition, pp 4561\u20134570",
        "ref_ids": [
          "33"
        ]
      },
      "Effects of Markers in Training Datasets on the Accuracy of 6D Pose Estimation": {
        "authors": [
          "Janis Rosskamp",
          "Rene Weller",
          "Gabriel Zachmann"
        ],
        "url": "https://openaccess.thecvf.com/content/WACV2024/papers/Rosskamp_Effects_of_Markers_in_Training_Datasets_on_the_Accuracy_of_WACV_2024_paper.pdf",
        "ref_texts": "[21] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. PVNet: Pixel-wise voting network for 6dof pose estimation. In IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) , pages 4556\u20134565, 2019.",
        "ref_ids": [
          "21"
        ]
      },
      "RDPN6D: Residual-based Dense Point-wise Network for 6Dof Object Pose Estimation Based on RGB-D Images": {
        "authors": [
          "Wei Hong",
          "Yang Hung",
          "Song Chen"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024W/DLGC/papers/Hong_RDPN6D_Residual-based_Dense_Point-wise_Network_for_6Dof_Object_Pose_Estimation_CVPRW_2024_paper.pdf",
        "ref_texts": "[31] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 4561\u2013",
        "ref_ids": [
          "31"
        ]
      },
      "Source-Free and Image-Only Unsupervised Domain Adaptation for Category Level Object Pose Estimation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2401.10848",
        "ref_texts": "6-dof object pose from semantic keypoints. 2017 IEEE International Conference on Robotics and Automation (ICRA) , May 2017b. doi: 10.1109/icra.2017.7989233. URL http://dx. doi.org/10.1109/ICRA.2017.7989233 . Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) , Jun 2019. doi: 10.1109/cvpr.2019.00469. URL http://dx.doi.org/"
      },
      "KVN: Keypoints Voting Network with Differentiable RANSAC for Stereo Pose Estimation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2307.11543",
        "ref_texts": "[3] S. Peng, X. Zhou, Y . Liu, H. Lin, Q. Huang, and H. Bao, \u201cPvnet: Pixelwise voting network for 6dof object pose estimation,\u201d IEEE Transactions on Pattern Analysis and Machine Intelligence , vol. 44, no. 6, pp. 3212\u2013",
        "ref_ids": [
          "3"
        ]
      },
      "Towards Robust Automation of Surgical Systems via Digital Twin-based Scene Representations from Foundation Models": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2409.13107",
        "ref_texts": "[26] S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao, \u201cPvnet: Pixelwise voting network for 6dof pose estimation,\u201d in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , 2019, pp. 4561\u20134570.",
        "ref_ids": [
          "26"
        ]
      },
      "Gs-pose: Cascaded framework for generalizable segmentation-based 6d object pose estimation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2403.10683",
        "ref_texts": "[38] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In CVPR , 2019. 2",
        "ref_ids": [
          "38"
        ]
      },
      "Uncertainty-aware 3D Object-Level Mapping with Deep Shape Priors": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2309.09118",
        "ref_texts": "[23] S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao, \u201cPvnet: Pixelwise voting network for 6dof pose estimation,\u201d in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pp. 4561\u20134570, 2019.",
        "ref_ids": [
          "23"
        ]
      },
      "Embedded 3d reconstruction of dynamic objects in real time for maritime situational awareness pictures": {
        "authors": [
          "Felix Sattler"
        ],
        "url": "https://link.springer.com/content/pdf/10.1007/s00371-023-02802-4.pdf",
        "ref_texts": "35. Peng, S., Liu, Y ., Huang, Q., Zhou, X., Bao, H.: Pvnet: pixelwise voting network for 6dof pose estimation. In: 2019 IEEE/CVFConference on Computer Vision and Pattern Recognition (CVPR),pp. 4556\u20134565. IEEE Computer Society, Los Alamitos, CA, USA(2019). https://doi.org/10.1109/CVPR.2019.00469 Publisher\u2019s Note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations. Felix Sattler has been a scientific researcher since 2021 at theGerman Aerospace Center (DLR)Institute for the Protection of Mar-itime Infrastructures with a back-ground in computer graphics andimage processing. His researchfocuses on 3D reconstruction ofdynamic scenes and real-time high-resolution image processing forembedded systems. Borja Carrillo-Perez has been a scientific researcher since 2018at the German Aerospace Cen-ter (DLR) Institute for the Protec-tion of Maritime infrastructures.His research activities include thedevelopment of image processinginstruments, research and applica-tion of deep learning algorithms,real-time data analysis and patterrecognition for the improvementof safety and security in maritime infrastructures. Sarah Barnes is the head of the Methods and Processing group atthe DLR Institute for the Protec-tion of Maritime Infrastructures.Sarah received her PhD from theUniversity of Manchester in 2016in the field of experimental par-ticle physics. Her broad research interests now lie in the fields of cosmic-ray tomography, optical sen-sor systems, sonar and machinelearning. Karsten Stebner is a researcher at the Institute of Optical Sen-sor Systems at German AerospaceCenter (DLR). His research interests are in the area of geo-referencing of complex configurations and sys-tems, dense image matching andsurface reconstruction.",
        "ref_ids": [
          "35"
        ]
      },
      "CLOSURE: Fast Quantification of Pose Uncertainty Sets": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2403.09990",
        "ref_texts": "[39] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 4561\u20134570, 2019. 1",
        "ref_ids": [
          "39"
        ]
      },
      "Keymatchnet: Zero-shot pose estimation in 3d point clouds by generalized keypoint matching": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2303.16102",
        "ref_texts": "[21] S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao, \u201cPvnet: Pixel-wise voting network for 6dof pose estimation,\u201d in IEEE Conference on Computer Vision and Pattern Recognition , 2019, pp. 4561\u20134570.",
        "ref_ids": [
          "21"
        ]
      },
      "DON6D: a decoupled one-stage network for 6D pose estimation": {
        "authors": [
          "Zheng Wang"
        ],
        "url": "https://www.nature.com/articles/s41598-024-59152-x.pdf",
        "ref_texts": ""
      },
      "FF-LOGO: Cross-Modality Point Cloud Registration with Feature Filtering and Local to Global Optimization": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2309.08966",
        "ref_texts": "[24] S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao, \u201cPvnet: Pixelwise voting network for 6dof pose estimation,\u201d in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , 2019, pp. 4561\u20134570.",
        "ref_ids": [
          "24"
        ]
      },
      "Instance-level 6D pose estimation based on multi-task parameter sharing for robotic grasping": {
        "authors": [
          "Liming Zhang"
        ],
        "url": "https://www.nature.com/articles/s41598-024-58590-x.pdf",
        "ref_texts": "1. Peng, S., Liu, Y ., Huang, Q., Zhou, X. & Bao, H. Pvnet: Pixel-wise voting network for 6dof pose estimation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 4561\u20134570 (2019).",
        "ref_ids": [
          "1"
        ]
      },
      "Advancing 6-DoF Instrument Pose Estimation in Variable X-Ray Imaging Geometries": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2405.11677",
        "ref_texts": "[23] S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao, \u201cPvnet: Pixelwise voting network for 6dof pose estimation,\u201d in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , 2019, pp. 4561\u20134570.",
        "ref_ids": [
          "23"
        ]
      },
      "Part-level Reconstruction for Self-Supervised Category-level 6D Object Pose Estimation with Coarse-to-Fine Correspondence Optimization": {
        "authors": [],
        "url": "https://openreview.net/pdf?id=D4cTfcaHOc",
        "ref_texts": "[17] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. 2019. Pvnet: Pixel-wise voting network for 6dof pose estimation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition . 4561\u20134570.",
        "ref_ids": [
          "17"
        ]
      },
      "A Common Knowledge-Driven Generic Vision Inspection Framework for Adaptation to Multiple Scenarios, Tasks, and Objects": {
        "authors": [
          "Delong Zhao",
          "Feifei Kong",
          "Nengbin Lv",
          "Zhangmao Xu",
          "Fuzhou Du"
        ],
        "url": "https://www.mdpi.com/1424-8220/24/13/4120/pdf",
        "ref_texts": "31. Peng, S.; Liu, Y.; Huang, Q.; Zhou, X.; Bao, H. PVNet: Pixel-wise voting network for 6D of pose estimation. IEEE Trans. Pattern Anal. Mach. Intell. 2022 ,44, 3212\u20133223. [CrossRef] [PubMed]",
        "ref_ids": [
          "31"
        ]
      },
      "Deep Learning-Based Object Pose Estimation: A Comprehensive Survey": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2405.07801",
        "ref_texts": "[17] S. Peng and Y. Liu, \u201cPvnet: Pixel-wise voting network for 6dof pose estimation,\u201d in CVPR , 2019.",
        "ref_ids": [
          "17"
        ]
      },
      "Multi-Modal Pose Representations for 6-DOF Object Tracking": {
        "authors": [],
        "url": "https://link.springer.com/content/pdf/10.1007/s10846-024-02181-5.pdf",
        "ref_texts": "15. Peng, S., Liu, Y ., Huang, Q., Zhou, X., Bao, H.: \u201cPVNet: PixelWise V oting Network for 6DoF Pose Estimation.\u201d in IEEE Conf.CVPR, pp. 4556\u20134565. (2019)",
        "ref_ids": [
          "15"
        ]
      },
      "FAFA: Frequency-Aware Flow-Aided Self-Supervision for Underwater Object Pose Estimation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2409.16600",
        "ref_texts": "36. Peng, S., Liu, Y., Huang, Q., Zhou, X., Bao, H.: Pvnet: Pixel-wise voting network for 6dof pose estimation. In: CVPR. pp. 4561\u20134570 (2019) FAFA for Self-Supervised Underwater Object Pose Estimation 17",
        "ref_ids": [
          "36"
        ]
      },
      "Learning 3D Robotics Perception using Inductive Priors": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2405.20364",
        "ref_texts": "[122] S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao, \u201cPVNet: Pixel-wise voting network for 6dof pose estimation,\u201d in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , 2019, pp. 4561\u20134570.",
        "ref_ids": [
          "122"
        ]
      },
      "Flying Projectile Attitude Determination from Ground-Based Monocular Imagery with a Priori Knowledge": {
        "authors": [
          "Huamei Chen",
          "Zhigang Zhu",
          "Hao Tang",
          "Erik Blasch",
          "Khanh D. Pham",
          "Genshe Chen"
        ],
        "url": "https://www.mdpi.com/2078-2489/15/4/201/pdf",
        "ref_texts": "34. Peng, S.; Liu, Y.; Huang, Q.; Zhou, X.; Bao, H. Pvnet: Pixel-wise voting network for 6dof pose estimation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, Long Beach, CA, USA, 15\u201320 June 2019.",
        "ref_ids": [
          "34"
        ]
      },
      "Visibility-Aware Keypoint Localization for 6DoF Object Pose Estimation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2403.14559",
        "ref_texts": "44. Peng, S., Liu, Y., Huang, Q., Zhou, X., Bao, H.: PVNet: pixel-wise voting network for 6dof pose estimation. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). pp. 4561\u20134570 (2019)",
        "ref_ids": [
          "44"
        ]
      },
      "AnnotateXR: An Extended Reality Workflow for Automating Data Annotation to Support Computer Vision Applications": {
        "authors": [
          "Subramanian Chidambaram",
          "Rahul Jain",
          "Sai Swarup",
          "Asim Unmesh",
          "Karthik Ramani"
        ],
        "url": "https://engineering.purdue.edu/cdesign/wp/wp-content/uploads/2024/11/jcise_24_12_121001.pdf",
        "ref_texts": "[27] Peng, S., Liu, Y., Huang, Q., Zhou, X., and Bao, H., 2019, \u201cPvnet: Pixel-Wise Voting Network for 6DOF Pose Estimation, \u201dProceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), LongBeach, CA, June 16 \u201320, pp. 4561 \u20134570.",
        "ref_ids": [
          "27"
        ]
      },
      "SCANet: Correcting LEGO Assembly Errors with Self-Correct Assembly Network": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2403.18195"
      },
      "Ontology based autonomous robot task processing framework": {
        "authors": [
          "Yueguang Ge"
        ],
        "url": "https://www.frontiersin.org/articles/10.3389/fnbot.2024.1401075/pdf",
        "ref_texts": "(2009). OWL 2 web ontology language: structural specification a nd functional-style syntax.W3C Recommend . 27:159. Available online at: http://www.w3.org/TR/owl2syntax/ Olivares-Alarcos,A.,Be\u00dfler,D.,Khamis,A.,Goncalves,P.,Hab ib,M.K.,BermejoAlonso, J., et al. (2019). A review and comparison of ontology-ba sed approaches to robotautonomy. Knowl.Eng.Rev .34:e29.doi:10.1017/S0269888919000237 Paulius, D., and Sun, Y. (2019). A survey of knowledge represent ation in service robotics.Robot.Autonom.Syst .118,13\u201330.doi:10.48550/arXiv.1807.02192 Peng,S.,Liu,Y.,Huang,Q.,Zhou,X.,andBao,H.(2019).\u201cPV Net:Pixel-wisevoting network for 6DoF pose estimation,\u201d in Proceedings of the IEEE/CVF Conference on ComputerVisionandPatternRecognition (LongBeach,CA:IEEE),4561\u20134570. Redmon, J., Divvala, S., Girshick, R., and Farhadi, A. (2016). \u201cYou only look once: unified,real-timeobjectdetection,\u201din ProceedingsoftheIEEEConferenceonComputer VisionandPatternRecognition (LasVegas,NV:IEEE),779\u2013788. Redmon, J., and Farhadi, A. (2017). \u201cYOLO9000: better, fast er, stronger,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognitio n (Honolulu,HI),7263\u20137271. Redmon, J., and Farhadi, A. (2018). YOLOv3: an incremental i mprovement. arXiv:1804.02767[cs] .doi:10.48550/arXiv.1804.02767Ren, S., He, K., Girshick, R., and Sun, J. (2015). Faster R-CNN : towards real-time object detection with region proposal networks. Adv. Neural Inform. Process. Syst ."
      },
      "Weakly Supervised Pose Estimation of Surgical Instrument from a Single Endoscopic Image": {
        "authors": [
          "Lihua Hu",
          "Shida Feng",
          "Bo Wang"
        ],
        "url": "https://www.mdpi.com/1424-8220/24/11/3355/pdf",
        "ref_texts": "26. Peng, S.; Liu, Y.; Huang, Q.; Bao, H. PVNet: Pixel-wise voting network for 6dof pose estimation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, Long Beach, CA, USA, 15\u201320 June 2019; pp. 4561\u20134570.",
        "ref_ids": [
          "26"
        ]
      },
      "Multi-View Metal Parts Pose Estimation Based on a Single Camera": {
        "authors": [
          "Chen Chen",
          "Xin Jiang"
        ],
        "url": "https://www.mdpi.com/1424-8220/24/11/3408/pdf",
        "ref_texts": "11. Peng, S.; Liu, Y.; Huang, Q.; Zhou, X.; Bao, H. Pvnet: Pixel-wise voting network for 6dof pose estimation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, Long Beach, CA, USA, 15\u201320 June 2019; pp. 4561\u20134570.",
        "ref_ids": [
          "11"
        ]
      },
      "Accurate Robot Arm Attitude Estimation Based on Multi-View Images and Super-Resolution Keypoint Detection Networks": {
        "authors": [
          "Ling Zhou",
          "Ruilin Wang",
          "Liyan Zhang"
        ],
        "url": "https://www.mdpi.com/1424-8220/24/1/305/pdf",
        "ref_texts": "10. Peng, S.; Liu, Y.; Huang, Q.; Zhou, X.; Bao, H. PVNet: Pixel-wise voting network for 6DoF pose estimation. In Proceedings of the 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition, Long Beach, CA, USA, 15\u201320 June 2019; pp. 4556\u20134565.",
        "ref_ids": [
          "10"
        ]
      },
      "MOTPose: Multi-object 6D Pose Estimation for Dynamic Video Sequences using Attention-based Temporal Fusion": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2403.09309",
        "ref_texts": "[20] Y . Hu, J. Hugonot, P. Fua, and M. Salzmann, \u201cSegmentation-driven 6D object pose estimation,\u201d in IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) , 2019, pp. 3385\u20133394.[21] S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao, \u201cPVNet: Pixelwise voting network for 6DOF pose estimation,\u201d in IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) , 2019, pp. 4561\u20134570.",
        "ref_ids": [
          "20",
          "21"
        ]
      },
      "CVAM-Pose: Conditional Variational Autoencoder for Multi-Object Monocular Pose Estimation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2410.09010",
        "ref_texts": "[32] Sida Peng, Xiaowei Zhou, Yuan Liu, Haotong Lin, Qixing Huang, and Hujun Bao. Pvnet: Pixel-wise voting network for 6dof object pose estimation. IEEE Transactions on Pattern Analysis and Machine Intelligence , 44(6):3212\u20133223, 2020.",
        "ref_ids": [
          "32"
        ]
      },
      "RHAML: Rendezvous-based Hierarchical Architecture for Mutual Localization": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2405.11726",
        "ref_texts": "[25] S. Peng, X. Zhou, Y . Liu, H. Lin, Q. Huang, and H. Bao, \u201cPVNet: Pixel-wise voting network for 6dof object pose estimation,\u201d IEEE Trans. Pattern Anal. Machine Intell. , vol. 44, no. 6, pp. 3212\u20133223, 2022.",
        "ref_ids": [
          "25"
        ]
      },
      "A Learnable Viewpoint Evolution Method for Accurate Pose Estimation of Complex Assembled Product": {
        "authors": [
          "Delong Zhao",
          "Feifei Kong",
          "Fuzhou Du"
        ],
        "url": "https://www.mdpi.com/2076-3417/14/11/4405/pdf",
        "ref_texts": "30. Peng, S.; Liu, Y.; Huang, Q.; Zhou, X.; Bao, H. PVNet: Pixel-wise voting network for 6dof pose estimation. IEEE Trans. Pattern Anal. Mach. Intell. 2022 ,44, 3212\u20133223. [CrossRef] [PubMed]",
        "ref_ids": [
          "30"
        ]
      },
      "A Robust CoS-PVNet Pose Estimation Network in Complex Scenarios": {
        "authors": [
          "Jiu Yong",
          "Xiaomei Lei",
          "Jianwu Dang",
          "Yangping Wang"
        ],
        "url": "https://www.mdpi.com/2079-9292/13/11/2089/pdf",
        "ref_texts": "21. Peng, S.; Liu, Y.; Huang, Q.; Zhou, X.; Bao, H. PVNet: Pixel-wise voting network for 6D of pose estimation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, Long Beach, CA, USA, 15\u201320 June 2019; pp. 4561\u20134570.",
        "ref_ids": [
          "21"
        ]
      },
      "NeuSurfEmb: A Complete Pipeline for Dense Correspondence-based 6D Object Pose Estimation without CAD Models": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2407.12207",
        "ref_texts": "[29] S. Peng, Y . Liu, Q. Huang, H. Bao, and X. Zhou, \u201cPVNet: Pixel-wise V oting Network for 6DoF Pose Estimation,\u201d in CVPR , 2019. 2, 4",
        "ref_ids": [
          "29"
        ]
      },
      "Six-Degree-of-Freedom Pose Estimation Method for Multi-Source Feature Points Based on Fully Convolutional Neural Network": {
        "authors": [],
        "url": "https://link.springer.com/content/pdf/10.1007/s10846-024-02154-8.pdf",
        "ref_texts": "33. Peng, S., Liu, Y ., Huang, Q., Zhou, X., Bao, H.: Pvnet: Pixelwise voting network for 6dof pose estimation. In: 2019 IEEE/CVFConference on Computer Vision and Pattern Recognition (CVPR),pp. 4556\u20134565 (2019). https://doi.org/10.1109/CVPR.2019.00469",
        "ref_ids": [
          "33"
        ]
      },
      "Certifying Robustness of Learning-Based Keypoint Detection and Pose Estimation Methods": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2408.00117",
        "ref_texts": "[33] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. 2019. Pvnet: Pixel-wise voting network for 6dof pose estimation. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition . 4561\u20134570.",
        "ref_ids": [
          "33"
        ]
      },
      "SD-Net: Symmetric-Aware Keypoint Prediction and Domain Adaptation for 6D Pose Estimation In Bin-picking Scenarios": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2403.09317",
        "ref_texts": "[4] S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao, \u201cPvnet: Pixelwise voting network for 6dof pose estimation,\u201d in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , 2019, pp. 4561\u20134570.",
        "ref_ids": [
          "4"
        ]
      },
      "Marrying NeRF with Feature Matching for One-step Pose Estimation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2404.00891",
        "ref_texts": "[7] S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao, \u201cPvnet: Pixelwise voting network for 6dof pose estimation,\u201d in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , 2019, pp. 4561\u20134570.",
        "ref_ids": [
          "7"
        ]
      },
      "Category Level Object Pose Estimation via Global High-Order Pooling": {
        "authors": [
          "Changhong Jiang",
          "Xiaoqiao Mu",
          "Bingbing Zhang",
          "Mujun Xie",
          "Chao Liang"
        ],
        "url": "https://www.mdpi.com/2079-9292/13/9/1720/pdf",
        "ref_texts": "6. Peng, S.; Liu, Y.; Huang, Q.; Zhou, X.; Bao, H. Pvnet: Pixel-wise voting network for 6dof pose estimation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, Long Beach, CA, USA, 16\u201317 June 2019; pp. 4561\u20134570.",
        "ref_ids": [
          "6"
        ]
      },
      "Axes-aligned non-linear optimized PnP algorithm": {
        "authors": [
          "Peter Roch"
        ],
        "url": "https://link.springer.com/content/pdf/10.1007/s00138-024-01618-z.pdf",
        "ref_texts": "61. Peng, S., Liu, Y ., Huang, Q., et al.: Pvnet: Pixel-wise voting network for 6dof pose estimation. In: 2019 IEEE/CVF Conference oncomputer vision and pattern recognition (CVPR), (2019). https:// doi.org/10.1109/CVPR.2019.00469",
        "ref_ids": [
          "61"
        ]
      },
      "ASDF: Assembly State Detection Utilizing Late Fusion by Integrating 6D Pose Estimation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2403.16400",
        "ref_texts": "[27] S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao. Pvnet: Pixelwise voting network for 6dof pose estimation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pp. 4561\u20134570. IEEE/CVF, 2019. 3",
        "ref_ids": [
          "27"
        ]
      },
      "Extending 6D Object Pose Estimators for Stereo Vision": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2402.05610",
        "ref_texts": "22. Peng, S., Liu, Y., Huang, Q., Zhou, X., Bao, H.: Pvnet: Pixel-wise voting network for 6dof pose estimation. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 4561\u20134570 (2019)",
        "ref_ids": [
          "22"
        ]
      },
      "Memory Efficient Deep Learning-Based Grasping Point Detection of Nontrivial Objects for Robotic Bin Picking": {
        "authors": [],
        "url": "https://link.springer.com/content/pdf/10.1007/s10846-024-02153-9.pdf",
        "ref_texts": "29. Peng, S., Zhou, X., Liu, Y ., Lin, H., Huang, Q., Bao, H.: Pvnet: pixel-wise voting network for 6dof object pose estimation. IEEETrans. Pattern Anal. Mach. Intell. (2020). https://doi.org/10.1109/ TPAMI.2020.3047388",
        "ref_ids": [
          "29"
        ]
      },
      "Monocular pose estimation of articulated surgical instruments in open surgery": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2407.12138",
        "ref_texts": "[46] Peng, S., Liu, Y ., Huang, Q., Zhou, X., Bao, H., 2019. Pvnet: Pixelwise voting network for 6dof pose estimation, in: Proceedings of the IEEE /CVF conference on computer vision and pattern recognition, pp.",
        "ref_ids": [
          "46"
        ]
      },
      "Leveraging Positional Encoding for Robust Multi-Reference-Based Object 6D Pose Estimation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2401.16284",
        "ref_texts": "[30] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 4561\u2013",
        "ref_ids": [
          "30"
        ]
      },
      "Sim-to-Real Dataset of Industrial Metal Objects": {
        "authors": [
          "Peter De",
          "Steven Moonen",
          "Nick Michiels"
        ],
        "url": "https://www.mdpi.com/2075-1702/12/2/99/pdf",
        "ref_texts": "35. Peng, S.; Liu, Y.; Huang, Q.; Zhou, X.; Bao, H. Pvnet: Pixel-wise voting network for 6DoF pose estimation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, Long Beach, CA, USA, 15\u201320 June 2019; pp. 4561\u20134570. Disclaimer/Publisher\u2019s Note: The statements, opinions and data contained in all publications are solely those of the individual author(s) and contributor(s) and not of MDPI and/or the editor(s). MDPI and/or the editor(s) disclaim responsibility for any injury to people or property resulting from any ideas, methods, instructions or products referred to in the content.",
        "ref_ids": [
          "35"
        ]
      },
      "SABER-6D: Shape Representation Based Implicit Object Pose Estimation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2408.05867",
        "ref_texts": "30. Peng, S., Liu, Y., Huang, Q., Bao, H., Zhou, X.: PVNet: Pixel-wise voting network for 6DoF pose estimation. In: Conference on Computer Vision and Pattern Recognition (CVPR). pp. 4556\u20134565 (2019)",
        "ref_ids": [
          "30"
        ]
      },
      "RoCap: A Robotic Data Collection Pipeline for the Pose Estimation of Appearance-Changing Objects": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2407.08081",
        "ref_texts": "[38] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. 2019. Pvnet: Pixel-wise voting network for 6dof pose estimation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition . 4561\u2013",
        "ref_ids": [
          "38"
        ]
      },
      "Research on Six-Degree-of-Freedom Refueling Robotic Arm Positioning and Docking Based on RGB-D Visual Guidance": {
        "authors": [
          "Mingbo Yang",
          "Jiapeng Liu"
        ],
        "url": "https://www.mdpi.com/2076-3417/14/11/4904/pdf",
        "ref_texts": "25. Peng, S.; Liu, Y.; Huang, Q.; Zhou, X.; Bao, H. Pvnet: Pixel-wise voting network for 6dof pose estimation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), Long Beach, CA, USA, 15\u201320 June 2019; pp.",
        "ref_ids": [
          "25"
        ]
      },
      "A Lightweight 6D Pose Estimation Network Based on Improved Atrous Spatial Pyramid Pooling": {
        "authors": [
          "Fupan Wang",
          "Xiaohang Tang",
          "Yadong Wu",
          "Yinfan Wang",
          "Huarong Chen",
          "Guijuan Wang",
          "Jing Liao"
        ],
        "url": "https://www.mdpi.com/2079-9292/13/7/1321/pdf",
        "ref_texts": "13. Peng, S.; Liu, Y.; Huang, Q.; Zhou, X.; Bao, H. Pvnet: Pixel-wise voting network for 6dof pose estimation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, Long Beach, CA, USA, 15\u201320 June 2019; pp. 4561\u20134570.",
        "ref_ids": [
          "13"
        ]
      },
      "Improving 2D-3D Dense Correspondences with Diffusion Models for 6D Object Pose Estimation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2402.06436",
        "ref_texts": "[17] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , 2019.",
        "ref_ids": [
          "17"
        ]
      },
      "Sparse Color-Code Net: Real-Time RGB-Based 6D Object Pose Estimation on Edge Devices": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2406.02977",
        "ref_texts": "[9] S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao, \u201cPVNet: Pixel-wise voting network for 6DoF pose estimation,\u201d in Proc. IEEE Comput. Soc. Conf. Comput. Vis. Pattern Recognit. , 2019, pp. 4561\u20134570.",
        "ref_ids": [
          "9"
        ]
      },
      "GS2Pose: Tow-stage 6D Object Pose Estimation Guided by Gaussian Splatting": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2411.03807"
      },
      "Deep sensor data fusion for environmental perception of automated systems": {
        "authors": [],
        "url": "https://tobias-lib.ub.uni-tuebingen.de/xmlui/bitstream/handle/10900/151623/Dissertation_Fabian_Duffhauss.pdf?sequence=1&isAllowed=y",
        "ref_texts": "[Pen+19] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. \u201cPVNet: Pixel-wise Voting Network for 6DoF Pose Estimation\u201d. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) . 2019, pp. 4561\u20134570.",
        "ref_ids": [
          "Pen\\+19"
        ]
      },
      "HPPS: A Hierarchical Progressive Perception System for Luggage Trolley Detection and Localization at Airports": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2405.05514",
        "ref_texts": "[29] S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao, \u201cPvnet: Pixelwise voting network for 6dof pose estimation,\u201d in Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , 2019, pp. 4561\u20134570.",
        "ref_ids": [
          "29"
        ]
      },
      "EasyHeC++: Fully Automatic Hand-Eye Calibration with Pretrained Image Models": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2410.09293",
        "ref_texts": "[42] S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao, \u201cPvnet: Pixel-wise voting network for 6dof pose estimation,\u201d in CVPR , 2019, pp. 4561\u2013",
        "ref_ids": [
          "42"
        ]
      },
      "SurgeoNet: Realtime 3D Pose Estimation of Articulated Surgical Instruments from Stereo Images using a Synthetically-trained Network": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2410.01293",
        "ref_texts": "14. Peng, S., Liu, Y., Huang, Q., Zhou, X., Bao, H.: Pvnet: Pixel-wise voting network for 6dof pose estimation. In: Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. pp. 4561\u20134570 (2019) 3, 10, 11",
        "ref_ids": [
          "14"
        ]
      },
      "RayEmb: Arbitrary Landmark Detection in X-Ray Images Using Ray Embedding Subspace": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2410.08152",
        "ref_texts": "30. Peng, S., Liu, Y., Huang, Q., Zhou, X., Bao, H.: PVNet: Pixel-wise voting network for 6DoF pose estimation. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 4561\u20134570 (2019)",
        "ref_ids": [
          "30"
        ]
      },
      "Synthetic Dataset Generation and Learning From Demonstration Applied to Industrial Manipulation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2404.00447",
        "ref_texts": "[3]S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao, \u201cPvnet: Pixel-wise voting network for 6dof pose estimation,\u201d in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , 2019, pp. 4561\u2013",
        "ref_ids": [
          "3"
        ]
      },
      "KGpose: Keypoint-Graph Driven End-to-End Multi-Object 6D Pose Estimation via Point-Wise Pose Voting": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2407.08909",
        "ref_texts": "[1] S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao, \u201cPvnet: Pixelwise voting network for 6dof pose estimation,\u201d in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , 2019, pp. 4561\u20134570.",
        "ref_ids": [
          "1"
        ]
      },
      "Pre-grasp planning for time-efficient and robust mobile manipulation": {
        "authors": [
          "Lakshadeep Naik"
        ],
        "url": "https://portal.findresearcher.sdu.dk/files/269162841/PhD_thesis_Lakshadeep_Naik.pdf",
        "ref_texts": "[27] S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao, \u201cPvnet: Pixel-wise voting network for 6dof pose estimation,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , 2019, pp.",
        "ref_ids": [
          "27"
        ]
      },
      "Learning and Optimizing Camera Pose": {
        "authors": [],
        "url": "https://research.chalmers.se/publication/539208/file/539208_Fulltext.pdf",
        "ref_texts": "[41] S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao, \u201cPVNet: Pixel-wise voting network for 6DoF pose estimation,\u201d in The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , Jun. 2019.",
        "ref_ids": [
          "41"
        ]
      },
      "Vision-Based 6D Pose Estimation and Tracking: From Known to Novel Objects": {
        "authors": [],
        "url": "https://qmro.qmul.ac.uk/xmlui/bitstream/handle/123456789/99018/PhD_Thesis_Long.pdf?sequence=2",
        "ref_texts": "[101] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. PVNet: Pixel-wise voting network for 6DoF pose estimation. In IEEE conference on Computer Vision and Pattern Recognition , pages 4561\u20134570, 2019.",
        "ref_ids": [
          "101"
        ]
      },
      "6D pose estimation of objects in images": {
        "authors": [],
        "url": "https://dspace.cuni.cz/bitstream/handle/20.500.11956/188520/120469921.pdf?sequence=1",
        "ref_texts": "[32] SidaPeng,YuanLiu,QixingHuang,XiaoweiZhou, andHujunBao. PVNet: Pixel-wise voting network for 6DoF pose estimation. In CVPR, pages 4561\u2013",
        "ref_ids": [
          "32"
        ]
      },
      "FruitBin: a tunable large-scale dataset for advancing 6D pose estimation in fruit bin-picking automation": {
        "authors": [],
        "url": "https://hal.science/hal-04683842/file/ECCV_Workshop_BOP_compressed.pdf",
        "ref_texts": "30. Peng, S., Liu, Y., Huang, Q., Zhou, X., Bao, H.: Pvnet: Pixel-wise voting network for 6dof pose estimation. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 4561\u20134570 (2019)",
        "ref_ids": [
          "30"
        ]
      },
      "Mapping Real-World Objects into Virtual Reality to Facilitate Interaction using 6DoF Pose Estimation": {
        "authors": [],
        "url": "https://scholar.sun.ac.za/bitstreams/ed797c6c-035f-4b97-a177-9bd22d3234db/download",
        "ref_texts": "[55]S. Peng, Y. Liu, Q. Huang, X. Zhou, and H. Bao, \u201cPVNet: Pixel-Wise Voting Network for 6DoF Pose Estimation,\u201d in 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2019, pp. 4556\u20134565.",
        "ref_ids": [
          "55"
        ]
      },
      "Active Perception for Estimating 6D Poses of Textureless Shiny Objects": {
        "authors": [],
        "url": "https://tspace.library.utoronto.ca/bitstream/1807/141311/3/Yang_Jun_202411_PhD_thesis.pdf",
        "ref_texts": "[27] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. \u201cPVNet: Pixel-wise voting network for 6DoF pose estimation\u201d. In: IEEE/CVF Conference on Computer Vision and Pattern recognition (CVPR) . 2019.",
        "ref_ids": [
          "27"
        ]
      },
      "Cuantificaci\u00f3n de la incertidumbre en la estimaci\u00f3n de la pose de objetos r\u00edgidos usando redes neuronales bayesianas profundas": {
        "authors": [],
        "url": "https://repositorio.utp.edu.co/bitstreams/781d6946-9247-4b7d-b4c2-50f9dd3f055b/download",
        "ref_texts": "[69] S. Peng, Y. Liu, Q. Huang, X. Zhou, and H. Bao, \u201cPvnet: Pixel-wise voting network for 6dof pose estimation,\u201d in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pp. 4561\u20134570, 2019. 2.1.2",
        "ref_ids": [
          "69"
        ]
      },
      "Image-Based Pose Estimation of Sub-Centimeter Industrial Parts for Automated Assembly": {
        "authors": [],
        "url": "https://roboassembly.github.io/assets/submissions/pdf/10_Pose_Estimation_of_Sub_Cent.pdf",
        "ref_texts": "[33] S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao. PVNet: Pixel-wise V oting Network for 6DoF Pose Estimation. In IEEE/CVF Int. Conf. Comput. Vis. Pattern Recognit. (CVPR) , 2019.",
        "ref_ids": [
          "33"
        ]
      },
      "\u57fa\u4e8e\u5355\u76ee RGB \u6570\u636e\u7684\u4e09\u7ef4\u6a21\u677f\u7269\u4f53\u8ddf\u8e2a\u7b97\u6cd5\u7efc\u8ff0": {
        "authors": [],
        "url": "https://www.jcad.cn/cn/article/pdf/preview/4fca7cc5-45ba-4747-a6ed-4c1bfdc01f09.pdf",
        "ref_texts": "): [1]Lepetit V , Fua P. Monocular model-based3D tracking of rigid objects: A survey[M]. Massachusetts: NowFoundations and Trends, 2005 [2]Marchand E, Uchiyama H, Spindler F. Poseestimation for augmented reality: a hands-on survey[J]. IEEETransactions on Visualization and Computer Graphics, 2016,22(12): 2633-2651[3]Peng S D, Zhou X W, Liu Y , et al. PVNet:pixel-wise voting network for 6DoF object pose estimation[J].IEEE Transactions on Pattern Analysis and Machine Intelli -gence, 2022, 44(6): 3212-3223[4]Kirillov A. An introduction to Lie groupsand Lie algebras[M]. Cambridge: Cambridge University Press,2008[5]Varadarajan V S. Lie groups, Lie algebras,and their representations[M]. Heidelberg: Springer, 1984[6]Murray R M, Li Z X, Sastry S S. A mathe -matical introduction to robotic manipulation[M]. Florida: CRCPress, 2017[7]He Xian, Li Jiachen, Jin Li, et al. A syn-thetic dataset and performance evaluation for 3D templatetracking[J]. Chinese Journal of Computers, 2022, 45(3): 585-600(in Chinese) (\u4f55\u5f26, \u674e\u4f73\u5bb8, \u91d1\u7acb\u7b49. \u4e09\u7ef4\u6a21\u677f\u8ddf\u8e2a\u7684\u57fa\u51c6\u5408\u6210\u6570\u636e\u96c6\u6784\u5efa\u53ca\u7b97\u6cd5\u8bc4\u4f30[J]. \u8ba1\u7b97\u673a\u5b66\u62a5, 2022, 45(3): 585-600)[8]Choi C, Christensen H I. RGB-D objecttracking: a particle filter approach on GPU[C] // Proceedings ofIEEE/RSJ International Conference on Intelligent Robots andSystems. Los Alamitos: IEEE Computer Society Press, 2013:1084-1091[9]Tjaden H, Schwanecke U, Sch\u00f6mer E, et al.A region-based Gauss-Newton approach to real-time monocu -lar multiple object tracking[J]. IEEE Transactions on PatternAnalysis and Machine Intelligence, 2019, 41(8): 1797-1812[10]Wu P C, Lee Y Y , Tseng H Y . et al. Abenchmark dataset for 6DoF object pose tracking[C] //Proceed -ings of IEEE International Symposium on Mixed and Aug -mented Reality. Los Alamitos: IEEE Computer Society Press,2017: 186-191[11]Xiang Y , Schmidt T, Narayanan V , et al.PoseCNN: a convolutional neural network for 6D object poseestimation in cluttered scenes[C] //Proceedings of Robotics:Science and Systems. Cambridge: MIT Press, 2018[12]Li J C, Wang B, Zhu S Q, et al. BCOT: amarkerless high-precision 3D object tracking benchmark[C] //Proceedings of IEEE/CVF Conference on Computer Vision andPattern Recognition. Los Alamitos: IEEE Computer SocietyPress, 2022: 6687-6696[13]Shapiro R. Direct linear transformation ",
        "ref_ids": [
          "1",
          "2",
          "3",
          "4",
          "5",
          "6",
          "7",
          "8",
          "9",
          "10",
          "11",
          "12",
          "13"
        ]
      },
      "\uc11c\ube44\uc2a4 \uc790\ub3d9\ud654 \uc2dc\uc2a4\ud15c\uc744 \uc704\ud55c \ubb3c\uccb4 \uc790\uc138 \uc778\uc2dd \ubc0f \ub3d9\uc791 \uacc4\ud68d": {
        "authors": [
          "Media Contents"
        ],
        "url": "https://jkros.org/xml/40708/40708.pdf",
        "ref_texts": "[13] S. Peng, X. Zhou, Y. Liu, H. Lin, Q. Huang, and H. Bao, \u201cPVNet: Pixel-Wise Voting Network for 6DoF Object Pose Estimation,\u201d IEEE Transactions on Pattern Analysis and Machine Intelli-gence , vol. 44, no. 6, pp. 3212-3223, Jun., 2022, DOI: 10.1109/ tpami.2020.3047388.",
        "ref_ids": [
          "13"
        ]
      },
      "\u878d\u5408 BRIEF \u4e0e ICP \u70b9\u4e91\u914d\u51c6\u7684\u96f6\u90e8\u4ef6\u59ff\u6001\u4f30\u8ba1\u65b9\u6cd5": {
        "authors": [],
        "url": "http://jsj.journal.cssc709.net/CN/article/downloadArticleFile.do?attachType=PDF&id=4245",
        "ref_texts": "[5]Peng S,Liu Y,Huang Q,et al. PVNet :Pixel-Wise Vot \u2043 ing Network for 6DoF Pose Estimation [C]//2019IEEE/ CVF Conference on Computer Vision and Pattern Recogni \u2043 tion(CVPR). IEEE,2019:4561-4570.",
        "ref_ids": [
          "5",
          "C"
        ]
      },
      "\ubb3c\uccb4 \ud30c\uc9c0\uc810 \uac80\ucd9c \ud5a5\uc0c1\uc744 \uc704\ud55c \ubd84\ud560 \uae30\ubc18 \uae4a\uc774 \uc9c0\ub3c4 \uc870\uc815": {
        "authors": [
          "Media Contents"
        ],
        "url": "https://jkros.org/xml/39599/39599.pdf",
        "ref_texts": "[3] S. Peng, Y. Liu, Q. Huang, H. Bao, and X. Zhou, \u201cPvnet: Pixelwise voting network for 6dof pose estimation,\u201d ",
        "ref_ids": [
          "3"
        ]
      },
      "Laboratoire d'InfoRmatique en Image et Syst\u00e8mes d'information": {
        "authors": [],
        "url": "https://perso.liris.cnrs.fr/florence.zara/Web/media/files/Poster_ECCV.pdf",
        "ref_texts": "[1] Peng, Sida, et al. \"Pvnet: Pixel-wise voting network for 6dof pose estimation.\" Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. 2019.",
        "ref_ids": [
          "1"
        ]
      },
      "6D object position estimation from 2D images: A literature review": {
        "authors": [
          "Giorgia Marullo"
        ],
        "url": "https://link.springer.com/content/pdf/10.1007/s11042-022-14213-z.pdf",
        "ref_texts": "43. Peng S, Liu Y, Huang Q, Zhou X, Bao H (2019) PVNet: pixel-wise voting network for 6DoF pose estimation. 2019 IEEECVF Conf. Comput. Vis. Pattern Recognit. CVPR, pp 4556 \u20134565. https://doi.org/10.",
        "ref_ids": [
          "43"
        ]
      },
      "Gapartnet: Cross-category domain-generalizable object perception and manipulation via generalizable and actionable parts": {
        "authors": [
          "Haoran Geng",
          "Helin Xu",
          "Chengyang Zhao",
          "Chao Xu",
          "Li Yi",
          "Siyuan Huang",
          "He Wang"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2023/papers/Geng_GAPartNet_Cross-Category_Domain-Generalizable_Object_Perception_and_Manipulation_via_Generalizable_and_CVPR_2023_paper.pdf",
        "ref_texts": "[41] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 4561\u2013",
        "ref_ids": [
          "41"
        ]
      },
      "Deep fusion transformer network with weighted vector-wise keypoints voting for robust 6d object pose estimation": {
        "authors": [
          "Jun Zhou",
          "Kai Chen",
          "Linlin Xu",
          "Qi Dou",
          "Jing Qin"
        ],
        "url": "http://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_Deep_Fusion_Transformer_Network_with_Weighted_Vector-Wise_Keypoints_Voting_for_ICCV_2023_paper.pdf",
        "ref_texts": "[47] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 4561\u20134570, 2019. 2, 5, 6, 7",
        "ref_ids": [
          "47"
        ]
      },
      "Visibility aware human-object interaction tracking from single rgb camera": {
        "authors": [
          "Xianghui Xie",
          "Bharat Lal",
          "Gerard Pons"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Xie_Visibility_Aware_Human-Object_Interaction_Tracking_From_Single_RGB_Camera_CVPR_2023_paper.pdf",
        "ref_texts": "[52] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. PVNet: Pixel-Wise V oting Network for 6DoF Pose Estimation. In 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) , pages 4556\u20134565, Long Beach, CA, USA, June 2019. IEEE. 2",
        "ref_ids": [
          "52"
        ]
      },
      "Object pose estimation with statistical guarantees: Conformal keypoint detection and geometric uncertainty propagation": {
        "authors": [
          "Heng Yang",
          "Marco Pavone"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Yang_Object_Pose_Estimation_With_Statistical_Guarantees_Conformal_Keypoint_Detection_and_CVPR_2023_paper.pdf",
        "ref_texts": "[72] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixel-wise voting network for 6dofpose estimation. IEEE Trans. Pattern Anal. Machine Intell. , 2022. 1,2,8",
        "ref_ids": [
          "72"
        ]
      },
      "Transhuman: A transformer-based human representation for generalizable neural human rendering": {
        "authors": [
          "Xiao Pan",
          "Zongxin Yang",
          "Jianxin Ma",
          "Chang Zhou",
          "Yi Yang"
        ],
        "url": "https://openaccess.thecvf.com/content/ICCV2023/papers/Pan_TransHuman_A_Transformer-based_Human_Representation_for_Generalizable_Neural_Human_Rendering_ICCV_2023_paper.pdf",
        "ref_texts": "[32] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 4561\u2013",
        "ref_ids": [
          "32"
        ]
      },
      "Hs-pose: Hybrid scope feature extraction for category-level object pose estimation": {
        "authors": [
          "Linfang Zheng",
          "Chen Wang",
          "Yinghan Sun",
          "Esha Dasgupta",
          "Hua Chen",
          "Ales Leonardis",
          "Wei Zhang",
          "Hyung Jin"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2023/papers/Zheng_HS-Pose_Hybrid_Scope_Feature_Extraction_for_Category-Level_Object_Pose_Estimation_CVPR_2023_paper.pdf",
        "ref_texts": "[10] Yisheng He, Wei Sun, Haibin Huang, Jianran Liu, Haoqiang Fan, and Jian Sun. Pvn3d: A deep point-wise 3d keypoints voting network for 6dof pose estimation. In IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) , June 2020. 2",
        "ref_ids": [
          "10"
        ]
      },
      "Tta-cope: Test-time adaptation for category-level object pose estimation": {
        "authors": [
          "Taeyeop Lee",
          "Jonathan Tremblay",
          "Valts Blukis",
          "Bowen Wen",
          "Uk Lee",
          "Inkyu Shin",
          "Stan Birchfield",
          "In So",
          "Jin Yoon"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Lee_TTA-COPE_Test-Time_Adaptation_for_Category-Level_Object_Pose_Estimation_CVPR_2023_paper.pdf",
        "ref_texts": "[28] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. PVNet: Pixel-wise voting network for 6DoF pose estimation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) , pages 4561\u20134570, 2019. 1",
        "ref_ids": [
          "28"
        ]
      },
      "Parallel inversion of neural radiance fields for robust pose estimation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2210.10108.pdf?trk=public_post_comment-text",
        "ref_texts": "[9] S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao, \u201cPVNet: Pixel-wise voting network for 6DoF pose estimation,\u201d in IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) , 2019.",
        "ref_ids": [
          "9"
        ]
      },
      "Texpose: Neural texture learning for self-supervised 6d object pose estimation": {
        "authors": [
          "Hanzhi Chen",
          "Fabian Manhardt",
          "Nassir Navab",
          "Benjamin Busam"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Chen_TexPose_Neural_Texture_Learning_for_Self-Supervised_6D_Object_Pose_Estimation_CVPR_2023_paper.pdf",
        "ref_texts": "[39] Sida Peng, Y uan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2019, Long Beach, CA, USA, June 16-20, 2019 , pages 4561\u20134570. Computer Vision Foundation / IEEE, 2019. 1,2",
        "ref_ids": [
          "39"
        ]
      },
      "Full-body articulated human-object interaction": {
        "authors": [
          "Nan Jiang",
          "Tengyu Liu",
          "Zhexuan Cao",
          "Jieming Cui",
          "Zhiyuan Zhang",
          "Yixin Chen",
          "He Wang",
          "Yixin Zhu",
          "Siyuan Huang"
        ],
        "url": "https://openaccess.thecvf.com/content/ICCV2023/papers/Jiang_Full-Body_Articulated_Human-Object_Interaction_ICCV_2023_paper.pdf",
        "ref_texts": "[39] Sida Peng, Y uan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In Conference on Computer Vision and Pattern Recognition (CVPR) , 2019. 2,3",
        "ref_ids": [
          "39"
        ]
      },
      "Learning symmetry-aware geometry correspondences for 6d object pose estimation": {
        "authors": [
          "Heng Zhao",
          "Shenxing Wei",
          "Dahu Shi",
          "Wenming Tan",
          "Zheyang Li",
          "Ye Ren",
          "Xing Wei",
          "Yi Yang",
          "Shiliang Pu"
        ],
        "url": "http://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_Learning_Symmetry-Aware_Geometry_Correspondences_for_6D_Object_Pose_Estimation_ICCV_2023_paper.pdf",
        "ref_texts": "[43] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In CVPR , 2019. 1, 2",
        "ref_ids": [
          "43"
        ]
      },
      "Shape-constraint recurrent flow for 6d object pose estimation": {
        "authors": [
          "Yang Hai",
          "Rui Song",
          "Jiaojiao Li",
          "Yinlin Hu"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Hai_Shape-Constraint_Recurrent_Flow_for_6D_Object_Pose_Estimation_CVPR_2023_paper.pdf",
        "ref_texts": "[36] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. PVNet: Pixel-Wise V oting Network for 6DoF Pose Estimation. In Conference on Computer Vision and Pattern Recognition , 2019. 2, 5, 6",
        "ref_ids": [
          "36"
        ]
      },
      "Nerf-pose: A first-reconstruct-then-regress approach for weakly-supervised 6d object pose estimation": {
        "authors": [
          "Fu Li",
          "Shishir Reddy",
          "Hao Yu",
          "Ivan Shugurov",
          "Benjamin Busam",
          "Shaowu Yang",
          "Slobodan Ilic"
        ],
        "url": "https://openaccess.thecvf.com/content/ICCV2023W/R6D/papers/Li_NeRF-Pose_A_First-Reconstruct-Then-Regress_Approach_for_Weakly-Supervised_6D_Object_Pose_Estimation_ICCVW_2023_paper.pdf",
        "ref_texts": "[36] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 4561\u20134570, 2019.",
        "ref_ids": [
          "36"
        ]
      },
      "Query6dof: Learning sparse queries as implicit shape prior for category-level 6dof pose estimation": {
        "authors": [
          "Ruiqi Wang",
          "Xinggang Wang",
          "Te Li",
          "Rong Yang",
          "Minhong Wan",
          "Wenyu Liu"
        ],
        "url": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Query6DoF_Learning_Sparse_Queries_as_Implicit_Shape_Prior_for_Category-Level_ICCV_2023_paper.pdf",
        "ref_texts": "[25] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 4561\u2013",
        "ref_ids": [
          "25"
        ]
      },
      "Crt-6d: Fast 6d object pose estimation with cascaded refinement transformers": {
        "authors": [
          "Pedro Castro",
          "Kyun Kim"
        ],
        "url": "https://openaccess.thecvf.com/content/WACV2023/papers/Castro_CRT-6D_Fast_6D_Object_Pose_Estimation_With_Cascaded_Refinement_Transformers_WACV_2023_paper.pdf",
        "ref_texts": "[34] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In CVPR , 2019.",
        "ref_ids": [
          "34"
        ]
      },
      "Rigidity-aware detection for 6d object pose estimation": {
        "authors": [
          "Yang Hai",
          "Rui Song",
          "Jiaojiao Li",
          "Mathieu Salzmann",
          "Yinlin Hu"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2023/papers/Hai_Rigidity-Aware_Detection_for_6D_Object_Pose_Estimation_CVPR_2023_paper.pdf",
        "ref_texts": "[33] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. PVNet: Pixel-Wise V oting Network for 6DoF Pose Estimation. In Conference on Computer Vision and Pattern Recognition , 2019. 2",
        "ref_ids": [
          "33"
        ]
      },
      "Nerf-loc: Visual localization with conditional neural radiance field": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2304.07979",
        "ref_texts": "[21] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 4561\u20134570, 2019.",
        "ref_ids": [
          "21"
        ]
      },
      "PoET: Pose estimation transformer for single-view, multi-object 6D pose estimation": {
        "authors": [
          "Anonymous Submission"
        ],
        "url": "https://proceedings.mlr.press/v205/jantos23a/jantos23a.pdf",
        "ref_texts": "[20] S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 4561\u20134570, 2019.",
        "ref_ids": [
          "20"
        ]
      },
      "Pseudo flow consistency for self-supervised 6d object pose estimation": {
        "authors": [
          "Yang Hai",
          "Rui Song",
          "Jiaojiao Li",
          "David Ferstl",
          "Yinlin Hu"
        ],
        "url": "https://openaccess.thecvf.com/content/ICCV2023/papers/Hai_Pseudo_Flow_Consistency_for_Self-Supervised_6D_Object_Pose_Estimation_ICCV_2023_paper.pdf",
        "ref_texts": "[42] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. PVNet: Pixel-Wise V oting Network for 6DoF Pose Estimation. In Conference on Computer Vision and Pattern Recognition , 2019. 1, 2",
        "ref_ids": [
          "42"
        ]
      },
      "Posematcher: One-shot 6d object pose estimation by deep feature matching": {
        "authors": [
          "Pedro Castro",
          "Kyun Kim"
        ],
        "url": "https://openaccess.thecvf.com/content/ICCV2023W/R6D/papers/Castro_PoseMatcher_One-Shot_6D_Object_Pose_Estimation_by_Deep_Feature_Matching_ICCVW_2023_paper.pdf",
        "ref_texts": "[30] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In CVPR , 2019. 2,6,7,8",
        "ref_ids": [
          "30"
        ]
      },
      "Multi-object manipulation via object-centric neural scattering functions": {
        "authors": [
          "Stephen Tian",
          "Yancheng Cai",
          "Xing Yu",
          "Sergey Zakharov",
          "Katherine Liu",
          "Adrien Gaidon",
          "Yunzhu Li",
          "Jiajun Wu"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2023/papers/Tian_Multi-Object_Manipulation_via_Object-Centric_Neural_Scattering_Functions_CVPR_2023_paper.pdf",
        "ref_texts": "[41] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. PVNet: Pixel-wise voting network for 6DoF pose estimation. In CVPR , pages 4561\u20134570, 2019. 2",
        "ref_ids": [
          "41"
        ]
      },
      "Revisiting Fully Convolutional Geometric Features for Object 6D Pose Estimation": {
        "authors": [
          "Jaime Corsetti",
          "Davide Boscaini",
          "Fabio Poiesi"
        ],
        "url": "https://openaccess.thecvf.com/content/ICCV2023W/R6D/papers/Corsetti_Revisiting_Fully_Convolutional_Geometric_Features_for_Object_6D_Pose_Estimation_ICCVW_2023_paper.pdf",
        "ref_texts": "[31] S. Peng, Y. Liu, Q. Huang, X. Zhou, and H. Bao. PVNet: Pixel-wise voting network for 6dof pose estimation. In CVPR , 2019. 2",
        "ref_ids": [
          "31"
        ]
      },
      "Center-Based Decoupled Point-cloud Registration for 6D Object Pose Estimation": {
        "authors": [
          "Haobo Jiang",
          "Zheng Dang",
          "Shuo Gu",
          "Jin Xie",
          "Mathieu Salzmann",
          "Jian Yang"
        ],
        "url": "https://openaccess.thecvf.com/content/ICCV2023/papers/Jiang_Center-Based_Decoupled_Point-cloud_Registration_for_6D_Object_Pose_Estimation_ICCV_2023_paper.pdf",
        "ref_texts": "[51] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In CVPR , 2019. 1",
        "ref_ids": [
          "51"
        ]
      },
      "Generative category-level shape and pose estimation with semantic primitives": {
        "authors": [
          "Anonymous Submission"
        ],
        "url": "https://proceedings.mlr.press/v205/li23d/li23d.pdf",
        "ref_texts": "[9]S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 4561\u20134570, 2019.",
        "ref_ids": [
          "9"
        ]
      },
      "Checkerpose: Progressive dense keypoint localization for object pose estimation with graph neural network": {
        "authors": [
          "Ruyi Lian",
          "Haibin Ling"
        ],
        "url": "http://openaccess.thecvf.com/content/ICCV2023/papers/Lian_CheckerPose_Progressive_Dense_Keypoint_Localization_for_Object_Pose_Estimation_with_ICCV_2023_paper.pdf",
        "ref_texts": "[43] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. PVNet: pixel-wise voting network for 6dof pose estimation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) , pages 4561\u20134570, 2019. 1, 2, 4, 5, 7",
        "ref_ids": [
          "43"
        ]
      },
      "Chain-of-thought predictive control": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2304.00776",
        "ref_texts": "11 Chain-of-Thought Predictive Control Laskey, M., Lee, J., Fox, R., Dragan, A., and Goldberg, K. Dart: Noise injection for robust imitation learning. InConference on robot learning , pp. 143\u2013156. PMLR, 2017. Levine, S., Kumar, A., Tucker, G., and Fu, J. Offline reinforcement learning: Tutorial, review, and perspectives on open problems. arXiv preprint arXiv:2005.01643 , 2020. Liang, Z., Bethard, S., and Surdeanu, M. Explainable multihop verbal reasoning through internal monologue. In Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies , 2021. Ling, W., Yogatama, D., Dyer, C., and Blunsom, P. Program induction by rationale generation: Learning to solve and explain algebraic word problems. arXiv preprint arXiv:1705.04146 , 2017. Liu, F., Liu, H., Grover, A., and Abbeel, P. Masked autoencoding for scalable and generalizable decision making. arXiv preprint arXiv:2211.12740 , 2022. Lynch, C., Khansari, M., Xiao, T., Kumar, V ., Tompson, J., Levine, S., and Sermanet, P. Learning latent plans from play. In Conference on robot learning , pp. 1113\u20131132. PMLR, 2020. Mandi, Z., Liu, F., Lee, K., and Abbeel, P. Towards more generalizable one-shot visual imitation learning. arXiv preprint arXiv:2110.13423 , 2021. Mandlekar, A., Xu, D., Wong, J., Nasiriany, S., Wang, C., Kulkarni, R., Fei-Fei, L., Savarese, S., Zhu, Y ., and Mart \u00b4\u0131n-Mart \u00b4\u0131n, R. What matters in learning from offline human demonstrations for robot manipulation. arXiv preprint arXiv:2108.03298 , 2021. Mu, T., Gu, J., Jia, Z., Tang, H., and Su, H. Refactoring policy for compositional generalizability using selfsupervised object proposals. Advances in Neural Information Processing Systems , 33:8883\u20138894, 2020. Mu, T., Ling, Z., Xiang, F., Yang, D., Li, X., Tao, S., Huang, Z., Jia, Z., and Su, H. Maniskill: Generalizable manipulation skill benchmark with large-scale demonstrations. arXiv preprint arXiv:2107.14483 , 2021. Nair, A., Dalal, M., Gupta, A., and Levine, S. Accelerating online reinforcement learning with offline datasets. arXiv preprint arXiv:2006.09359 , 2020. Nye, M., Andreassen, A. J., Gur-Ari, G., Michalewski, H., Austin, J., Bieber, D., Dohan, D., Lewkowycz, A., Bosma, M., Luan, D., et al. Show your work: Scratchpads for intermediate computation with language models. arXiv preprint arXiv:2112.00114 , 2021.Pan, Y ., Li, Y ., Zhang, Y ., Cai, Q., Long, F., Qiu, Z., Yao, T., and Mei, T. Silver-bullet-3d at maniskill 2021: Learning-from-demonstrations and heuristic rulebased methods for object manipulation. arXiv preprint arXiv:2206.06289 , 2022. Paster, K., McIlraith, S., and Ba, J. You can\u2019t count on luck: Why decision transformers fail in stochastic environments. arXiv preprint arXiv:2205.15967 , 2022. Peng, S., Liu, Y ., Huang, Q., Zhou, X., and Bao, H. Pvnet: Pixel-wise voting network for 6dof pose estimation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pp. 4561\u20134570, 2019. Pertsch, K., Lee, Y ., and Lim, J. Accelerating reinforcement learning with learned skill priors. In Conference on robot learning , pp. 188\u2013204. PMLR, 2021. Pfrommer, S., Halm, M., and Posa, M. Contactnets: Learning discontinuous contact dynamics with smooth, implicit representations. In Conference on Robot Learning , pp."
      },
      "Interacting hand-object pose estimation via dense mutual attention": {
        "authors": [
          "Rong Wang",
          "Wei Mao",
          "Hongdong Li"
        ],
        "url": "https://openaccess.thecvf.com/content/WACV2023/papers/Wang_Interacting_Hand-Object_Pose_Estimation_via_Dense_Mutual_Attention_WACV_2023_paper.pdf",
        "ref_texts": "[31] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 4561\u2013",
        "ref_ids": [
          "31"
        ]
      },
      "Stereopose: Category-level 6d transparent object pose estimation from stereo images via back-view nocs": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2211.01644",
        "ref_texts": "[10] S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao, \u201cPvnet: Pixelwise voting network for 6dof pose estimation,\u201d in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , 2019, pp. 4561\u20134570.",
        "ref_ids": [
          "10"
        ]
      },
      "Symfm6d: Symmetry-aware multi-directional fusion for multi-view 6d object pose estimation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2307.00306",
        "ref_texts": "[21] S. Peng et al. , \u201cPVNet: Pixel-wise voting network for 6DoF pose estimation,\u201d in CVPR , 2019, pp. 4561\u20134570.",
        "ref_ids": [
          "21"
        ]
      },
      "Linear-covariance loss for end-to-end learning of 6d pose estimation": {
        "authors": [
          "Fulin Liu",
          "Yinlin Hu",
          "Mathieu Salzmann"
        ],
        "url": "http://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Linear-Covariance_Loss_for_End-to-End_Learning_of_6D_Pose_Estimation_ICCV_2023_paper.pdf",
        "ref_texts": "[41] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) , June 2019. 1, 2",
        "ref_ids": [
          "41"
        ]
      },
      "Digital twin tracking dataset (DTTD): a new RGB+ depth 3D dataset for longer-range object tracking applications": {
        "authors": [
          "Weiyu Feng",
          "Seth Z. Zhao",
          "Chuanyu Pan",
          "Adam Chang",
          "Yichen Chen",
          "Zekun Wang",
          "Allen Y. Yang"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2023W/VDU/papers/Feng_Digital_Twin_Tracking_Dataset_DTTD_A_New_RGBDepth_3D_Dataset_CVPRW_2023_paper.pdf",
        "ref_texts": "[23] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In CVPR , 2019. 3",
        "ref_ids": [
          "23"
        ]
      },
      "Generalizable pose estimation using implicit scene representations": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2305.17252",
        "ref_texts": "[13] S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao, \u201cPvnet: Pixelwise voting network for 6dof pose estimation,\u201d in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , 2019, pp. 4561\u20134570.",
        "ref_ids": [
          "13"
        ]
      },
      "Cad2render: A modular toolkit for gpu-accelerated photorealistic synthetic data generation for the manufacturing industry": {
        "authors": [
          "Steven Moonen",
          "Bram Vanherle",
          "Taoufik Bourgana",
          "Abdellatif Bey",
          "Nick Michiels"
        ],
        "url": "https://openaccess.thecvf.com/content/WACV2023W/PIES-CV/papers/Moonen_CAD2Render_A_Modular_Toolkit_for_GPU-Accelerated_Photorealistic_Synthetic_Data_Generation_WACVW_2023_paper.pdf",
        "ref_texts": "[17] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In CVPR , 2019.",
        "ref_ids": [
          "17"
        ]
      },
      "Complementary bi-directional feature compression for indoor 360deg semantic segmentation with self-distillation": {
        "authors": [
          "Zishuo Zheng",
          "Chunyu Lin",
          "Lang Nie",
          "Kang Liao",
          "Zhijie Shen",
          "Yao Zhao"
        ],
        "url": "https://openaccess.thecvf.com/content/WACV2023/papers/Zheng_Complementary_Bi-Directional_Feature_Compression_for_Indoor_360deg_Semantic_Segmentation_With_WACV_2023_paper.pdf",
        "ref_texts": "[26] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 4561\u2013",
        "ref_ids": [
          "26"
        ]
      },
      "Toward 3d face reconstruction in perspective projection: Estimating 6dof face pose from monocular image": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2205.04126",
        "ref_texts": "[15] S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao, \u201cPvnet: Pixelwise voting network for 6dof pose estimation,\u201d in IEEE Conference on Computer Vision and Pattern Recognition , 2019, pp. 4561\u20134570.",
        "ref_ids": [
          "15"
        ]
      },
      "Fusionnet: An end-to-end hybrid model for 6D object pose estimation": {
        "authors": [
          "Yuning Ye",
          "Hanhoon Park"
        ],
        "url": "https://www.mdpi.com/2079-9292/12/19/4162/pdf",
        "ref_texts": "39. Peng, S.; Zhou, X.; Liu, Y.; Lin, H.; Huang, Q.; Bao, H. PVNet: Pixel-Wise Voting Network for 6DoF Object Pose Estimation. IEEE Trans. Pattern Anal. Mach. Intell. 2022 ,44, 3212\u20133223. [CrossRef] [PubMed]",
        "ref_ids": [
          "39"
        ]
      },
      "Optimal and Robust Category-Level Perception: Object Pose and Shape Estimation From 2-D and 3-D Semantic Keypoints": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2206.12498",
        "ref_texts": "[96] S. Peng et al. , \u201cPVNet: Pixel-wise V oting Network for 6DoF Pose Estimation,\u201d in IEEE Conf. on Computer Vision and Pattern Recognition (CVPR) , 2019, pp. 4561\u20134570.",
        "ref_ids": [
          "96"
        ]
      },
      "External camera-based mobile robot pose estimation for collaborative perception with smart edge sensors": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2303.03797",
        "ref_texts": "[28] S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao, \u201cPVNet: Pixel-wise voting network for 6DoF pose estimation,\u201d in IEEE Conf. on Computer Vision and Pattern Recognition (CVPR) , 2019, pp. 4561\u20134570.",
        "ref_ids": [
          "28"
        ]
      },
      "SMOC-Net: Leveraging Camera Pose for Self-Supervised Monocular Object Pose Estimation": {
        "authors": [
          "Tao Tan",
          "Qiulei Dong"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Tan_SMOC-Net_Leveraging_Camera_Pose_for_Self-Supervised_Monocular_Object_Pose_Estimation_CVPR_2023_paper.pdf",
        "ref_texts": "[22] Sida Peng, Xiaowei Zhou, Yuan Liu, Haotong Lin, Qixing Huang, and Hujun Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In CVPR , pages 4561\u20134570, 2019.",
        "ref_ids": [
          "22"
        ]
      },
      "6d pose estimation for textureless objects on rgb frames using multi-view optimization": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2210.11554",
        "ref_texts": "[26] S. Peng, Y. Liu, Q. Huang, X. Zhou, and H. Bao, \u201cPvnet: Pixel-wise voting network for 6dof pose estimation,\u201d in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pp. 4561\u20134570, 2019.",
        "ref_ids": [
          "26"
        ]
      },
      "Perceiving unseen 3d objects by poking the objects": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2302.13375",
        "ref_texts": "[4] S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao, \u201cPvnet: Pixelwise voting network for 6dof pose estimation,\u201d in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , 2019, pp. 4561\u20134570.",
        "ref_ids": [
          "4"
        ]
      },
      "Easyhec: Accurate and automatic hand-eye calibration via differentiable rendering and space exploration": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2305.01191",
        "ref_texts": "[25] S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao, \u201cPvnet: Pixelwise voting network for 6dof pose estimation,\u201d in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , 2019, pp. 4561\u20134570.",
        "ref_ids": [
          "25"
        ]
      },
      "DR-Pose: A Two-stage Deformation-and-Registration Pipeline for Category-level 6D Object Pose Estimation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2309.01925",
        "ref_texts": "[7] S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao, \u201cPvnet: Pixel-wise voting network for 6dof pose estimation,\u201d in CVPR , 2019.",
        "ref_ids": [
          "7"
        ]
      },
      "Diff-dope: Differentiable deep object pose estimation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2310.00463",
        "ref_texts": "[29] S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao, \u201cPVNet: Pixelwise voting network for 6DoF pose estimation,\u201d in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) , 2019, pp. 4561\u20134570.",
        "ref_ids": [
          "29"
        ]
      },
      "Spyropose: Se (3) pyramids for object pose distribution estimation": {
        "authors": [
          "Rasmus Laurvig",
          "Frederik Hagelskjaer",
          "Thorbjorn Mosekjaer"
        ],
        "url": "https://openaccess.thecvf.com/content/ICCV2023W/R6D/papers/Haugaard_SpyroPose_SE3_Pyramids_for_Object_Pose_Distribution_Estimation_ICCVW_2023_paper.pdf",
        "ref_texts": "[24] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 4561\u2013",
        "ref_ids": [
          "24"
        ]
      },
      "Knowledge distillation for 6d pose estimation by aligning distributions of local predictions": {
        "authors": [
          "Shuxuan Guo",
          "Yinlin Hu",
          "Jose M. Alvarez",
          "Mathieu Salzmann"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2023/papers/Guo_Knowledge_Distillation_for_6D_Pose_Estimation_by_Aligning_Distributions_of_CVPR_2023_paper.pdf",
        "ref_texts": "[33] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. PVNet: Pixel-wise V oting Network for 6DoF Pose Estimation. In Conference on Computer Vision and Pattern Recognition , 2019. 1, 2, 3, 4",
        "ref_ids": [
          "33"
        ]
      },
      "Collision-aware in-hand 6d object pose estimation using multiple vision-based tactile sensors": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2301.13667",
        "ref_texts": "[3]S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao, \u201cPVNet: PixelWise Voting Network for 6DoF Pose Estimation,\u201d in 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) . IEEE, 2019, pp. 4556\u20134565.",
        "ref_ids": [
          "3"
        ]
      },
      "2d semantic segmentation: Recent developments and future directions": {
        "authors": [
          "Yu Guo",
          "Guigen Nie",
          "Wenliang Gao",
          "Mi Liao"
        ],
        "url": "https://www.mdpi.com/1999-5903/15/6/205/pdf",
        "ref_texts": "17. Peng, S.; Liu, Y.; Huang, Q.; Zhou, X.; Bao, H. Pvnet: Pixel-wise voting network for 6dof pose estimation. In Proceedings of the 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition, Long Beach, CA, USA, 16\u201320 June 2019.",
        "ref_ids": [
          "17"
        ]
      },
      "3d-aware hypothesis & verification for generalizable relative object pose estimation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2310.03534",
        "ref_texts": "6771\u20136780, 2022. Keunhong Park, Arsalan Mousavian, Yu Xiang, and Dieter Fox. Latentfusion: End-to-end differentiable reconstruction and rendering for unseen object pose estimation. In Proceedings of the IEEE conference on Computer Vision and Pattern Recognition , pp. 10710\u201310719, 2020. Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pp. 4561\u20134570, 2019. Ren\u00b4e Ranftl, Katrin Lasinger, David Hafner, Konrad Schindler, and Vladlen Koltun. Towards robust monocular depth estimation: Mixing datasets for zero-shot cross-dataset transfer. IEEE transactions on Pattern Analysis and Machine Intelligence , 44(3):1623\u20131637, 2020. Jeremy Reizenstein, Roman Shapovalov, Philipp Henzler, Luca Sbordone, Patrick Labatut, and David Novotny. Common objects in 3d: Large-scale learning and evaluation of real-life 3d category reconstruction. In Proceedings of the IEEE/CVF International Conference on Computer Vision , pp. 10901\u201310911, 2021. Ethan Rublee, Vincent Rabaud, Kurt Konolige, and Gary Bradski. Orb: An efficient alternative to sift or surf. In Proceedings of the IEEE/CVF International Conference on Computer Vision , pp."
      },
      "Uni6Dv2: Noise elimination for 6D pose estimation": {
        "authors": [],
        "url": "https://proceedings.mlr.press/v206/sun23b/sun23b.pdf",
        "ref_texts": "2125. Mallick, T., Das, P. P., and Majumdar, A. K. (2014). Characterizations of noise in kinect depth images: A review. IEEE Sensors journal , 14(6):1731\u20131740. Marchand, E., Uchiyama, H., and Spindler, F. (2015). Pose estimation for augmented reality: a hands-on survey. IEEE transactions on visualization and computer graphics, 22(12):2633\u20132651. Mo, N., Gan, W., Yokoya, N., and Chen, S. (2022). Es6d: A computation efficient and symmetry-aware 6d pose regression framework. arXiv preprint arXiv:2204.01080 . Mingshan Sun, Ye Zheng, Tianpeng Bao, Jianqiu Chen, et al. Newell, A., Yang, K., and Deng, J. (2016). Stacked hourglass networks for human pose estimation. In European conference on computer vision , pages 483\u2013499. Oberweger, M., Rad, M., and Lepetit, V . (2018). Making deep heatmaps robust to partial occlusions for 3d object pose estimation. In Proceedings of the European Conference on Computer Vision (ECCV) , pages 119\u2013134. Peng, S., Liu, Y ., Huang, Q., Zhou, X., and Bao, H. (2019a). Pvnet: Pixel-wise voting network for 6dof pose estimation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 4561\u2013",
        "ref_ids": [
          "2125"
        ]
      },
      "Multi-view keypoints for reliable 6d object pose estimation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2303.16833",
        "ref_texts": "[7] Peng, S., Liu, Y ., Huang, Q., Zhou, X., Bao, H. Pvnet: Pixel-wise voting network for 6dof pose estimation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. (2019)",
        "ref_ids": [
          "7"
        ]
      },
      "icomma: Inverting 3d gaussians splatting for camera pose estimation via comparing and matching": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2312.09031",
        "ref_texts": "28. Peng, S., Liu, Y., Huang, Q., Zhou, X., Bao, H.: Pvnet: Pixel-wise voting network for 6dof pose estimation. In: CVPR. pp. 4561\u20134570 (2019) 1",
        "ref_ids": [
          "28"
        ]
      },
      "Depth-based 6dof object pose estimation using swin transformer": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2303.02133",
        "ref_texts": "[10] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. PVNet: Pixel-wise V oting Network for 6DOF Pose Estimation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 4561\u20134570, 2019.",
        "ref_ids": [
          "10"
        ]
      },
      "YOLOPose V2: Understanding and improving transformer-based 6D pose estimation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2307.11550",
        "ref_texts": "[40] Peng, S., Liu, Y., Huang, Q., Zhou, X., Bao, H.: PVNet: Pixel-wise voting network for 6DOF pose estimation. In: IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pp. 4561\u20134570 (2019)",
        "ref_ids": [
          "40"
        ]
      },
      "Ist-net: Prior-free category-level pose estimation with implicit space transformation": {
        "authors": [
          "Jianhui Liu",
          "Yukang Chen",
          "Xiaoqing Ye",
          "Xiaojuan Qi"
        ],
        "url": "https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_IST-Net_Prior-Free_Category-Level_Pose_Estimation_with_Implicit_Space_Transformation_ICCV_2023_paper.pdf",
        "ref_texts": "[30] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 4561\u2013",
        "ref_ids": [
          "30"
        ]
      },
      "LanPose: Language-Instructed 6D Object Pose Estimation for Robotic Assembly": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2310.13819",
        "ref_texts": "[9] S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao, \u201cPvnet: Pixelwise voting network for 6dof pose estimation,\u201d in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , 2019, pp. 4561\u20134570.",
        "ref_ids": [
          "9"
        ]
      },
      "6D Object Pose Estimation Based on Cross-Modality Feature Fusion": {
        "authors": [
          "Meng Jiang",
          "Liming Zhang",
          "Xiaohua Wang",
          "Shuang Li",
          "Yijie Jiao"
        ],
        "url": "https://www.mdpi.com/1424-8220/23/19/8088/pdf",
        "ref_texts": "26. Peng, S.; Liu, Y.; Huang, Q.; Zhou, X.; Bao, H. Pvnet: Pixel-wise voting network for 6dof pose estimation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, Long Beach, CA, USA, 15\u201320 June 2019; pp. 4561\u20134570.",
        "ref_ids": [
          "26"
        ]
      },
      "Enhancing 6-DoF object pose estimation through multiple modality fusion: a hybrid CNN architecture with cross-layer and cross-modal integration": {
        "authors": [
          "Zihang Wang",
          "Xueying Sun",
          "Hao Wei",
          "Qing Ma",
          "Qiang Zhang"
        ],
        "url": "https://www.mdpi.com/2075-1702/11/9/891/pdf",
        "ref_texts": "50. Peng, S.; Liu, Y.; Huang, Q.; Bao, H.; Zhou, X. PVNet: Pixel-Wise Voting Network for 6DoF Pose Estimation. IEEE Trans. Pattern Anal. Mach. Intell. 2022 ,44, 3212\u20133223. [CrossRef]",
        "ref_ids": [
          "50"
        ]
      },
      "For a more comprehensive evaluation of 6dof object pose tracking": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2309.07796",
        "ref_texts": "[24] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. PVNet: Pixel-Wise V oting Network for 6DoF Pose Estimation. In IEEE/CVF Conference on CVPR , pages 4556\u20134565, Long Beach, CA, USA, June 2019. IEEE.",
        "ref_ids": [
          "24"
        ]
      },
      "Learning bifunctional push-grasping synergistic strategy for goal-agnostic and goal-oriented tasks": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2212.01763",
        "ref_texts": "[24] S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao, \u201cPvnet: Pixel-wise voting network for 6dof pose estimation,\u201d in IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2019, pp. 4561\u2013",
        "ref_ids": [
          "24"
        ]
      },
      "Sd-pose: Structural discrepancy aware category-level 6d object pose estimation": {
        "authors": [
          "Guowei Li",
          "Dongchen Zhu",
          "Guanghui Zhang",
          "Wenjun Shi",
          "Tianyu Zhang",
          "Xiaolin Zhang",
          "Jiamao Li"
        ],
        "url": "https://openaccess.thecvf.com/content/WACV2023/papers/Li_SD-Pose_Structural_Discrepancy_Aware_Category-Level_6D_Object_Pose_Estimation_WACV_2023_paper.pdf",
        "ref_texts": "[27] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 4561\u2013",
        "ref_ids": [
          "27"
        ]
      },
      "Transpose: A transformer-based 6d object pose estimation network with depth refinement": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2307.05561",
        "ref_texts": "[49] S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao, \u201cPvnet: Pixelwise voting network for 6dof pose estimation,\u201d in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , 2019, pp. 4561\u20134570.",
        "ref_ids": [
          "49"
        ]
      },
      "QaQ: Robust 6D pose estimation via quality-assessed RGB-D fusion": {
        "authors": [],
        "url": "https://hal.science/hal-04166639/file/MVA_2023.pdf",
        "ref_texts": "[12] Peng, S., Liu, Y., Huang, Q., Zhou, X. & Bao, H. Pvnet: Pixel-wise voting network for 6dof pose estimation. Proceedings Of The IEEE Conference On Computer Vision And Pattern Recognition . pp. 4561-4570",
        "ref_ids": [
          "12"
        ]
      },
      "Efficient Multi-Object Pose Estimation using Multi-Resolution Deformable Attention and Query Aggregation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2312.08268",
        "ref_texts": "[10] S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao, \u201cPVNet: Pixel-wise voting network for 6DOF pose estimation,\u201d in IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) , 2019.",
        "ref_ids": [
          "10"
        ]
      },
      "Exploiting Point-Wise Attention in 6D Object Pose Estimation Based on Bidirectional Prediction": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2308.08518",
        "ref_texts": "[9] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , pages 4561\u20134570, 2019.",
        "ref_ids": [
          "9"
        ]
      },
      "FilterformerPose: Satellite Pose Estimation Using Filterformer": {
        "authors": [
          "Ruida Ye",
          "Lifen Wang",
          "Yuan Ren",
          "Yujing Wang",
          "Xiaocen Chen",
          "Yufei Liu"
        ],
        "url": "https://www.mdpi.com/1424-8220/23/20/8633/pdf",
        "ref_texts": "20. Peng, S.; Liu, Y.; Huang, Q.; Zhou, X.; Bao, H. PVNet: Pixel-Wise Voting Network for 6DoF Pose Estimation. In Proceedings of the 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), Long Beach, CA, USA, 15\u201320 June 2019; pp. 4556\u20134565.",
        "ref_ids": [
          "20"
        ]
      },
      "NormNet: Scale Normalization for 6D Pose Estimation in Stacked Scenarios": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2311.09269",
        "ref_texts": "[21] S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao, \u201cPvnet: Pixelwise voting network for 6dof pose estimation,\u201d in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , 2019, pp. 4561\u20134570.",
        "ref_ids": [
          "21"
        ]
      },
      "Rigidity preserving image transformations and equivariance in perspective": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2201.13065",
        "ref_texts": "44.Peng, S., Liu, Y., Huang, Q., Zhou, X., Bao, H.: Pvnet: Pixel-wise voting network for 6dof pose estimation. In: IEEE/CVF Conf. Computer Vision and Pattern Recognition (2019)",
        "ref_ids": [
          "44"
        ]
      },
      "Pseudo-keypoints RKHS Learning for Self-supervised 6DoF Pose Estimation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2311.09500",
        "ref_texts": "61. Peng, S., Liu, Y., Huang, Q., Zhou, X., Bao, H.: Pvnet: Pixel-wise voting network for 6dof pose estimation. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 4561\u20134570 (2019) 3, 4, 6, 9",
        "ref_ids": [
          "61"
        ]
      },
      "Deep Learning-Based 6-DoF Object Pose Estimation Considering Synthetic Dataset": {
        "authors": [
          "Tianyu Zheng",
          "Chunyan Zhang",
          "Shengwen Zhang",
          "Yanyan Wang"
        ],
        "url": "https://www.mdpi.com/1424-8220/23/24/9854/pdf",
        "ref_texts": "19. Peng, S.; Liu, Y.; Huang, Q.; Zhou, X.; Bao, H. Pvnet: Pixel-Wise Voting Network for 6dof Pose Estimation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, Seoul, Republic of Korea, 27 October\u20132 November 2019; pp. 4561\u20134570.",
        "ref_ids": [
          "19"
        ]
      },
      "DeepRM: Deep Recurrent Matching for 6D Pose Refinement": {
        "authors": [
          "Alexander Avery",
          "Andreas Savakis"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2023W/RHOBIN/papers/Avery_DeepRM_Deep_Recurrent_Matching_for_6D_Pose_Refinement_CVPRW_2023_paper.pdf",
        "ref_texts": "[22] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. PVNET: Pixel-wise voting network for 6dof pose estimation. Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition , 2019June:4556\u20134565, dec 2019. 2, 5, 6",
        "ref_ids": [
          "22"
        ]
      },
      "AttentionPose: Attention-driven end-to-end model for precise 6D pose estimation": {
        "authors": [],
        "url": "https://www.degruyter.com/document/doi/10.1515/jisys-2023-0153/pdf",
        "ref_texts": "[13] Peng S, Zhou X, Liu Y, Lin H, Huang Q, Bao H. PVNet: Pixel-wise voting network for 6DoF object pose estimation. IEEE Trans Pattern Anal Mach Intell. 2022;44(6):3212 \u201323.",
        "ref_ids": [
          "13"
        ]
      },
      "Dual Branch PnP Based Network for Monocular 6D Pose Estimation": {
        "authors": [],
        "url": "https://cdn.techscience.cn/files/iasc/2023/TSP_IASC-36-3/TSP_IASC_35812/TSP_IASC_35812.pdf",
        "ref_texts": "[23] S. Peng, Y. Liu, Q. Huang, X. Zhou and H. Bao, \u201cPVNet: Pixel-wise voting network for 6D of pose estimation, \u201din Proc. CVPR , Long Beach, CA, USA, pp. 4556 \u20134565, 2019.",
        "ref_ids": [
          "23"
        ]
      },
      "MSDA: Monocular Self-supervised Domain Adaptation for 6D Object Pose Estimation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2302.07300",
        "ref_texts": "23. Peng, S., Zhou, X., Liu, Y., Lin, H., Huang, Q., Bao, H.: Pvnet: pixel-wise voting network for 6dof object pose estimation. IEEE Transactions on Pattern Analysis and Machine Intelligence (2020)",
        "ref_ids": [
          "23"
        ]
      },
      "PViT-6D: Overclocking Vision Transformers for 6D Pose Estimation with Confidence-Level Prediction and Pose Tokens": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2311.17504",
        "ref_texts": "[33] Sida Peng, Yuan Liu, Qixing Huang, Hujun Bao, and Xiaowei Zhou. Pvnet: Pixel-wise voting network for 6dof pose estimation. CoRR , abs/1812.11788, 2018. 1, 2, 8",
        "ref_ids": [
          "33"
        ]
      },
      "Manifold-aware self-training for unsupervised domain adaptation on regressing 6D object pose": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2305.10808",
        "ref_texts": "[Peng et al. , 2019 ]Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In CVPR , 2019.",
        "ref_ids": [
          "Peng et al\\. , 2019 "
        ]
      },
      "Robust and Efficient Edge-guided Pose Estimation with Resolution-conditioned NeRF.": {
        "authors": [],
        "url": "https://papers.bmvc2023.org/0543.pdf",
        "ref_texts": "[30] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2019 , pages 4561\u20134570. Computer Vision Foundation / IEEE, 2019. doi: 10.1109/CVPR.2019.00469.",
        "ref_ids": [
          "30"
        ]
      },
      "Accurate robotic grasp detection with angular label smoothing": {
        "authors": [],
        "url": "https://jcst.ict.ac.cn/en/article/pdf/preview/10.1007/s11390-022-1458-5.pdf",
        "ref_texts": "\u00a0Peng S D, Liu Y, Huang Q X, Zhou X W, Bao H J. PVNet: Pixel-wise voting network for 6DoF pose estimation. In Proc. the 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition , Jun. 2019, pp.4556\u20134565. DOI: 10.1109/CVPR.2019.00469.[20]",
        "ref_ids": [
          "20"
        ]
      },
      "An open-source recipe for building simulated robot manipulation benchmarks": {
        "authors": [],
        "url": "https://cseweb.ucsd.edu/~jigu/pdf/icra23-compare.pdf",
        "ref_texts": "[25] S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao, \u201cPvnet: Pixelwise voting network for 6dof pose estimation,\u201d in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , 2019, pp. 4561\u20134570.",
        "ref_ids": [
          "25"
        ]
      },
      "Keypoint matching via random network consensus": {
        "authors": [],
        "url": "https://openreview.net/pdf?id=WhbWzFg8cZ",
        "ref_texts": "11 Under review as a conference paper at ICLR 2023 David G Lowe. Distinctive image features from scale-invariant keypoints. International journal of computer vision , 60(2):91\u2013110, 2004. Zixin Luo, Tianwei Shen, Lei Zhou, Jiahui Zhang, Yao Yao, Shiwei Li, Tian Fang, and Long Quan. Contextdesc: Local descriptor augmentation with cross-modality context. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , pp. 2527\u20132536, 2019. Zixin Luo, Lei Zhou, Xuyang Bai, Hongkai Chen, Jiahui Zhang, Yao Yao, Shiwei Li, Tian Fang, and Long Quan. Aslfeat: Learning local features of accurate shape and localization. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , pp. 6589\u20136598, 2020. Krystian Mikolajczyk and Cordelia Schmid. Scale & affine invariant interest point detectors. International journal of computer vision , 60(1):63\u201386, 2004. Anastasiia Mishchuk, Dmytro Mishkin, Filip Radenovic, and Jiri Matas. Working hard to know your neighbor\u2019s margins: Local descriptor learning loss. Advances in neural information processing systems , 30, 2017. Dmytro Mishkin, Filip Radenovic, and Jiri Matas. Repeatability is not enough: Learning affine regions via discriminability. In Proceedings of the European Conference on Computer Vision (ECCV) , pp. 284\u2013300, 2018. Raul Mur-Artal and Juan D Tard \u00b4os. Orb-slam2: An open-source slam system for monocular, stereo, and rgb-d cameras. IEEE transactions on robotics , 33(5):1255\u20131262, 2017. Raul Mur-Artal, Jose Maria Martinez Montiel, and Juan D Tardos. Orb-slam: a versatile and accurate monocular slam system. IEEE transactions on robotics , 31(5):1147\u20131163, 2015. Hyeonwoo Noh, Andre Araujo, Jack Sim, Tobias Weyand, and Bohyung Han. Large-scale image retrieval with attentive deep local features. In Proceedings of the IEEE international conference on computer vision , pp. 3456\u20133465, 2017. Yuki Ono, Eduard Trulls, Pascal Fua, and Kwang Moo Yi. Lf-net: Learning local features from images. Advances in neural information processing systems , 31, 2018. F. Pedregosa, G. Varoquaux, A. Gramfort, V . Michel, B. Thirion, O. Grisel, M. Blondel, P. Prettenhofer, R. Weiss, V . Dubourg, J. Vanderplas, A. Passos, D. Cournapeau, M. Brucher, M. Perrot, and E. Duchesnay. Scikit-learn: Machine learning in Python. Journal of Machine Learning Research , 12:2825\u20132830, 2011. Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pp. 4561\u20134570, 2019. Charles R Qi, Or Litany, Kaiming He, and Leonidas J Guibas. Deep hough voting for 3d object detection in point clouds. In proceedings of the IEEE/CVF International Conference on Computer Vision , pp. 9277\u20139286, 2019. Jerome Revaud, Cesar De Souza, Martin Humenberger, and Philippe Weinzaepfel. R2d2: Reliable and repeatable detector and descriptor. Advances in neural information processing systems , 32, 2019. Edward Rosten and Tom Drummond. Machine learning for high-speed corner detection. In European conference on computer vision , pp. 430\u2013443. Springer, 2006. Ethan Rublee, Vincent Rabaud, Kurt Konolige, and Gary Bradski. Orb: An efficient alternative to sift or surf. In 2011 International conference on computer vision , pp. 2564\u20132571. Ieee, 2011. Paul-Edouard Sarlin, Cesar Cadena, Roland Siegwart, and Marcin Dymczyk. From coarse to fine: Robust hierarchical localization at large scale. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pp. 12716\u201312725, 2019. Paul-Edouard Sarlin, Daniel DeTone, Tomasz Malisiewicz, and Andrew Rabinovich. Superglue: Learning feature matching with graph neural networks. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , pp. 4938\u20134947, 2020."
      },
      "Modular Quantization-Aware Training: Increasing Accuracy by Decreasing Precision in 6D Object Pose Estimation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2303.06753",
        "ref_texts": "14 Published in Transactions on Machine Learning Research (November/2024) Markus Nagel, Mart van Baalen, Tijmen Blankevoort, and Max Welling. Data-Free Quantization Through Weight Equalization and Bias Correction. In International Conference on Computer Vision , 2019. Markus Nagel, Rana Ali Amjad, Mart van Baalen, Christos Louizos, and Tijmen Blanevoort. Up or Down? Adaptive Rounding for Post-Training Quantization. In International Conference on Machine Learning , 2020. VanNguyenNguyen, ThibaultGroueix, MathieuSalzmann, andVincentLepetit. GigaPose: FastandRobust Novel Object Pose Estimation via One Correspondence. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , 2024. Tae Ha Park, Marcus M\u00e4rtens, Gurvan Lecuyer, Dario Izzo, and Simone D\u2019Amico. Speed+: Next-generation dataset for spacecraft pose estimation across domain gap. In Aerospace Conference , 2022. Sida Peng, Yuan Liu, Qixing Huang, Hujun Bao, and Xiaowei Zhou. PVNet: Pixel-wise Voting Network for 6DoF Pose Estimation. In Computer Vision and Pattern Recognition , 2019. Luis P\u00e9rez, \u00cdnigo Rodr\u00edguez, Nuria Rodr\u00edguez, Rub\u00e9n Usamentiaga, and Daniel F. Garc\u00eda. Robot Guidance Using Machine Vision Techniques in Industrial Environmnets: A Comparative Review. Sensors, 2016. Jorn Peters, Marios Fournarakis, Markus Nagel, Mart van Baalen, and Tijmen Blankevoort. QBitOpt: Fast and Accurate Bitwidth Reallocation during Training. In International Conference on Computer Vision , 2023. Jonas Pfeiffer, Ivan Vuli\u0107, Iryna Gurevych, and Sebastian Ruder. MMAD-X: An Adapter-Based Framework for Multi-Task Cross-Lingual Transfer. EMNLP, 2020. Jonas Pfeiffer, Sebastian Ruder, Ivan Vuli\u0107, and Edoardo Maria Ponti. Modular deep learning. Transactions on Machine Learning Research , 2023. Pedro F. Proen\u00e7a and Yang Gao. Deep Learning for Spacecraft Pose Estimation from Photorealistic Rendering. In International Conference on Robotics and Automation , 2020. Mahdi Rad and Vincent Lepetit. BB8: A Scalable, Accurate, Robust to Partial Occlusion Method for Predicting the 3D Poses of Challenging Objects without Using Depth. In International Conference on Computer Vision , 2017. Wenqi Shao, Mengzhao Chen, Zhaoyang Zhang, Peng Xu, Lirui Zhao, Zhiqian Li, Kaipeng Zhang, Peng Gao, Yu Qiao, and Ping Luo. OmniQuant: Omnidirectionally Calibrated Quantization for Large Language Models. In International Conference on Learning Representations , 2024. Juncheol Shin, Junhyuk So, Sein Park, Seungyeop Kang, Sungjoo Yoo, and Eunhyeok Park. NIPQ: Noise Proxy-Based Integrated Pseudo-Quantization. In Computer Vision and Pattern Recognition , 2023. Abhilasha Singh, V. Kalaichelvi, and R. Karthikeyan. A survey on vision guided robotic systems with intelligent control strategies for autonomous tasks. Cogent Engineering , 2022. Chen Song, Jiaru Song, and Qixing Huang. HybridPose: 6D Object Pose Estimation under Hybrid Representations. In Computer Vision and Pattern Recognition , 2020. Jianing Song, Duarte Rondao, and Nabil Aouf. Deep Learning-based Spacecraft Relative Navigation Methods: A Survey. Acta Astronautica , 2022. Sebastian Stapf, Tobias Bauernfeind, and Marco Riboldi. PViT-6D: Overclocking Vision Transformers for 6D Pose Estimation with Confidence-Level Prediction and Pose Tokens, 2023. URL https://arxiv.org/ abs/2311.17504 . Yongzhi Su, Mahdi Saleh, Torben Fetzer, Jason Rambach, Nassir Navab, Benjamin Busam, Didier Stricker, and Deferico Tombari. ZebraPose: Coarse to Fine Surface Encoding for 6DoF Object Pose Estimation. In Computer Vision and Pattern Recognition , 2022."
      },
      "Robust Category-Level 3D Pose Estimation from Synthetic Data": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2305.16124",
        "ref_texts": "[25] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) , June 2019. 1",
        "ref_ids": [
          "25"
        ]
      },
      "\u4f4d\u59ff\u89c6\u89c9\u6d4b\u91cf\u65b9\u6cd5\u53ca\u5e94\u7528\u7efc\u8ff0": {
        "authors": [],
        "url": "https://www.researching.cn/ArticlePdf/m00002/2023/60/3/0312010.pdf",
        "ref_texts": "[22]Peng S D , Liu Y , Huang Q X , et al . PVNet : pixel -wise voting network for 6DoF pose estimation [C]\u22252019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR ), June 15-20, 2019 , Long Beach , CA, USA . New York : IEEE Press , 2020 : 4556 -4565 .",
        "ref_ids": [
          "22",
          "C"
        ]
      },
      "A Benchmark for Cycling Close Pass Near Miss Event Detection from Video Streams": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2304.11868",
        "ref_texts": "[40] Peng, S., Liu, Y ., Huang, Q., Zhou, X., Bao, H.: Pvnet: Pixel-wise voting network for 6dof pose estimation. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 4561\u20134570",
        "ref_ids": [
          "40"
        ]
      },
      "Smart Task Assistance in Mixed Reality for Astronauts": {
        "authors": [
          "Qingwei Sun",
          "Wei Chen",
          "Jiangang Chao",
          "Wanhong Lin",
          "Zhenying Xu",
          "Ruizhi Cao"
        ],
        "url": "https://www.mdpi.com/1424-8220/23/9/4344/pdf",
        "ref_texts": "29. Peng, S.; Zhou, X.; Liu, Y.; Lin, H.; Huang, Q.; Bao, H. PVNet: Pixel-Wise Voting Network for 6DoF Object Pose Estimation. IEEE Trans. Pattern Anal. Mach. Intell. 2022 ,44, 3212\u20133223. [CrossRef] [PubMed]",
        "ref_ids": [
          "29"
        ]
      },
      "MPF6D: masked pyramid fusion 6D pose estimation": {
        "authors": [
          "Nuno Pereira"
        ],
        "url": "https://link.springer.com/content/pdf/10.1007/s10044-023-01165-9.pdf",
        "ref_texts": ""
      },
      "Jenga Stacking Based on 6D Pose Estimation for Architectural Form Finding Process": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2311.10918",
        "ref_texts": "1230. International Association for Automation and Robotics in Construction (IAARC . . . . Liu, Y ., Wen, Y ., Peng, S., Lin, C., Long, X., Komura, T., and Wang, W. (2022). Gen6d: Generalizable model-free 6-dof object pose estimation from rgb images. arXiv preprint arXiv:2204.10776 . Peng, S., Liu, Y ., Huang, Q., Zhou, X., and Bao, H. (2019). Pvnet: Pixel-wise voting network for 6dof pose estimation. In Proceedings of the IEEE /CVF Conference on Computer Vision and Pattern Recognition , pages 4561\u20134570. Rad, M. and Lepetit, V . (2017). Bb8: A scalable, accurate, robust to partial occlusion method for predicting the 3d poses of challenging objects without using depth. In Proceedings of the IEEE international conference on computer vision , pages 3828\u20133836. Roudsari, M. S., Pak, M., Smith, A., et al. (2013). Ladybug: a parametric environmental plugin for grasshopper to help designers create an environmentally-conscious design. In Proceedings of the 13th international IBPSA conference held in Lyon, France Aug , pages 3128\u20133135. Schonberger, J. L. and Frahm, J.-M. (2016). Structure-from-motion revisited. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 4104\u20134113. Sch\u00a8onberger, J. L., Zheng, E., Pollefeys, M., and Frahm, J.-M. (2016). Pixelwise view selection for unstructured multi-view stereo. In European Conference on Computer Vision (ECCV) . Schumacher, P. (2009). Parametricism: A new global style for architecture and urban design. Architectural Design , 79(4):14\u201323. Schumacher, P. (2011). The autopoiesis of architecture, Volume I: A new framework for architecture , volume 1. John Wiley & Sons. Smith, R. E. (2010). Prefab architecture: A guide to modular design and construction . John Wiley & Sons. Song, Y . (2020). Bloomshell-augmented reality for the assembly and real-time modification of complex curved structure. Song, Y ., Li, K., Lin, Y ., and Yuan, P. F. (2021). Research on self-formation wind tunnel platform design based on dynamic gridding mechanical devices. Sun, C., Zheng, Z., and Sun, T. (2018). Hybrid fabrication. a free-form building process with high on-site flexibility and acceptable accumulative error. Sundermeyer, M., Durner, M., Puang, E. Y ., Marton, Z.-C., Vaskevicius, N., Arras, K. O., and Triebel, R. (2020). Multi-path learning for object pose estimation across domains. In Proceedings of the IEEE /CVF conference on computer vision and pattern recognition , pages 13916\u201313925. Sundermeyer, M., Marton, Z.-C., Durner, M., Brucker, M., and Triebel, R.",
        "ref_ids": [
          "1230"
        ]
      },
      "Robust 6DoF Pose Estimation Against Depth Noise and a Comprehensive Evaluation on a Mobile Dataset": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2309.13570",
        "ref_texts": "6718\u20136727, 2022. Nguyen, V . N., Hu, Y ., Xiao, Y ., Salzmann, M., and Lepetit, V . Templates for 3d object pose estimation revisited: Generalization to new objects and robustness to occlusions. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pp. 6771\u20136780, 2022. Paul, S. and Chen, P.-Y . Vision transformers are robust learners, 2021. Peng, S., Liu, Y ., Huang, Q., Zhou, X., and Bao, H. Pvnet: Pixel-wise voting network for 6dof pose estimation. In CVPR , 2019. Permozer, I. and Orehova \u02c7cki, T. Utilizing apple\u2019s arkit 2.0 for augmented reality application development. In 2019 42nd International Convention on Information and Communication Technology, Electronics and Microelectronics (MIPRO) , pp. 1629\u20131634, 2019. doi: 10.23919/MIPRO.2019.8756928. Qi, C. R., Su, H., Mo, K., and Guibas, L. J. Pointnet: Deep learning on point sets for 3d classification and segmentation, 2017. Radford, A., Kim, J. W., Hallacy, C., Ramesh, A., Goh, G., Agarwal, S., Sastry, G., Askell, A., Mishkin, P., Clark, J., Krueger, G., and Sutskever, I. Learning transferable visual models from natural language supervision, 2021. Sch\u00a8ops, T., Sattler, T., and Pollefeys, M. Bad slam: Bundle adjusted direct rgb-d slam. In 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) , pp. 134\u2013144, 2019. doi: 10.1109/CVPR.2019."
      },
      "Study on 6D Pose Estimation System of Occlusion Targets for the Spherical Amphibious Robot based on Neural Network": {
        "authors": [
          "A Publication"
        ],
        "url": "http://www.guolab.org/Papers/2023/Study%20on%206D%20Pose%20Estimation%20System%20of%20Occlusion%20Targets%20for%20the%20Spherical%20Amphibious%20Robot%20based%20on%20Neural%20Network.pdf"
      },
      "Reliable Object Pose Estimation": {
        "authors": [],
        "url": "https://portal.findresearcher.sdu.dk/files/242265002/phd_thesis.pdf",
        "ref_texts": "[26] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 4561\u2013",
        "ref_ids": [
          "26"
        ]
      },
      "Detection and Pose Estimation of Flat, Texture-Less Industry Objects on HoloLens Using Synthetic Training": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2402.04979",
        "ref_texts": "32. Peng, S., Liu, Y., Huang, Q., Zhou, X., Bao, H.: Pvnet: Pixel-wise voting network for 6dof pose estimation. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) (2019)",
        "ref_ids": [
          "32"
        ]
      },
      "\u57fa\u4e8e\u5173\u952e\u70b9\u8ddd\u79bb\u8868\u5f81\u7f51\u7edc\u7684\u7269\u4f53\u4f4d\u59ff\u4f30\u8ba1\u65b9\u6cd5": {
        "authors": [],
        "url": "https://www.researching.cn/ArticlePdf/m00002/2023/60/16/1615008.pdf",
        "ref_texts": "[9]Peng S D , Zhou X W , Liu Y , et al . PVNet : pixel -wise voting network for 6DoF object pose estimation [J]. IEEE Transactions on Pattern Analysis and Machine Intelligence , ",
        "ref_ids": [
          "9",
          "J"
        ]
      },
      "Artificial Intelligence based Robotic Platforms for Autonomous Precision Agriculture": {
        "authors": [],
        "url": "https://openaccess.city.ac.uk/id/eprint/31615/1/Abdulsalam%20Thesis%202023%20PDF-A.pdf",
        "ref_texts": "7989233. Peng, S., Liu, Y ., Huang, Q., Zhou, X., and Bao, H. (2019). Pvnet: Pixel-wise voting network for 6dof pose estimation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 4561\u20134570. DOI: https://doi.org/10.1109/TPAMI.2020.",
        "ref_ids": [
          "7989233"
        ]
      },
      "Development of Vision Guided Real-Time Trajectory Planning System for Autonomous Ground Refuelling Operations using Hybrid Dataset": {
        "authors": [],
        "url": "https://open.metu.edu.tr/bitstream/handle/11511/110790/index.pdf",
        "ref_texts": "[18] Sida Peng et al. \u201cPvnet\u0237 Pixel-wise voting network for 6dof pose estimation\u201d. In\u0237 Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2019, pp. \u00bb561\u2013\u00bb570.",
        "ref_ids": [
          "18"
        ]
      },
      "Deep learning on point clouds with applications in vehicle self-localization": {
        "authors": [],
        "url": "https://oparu.uni-ulm.de/xmlui/bitstream/handle/123456789/48402/diss_nico_engel.pdf?sequence=3",
        "ref_texts": "[PLH+19]Peng, Sida; Liu, Yuan; Huang, Qixing; Zhou, Xiaowei; and Bao, Hujun: PVNet: Pixel-Wise Voting Network for 6DoF Pose Estimation . In: IEEE Conference on Computer Vision and Pattern Recognition, CVPR",
        "ref_ids": [
          "PLH\\+19"
        ]
      },
      "Data-Link: High Fidelity Manufacturing Datasets for Model2Real Transfer under Industrial Settings": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2306.05766",
        "ref_texts": "[9] Peng S., Yuan L., Qixing H., Xiaowei Z., and Hujun B.. \u201dPvnet: Pixel-wise voting network for 6dof pose estimation.\u201d In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 45614570. 2019.",
        "ref_ids": [
          "9"
        ]
      },
      "Driving Reasoning Systems for Product Design and Flexible Robotic Manipulation Using 3D Design-Based Knowledge Graphs": {
        "authors": [
          "Skyler Bunn"
        ],
        "url": "https://repository.lib.ncsu.edu/bitstream/handle/1840.20/41238/etd.pdf?sequence=1",
        "ref_texts": " [127] S. Peng, Y. Liu, Q. Huang, X. Zhou, and H. Bao, \u201cPVNet: Pixel -Wise Voting Network for 6DoF Pose Estimation,\u201d in 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) , Long Beach, CA, USA: IEEE, Jun. 2019, pp. 4556 \u20134565. doi: ",
        "ref_ids": [
          "127"
        ]
      },
      "Learning Embodied AI Agents with Task Decomposition": {
        "authors": [],
        "url": "https://escholarship.org/content/qt0c70b68j/qt0c70b68j.pdf",
        "ref_texts": "[118] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixelwise voting network for 6dof pose estimation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 4561\u20134570, 2019.",
        "ref_ids": [
          "118"
        ]
      },
      "OLF: RGB-D Adaptive Late Fusion for Robust 6D Pose Estimation": {
        "authors": [],
        "url": "https://hal.science/hal-04085729/document",
        "ref_texts": "[25] Peng, S., Liu, Y., Huang, Q., Zhou, X., and Bao, H., \u201cPvnet: Pixel-wise voting network for 6dof pose estimation,\u201d in [CVPR ], (2019).",
        "ref_ids": [
          "25",
          "CVPR "
        ]
      },
      "Zhiwen_Dissertation. pdf": {
        "authors": [],
        "url": "https://hammer.purdue.edu/articles/thesis/Zhiwen_Dissertation_pdf/22684813/1/files/40273888.pdf",
        "ref_texts": "[88] S. Peng, Y. Liu, Q. Huang, X. Zhou, and H. Bao, \u201cPvnet: Pixel-wise voting network for 6dof pose estimation,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , 2019, pp. 4561\u20134570.",
        "ref_ids": [
          "88"
        ]
      },
      "A Farewell to Supervision: Towards Self-supervised Autonomous Systems": {
        "authors": [],
        "url": "https://www.research-collection.ethz.ch/bitstream/handle/20.500.11850/650308/1/thesis-kenneth.pdf",
        "ref_texts": "[86]S. Peng, Y. Liu, Q. Huang, X. Zhou, and H. Bao. PVNet: Pixel-wise voting network for 6DoF pose estimation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 4561 \u20134570 , 2019 .",
        "ref_ids": [
          "86"
        ]
      },
      "Affordance-grounded Robot Perception and Manipulation in Adversarial, Translucent, and Cluttered Environments": {
        "authors": [
          "Xiaotong Chen"
        ],
        "url": "https://deepblue.lib.umich.edu/bitstream/handle/2027.42/177867/cxt_1.pdf?sequence=1",
        "ref_texts": "[147] S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 4561\u20134570, 2019.",
        "ref_ids": [
          "147"
        ]
      },
      "Category-level 6D object pose estimation based on mixed channel attention": {
        "authors": [],
        "url": "http://jemi.cnjournals.com/jemien/article/pdf/20230708",
        "ref_texts": "[15] PENG S, ZHOU X, LIU Y, et al. Pvnet: Pixel-wise voting network for ",
        "ref_ids": [
          "15"
        ]
      },
      "AI-based visual pose estimation for space applications": {
        "authors": [
          "Federico Moscato"
        ],
        "url": "https://webthesis.biblio.polito.it/secure/29475/1/tesi.pdf",
        "ref_texts": "[23] Sida Peng et al. \u201cPVNet: Pixel-wise Voting Network for 6DoF Pose Estimation\u201d. In: CoRR abs/1812.11788 (2018). arXiv: 1812.11788 .URL:http://arxiv. org/abs/1812.11788 .",
        "ref_ids": [
          "23"
        ]
      },
      "6D Pose Estimation of Weakly Textured Object Driven by Decoupling Analysis and Algorithm Fusion Strategy": {
        "authors": [],
        "url": "https://www.researchsquare.com/article/rs-3105669/latest.pdf",
        "ref_texts": "32. Peng S, Liu Y , Huang Q, Zhou X, Bao H (2019) Pvnet: Pixel-wise voting netwo rk for 6dof pose estimation. Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 4561-4570 ",
        "ref_ids": [
          "32"
        ]
      },
      "NeRF-Pose: A First-Reconstruct-Then-Regress Approach for Weakly-supervised 6D Object Pose Estimation Supplementary": {
        "authors": [],
        "url": "https://openaccess.thecvf.com/content/ICCV2023W/R6D/supplemental/Li_NeRF-Pose_A_First-Reconstruct-Then-Regress_ICCVW_2023_supplemental.pdf",
        "ref_texts": "[16] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 4561\u20134570, 2019.",
        "ref_ids": [
          "16"
        ]
      },
      "Image-based Object Pose Estimation for Robotic Manipulation: A Cost-effective Approach in Virtual Environment": {
        "authors": [],
        "url": "https://gunma-u.repo.nii.ac.jp/record/10029/files/T201D604.pdf",
        "ref_texts": "[10] Peng, S., Liu, Y ., Huang, Q., Zhou, X., & Bao, H. (2019). Pvnet: Pixel -wise voting network for 6dof pose estimation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 4561 -4570). ",
        "ref_ids": [
          "10"
        ]
      },
      "A Survey of 3D Template Object Tracking Algorithms Based on Monocular RGB Data": {
        "authors": [],
        "url": "https://www.jcad.cn/en/article/pdf/preview/4fca7cc5-45ba-4747-a6ed-4c1bfdc01f09.pdf",
        "ref_texts": "): [1]Lepetit V , Fua P. Monocular model-based3D tracking of rigid objects: A survey[M]. Massachusetts: NowFoundations and Trends, 2005 [2]Marchand E, Uchiyama H, Spindler F. Poseestimation for augmented reality: a hands-on survey[J]. IEEETransactions on Visualization and Computer Graphics, 2016,22(12): 2633-2651[3]Peng S D, Zhou X W, Liu Y , et al. PVNet:pixel-wise voting network for 6DoF object pose estimation[J].IEEE Transactions on Pattern Analysis and Machine Intelli -gence, 2022, 44(6): 3212-3223[4]Kirillov A. An introduction to Lie groupsand Lie algebras[M]. Cambridge: Cambridge University Press,2008[5]Varadarajan V S. Lie groups, Lie algebras,and their representations[M]. Heidelberg: Springer, 1984[6]Murray R M, Li Z X, Sastry S S. A mathe -matical introduction to robotic manipulation[M]. Florida: CRCPress, 2017[7]He Xian, Li Jiachen, Jin Li, et al. A syn-thetic dataset and performance evaluation for 3D templatetracking[J]. Chinese Journal of Computers, 2022, 45(3): 585-600(in Chinese) (\u4f55\u5f26, \u674e\u4f73\u5bb8, \u91d1\u7acb\u7b49. \u4e09\u7ef4\u6a21\u677f\u8ddf\u8e2a\u7684\u57fa\u51c6\u5408\u6210\u6570\u636e\u96c6\u6784\u5efa\u53ca\u7b97\u6cd5\u8bc4\u4f30[J]. \u8ba1\u7b97\u673a\u5b66\u62a5, 2022, 45(3): 585-600)[8]Choi C, Christensen H I. RGB-D objecttracking: a particle filter approach on GPU[C] // Proceedings ofIEEE/RSJ International Conference on Intelligent Robots andSystems. Los Alamitos: IEEE Computer Society Press, 2013:1084-1091[9]Tjaden H, Schwanecke U, Sch\u00f6mer E, et al.A region-based Gauss-Newton approach to real-time monocu -lar multiple object tracking[J]. IEEE Transactions on PatternAnalysis and Machine Intelligence, 2019, 41(8): 1797-1812[10]Wu P C, Lee Y Y , Tseng H Y . et al. Abenchmark dataset for 6DoF object pose tracking[C] //Proceed -ings of IEEE International Symposium on Mixed and Aug -mented Reality. Los Alamitos: IEEE Computer Society Press,2017: 186-191[11]Xiang Y , Schmidt T, Narayanan V , et al.PoseCNN: a convolutional neural network for 6D object poseestimation in cluttered scenes[C] //Proceedings of Robotics:Science and Systems. Cambridge: MIT Press, 2018[12]Li J C, Wang B, Zhu S Q, et al. BCOT: amarkerless high-precision 3D object tracking benchmark[C] //Proceedings of IEEE/CVF Conference on Computer Vision andPattern Recognition. Los Alamitos: IEEE Computer SocietyPress, 2022: 6687-6696[13]Shapiro R. Direct linear transformation ",
        "ref_ids": [
          "1",
          "2",
          "3",
          "4",
          "5",
          "6",
          "7",
          "8",
          "9",
          "10",
          "11",
          "12",
          "13"
        ]
      },
      "DAPO: Self-Supervised Domain Adaptation for 6DoF Pose Estimation": {
        "authors": [],
        "url": "https://sslneurips23.github.io/paper_pdfs/paper_21.pdf",
        "ref_texts": "[12] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 4561\u20134570, 2019.",
        "ref_ids": [
          "12"
        ]
      },
      "A performance evaluation of pixel-wise voting networks for object pose estimation": {
        "authors": [],
        "url": "https://thesis.unipd.it/bitstream/20.500.12608/54926/1/Mantovan_Lorenzo.pdf",
        "ref_texts": "[26] Z. Cao, Y. Sheikh, and N. K. Banerjee, \u201cReal-time scalable 6dof pose estimation for textureless objects,\u201d in 2016 IEEE International Conference on Robotics and Automation (ICRA) , 2016, pp. 2441\u20132448. doi:10.1109/ICRA.",
        "ref_ids": [
          "26"
        ]
      },
      "Planung und Simulation taktiler, intelligenter und kollaborativer Roboterf\u00e4higkeiten in der Montage": {
        "authors": [
          "Metzner Maximilian"
        ],
        "url": "https://scholar.archive.org/work/fiix5nacqzbxxagusceevjcrhy/access/wayback/https://opus4.kobv.de/opus4-fau/frontdoor/deliver/index/docId/21521/file/Metzner_Diss_MB_414.pdf",
        "ref_texts": "[86] PENG , S., Y. LIU, Q. HUANG , X. ZHOU und H. BAO. PVNet: Pixel -Wise Voting Network for 6DoF Pose Estimation. In: 2019 IEEE/CVF Conference on Computer Vision and Pattern R ecognition (CVPR): IEEE, 15. Juni 2019 20. Juni 2019, S. 4556 -4565. ISBN 978 -1-7281-3293 -8 ",
        "ref_ids": [
          "86"
        ]
      },
      "\u57fa\u4e8e\u5355\u89c6\u56fe\u5173\u952e\u70b9\u6295\u7968\u7684\u673a\u5668\u4eba\u6293\u53d6\u65b9\u6cd5": {
        "authors": [],
        "url": "http://www.cims-journal.cn/CN/article/downloadArticleFile.do?attachType=PDF&id=8272",
        "ref_texts": "[19] PENGSD,LIUY,HUANGQX,etal.Pvnet:Pixel-wise votingnetworkfor6DoFposeestimation[C]//Proceedingsof theIEEE/CVFConferenceonComputerVisionandPattern Recognition.Washington,D.C.,USA:IEEE,2019.",
        "ref_ids": [
          "19",
          "C"
        ]
      },
      "\u57fa\u4e8e\u6df7\u5408\u901a\u9053\u6ce8\u610f\u529b\u7684\u7c7b\u522b\u7ea7\u7269\u4f53\u516d\u81ea\u7531\u5ea6\u4f4d\u59ff\u4f30\u8ba1": {
        "authors": [],
        "url": "http://jemi.cnjournals.com/jemi/article/pdf/20230708",
        "ref_texts": "[15] PENG S, ZHOU X, LIU Y, et al. Pvnet: Pixel-wise voting network for ",
        "ref_ids": [
          "15"
        ]
      },
      "\u57fa\u4e8e\u5408\u6210\u6570\u636e\u7684\u6c34\u4e0b\u673a\u5668\u4eba\u89c6\u89c9\u5b9a\u4f4d\u65b9\u6cd5": {
        "authors": [],
        "url": "https://xk.sia.cn/cn/article/pdf/preview/10.13976/j.cnki.xk.2023.2257.pdf",
        "ref_texts": "Pixel\ue011wisevotingnetworkfor6DoFposeestimation"
      },
      "\u57fa\u4e8e\u9ad8\u5206\u8fa8\u7f51\u7edc\u7684\u7a7a\u95f4\u76ee\u6807\u4f4d\u59ff\u4f30\u8ba1\u65b9\u6cd5.": {
        "authors": [],
        "url": "https://www.aeeisp.com/csjsxb/cn/article/pdf/preview/18449c19-4b57-41c0-8679-78bcfd7707c5.pdf",
        "ref_texts": "[2]PENG S, LIU Y, HUANG Q, et al. PVNet: pixelwise voting network for ",
        "ref_ids": [
          "2"
        ]
      },
      "Ricerca sistematica e comparazione delle metodologie per la stima della posa 6D": {
        "authors": [
          "Matteo Tonello"
        ],
        "url": "https://thesis.unipd.it/bitstream/20.500.12608/52406/1/Tonello_Matteo.pdf",
        "ref_texts": "[15] S. Peng et al. \u00abPVNet: Pixel-Wise Voting Network for 6DoF Object Pose Estimation\u00bb. In: IEEE Transactions on Pattern Analysis and Machine Intelligence 44(6), pp. 3212-3223 (2022).",
        "ref_ids": [
          "15"
        ]
      },
      "Rilevamento di oggetti 3D da immagini 2D: metodi e applicazioni": {
        "authors": [
          "Zlatko Kovachev"
        ],
        "url": "https://thesis.unipd.it/bitstream/20.500.12608/57086/1/Kovachev_Zlatko.pdf",
        "ref_texts": "[13]S. Peng, Y. Liu, Q. Huang, X. Zhou e H. Bao, \u00abPVNet: Pixel-Wise Voting Network for 6DoF Pose Estimation,\u00bb in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) , 2019.",
        "ref_ids": [
          "13"
        ]
      },
      "Utilizzo di reti GAN per la creazione di immagini di addestramento per l'object pose estimation": {
        "authors": [],
        "url": "https://thesis.unipd.it/bitstream/20.500.12608/54924/1/DelBen_Roberto.pdf",
        "ref_texts": "[2] S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao, \u201cPvnet: Pixel-wise voting network for 6dof pose estimation,\u201d in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) , 2019.",
        "ref_ids": [
          "2"
        ]
      },
      "Deep learning on monocular object pose detection and tracking: A comprehensive overview": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2105.14291",
        "ref_texts": "[118] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. 2019. Pvnet: Pixel-wise voting network for 6dof pose estimation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition . 4561\u20134570.",
        "ref_ids": [
          "118"
        ]
      },
      "Epro-pnp: Generalized end-to-end probabilistic perspective-n-points for monocular object pose estimation": {
        "authors": [
          "Hansheng Chen",
          "Pichao Wang",
          "Fan Wang",
          "Wei Tian",
          "Lu Xiong",
          "Hao Li"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2022/papers/Chen_EPro-PnP_Generalized_End-to-End_Probabilistic_Perspective-N-Points_for_Monocular_Object_Pose_Estimation_CVPR_2022_paper.pdf",
        "ref_texts": "[31] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In CVPR , 2019. 1, 2, 4, 7",
        "ref_ids": [
          "31"
        ]
      },
      "Onepose: One-shot object pose estimation without cad models": {
        "authors": [
          "Jiaming Sun",
          "Zihao Wang",
          "Siyu Zhang",
          "Xingyi He",
          "Hongcheng Zhao",
          "Guofeng Zhang",
          "Xiaowei Zhou"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2022/papers/Sun_OnePose_One-Shot_Object_Pose_Estimation_Without_CAD_Models_CVPR_2022_paper.pdf",
        "ref_texts": "[26] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. PVNet: Pixel-wise voting network for 6dof pose estimation. In CVPR , 2019. 1, 2, 6, 7",
        "ref_ids": [
          "26"
        ]
      },
      "Zebrapose: Coarse to fine surface encoding for 6dof object pose estimation": {
        "authors": [
          "Yongzhi Su",
          "Mahdi Saleh",
          "Torben Fetzer",
          "Jason Rambach",
          "Nassir Navab",
          "Benjamin Busam",
          "Didier Stricker",
          "Federico Tombari"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2022/papers/Su_ZebraPose_Coarse_To_Fine_Surface_Encoding_for_6DoF_Object_Pose_CVPR_2022_paper.pdf",
        "ref_texts": "[49] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 4561\u2013",
        "ref_ids": [
          "49"
        ]
      },
      "Gpv-pose: Category-level object pose estimation via geometry-guided point-wise voting": {
        "authors": [
          "Yan Di",
          "Ruida Zhang",
          "Zhiqiang Lou",
          "Fabian Manhardt",
          "Xiangyang Ji",
          "Nassir Navab",
          "Federico Tombari"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2022/papers/Di_GPV-Pose_Category-Level_Object_Pose_Estimation_via_Geometry-Guided_Point-Wise_Voting_CVPR_2022_paper.pdf",
        "ref_texts": ""
      },
      "Dexmv: Imitation learning for dexterous manipulation from human videos": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2108.05877",
        "ref_texts": "57. Peng, S., Liu, Y., Huang, Q.X., Bao, H., Zhou, X.: Pvnet: Pixel-wise voting network for 6dof pose estimation. CVPR (2019) 4",
        "ref_ids": [
          "57"
        ]
      },
      "Surfemb: Dense and continuous correspondence distributions for object pose estimation with learnt surface embeddings": {
        "authors": [
          "Rasmus Laurvig",
          "Anders Glent"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2022/papers/Haugaard_SurfEmb_Dense_and_Continuous_Correspondence_Distributions_for_Object_Pose_Estimation_CVPR_2022_paper.pdf",
        "ref_texts": "[26] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 4561\u2013",
        "ref_ids": [
          "26"
        ]
      },
      "Onepose++: Keypoint-free one-shot object pose estimation without CAD models": {
        "authors": [],
        "url": "https://proceedings.neurips.cc/paper_files/paper/2022/file/e43f900f571de6c96a70d5724a0fb565-Paper-Conference.pdf",
        "ref_texts": "[39] Sida Peng, Xiaowei Zhou, Yuan Liu, Haotong Lin, Qixing Huang, and Hujun Bao. PVNet: pixel-wise voting network for 6dof object pose estimation. T-PAMI , 2020. 1, 2, 3, 8, 9",
        "ref_ids": [
          "39"
        ]
      },
      "Megapose: 6d pose estimation of novel objects via render & compare": {
        "authors": [
          "Anonymous Submission"
        ],
        "url": "https://arxiv.org/pdf/2212.06870",
        "ref_texts": "[44] S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. InCVPR , 2019.",
        "ref_ids": [
          "44"
        ]
      },
      "Gen6d: Generalizable model-free 6-dof object pose estimation from rgb images": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2204.10776",
        "ref_texts": "42. Peng, S., Liu, Y., Huang, Q., Zhou, X., Bao, H.: Pvnet: Pixel-wise voting network for 6-dof pose estimation. In: CVPR (2019) Gen6D Pose Estimator 17",
        "ref_ids": [
          "42"
        ]
      },
      "Shapo: Implicit representations for multi-object shape, appearance, and pose optimization": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2207.13691",
        "ref_texts": "41. Peng, S., Liu, Y., Huang, Q., Zhou, X., Bao, H.: Pvnet: Pixel-wise voting network for 6dof pose estimation. In: CVPR (2019)",
        "ref_ids": [
          "41"
        ]
      },
      "Rnnpose: Recurrent 6-dof object pose refinement with robust correspondence field estimation and pose optimization": {
        "authors": [
          "Yan Xu",
          "Yee Lin",
          "Guofeng Zhang",
          "Xiaogang Wang",
          "Hongsheng Li"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2022/papers/Xu_RNNPose_Recurrent_6-DoF_Object_Pose_Refinement_With_Robust_Correspondence_Field_CVPR_2022_paper.pdf",
        "ref_texts": "[34] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. PVNet: Pixel-wise voting network for 6DoF pose estimation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 4561\u2013",
        "ref_ids": [
          "34"
        ]
      },
      "Templates for 3d object pose estimation revisited: Generalization to new objects and robustness to occlusions": {
        "authors": [
          "Van Nguyen",
          "Yinlin Hu",
          "Yang Xiao",
          "Mathieu Salzmann",
          "Vincent Lepetit"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2022/papers/Nguyen_Templates_for_3D_Object_Pose_Estimation_Revisited_Generalization_to_New_CVPR_2022_paper.pdf",
        "ref_texts": "[27] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. PVNet: Pixel-Wise V oting Network for 6DoF Pose Estimation. In Conference on Computer Vision and Pattern Recognition (CVPR) , 2019. 1, 2",
        "ref_ids": [
          "27"
        ]
      },
      "Fs6d: Few-shot 6d pose estimation of novel objects": {
        "authors": [
          "Yisheng He",
          "Yao Wang",
          "Haoqiang Fan",
          "Jian Sun",
          "Qifeng Chen"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2022/papers/He_FS6D_Few-Shot_6D_Pose_Estimation_of_Novel_Objects_CVPR_2022_paper.pdf",
        "ref_texts": "[38] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 4561\u20134570, 2019. 2, 6[39] Gabriel Peyr \u00b4e, Marco Cuturi, et al. Computational optimal transport: With applications to data science. Foundations and Trends\u00ae in Machine Learning , 11(5-6):355\u2013607, 2019.",
        "ref_ids": [
          "38",
          "39"
        ]
      },
      "Osop: A multi-stage one shot object pose estimation framework": {
        "authors": [
          "Ivan Shugurov",
          "Fu Li",
          "Benjamin Busam",
          "Slobodan Ilic"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2022/papers/Shugurov_OSOP_A_Multi-Stage_One_Shot_Object_Pose_Estimation_Framework_CVPR_2022_paper.pdf",
        "ref_texts": "[37] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In CVPR , 2019. 1, 2",
        "ref_ids": [
          "37"
        ]
      },
      "6-DoF pose estimation of household objects for robotic manipulation: An accessible dataset and benchmark": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2203.05701",
        "ref_texts": "[6] S. Peng, Y . Liu, Q. Huang, H. Bao, and X. Zhou, \u201cPVNet: Pixel-wise voting network for 6DoF pose estimation,\u201d in CVPR , 2019. 1",
        "ref_ids": [
          "6"
        ]
      },
      "Coupled iterative refinement for 6d multi-object pose estimation": {
        "authors": [
          "Lahav Lipson",
          "Zachary Teed",
          "Ankit Goyal",
          "Jia Deng"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2022/papers/Lipson_Coupled_Iterative_Refinement_for_6D_Multi-Object_Pose_Estimation_CVPR_2022_paper.pdf",
        "ref_texts": "[28] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 4561\u2013",
        "ref_ids": [
          "28"
        ]
      },
      "Tracking objects as pixel-wise distributions": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2207.05518",
        "ref_texts": "44. Peng, S., Liu, Y., Huang, Q., Zhou, X., Bao, H.: Pvnet: Pixel-wise voting network for 6dof pose estimation. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 4561\u20134570 (2019)",
        "ref_ids": [
          "44"
        ]
      },
      "Rbp-pose: Residual bounding box projection for category-level pose estimation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2208.00237",
        "ref_texts": "31. Peng, S., Liu, Y., Huang, Q., Zhou, X., Bao, H.: Pvnet: Pixel-wise voting network for 6dof pose estimation. In: CVPR (2019) 3",
        "ref_ids": [
          "31"
        ]
      },
      "Ifor: Iterative flow minimization for robotic object rearrangement": {
        "authors": [
          "Ankit Goyal",
          "Arsalan Mousavian",
          "Chris Paxton",
          "Wei Chao",
          "Brian Okorn",
          "Jia Deng",
          "Dieter Fox"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2022/papers/Goyal_IFOR_Iterative_Flow_Minimization_for_Robotic_Object_Rearrangement_CVPR_2022_paper.pdf",
        "ref_texts": "[50] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. PVNet: Pixel-wise voting network for 6DoF pose estimation. In CVPR , 2019. 2",
        "ref_ids": [
          "50"
        ]
      },
      "Centersnap: Single-shot multi-object 3d shape reconstruction and categorical 6d pose and size estimation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2203.01929",
        "ref_texts": "[17] S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao, \u201cPVNet: Pixel-wise voting network for 6dof pose estimation,\u201d in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , 2019, pp.",
        "ref_ids": [
          "17"
        ]
      },
      "Symmetry and uncertainty-aware object slam for 6dof object pose estimation": {
        "authors": [
          "Nathaniel Merrill",
          "Yuliang Guo",
          "Xingxing Zuo",
          "Xinyu Huang",
          "Stefan Leutenegger",
          "Xi Peng",
          "Liu Ren",
          "Guoquan Huang"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2022/papers/Merrill_Symmetry_and_Uncertainty-Aware_Object_SLAM_for_6DoF_Object_Pose_Estimation_CVPR_2022_paper.pdf",
        "ref_texts": "[26] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixel-wise voting network for 6dof pose 14909",
        "ref_ids": [
          "26"
        ]
      },
      "Category-level 6d object pose estimation in the wild: A semi-supervised learning approach and a new dataset": {
        "authors": [],
        "url": "https://proceedings.neurips.cc/paper_files/paper/2022/file/afe99e55be23b3523818da1fefa33494-Paper-Conference.pdf",
        "ref_texts": "[34] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 4561\u20134570, 2019. 1",
        "ref_ids": [
          "34"
        ]
      },
      "Sar-net: Shape alignment and recovery network for category-level 6d object pose and size estimation": {
        "authors": [
          "Haitao Lin",
          "Zichang Liu",
          "Chilam Cheang",
          "Yanwei Fu",
          "Guodong Guo",
          "Xiangyang Xue"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2022/papers/Lin_SAR-Net_Shape_Alignment_and_Recovery_Network_for_Category-Level_6D_Object_CVPR_2022_paper.pdf",
        "ref_texts": "[39] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 4561\u20134570, 2019. 1, 3, 4, 5, 6, 7",
        "ref_ids": [
          "39"
        ]
      },
      "Uni6d: A unified cnn framework without projection breakdown for 6d pose estimation": {
        "authors": [
          "Xiaoke Jiang",
          "Donghai Li",
          "Hao Chen",
          "Ye Zheng",
          "Rui Zhao",
          "Liwei Wu"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2022/papers/Jiang_Uni6D_A_Unified_CNN_Framework_Without_Projection_Breakdown_for_6D_CVPR_2022_paper.pdf",
        "ref_texts": "[30] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 4561\u2013",
        "ref_ids": [
          "30"
        ]
      },
      "Ove6d: Object viewpoint encoding for depth-based 6d object pose estimation": {
        "authors": [
          "Dingding Cai",
          "Janne Heikkila",
          "Esa Rahtu"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2022/papers/Cai_OVE6D_Object_Viewpoint_Encoding_for_Depth-Based_6D_Object_Pose_Estimation_CVPR_2022_paper.pdf",
        "ref_texts": "[36] Sida Peng, Xiaowei Zhou, Yuan Liu, Haotong Lin, Qixing Huang, and Hujun Bao. Pvnet: pixel-wise voting network for 6dof object pose estimation. IEEE Transactions on Pattern Analysis and Machine Intelligence , 2020. 1, 2, 6, 7, 8",
        "ref_ids": [
          "36"
        ]
      },
      "Towards unbiased label distribution learning for facial pose estimation using anisotropic spherical gaussian": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2208.09122",
        "ref_texts": "34. Peng, S., Liu, Y., Huang, Q., Zhou, X., Bao, H.: Pvnet: Pixel-wise voting network for 6dof pose estimation. In: CVPR (2019)",
        "ref_ids": [
          "34"
        ]
      },
      "UDA-COPE: Unsupervised domain adaptation for category-level object pose estimation": {
        "authors": [
          "Taeyeop Lee",
          "Uk Lee",
          "Inkyu Shin",
          "Jaesung Choe",
          "Ukcheol Shin",
          "In So",
          "Jin Yoon"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2022/papers/Lee_UDA-COPE_Unsupervised_Domain_Adaptation_for_Category-Level_Object_Pose_Estimation_CVPR_2022_paper.pdf",
        "ref_texts": "[27] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) , pages 4561\u20134570, 2019. 1",
        "ref_ids": [
          "27"
        ]
      },
      "Catre: Iterative point clouds alignment for category-level object pose refinement": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2207.08082",
        "ref_texts": "38. Peng, S., Liu, Y., Huang, Q., Zhou, X., Bao, H.: Pvnet: Pixel-wise voting network for 6dof pose estimation. In: IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). pp. 4561\u20134570 (2019)",
        "ref_ids": [
          "38"
        ]
      },
      "Perspective flow aggregation for data-limited 6d object pose estimation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2203.09836",
        "ref_texts": "32. Peng, S., Liu, Y., Huang, Q., Zhou, X., Bao, H.: PVNet: Pixel-Wise Voting Network for 6DoF Pose Estimation. In: Conference on Computer Vision and Pattern Recognition (2019)",
        "ref_ids": [
          "32"
        ]
      },
      "Neural correspondence field for object pose estimation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2208.00113",
        "ref_texts": "61. Peng, S., Liu, Y., Huang, Q., Zhou, X., Bao, H.: PVNet: Pixel-wise voting network for 6DoF pose estimation. CVPR (2019) 2, 3",
        "ref_ids": [
          "61"
        ]
      },
      "Clearpose: Large-scale transparent object dataset and benchmark": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2203.03890",
        "ref_texts": "14. Peng, S., Liu, Y., Huang, Q., Zhou, X., Bao, H.: Pvnet: Pixel-wise voting network for 6dof pose estimation. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 4561{4570 (2019)",
        "ref_ids": [
          "14"
        ]
      },
      "Single-stage keypoint-based category-level object pose estimation from an RGB image": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2109.06161",
        "ref_texts": "[28] S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao, \u201cPVNet: Pixelwise voting network for 6DoF pose estimation,\u201d in CVPR , 2019, pp.",
        "ref_ids": [
          "28"
        ]
      },
      "Es6d: A computation efficient and symmetry-aware 6d pose regression framework": {
        "authors": [
          "Ningkai Mo",
          "Wanshui Gan",
          "Naoto Yokoya",
          "Shifeng Chen"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2022/papers/Mo_ES6D_A_Computation_Efficient_and_Symmetry-Aware_6D_Pose_Regression_Framework_CVPR_2022_paper.pdf",
        "ref_texts": "[26] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 4561\u20134570, 2019. 1",
        "ref_ids": [
          "26"
        ]
      },
      "iCaps: Iterative category-level object pose and shape estimation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2201.00059",
        "ref_texts": "[5] S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao, \u201cPVNet: Pixel-wise voting network for 6DoF pose estimation,\u201d in Proc. IEEE Int. Conf. Comput. Vis. Pattern Recognit. , 2019, pp. 4556\u20134565.",
        "ref_ids": [
          "5"
        ]
      },
      "DGECN: A depth-guided edge convolutional network for end-to-end 6D pose estimation": {
        "authors": [
          "Tuo Cao",
          "Fei Luo",
          "Yanping Fu",
          "Wenxiao Zhang",
          "Shengjie Zheng",
          "Chunxia Xiao"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2022/papers/Cao_DGECN_A_Depth-Guided_Edge_Convolutional_Network_for_End-to-End_6D_Pose_CVPR_2022_paper.pdf",
        "ref_texts": "[28] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 4561\u2013",
        "ref_ids": [
          "28"
        ]
      },
      "Learning to detect scene landmarks for camera localization": {
        "authors": [
          "Tien Do",
          "Ondrej Miksik",
          "Joseph De",
          "Hyun Soo",
          "Sudipta N. Sinha"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2022/papers/Do_Learning_To_Detect_Scene_Landmarks_for_Camera_Localization_CVPR_2022_paper.pdf",
        "ref_texts": "[52] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In CVPR, 2019. 3[53] No \u00b4e Pion, Martin Humenberger, Gabriela Csurka, Yohann Cabon, and Torsten Sattler. Benchmarking image retrieval for visual localization. In 3DV, 2020. 2",
        "ref_ids": [
          "52",
          "53"
        ]
      },
      "Refine-net: Normal refinement neural network for noisy point clouds": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2203.12514",
        "ref_texts": "[2] S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao, \u201cPvnet: Pixelwise voting network for 6dof pose estimation,\u201d in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , 2019, pp. 4561\u20134570.",
        "ref_ids": [
          "2"
        ]
      },
      "Monocular relative pose estimation pipeline for uncooperative resident space objects": {
        "authors": [],
        "url": "https://re.public.polimi.it/bitstream/11311/1216796/3/PIAZM_OA_01-22.pdf",
        "ref_texts": "[24]Peng, S., Liu, Y., Huang, Q., Zhou, X., and Bao, H., \u201cPVNet: Pixel-Wise Voting Network for 6DoF Pose Estimation,\u201d 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) , IEEE, 2019, pp. 4556\u20134565. https: //doi.org/10.1109/CVPR.2019.00469.",
        "ref_ids": [
          "24"
        ]
      },
      "Ssp-pose: Symmetry-aware shape prior deformation for direct category-level object pose estimation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2208.06661",
        "ref_texts": "[25] S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao, \u201cPvnet: Pixel-wise voting network for 6dof pose estimation,\u201d in CVPR , 2019.",
        "ref_ids": [
          "25"
        ]
      },
      "E2EK: End-to-end regression network based on keypoint for 6D pose estimation": {
        "authors": [],
        "url": "https://uwe-repository.worktribe.com/index.php/preview/9655564/E2EK_RAL_finalversion_plain.pdf",
        "ref_texts": "[2] S. Peng, Y . Liu, Q. Huang, et al . \u201dPvnet: Pixel-wise voting network for 6dof pose estimation,\u201d in Proc. IEEE Conf. Comput. Vis. Pattern Recognit., 2019, pp. 4561-4570.",
        "ref_ids": [
          "2"
        ]
      },
      "Robust category-level 6d pose estimation with coarse-to-fine rendering of neural features": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2209.05624",
        "ref_texts": "23. Peng, S., Liu, Y., Huang, Q., Zhou, X., Bao, H.: Pvnet: Pixel-wise voting network for 6dof pose estimation. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) (June 2019)",
        "ref_ids": [
          "23"
        ]
      },
      "YOLOPose: Transformer-based multi-object 6D pose estimation using keypoint regression": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2205.02536",
        "ref_texts": "[21] Peng, S., Liu, Y., Huang, Q., Zhou, X., Bao, H.: PVNet: Pixel-wise voting network for 6DOF pose estimation. In: IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 4561{4570 (2019)",
        "ref_ids": [
          "21"
        ]
      },
      "6d-vit: Category-level 6d object pose estimation via transformer-based instance representation learning": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2110.04792",
        "ref_texts": "[7] S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao, \u201cPvnet: Pixel-wise voting network for 6dof pose estimation,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , 2019, pp.",
        "ref_ids": [
          "7"
        ]
      },
      "Polarimetric pose prediction": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2112.03810",
        "ref_texts": "41. Peng, S., Liu, Y., Huang, Q., Zhou, X., Bao, H.: Pvnet: Pixel-wise voting network for 6dof pose estimation. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 4561\u20134570 (2019)",
        "ref_ids": [
          "41"
        ]
      },
      "Vote from the center: 6 dof pose estimation in rgb-d images by radial keypoint voting": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2104.02527",
        "ref_texts": "36. Peng, S., Liu, Y., Huang, Q., Zhou, X., Bao, H.: Pvnet: Pixel-wise voting network for 6dof pose estimation. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 4561\u20134570 (2019)",
        "ref_ids": [
          "36"
        ]
      },
      "Translating a visual lego manual to a machine-executable plan": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2207.12572",
        "ref_texts": "32.Peng, S., Liu, Y., Huang, Q., Zhou, X., Bao, H.: Pvnet: Pixel-wise voting network for 6dof pose estimation. In: CVPR (2019)",
        "ref_ids": [
          "32"
        ]
      },
      "Trans6d: Transformer-based 6d object pose estimation and refinement": {
        "authors": [],
        "url": "http://pure-oai.bham.ac.uk/ws/files/176233159/R6D2022_Camera_Ready_2.pdf",
        "ref_texts": "31. Peng, S., Zhou, X., Liu, Y., Lin, H., Huang, Q., Bao, H.: Pvnet: Pixel-wise voting network for 6dof object pose estimation. IEEE Transactions on Pattern Analysis and Machine Intelligence pp. 1\u20131 (2020). https://doi.org/10.1109/TPAMI.2020.3047388",
        "ref_ids": [
          "31"
        ]
      },
      "Dcl-net: Deep correspondence learning network for 6d pose estimation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2210.05232",
        "ref_texts": "31. Peng, S., Liu, Y., Huang, Q., Zhou, X., Bao, H.: Pvnet: Pixel-wise voting network for 6dof pose estimation. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 4561\u20134570 (2019) 1, 3, 14 DCL-Net: Deep Correspondence Learning Network for 6D Pose Estimation 17",
        "ref_ids": [
          "31"
        ]
      },
      "Focal length and object pose estimation via render and compare": {
        "authors": [
          "Georgy Ponimatkin",
          "Yann Labbe",
          "Bryan Russell",
          "Mathieu Aubry",
          "Josef Sivic"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2022/papers/Ponimatkin_Focal_Length_and_Object_Pose_Estimation_via_Render_and_Compare_CVPR_2022_paper.pdf",
        "ref_texts": "[34] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. PVNet: Pixel-wise voting network for 6DoF pose estimation. In CVPR , pages 4561\u20134570, 2019. 2",
        "ref_ids": [
          "34"
        ]
      },
      "Pizza: A powerful image-only zero-shot zero-cad approach to 6 dof tracking": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2209.07589",
        "ref_texts": "[37] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. PVNet: Pixel-Wise V oting Network for 6DoF Pose Estimation. In IEEE Conference on Computer Vision and Pattern Recognition , 2019. 2",
        "ref_ids": [
          "37"
        ]
      },
      "Sim-to-real 6d object pose estimation via iterative self-training for robotic bin picking": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2204.07049",
        "ref_texts": "37. Peng, S., Zhou, X., Liu, Y., Lin, H., Huang, Q., Bao, H.: Pvnet: pixel-wise voting network for 6dof object pose estimation. TPAMI (2020) 1, 3",
        "ref_ids": [
          "37"
        ]
      },
      "Photo-realistic neural domain randomization": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2210.12682",
        "ref_texts": "48. Peng, S., Liu, Y., Huang, Q., Zhou, X., Bao, H.: Pvnet: Pixel-wise voting network for 6dof pose estimation. In: CVPR. pp. 4561\u20134570 (2019)",
        "ref_ids": [
          "48"
        ]
      },
      "Spatial feature mapping for 6DoF object pose estimation": {
        "authors": [
          "Jianhan Mei",
          "Xudong Jiang",
          "Henghui Ding"
        ],
        "url": "https://arxiv.org/pdf/2206.01831",
        "ref_texts": "[25] S. Peng, Y. Liu, Q. Huang, X. Zhou, H. Bao, Pvnet: Pixel-wise voting network for 6dof pose estimation, in: IEEE Conf. Comput. Vis. Pattern Recog., 2019, pp.",
        "ref_ids": [
          "25"
        ]
      },
      "Ikea-manual: Seeing shape assembly step by step": {
        "authors": [],
        "url": "https://proceedings.neurips.cc/paper_files/paper/2022/file/b645d1a085bcb39bece5c03703b62464-Paper-Datasets_and_Benchmarks.pdf",
        "ref_texts": "[37] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. PVNet: Pixel-wise voting network for 6DOF pose estimation. In CVPR , 2019. 6",
        "ref_ids": [
          "37"
        ]
      },
      "Keypoint-based category-level object pose tracking from an RGB sequence with uncertainty estimation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2205.11047",
        "ref_texts": "[21] J. Tremblay, T. To, B. Sundaralingam, Y . Xiang, D. Fox, and S. Birchfield, \u201cDeep object pose estimation for semantic robotic grasping of household objects,\u201d in Conference on Robot Learning (CoRL) , 2018, pp. 306\u2013316.[22] S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao, \u201cPVNet: Pixelwise voting network for 6DoF pose estimation,\u201d in Proceedings of the European Conference on Computer Vision (ECCV) , 2019, pp. 4561\u2013",
        "ref_ids": [
          "21",
          "22"
        ]
      },
      "Sc6d: Symmetry-agnostic and correspondence-free 6d object pose estimation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2208.02129",
        "ref_texts": "[32] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In CVPR , 2019. 2",
        "ref_ids": [
          "32"
        ]
      },
      "Object level depth reconstruction for category level 6d object pose estimation from monocular rgb image": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2204.01586",
        "ref_texts": "19. Peng, S., Liu, Y., Huang, Q., Zhou, X., Bao, H.: Pvnet: Pixel-wise voting network for 6dof pose estimation. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 4561{4570 (2019)",
        "ref_ids": [
          "19"
        ]
      },
      "Learning-based point cloud registration for 6d object pose estimation in the real world": {
        "authors": [],
        "url": "https://infoscience.epfl.ch/record/295132/files/ECCV2022_Match_Normalisation_Point_Cloud_Registration__New_.pdf",
        "ref_texts": "40. Peng, S., Liu, Y., Huang, Q., Zhou, X., Bao, H.: PVNet: Pixel-wise Voting Network for 6DoF Pose Estimation. In: Conference on Computer Vision and Pattern Recognition. pp. 4561\u20134570. Long Beach, California (2019) 1",
        "ref_ids": [
          "40"
        ]
      },
      "Occlusion-robust object pose estimation with holistic representation": {
        "authors": [
          "Bo Chen",
          "Jun Chin",
          "Marius Klimavicius"
        ],
        "url": "http://openaccess.thecvf.com/content/WACV2022/papers/Chen_Occlusion-Robust_Object_Pose_Estimation_With_Holistic_Representation_WACV_2022_paper.pdf",
        "ref_texts": "[44] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In CVPR , 2019. 1, 2, 5, 7, 8",
        "ref_ids": [
          "44"
        ]
      },
      "Bcot: A markerless high-precision 3d object tracking benchmark": {
        "authors": [
          "Jiachen Li",
          "Bin Wang",
          "Shiqiang Zhu",
          "Xin Cao",
          "Fan Zhong",
          "Wenxuan Chen",
          "Te Li",
          "Jason Gu",
          "Xueying Qin"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2022/papers/Li_BCOT_A_Markerless_High-Precision_3D_Object_Tracking_Benchmark_CVPR_2022_paper.pdf",
        "ref_texts": "[32] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. PVNet: Pixel-wise voting network for 6DoF pose estimation. In CVPR , pages 4561\u20134570. Computer Vision Foundation / IEEE, 2019. 1",
        "ref_ids": [
          "32"
        ]
      },
      "Pixel2mesh++: 3d mesh generation and refinement from multi-view images": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2204.09866",
        "ref_texts": "[68] S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao, \u201cPvnet: Pixel-wise voting network for 6dof pose estimation,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2019, pp. 4561\u20134570.",
        "ref_ids": [
          "68"
        ]
      },
      "A visual navigation perspective for category-level object pose estimation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2203.13572",
        "ref_texts": "40. Peng, S., Liu, Y., Huang, Q., Zhou, X., Bao, H.: Pvnet: Pixel-wise voting network for 6dof pose estimation. In: Proc. IEEE Conf. on Computer Vision and Pattern Recognition (CVPR) (2019) 3",
        "ref_ids": [
          "40"
        ]
      },
      "Fusing local similarities for retrieval-based 3d orientation estimation of unseen objects": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2203.08472",
        "ref_texts": "24. Peng, S., Liu, Y., Huang, Q., Zhou, X., Bao, H.: Pvnet: Pixel-wise voting network for 6dof pose estimation. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. pp. 4561\u20134570 (2019)",
        "ref_ids": [
          "24"
        ]
      },
      "Unseen object 6D pose estimation: a benchmark and baselines": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2206.11808",
        "ref_texts": "[41] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) , pages 4561\u20134570, 2019. 1, 2",
        "ref_ids": [
          "41"
        ]
      },
      "Large-displacement 3d object tracking with hybrid non-local optimization": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2207.12620",
        "ref_texts": "15. Peng, S., Liu, Y., Huang, Q., Zhou, X., Bao, H.: PVNet: Pixel-Wise Voting Network for 6DoF Pose Estimation. In: IEEE/CVF Conference on CVPR. pp. 4556{4565. IEEE, Long Beach, CA, USA (Jun 2019). https://doi.org/10.1109/CVPR.2019.00469",
        "ref_ids": [
          "15"
        ]
      },
      "Mv6d: Multi-view 6d pose estimation on rgb-d frames using a deep point-wise voting network": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2208.01172",
        "ref_texts": "[13] S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao, \u201cPVNet: Pixelwise voting network for 6DoF pose estimation,\u201d in CVPR , 2019, pp.",
        "ref_ids": [
          "13"
        ]
      },
      "Keypoint cascade voting for point cloud based 6DoF pose estimation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2210.08123",
        "ref_texts": "[42] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 4561\u2013",
        "ref_ids": [
          "42"
        ]
      },
      "Learning 6-dof object poses to grasp category-level objects by language instructions": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2205.04028",
        "ref_texts": "[24] S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao, \u201cPvnet: Pixelwise voting network for 6dof pose estimation,\u201d in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , 2019, pp. 4561\u20134570. 2",
        "ref_ids": [
          "24"
        ]
      },
      "Video based object 6d pose estimation using transformers": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2210.13540",
        "ref_texts": "[40] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , pages 4561\u20134570, 2019.",
        "ref_ids": [
          "40"
        ]
      },
      "Bico-net: Regress globally, match locally for robust 6d pose estimation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2205.03536",
        "ref_texts": "[Peng et al. , 2019 ]Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In CVPR , 2019.",
        "ref_ids": [
          "Peng et al\\. , 2019 "
        ]
      },
      "Stability-driven contact reconstruction from monocular color images": {
        "authors": [
          "Zimeng Zhao",
          "Binghui Zuo",
          "Wei Xie",
          "Yangang Wang"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2022/papers/Zhao_Stability-Driven_Contact_Reconstruction_From_Monocular_Color_Images_CVPR_2022_paper.pdf",
        "ref_texts": "[43] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In CVPR , pages 4561\u20134570, 2019. 2",
        "ref_ids": [
          "43"
        ]
      },
      "Disp6d: Disentangled implicit shape and pose learning for scalable 6d pose estimation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2107.12549",
        "ref_texts": "44. Peng, S., Liu, Y., Huang, Q., Zhou, X., Bao, H.: Pvnet: Pixel-wise voting network for 6dof pose estimation. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. pp. 4561\u20134570 (2019)",
        "ref_ids": [
          "44"
        ]
      },
      "Sequential voting with relational box fields for active object detection": {
        "authors": [
          "Qichen Fu",
          "Xingyu Liu",
          "Kris Kitani"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2022/papers/Fu_Sequential_Voting_With_Relational_Box_Fields_for_Active_Object_Detection_CVPR_2022_paper.pdf",
        "ref_texts": "[26] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 4561\u2013",
        "ref_ids": [
          "26"
        ]
      },
      "A survey of 6d object detection based on 3d models for industrial applications": {
        "authors": [],
        "url": "https://www.mdpi.com/2313-433X/8/3/53/pdf",
        "ref_texts": "49. Peng, S.; Liu, Y.; Huang, Q.; Zhou, X.; Bao, H. PVNET: Pixel-wise voting network for 6dof pose estimation. In Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition, Long Beach, CA, USA, 15\u201320 June 2019; IEEE Computer Society: Washington, DC, USA, 2019; pp. 4556\u20134565. [CrossRef]",
        "ref_ids": [
          "49"
        ]
      },
      "HMD-EgoPose: Head-mounted display-based egocentric marker-less tool and hand pose estimation for augmented surgical guidance": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2202.11891",
        "ref_texts": "[18] Peng, S., Liu, Y., Huang, Q., Zhou, X., Bao, H.: Pvnet: Pixel-wise voting network for 6dof pose estimation. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 4561{4570 (2019)",
        "ref_ids": [
          "18"
        ]
      },
      "A study on recognizing multi-real world object and estimating 3D position in augmented reality": {
        "authors": [
          "Taemin Lee"
        ],
        "url": "https://link.springer.com/content/pdf/10.1007/s11227-021-04161-0.pdf",
        "ref_texts": ""
      },
      "Template-based category-agnostic instance detection for robotic manipulation": {
        "authors": [],
        "url": "https://dr.ntu.edu.sg/bitstream/10356/164360/2/Template%20Based%20Category%20Agnostic%20Instance%20Detection%20for%20Robotic%20Manipulation.pdf",
        "ref_texts": "[21] S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao, \u201cPvnet: Pixelwise voting network for 6dof pose estimation,\u201d in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), June 2019.",
        "ref_ids": [
          "21"
        ]
      },
      "Ambiguity-aware multi-object pose optimization for visually-assisted robot manipulation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2211.00960",
        "ref_texts": "[2] S. Peng et al. , \u201cPvnet: Pixel-wise voting network for 6dof pose estimation,\u201d in Proc. IEEE Conf. on Comput. Vision and Pattern Recog. , 2019, pp. 4561\u20134570.",
        "ref_ids": [
          "2"
        ]
      },
      "GoferBot: A Visual Guided Human-Robot Collaborative Assembly System": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2304.08840",
        "ref_texts": "[26] S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao, \u201cPvnet: Pixel-wise voting network for 6dof pose estimation,\u201d in CVPR , 2019.",
        "ref_ids": [
          "26"
        ]
      },
      "A 6D pose estimation for robotic bin-picking using point-pair features with curvature (Cur-PPF)": {
        "authors": [
          "Xining Cui",
          "Menghui Yu",
          "Linqigao Wu",
          "Shiqian Wu"
        ],
        "url": "https://www.mdpi.com/1424-8220/22/5/1805/pdf",
        "ref_texts": "16. Peng, S.; Liu, Y.; Huang, Q.; Zhou, X.; Bao, H. PVNET: Pixel-Wise Voting Network for 6dof Pose Estimation. In Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition, Los Angeles, CA, USA, 15\u201321 June 2019. Sensors 2022 ,22, 1805 20 of 20",
        "ref_ids": [
          "16"
        ]
      },
      "SO (3)\u2010Pose: SO (3)\u2010Equivariance Learning for 6D Object Pose Estimation": {
        "authors": [
          "Haoran Pan"
        ],
        "url": "https://arxiv.org/pdf/2208.08338",
        "ref_texts": "[PLH\u000319] P ENG S., L IUY., H UANG Q., Z HOU X., B AOH.: Pvnet: Pixel-wise voting network for 6dof pose estimation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (2019), pp. 4561\u20134570. 6, 8, 9",
        "ref_ids": [
          "PLH\u000319"
        ]
      },
      "Sim2Real instance-level style transfer for 6D pose estimation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2203.02069",
        "ref_texts": "[25] S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao, \u201cPvnet: Pixelwise voting network for 6dof pose estimation,\u201d in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , 2019, pp. 4561\u20134570.",
        "ref_ids": [
          "25"
        ]
      },
      "Collaborative Viewpoint Adjusting and Grasping via Deep Reinforcement Learning in Clutter Scenes": {
        "authors": [
          "Firstname Lastname",
          "Firstname Lastname",
          "Firstname Lastname"
        ],
        "url": "https://www.mdpi.com/2075-1702/10/12/1135/pdf",
        "ref_texts": "9. Peng, S.; Liu, Y.; Huang, Q.; Zhou, X.; Bao, H. Pvnet: Pixel-wise voting network for 6dof pose estimation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, Long Beach, CA, USA, 15\u201320 June 2019; pp. 4561\u20134570.",
        "ref_ids": [
          "9"
        ]
      },
      "Combining local and global pose estimation for precise tracking of similar objects": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2201.13278",
        "ref_texts": "(2020). Tga: Two-level group attention for assembly state detection. In Proc. ISMAR . Masood, T. and Egger, J. (2020). Adopting augmented reality in the age of industrial digitalisation. Computers in Industry , 115:103112. Park, K., Patten, T., and Vincze, M. (2019). Pix2pose: Pixelwise coordinate regression of objects for 6d pose estimation. In Proc. ICCV . Peng, S., Liu, Y ., Huang, Q., Zhou, X., and Bao, H. (2019). Pvnet: Pixel-wise voting network for 6dof pose estimation. In Proc. CVPR . Prisacariu, V . A. and Reid, I. D. (2012). Pwp3d: Real-time segmentation and tracking of 3d objects. International Journal of Computer Vision , 98(3):335\u2013354. Rad, M. and Lepetit, V . (2017). Bb8: A scalable, accurate, robust to partial occlusion method for predicting the 3d poses of challenging objects without using depth. InProc. ICCV . Seibold, C., Hilsmann, A., and Eisert, P. (2017). Modelbased motion blur estimation for the improvement of motion tracking. Computer Vision and Image Understanding , 160:45\u201356. Seo, B.-K., Park, H., Park, J.-I., Hinterstoisser, S., and Ilic, S. (2013). Optimal local searching for fast and robust textureless 3d object tracking in highly cluttered backgrounds. IEEE Transactions on Visualization and Computer Galraphics , 20(1):99\u2013110. Sock, J., Castro, P., Armagan, A., Garcia-Hernando, G., and Kim, T.-K. (2020). Tackling two challenges of 6d object pose estimation: Lack of real annotated rgb images and scalability to number of objects. arXiv preprint arXiv:2003.12344v1 . Song, C., Song, J., and Huang, Q. (2020). Hybridpose: 6d object pose estimation under hybrid representations. In Proc. CVPR . Steinbach, E., Eisert, P., and Girod, B. (2001). Model-based 3-d shape and motion estimation using sliding textures. InProc. VMV . Su, Y ., Rambach, J., Minaskan, N., Lesur, P., Pagani, A., and Stricker, D. (2019). Deep multi-state object pose estimation for augmented reality assembly. In Proc. ISMAR . Sun, D., Roth, S., and Black, M. J. (2010). Secrets of optical flow estimation and their principles. In Proc. CVPR . Sun, X., Zhou, J., Zhang, W., Wang, Z., and Yu, Q. (2021). Robust monocular pose tracking of less-distinct objects based on contour-part model. IEEE Transactions on Circuits and Systems for Video Technology , 31(11):4409\u20134421. Tan, Z., Chen, D., Chu, Q., Chai, M., Liao, J., He, M., Yuan, L., Hua, G., and Yu, N. (2021). Efficient semantic image synthesis via class-adaptive normalization. IEEE Transactions on Pattern Analysis and Machine Intelligence . Thalhammer, S., Leitner, M., Patten, T., and Vincze, M."
      },
      "Structure-aware nerf without posed camera via epipolar constraint": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2210.00183",
        "ref_texts": "[47] S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao, \u201cPvnet: Pix el-wise voting network for 6dof pose estimation,\u201d in Proc. IEEE Conf . Comput. Vis. Pattern Recognit., Jun. 2019, pp. 4561-4570.",
        "ref_ids": [
          "47"
        ]
      },
      "Visual Positioning System Based on 6D Object Pose Estimation Using Mobile Web": {
        "authors": [
          "Young Kim",
          "Seon Kim",
          "Yeol Yun",
          "Won Jung",
          "Chul Kwon",
          "Dong Jung"
        ],
        "url": "https://www.mdpi.com/2079-9292/11/6/865/pdf",
        "ref_texts": "10. Peng, S.; Liu, Y.; Huang, Q.; Zhou, X.; Bao, H. Pvnet: Pixel-wise voting network for 6dof pose estimation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, Long Beach, CA, USA, 15\u201320 June 2019; pp. 4556\u20134565.",
        "ref_ids": [
          "10"
        ]
      },
      "Canonical voting: Towards robust oriented bounding box detection in 3d scenes": {
        "authors": [
          "Yang You",
          "Zelin Ye",
          "Yujing Lou",
          "Chengkun Li",
          "Lu Li",
          "Lizhuang Ma",
          "Weiming Wang",
          "Cewu Lu"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2022/papers/You_Canonical_Voting_Towards_Robust_Oriented_Bounding_Box_Detection_in_3D_CVPR_2022_paper.pdf",
        "ref_texts": "[14] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 4561\u20134570, 2019.",
        "ref_ids": [
          "14"
        ]
      },
      "Dprost: Dynamic projective spatial transformer network for 6d pose estimation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2112.08775",
        "ref_texts": "31. Peng, S., Liu, Y., Huang, Q., Zhou, X., Bao, H.: Pvnet: Pixel-wise voting network for 6dof pose estimation. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 4561\u20134570 (2019)",
        "ref_ids": [
          "31"
        ]
      },
      "6D Robotic assembly based on RGB-only object pose estimation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2208.12986",
        "ref_texts": "[17] S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao, \u201cPvnet: Pixelwise voting network for 6dof pose estimation,\u201d in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , 2019, pp. 4561\u20134570.",
        "ref_ids": [
          "17"
        ]
      },
      "Learning to Estimate Object Poses without Real Image Annotations.": {
        "authors": [
          "Haotong Lin",
          "Sida Peng",
          "Zhize Zhou",
          "Xiaowei Zhou"
        ],
        "url": "https://www.ijcai.org/proceedings/2022/0162.pdf",
        "ref_texts": "[Park et al., 2019 ]Kiru Park, Timothy Patten, and Markus Vincze. Pix2pose: Pixel-wise coordinate regression of objects for 6d pose estimation. In ICCV, pages 7668\u20137677, 2019.[Peng et al., 2019 ]Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In CVPR, pages 4561\u2013",
        "ref_ids": [
          "Park et al\\., 2019 ",
          "Peng et al\\., 2019 "
        ]
      },
      "Parapose: Parameter and domain randomization optimization for pose estimation using synthetic data": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2203.00945",
        "ref_texts": "[27] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In IEEE Conference on Computer Vision and Pattern Recognition , pages 4561\u2013",
        "ref_ids": [
          "27"
        ]
      },
      "Automatic landmark detection and mapping for 2D/3D registration with BoneNet": {
        "authors": [
          "Van Nguyen"
        ],
        "url": "https://www.frontiersin.org/articles/10.3389/fvets.2022.923449/pdf",
        "ref_texts": "23. Peng S, Liu Y, Huang Q, Bao H, Zhou X. PVNet: pixel-wise votin g network for 6DoF pose estimation. In: 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) . Long Beach, CA (2019). doi:10.1109/CVPR.2019.00469",
        "ref_ids": [
          "23"
        ]
      },
      "Robust 6-dof pose estimation under hybrid constraints": {
        "authors": [
          "Hong Ren",
          "Lin Lin",
          "Yanjie Wang",
          "Xin Dong"
        ],
        "url": "https://www.mdpi.com/1424-8220/22/22/8758/pdf",
        "ref_texts": "27. Peng, S.; Zhou, X.; Liu, Y.; Lin, H.; Huang, Q.; Bao, H. PVNet: Pixel-Wise Voting Network for 6DoF Object Pose Estimation. IEEE Trans. Pattern Anal. Mach. Intell. 2022 ,44, 3212\u20133223. [CrossRef]",
        "ref_ids": [
          "27"
        ]
      },
      "CSA6D: Channel-spatial attention networks for 6D object pose estimation": {
        "authors": [
          "Tao Chen"
        ],
        "url": "https://link.springer.com/content/pdf/10.1007/s12559-021-09966-y.pdf",
        "ref_texts": " 34. Peng S, Liu Y, Huang Q, Zhou X, Bao H. PVNet: pixel-wise voting network for 6DoF pose estimation . In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recogni tion; 2019. p. 4561-70."
      },
      "Welsa: Learning to predict 6d pose from weakly labeled data using shape alignment": {
        "authors": [],
        "url": "https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136680633.pdf",
        "ref_texts": "28. Peng, S., Liu, Y., Huang, Q., Zhou, X., Bao, H.: Pvnet: Pixel-wise voting network for 6dof pose estimation. In: CVPR (2019)",
        "ref_ids": [
          "28"
        ]
      },
      "Single rgb image 6d object grasping system using pixel-wise voting network": {
        "authors": [
          "Zhongjie Zhang",
          "Chengzhe Zhou",
          "Yasuharu Koike",
          "Jiamao Li"
        ],
        "url": "https://www.mdpi.com/2072-666X/13/2/293/pdf",
        "ref_texts": "27. Peng, S.; Zhou, X.; Liu, Y.; Lin, H.; Huang, Q.; Bao, H. Pvnet: pixel-wise voting network for 6dof object pose estimation. IEEE Trans. Pattern Anal. Mach. Intell. 2020 ,2020 . [CrossRef] [PubMed]",
        "ref_ids": [
          "27"
        ]
      },
      "Multi-view object pose distribution tracking for pre-grasp planning on mobile robots": {
        "authors": [],
        "url": "https://portal.findresearcher.sdu.dk/files/206261625/Multi_view_pose_distribution_tracking_ICRA2022_camera_ready_2_.pdf",
        "ref_texts": "[28] S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao, \u201cPvnet: Pixel-wise voting network for 6dof pose estimation,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , 2019, pp.",
        "ref_ids": [
          "28"
        ]
      },
      "A dynamic keypoint selection network for 6dof pose estimation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2110.12401",
        "ref_texts": "[25] Peng, S., Liu, Y., Huang, Q., Zhou, X., & Bao, H. (2019). Pvnet: Pixel -wise voting network for 6dof pose estimation. In Proceedin gs of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 4561 -4570). ",
        "ref_ids": [
          "25"
        ]
      },
      "CenDerNet: Center and Curvature Representations for Render-and-Compare 6D Pose Estimation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2208.09829",
        "ref_texts": "20. Peng, S., Liu, Y., Huang, Q., Zhou, X., Bao, H.: Pvnet: Pixel-wise voting network for 6dof pose estimation. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 4561\u20134570 (2019)",
        "ref_ids": [
          "20"
        ]
      },
      "CASAPose: Class-Adaptive and Semantic-Aware Multi-Object Pose Estimation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2210.05318",
        "ref_texts": "[30] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In Proc. CVPR , 2019.",
        "ref_ids": [
          "30"
        ]
      },
      "Reflective texture-less object registration using multiple edge features for augmented reality assembly": {
        "authors": [],
        "url": "https://www.researchsquare.com/article/rs-1578869/latest.pdf",
        "ref_texts": "23. S. Peng, Y. Liu, Q. Huang, H. Bao, and X. Zhou, \"PVNet: Pixel-wise Voting Network for 6DoF Pose Estimation,\" 2018.",
        "ref_ids": [
          "23"
        ]
      },
      "Research on non-pooling YOLOv5 based algorithm for the recognition of randomly distributed multiple types of parts": {
        "authors": [
          "Zehua Yu",
          "Ling Zhang",
          "Xingyu Gao",
          "Yang Huang",
          "Xiaoke Liu"
        ],
        "url": "https://www.mdpi.com/1424-8220/22/23/9335/pdf",
        "ref_texts": "2. Peng, S.; Zhou, X.; Liu, Y.; Lin, H.; Huang, Q.; Bao, H. PVNet: Pixel-Wise Voting Network for 6DoF Object Pose Estimation. IEEE Trans. Pattern. Anal. Mach. Intell. 2022 ,44, 3212\u20133223. [CrossRef] [PubMed]",
        "ref_ids": [
          "2"
        ]
      },
      "3D object reconstruction and 6D-pose estimation from 2D shape for robotic grasping of objects": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2203.01051",
        "ref_texts": "[25] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. 2019. Pvnet: Pixel-wise voting network for 6dof pose estimation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition . 4561\u20134570.",
        "ref_ids": [
          "25"
        ]
      },
      "Shape Enhanced Keypoints Learning with Geometric Prior for 6D Object Pose Tracking": {
        "authors": [
          "Mateusz Majcher",
          "Bogdan Kwolek"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2022W/DLGC/papers/Majcher_Shape_Enhanced_Keypoints_Learning_With_Geometric_Prior_for_6D_Object_CVPRW_2022_paper.pdf",
        "ref_texts": "[20] S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao. PVNet: Pixel-wise voting network for 6DoF pose estimation. In CVPR , pages 4556\u20134565, 2019. 2, 3",
        "ref_ids": [
          "20"
        ]
      },
      "Semi-automatic 3D object keypoint annotation and detection for the masses": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2201.07665",
        "ref_texts": "[16] S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao, \u201cPVNet: Pixel-wise voting network for 6DoF pose estimation,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , 2019, pp.",
        "ref_ids": [
          "16"
        ]
      },
      "Adversarial samples for deep monocular 6d object pose estimation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2203.00302",
        "ref_texts": "33. Peng, S., Liu, Y., Huang, Q., Zhou, X., Bao, H.: Pvnet: Pixel-wise voting network for 6dof pose estimation. In: CVPR (2019)",
        "ref_ids": [
          "33"
        ]
      },
      "Cross-attention-based reflection-aware 6D pose estimation network for non-Lambertian objects from RGB images": {
        "authors": [
          "Chenrui Wu",
          "Long Chen",
          "Shiqing Wu"
        ],
        "url": "https://www.mdpi.com/2075-1702/10/12/1107/pdf",
        "ref_texts": "17. Peng, S.; Liu, Y.; Huang, Q.; Zhou, X.; Bao, H. Pvnet: Pixel-wise voting network for 6dof pose estimation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), Long Beach, CA, USA, 15\u201320 June 2019; pp. 4561\u20134570.",
        "ref_ids": [
          "17"
        ]
      },
      "Primitive shape recognition for object grasping": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2201.00956",
        "ref_texts": "10344\u201310353. Paschalidou D, van Gool L and Geiger A (2020) Learning unsupervised hierarchical part decomposition of 3D objects from a single rgb image. arXiv preprint arXiv:2004.01176 . Peng S, Liu Y , Huang Q, Zhou X and Bao H (2019) PVNet: Pixelwise voting network for 6DoF pose estimation. In: IEEE Conference on Computer Vision and Pattern Recognition . pp."
      },
      "Semantic keypoint-based pose estimation from single RGB frames": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2204.05864",
        "ref_texts": "551. Lee, C.-Y., Xie, S., Gallagher, P., Zhang, Z., and Tu, Z. (2015). Deeply-supervised nets. In AISTATS , volume 2, page 6. Lepetit, V., Moreno-Noguer, F., and Fua, P. (2009). EP nP: An accurate O(n) solution to the P nP problem. IJCV , 81(2):155{166. Li, Y., Wang, G., Ji, X., Xiang, Y., and Fox, D. (2018). Deepim: Deep iterative matching for 6d pose estimation. In Proceedings of the European Conference on Computer Vision (ECCV) , pages 683{698. Li, Z., Wang, G., and Ji, X. (2019). Cdpn: Coordinates-based disentangled pose network for real-time rgb-based 6-dof object pose estimation. In Proceedings of the IEEE/CVF International Conference on Computer Vision , pages 7678{7687. Liu, J., Zou, Z., Ye, X., Tan, X., Ding, E., Xu, F., and Yu, X. (2020). Leaping from 2d detection to eflcient 6dof object pose estimation. In Computer Vision { ECCV 2020 Workshops , pages 707{714. Long, J., Zhang, N., and Darrell, T. (2014). Do convnets learn correspondence? In NIPS , pages 1601{1609. Lowe, D. G. (2004). Distinctive image features from scale-invariant keypoints. IJCV , 60(2):91{110. Manuelli, L., Gao, W., Florence, P., and Tedrake, R. (2019). Kpam: Keypoint afiordances for category-level robotic manipulation. International Symposium on Robotics Research (ISRR) . Marion, P., Florence, P. R., Manuelli, L., and Tedrake, R. (2018). Label fusion: A pipeline for generating ground truth labels for real rgbd data of cluttered scenes. In ICRA . Massa, F., Aubry, M., and Marlet, R. (2014). Convolutional neural networks for joint object detection and pose estimation: A comparative study. CoRR , abs/1412.7190. Michel, F., Kirillov, A., Brachmann, E., Krull, A., Gumhold, S., Savchynskyy, B., and Rother, C. (2017). Global hypothesis generation for 6D object pose estimation. In CVPR . Montserrat, D. M., Chen, J., Lin, Q., Allebach, J. P., and Delp, E. J. (2019). Multi-view matching network for 6d pose estimation. arXiv preprint arXiv:1911.12330 . Mousavian, A., Anguelov, D., Flynn, J., and Kosecka, J. (2017). 3d bounding box estimation using deep learning and geometry. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 7074{7082. Muja, M., Rusu, R. B., Bradski, G. R., and Lowe, D. G. (2011). REIN A fast, robust, scalable recognition infrastructure. In ICRA , pages 2939{2946. Murthy, J. K., Krishna, G., Chhaya, F., and Krishna, K. M. (2017). Reconstructing vechicles from a single image: Shape priors for road scene understanding. ICRA . Narayanan, P., Yeh, B., Holmes, E., Martucci, S., Schmeckpeper, K., Mertz, C., Osteen, P., and Wigness, M. (2020). An integrated perception pipeline for robot mission execution in unstructured environments. InArtiffcial Intelligence and Machine Learning for Multi-Domain Operations Applications II , volume 11413, page 1141318. International Society for Optics and Photonics. Newell, A., Yang, K., and Deng, J. (2016). Stacked hourglass networks for human pose estimation. In ECCV . Osteen, P. R., Owens, J. L., and Kaukeinen, B. (2019). Reducing the cost of visual DL datasets. In Pham, T., editor, Artiffcial Intelligence and Machine Learning for Multi-Domain Operations Applications , volume 11006, pages 121 { 139. International Society for Optics and Photonics, SPIE. Park, K., Patten, T., and Vincze, M. (2019). Pix2pose: Pixel-wise coordinate regression of objects for 6d pose estimation. In Proceedings of the IEEE/CVF International Conference on Computer Vision , pages 7668{7677. Pavlakos, G., Zhou, X., Chan, A., Derpanis, K. G., and Daniilidis, K. (2017). 6-DoF object pose from semantic keypoints. ICRA , pages 2011{2018. Peng, S., Liu, Y., Huang, Q., Zhou, X., and Bao, H. (2019). Pvnet: Pixel-wise voting network for 6dof pose estimation. In CVPR , pages 4561{4570. Pepik, B., Stark, M., Gehler, P. V., and Schiele, B. (2012). Teaching 3D geometry to deformable part models. InCVPR , pages 3362{3369. Qin, Z., Fang, K., Zhu, Y., Fei-Fei, L., and Savarese, S. (2019). Keto: Learning keypoint representations for tool manipulation. International Conference on Robotics and Automation (ICRA) . Rad, M. and Lepetit, V. (2017). Bb8: A scalable, accurate, robust to partial occlusion method for predicting the 3d poses of challenging objects without using depth. In Proceedings of the IEEE International Conference on Computer Vision , pages 3828{3836. Ramakrishna, V., Kanade, T., and Sheikh, Y. (2012). Reconstructing 3D human pose from 2D image landmarks. In ECCV , pages 573{586. Ren, S., He, K., Girshick, R., and Sun, J. (2015). Faster R-CNN: Towards real-time object detection with region proposal networks. In NIPS , pages 91{99. Rios-Cabrera, R. and Tuytelaars, T. (2013). Discriminatively trained templates for 3D object detection: A real time scalable approach. In ICCV , pages 2048{2055. Rusu, R. B., Blodow, N., and Beetz, M. (2009). Fast point feature histograms (FPFH) for 3D registration. InICRA , pages 3212{3217. Salti, S., Tombari, F., and di Stefano, L. (2014). Shot: Unique signatures of histograms for surface and texture description. CVIU , 125:251{264. Sohn, K., Berthelot, D., Li, C.-L., Zhang, Z., Carlini, N., Cubuk, E. D., Kurakin, A., Zhang, H., and Rafiel, C. (2020). Fixmatch: Simplifying semi-supervised learning with consistency and conffdence. Advances in Neural Information Processing Systems (NeurIPS) . Song, C., Song, J., and Huang, Q. (2020). Hybridpose: 6d object pose estimation under hybrid representations. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , pages 431{440. Su, H., Qi, C. R., Li, Y., and Guibas, L. J. (2015a). Render for CNN: viewpoint estimation in images using CNNs trained with rendered 3D model views. In ICCV , pages 2686{2694. Su, H., Qi, C. R., Li, Y., and Guibas, L. J. (2015b). Render for cnn: Viewpoint estimation in images using cnns trained with rendered 3d model views. In Proceedings of the IEEE International Conference on Computer Vision , pages 2686{2694. Sundermeyer, M., Marton, Z.-C., Durner, M., and Triebel, R. (2020). Augmented autoencoders: Implicit 3d orientation learning for 6d object detection. International Journal of Computer Vision , 128(3):714{729. Tekin, B., Sinha, S. N., and Fua, P. (2018). Real-time seamless single shot 6d object pose prediction. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 292{301. Tieleman, T. and Hinton, G. (2012). Lecture 6.5-rmsprop, coursera: Neural networks for machine learning. University of Toronto, Technical Report . Toshev, A. and Szegedy, C. (2014). DeepPose: Human pose estimation via deep neural networks. In CVPR , pages 1653{1660. Tremblay, J., To, T., Sundaralingam, B., Xiang, Y., Fox, D., and Birchffeld, S. (2018). Deep object pose estimation for semantic robotic grasping of household objects. Conference on Robot Learning (CoRL) . Tulsiani, S. and Malik, J. (2015). Viewpoints and keypoints. In CVPR , pages 1510{1519. Vasilopoulos, V. and Koditschek, D. E. (2018). Reactive navigation in partially known non-convex environments. In International Workshop on the Algorithmic Foundations of Robotics , pages 406{421. Springer. Vasilopoulos, V., Pavlakos, G., Bowman, S. L., Caporale, J. D., Daniilidis, K., Pappas, G. J., and Koditschek, D. E. (2020a). Reactive Semantic Planning in Unexplored Semantic Environments Using Deep Perceptual Feedback. RAL , 5(3):4455{4462. Vasilopoulos, V., Pavlakos, G., Schmeckpeper, K., Daniilidis, K., and Koditschek, D. E. (2020b). Reactive navigation in partially familiar planar environments using semantic perceptual feedback. arXiv preprint arXiv:2002.08946 . Wang, C., Mart\u0013 \u0010n-Mart\u0013 \u0010n, R., Xu, D., Lv, J., Lu, C., Fei-Fei, L., Savarese, S., and Zhu, Y. (2019). 6-pack: Category-level 6D pose tracker with anchor-based keypoints. International Conference on Robotics and Automation (ICRA) . Wang, G., Manhardt, F., Shao, J., Ji, X., Navab, N., and Tombari, F. (2020). Self6d: Self-supervised monocular 6d object pose estimation. In European Conference on Computer Vision , pages 108{125. Springer. Wei, S.-E., Ramakrishna, V., Kanade, T., and Sheikh, Y. (2016). Convolutional pose machines. In CVPR . Whelan, T., Kaess, M., Johannsson, H., Fallon, M., Leonard, J. J., and McDonald, J. (2015). Real-time large-scale dense rgb-d slam with volumetric fusion. The International Journal of Robotics Research , 34(4-5):598{626. Whelan, T., Salas-Moreno, R. F., Glocker, B., Davison, A. J., and Leutenegger, S. (2016). Elasticfusion: Real-time dense slam and light source estimation. The International Journal of Robotics Research , 35(14):1697{1716. Xiang, Y., Mottaghi, R., and Savarese, S. (2014). Beyond PASCAL: A benchmark for 3D object detection in the wild. In WACV , pages 75{82. Xiang, Y., Schmidt, T., Narayanan, V., and Fox, D. (2017). Posecnn: A convolutional neural network for 6d object pose estimation in cluttered scenes. Robotics: Science and Systems (RSS) . Xie, Q., Dai, Z., Hovy, E., Luong, M.-T., and Le, Q. V. (2019). Unsupervised data augmentation for consistency training. Advances in Neural Information Processing Systems (NeurIPS) . Xie, Z., Singh, A., Uang, J., Narayan, K. S., and Abbeel, P. (2013). Multimodal blending for high-accuracy instance recognition. In IROS , pages 2214{2221. Zeng, A., Yu, K.-T., Song, S., Suo, D., Walker, E., Rodriguez, A., and Xiao, J. (2017). Multi-view selfsupervised deep learning for 6d pose estimation in the amazon picking challenge. In 2017 IEEE international conference on robotics and automation (ICRA) , pages 1386{1383. IEEE. Zhou, X., Karpur, A., Luo, L., and Huang, Q. (2018). Starmap for category-agnostic keypoint and viewpoint estimation. In ECCV , pages 318{334. Zhou, X., Leonardos, S., Hu, X., and Daniilidis, K. (2015a). 3D shape estimation from 2D landmarks: A convex relaxation approach. In CVPR , pages 4447{4455. Zhou, X., Zhu, M., Leonardos, S., Derpanis, K., and Daniilidis, K. (2015b). Sparseness meets deepness: 3D human pose estimation from monocular video. In CVPR . Zhu, M., Derpanis, K. G., Yang, Y., Brahmbhatt, S., Zhang, M., Phillips, C., Lecce, M., and Daniilidis, K.",
        "ref_ids": [
          "551"
        ]
      },
      "A deep learning framework for accurate vehicle yaw angle estimation from a monocular camera based on part arrangement": {
        "authors": [
          "Wenjun Huang",
          "Wenbo Li",
          "Luqi Tang",
          "Xiaoming Zhu",
          "Bin Zou"
        ],
        "url": "https://www.mdpi.com/1424-8220/22/20/8027/pdf",
        "ref_texts": "9. Peng, S.D.; Liu, Y.; Huang, Q.X.; Zhou, X.W.; Bao, H.J.; Soc, I.C. PVNet: Pixel-wise Voting Network for 6DoF Pose Estimation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), Long Beach, CA, USA, 15\u201320 June 2019.",
        "ref_ids": [
          "9"
        ]
      },
      "Joint Hand and Object Pose Estimation from a Single RGB Image using High\u2010level 2D Constraints": {
        "authors": [],
        "url": "https://diglib.eg.org/bitstreams/9caaade5-8e65-439e-b0df-aa1cec97570d/download",
        "ref_texts": "[PLH\u221719] P ENG S., L IUY., H UANG Q., Z HOU X., B AOH.: Pvnet: Pixel-wise voting network for 6dof pose estimation. In IEEE/CVF CVPR",
        "ref_ids": [
          "PLH\u221719"
        ]
      },
      "Object-based visual camera pose estimation from ellipsoidal model and 3D-aware ellipse prediction": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2203.04613",
        "ref_texts": "32. Peng, S., Liu, Y., Huang, Q., Zhou, X., Bao, H.: Pvnet: Pixel-wise voting network for 6dof pose estimation. In: IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2019, Long Beach, CA, USA, June 16-20, 2019, pp. 4561{4570. Computer Vision Foundation / IEEE (2019)",
        "ref_ids": [
          "32"
        ]
      },
      "DFBVS: Deep feature-based visual servo": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2201.08046",
        "ref_texts": "[25] S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao, \u201cPvnet: Pixelwise voting network for 6dof pose estimation,\u201d in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pp. 4561\u20134570, 2019.",
        "ref_ids": [
          "25"
        ]
      },
      "Texture-less shiny objects grasping in a single rgb image using synthetic training data": {
        "authors": [
          "Chen Chen",
          "Xin Jiang",
          "Shu Miao",
          "Guo Zhou",
          "Hui Liu"
        ],
        "url": "https://www.mdpi.com/2076-3417/12/12/6188/pdf",
        "ref_texts": "17. Peng, S.; Liu, Y.; Huang, Q.; Zhou, X.; Bao, H. Pvnet: Pixel-wise voting network for 6dof pose estimation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, Long Beach, CA, USA, 15\u201320 June 2019; pp. 4561\u20134570.",
        "ref_ids": [
          "17"
        ]
      },
      "KRF: Keypoint refinement with fusion network for 6D pose estimation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2210.03437",
        "ref_texts": "[11] S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao, \u201cPVNet: Pixelwise voting network for 6dof pose estimation,\u201d in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , 2019, pp. 4561\u20134570.",
        "ref_ids": [
          "11"
        ]
      },
      "Mds-net: A multi-scale depth stratification based monocular 3d object detection algorithm": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2201.04341",
        "ref_texts": "2017. 3D Bounding Box Estimation Using Deep Learning and Geometry. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) . Naiden, A.; Paunescu, V .; Kim, G.; Jeon, B.; and Leordeanu, M. 2019. Shift r-cnn: Deep monocular 3d object detection with closed-form geometric constraints. In 2019 IEEE International Conference on Image Processing (ICIP) , 61\u201365. IEEE. Nguyen, T.; and Grishman, R. 2018. Graph convolutional networks with argument-aware pooling for event detection. InProceedings of the AAAI Conference on Artificial Intelligence , volume 32. Peng, S.; Liu, Y .; Huang, Q.; Zhou, X.; and Bao, H. 2019. PVNet: Pixel-Wise V oting Network for 6DoF Pose Estimation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) . Qi, C. R.; Liu, W.; Wu, C.; Su, H.; and Guibas, L. J. 2018. Frustum PointNets for 3D Object Detection From RGB-D Data. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) . Qi, C. R.; Su, H.; Mo, K.; and Guibas, L. J. 2017. PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) . Qin, Z.; Wang, J.; and Lu, Y . 2019. Monogrnet: A geometric reasoning network for monocular 3d object localization. InProceedings of the AAAI Conference on Artificial Intelligence , volume 33, 8851\u20138858. Ravanbakhsh, M.; Nabi, M.; Sangineto, E.; Marcenaro, L.; Regazzoni, C.; and Sebe, N. 2017. Abnormal event detection in videos using generative adversarial nets. In 2017 IEEE International Conference on Image Processing (ICIP) , 1577\u20131581. IEEE. Redmon, J.; Divvala, S.; Girshick, R.; and Farhadi, A. 2016. You Only Look Once: Unified, Real-Time Object Detection. InProceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) . Ren, S.; He, K.; Girshick, R.; and Sun, J. 2017. Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks. IEEE Transactions on Pattern Analysis and Machine Intelligence , 39(6): 1137\u20131149.Shi, W.; and Rajkumar, R. 2020. Point-gnn: Graph neural network for 3d object detection in a point cloud. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , 1711\u20131719. Shi, X.; Ye, Q.; Chen, X.; Chen, C.; Chen, Z.; and Kim, T.-K.",
        "ref_ids": [
          "2017"
        ]
      },
      "Category-level 6d object pose estimation with flexible vector-based rotation representation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2212.04632",
        "ref_texts": "[23] S. Peng, Y. Liu, Q. Huang, X. Zhou, and H. Bao, \u201cPvnet: Pixelwise voting network for 6dof pose estimation,\u201d in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , 2019, pp. 4561\u20134570.",
        "ref_ids": [
          "23"
        ]
      },
      "HRPose: Real-Time High-Resolution 6D Pose Estimation Network Using Knowledge Distillation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2204.09429",
        "ref_texts": "[15] S. Peng, Y . Liu, Q. Huang, et al. , \u201cPVNet: Pixel-wise voting network for 6DoF pose estimation,\u201d Proceedings of the Conference on Computer Vision and Pattern Recognition , Long Beach, CA, USA, pp.4556\u20134565, 2019.",
        "ref_ids": [
          "15"
        ]
      },
      "Review on 6D Object Pose Estimation with the focus on Indoor Scene Understanding": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2212.01920",
        "ref_texts": "[58] S. Peng, Y . Liu, Q. Huang, H. Bao, and X. Zhou. Pvnet: Pixel-wise voting network for 6dof pose estimation. 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) , pages 4556\u20134565, 2019.",
        "ref_ids": [
          "58"
        ]
      },
      "Towards Two-view 6D Object Pose Estimation: A Comparative Study on Fusion Strategy": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2207.00260",
        "ref_texts": "[18] S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao, \u201cPvnet: Pixelwise voting network for 6dof pose estimation,\u201d in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pp. 4561\u20134570, 2019.",
        "ref_ids": [
          "18"
        ]
      },
      "Cluster-Based 3D Keypoint Detection for Category-Agnostic 6D Pose Tracking": {
        "authors": [],
        "url": "https://qmro.qmul.ac.uk/xmlui/bitstream/handle/123456789/93424/Oh%20CLUSTER-BASED%203D%202022.pdf?sequence=2&isAllowed=y",
        "ref_texts": "[21] S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao, \u201cPVNet: Pixel-wise voting network for 6DoF pose estimation,\u201d in Conf. Comput. Vis. Pattern Recognit. , 2019.",
        "ref_ids": [
          "21"
        ]
      },
      "Geo6D: Geometric Constraints Learning for 6D Pose Estimation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2210.10959",
        "ref_texts": "6727. Peng, S.; Liu, Y .; Huang, Q.; Zhou, X.; and Bao, H. 2019. Pvnet: Pixel-wise voting network for 6dof pose estimation. InProceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , 4561\u20134570. Rad, M.; and Lepetit, V . 2017. Bb8: A scalable, accurate, robust to partial occlusion method for predicting the 3d poses of challenging objects without using depth. In Proceedings of the IEEE international conference on computer vision , 3828\u20133836. Su, Y .; Saleh, M.; Fetzer, T.; Rambach, J.; Navab, N.; Busam, B.; Stricker, D.; and Tombari, F. 2022. ZebraPose: Coarse to Fine Surface Encoding for 6DoF Object Pose Estimation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , 6738\u20136748. Sun, M.; Zheng, Y .; Bao, T.; Chen, J.; Jin, G.; Zhao, R.; Wu, L.; and Jiang, X. 2022. Uni6Dv2: Noise Elimination for 6D Pose Estimation. arXiv preprint arXiv:2208.06416 . Wang, C.; Xu, D.; Zhu, Y .; Mart \u00b4\u0131n-Mart \u00b4\u0131n, R.; Lu, C.; FeiFei, L.; and Savarese, S. 2019. Densefusion: 6d object pose estimation by iterative dense fusion. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , 3343\u20133352. Wang, G.; Manhardt, F.; Shao, J.; Ji, X.; Navab, N.; and Tombari, F. 2020. Self6d: Self-supervised monocular 6d object pose estimation. In European Conference on Computer Vision , 108\u2013125. Wang, G.; Manhardt, F.; Tombari, F.; and Ji, X. 2021. Gdrnet: Geometry-guided direct regression network for monocular 6d object pose estimation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , 16611\u201316621. Xiang, Y .; Schmidt, T.; Narayanan, V .; and Fox, D. 2018. PoseCNN: A Convolutional Neural Network for 6D Object Pose Estimation in Cluttered Scenes. In Robotics: Science and Systems (RSS) . Xu, D.; Anguelov, D.; and Jain, A. 2018. Pointfusion: Deep sensor fusion for 3d bounding box estimation. In Proceedings of the IEEE conference on computer vision and pattern recognition , 244\u2013253. Zeng, L.; Lv, W. J.; Dong, Z. K.; and Liu, Y . J. 2022. PPRNet++: Accurate 6-D Pose Estimation in Stacked Scenarios. IEEE Transactions on Automation Science and Engineering , 19(4): 3139\u20133151.",
        "ref_ids": [
          "6727"
        ]
      },
      "Category-agnostic 6d pose estimation with conditional neural processes": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2206.07162",
        "ref_texts": "[45] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) , June 2019. 1, 2, 6",
        "ref_ids": [
          "45"
        ]
      },
      "MatchNorm: Learning-based Point Cloud Registration for 6D Object Pose Estimation in the Real World": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2203.15309",
        "ref_texts": "44. Peng, S., Liu, Y., Huang, Q., Zhou, X., Bao, H.: PVNet: Pixel-wise Voting Network for 6DoF Pose Estimation. In: Conference on Computer Vision and Pattern Recognition. pp. 4561\u20134570. Long Beach, California (2019) 1",
        "ref_ids": [
          "44"
        ]
      },
      "Real-time detection of 2d tool landmarks with synthetic training data": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2210.11991",
        "ref_texts": "(2019). Photorealistic image synthesis for object instance detection. In 2019 IEEE International Conference on Image Processing (ICIP) , pages 66\u201370. Ioffe, S. and Szegedy, C. (2015). Batch normalization: Accelerating deep network training by reducing internal covariate shift. CoRR , abs/1502.03167. Kingma, D. P. and Ba, J. (2017). Adam: A method for stochastic optimization. Law, H. and Deng, J. (2020). Cornernet: Detecting objects as paired keypoints. International Journal of Computer Vision , 128. Long, J., Zhang, N., and Darrell, T. (2014). Do convnets learn correspondence? CoRR , abs/1411.1091. Lowe, D. (2004). Distinctive image features from scaleinvariant keypoints. International Journal of Computer Vision , 60:91\u2013.Newell, A., Yang, K., and Deng, J. (2016). Stacked hourglass networks for human pose estimation. In Leibe, B., Matas, J., Sebe, N., and Welling, M., editors, Computer Vision \u2013 ECCV 2016 , pages 483\u2013499, Cham. Springer International Publishing. Pavlakos, G., Zhou, X., Chan, A., Derpanis, K. G., and Daniilidis, K. (2017). 6-dof object pose from semantic keypoints. In 2017 IEEE International Conference on Robotics and Automation (ICRA) , pages 2011\u20132018. Peng, S., Liu, Y ., Huang, Q., Zhou, X., and Bao, H. (2019). Pvnet: Pixel-wise voting network for 6dof pose estimation. pages 4556\u20134565. P\u00b4erez, P., Gangnet, M., and Blake, A. (2003). Poisson image editing. ACM Trans. Graph. , 22(3):313\u2013318. Srivastava, N., Hinton, G., Krizhevsky, A., Sutskever, I., and Salakhutdinov, R. (2014). Dropout: A simple way to prevent neural networks from overfitting. Journal of Machine Learning Research , 15(56):1929\u20131958. Toshev, A. and Szegedy, C. (2014). Deeppose: Human pose estimation via deep neural networks. In 2014 IEEE Conference on Computer Vision and Pattern Recognition, pages 1653\u20131660. Tulsiani, S. and Malik, J. (2014). Viewpoints and keypoints. CoRR , abs/1411.6067. Wei, S., Ramakrishna, V ., Kanade, T., and Sheikh, Y ."
      },
      "Learned perception systems for self-driving vehicles": {
        "authors": [],
        "url": "https://mountainscholar.org/bitstream/10217/235337/1/Chaabane_colostate_0053A_17155.pdf",
        "ref_texts": "[43] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. PVNet: Pixel-wise V oting Network for 6DoF Pose Estimation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) , 2019.",
        "ref_ids": [
          "43"
        ]
      },
      "Shape-coded aruco: Fiducial marker for bridging 2d and 3d modalities": {
        "authors": [
          "Lilika Makabe",
          "Hiroaki Santo",
          "Fumio Okura",
          "Yasuyuki Matsushita"
        ],
        "url": "https://openaccess.thecvf.com/content/WACV2022/papers/Makabe_Shape-Coded_ArUco_Fiducial_Marker_for_Bridging_2D_and_3D_Modalities_WACV_2022_paper.pdf",
        "ref_texts": "[27] Sida Peng, Xiaowei Zhou, Yuan Liu, Haotong Lin, Qixing Huang, and Hujun Bao. PVNet: Pixel-wise V oting Network for 6DoF Object Pose Estimation. IEEE Transactions on Pattern Analysis and Machine Intelligence (PAMI) , 2020. early access.",
        "ref_ids": [
          "27"
        ]
      },
      "Real-time embedded reconstruction of dynamic objects for a 3D maritime situational awareness picture": {
        "authors": [],
        "url": "https://elib.dlr.de/193059/1/MARESEC_2022_11_final.pdf",
        "ref_texts": "[20] S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao, \u201cPvnet: Pixelwise voting network for 6dof pose estimation,\u201d in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) , June 2019.",
        "ref_ids": [
          "20"
        ]
      },
      "SaMfENet: Self-Attention Based Multi-Scale Feature Fusion Coding and Edge Information Constraint Network for 6D Pose Estimation": {
        "authors": [
          "Zhuoxiao Li",
          "Xiaobing Li",
          "Shihao Chen",
          "Jialong Du",
          "Yong Li"
        ],
        "url": "https://www.mdpi.com/2227-7390/10/19/3671/pdf",
        "ref_texts": "2. Peng, S.; Liu, Y.; Huang, Q.; Zhou, X.; Bao, H. Pvnet: Pixel-wise voting network for 6dof pose estimation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, Padua, Italy, 18\u201323 July 2019; pp. 4561\u20134570.",
        "ref_ids": [
          "2"
        ]
      },
      "6d object pose estimation in cluttered scenes from RGB images": {
        "authors": [],
        "url": "https://jcst.ict.ac.cn/fileup/1000-9000/PDF/2022-3-16-1311.pdf",
        "ref_texts": "[46] Peng S, Liu Y, Huang Q, Zhou X, Bao H. PVNet: Pixelwise voting network for 6DoF pose estimation. In Proc. the 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition , June 2019, pp.4561-4570. DOI: 10.1109/CVPR.2019.00469.",
        "ref_ids": [
          "46"
        ]
      },
      "A Flexible-Frame-Rate Vision-Aided Inertial Object Tracking System for Mobile Devices": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2210.12476",
        "ref_texts": "[29] S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao. PVNet: Pixelwise voting network for 6DoF pose estimation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pp. 4561\u20134570, 2019.",
        "ref_ids": [
          "29"
        ]
      },
      "Object Recognition and Pose Estimation from RGB-D Data Using Active Sensing": {
        "authors": [],
        "url": "http://web-ext.u-aizu.ac.jp/conference/ieeeuoas/files/CFP_GS_Info_2022/Posters/24.pdf",
        "ref_texts": ""
      },
      "One-Shot General Object Localization": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2211.13392",
        "ref_texts": "[15] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 4561\u2013",
        "ref_ids": [
          "15"
        ]
      },
      "Pose Guided Feature Learning for 3D Object Tracking on RGB Videos.": {
        "authors": [],
        "url": "https://www.scitepress.org/Papers/2022/108868/108868.pdf",
        "ref_texts": "(2017). Nonlinear Bayesian filtering and learning: A neuronal dynamics for perception. Scientific Reports , 7(1).Majcher, M. and Kwolek, B. (2021). Deep quaternion pose proposals for 6D object pose tracking. In Proceedings of the IEEE/CVF Int. Conf. on Computer Vision (ICCV) Workshops , pages 243\u2013251. Manhardt, F., Wang, G., Busam, B., Nickel, M., Meier, S., Minciullo, L., Ji, X., and Navab, N. (2020). CPS++: Improving class-level 6D pose and shape estimation from monocular images with self-supervised learning. arXiv 2003.05848. Newell, A., Yang, K., and Deng, J. (2016). Stacked hourglass networks for human pose estimation. In ECCV , pages 483\u2013499. Springer. Pavlakos, G., Zhou, X., Chan, A., Derpanis, K. G., and Daniilidis, K. (2017). 6-DoF object pose from semantic keypoints. In IEEE Int. Conf. on Robotics and Automation (ICRA) , pages 2011\u20132018. Peng, S., Liu, Y ., Huang, Q., Zhou, X., and Bao, H. (2019). PVNet: Pixel-Wise V oting Network for 6DoF Pose Estimation. In IEEE Conf. on Comp. Vision and Patt. Rec., pages 4556\u20134565. Prisacariu, V . A. and Reid, I. D. (2012). PWP3D: RealTime Segmentation and Tracking of 3D Objects. Int. J. Comput. Vision , 98(3):335\u2013354. Rad, M. and Lepetit, V . (2017). BB8: A scalable, accurate, robust to partial occlusion method for predicting the 3D poses of challenging objects without using depth. InIEEE Int. Conf. on Comp. Vision , pages 3848\u20133856. Tekin, B., Sinha, S. N., and Fua, P. (2018). Real-time seamless single shot 6D object pose prediction. In IEEE/CVF Conf. on Comp. Vision and Pattern Rec."
      },
      "Iterative 3D Deformable Registration from Single-view RGB Images using Differentiable Rendering.": {
        "authors": [],
        "url": "https://www.scitepress.org/Papers/2022/108171/108171.pdf",
        "ref_texts": "468. Peng, S., Liu, Y ., Huang, Q., Zhou, X., and Bao, H. (2019). PVNet: Pixel-wise voting network for 6DOF pose estimation. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , pages 4561\u20134570. Periyasamy, A. S., Schwarz, M., and Behnke, S. (2019). Refining 6D object pose predictions using abstract render-and-compare. In IEEE-RAS 19th International Conference on Humanoid Robots (Humanoids) , pages 739\u2013746. Pharr, M., Jakob, W., and Humphreys, G. (2016). Physically based rendering: From theory to implementation. Morgan Kaufmann. Ravi, N., Reizenstein, J., Novotny, D., Gordon, T., Lo, W.Y ., Johnson, J., and Gkioxari, G. (2020). Accelerating 3D deep learning with PyTorch3D. In European Conference on Computer Vision (ECCV) . Rodriguez, D., Cogswell, C., Koo, S., and Behnke, S.",
        "ref_ids": [
          "468"
        ]
      },
      "6D Pose Estimation for Precision Assembly": {
        "authors": [],
        "url": "https://researchportal.hw.ac.uk/files/55099980/6D_pose_estimation_for_precision_assembly_IPAS_cor_ver_may_2022.pdf",
        "ref_texts": "[14] S. Peng, Y. Liu, Q. Huang, H. Bao, and X. Zhou, \u201cPVNet: Pixe lwise voting network for 6DoF pose estimation,\u201d IEEE Trans. Pattern Anal. Mach. Intell. ",
        "ref_ids": [
          "14"
        ]
      },
      "Hybrid architectures for object pose and velocity tracking at the intersection of Kalman filtering and machine learning": {
        "authors": [],
        "url": "https://tesidottorato.depositolegale.it/bitstream/20.500.14242/107354/1/phdunige_4620387.pdf",
        "ref_texts": "(2019). PyTorch: An Imperative Style, High-Performance Deep Learning Library. In Wallach, H., Larochelle, H., Beygelzimer, A., d 'Alch\u00e9-Buc, F., Fox, E., and Garnett, R., editors, Advances in Neural Information Processing Systems 32 , pages 8024\u015b8035. Curran Associates, Inc. Pattacini, U., Nori, F., Natale, L., Metta, G., and Sandini, G. (2010). An Experimental Evaluation of a Novel Minimum-Jerk Cartesian Controller for Humanoid Robots. In 2010 IEEE/RSJ International Conference on Intelligent Robots and Systems , pages 1668\u015b1674. Pauwels, K., Rubio, L., and Ros, E. (2016). Real-Time Pose Detection and Tracking of Hundreds of Objects. IEEE Transactions on Circuits and Systems for Video Technology , 26(12):2200\u015b2214. Peng, S., Liu, Y., Huang, Q., Zhou, X., and Bao, H. (2019). PVNet: Pixel-Wise Voting Network for 6DoF Pose Estimation. In 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) , pages 4556\u015b4565. IEEE. Periyasamy, A. S., Schwarz, M., and Behnke, S. (2019). Re\u0151ning 6D Object Pose Predictions using Abstract Render-and-Compare. In 2019 IEEE-RAS 19th International Conference on Humanoid Robots (Humanoids) , pages 739\u015b746. IEEE. Piga, N. A., Bottarel, F., Fantacci, C., Vezzani, G., Pattacini, U., and Natale, L."
      },
      "Weakly Supervised Learning of Keypoints for 6D Object Pose Estimation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2203.03498",
        "ref_texts": "[26] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 4561\u20134570, 2019. 1, 2, 4, 6, 7, 8",
        "ref_ids": [
          "26"
        ]
      },
      "\u4e09\u7ef4\u6a21\u677f\u8ddf\u8e2a\u7684\u57fa\u51c6\u5408\u6210\u6570\u636e\u96c6\u6784\u5efa\u53ca\u7b97\u6cd5\u8bc4\u4f30": {
        "authors": [],
        "url": "http://cjc.ict.ac.cn/online/bfpub/hx-20211122162521.pdf",
        "ref_texts": "[19] Sida P, Yuan L, Qixing H, et al. PVNet: Pixel -Wise V oting Network for 6DoF Pose Estimation//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. Long Beach , USA , 2019: ",
        "ref_ids": [
          "19"
        ]
      },
      "Satellite Pose Estimation via Only a Single Spatial Circle": {
        "authors": [
          "Wei Zhang",
          "Pingguo Xiao",
          "Junlin Li"
        ],
        "url": "https://www.mdpi.com/2078-2489/13/2/95/pdf",
        "ref_texts": "29. Peng, S.; Liu, Y.; Huang, Q.; Zhou, X.; Bao, H. Pvnet: Pixel-Wise Voting Network for 6dof Pose Estimation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, Long Beach, CA, USA, 15\u201320 June 2019; pp. 4561\u20134570.",
        "ref_ids": [
          "29"
        ]
      },
      "Augmented Reality Pilot Assistance System for Helicopter Shipboard Operations": {
        "authors": [],
        "url": "https://mediatum.ub.tum.de/doc/1655458/document.pdf",
        "ref_texts": "[114] Peng, S., Liu, Y., Huang, Q., Bao, H., Zhou, X. (2018). PVNet: Pixel -wise Voting Network for 6DoF Pose Estimation. Retrieved from https://arxiv.org/pdf/1812.11788 ",
        "ref_ids": [
          "114"
        ]
      },
      "MULTI LEVEL REFINEMENT ENRICHED FEATURE PYRAMID NETWORK FOR SCALE AND CLASS IMBALANCE IN OBJECT DETECTION": {
        "authors": [],
        "url": "http://eprints.utm.my/101479/1/LubnaAzizPSC2022.pdf.pdf",
        "ref_texts": "185 Pang, Y., Wang, T., Anwer, R. M., Khan, F. S., and Shao, L. (2019a). Efficie nt featurized image pyramid network for single shot detector. Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, Pang, Y., Wang, T., Anwer, R. M., Khan, F. S., and Shao, L. (2019b). Efficient featurized image pyramid networ k for single shot detector. Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Peng, S., Liu, Y., Huang, Q., Zhou, X., and Bao, H. (2019). Pvnet: Pixel -wise voting network for 6dof pose estimation. Proceedings of the IEEE/CVF C onference on Computer Vision and Pattern Recognition, Picron, C., and Tuytelaars, T. (2021). Trident Pyramid Networks: The importance of processing at the feature pyramid level for better object detection. arXiv preprint arXiv:2110.04004 . Pitts, W., and McCulloch, W. S. (1947). How we know universals the perception of auditory and visual forms. The Bulletin of mathematical biophysics , 9(3), "
      },
      "Simultaneous Object Detection and Pose Estimation under Domain Shift": {
        "authors": [
          "Stefan Thalhammer"
        ],
        "url": "https://scholar.archive.org/work/frqksitta5brpfxfjmkw6rgeqe/access/wayback/https://repositum.tuwien.at/bitstream/20.500.12708/120374/1/Thalhammer%20Stefan%20-%202022%20-%20Simultaneous%20Object%20Detection%20and%20Pose%20Estimation...pdf",
        "ref_texts": "[22] S. Peng,Y. Liu, Q.Hua ng,X. Zhou, and H. Bao,\u201cPVNe t:Pixel-wisevoting networkfor6DoFposeestima tion,\u201d in Proceedings of the IEEEConfer enc eon Compu ter Vision and Patter nRecognition ,2019,pp. 4561\u20134570(cit.onpp .2,6, 14,18,19,31,38,40).",
        "ref_ids": [
          "22"
        ]
      },
      "\u57fa\u4e8e\u865a\u62df\u76f8\u673a\u7684\u4f4d\u59ff\u4f30\u8ba1\u7814\u7a76\u8fdb\u5c55": {
        "authors": [],
        "url": "https://www.researching.cn/ArticlePdf/m00002/2022/59/14/1415002.pdf",
        "ref_texts": "[140]PengSD,ZhouXW,LiuY,etal.PVNet:pixel -wise votingnetworkfor 6DoFobjectposeestimation [J].IEEE TransactionsonPatternAnalysisandMachineIntelligence , 2022,44(6):3212 -3223.",
        "ref_ids": [
          "140",
          "J"
        ]
      },
      "Texture Optimization for 6 DoF Pose Estimation": {
        "authors": [],
        "url": "https://www.research-collection.ethz.ch/bitstream/handle/20.500.11850/583168/1/Masters_Thesis_Jiale_Chen_20-961-504_V2.pdf",
        "ref_texts": "[69] Sida Peng et al. \u201cPVNet: Pixel-wise Voting Network for 6DoF Pose Estimation\u201d. In: CVPR .",
        "ref_ids": [
          "69"
        ]
      },
      "Advances in biplanar X-ray imaging: calibration and 2D/3D registration": {
        "authors": [],
        "url": "https://repository.uantwerpen.be/docstore/d:irua:15079",
        "ref_texts": "[41]S. Peng, Y. Liu, Q. Huang, H. Bao, and X. Zhou, \u201cPVNet: Pixel-wise voting network for 6DoF pose estimation,\u201d in 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) , (Long Beach, CA, USA, USA), June 2019.",
        "ref_ids": [
          "41"
        ]
      },
      "An intelligent robotic vision system with environment perception": {
        "authors": [],
        "url": "https://etheses.whiterose.ac.uk/31259/1/Yixiang_s_PhD_thesis_final.pdf",
        "ref_texts": "[23] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In Proceedings of the 131 IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 4561\u20134570, 2019.",
        "ref_ids": [
          "23"
        ]
      },
      "DenseTransformer: Direct 6D OPE using self-attention on dense representations": {
        "authors": [],
        "url": "https://fse.studenttheses.ub.rug.nl/28988/1/mAI_2022_DesaiN.pdf",
        "ref_texts": "[33] S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao, \u201cPvnet: Pixel-wise voting network for 6dof pose estimation,\u201d in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pp. 4561\u20134570, 2019.",
        "ref_ids": [
          "33"
        ]
      },
      "Recovering 6D pose of rigid object from point cloud at the level of instance and category": {
        "authors": [],
        "url": "https://etheses.bham.ac.uk/id/eprint/12424/7/Chen2022PhD.pdf",
        "ref_texts": "[60] Sida Peng, Yuan Liu, Qixing Huang, Hujun Bao, and Xiaowei Zhou. Pvnet: Pixel-wise voting network for 6dof pose estimation. arXiv preprint arXiv:1812.11788 , 2018.",
        "ref_ids": [
          "60"
        ]
      },
      "QUANTIZED NEURAL NETWORKS FOR 6D POSE ESTIMATION": {
        "authors": [],
        "url": "https://robertflame.github.io/Homepage/assets/docs/theses/Master%20Thesis.pdf",
        "ref_texts": "[18] S. Peng, Y . Liu, Q. Huang, X. Zhou and H. Bao, \u2018Pvnet: Pixel-wise voting network for 6dof pose estimation,\u2019 in CVPR , 2019.",
        "ref_ids": [
          "18"
        ]
      },
      "Perception Systems for Robust Autonomous Navigation in Natural Environments": {
        "authors": [],
        "url": "https://mountainscholar.org/bitstream/10217/235264/1/Trabelsi_colostate_0053A_17016.pdf",
        "ref_texts": "[32] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. PVNet: Pixel-wise V oting Network for 6DoF Pose Estimation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) , pages 4561\u20134570, 2019.",
        "ref_ids": [
          "32"
        ]
      },
      "An Exploration of the Virtual Digital Twin Capture for Spatial Tasks and its Applications": {
        "authors": [],
        "url": "https://hammer.purdue.edu/articles/thesis/An_Exploration_of_the_Virtual_Digital_Twin_Capture_for_Spatial_Tasks_and_its_Applications/19666338/1/files/34929147.pdf",
        "ref_texts": "[4]S. Peng, Y. Liu, Q. Huang, X. Zhou, and H. Bao, \u201cPvnet: Pixel-wise voting network for 6dof pose estimation,\u201d in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , 2019, pp. 4561\u20134570.",
        "ref_ids": [
          "4"
        ]
      },
      "Motion Recognition of Workers using Skeleton and LSTM": {
        "authors": [],
        "url": "https://koreascience.kr/article/JAKO202214437490566.pdf",
        "ref_texts": "[4]S.Peng,Y.Liu,Q.Huang,X.Zhou,andH. Bao,\u201cPVNet:Pixel-WiseVotingNetworkfor 6-DOFPoseEstimation,\u201dIEEEConference onComputerVisionandPatternRecognition, pp.4561-4570,2019.",
        "ref_ids": [
          "4"
        ]
      },
      "Direct pose estimation from RGB images using 3D objects": {
        "authors": [],
        "url": "https://dergipark.org.tr/en/download/article-file/2402755",
        "ref_texts": ""
      },
      "Optimization of visual SLAM by semantic analysis of the environment": {
        "authors": [],
        "url": "https://theses.hal.science/tel-03967982/document",
        "ref_texts": "2018. Peng, J., Shi, X., Wu, J., & Xiong, Z., (2019), An object-oriented semantic SLAM system towards dynamic environments for mobile manipulation, 2019 IEEE/ASME International Conference on Advanced Intelligent Mechatronics (AIM) , 199\u2013204. Peng, S., Liu, Y., Huang, Q., Zhou, X., & Bao, H., (2019), PVNet: Pixel-wise Voting Network for 6DoF pose estimation, IEEE Conf. on Computer Vision and Pattern Recognition , 4561\u20134570. Pham, Q.-H., Hua, B.-S., Nguyen, T., & Yeung, S.-K., (2019), Real-time progressive 3d semantic segmentation for indoor scenes, 2019 IEEE Winter Conference on Applications of Computer Vision (WACV) , 1089\u20131098. Pham, Q.-H., Nguyen, T., Hua, B.-S., Roig, G., & Yeung, S.-K., (2019), Jsis3d: joint semantic-instance segmentation of 3d point clouds with multi-task pointwise networks and multi-value conditional random fields, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , 8827\u20138836. Pizer, S. M., Amburn, E. P., Austin, J. D., Cromartie, R., Geselowitz, A., Greer, T., ter HaarRomeny,B.,Zimmerman,J.B.,&Zuiderveld,K.,(1987),Adaptivehistogram equalization and its variations, Computer vision, graphics, and image processing , 39(3), 355\u2013368. Pizer, S. M., Johnston, R. E., Ericksen, J. P., Yankaskas, B. C., & Muller, K. E., (1990), Contrast-limited adaptive histogram equalization: speed and effectiveness, [1990]",
        "ref_ids": [
          "2018"
        ]
      },
      "PoET: Pose Estimation Transformer for Single-View, Multi-Object 6D Pose Estimation\u2013Supplementary Material\u2013": {
        "authors": [],
        "url": "https://proceedings.mlr.press/v205/jantos23a/jantos23a-supp.pdf",
        "ref_texts": "[20] S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 4561\u20134570, 2019.",
        "ref_ids": [
          "20"
        ]
      },
      "Vote from the Center: 6 DoF Pose Estimation in RGB-D Images by Radial Keypoint Voting (Supplementary Material)": {
        "authors": [],
        "url": "https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136700331-supp.pdf",
        "ref_texts": "[S.17] Peng, S., Liu, Y., Huang, Q., Zhou, X., Bao, H.: Pvnet: Pixel-wise voting network for 6dof pose estimation. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 4561\u20134570",
        "ref_ids": [
          "S\\.17"
        ]
      },
      "Supplementary Material: Gen6D: Generalizable Model-Free 6-DoF Object Pose Estimation from RGB Images": {
        "authors": [],
        "url": "https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136920297-supp.pdf",
        "ref_texts": "5. Peng, S., Liu, Y., Huang, Q., Zhou, X., Bao, H.: Pvnet: Pixel-wise voting network for 6-dof pose estimation. In: CVPR (2019)",
        "ref_ids": [
          "5"
        ]
      },
      "Monocular Markerless 6D Pose Estimation of ANYmal": {
        "authors": [],
        "url": "https://tenhearts.github.io/assets/pdf/plr_report.pdf",
        "ref_texts": "[14] S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 4561\u20134570, 2019.",
        "ref_ids": [
          "14"
        ]
      },
      "Supplementary Material for EPro-PnP: Generalized End-to-End Probabilistic Perspective-n-Points for Monocular Object Pose Estimation": {
        "authors": [],
        "url": "http://openaccess.thecvf.com/content/CVPR2022/supplemental/Chen_EPro-PnP_Generalized_End-to-End_CVPR_2022_supplemental.pdf",
        "ref_texts": "[13] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In CVPR , 2019. 5",
        "ref_ids": [
          "13"
        ]
      },
      "A Multi-view Pixel-wise Voting Network for 6DoF Pose Estimation": {
        "authors": [],
        "url": "https://thesis.unipd.it/bitstream/20.500.12608/31496/1/tesi_3d_pose_estimation_pdfA.pdf",
        "ref_texts": ""
      },
      "RNNPose: Recurrent 6-DoF Object Pose Refinement with Robust Correspondence Field Estimation and Pose Optimization": {
        "authors": [],
        "url": "https://decayale.github.io/publication/rnnpose/paper.pdf",
        "ref_texts": "[34] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. PVNet: Pixel-wise voting network for 6DoF pose estimation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 4561\u2013",
        "ref_ids": [
          "34"
        ]
      },
      "D\u00e9tection 3D pour la r\u00e9alit\u00e9 mixte en maintenance industrielle": {
        "authors": [],
        "url": "https://theses.hal.science/tel-04089831/document",
        "ref_texts": "[86] Sida Peng et al. \u0013 PVNet : Pixel-wise v oting net w ork for 6DoF p ose estimation \u0014. In : Computer Vision and Pattern R e c o gnition (CVPR) . Long Beac h, Californie, \u00c9tatsUnis, juin 2019. url : https : / / openaccess . thecvf . com / content _ CVPR _ 2019 / html / Peng _ PVNet _ Pixel Wise _ Voting _ Network _ for _ 6DoF _ Pose _ Estimation _ CVPR_2019_paper.html.",
        "ref_ids": [
          "86"
        ]
      },
      "A Smart Workcell for Automatic Pick and Sorting for Logistics": {
        "authors": [],
        "url": "https://www.research.unipd.it/bitstream/11577/3471171/1/A_Smart_Workcell_for_Automatic_Pick_and_Sorting_for_Logistics.pdf",
        "ref_texts": "[4] S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao, Pvnet: \u201cPixelwise voting network for 6DOF pose estimation,\u201d in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2019, pp. 4561\u20134570",
        "ref_ids": [
          "4"
        ]
      },
      "Direct pose estimation from RGB images using 3D objects 3 Boyutlu nesneleri kullanarak imgelerden poz kestirimi": {
        "authors": [],
        "url": "https://jag.journalagent.com/z4/download_fulltext.asp?pdir=pajes&plng=tur&un=PAJES-08566",
        "ref_texts": ""
      },
      "Supplementary Material for OnePose: One-Shot Object Pose Estimation without CAD Models": {
        "authors": [],
        "url": "http://www.cad.zju.edu.cn/home/gfzhang/papers/OnePose/onepose_supp.pdf",
        "ref_texts": "[8] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In CVPR , 2019. 3",
        "ref_ids": [
          "8"
        ]
      },
      "\u9762\u5411\u7a7a\u95f4\u5e94\u7528\u7684\u89c6\u89c9\u4f4d\u59ff\u4f30\u8ba1\u6280\u672f\u7efc\u8ff0": {
        "authors": [],
        "url": "https://scholar.archive.org/work/3h5ntyfj45acbfpwywjreyxuke/access/wayback/https://ope.lightpublishing.cn/rc-pub/front/front-article/download?siteId=65&id=31623419&attachType=lowqualitypdf&token=&language=zh",
        "ref_texts": "[89]PENG S D ,LIU Y,HUANG Q X ,et al. PVNet:pixel -wise voting network for 6DoF pose estimation [C].2019IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR).LongBeach ,CA,USA.IEEE,2019:",
        "ref_ids": [
          "89",
          "C"
        ]
      },
      "PVANet: \u9488\u5bf9\u5f31\u7eb9\u7406\u5de5\u4e1a\u96f6\u4ef6\u7684\u50cf\u7d20\u7ea7 6DoF \u4f4d\u59ff\u4f30\u8ba1\u65b9\u6cd5": {
        "authors": [],
        "url": "https://cs.hit.edu.cn/_upload/article/files/8a/60/de3150c846d09606e0538fc4f699/1e2b719a-10e4-4bd1-824a-93eeda770cee.pdf",
        "ref_texts": "wisevotingnetworkfor6DoFposeestimation[C]//2019IEEE/"
      },
      "Vision-based robotic grasping from object localization, object pose estimation to grasp estimation for parallel grippers: a review": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1905.06658",
        "ref_texts": "[Peng et al. , 2019 ]Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 4561\u20134570, 2019.",
        "ref_ids": [
          "Peng et al\\. , 2019 "
        ]
      },
      "Gdr-net: Geometry-guided direct regression network for monocular 6d object pose estimation": {
        "authors": [
          "Gu Wang",
          "Fabian Manhardt",
          "Federico Tombari",
          "Xiangyang Ji"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wang_GDR-Net_Geometry-Guided_Direct_Regression_Network_for_Monocular_6D_Object_Pose_CVPR_2021_paper.pdf",
        "ref_texts": "[40] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. PVNet: Pixel-wise V oting Network for 6DoF Pose Estimation. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , pages 4561\u20134570, 2019. 2,5, 7,8",
        "ref_ids": [
          "40"
        ]
      },
      "Ffb6d: A full flow bidirectional fusion network for 6d pose estimation": {
        "authors": [
          "Yisheng He",
          "Haibin Huang",
          "Haoqiang Fan",
          "Qifeng Chen",
          "Jian Sun"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2021/papers/He_FFB6D_A_Full_Flow_Bidirectional_Fusion_Network_for_6D_Pose_CVPR_2021_paper.pdf",
        "ref_texts": "[46] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 4561\u20134570, 2019. 1, 2,5,7",
        "ref_ids": [
          "46"
        ]
      },
      "Pointdsc: Robust point cloud registration using deep spatial consistency": {
        "authors": [
          "Xuyang Bai",
          "Zixin Luo",
          "Lei Zhou",
          "Hongkai Chen",
          "Lei Li",
          "Zeyu Hu",
          "Hongbo Fu",
          "Lan Tai"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2021/papers/Bai_PointDSC_Robust_Point_Cloud_Registration_Using_Deep_Spatial_Consistency_CVPR_2021_paper.pdf",
        "ref_texts": ""
      },
      "DexYCB: A benchmark for capturing hand grasping of objects": {
        "authors": [
          "Wei Chao",
          "Wei Yang",
          "Yu Xiang",
          "Pavlo Molchanov",
          "Ankur Handa",
          "Jonathan Tremblay",
          "Yashraj S. Narang",
          "Karl Van",
          "Umar Iqbal",
          "Stan Birchfield",
          "Jan Kautz",
          "Dieter Fox"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2021/papers/Chao_DexYCB_A_Benchmark_for_Capturing_Hand_Grasping_of_Objects_CVPR_2021_paper.pdf",
        "ref_texts": "[27] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. PVNet: Pixel-wise voting network for 6DoF pose estimation. In CVPR , 2019. 1",
        "ref_ids": [
          "27"
        ]
      },
      "So-pose: Exploiting self-occlusion for direct 6d pose estimation": {
        "authors": [
          "Yan Di",
          "Fabian Manhardt",
          "Gu Wang",
          "Xiangyang Ji",
          "Nassir Navab",
          "Federico Tombari"
        ],
        "url": "https://openaccess.thecvf.com/content/ICCV2021/papers/Di_SO-Pose_Exploiting_Self-Occlusion_for_Direct_6D_Pose_Estimation_ICCV_2021_paper.pdf",
        "ref_texts": "[28] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixel-wise voting network for 6dof poseestimation. In CVPR , 2019. 2,6,7",
        "ref_ids": [
          "28"
        ]
      },
      "3d-future: 3d furniture shape with texture": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2009.09633",
        "ref_texts": "(2020) Latentfusion: End-to-end difierentiable reconstruction and rendering for unseen object pose estimation. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp 10710{10719 Peng S, Liu Y, Huang Q, Zhou X, Bao H (2019) Pvnet: Pixel-wise voting network for 6dof pose estimation. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp 4561{4570 Qi CR, Su H, Mo K, Guibas LJ (2017a) Pointnet: Deep learning on point sets for 3d classiffcation and segmentation. In: Proceedings of the IEEE conference on computer vision and pattern recognition, pp 652{660 Qi CR, Yi L, Su H, Guibas LJ (2017b) Pointnet++: Deep hierarchical feature learning on point sets in a metric space. In: Advances in neural information processing systems, pp 5099{5108 Rad M, Lepetit V (2017) Bb8: A scalable, accurate, robust to partial occlusion method for predicting the 3d poses of challenging objects without using depth. In: Proceedings of the IEEE International Conference on Computer Vision, pp 3828{3836 Raj A, Ham C, Barnes C, Kim V, Lu J, Hays J"
      },
      "Fs-net: Fast shape-based network for category-level 6d object pose estimation with decoupled rotation mechanism": {
        "authors": [
          "Wei Chen",
          "Xi Jia",
          "Hyung Jin",
          "Jinming Duan",
          "Linlin Shen",
          "Ales Leonardis"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2021/papers/Chen_FS-Net_Fast_Shape-Based_Network_for_Category-Level_6D_Object_Pose_Estimation_CVPR_2021_paper.pdf",
        "ref_texts": "[23] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. PVNet: Pixel-wise V oting Network for 6DoF Pose Estimation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 4561\u2013",
        "ref_ids": [
          "23"
        ]
      },
      "Sgpa: Structure-guided prior adaptation for category-level 6d object pose estimation": {
        "authors": [
          "Kai Chen",
          "Qi Dou"
        ],
        "url": "https://openaccess.thecvf.com/content/ICCV2021/papers/Chen_SGPA_Structure-Guided_Prior_Adaptation_for_Category-Level_6D_Object_Pose_Estimation_ICCV_2021_paper.pdf",
        "ref_texts": "[20] Sida Peng, Y uan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixel-wise voting network for 6dof poseestimation. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , pages 4561\u20134570, 2019. 1,2",
        "ref_ids": [
          "20"
        ]
      },
      "Semi-supervised 3d hand-object poses estimation with interactions in time": {
        "authors": [
          "Shaowei Liu",
          "Hanwen Jiang",
          "Jiarui Xu",
          "Sifei Liu",
          "Xiaolong Wang"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2021/papers/Liu_Semi-Supervised_3D_Hand-Object_Poses_Estimation_With_Interactions_in_Time_CVPR_2021_paper.pdf",
        "ref_texts": "[43] Sida Peng, Yuan Liu, Qi-Xing Huang, Hujun Bao, and Xiaowei Zhou. Pvnet: Pixel-wise voting network for 6dof pose estimation. CVPR , pages 4556\u20134565, 2019.",
        "ref_ids": [
          "43"
        ]
      },
      "H2o: Two hands manipulating objects for first person interaction recognition": {
        "authors": [
          "Taein Kwon",
          "Bugra Tekin",
          "Jan Stuhmer",
          "Federica Bogo",
          "Marc Pollefeys"
        ],
        "url": "http://openaccess.thecvf.com/content/ICCV2021/papers/Kwon_H2O_Two_Hands_Manipulating_Objects_for_First_Person_Interaction_Recognition_ICCV_2021_paper.pdf",
        "ref_texts": "[59] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In CVPR , 2019. 3",
        "ref_ids": [
          "59"
        ]
      },
      "Geometry-based distance decomposition for monocular 3d object detection": {
        "authors": [
          "Xuepeng Shi",
          "Qi Ye",
          "Xiaozhi Chen",
          "Chuangrong Chen",
          "Zhixiang Chen",
          "Kyun Kim"
        ],
        "url": "https://openaccess.thecvf.com/content/ICCV2021/papers/Shi_Geometry-Based_Distance_Decomposition_for_Monocular_3D_Object_Detection_ICCV_2021_paper.pdf",
        "ref_texts": "[35] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In CVPR , 2019.",
        "ref_ids": [
          "35"
        ]
      },
      "Dualposenet: Category-level 6d object pose and size estimation using dual pose network with refined learning of pose consistency": {
        "authors": [
          "Jiehong Lin",
          "Zewei Wei",
          "Zhihao Li",
          "Songcen Xu",
          "Kui Jia",
          "Yuanqing Li"
        ],
        "url": "http://openaccess.thecvf.com/content/ICCV2021/papers/Lin_DualPoseNet_Category-Level_6D_Object_Pose_and_Size_Estimation_Using_Dual_ICCV_2021_paper.pdf",
        "ref_texts": "[20] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In CVPR , 2019. 1, 2",
        "ref_ids": [
          "20"
        ]
      },
      "Rgb matters: Learning 7-dof grasp poses on monocular rgbd images": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2103.02184",
        "ref_texts": "[31] Sida Peng et al. \u201cPvnet: Pixel-wise voting network for 6dof pose estimation\u201d. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition . 2019, pp. 4561\u20134570.",
        "ref_ids": [
          "31"
        ]
      },
      "Repose: Fast 6d object pose refinement via deep texture rendering": {
        "authors": [
          "Shun Iwase",
          "Xingyu Liu",
          "Rawal Khirodkar",
          "Rio Yokota",
          "Kris M. Kitani"
        ],
        "url": "https://openaccess.thecvf.com/content/ICCV2021/papers/Iwase_RePOSE_Fast_6D_Object_Pose_Refinement_via_Deep_Texture_Rendering_ICCV_2021_paper.pdf",
        "ref_texts": "[27] Sida Peng, Xiaowei Liu, and Hujun Bao. Pvnet: Pixelwise voting network for 6dof pose estimation. In CVPR , 2019. 2, 3, 5, 6, 7, 8",
        "ref_ids": [
          "27"
        ]
      },
      "A vector-based representation to enhance head pose estimation": {
        "authors": [
          "Zongcheng Chu",
          "Dongfang Liu",
          "Yingjie Chen",
          "Zhiwen Cao"
        ],
        "url": "http://openaccess.thecvf.com/content/WACV2021/papers/Chu_A_Vector-Based_Representation_to_Enhance_Head_Pose_Estimation_WACV_2021_paper.pdf",
        "ref_texts": "[20] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 4561\u20134570, 2019.",
        "ref_ids": [
          "20"
        ]
      },
      "Category-level 6d object pose estimation via cascaded relation and recurrent reconstruction networks": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2108.08755",
        "ref_texts": "[2] S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao, \u201cPvnet: Pixel-wise voting network for 6dof pose estimation,\u201d in CVPR , 2019, pp. 4561\u2013",
        "ref_ids": [
          "2"
        ]
      },
      "Wide-depth-range 6d object pose estimation in space": {
        "authors": [
          "Yinlin Hu",
          "Sebastien Speierer",
          "Wenzel Jakob",
          "Pascal Fua",
          "Mathieu Salzmann"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2021/papers/Hu_Wide-Depth-Range_6D_Object_Pose_Estimation_in_Space_CVPR_2021_paper.pdf",
        "ref_texts": "[31] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. PVNet: Pixel-Wise V oting Network for 6DoF Pose Estimation. In Conference on Computer Vision and Pattern Recognition , 2019.",
        "ref_ids": [
          "31"
        ]
      },
      "Occlusion-aware self-supervised monocular 6D object pose estimation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2203.10339",
        "ref_texts": "[14] S. Peng, Y. Liu, Q. Huang, X. Zhou, and H. Bao, \u201cPvnet: Pixel-wise voting network for 6dof pose estimation,\u201d in Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit. , 2019, pp. 4561\u20134570.",
        "ref_ids": [
          "14"
        ]
      },
      "Survey on localization systems and algorithms for unmanned systems": {
        "authors": [],
        "url": "https://dr.ntu.edu.sg/bitstream/10356/146492/2/Yuan_Shenghai_Survey_revision.pdf",
        "ref_texts": "[321] S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao. \u201cPvnet: Pixel-wise voting network for 6dof pose estimation.\u201d In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 4561-4570.",
        "ref_ids": [
          "321"
        ]
      },
      "Stereobj-1m: Large-scale stereo image dataset for 6d object pose estimation": {
        "authors": [
          "Xingyu Liu",
          "Shun Iwase",
          "Kris M. Kitani"
        ],
        "url": "http://openaccess.thecvf.com/content/ICCV2021/papers/Liu_StereOBJ-1M_Large-Scale_Stereo_Image_Dataset_for_6D_Object_Pose_Estimation_ICCV_2021_paper.pdf",
        "ref_texts": "[27] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In CVPR , 2019. 1, 2, 6, 7, 8",
        "ref_ids": [
          "27"
        ]
      },
      "Dpodv2: Dense correspondence-based 6 dof pose estimation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2207.02805",
        "ref_texts": "[34] S. Peng, Y. Liu, Q. Huang, X. Zhou, and H. Bao, \u201cPvnet: Pixel-wise voting network for 6dof pose estimation,\u201d in CVPR , 2019.",
        "ref_ids": [
          "34"
        ]
      },
      "Vs-net: Voting with segmentation for visual localization": {
        "authors": [
          "Zhaoyang Huang",
          "Han Zhou",
          "Yijin Li",
          "Bangbang Yang",
          "Yan Xu",
          "Xiaowei Zhou",
          "Hujun Bao",
          "Guofeng Zhang",
          "Hongsheng Li"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2021/papers/Huang_VS-Net_Voting_With_Segmentation_for_Visual_Localization_CVPR_2021_paper.pdf",
        "ref_texts": "[38] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 4561\u20134570, 2019.",
        "ref_ids": [
          "38"
        ]
      },
      "Keypoint-graph-driven learning framework for object pose estimation": {
        "authors": [
          "Shaobo Zhang",
          "Wanqing Zhao",
          "Ziyu Guan",
          "Xianlin Peng",
          "Jinye Peng"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2021/papers/Zhang_Keypoint-Graph-Driven_Learning_Framework_for_Object_Pose_Estimation_CVPR_2021_paper.pdf",
        "ref_texts": "[26] S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In CVPR , 2019. 1,2,5,6,7,8",
        "ref_ids": [
          "26"
        ]
      },
      "Pr-gcn: A deep graph convolutional network with point refinement for 6d pose estimation": {
        "authors": [
          "Guangyuan Zhou",
          "Huiqun Wang",
          "Jiaxin Chen",
          "Di Huang"
        ],
        "url": "https://openaccess.thecvf.com/content/ICCV2021/papers/Zhou_PR-GCN_A_Deep_Graph_Convolutional_Network_With_Point_Refinement_for_ICCV_2021_paper.pdf",
        "ref_texts": "[29] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In IEEE Conference on Computer Vision and Pattern Recognition , pages 4561\u20134570, 2019.",
        "ref_ids": [
          "29"
        ]
      },
      "Hpnet: Deep primitive segmentation using hybrid representations": {
        "authors": [
          "Siming Yan",
          "Zhenpei Yang",
          "Chongyang Ma",
          "Haibin Huang",
          "Etienne Vouga",
          "Qixing Huang"
        ],
        "url": "http://openaccess.thecvf.com/content/ICCV2021/papers/Yan_HPNet_Deep_Primitive_Segmentation_Using_Hybrid_Representations_ICCV_2021_paper.pdf",
        "ref_texts": "[18] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2019, Long Beach, CA, USA, June 16-20, 2019 , pages 4561\u20134570. Computer Vision Foundation / IEEE, 2019. 3",
        "ref_ids": [
          "18"
        ]
      },
      "Single-view robot pose and joint angle estimation via render & compare": {
        "authors": [
          "Yann Labbe",
          "Justin Carpentier",
          "Mathieu Aubry",
          "Josef Sivic"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2021/papers/Labbe_Single-View_Robot_Pose_and_Joint_Angle_Estimation_via_Render__CVPR_2021_paper.pdf",
        "ref_texts": "[44] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In CVPR , 2019. 2",
        "ref_ids": [
          "44"
        ]
      },
      "Dsc-posenet: Learning 6dof object pose estimation via dual-scale consistency": {
        "authors": [
          "Zongxin Yang",
          "Xin Yu",
          "Yi Yang"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2021/papers/Yang_DSC-PoseNet_Learning_6DoF_Object_Pose_Estimation_via_Dual-Scale_Consistency_CVPR_2021_paper.pdf",
        "ref_texts": "[29] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In CVPR , pages 4561\u20134570, 2019. 2, 4, 7",
        "ref_ids": [
          "29"
        ]
      },
      "Cloudaae: Learning 6d object pose regression with on-line data synthesis on point clouds": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2103.01977",
        "ref_texts": "[30] S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao, \u201cPVNet: Pixel-wise voting network for 6dof pose estimation,\u201d in CVPR , 2019.",
        "ref_ids": [
          "30"
        ]
      },
      "Category-level metric scale object shape and pose estimation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2109.00326",
        "ref_texts": "[19] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 4561\u20134570, 2019.",
        "ref_ids": [
          "19"
        ]
      },
      "Nemo: Neural mesh models of contrastive features for robust 3d pose estimation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2101.12378",
        "ref_texts": "6-dof object pose from semantic keypoints. In 2017 IEEE international conference on robotics and automation (ICRA) , pp. 2011\u20132018. IEEE, 2017. 2, 3 Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pp. 4561\u20134570, 2019. 3 Nikhila Ravi, Jeremy Reizenstein, David Novotny, Taylor Gordon, Wan-Yen Lo, Justin Johnson, and Georgia Gkioxari. Accelerating 3d deep learning with pytorch3d. arXiv:2007.08501 , 2020."
      },
      "Stablepose: Learning 6d object poses from geometrically stable patches": {
        "authors": [
          "Yifei Shi",
          "Junwen Huang",
          "Xin Xu",
          "Yifan Zhang",
          "Kai Xu"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2021/papers/Shi_StablePose_Learning_6D_Object_Poses_From_Geometrically_Stable_Patches_CVPR_2021_paper.pdf",
        "ref_texts": "[32] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 4561\u20134570, 2019. 2",
        "ref_ids": [
          "32"
        ]
      },
      "A survey on deep learning based methods and datasets for monocular 3D object detection": {
        "authors": [],
        "url": "https://www.mdpi.com/2079-9292/10/4/517/pdf",
        "ref_texts": "72. Peng, S.; Liu, Y.; Huang, Q.; Zhou, X.; Bao, H. PVNet: Pixel-wise Voting Network for 6DOF Pose Estimation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Long Beach, CA, USA, 16\u201320 June 2019; pp. 4561\u20134570.",
        "ref_ids": [
          "72"
        ]
      },
      "Monocinis: Camera independent monocular 3d object detection using instance segmentation": {
        "authors": [
          "Jonas Heylen",
          "Mark De",
          "Bruno Dawagne",
          "Marc Proesmans",
          "Luc Van",
          "Wim Abbeloos",
          "Hazem Abdelkawy",
          "Daniel Olmeda"
        ],
        "url": "https://openaccess.thecvf.com/content/ICCV2021W/3DODI/papers/Heylen_MonoCInIS_Camera_Independent_Monocular_3D_Object_Detection_Using_Instance_Segmentation_ICCVW_2021_paper.pdf",
        "ref_texts": "[65] S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao, \u201cPvnet: Pixel-wise voting network for 6dof pose estimation,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pp. 4561\u20134570, 2019.[66] Y . Hu, J. Hugonot, P. Fua, and M. Salzmann, \u201cSegmentationdriven 6d object pose estimation,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pp. 3385\u20133394, 2019.",
        "ref_ids": [
          "65",
          "66"
        ]
      },
      "Sparse steerable convolutions: An efficient learning of se (3)-equivariant features for estimation and tracking of object poses in 3d space": {
        "authors": [],
        "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/8c1b6fa97c4288a4514365198566c6fa-Paper.pdf",
        "ref_texts": "[17] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 4561\u20134570, 2019.",
        "ref_ids": [
          "17"
        ]
      },
      "Neural free-viewpoint performance rendering under complex human-object interactions": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2108.00362",
        "ref_texts": "[46] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. 2019. PVNet: Pixel-wise Voting Network for 6DoF Pose Estimation. In CVPR .",
        "ref_ids": [
          "46"
        ]
      },
      "Rede: End-to-end object 6d pose robust estimation using differentiable outliers elimination": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2010.12807",
        "ref_texts": "[13] S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao, \u201cPvnet: Pixel-wise voting network for 6dof pose estimation,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , 2019, pp.",
        "ref_ids": [
          "13"
        ]
      },
      "Self-supervised geometric perception": {
        "authors": [
          "Heng Yang",
          "Wei Dong",
          "Luca Carlone",
          "Vladlen Koltun"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2021/papers/Yang_Self-Supervised_Geometric_Perception_CVPR_2021_paper.pdf",
        "ref_texts": "[58] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. PVNet: Pixel-wise voting network for 6dof pose estimation. In IEEE Conf. on Computer Vision and Pattern Recognition (CVPR) , pages 4561\u20134570, 2019. 1,6",
        "ref_ids": [
          "58"
        ]
      },
      "Visual identification of articulated object parts": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2012.00284",
        "ref_texts": "[29] S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao, \u201cPVNet: Pixel-wise V oting Network for 6DoF Pose Estimation,\u201d in Conf. on Computer Vision and Pattern Recognition (CVPR) , 2019.",
        "ref_ids": [
          "29"
        ]
      },
      "T6d-direct: Transformers for multi-object 6d pose direct regression": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2109.10948",
        "ref_texts": "20. Peng, S., Liu, Y., Huang, Q., Zhou, X., Bao, H.: PVNet: Pixel-wise voting network for 6DOF pose estimation. In: CVPR, pp. 4561{4570 (2019)",
        "ref_ids": [
          "20"
        ]
      },
      "DemoGrasp: Few-shot learning for robotic grasping with human demonstration": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2112.02849",
        "ref_texts": "[35] S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao, \u201cPvnet: Pixel-wise voting network for 6dof pose estimation,\u201d in CVPR , 2019.",
        "ref_ids": [
          "35"
        ]
      },
      "Roft: Real-time optical flow-aided 6d object pose and velocity tracking": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2111.03821",
        "ref_texts": "[2]S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao, \u201cPVnet: Pixel-wise voting network for 6DoF pose estimation,\u201d in 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) . IEEE, 2019, pp.",
        "ref_ids": [
          "2"
        ]
      },
      "Towards markerless surgical tool and hand pose estimation": {
        "authors": [
          "Jonas Hein"
        ],
        "url": "https://link.springer.com/content/pdf/10.1007/s11548-021-02369-2.pdf",
        "ref_texts": "26. Peng S, Liu Y , Huang Q, Zhou X, Bao H (2019) Pvnet: pixel-wise voting network for 6dof pose estimation. In: Proceedings of theIEEE conference on computer vision and pattern recognition, pp4561\u20134570",
        "ref_ids": [
          "26"
        ]
      },
      "6D pose estimation with combined deep learning and 3D vision techniques for a fast and accurate object grasping": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2111.06276",
        "ref_texts": ""
      },
      "A pose proposal and refinement network for better 6d object pose estimation": {
        "authors": [
          "Ameni Trabelsi",
          "Mohamed Chaabane",
          "Nathaniel Blanchard",
          "Ross Beveridge"
        ],
        "url": "http://openaccess.thecvf.com/content/WACV2021/papers/Trabelsi_A_Pose_Proposal_and_Refinement_Network_for_Better_6D_Object_WACV_2021_paper.pdf",
        "ref_texts": "[21] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixel-wise voting network for 6DoF pose estimation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 4561\u2013",
        "ref_ids": [
          "21"
        ]
      },
      "Multi-view fusion for multi-level robotic scene understanding": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2103.13539",
        "ref_texts": "[6] S. Peng, Y . Liu, Q. Huang, H. Bao, and X. Zhou, \u201cPVNet: Pixel-wise voting network for 6DoF pose estimation,\u201d in CVPR , 2019.",
        "ref_ids": [
          "6"
        ]
      },
      "3D object tracking with adaptively weighted local bundles": {
        "authors": [],
        "url": "https://jcst.ict.ac.cn/fileup/1000-9000/PDF/2021-3-7-1272.pdf",
        "ref_texts": "[6] Peng S, Liu Y, Huang Q, Zhou X, Bao H. PVNet: Pixel-wise voting network for 6DoF pose estimation. In Proc. the 2019 IEEE Conference on Computer Vision and Pattern Recognition , June 2019, pp.4561-4570. DOI: 10.1109/CVPR.2019.00469.",
        "ref_ids": [
          "6"
        ]
      },
      "Optimal pose and shape estimation for category-level 3d object perception": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2104.08383.pdf?trk=public_post_comment-text",
        "ref_texts": "[57] S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao. PVNet: Pixel-wise V oting Network for 6DoF Pose Estimation. In IEEE Conf. on Computer Vision and Pattern Recognition (CVPR) , pages 4561\u20134570, 2019. 2",
        "ref_ids": [
          "57"
        ]
      },
      "Pyrapose: Feature pyramids for fast and accurate object pose estimation under domain shift": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2010.16117",
        "ref_texts": "[5] S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao, \u201cPVNet: Pixelwise voting network for 6DoF pose estimation,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , 2019, pp. 4561\u20134570.",
        "ref_ids": [
          "5"
        ]
      },
      "Fast uncertainty quantification for deep object pose estimation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2011.07748",
        "ref_texts": "[25] S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao, \u201cPvnet: Pixel-wise voting network for 6dof pose estimation,\u201d in CVPR , 2019.",
        "ref_ids": [
          "25"
        ]
      },
      "Multi-view object pose refinement with differentiable renderer": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2207.02811",
        "ref_texts": "[14] S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao, \u201cPvnet: Pixel-wise voting network for 6dof pose estimation,\u201d in CVPR , 2019.",
        "ref_ids": [
          "14"
        ]
      },
      "Online object searching by a humanoid robot in an unknown environment": {
        "authors": [],
        "url": "https://raw.githubusercontent.com/aescande/website/master/papers/2021_RAL_Tsuru.pdf",
        "ref_texts": "[14] S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao. Pvnet: Pixe lwise voting network for 6dof pose estimation. In IEEE/CVF Conf. on Computer Vision and Pattern Recognition , pages 4556\u20134565, 2019.",
        "ref_ids": [
          "14"
        ]
      },
      "Single-shot scene reconstruction": {
        "authors": [
          "Anonymous Submission"
        ],
        "url": "https://openreview.net/pdf?id=CGn3XKSf7vf",
        "ref_texts": "[7] S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In CVPR , 2019.",
        "ref_ids": [
          "7"
        ]
      },
      "Votehmr: Occlusion-aware voting network for robust 3d human mesh recovery from partial point clouds": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2110.08729",
        "ref_texts": "[32] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. 2019. PVNet: Pixel-Wise Voting Network for 6DoF Pose Estimation. In IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2019, Long Beach, CA, USA, June 16-20, 2019 . Computer Vision Foundation / IEEE, Long Beach, 4561\u20134570. https: //doi.org/10.1109/CVPR.2019.00469",
        "ref_ids": [
          "32"
        ]
      },
      "Data-driven object pose estimation in a practical bin-picking application": {
        "authors": [],
        "url": "https://www.mdpi.com/1424-8220/21/18/6093/pdf",
        "ref_texts": "16. Peng, S.; Liu, Y.; Huang, Q.; Zhou, X.; Bao, H. PVNet: Pixel-Wise Voting Network for 6DoF Pose Estimation. In Proceedings of the 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), Long Beach, CA, USA, 15\u201320 June 2019; pp. 4556\u20134565.",
        "ref_ids": [
          "16"
        ]
      },
      "Synpick: A dataset for dynamic bin picking scene understanding": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2107.04852",
        "ref_texts": "[16] S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao, \u201cPVNet: Pixel-wise voting network for 6DOF pose estimation,\u201d in Conf. on Computer Vision and Pattern Recognition (CVPR) , 2019.",
        "ref_ids": [
          "16"
        ]
      },
      "Geometric change detection in digital twins": {
        "authors": [
          "Tiril Sundby",
          "Julia Maria",
          "Adil Rasheed",
          "Mandar Tabib",
          "Omer San"
        ],
        "url": "https://www.mdpi.com/2673-6470/1/2/9/pdf",
        "ref_texts": "21. Peng, S.; Liu, Y.; Huang, Q.; Bao, H.; Zhou, X. PVNet: Pixel-wise Voting Network for 6DoF Pose Estimation. arXiv 2018 , arXiv:1812.11788.",
        "ref_ids": [
          "21"
        ]
      },
      "ARShoe: Real-time augmented reality shoe try-on system on smartphones": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2108.10515.pdf?trk=public_post_comment-text",
        "ref_texts": "[23] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. 2019. PVNet: Pixel-Wise Voting Network for 6DoF Pose Estimation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) . 4556\u2013",
        "ref_ids": [
          "23"
        ]
      },
      "Vipose: Real-time visual-inertial 6d object pose tracking": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2107.12617",
        "ref_texts": "[10] S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao, \u201cPvnet: Pixelwise voting network for 6dof pose estimation,\u201d in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , 2019, pp. 4561\u20134570.",
        "ref_ids": [
          "10"
        ]
      },
      "Estimating 6D aircraft pose from keypoints and structures": {
        "authors": [
          "Runze Fan",
          "Bing X",
          "Zhenzhong Wei"
        ],
        "url": "https://www.mdpi.com/2072-4292/13/4/663/pdf",
        "ref_texts": ""
      },
      "Synpo-net\u2014accurate and fast cnn-based 6dof object pose estimation using synthetic training": {
        "authors": [
          "Yongzhi Su",
          "Jason Rambach",
          "Alain Pagani",
          "Didier Stricker"
        ],
        "url": "https://www.mdpi.com/1424-8220/21/1/300/pdf",
        "ref_texts": ""
      },
      "6D object pose estimation using keypoints and part affinity fields": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2107.02057",
        "ref_texts": "15. Peng, S., Liu, Y., Huang, Q., Zhou, X., Bao, H.: PVNet: Pixel-wise voting network for 6DoF pose estimation. In: IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). pp. 4561\u20134570 (2019)",
        "ref_ids": [
          "15"
        ]
      },
      "Deepflux for skeleton detection in the wild": {
        "authors": [],
        "url": "https://www.cs.toronto.edu/~sven/Papers/IJCVDeepFlux21.pdf",
        "ref_texts": "1. Ahn, J., Cho, S., & Kwak, S. (2019). Weakly supervised learningof instance segmentation with inter-pixel relations. InProceedingsof IEEE international conference on computer vision and patternrecognition(pp. 2209\u20132218).2. Bai, M., & Urtasun, R. (2017). Deep watershed transform forinstance segmentation. InProceedings of IEEE internationalconference on computer vision and pattern recognition(pp. 2858\u20132866).3. Bai, X., Wang, X., Latecki, L. J., Liu, W., & Tu, Z. (2009). Activeskeleton for non-rigid object detection. InProceedings of IEEEinternational conference on computer vision(pp. 575\u2013582).4. Blum, H. (1973). Biological shape and visual science (part i).Jour-nal of Theoretical Biology,38(2), 205\u2013287.5. Borenstein, E., & Ullman, S. (2002). Class-specific, top-down seg-mentation. InProceedings of European conference on computervision(pp. 109\u2013122).6. Chen, L. C., Hermans, A., Papandreou, G., Schroff, F., Wang, P.,& Adam, H. (2018). Masklab: Instance segmentation by refiningobject detection with semantic and direction features. InProceed-ings of IEEE international conference on computer vision andpattern recognition(pp. 4013\u20134022).7. Chen, L. C., Papandreou, G., Kokkinos, I., Murphy, K., & Yuille,A. L. (2018). Deeplab: Semantic image segmentation with deepconvolutional nets, atrous convolution, and fully connected crfs.IEEE Transactions on Pattern Analysis and Machine Intelligence,40(4), 834\u2013848.8. Chen, X., Fang, H., Lin, T. Y., Vedantam, R., Gupta, S., Doll\u00e1r, P.,& Zitnick, C. L. (2015). Microsoft coco captions: Data collectionand evaluation server. CoRRabs/1504.00325.9. Ci, H., Wang, C., & Wang, Y. (2018). Video object segmentationby learning location-sensitive embeddings. InProceedings of Euro-pean conference on computer vision(pp. 501\u2013516).10. Deng, J., Dong, W., Socher, R., Li, L. J., Li, K., & Li, F. F. (2009).Imagenet: A large-scale hierarchical image database. InProceed-ings of IEEE international conference on computer vision andpattern recognition(pp. 248\u2013255).11. Dickinson, S. J. (2009).Object categorization: Computer andhuman vision perspectives.C a m b r i d g e :C a m b r i d g eU n i v e r s i t yPress.12. Dimitrov, P., Damon, J. N., & Siddiqi, K. (2013). Flux invariants forshape. InProceedings of IEEE international conference on com-puter vision and pattern recognition.13. Ding, J., Xue, N., Long, Y., Xia, G. S., & Lu, Q. (2019). LearningRoI transformer for oriented object detection in aerial images. InProceedings of IEEE international conference on computer visionand pattern recognition(pp. 2849\u20132858).14. Doll\u00e1r, P., & Zitnick, C. L. (2015). Fast edge detection using struc-tured forests.IEEE Transactions on Pattern Analysis and MachineIntelligence,37(8), 1558\u20131570.15. Dufresne-Camaro, C. O., Rezanejad, M., Tsogkas, S., Siddiqi, K.,&D i c k i n s o n ,S .(2 0 2 0 ) .A p p e a r a n c es h o c kg r a m m a rf o rf a s tm e d i a laxis extraction from real images. InProceedings of IEEE interna-tional conference on computer vision and pattern recognition.16. Everingham, M., Van Gool, L., Williams, C. K., Winn, J., & Zisser-man, A. (2010). The pascal visual object classes (voc) challenge.International Journal of Computer Vision,88(2), 303\u2013338.17. Felzenszwalb, P. F., & Huttenlocher, D. P. (2005). Pictorial struc-tures for object recognition.International Journal of ComputerVision,61(1), 55\u201379.18. Felzenszwalb, P. F., & Huttenlocher, D. P. (2012). Distance trans-forms of sampled functions.Theory of Computing,8(1), 415\u2013428.19. Girshick, R., Shotton, J., Kohli, P., Criminisi, A., & Fitzgibbon, A.(2011). Efficient regression of general-activity human poses fromdepth images. InProceedings of IEEE international conference oncomputer vision(pp. 415\u2013422).20. He, K., Zhang, X., Ren, S., & Sun, J. (2016). Deep residual learningfor image recognition. InProceedings of IEEE international con-ference on computer vision and pattern recognition(pp. 770\u2013778).21. Jang, J. H., & Hong, K. S. (2001). A pseudo-distance map for thesegmentation-free skeletonization of gray-scale images. InPro-ceedings of IEEE international conference on computer vision(vol. 2, pp. 18\u201323).22. Jerripothula, K. R., Cai, J., Lu, J., & Yuan, J. (2017). Objectco-skeletonization with co-segmentation. InProceedings of IEEEinternational conference on computer vision and pattern recogni-tion(pp. 3881\u20133889).23. Jia, Y., Shelhamer, E., Donahue, J., Karayev, S., Long, J., Girshick,R., Guadarrama, S., & Darrell, T. (2014). Caffe: Convolutionalarchitecture for fast feature embedding. InProceedings of ACMmultimedia(pp. 675\u2013678).24. Jiang, Y., Zhu, X., Wang, X., Yang, S., Li, W., Wang, H., Fu, P.,&L u o ,Z .(2 0 1 7 ) .R 2 C N N :R o t a t i o n a lr e g i o nC N Nf o ro r i e n t a t i o nrobust scene text detection. PreprintarXiv:1706.09579.123 International Journal of Computer Vision25. Ke, W., Chen, J., Jiao, J., Zhao, G., & Ye, Q. (2017) SRN: Side-output residual network for object symmetry detection in the wild.InProceedings of IEEE international conference on computervision and pattern recognition(pp. 302\u2013310).26. Kinga, D., & Adam, J. B.: A method for stochastic optimization.InProceedings of international conference on learning represen-tations(vol. 5).27. Kreiss, S., Bertoni, L., & Alahi, A. (2019) PifPaf: Composite fieldsfor human pose estimation. InProceedings of IEEE internationalconference on computer vision and pattern recognition(pp. 11977\u201311986).28. Levinshtein, A., Sminchisescu, C., & Dickinson, S. (2013). Multi-scale symmetric part detection and grouping.International Journalof Computer Vision,104(2), 117\u2013134.29. Lindeberg, T. (1998). Edge detection and ridge detection with auto-matic scale selection.International Journal of Computer Vision,30(2), 117\u2013156.30. Lindeberg, T. (2013). Scale selection properties of generalizedscale-space interest point detectors.Journal of Mathematical Imag-ing and Vision,46(2), 177\u2013210.31. Liu, C., Ke, W., Qin, F., & Ye, Q. (2018). Linear span network forobject skeleton detection. InProceedings of European conferenceon computer vision(pp. 136\u2013151).32. Liu, T. L., Geiger, D., & Yuille, A. L. (1998). Segmenting by seek-ing the symmetry axis. InProceedings of international conferenceon pattern recognition(vol. 2, pp. 994\u2013998).33. Liu, X., Lyu, P., Bai, X., & Cheng, M. M. (2017). Fusing image andsegmentation cues for skeleton extraction in the wild. InProceed-ings of ICCV workshop on detecting symmetry in the wild(vol. 6,p. 8).34. Liu, Y., Cheng, M. M., Hu, X., Wang, K., & Bai, X. (2017). Richerconvolutional features for edge detection. InProceedings of IEEEinternational conference on computer vision and pattern recogni-tion(pp. 5872\u20135881).35. Long, J., Shelhamer, E., & Darrell, T. (2015) Fully convolutionalnetworks for semantic segmentation. InProceedings of IEEE inter-national conference on computer vision and pattern recognition(pp. 3431\u20133440).36. Luo, W., Li, Y., Urtasun, R., & Zemel, R. (2016). Understanding theeffective receptive field in deep convolutional neural networks. InProceedings of advances in neural information processing systems(pp. 4898\u20134906).37. Ma, J., Shao, W., Ye, H., Wang, L., Wang, H., Zheng, Y., et al.(2018). Arbitrary-oriented scene text detection via rotation pro-posals.IEEE Transactions on Multimedia,20(11), 3111\u20133122.38. Maninis, K. K., Pont-Tuset, J., Arbel\u00e1ez, P., & Van Gool, L.(2018). Convolutional oriented boundaries: From image segmen-tation to high-level tasks.IEEE Transactions on Pattern Analysisand Machine Intelligence,40(4), 819\u2013833.39. Marr, D., & Nishihara, H. K. (1978). Representation and recog-nition of the spatial organization of three-dimensional shapes.Proceedings of the Royal Society of London B: Biological Sciences,200(1140), 269\u2013294.40. Martin, D., Fowlkes, C., Tal, D., & Malik, J. (2001). A database ofhuman segmented natural images and its application to evaluatingsegmentation algorithms and measuring ecological statistics. InProceedings of IEEE international conference on computer vision(vol. 2, pp. 416\u2013423).41. Martin, D. R., Fowlkes, C. C., & Malik, J. (2004). Learning todetect natural image boundaries using local brightness, color, andtexture cues.IEEE Transactions on Pattern Analysis and MachineIntelligence,26(5), 530\u2013549.42. M\u00e1ttyus, G., Luo, W., & Urtasun, R. (2017). Deeproadmapper:Extracting road topology from aerial images. InProceedings of theIEEE international conference on computer vision.43. Mattyus, G., Wang, S., Fidler, S., & Urtasun, R. (2015). Enhancingroad maps by parsing aerial images around the world. InProceed-ings of the IEEE international conference on computer vision(pp.1689\u20131697).44. Nedzved, A., Ablameyko, S., & Uchida, S. (2006). Gray-scalethinning by using a pseudo-distance map. InProceedings of IEEEinternational conference on pattern recognition.45. Peng, S., Liu, Y., Huang, Q., Zhou, X., & Bao, H. (2019). PVNet:Pixel-wise voting network for 6dof pose estimation. InProceedingsof IEEE international conference on computer vision and patternrecognition(pp. 4561\u20134570).46. Ren, Z., Yuan, J., Meng, J., & Zhang, Z. (2013). Robust part-basedhand gesture recognition using kinect sensor.IEEE Transactionson Multimedia,15(5), 1110\u20131120.47. Shen, W., Bai, X., Hu, R., Wang, H., & Latecki, L. J. (2011).Skeleton growing and pruning with bending potential ratio.Pat-tern Recognition,44(2), 196\u2013209.48. Shen, W., Bai, X., Hu, Z., & Zhang, Z. (2016). Multiple instancesubspace learning via partial random projection tree for localreflection symmetry in natural images.Pattern Recognition,52,306\u2013316.49. Shen, W., Zhao, K., Jiang, Y., Wang, Y., Bai, X., & Yuille, A.(2017). Deepskeleton: Learning multi-task scale-associated deepside outputs for object skeleton extraction in natural images.IEEETransactions on Image Processing,26(11), 5298\u20135311.50. Shen, W., Zhao, K., Jiang, Y., Wang, Y., Zhang, Z., & Bai, X.(2016). Object skeleton extraction in natural images by fusingscale-associated deep side outputs. InProceedings of IEEE inter-national conference on computer vision and pattern recognition(pp. 222\u2013230).51. Shotton, J., Fitzgibbon, A., Cook, M., Sharp, T., Finocchio, M.,Moore, R., Kipman, A., & Blake, A. (2011) Real-time humanpose recognition in parts from single depth images. InProceedingsof IEEE international conference on computer vision and patternrecognition(pp. 1297\u20131304).52. Siddiqi, K., Bouix, S., Tannenbaum, A., & Zucker, S. W. (2002).Hamilton-jacobi skeletons.International Journal of ComputerVision,48(3), 215\u2013231.53. Siddiqi, K., & Pizer, S. M. (2008).Medial Representations: Math-ematics., Algorithms and Applications Berlin: Springer.54. Siddiqi, K., Shokoufandeh, A., Dickinson, S. J., & Zucker, S. W.(1999). Shock graphs and shape matching.International Journalof Computer Vision,35(1), 13\u201332.55. Sie Ho Lee, T., Fidler, S., & Dickinson, S. (2013). Detecting curvedsymmetric parts using a deformable disc model. InProceedingsof IEEE international conference on computer vision(pp. 1753\u20131760).56. Simonyan, K., & Zisserman, A. (2015). Very deep convolutionalnetworks for large-scale image recognition. InProceedings of inter-national conference on learning representations.57. Sironi, A., Lepetit, V., & Fua, P. (2014). Multiscale centerline detec-tion by learning a scale-space distance transform. InProceedingsof IEEE international conference on computer vision and patternrecognition(pp. 2697\u20132704).58. Trinh, N. H., & Kimia, B. B. (2011). Skeleton search: Category-specific object recognition and segmentation using a skeletal shapemodel.International Journal of Computer Vision,2,2 1 5 \u2013 2 4 0 .59. Tsogkas, S., & Dickinson, S. (2017) AMAT: Medial axis transformfor natural images. InProceedings of IEEE international confer-ence on computer vision(pp. 2727\u20132736).60. Tsogkas, S., & Kokkinos, I. (2012). Learning-based symmetrydetection in natural images. InProceedings of European confer-ence on computer vision(pp. 41\u201354).61. Wang, Y., Xu, Y., Tsogkas, S., Bai, X., Dickinson, S., & Siddiqi, K.(2019). Deepflux for skeletons in the wild. InProceedings of IEEE123 International Journal of Computer Visioninternational conference on computer vision and pattern recogni-tion(pp. 5287\u20135296).62. Wei, S. E., Ramakrishna, V., Kanade, T., & Sheikh, Y. (2016).Convolutional pose machines. InProceedings of IEEE interna-tional conference on computer vision and pattern recognition(pp.4724\u20134732).63. Xia, G., Hu, J., Hu, F., Shi, B., Bai, X., Zhong, Y., et al. (2017).AID: A benchmark data set for performance evaluation of aerialscene classification.IEEE Transactions Geoscience and RemoteSensing,55(7), 3965\u20133981.64. Xia, G. S., Bai, X., Ding, J., Zhu, Z., Belongie, S., Luo, J., Datcu,M., Pelillo, M., & Zhang, L. (2018) DOTA: A large-scale datasetfor object detection in aerial images. InProceedings of IEEE inter-national conference on computer vision and pattern recognition(pp. 3974\u20133983).65. Xie, S., & Tu, Z. (2015). Holistically-nested edge detection. InProceedings of IEEE international conference on computer vision(pp. 1395\u20131403).66. Xu, W., Parmar, G., & Tu, Z. (2019). Geometry-aware end-to-endskeleton detection. InBritish Machine Vision Conference.67. Xu, Y., Wang, Y., Zhou, W., Wang, Y., Yang, Z., & Bai, X. (2019).Textfield: Learning a deep direction field for irregular scene textdetection.IEEE Transactions on Image Processing,28(11), 5566\u20135579.68. Yang, X., Sun, H., Fu, K., Yang, J., Sun, X., Yan, M., et al. (2018).Automatic ship detection in remote sensing images from googleearth of complex scenes based on multiscale rotation dense featurepyramid networks.Remote Sensing,10(1), 132.69. Yu, Z., & Bajaj, C. (2004). A segmentation-free approach for skele-tonization of gray-scale images via anisotropic vector diffusion. InProceedings of IEEE international conference on computer visionand pattern recognition(pp. 415\u2013420).70. Zhang, Q., & Couloigner, I. (2007). Accurate centerline detectionand line width estimation of thick lines using the radon transform.IEEE Transactions on Image Processing,16(2), 310\u2013316.71. Zhang, Z., Shen, W., Yao, C., & Bai, X. (2015). Symmetry-basedtext line detection in natural scenes. InProceedings of IEEE inter-national conference on computer vision and pattern recognition(pp. 2558\u20132567).72. Zhao, K., Shen, W., Gao, S., Li, D., & Cheng, M. M. (2018). Hi-fi:Hierarchical feature integration for skeleton detection. InProceed-ings of international joint conference on artificial intelligence(pp.1191\u20131197).73. Zhu, S. C., & Yuille, A. L. (1996). Forms: A flexible object recog-nition and modelling system.International Journal of ComputerVision,20(3), 187\u2013212.74. Zucker, S. W. (2012). Local field potentials and border owner-ship: A conjecture about computation in visual cortex.Journal ofPhysiology-Paris,106,2 9 7 \u2013 3 1 5 .Publisher\u2019s NoteSpringer Nature remains neutral with regard to juris-dictional claims in published maps and institutional affiliations.",
        "ref_ids": [
          "1"
        ]
      },
      "Top-1 CORSMAL challenge 2020 submission: Filling mass estimation using multi-modal observations of human-robot handovers": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2012.01311",
        "ref_texts": "22. Peng, S., Liu, Y., Huang, Q., Zhou, X., Bao, H.: Pvnet: Pixel-wise voting network for 6dof pose estimation. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. pp. 4561{4570 (2019)",
        "ref_ids": [
          "22"
        ]
      },
      "Vision-based neural scene representations for spacecraft": {
        "authors": [
          "Anne Mergy",
          "Gurvan Lecuyer",
          "Dawa Derksen",
          "Dario Izzo"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2021W/AI4Space/papers/Mergy_Vision-Based_Neural_Scene_Representations_for_Spacecraft_CVPRW_2021_paper.pdf",
        "ref_texts": "[37] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 4561\u2013",
        "ref_ids": [
          "37"
        ]
      },
      "Kdfnet: Learning keypoint distance field for 6d object pose estimation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2109.10127",
        "ref_texts": "[5] S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao, \u201cPvnet: Pixel-wise voting network for 6dof pose estimation,\u201d in CVPR , 2019. 1, 2, 4, 5, 6",
        "ref_ids": [
          "5"
        ]
      },
      "Fast-learning grasping and pre-grasping via clutter quantization and Q-map masking": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2107.02452",
        "ref_texts": "[20] S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao, \u201cPvnet: Pixel-wise voting network for 6dof pose estimation,\u201d in IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2019, pp. 4561\u2013",
        "ref_ids": [
          "20"
        ]
      },
      "Parametricnet: 6dof pose estimation network for parametric shapes in stacked scenarios": {
        "authors": [],
        "url": "https://yongjinliu.github.io/files/2021-ParametricNet-6DoF-Pose-Estimation-Network-for-Parametric-Shapes-in-Stacked-Scenarios.pdf",
        "ref_texts": "[15] S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao, \u201cPVNet: Pixel-wise voting network for 6DoF pose estimation,\u201d in IEEE/CVF Conference on CVPR , 2019, pp. 4556\u20134565.",
        "ref_ids": [
          "15"
        ]
      },
      "ASM-Net: Category-level Pose and Shape Estimation Using Parametric Deformation.": {
        "authors": [],
        "url": "https://www.bmvc2021-virtualconference.com/assets/papers/1277.pdf",
        "ref_texts": "[19] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. PVNet: Pixelwise V oting Network for 6DoF Pose Estimation. In Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , pages 4561\u20134570, 2019.",
        "ref_ids": [
          "19"
        ]
      },
      "End-to-end learning improves static object geo-localization from video": {
        "authors": [
          "Mohamed Chaabane",
          "Lionel Gueguen",
          "Ameni Trabelsi",
          "Ross Beveridge",
          "Stephen O"
        ],
        "url": "http://openaccess.thecvf.com/content/WACV2021/papers/Chaabane_End-to-End_Learning_Improves_Static_Object_Geo-Localization_From_Video_WACV_2021_paper.pdf",
        "ref_texts": "[24] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixel-wise voting network for 6DoF pose estimation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 4561\u2013",
        "ref_ids": [
          "24"
        ]
      },
      "Robust 2D/3D vehicle parsing in arbitrary camera views for CVIS": {
        "authors": [
          "Hui Miao",
          "Feixiang Lu",
          "Zongdai Liu",
          "Liangjun Zhang",
          "Dinesh Manocha",
          "Bin Zhou"
        ],
        "url": "https://openaccess.thecvf.com/content/ICCV2021/papers/Miao_Robust_2D3D_Vehicle_Parsing_in_Arbitrary_Camera_Views_for_CVIS_ICCV_2021_paper.pdf",
        "ref_texts": "[36] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In CVPR , pages 4561\u20134570, 2019.",
        "ref_ids": [
          "36"
        ]
      },
      "6d pose estimation with correlation fusion": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1909.12936",
        "ref_texts": "[10] S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao, \u201cPvnet: Pixel-wise voting network for 6dof pose estimation,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , 2019, pp.",
        "ref_ids": [
          "10"
        ]
      },
      "Dynamical pose estimation": {
        "authors": [
          "Heng Yang",
          "Chris Doran",
          "Jacques Slotine"
        ],
        "url": "https://openaccess.thecvf.com/content/ICCV2021/papers/Yang_Dynamical_Pose_Estimation_ICCV_2021_paper.pdf",
        "ref_texts": "[39] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. PVNet: Pixel-wise Voting Network for 6DoF Pose Estimation. In IEEE Conf. on Computer Vision and Pattern Recognition (CVPR) , pages 4561\u20134570, 2019. 2",
        "ref_ids": [
          "39"
        ]
      },
      "L6dnet: Light 6 DoF network for robust and precise object pose estimation with small datasets": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2002.00911",
        "ref_texts": "[7]S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao, \u201cPVNet: Pixel-wise V oting Network for 6DoF pose estimation,\u201d in IEEE Conf. on Computer Vision and Pattern Recognition , 2019, pp. 4561\u20134570.",
        "ref_ids": [
          "7"
        ]
      },
      "A novel metric-learning-based method for multi-instance textureless objects' 6D pose estimation": {
        "authors": [
          "Chenrui Wu",
          "Long Chen",
          "Shiqing Wu"
        ],
        "url": "https://www.mdpi.com/2076-3417/11/22/10531/pdf",
        "ref_texts": "9. Peng, S.; Liu, Y.; Huang, Q.; Zhou, X.; Bao, H. Pvnet: Pixel-wise voting network for 6dof pose estimation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), Long Beach, CA, USA, 16\u201320 June 2019; pp. 4561\u20134570.",
        "ref_ids": [
          "9"
        ]
      },
      "Strumononet: Structure-aware monocular 3d prediction": {
        "authors": [
          "Zhenpei Yang",
          "Li Erran",
          "Qixing Huang"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2021/papers/Yang_StruMonoNet_Structure-Aware_Monocular_3D_Prediction_CVPR_2021_paper.pdf",
        "ref_texts": "[29] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2019, Long Beach, CA, USA, June 16-20, 2019 , pages 4561\u20134570. Computer Vision Foundation / IEEE, 2019.",
        "ref_ids": [
          "29"
        ]
      },
      "From IR images to point clouds to pose: point cloud-based AR glasses pose estimation": {
        "authors": [
          "Ahmet Firintepe",
          "Carolin Vey",
          "Stylianos Asteriadis",
          "Alain Pagani",
          "Didier Stricker"
        ],
        "url": "https://www.mdpi.com/2313-433X/7/5/80/pdf",
        "ref_texts": "1. Peng, S.; Liu, Y.; Huang, Q.; Zhou, X.; Bao, H. PVNet: Pixel-Wise Voting Network for 6DoF Pose Estimation. In Proceedings of the The IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Long Beach, CA, USA, 15\u201320 June 2019.",
        "ref_ids": [
          "1"
        ]
      },
      "A 3d keypoints voting network for 6dof pose estimation in indoor scene": {
        "authors": [
          "Huikai Liu",
          "Gaorui Liu",
          "Yue Zhang",
          "Linjian Lei",
          "Hui Xie",
          "Yan Li",
          "Shengli Sun"
        ],
        "url": "https://www.mdpi.com/2075-1702/9/10/230/pdf",
        "ref_texts": "7. Peng, S.; Liu, Y.; Huang, Q.; Zhou, X.; Bao, H. Pvnet: Pixel-wise voting network for 6dof pose estimation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, Long Beach, CA, USA, 15\u201320 June 2019; pp. 4561\u20134570.",
        "ref_ids": [
          "7"
        ]
      },
      "DRNet: A depth-based regression network for 6D object pose estimation": {
        "authors": [
          "Lei Jin",
          "Xiaojuan Wang",
          "Mingshu He",
          "Jingyue Wang"
        ],
        "url": "https://www.mdpi.com/1424-8220/21/5/1692/pdf",
        "ref_texts": "28. Peng, S.; Liu, Y.; Huang, Q.; Bao, H.; Zhou, X. PVNet: Pixel-Wise Voting Network for 6DoF Pose Estimation. In Proceedings of the CVPR, Long Beach, CA, USA, 15\u201321 June 2019; pp. 4561\u20134570. Sensors 2021 ,21, 1692 14 of 14",
        "ref_ids": [
          "28"
        ]
      },
      "Region pixel voting network (RPVNet) for 6d pose estimation from monocular image": {
        "authors": [
          "Feng Xiong",
          "Chengju Liu",
          "Qijun Chen"
        ],
        "url": "https://www.mdpi.com/2076-3417/11/2/743/pdf",
        "ref_texts": "29. Peng, S.; Liu, Y.; Huang, Q.; Zhou, X.; Bao, H. PVNet: Pixel-Wise Voting Network for 6DoF Pose Estimation. In Proceedings of the 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), Los Alamitos, CA, USA, 16\u201320 June 2019; IEEE Computer Society: Los Alamitos, CA, USA, 2019; pp. 4556\u20134565.",
        "ref_ids": [
          "29"
        ]
      },
      "Instancepose: Fast 6dof pose estimation for multiple objects from a single rgb image": {
        "authors": [
          "Lee Aing",
          "Nung Lie",
          "Chiu Chiang",
          "Shiang Lin"
        ],
        "url": "https://openaccess.thecvf.com/content/ICCV2021W/CVinHRC/papers/Aing_InstancePose_Fast_6DoF_Pose_Estimation_for_Multiple_Objects_From_a_ICCVW_2021_paper.pdf",
        "ref_texts": "[19] S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) , pages 4556\u20134565, 2019. 1, 2, 6, 7",
        "ref_ids": [
          "19"
        ]
      },
      "Bridging the reality gap for pose estimation networks using sensor-based domain randomization": {
        "authors": [
          "Frederik Hagelskjaer",
          "Anders Glent"
        ],
        "url": "https://openaccess.thecvf.com/content/ICCV2021W/3DODI/papers/Hagelskjaer_Bridging_the_Reality_Gap_for_Pose_Estimation_Networks_Using_Sensor-Based_ICCVW_2021_paper.pdf",
        "ref_texts": "[24] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In IEEE Conference on Computer Vision and Pattern Recognition , pages 4561\u20134570, 2019. 2, 7",
        "ref_ids": [
          "24"
        ]
      },
      "Automatic generation of machine learning synthetic data using ros": {
        "authors": [
          "Markus Richter"
        ],
        "url": "https://arxiv.org/pdf/2106.04547",
        "ref_texts": "20. Peng, S., Liu, Y., Huang, Q., Bao, H., Zhou, X.: PVNet: Pixel -wise Voting Network for ",
        "ref_ids": [
          "20"
        ]
      },
      "Investigations on output parameterizations of neural networks for single shot 6d object pose estimation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2104.07528",
        "ref_texts": "[28] S. Peng, Y . Liu, Q. Huang, H. Bao, and X. Zhou, \u201cPVNet: Pixelwise voting network for 6dof pose estimation,\u201d in IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2019.",
        "ref_ids": [
          "28"
        ]
      },
      "Soft-jig-driven assembly operations": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2010.10843",
        "ref_texts": "[36] S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao, \u201cPVNet: Pixelwise voting network for 6DoF pose estimation,\u201d in CVPR , 2019, pp.",
        "ref_ids": [
          "36"
        ]
      },
      "A differentiable extended kalman filter for object tracking under sliding regime": {
        "authors": [],
        "url": "https://www.frontiersin.org/articles/10.3389/frobt.2021.686447/pdf",
        "ref_texts": "(20198024 \u20138035). \u201cPyTorch: An Imperative Style, High-Performance Deep Learning Library, \u201dinAdvances in Neural Information Processing Systems 32 . Editors H. Wallach, H. Larochelle, A. Beygelzimer, F. d \u2019Alch\u00e9-Buc, E. Fox, and R. Garnett (New York: Curran Associates, Inc.). Peng, S., Liu, Y., Huang, Q., Zhou, X., and Bao, H. (2019). PVNet: Pixel-wise Voting Network for 6DoF Pose Estimation . CVPR. doi:10.1109/cvpr.2019.00469 Regoli, M., Pattacini, U., Metta, G., and Natale, L. (2016). \u201cHierarchical Grasp Controller Using Tactile Feedback, \u201din 2016 IEEE-RAS 16th International Conference on Humanoid Robots (Humanoids, 387 \u2013394. doi:10.1109/ HUMANOIDS.2016.7803305 Sodhi, P., Kaess, M., Mukadam, M., and Anderson, S. (2020). Learning Tactile Models for Factor Graph-Based State Estimation . Sundaralingam, B., Lambert, A. S., Handa, A., Boots, B., Hermans, T., Birch field, S., Ratliff, N., and Fox, D. (2019201999042). \u201cRobust Learning of Tactile Force Estimation through Robot Interaction, \u201din International Conference on Robotics and Automation (ICRA). doi:10.1109/ICRA.2019.8793502 Suresh, S., Bauza, M., Yu, K.-T., Mangelson, J. G., Rodriguez, A., and Kaess, M."
      },
      "A high-resolution network-based approach for 6D pose estimation of industrial parts": {
        "authors": [],
        "url": "https://ira.lib.polyu.edu.hk/bitstream/10397/92496/1/Fan_High-Resolution_Network-Based_Approach.pdf",
        "ref_texts": "[23] S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao, \u201cPvnet: Pixelwise voting network for 6dof pose estimation,\u201d in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , 2019, pp. 4561\u20134570.",
        "ref_ids": [
          "23"
        ]
      },
      "A 6DoF Pose Estimation Dataset and Network for Multiple Parametric Shapes in Stacked Scenarios": {
        "authors": [
          "Xinyu Zhang",
          "Weijie Lv",
          "Long Zeng"
        ],
        "url": "https://www.mdpi.com/2075-1702/9/12/321/pdf",
        "ref_texts": "7. Peng, S.; Liu, Y.; Huang, Q.; Zhou, X.; Bao, H. PVNet: Pixel-Wise Voting Network for 6DoF Pose Estimation. In Proceedings of the 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), Long Bench, CA, USA, 16\u201320 June 2019; pp. 4556\u20134565.",
        "ref_ids": [
          "7"
        ]
      },
      "Pose estimation from RGB images of highly symmetric objects using a novel multi-pose loss and differential rendering": {
        "authors": [],
        "url": "https://vbn.aau.dk/files/458094775/IROS_2021_Pose_Estimation_from_RGB_Images_of_Highly_Symmetric_Objects_using_a_Novel_Multi_Pose_Loss_and_Differential_Rendering.pdf",
        "ref_texts": "[9] S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao, \u201cPvnet: Pixel-wise voting network for 6dof pose estimation,\u201d in CVPR , June 2019.",
        "ref_ids": [
          "9"
        ]
      },
      "MBAPose: Mask and bounding-box aware pose estimation of surgical instruments with photorealistic domain randomization": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2103.08105",
        "ref_texts": "[23] S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao, \u201cPvnet: Pixelwise voting network for 6dof pose estimation,\u201d in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , 2019, pp. 4561\u20134570.",
        "ref_ids": [
          "23"
        ]
      },
      "Toward augmented reality in museums: evaluation of design choices for 3D object pose estimation": {
        "authors": [
          "Paschalis Panteleris"
        ],
        "url": "https://www.frontiersin.org/articles/10.3389/frvir.2021.649784/pdf",
        "ref_texts": "2018. ECCV 2018 . Lecture Notes in Computer Science, Vol. 11219, eds V. Ferrari,M.Hebert,C.Sminchisescu,andY.Weiss(Cham:Springer).119 \u2013134. doi:10.1007/978-3-030-01267-0_8 Park, K., Patten, T., and Vincze, M. (2019). \u201cPix2pose: pixel-wi se coordinate regression of objects for 6D pose estimation,\u201d in 2019 IEEE/CVF International Conference on Computer Vision (ICCV) (Seoul), 7668\u20137677. doi:10.1109/ICCV.2019.00776 Payet, N., and Todorovic, S. (2011). \u201cFrom contours to 3D objec t detection and pose estimation,\u201d in 2011 International Conference on Computer Vision (Barcelona),983\u2013990.doi:10.1109/ICCV.2011.6126342 Peng, S., Liu, Y., Huang, Q., Zhou, X., and Bao, H. (2019). PVNet: pixel-wise voting network for 6Dof pose estimation,\u201d in 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) (Long Beach, CA), 4556\u20134565.doi:10.1109/CVPR.2019.00469 Pitteri,G.,Ilic,S.,andLepetit,V.(2019).\u201cCORNet:generic3 Dcornersfor6Dpose estimation of new objects without retraining,\u201d in ICCV Workshops . (Seoul). doi:10.1109/ICCVW.2019.00342 Rad, M., and Lepetit, V. (2017). \u201cBB8: a scalable, accurate, robus t to partial occlusion method for predicting the 3D poses of challenging objects without using depth,\u201d in 2017 IEEE International Conference on Computer Vision (ICCV)(Venice),3848\u20133856.doi:10.1109/ICCV.2017.413 Redmon, J., and Farhadi, A. (2017). \u201cYolo9000: better, faster, stronger,\u201d in 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)",
        "ref_ids": [
          "2018"
        ]
      },
      "Self-guided instance-aware network for depth completion and enhancement": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2105.12186",
        "ref_texts": "[12] S. Y . Q. H.Bao and X.Zhou, \u201cPvnet: Pixel-wise voting network for 6dof pose estimation,\u201d IEEE Conference on Computer Vision and Pattern Recognition , pp. 4556\u20134565, 2018.",
        "ref_ids": [
          "12"
        ]
      },
      "Attention voting network with prior distance augmented loss for 6DoF pose estimation": {
        "authors": [],
        "url": "https://www.jstage.jst.go.jp/article/transinf/E104.D/7/E104.D_2020EDP7235/_pdf",
        "ref_texts": "[7]S. Peng, Y. Liu, Q. Huang, X. Zhou, and H. Bao, \u201cPvnet: Pixel-wise voting network for 6dof pose estimation,\u201d Proc. IEEE Conference on Computer Vision and Pattern Recognition, pp.4561\u20134570, 2019.",
        "ref_ids": [
          "7"
        ]
      },
      "6D UAV pose estimation for ship landing guidance": {
        "authors": [],
        "url": "https://welcome.isr.tecnico.ulisboa.pt/wp-content/uploads/2021/12/2021141083.pdf",
        "ref_texts": "[14] G. Billings and M. Johnson-Roberson. SilhoNet: An RGB Method for 6D Object Pose Estimation. IEEE Robotics and Automation Letters, 2019.[15] S. Peng, Y . Liu, Q. Huang, X. Zhou and H. Bao. PVNet: Pixelwise V oting Network for 6DoF Pose Estimation. IEEE conference on computer vision and pattern recognition, 2019.",
        "ref_ids": [
          "14",
          "15"
        ]
      },
      "\u57fa\u4e8e\u4e09\u7ef4\u68c0\u6d4b\u7f51\u7edc\u7684\u673a\u5668\u4eba\u6293\u53d6\u65b9\u6cd5": {
        "authors": [],
        "url": "http://emt.cnjournals.com/yqyb/ch/reader/create_pdf.aspx?file_no=20210817&year_id=2021&quarter_id=8&falg=1",
        "ref_texts": "[19] PENG S, LIU Y, HUANG Q, et al. Pvnet: Pixel-wise voting network for ",
        "ref_ids": [
          "19"
        ]
      },
      "BIFNOM: Binary-coded features on normal maps": {
        "authors": [],
        "url": "https://www.mdpi.com/1424-8220/21/10/3469/pdf",
        "ref_texts": "7. Peng, S.; Liu, Y.; Huang, Q.; Zhou, X.; Bao, H. PVNet: Pixel-wise Voting Network for 6DoF Pose Estimation. In Proceedings of the CVPR, Long Beach, CA, USA, 16\u201320 June 2019.",
        "ref_ids": [
          "7"
        ]
      },
      "Iterative Coarse-to-Fine 6D-Pose Estimation Using Back-propagation": {
        "authors": [],
        "url": "http://mprg.jp/data/MPRG/C_group/C20210929_araki.pdf",
        "ref_texts": "[21] S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao, \u201cPVNet: Pixel-wise V oting Network for 6DoF Pose Estimation,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , 2019, pp. 4561\u20134570.",
        "ref_ids": [
          "21"
        ]
      },
      "Deep quaternion pose proposals for 6D object pose tracking": {
        "authors": [
          "Mateusz Majcher",
          "Bogdan Kwolek"
        ],
        "url": "https://openaccess.thecvf.com/content/ICCV2021W/DSC/papers/Majcher_Deep_Quaternion_Pose_Proposals_for_6D_Object_Pose_Tracking_ICCVW_2021_paper.pdf",
        "ref_texts": "[21] S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao. PVNet: Pixel-Wise V oting Network for 6DoF Pose Estimation. In IEEE Conf. CVPR , pages 4556\u20134565, 2019. 1, 4",
        "ref_ids": [
          "21"
        ]
      },
      "Joint Learning of Object Detection and Pose Estimation using Augmented Autoencoder": {
        "authors": [],
        "url": "https://www.mva-org.jp/Proceedings/2021/papers/P1-10.pdf",
        "ref_texts": "[13] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In CVPR , 2019.[14] Yinlin Hu, Pascal Fua, Wei Wang, and Mathieu Salzmann. Single-stage 6d object pose estimation. In CVPR , 2020.",
        "ref_ids": [
          "13",
          "14"
        ]
      },
      "An improved estimation algorithm of space targets pose based on multi-modal feature fusion": {
        "authors": [
          "Jiang Hua",
          "Tonglin Hao",
          "Liangcai Zeng",
          "Gui Yu"
        ],
        "url": "https://www.mdpi.com/2227-7390/9/17/2085/pdf",
        "ref_texts": "3. Peng, S.; Liu, Y.; Huang, Q.; Zhou, X.; Bao, H. PVNet: Pixel-Wise Voting Network for 6DoF Pose Estimation. In Proceedings of the 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), Long Beach, CA, USA, 15\u201320 June 2019; IEEE: Long Beach, CA, USA; pp. 4556\u20134565.",
        "ref_ids": [
          "3"
        ]
      },
      "Iterative optimisation with an innovation CNN for pose refinement": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2101.08895",
        "ref_texts": "[PLH+19] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. InCVPR , 2019.",
        "ref_ids": [
          "PLH\\+19"
        ]
      },
      "End-to-end multi-instance robotic reaching from monocular vision": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2401.11834",
        "ref_texts": "[3] S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao, \u201cPvnet: Pixel-wise voting network for 6dof pose estimation,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , 2019, pp.",
        "ref_ids": [
          "3"
        ]
      },
      "MixedFusion: 6D Object pose estimation from decoupled RGB-depth features": {
        "authors": [],
        "url": "https://ailb-web.ing.unimore.it/icpr/media/posters/10918.pdf",
        "ref_texts": ""
      },
      "Experimental Evaluation of Affordance Detection Applied to 6-DoF Pose Estimation for Intelligent Robotic Grasping of Household Objects": {
        "authors": [
          "Aidan Keaveny"
        ],
        "url": "https://uwspace.uwaterloo.ca/bitstream/handle/10012/17716/Keaveny_Aidan.pdf?sequence=3",
        "ref_texts": "[19] S. Peng, Y. Liu, Q. Huang, X. Zhou, and H. Bao. PVNET: Pixel-wise Voting Network for 6DoF Pose Estimation. Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition , pages 4556\u20134565, 2019. ISSN 10636919. doi: 10.1109/CVPR.2019.00469.",
        "ref_ids": [
          "19"
        ]
      },
      "Learning Stereopsis from Geometric Synthesis for 6D Object Pose Estimation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2109.12266",
        "ref_texts": "[14] S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao, \u201cPvnet: Pixelwise voting network for 6dof pose estimation,\u201d in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pp. 4561\u20134570, 2019.",
        "ref_ids": [
          "14"
        ]
      },
      "Towards real-time Scan-versus-BIM: methods applications and challenges": {
        "authors": [],
        "url": "https://ec-3.org/publications/conferences/EC32021/papers/EC32021_176.pdf",
        "ref_texts": "10.1109/ICCV.2019.00776. P\u0103tr\u0103ucean, V. et al. (2015) 'State of research in automatic as-built modelling', Advanced Engineering Informatics, 29(2), pp. 162 \u2013171. doi: https://doi.org/10.1016/j .aei.2015.01.001. Peng, S. et al. (2019) 'PVNET: Pixel -wise voting network for 6dof pose estimation', in Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition. IEEE Computer Society, pp. "
      },
      "Pose Estimation and Image Matching for Tidy-up Task using a Robot Arm": {
        "authors": [],
        "url": "https://koreascience.kr/article/JAKO202109065713449.pdf",
        "ref_texts": "[3] S. Peng, Y. Liu, Q. Huang, X. Zhou, and H. Bao, \u201cPvnet: Pixelwise voting network for 6dof pose estimation,\u201d 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) , Long Beach, CA, USA, 2019, DOI: 10.1109/CVPR.2019.00469.",
        "ref_ids": [
          "3"
        ]
      },
      "Pose Tracking vs. Pose Estimation of AR Glasses with Convolutional, Recurrent, and Non-local Neural Networks: A Comparison": {
        "authors": [],
        "url": "https://www-live.dfki.de/fileadmin/user_upload/import/11858_Firintepe2021_EUROXR.pdf",
        "ref_texts": "26. Peng, S., Liu, Y., Huang, Q., Zhou, X., Bao, H.: PVNet: Pixel-Wise Voting Network for 6DoF Pose Estimation. In: The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) (June 2019)",
        "ref_ids": [
          "26"
        ]
      },
      "Fiducial Points-supported Object Pose Tracking on RGB Images via Particle Filtering with Heuristic Optimization.": {
        "authors": [],
        "url": "https://www.scitepress.org/Papers/2021/102371/102371.pdf",
        "ref_texts": "(2017). SSD-6D: Making RGB-Based 3D Detection and 6D Pose Estimation Great Again. In IEEE Int. Conf. on Computer Vision , pages 1530\u20131538. Lepetit, V ., Moreno-Noguer, F., and Fua, P. (2009). EPnP: An accurate O(n) solution to the PnP problem. Int. J. Comput. Vision , 81(2):155\u2013166. Lepetit, V ., Pilet, J., and Fua, P. (2004). Point matching as a classification problem for fast and robust object pose estimation. In CVPR , pages 244\u2013250. Lin, T.-Y ., Maire, M., Belongie, S., Hays, J., Perona, P., Ramanan, D., Dollar, P., and Zitnick, C. L. (2014). Microsoft COCO: Common Objects in Context. In ECCV , pages 740\u2013755. Springer. Lopatin, V . and Kwolek, B. (2020). 6D pose estimation of texture-less objects on RGB images using CNNs. In The 19th Int. Conf. on Artificial Intelligence and Soft Computing , pages 180\u2013192. Springer. Majcher, M. and Kwolek, B. (2020). 3D Model-Based 6D Object Pose Tracking on RGB Images Using Particle Filtering and Heuristic Optimization. In 15th Int. The Int. Conf. on Computer Vision Theory and Applications (VISAPP) , pages 690\u2013697, vol. 5. SciTePress. Marchand, E., Uchiyama, H., and Spindler, F. (2016). Pose estimation for augmented reality: A hands-on survey. IEEE Trans. on Vis. and Comp. Graphics , 22(12):2633\u20132651. Peng, S., Liu, Y ., Huang, Q., Zhou, X., and Bao, H. (2019). PVNet: Pixel-Wise V oting Network for 6DoF Pose Estimation. In IEEE Conf. on Comp. Vision and Patt. Rec., pages 4556\u20134565. Prisacariu, V . A. and Reid, I. D. (2012). PWP3D: RealTime Segmentation and Tracking of 3D Objects. Int. J. Comput. Vision , 98(3):335\u2013354. Rad, M. and Lepetit, V . (2017). BB8: A scalable, accurate, robust to partial occlusion method for predicting the 3D poses of challenging objects without using depth. InIEEE Int. Conf. on Comp. Vision , pages 3848\u20133856. Ronneberger, O., Fischer, P., and Brox, T. (2015). UNet: Convolutional networks for biomedical image segmentation. In MICCAI , pages 234\u2013241. Springer."
      },
      "Detecting and tracking outdoor gym geometry for AR display of exercise suggestions": {
        "authors": [],
        "url": "https://upcommons.upc.edu/bitstream/handle/2117/360080/M_Thesis_Aina_Maki.pdf?sequence=2",
        "ref_texts": "[11] Sida Peng et al. \\PVNet: Pixel-Wise Voting Network for 6DoF Pose Estimation\". In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) . June 2019.",
        "ref_ids": [
          "11"
        ]
      },
      "Learning and Leveraging Kinematics for Robot Motion Planning Under Uncertainty": {
        "authors": [],
        "url": "https://repositories.lib.utexas.edu/bitstreams/513f82bf-e88d-4287-9c29-002490f924c1/download",
        "ref_texts": "[107] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 4561{4570, 2019.",
        "ref_ids": [
          "107"
        ]
      },
      "Graph Neural Network based on Geometric and Appearance Attention for 6D Pose Estimation": {
        "authors": [],
        "url": "https://dl.acm.org/doi/pdf/10.1145/3488933.3488959",
        "ref_texts": "[18] Peng, S., Liu, Y., Huang, Q., Zhou, X., & Bao, H. (2019). Pvnet: Pixel-wise voting network for 6dof pose estimation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 4561-4570).",
        "ref_ids": [
          "18"
        ]
      },
      "Robust 2D/3D Vehicle Parsing in CVIS": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2103.06432",
        "ref_texts": "[34] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In CVPR , pages 4561\u20134570, 2019.",
        "ref_ids": [
          "34"
        ]
      },
      "Deep Learning for Object Detection: Training Data Generation using Parametric CAD Modelling and Gazebo Simulation": {
        "authors": [
          "Akber Khan"
        ],
        "url": "https://trepo.tuni.fi/bitstream/handle/10024/135807/KhanAkberAli.pdf?sequence=4",
        "ref_texts": "[29] S. Peng, Y. Liu, Q. Huang, X. Zhou and H. Bao, \"PVNET: Pixel -wise voting network for 6dof pose estimation,\" in Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2019 06-01, vol. 2019, pp. 4556 \u20134565 , 2019. ",
        "ref_ids": [
          "29"
        ]
      },
      "Object 6DoF Pose Estimation for Power Grid Manipulating Robots": {
        "authors": [],
        "url": "http://mvr.whu.edu.cn/pubs/6dof-ICIG-v3-final.pdf",
        "ref_texts": "15. Peng, S., Liu, Y., Huang, Q., Zhou, X., Bao, H.: Pvnet: Pixel-wise voting network for 6dof pose estimation. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 4561{4570 (2019)",
        "ref_ids": [
          "15"
        ]
      },
      "A Comprehensive Review on 3D Object Detection and 6D Pose Estimation With Deep Learning": {
        "authors": [
          "Sabera Hoque"
        ],
        "url": "https://figshare.utas.edu.au/ndownloader/files/40754126",
        "ref_texts": "[191] S. Peng, Y. Liu, Q. Huang, H. Bao, and X. Zhou, ``PVNet: Pixel-wise voting network for 6DoF pose estimation,'' Tech. Rep., 2018.",
        "ref_ids": [
          "191"
        ]
      },
      "Learning Robot Skills from Few Demonstrations": {
        "authors": [],
        "url": "https://www.research-collection.ethz.ch/bitstream/handle/20.500.11850/478140/3/Stefan_Thesis.pdf",
        "ref_texts": "[131]S. Peng, Y. Liu, Q. Huang, X. Zhou, and H. Bao, \u201cPvnet: Pixel-wise voting network for 6dof pose estimation\u201d, in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition ,2019 , pp. 4561 \u2013",
        "ref_ids": [
          "131"
        ]
      },
      "Impact of Segmentation and Color Spaces in 6D Pose Estimation": {
        "authors": [],
        "url": "http://www.di.ubi.pt/~lfbaa/pubs/icarsc2021.pdf",
        "ref_texts": "[4] S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao, \u201cPvnet: Pixel-wise voting network for 6dof pose estimation,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , 2019, pp.",
        "ref_ids": [
          "4"
        ]
      },
      "A Survey on Deep Learning Based Methods and Datasets for Monocular 3D Object Detection. Electronics 2021, 10, 517": {
        "authors": [],
        "url": "https://pdfs.semanticscholar.org/076b/052fe9aa43e1f8619cc9e8aab29966a32f6d.pdf",
        "ref_texts": "72. Peng, S.; Liu, Y.; Huang, Q.; Zhou, X.; Bao, H. PVNet: Pixel-wise Voting Network for 6DOF Pose Estimation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Long Beach, CA, USA, 16\u201320 June 2019; pp. 4561\u20134570.",
        "ref_ids": [
          "72"
        ]
      },
      "Graph-Theoretic Outlier Rejection: From Instance to Category-Level Perception": {
        "authors": [],
        "url": "https://dspace.mit.edu/bitstream/handle/1721.1/139117/shi-jnshi-sm-AeroAstro-2021-thesis.pdf?sequence=1&isAllowed=y",
        "ref_texts": "[83] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. PVNet: Pixel-wise Voting Network for 6DoF Pose Estimation. In IEEE Conf. on Computer Vision and Pattern Recognition (CVPR) , pages 4561\u20134570, 2019.",
        "ref_ids": [
          "83"
        ]
      },
      "Learning Innovations for State Estimation": {
        "authors": [],
        "url": "http://www.gerard-kennedy.com/files/iros-2021.pdf",
        "ref_texts": "[31] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In CVPR , 2019.",
        "ref_ids": [
          "31"
        ]
      },
      "Supplementary Material-FFB6D: A Full Flow Bidirectional Fusion Network for 6D Pose Estimation": {
        "authors": [],
        "url": "https://openaccess.thecvf.com/content/CVPR2021/supplemental/He_FFB6D_A_Full_CVPR_2021_supplemental.pdf",
        "ref_texts": "[15] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 4561\u20134570, 2019. 3",
        "ref_ids": [
          "15"
        ]
      },
      "Self-supervised Geometric Perception": {
        "authors": [],
        "url": "https://openaccess.thecvf.com/content/CVPR2021/supplemental/Yang_Self-Supervised_Geometric_Perception_CVPR_2021_supplemental.pdf",
        "ref_texts": "[12] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. PVNet: Pixel-wise voting network for 6dof pose estimation. In IEEE Conf. on Computer Vision and Pattern Recognition (CVPR) , pages 4561\u20134570, 2019. 3",
        "ref_ids": [
          "12"
        ]
      },
      "VS-Net: Voting with Segmentation for Visual Localization-Supplementary Material": {
        "authors": [],
        "url": "http://openaccess.thecvf.com/content/CVPR2021/supplemental/Huang_VS-Net_Voting_With_CVPR_2021_supplemental.pdf",
        "ref_texts": "[6] Jeremie Papon, Alexey Abramov, Markus Schoeler, and Florentin W \u00a8org\u00a8otter. V oxel cloud connectivity segmentation supervoxels for point clouds. In Computer Vision and Pattern Recognition (CVPR), 2013 IEEE Conference on , Portland, Oregon, June 22-27 2013. 1[7] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 4561\u20134570, 2019. 1",
        "ref_ids": [
          "6",
          "7"
        ]
      },
      "Odhadov\u00e1n\u00ed rotace a translace netexturovan\u00e9ho objektu z jedn\u00e9 kamery": {
        "authors": [],
        "url": "https://dspace.cvut.cz/bitstream/handle/10467/96699/F3-BP-2021-Lukes-Michal-Michal%20Lukes%20thesis%20-%20final2.pdf?sequence=-1",
        "ref_texts": "8. PENG, Sida; LIU, Yuan; HUANG, Qixing; BAO, Hujun; ZHOU, Xiaowei. PVNet: Pixel-wise Voting Network for 6DoF Pose Estimation. CoRR. 2018, ro\u010d. abs/1812.11788. Available from arXiv: 1812.11788 .",
        "ref_ids": [
          "8"
        ]
      },
      "\ub85c\ubd07 \ud314\uc744 \ud65c\uc6a9\ud55c \uc815\ub9ac\uc791\uc5c5\uc744 \uc704\ud55c\ubb3c\uccb4 \uc790\uc138\ucd94\uc815 \ubc0f \uc774\ubbf8\uc9c0 \ub9e4\uce6d": {
        "authors": [
          "Media Contents"
        ],
        "url": "https://jkros.org/xml/31147/31147.pdf",
        "ref_texts": "[3] S. Peng, Y. Liu, Q. Huang, X. Zhou, and H. Bao, \u201cPvnet: Pixelwise voting network for 6dof pose estimation,\u201d 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) , Long Beach, CA, USA, 2019, DOI: 10.1109/CVPR.2019.00469.",
        "ref_ids": [
          "3"
        ]
      },
      "\ub80c\ub354\ub9c1 \ube44\uad50 \ub274\ub7f4\ub137 \uae30\ubc18 \uac00\uad6c \uc870\ub9bd \uc124\uba85\uc11c \ubd80\ud488\uc758 6D \uc790\uc138 \ucd94\uc815": {
        "authors": [],
        "url": "https://koreascience.kr/article/CFKO202115161214728.pdf",
        "ref_texts": "[6] Peng, Sida, et al. \"Pvnet: Pixel -wise voting network for 6dof pose estimation.\" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition . 2019. ",
        "ref_ids": [
          "6"
        ]
      },
      "A review on object pose recovery: From 3D bounding box detectors to full 6D pose estimators": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2001.10609",
        "ref_texts": "[160] S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao, PVNet: Pixel-wise Voting Network for 6DoF Pose Estimation , In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (pp. 4561-4570), 2019.",
        "ref_ids": [
          "160"
        ]
      },
      "Cosypose: Consistent multi-view multi-object 6d pose estimation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2008.08465",
        "ref_texts": "5. Peng, S., Liu, Y., Huang, Q., Zhou, X., Bao, H.: Pvnet: Pixel-wise voting network for 6dof pose estimation. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. (2019) 4561{4570",
        "ref_ids": [
          "5"
        ]
      },
      "Pvn3d: A deep point-wise 3d keypoints voting network for 6dof pose estimation": {
        "authors": [
          "Yisheng He",
          "Wei Sun",
          "Haibin Huang",
          "Jianran Liu",
          "Haoqiang Fan",
          "Jian Sun"
        ],
        "url": "https://openaccess.thecvf.com/content_CVPR_2020/papers/He_PVN3D_A_Deep_Point-Wise_3D_Keypoints_Voting_Network_for_6DoF_CVPR_2020_paper.pdf",
        "ref_texts": "[37] S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 4561\u20134570, 2019. 1,2,4,5,6,7",
        "ref_ids": [
          "37"
        ]
      },
      "Grnet: Gridding residual network for dense point cloud completion": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2006.03761",
        "ref_texts": "24. Peng, S., Liu, Y., Huang, Q., Zhou, X., Bao, H.: Pvnet: Pixel-wise voting network for 6dof pose estimation. In: CVPR 2019. (2019) 3",
        "ref_ids": [
          "24"
        ]
      },
      "6D pose estimation of objects: Recent technologies and challenges": {
        "authors": [],
        "url": "https://www.mdpi.com/2076-3417/11/1/228/pdf",
        "ref_texts": "32. Peng, S.; Liu, Y.; Huang, Q.; Bao, H.; Zhou, X. PVNet: Pixel-wise Voting Network for 6DoF Pose Estimation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Salt Lake City, UT, USA, 18\u201323 June 2018.",
        "ref_ids": [
          "32"
        ]
      },
      "Deep snake for real-time instance segmentation": {
        "authors": [
          "Sida Peng",
          "Wen Jiang",
          "Huaijin Pi",
          "Xiuli Li",
          "Hujun Bao",
          "Xiaowei Zhou"
        ],
        "url": "https://openaccess.thecvf.com/content_CVPR_2020/papers/Peng_Deep_Snake_for_Real-Time_Instance_Segmentation_CVPR_2020_paper.pdf",
        "ref_texts": "[33] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In CVPR , 2019. 3",
        "ref_ids": [
          "33"
        ]
      },
      "Honnotate: A method for 3d annotation of hand and object poses": {
        "authors": [
          "Shreyas Hampali",
          "Mahdi Rad",
          "Markus Oberweger",
          "Vincent Lepetit"
        ],
        "url": "https://openaccess.thecvf.com/content_CVPR_2020/papers/Hampali_HOnnotate_A_Method_for_3D_Annotation_of_Hand_and_Object_CVPR_2020_paper.pdf",
        "ref_texts": ""
      },
      "Hybridpose: 6d object pose estimation under hybrid representations": {
        "authors": [
          "Chen Song",
          "Jiaru Song",
          "Qixing Huang"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPR_2020/papers/Song_HybridPose_6D_Object_Pose_Estimation_Under_Hybrid_Representations_CVPR_2020_paper.pdf",
        "ref_texts": "[34] Sida Peng, Yuan Liu, Qixing Huang, Hujun Bao, and Xiaowei Zhou. Pvnet: Pixel-wise voting network for 6dof pose estimation. CoRR , abs/1812.11788, 2018. 1,2,3,4,6,7,8",
        "ref_ids": [
          "34"
        ]
      },
      "Epos: Estimating 6d pose of objects with symmetries": {
        "authors": [
          "Tomas Hodan",
          "Daniel Barath",
          "Jiri Matas"
        ],
        "url": "https://openaccess.thecvf.com/content_CVPR_2020/papers/Hodan_EPOS_Estimating_6D_Pose_of_Objects_With_Symmetries_CVPR_2020_paper.pdf",
        "ref_texts": "[50] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. PVNet: Pixel-wise voting network for 6DoF pose estimation. CVPR , 2019. 1, 2, 3",
        "ref_ids": [
          "50"
        ]
      },
      "Shape prior deformation for categorical 6d object pose and size estimation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2007.08454",
        "ref_texts": "18. Peng, S., Liu, Y., Huang, Q., Zhou, X., Bao, H.: Pvnet: Pixel-wise voting network for 6dof pose estimation. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. pp. 4561{4570 (2019)",
        "ref_ids": [
          "18"
        ]
      },
      "Variable compliance control for robotic peg-in-hole assembly: A deep-reinforcement-learning approach": {
        "authors": [
          "Cristian Camilo",
          "Damien Petit",
          "Ixchel Georgina",
          "Kensuke Harada"
        ],
        "url": "https://www.mdpi.com/2076-3417/10/19/6923/pdf",
        "ref_texts": "29. Peng, S.; Liu, Y.; Huang, Q.; Zhou, X.; Bao, H. Pvnet: Pixel-wise voting network for 6dof pose estimation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Long Beach, CA, USA, 16\u201320 June 2019; pp. 4561\u20134570.",
        "ref_ids": [
          "29"
        ]
      },
      "Single-stage 6d object pose estimation": {
        "authors": [
          "Yinlin Hu",
          "Pascal Fua",
          "Wei Wang",
          "Mathieu Salzmann"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPR_2020/papers/Hu_Single-Stage_6D_Object_Pose_Estimation_CVPR_2020_paper.pdf",
        "ref_texts": "[36] Sida Peng, Yuan Liu, Qixing Huang, Hujun Bao, and Xiaowei Zhou. PVNet: Pixel-Wise V oting Network for 6DoF Pose Estimation. In Conference on Computer Vision and Pattern Recognition , 2019. 1,2,3,4,5,6,7,8",
        "ref_ids": [
          "36"
        ]
      },
      "H3dnet: 3d object detection using hybrid geometric primitives": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2006.05682",
        "ref_texts": "26. Peng, S., Liu, Y., Huang, Q., Zhou, X., Bao, H.: Pvnet: Pixel-wise voting network for 6dof pose estimation. In: IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2019, Long Beach, CA, USA, June 16-20, 2019. pp. 4561{4570",
        "ref_ids": [
          "26"
        ]
      },
      "Satellite pose estimation challenge: Dataset, competition design, and results": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1911.02050",
        "ref_texts": "[40] S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao, \u201cPVNet: Pixel-wise voting network for 6DoF pose estimation,\u201d in The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) Oral , 2019.",
        "ref_ids": [
          "40"
        ]
      },
      "Learning canonical shape space for category-level 6d object pose and size estimation": {
        "authors": [
          "Dengsheng Chen",
          "Jun Li",
          "Zheng Wang",
          "Kai Xu"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPR_2020/papers/Chen_Learning_Canonical_Shape_Space_for_Category-Level_6D_Object_Pose_and_CVPR_2020_paper.pdf",
        "ref_texts": "[17] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. PVNet: Pixel-wise voting network for 6dof pose estimation. In Proc. CVPR , pages 4561\u20134570, 2019. 1,2",
        "ref_ids": [
          "17"
        ]
      },
      "Category level object pose estimation via neural analysis-by-synthesis": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2008.08145",
        "ref_texts": "39. Peng, S., Liu, Y., Huang, Q., Zhou, X., Bao, H.: Pvnet: Pixel-wise voting network for 6dof pose estimation. In: Proc. IEEE Conf. on Computer Vision and Pattern Recognition (CVPR) (2019)",
        "ref_ids": [
          "39"
        ]
      },
      "Self6d: Self-supervised monocular 6d object pose estimation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2004.06468",
        "ref_texts": "44. Peng, S., Liu, Y., Huang, Q., Zhou, X., Bao, H.: Pvnet: Pixel-wise voting network for 6dof pose estimation. In: IEEE Conference on Computer Vision and Pattern Recognition (CVPR). pp. 4561{4570 (2019)",
        "ref_ids": [
          "44"
        ]
      },
      "G2l-net: Global to local network for real-time 6d pose estimation with embedding vector features": {
        "authors": [
          "Wei Chen",
          "Xi Jia",
          "Hyung Jin",
          "Jinming Duan",
          "Ales Leonardis"
        ],
        "url": "https://openaccess.thecvf.com/content_CVPR_2020/papers/Chen_G2L-Net_Global_to_Local_Network_for_Real-Time_6D_Pose_Estimation_CVPR_2020_paper.pdf",
        "ref_texts": "[29] Sida Peng, Yuan Liu, Qixing Huang, Hujun Bao, and Xiaowei Zhou. Pvnet: Pixel-wise voting network for 6dof pose estimation. arXiv preprint arXiv:1812.11788 , 2018. 1,2,4, 5,6,7",
        "ref_ids": [
          "29"
        ]
      },
      "Latentfusion: End-to-end differentiable reconstruction and rendering for unseen object pose estimation": {
        "authors": [
          "Keunhong Park",
          "Arsalan Mousavian",
          "Yu Xiang",
          "Dieter Fox"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPR_2020/papers/Park_LatentFusion_End-to-End_Differentiable_Reconstruction_and_Rendering_for_Unseen_Object_Pose_CVPR_2020_paper.pdf",
        "ref_texts": "[33] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , pages 4561\u20134570, 2019. 2",
        "ref_ids": [
          "33"
        ]
      },
      "End-to-end learnable geometric vision by backpropagating pnp optimization": {
        "authors": [
          "Bo Chen",
          "Alvaro Parra",
          "Jiewei Cao",
          "Nan Li",
          "Jun Chin"
        ],
        "url": "https://openaccess.thecvf.com/content_CVPR_2020/papers/Chen_End-to-End_Learnable_Geometric_Vision_by_Backpropagating_PnP_Optimization_CVPR_2020_paper.pdf",
        "ref_texts": "[36] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In CVPR , 2019. 2,7",
        "ref_ids": [
          "36"
        ]
      },
      "Autolabeling 3d objects with differentiable rendering of sdf shape priors": {
        "authors": [
          "Sergey Zakharov",
          "Wadim Kehl",
          "Arjun Bhargava",
          "Adrien Gaidon"
        ],
        "url": "https://openaccess.thecvf.com/content_CVPR_2020/papers/Zakharov_Autolabeling_3D_Objects_With_Differentiable_Rendering_of_SDF_Shape_Priors_CVPR_2020_paper.pdf",
        "ref_texts": "[33] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In CVPR , 2019. 2",
        "ref_ids": [
          "33"
        ]
      },
      "Camera-to-robot pose estimation from a single image": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1911.09231",
        "ref_texts": "[10] S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao, \u201cPVNet: Pixel-wise voting network for 6DoF pose estimation,\u201d in CVPR , 2019.",
        "ref_ids": [
          "10"
        ]
      },
      "Hot-net: Non-autoregressive transformer for 3d hand-object pose estimation": {
        "authors": [],
        "url": "https://cse.buffalo.edu/~jsyuan/papers/2020/lin_mm20.pdf",
        "ref_texts": "[37] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. 2019. PVNet: Pixel-wise Voting Network for 6DoF Pose Estimation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition .",
        "ref_ids": [
          "37"
        ]
      },
      "Gsnet: Joint vehicle pose and shape reconstruction with geometrical and scene-aware supervision": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2007.13124",
        "ref_texts": "39. Peng, S., Liu, Y., Huang, Q., Zhou, X., Bao, H.: Pvnet: Pixel-wise voting network for 6dof pose estimation. In: CVPR (2019)",
        "ref_ids": [
          "39"
        ]
      },
      "Guided uncertainty-aware policy optimization: Combining learning and model-based strategies for sample-efficient policy learning": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2005.10872",
        "ref_texts": "[44] S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao, \u201cPvnet: Pixel-wise voting network for 6dof pose estimation,\u201d in CVPR , 2019.",
        "ref_ids": [
          "44"
        ]
      },
      "Single shot 6d object pose estimation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2004.12729",
        "ref_texts": "[10] S. Peng, Y . Liu, Q. Huang, H. Bao, and X. Zhou, \u201cPVNet: Pixelwise voting network for 6dof pose estimation,\u201d in IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , June 2019.",
        "ref_ids": [
          "10"
        ]
      },
      "CPS++: Improving class-level 6D pose and shape estimation from monocular images with self-supervised learning": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2003.05848",
        "ref_texts": "3515 Park JJ, Florence P, Straub J, Newcombe R, Lovegrove S (2019a) Deepsdf: Learning continuous signed distance functions for shape representation. In: CVPR Park K, Patten T, Vincze M (2019b) Pix2pose: Pixel-wise coordinate regression of objects for 6d pose estimation. In: ICCV Park K, Mousavian A, Xiang Y, Fox D (2020) Latentfusion: End-to-end difierentiable reconstruction and rendering for unseen object pose estimation. In: CVPR, pp 10710{10719 Paszke A, Gross S, Massa F, Lerer A, Bradbury J, Chanan G, Killeen T, Lin Z, Gimelshein N, Antiga L, et al. (2019) Pytorch: An imperative style, high-performance deep learning library. In: NeurIPS, pp 8026{8037 Peng S, Liu Y, Huang Q, Zhou X, Bao H (2019) Pvnet: Pixelwise voting network for 6dof pose estimation. In: CVPR Qi CR, Su H, Mo K, Guibas LJ (2017) Pointnet: Deep learning on point sets for 3d classiffcation and segmentation. In: CVPR Rad M, Lepetit V (2017) BB8: A scalable, accurate, robust to partial occlusion method for predicting the 3D poses of challenging objects without using depth. In: ICCV, pp 3828{3836 Ren S, He K, Girshick R, Sun J (2015) Faster r-cnn: Towards real-time object detection with region proposal networks. In: NeurIPS Romea AC, Torres MM, Srinivasa S (2011) The moped framework: Object recognition and pose estimation for manipulation. International Journal of Robotics Research 30(10):1284 { 1306 Simonelli A, Rota Bulo S, Porzi L, Lopez-Antequera M, Kontschieder P (2019) Disentangling monocular 3d object detection. In: ICCV Song S, Xiao J (2016) Deep sliding shapes for amodal 3d object detection in rgb-d images. In: CVPR Sundermeyer M, Marton ZC, Durner M, Brucker M, Triebel R (2018a) Implicit 3d orientation learning for 6d object detection from rgb images. In: ECCV Sundermeyer M, Marton ZC, Durner M, Brucker M, Triebel R (2018b) Implicit 3d orientation learning for 6d object detection from rgb images. In: ECCV, pp 699{715 Sundermeyer M, Durner M, Puang EY, Marton ZC, Vaskevicius N, Arras KO, Triebel R (2020) Multi-path learning for object pose estimation across domains. In: CVPR, pp 13916{13925 Tekin B, Sinha SN, Fua P (2018) Real-time seamless single shot 6d object pose prediction. In: CVPR Tian Z, Shen C, Chen H, He T (2019) FCOS: Fully convolutional one-stage object detection. In: ICCV, pp 9627{9636 Tremblay J, To T, Birchffeld S (2018) Falling things: A synthetic dataset for 3d object detection and pose estimation. In: CVPRW, pp 2038{2041 Umeyama S (1991) Least-squares estimation of transformation parameters between two point patterns. IEEE Transactions on Pattern Analysis & Machine Intelligence pp 18 F. Manhardt et al."
      },
      "Robust 6d object pose estimation by learning rgb-d features": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2003.00188",
        "ref_texts": "[7] S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao, \u201cPvnet: Pixel-wise voting network for 6dof pose estimation,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , 2019, pp.",
        "ref_ids": [
          "7"
        ]
      },
      "MobilePose: Real-time pose estimation for unseen objects with weak shape supervision": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2003.03522",
        "ref_texts": "20. Peng, S., Liu, Y., Huang, Q., Bao, H., Zhou, X.: Pvnet: Pixel-wise voting network for 6DoF pose estimation. In: IEEE Conference on Computer Vision and Pattern Recognition (CVPR) (2019)",
        "ref_ids": [
          "20"
        ]
      },
      "Monocular localization with vector HD map (MLVHM): A low-cost method for commercial IVs": {
        "authors": [],
        "url": "https://www.mdpi.com/1424-8220/20/7/1870/pdf",
        "ref_texts": "31. Peng, S.; Liu, Y.; Huang, Q.; Zhou, X.; Bao, H. Pvnet: Pixel-wise voting network for 6dof pose estimation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Long Beach, CA, USA, 16\u201320 June 2019.",
        "ref_ids": [
          "31"
        ]
      },
      "6dof pose estimation of transparent object from a single rgb-d image": {
        "authors": [],
        "url": "https://www.mdpi.com/1424-8220/20/23/6790/pdf",
        "ref_texts": "13. Peng, S.; Liu, Y.; Huang, Q.; Zhou, X.; Bao, H. PVNet: Pixel-Wise Voting Network for 6DoF Pose Estimation. In Proceedings of the 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), Long Beach, CA, USA, 16\u201318 June 2019; pp. 4561\u20134570. [CrossRef]",
        "ref_ids": [
          "13"
        ]
      },
      "Pfrl: Pose-free reinforcement learning for 6d pose estimation": {
        "authors": [
          "Jianzhun Shao",
          "Yuhang Jiang",
          "Gu Wang",
          "Zhigang Li",
          "Xiangyang Ji"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPR_2020/papers/Shao_PFRL_Pose-Free_Reinforcement_Learning_for_6D_Pose_Estimation_CVPR_2020_paper.pdf",
        "ref_texts": "[25] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 4561\u20134570, 2019.",
        "ref_ids": [
          "25"
        ]
      },
      "PointPoseNet: Point pose network for robust 6D object pose estimation": {
        "authors": [
          "Wei Chen",
          "Jinming Duan",
          "Hector Basevi",
          "Hyung Jin",
          "Ales Leonardis"
        ],
        "url": "http://openaccess.thecvf.com/content_WACV_2020/papers/Chen_PonitPoseNet_Point_Pose_Network_for_Robust_6D_Object_Pose_Estimation_WACV_2020_paper.pdf",
        "ref_texts": "[22] S. Peng, Y . Liu, Q. Huang, H. Bao, and X. Zhou. Pvnet: Pixel-wise voting network for 6dof pose estimation. arXiv preprint arXiv:1812.11788 , 2018.",
        "ref_ids": [
          "22"
        ]
      },
      "3d object detection and pose estimation of unseen objects in color images with local surface embeddings": {
        "authors": [
          "Giorgia Pitteri",
          "Aurelie Bugeau",
          "Slobodan Ilic",
          "Vincent Lepetit"
        ],
        "url": "http://openaccess.thecvf.com/content/ACCV2020/papers/Pitteri_3D_Object_Detection_and_Pose_Estimation_of_Unseen_Objects_in_ACCV_2020_paper.pdf",
        "ref_texts": "8. Peng,S.,Liu,Y.,Huang,Q.,Bao,H.,Zhou,X.: PVNet:Pixe l-WiseVotingNetwork for 6DoF Pose Estimation. CoRR abs/1812.11788 (2018)",
        "ref_ids": [
          "8"
        ]
      },
      "Pointvotenet: Accurate object detection and 6 dof pose estimation in point clouds": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1912.09057",
        "ref_texts": "[6]S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao, \u201cPvnet: Pixel-wise voting network for 6dof pose estimation,\u201d in IEEE Conference on Computer Vision and Pattern Recognition , pp. 4561\u20134570, 2019.",
        "ref_ids": [
          "6"
        ]
      },
      "6dof object pose estimation via differentiable proxy voting loss": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2002.03923",
        "ref_texts": "[21] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , pages 4561\u20134570, 2019.",
        "ref_ids": [
          "21"
        ]
      },
      "SymmetryNet: learning to predict reflectional and rotational symmetries of 3D shapes from single-view RGB-D images": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2008.00485",
        "ref_texts": "2001, volume 1, pages I\u2013I. IEEE, 2001. Yanxi Liu, Hagit Hel-Or, Craig S Kaplan, Luc Van Gool, et al. Computational symmetry in computer vision and computer graphics. Foundations and Trends \u00aein Computer Graphics and Vision , 5(1\u20132):1\u2013195, 2010. Giovanni Marola. On the detection of the axes of symmetry of symmetric and almost symmetric planar images. IEEE Transactions on Pattern Analysis and Machine Intelligence , 11(1):104\u2013108, 1989. Aur\u00e9lien Martinet, Cyril Soler, Nicolas Holzschuch, and Fran\u00e7ois X Sillion. Accurate detection of symmetries in 3d shapes. ACM Transactions on Graphics (TOG) , 25(2): 439\u2013464, 2006. Niloy J Mitra, Leonidas J Guibas, and Mark Pauly. Partial and approximate symmetry detection for 3d geometry. In ACM Transactions on Graphics (TOG) , volume 25, pages 560\u2013568. ACM, 2006. Niloy J Mitra, Mark Pauly, Michael Wand, and Duygu Ceylan. Symmetry in 3d geometry: Extraction and applications. In Computer Graphics Forum , volume 32, pages 1\u201323. Wiley Online Library, 2013. Hideo Ogawa. Symmetry analysis of line drawings using the hough transform. Pattern Recognition Letters , 12(1):9\u201312, 1991. Maks Ovsjanikov, Jian Sun, and Leonidas Guibas. Global intrinsic symmetries of shapes. InComputer graphics forum , volume 27, pages 1341\u20131348. Wiley Online Library, 2008. Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, et al. Pytorch: An imperative style, high-performance deep learning library. In Advances in Neural Information Processing Systems , pages 8024\u20138035, 2019. Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. PVNet: Pixel-wise voting network for 6dof pose estimation. In Proc. CVPR , pages 4561\u20134570, 2019. Joshua Podolak, Philip Shilane, Aleksey Golovinskiy, Szymon Rusinkiewicz, and Thomas Funkhouser. A planar-reflective symmetry transform for 3d shapes. In ACM SIGGRAPH 2006 Papers , pages 549\u2013559. 2006. Charles R Qi, Hao Su, Kaichun Mo, and Leonidas J Guibas. Pointnet: Deep learning on point sets for 3d classification and segmentation. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 652\u2013660, 2017. ACM Trans. Graph., Vol. 1, No. 1, Article 1. Publication date: August 2020. SymmetryNet: Learning to Predict Reflectional and Rotational Symmetries of 3D Shapes from Single-View RGB-D Images \u20221:15 D. Raviv, A. M. Bronstein, M. M. Bronstein, and R. Kimmel. Symmetries of non-rigid shapes. In Proc. ICCV , pages 1\u20137. IEEE, 2007. Dan Raviv, Alexander M Bronstein, Michael M Bronstein, and Ron Kimmel. Full and partial symmetries of non-rigid shapes. International journal of computer vision , 89"
      },
      "Occlusion-aware region-based 3D pose tracking of objects with temporally consistent polar-based local partitioning": {
        "authors": [],
        "url": "https://zx007zls.github.io/zls_ch/TIP2020_preprint.pdf",
        "ref_texts": "[46] S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao, \u201cPvnet: Pixelwise voting network for 6dof pose estimation,\u201d in IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2019, pp. 4561\u2013",
        "ref_ids": [
          "46"
        ]
      },
      "Edge enhanced implicit orientation learning with geometric prior for 6D pose estimation": {
        "authors": [],
        "url": "https://haopan.github.io/papers/6dpose.pdf",
        "ref_texts": "[27] S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao, \u201cPvnet: Pixel-wise voting network for 6dof pose estimation,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2019, pp. 4561\u20134570.",
        "ref_ids": [
          "27"
        ]
      },
      "Learning deep network for detecting 3d object keypoints and 6d poses": {
        "authors": [
          "Wanqing Zhao",
          "Shaobo Zhang",
          "Ziyu Guan",
          "Wei Zhao",
          "Jinye Peng",
          "Jianping Fan"
        ],
        "url": "https://openaccess.thecvf.com/content_CVPR_2020/papers/Zhao_Learning_Deep_Network_for_Detecting_3D_Object_Keypoints_and_6D_CVPR_2020_paper.pdf",
        "ref_texts": "[25] S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In CVPR , 2019.",
        "ref_ids": [
          "25"
        ]
      },
      "TANet: towards fully automatic tooth arrangement": {
        "authors": [],
        "url": "https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123600477.pdf",
        "ref_texts": "25. Peng, S., Liu, Y., Huang, Q., Zhou, X., Bao, H.: Pvnet: Pixel-wise voting network for 6dof pose estimation. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. pp. 4561{4570 (2019)",
        "ref_ids": [
          "25"
        ]
      },
      "MaskedFusion: Mask-based 6D object pose estimation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1911.07771",
        "ref_texts": "17. Peng, S., Liu, Y., Huang, Q., Zhou, X., Bao, H.: Pvnet: Pixel-wise voting network for 6dof pose estimation. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. pp. 4561{4570 (2019)",
        "ref_ids": [
          "17"
        ]
      },
      "Introducing pose consistency and warp-alignment for self-supervised 6d object pose estimation in color images": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2003.12344",
        "ref_texts": "[27] S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In CVPR , 2019.",
        "ref_ids": [
          "27"
        ]
      },
      "Super-BPD: Super boundary-to-pixel direction for fast image segmentation": {
        "authors": [
          "Jianqiang Wan",
          "Yang Liu",
          "Donglai Wei",
          "Xiang Bai",
          "Yongchao Xu"
        ],
        "url": "https://openaccess.thecvf.com/content_CVPR_2020/papers/Wan_Super-BPD_Super_Boundary-to-Pixel_Direction_for_Fast_Image_Segmentation_CVPR_2020_paper.pdf",
        "ref_texts": "[32] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. PVNet: Pixel-wise voting network for 6dof pose estimation. In Proc. of CVPR , pages 4561\u20134570, 2019. 3",
        "ref_ids": [
          "32"
        ]
      },
      "Reconstruct locally, localize globally: A model free method for object pose estimation": {
        "authors": [
          "Ming Cai",
          "Ian Reid"
        ],
        "url": "https://openaccess.thecvf.com/content_CVPR_2020/papers/Cai_Reconstruct_Locally_Localize_Globally_A_Model_Free_Method_for_Object_CVPR_2020_paper.pdf",
        "ref_texts": "[40] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In CVPR , 2019. 1,3,8",
        "ref_ids": [
          "40"
        ]
      },
      "Indirect object-to-robot pose estimation from an external monocular rgb camera": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2008.11822",
        "ref_texts": "[3] S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao, \u201cPVNet: Pixel-wise voting network for 6DoF pose estimation,\u201d in CVPR , 2019.",
        "ref_ids": [
          "3"
        ]
      },
      "6DoF Object Pose Estimation via Differentiable Proxy Voting Regularizer.": {
        "authors": [],
        "url": "https://www.bmvc2020-conference.com/assets/papers/0287.pdf",
        "ref_texts": "[21] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , pages 4561\u20134570, 2019.",
        "ref_ids": [
          "21"
        ]
      },
      "Deepurl: Deep pose estimation framework for underwater relative localization": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2003.05523",
        "ref_texts": "[32] S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao, \u201cPVNet: Pixel-wise V oting Network for 6DoF Pose Estimation,\u201d in Proc. CVPR , 2019.",
        "ref_ids": [
          "32"
        ]
      },
      "Neural object learning for 6d pose estimation using a few cluttered images": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2005.03717",
        "ref_texts": "28. Peng, S., Liu, Y., Huang, Q., Zhou, X., Bao, H.: Pvnet: Pixel-wise voting network for 6dof pose estimation. In: The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) (June 2019) 2, 3",
        "ref_ids": [
          "28"
        ]
      },
      "Lit: Light-field inference of transparency for refractive object localization": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1910.00721",
        "ref_texts": "[15] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 4561\u20134570, 2019.",
        "ref_ids": [
          "15"
        ]
      },
      "6 dof pose estimation of textureless objects from multiple rgb frames": {
        "authors": [],
        "url": "https://campar.cs.tum.edu/pub/kaskman2020eccvw/kaskman2020eccvw.pdf",
        "ref_texts": "40. Peng, S., Liu, Y., Huang, Q., Zhou, X., Bao, H.: Pvnet: Pixel-wise voting network for 6dof pose estimation. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. pp. 4561{4570 (2019)",
        "ref_ids": [
          "40"
        ]
      },
      "Dronepose: photorealistic uav-assistant dataset synthesis for 3d pose estimation via a smooth silhouette loss": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2008.08823",
        "ref_texts": "48. Peng, S., Liu, Y., Huang, Q., Zhou, X., Bao, H.: Pvnet: Pixel-wise voting network for 6dof pose estimation. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. pp. 4561{4570 (2019)",
        "ref_ids": [
          "48"
        ]
      },
      "Pixel-pair occlusion relationship map (p2orm): formulation, inference and application": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2007.12088",
        "ref_texts": "36. Peng, S., Liu, Y., Huang, Q., Zhou, X., Bao, H.: PVNet: Pixel-wise voting network for 6DoF pose estimation. In: Conference on Computer Vision and Pattern Recognition (CVPR). pp. 4561{4570 (2019) P2ORM: Formulation, Inference & Application 17",
        "ref_ids": [
          "36"
        ]
      },
      "Spatial attention improves iterative 6D object pose estimation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2101.01659",
        "ref_texts": "[21] S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 4561\u20134570, 2019. 1, 2, 3, 5, 6, 16, 17",
        "ref_ids": [
          "21"
        ]
      },
      "Active 6d multi-object pose estimation in cluttered scenarios with deep reinforcement learning": {
        "authors": [
          "Anonymous Submission"
        ],
        "url": "https://arxiv.org/pdf/1910.08811",
        "ref_texts": "[15] S. Peng, Y . Liu, Q. Huang, H. Bao, and X. Zhou. Pvnet: Pixel-wise voting network for 6dof pose estimation. In CVPR , 2019.",
        "ref_ids": [
          "15"
        ]
      },
      "Robust rgb-based 6-dof pose estimation without real pose annotations": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2008.08391",
        "ref_texts": "23. Peng, S., Liu, Y., Huang, Q., Zhou, X., Bao, H.: Pvnet: Pixel-wise voting network for 6dof pose estimation. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR). pp. 4561{4570 (2019)",
        "ref_ids": [
          "23"
        ]
      },
      "How to track your dragon: A multi-attentional framework for real-time rgb-d 6-dof object pose tracking": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2004.10335",
        "ref_texts": "31. Peng, S., Liu, Y., Huang, Q., Zhou, X., Bao, H.: Pvnet: Pixel-wise voting network for 6dof pose estimation. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. pp. 4561{4570 (2019)",
        "ref_ids": [
          "31"
        ]
      },
      "Fully convolutional geometric features for category-level object alignment": {
        "authors": [
          "Qiaojun Feng",
          "Nikolay Atanasov"
        ],
        "url": "https://arxiv.org/pdf/2103.04494",
        "ref_texts": "[13] S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao, \u201cPVNet: Pixel-Wise V oting Network for 6DoF Pose Estimation,\u201d in IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) , June 2019, pp.",
        "ref_ids": [
          "13"
        ]
      },
      "Multi-view shape estimation of transparent containers": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1911.12354",
        "ref_texts": "[6] S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao, \u201cPVNet: Pixel-wise voting network for 6DoF pose estimation,\u201d in Proc. IEEE Conf. Comput. Vis. Pattern Recognit. , Long Beach, CA, USA, 16\u201320 June 2019.",
        "ref_ids": [
          "6"
        ]
      },
      "Prima6d: rotational primitive reconstruction for enhanced and robust 6d pose estimation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2006.07789",
        "ref_texts": "[1] S. Peng, Y . Liu, Q. Huang, H. Bao, and X. Zhou, \u201cPvnet: Pixel-wise voting network for 6dof pose estimation,\u201d 12 2018.",
        "ref_ids": [
          "1"
        ]
      },
      "Towards an egocentric framework for rigid and articulated object tracking in virtual reality": {
        "authors": [],
        "url": "https://wevr.adalsimeone.me/2020/WEVR2020_Taylor.pdf",
        "ref_texts": "[24] S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In IEEE Conf. on Comp. Vision and Pattern Recognition , 2019.",
        "ref_ids": [
          "24"
        ]
      },
      "3d-aware ellipse prediction for object-based camera pose estimation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2105.11494",
        "ref_texts": "[24] S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2019, Long Beach, CA, USA, June 16-20, 2019 , pages 4561\u20134570. Computer Vision Foundation / IEEE, 2019.",
        "ref_ids": [
          "24"
        ]
      },
      "Deep soft procrustes for markerless volumetric sensor alignment": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2003.10176",
        "ref_texts": "[30] S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao. PVNet: Pixel-wise voting network for 6dof pose estimation. In Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR , pp. 4561\u20134570, 2019.",
        "ref_ids": [
          "30"
        ]
      },
      "Pose estimation of primitive-shaped objects from a depth image using superquadric representation": {
        "authors": [],
        "url": "https://www.mdpi.com/2076-3417/10/16/5442/pdf",
        "ref_texts": "3. Peng, S.; Liu, Y.; Huang, Q.; Zhou, X.; Bao, H. PVNet: Pixel-wise Voting Network for 6DoF Pose Estimation. In Proceedings of the CVPR 2019, Long Beach, CA, USA, 15\u201321 June 2019.",
        "ref_ids": [
          "3"
        ]
      },
      "Pose proposal critic: Robust pose refinement by learning reprojection errors": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2005.06262",
        "ref_texts": "[18] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. PVNet: Pixel-wise voting network for 6DoF pose estimation. In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , June 2019.",
        "ref_ids": [
          "18"
        ]
      },
      "End-to-end learning improves static object geo-localization in monocular video": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2004.05232",
        "ref_texts": "[32] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixel-wise voting network for 6DoF pose estimation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 4561\u20134570, 2019.",
        "ref_ids": [
          "32"
        ]
      },
      "End-to-end differentiable 6DoF object pose estimation with local and global constraints": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2011.11078",
        "ref_texts": "[9]S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao, \u201cPvnet: Pixel-wise voting network for 6dof pose estimation,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , 2019, pp. 4561\u20134570.",
        "ref_ids": [
          "9"
        ]
      },
      "Iterative pose refinement for object pose estimation based on RGBD data": {
        "authors": [],
        "url": "https://www.mdpi.com/1424-8220/20/15/4114/pdf",
        "ref_texts": "13. Peng, S.; Liu, Y.; Huang, Q.; Zhou, X.; Bao, H. Pvnet: pixel-wise voting network for 6dof pose estimation. In Proceedings of the 2019 IEEE /CVF Conference on Computer Vision and Pattern Recognition (CVPR), Long Beach, CA, USA, 15\u201321 June 2019.",
        "ref_ids": [
          "13"
        ]
      },
      "A 3D real object recognition and localization on SLAM based augmented reality environment": {
        "authors": [
          "Jongin Choe",
          "Ang University",
          "Sanghyun Seo",
          "Ang University"
        ],
        "url": "https://american-cse.org/sites/csci2020proc/pdfs/CSCI2020-6SccvdzjqC7bKupZxFmCoA/762400a745/762400a745.pdf",
        "ref_texts": "[8] Peng, S., Liu, Y., Huang, Q., Zhou, X., and Bao, H, \"Pvnet: Pix el-wise voting network for 6dof pose estimation,\" Proceedings of the IE EE Conference on Computer Vision and Pattern Recognition, pp. 4561 4570, 2019. ",
        "ref_ids": [
          "8"
        ]
      },
      "Pose estimation of specular and symmetrical objects": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2011.00372",
        "ref_texts": "[17] S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao, \u201cPvnet: Pixelwise voting network for 6dof pose estimation,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , 2019, pp. 4561\u20134570.",
        "ref_ids": [
          "17"
        ]
      },
      "3DPVNet: Patch-level 3D Hough Voting Network for 6D Pose Estimation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2009.06887",
        "ref_texts": "[26] S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao. Pvnet: Pixelwise voting network for 6dof pose estimation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 4561\u20134570, 2019. 1, 2",
        "ref_ids": [
          "26"
        ]
      },
      "3D point-to-keypoint voting network for 6D pose estimation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2012.11938",
        "ref_texts": "[6] S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao, \u201cPvnet: Pixel-wise voting network for 6dof pose estimation,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , 2019, pp.",
        "ref_ids": [
          "6"
        ]
      },
      "Lyrn (lyapunov reaching network): A real-time closed loop approach from monocular vision": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2005.12072",
        "ref_texts": "[11] S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao, \u201cPvnet: Pixel-wise voting network for 6dof pose estimation,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , 2019, pp.",
        "ref_ids": [
          "11"
        ]
      },
      "Kosnet: A unified keypoint, orientation and scale network for probabilistic 6d pose estimation": {
        "authors": [],
        "url": "http://groups.csail.mit.edu/robotics-center/public_papers/Hashimoto20.pdf",
        "ref_texts": "[19] S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao, \u201cPVNet: Pixel-wise V oting Network for 6DoF Pose Estimation,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , 2019, pp. 4561\u20134570.",
        "ref_ids": [
          "19"
        ]
      },
      "Pam: Point-wise attention module for 6d object pose estimation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2008.05242",
        "ref_texts": "[20] S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao, \u201cPvnet: Pixel-wise voting network for 6dof pose estimation,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , 2019, pp.",
        "ref_ids": [
          "20"
        ]
      },
      "Model-free Bin-Picking: Food Processing and Parcel Processing Use Cases": {
        "authors": [],
        "url": "https://i-rim.it/wp-content/uploads/2020/12/I-RIM_2020_paper_153.pdf",
        "ref_texts": "[5] S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao, \u201cPvnet: Pixel-wise voting network for 6dof pose estimation,\u201d in CVPR , 2019.",
        "ref_ids": [
          "5"
        ]
      },
      "Generative model for spacecraft image synthesis using limited dataset": {
        "authors": [],
        "url": "https://taehajeffpark.com/files/papers/parkdamico_aas2020.pdf",
        "ref_texts": "[19] S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao, \u201cPVNet: Pixel-wise V oting Network for 6DoF Pose Estimation,\u201d The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) Oral , 2019.",
        "ref_ids": [
          "19"
        ]
      },
      "Instance-specific 6-dof object pose estimation from minimal annotations": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2207.13264",
        "ref_texts": "[2] S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao, \u201cPvnet: Pixel-wise voting network for 6dof pose estimation,\u201d in IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2019.",
        "ref_ids": [
          "2"
        ]
      },
      "Robotic assembly, using RGBD-based object pose estimation & grasp detection.": {
        "authors": [
          "Jaana Kunnari"
        ],
        "url": "https://trepo.tuni.fi/bitstream/handle/10024/123320/AhmadSaad.pdf?sequence=2",
        "ref_texts": "[37] Peng, S. et al. \u201cPVNet: Pixel -Wise Voting Network for 6DoF Pose Estimation.\u201d ",
        "ref_ids": [
          "37"
        ]
      },
      "Usability Study of Learning-Based Pose Estimation of Industrial Objects from Synthetic Depth Data": {
        "authors": [
          "Stefan Thalhammer"
        ],
        "url": "https://link.springer.com/content/pdf/10.1007/978-3-030-72632-4_21.pdf",
        "ref_texts": "17. Peng, S., Liu, Y., Huang, Q., Bao, H., Zhou, X.: PVNet: Pixel-wise voting network for 6DoF pose estimation. In: The IEEE Conference on Computer Vision and Pattern Recognition, pp. 4561\u20134570 (2019)",
        "ref_ids": [
          "17"
        ]
      },
      "Neural Object Learning for 6D Pose Estimation Using a Few Cluttered Images": {
        "authors": [],
        "url": "https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123490630.pdf",
        "ref_texts": "28. Peng, S., Liu, Y., Huang, Q., Zhou, X., Bao, H.: Pvnet: Pixel-wise voting network for 6dof pose estimation. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR). pp. 4556{4565 (June 2019)",
        "ref_ids": [
          "28"
        ]
      },
      "Deep object 6-DoF pose estimation using instance segmentation": {
        "authors": [],
        "url": "https://alife-robotics.co.jp/members2020/icarob/data/html/data/OS/OS24/OS24-1.pdf",
        "ref_texts": "7. Peng, Sida & Liu, Yuan & Huang, Qixing & Bao, Hujun & Zhou, PVNet: Pixel-wise Voti ng Network for 6DoF Pose Estimation, Xiaowei, 2018. ",
        "ref_ids": [
          "7"
        ]
      },
      "R-SAC: Reinforcement Sample Consensus": {
        "authors": [],
        "url": "https://openreview.net/pdf?id=Urn3WzRwhXO",
        "ref_texts": "[13] S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. InProceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 4561\u20134570, 2019.",
        "ref_ids": [
          "13"
        ]
      },
      "UV Mapping Based Pose Estimation of Furniture Parts in Assembly Manuals": {
        "authors": [],
        "url": "https://koreascience.kr/article/CFKO202023758834479.pdf",
        "ref_texts": "[9] Peng, Sida, et al. \"Pvnet: Pixel-wise voting network for 6dof pose estimation.\" Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2019.",
        "ref_ids": [
          "9"
        ]
      },
      "Supplement to \u201cPose Proposal Critic: Robust Pose Refinement by Learning Reprojection Errors\u201d": {
        "authors": [],
        "url": "https://research.chalmers.se/publication/538336/file/538336_AdditionalFile_dad0f2b5.pdf",
        "ref_texts": "[9]Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. PVNet: Pixelwise voting network for 6DoF pose estimation. In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , June 2019. BRYNTE, KAHL: SUPPLEMENT TO \u201cPOSE PROPOSAL CRITIC\u201d 9",
        "ref_ids": [
          "9"
        ]
      },
      "Model-based 3D Tracking for Augmented Orthopedic Surgery": {
        "authors": [],
        "url": "https://hal.science/hal-03022939/document",
        "ref_texts": "[9] S Peng, Y Liu, Q Huang, X Zhou, H Bao. Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition . (2018) . Pvnet: Pixel -wise voting network for 6dof pose estimation . ",
        "ref_ids": [
          "9"
        ]
      },
      "Review on 6D Object Pose Estimation With the Focus on Indoor Scene Understanding. 2022\u037e 2 (4): 41": {
        "authors": [],
        "url": "https://www.oajaiml.com/uploads/archivepdf/24821141.pdf",
        "ref_texts": "[41] Peng S, Liu Y , Huang Q, Zhou X, Bao H. Pvnet: Pixel-Wise V oting Network for 6DOF Pose Estimation. InProceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2019:4561-4570.",
        "ref_ids": [
          "41"
        ]
      },
      "What Supervision Scales? Practical Learning Through Interaction": {
        "authors": [],
        "url": "https://escholarship.org/content/qt38x6942b/qt38x6942b.pdf",
        "ref_texts": "[112] Sida Peng et al. \u201cPVNet: Pixel-wise V oting Network for 6DoF Pose Estimation\u201d. In: CVPR .",
        "ref_ids": [
          "112"
        ]
      },
      "Automatic 3D Object Recognition and Localization for Robotic Grasping": {
        "authors": [],
        "url": "https://repositorio-aberto.up.pt/bitstream/10216/132916/2/419215.pdf",
        "ref_texts": "[29] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) , Jun 2019. URL: http://dx.doi.org/10.1109/CVPR.",
        "ref_ids": [
          "29"
        ]
      },
      "Deep Snake for Real-Time Instance Segmentation": {
        "authors": [],
        "url": "https://ask.qcloudimg.com/draft/6837186/79j1ad13cu.pdf",
        "ref_texts": "[30] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In CVPR , 2019. 3",
        "ref_ids": [
          "30"
        ]
      },
      "\u7269\u54c1\u63b4\u307f\u4e0a\u3052\u4f5c\u696d\u3067\u6c42\u3081\u3089\u308c\u308b\u8996\u899a\u6a5f\u80fd": {
        "authors": [],
        "url": "https://www.jstage.jst.go.jp/article/jrsj/38/6/38_38_538/_pdf",
        "ref_texts": "[14] S. Peng, et al.: \u201cPVNet: Pixel-wise Voting Network for 6DoF Pose Estimation,\u201d CVPR, pp.4556\u20134565, 2019.",
        "ref_ids": [
          "14"
        ]
      },
      "20 (V)\u20121 \u899a\u9192\u4e0b\u8133\u816b\u760d\u6458\u51fa\u8853\u306b\u304a\u3051\u308b\u9855\u5fae\u93e1\u753b\u50cf\u3078\u306e\u8133\u69cb\u9020\u30fb\u63a8\u5b9a\u8133\u6a5f\u80fd\u4f4d\u7f6e\u91cd\u7573\u8868\u793a": {
        "authors": [],
        "url": "https://www.jstage.jst.go.jp/article/jscas/22/4/22_301/_pdf",
        "ref_texts": " 3) Peng S, Liu Y , Huang Q, et al. Pvnet: Pixel\u2012wise voting network for 6dof pose estimation. IEEE CVPR 2019."
      },
      "Visual slam in dynamic environments": {
        "authors": [],
        "url": "https://zaguan.unizar.es/record/100672/files/TESIS-2021-083.pdf",
        "ref_texts": "104 Mur-Artal, R. & Tard\u0013 os, J. D. (2017), `ORB-SLAM2: An open-source slam system for monocular, stereo, and RGB-D cameras', IEEE T-RO . Newcombe, R. A., Lovegrove, S. J. & Davison, A. J. (2011), DTAM: Dense tracking and mapping in real-time, in `ICCV', IEEE. Oquab, M., Bottou, L., Laptev, I. & Sivic, J. (2014), Learning and transferring midlevel image representations using convolutional neural networks, in `Proceedings of the IEEE conference on computer vision and pattern recognition', pp. 1717{1724. Pathak, D., Krahenbuhl, P., Donahue, J., Darrell, T. & Efros, A. A. (2016), Context encoders: Feature learning by inpainting, in `Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition', pp. 2536{2544. Paz, L. M., Pini\u0013 es, P., Tard\u0013 os, J. D. & Neira, J. (2008), `Large-scale 6-dof slam with stereo-in-hand', IEEE transactions onrobotics 24(5), 946{957. Peng, S., Liu, Y., Huang, Q., Zhou, X. & Bao, H. (2019), Pvnet: Pixel-wise voting network for 6dof pose estimation, in `Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition', pp. 4561{4570. Peris, M., Martull, S., Maki, A., Ohkawa, Y. & Fukui, K. (2012), Towards a simulation driven stereo vision system, in `Pattern Recognition (ICPR), 2012 21st International Conference on', IEEE, pp. 1038{1042. Pinheiro, P. O., Lin, T.-Y., Collobert, R. & Doll\u0013 ar, P. (2016), Learning to reffne object segments, in `European conference on computer vision', Springer, pp. 75{91. Porav, H., Maddern, W. & Newman, P. (2018), `Adversarial training for adverse conditions: Robust metric localisation using appearance transfer', IEEE International Conference onRobotics andAutomation . Ren, S., He, K., Girshick, R. & Sun, J. (2015), Faster r-cnn: Towards real-time object detection with region proposal networks, in `Advances in neural information processing systems', pp. 91{99. Ren, X. & Malik, J. (2003), Learning a classiffcation model for segmentation, in `nternational Conference on Computer Vision', IEEE, p. 10. Riazuelo, L., Montano, L. & Montiel, J. M. M. (2017), `Semantic visual SLAM in populated environments', ECMR . Rogers, J. G., Trevor, A. J., Nieto-Granda, C. & Christensen, H. I. (2010), SLAM with expectation maximization for moveable object tracking, in `2010 IEEE/RSJ International Conference on Intelligent Robots and Systems', IEEE, pp. 2077{2082. Romera, E., Alvarez, J. M., Bergasa, L. M. & Arroyo, R. (2017), `ERFNet', https: //github.com/Eromera/erfnet. Romera, E., Alvarez, J. M., Bergasa, L. M. & Arroyo, R. (2018), `ERFNet: Eflcient Residual Factorized ConvNet for Real-Time Semantic Segmentation', IEEE Transactions onIntelligent Transportation Systems 19(1), 263{272."
      },
      "Learning to Estimate 3D Object Pose from Synthetic Data": {
        "authors": [
          "Sergey Zakharov"
        ],
        "url": "https://mediatum.ub.tum.de/doc/1550255/document.pdf",
        "ref_texts": "[93]S. Peng, Y. Liu, Q. Huang, X. Zhou, and H. Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2019.",
        "ref_ids": [
          "93"
        ]
      },
      "Dpod: 6d pose object detector and refiner": {
        "authors": [
          "Sergey Zakharov",
          "Ivan Shugurov",
          "Slobodan Ilic"
        ],
        "url": "https://openaccess.thecvf.com/content_ICCV_2019/papers/Zakharov_DPOD_6D_Pose_Object_Detector_and_Refiner_ICCV_2019_paper.pdf",
        "ref_texts": "[25] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 4561\u20134570, 2019.",
        "ref_ids": [
          "25"
        ]
      },
      "Satellite pose estimation with deep landmark regression and nonlinear pose refinement": {
        "authors": [
          "Bo Chen",
          "Jiewei Cao",
          "Alvaro Parra",
          "Jun Chin"
        ],
        "url": "http://openaccess.thecvf.com/content_ICCVW_2019/papers/R6D/Chen_Satellite_Pose_Estimation_with_Deep_Landmark_Regression_and_Nonlinear_Pose_ICCVW_2019_paper.pdf",
        "ref_texts": "[26] S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In CVPR , 2019. 2,3",
        "ref_ids": [
          "26"
        ]
      },
      "Towards robust learning-based pose estimation of noncooperative spacecraft": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1909.00392",
        "ref_texts": "[21] S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao, \u201cPVNet: Pixel-wise V oting Network for 6DoF Pose Estimation,\u201d The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) Oral , 2019.",
        "ref_ids": [
          "21"
        ]
      },
      "On object symmetries and 6d pose estimation from images": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1908.07640",
        "ref_texts": "[22] S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao. PVNet: Pixel-Wise V oting Network for 6DoF Pose Estimation. In Conference on Computer Vision and Pattern Recognition , 2019. 1, 2, 6",
        "ref_ids": [
          "22"
        ]
      },
      "ConvPoseCNN: Dense convolutional 6D object pose estimation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1912.07333",
        "ref_texts": "[22] S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao, \u201cPvnet: Pixel-wise voting network for 6dof pose estimation,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , 2019, pp. 4561\u20134570.",
        "ref_ids": [
          "22"
        ]
      },
      "Cullnet: Calibrated and pose aware confidence scores for object pose estimation": {
        "authors": [
          "Kartik Gupta",
          "Lars Petersson",
          "Richard Hartley"
        ],
        "url": "http://openaccess.thecvf.com/content_ICCVW_2019/papers/R6D/Gupta_CullNet_Calibrated_and_Pose_Aware_Confidence_Scores_for_Object_Pose_ICCVW_2019_paper.pdf",
        "ref_texts": "[17] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 4561\u20134570, 2019. 3",
        "ref_ids": [
          "17"
        ]
      },
      "CorNet: generic 3D corners for 6D pose estimation of new objects without retraining": {
        "authors": [
          "Giorgia Pitteri",
          "Slobodan Ilic",
          "Vincent Lepetit"
        ],
        "url": "http://openaccess.thecvf.com/content_ICCVW_2019/papers/R6D/Pitteri_CorNet_Generic_3D_Corners_for_6D_Pose_Estimation_of_New_ICCVW_2019_paper.pdf",
        "ref_texts": "[24] S. Peng, Y . Liu, Q. Huang, H. Bao, and X. Zhou. Pvnet: Figure 9: Some qualitative results on Object #20 in Scene #13 of the T-LESS dataset. Figure 10: Some qualitative results on Object #20 in Scene #14 of the T-LESS dataset. Figure 11: Some qualitative results on Object #26 and Object #29 in Scene #15 of the T-LESS dataset. Pixel-Wise V oting Network for 6DoF Pose Estimation. CoRR , abs/1812.11788, 2018.",
        "ref_ids": [
          "24"
        ]
      },
      "W-posenet: Dense correspondence regularized pixel pair pose regression": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1912.11888",
        "ref_texts": "[20] S. Peng, Y . Liu, Q. Huang, X. Zhou, and H. Bao, \u201cPvnet: Pixel-wise voting network for 6dof pose estimation,\u201d in CVPR , 2019.",
        "ref_ids": [
          "20"
        ]
      },
      "Car Pose in Context: Accurate Pose Estimation with Ground Plane Constraints": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1912.04363",
        "ref_texts": "[36] Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In CVPR , 2019. 2",
        "ref_ids": [
          "36"
        ]
      },
      "Evaluating Computer Vision Methods for Detection and Pose Estimation of Textureless Objects": {
        "authors": [
          "Name Last"
        ],
        "url": "https://uis.brage.unit.no/uis-xmlui/bitstream/handle/11250/2620242/Skutvik_Harald_Thirud.pdf?sequence=1",
        "ref_texts": "[10]Sida Peng, Yuan Liu, Qixing Huang, Hujun Bao, and Xiaowei Zhou. Pvnet: Pixelwise voting network for 6dof pose estimation. CoRR, abs/1812.11788, 2018. URL http://arxiv.org/abs/1812.11788 .",
        "ref_ids": [
          "10"
        ]
      }
    }
  },
  {
    "title": "consistent depth maps recovery from a video sequence",
    "id": 1,
    "valid_pdf_number": "147/216",
    "matched_pdf_number": "0/147",
    "matched_rate": 0.0,
    "citations": {
      "3d object detection from images for autonomous driving: a survey": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2202.02980",
        "ref_texts": "[175] G. Zhang, J. Jia, T.-T. Wong, and H. Bao, \u201cConsistent depth maps recovery from a video sequence,\u201d T-P AMI , 2009.",
        "ref_ids": [
          "175"
        ]
      },
      "The temporal opportunist: Self-supervised multi-frame monocular depth": {
        "authors": [
          "Jamie Watson",
          "Oisin Mac",
          "Victor Prisacariu",
          "Gabriel Brostow",
          "Michael Firman"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2021/papers/Watson_The_Temporal_Opportunist_Self-Supervised_Multi-Frame_Monocular_Depth_CVPR_2021_paper.pdf",
        "ref_texts": "[96] Guofeng Zhang, Jiaya Jia, Tien-Tsin Wong, and Hujun Bao. Consistent depth maps recovery from a video sequence. PAMI , 2009.",
        "ref_ids": [
          "96"
        ]
      },
      "Depth transfer: Depth extraction from video using non-parametric sampling": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2001.00987",
        "ref_texts": "[23] G. Zhang, J. Jia, T.-T. Wong, and H. Bao, \u201cConsistent depth maps recovery from a video sequence,\u201d IEEE TP AMI , vol. 31, pp. 974\u2013988, 2009.",
        "ref_ids": [
          "23"
        ]
      },
      "Novel view synthesis of dynamic scenes with globally coherent depths from a monocular camera": {
        "authors": [
          "Jae Shin",
          "Kihwan Kim",
          "Orazio Gallo",
          "Hyun Soo",
          "Jan Kautz"
        ],
        "url": "https://openaccess.thecvf.com/content_CVPR_2020/papers/Yoon_Novel_View_Synthesis_of_Dynamic_Scenes_With_Globally_Coherent_Depths_CVPR_2020_paper.pdf",
        "ref_texts": "[56] Guofeng Zhang, Jiaya Jia, Tien-Tsin Wong, and Hujun Bao. Consistent depth maps recovery from a video sequence. TPAMI, year=2009, .",
        "ref_ids": [
          "56"
        ]
      },
      "Multi-view depth estimation using epipolar spatio-temporal networks": {
        "authors": [
          "Xiaoxiao Long",
          "Lingjie Liu",
          "Wei Li",
          "Christian Theobalt",
          "Wenping Wang"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2021/papers/Long_Multi-view_Depth_Estimation_using_Epipolar_Spatio-Temporal_Networks_CVPR_2021_paper.pdf",
        "ref_texts": "[45] Guofeng Zhang, Jiaya Jia, Tien-Tsin Wong, and Hujun Bao. Consistent depth maps recovery from a video sequence. IEEE Transactions on pattern analysis and machine intelligence , 31(6):974\u2013988, 2009. 1",
        "ref_ids": [
          "45"
        ]
      },
      "Haze visibility enhancement: A survey and quantitative benchmarking": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1607.06235",
        "ref_texts": "[28] G. Zhang, J. Jia, T.-T. Wong, and H. Bao, \u201cConsistent depth maps recovery from a video sequence,\u201d IEEE Trans. Pattern Analysis and Machine Intelligence , vol. 31, no. 6, pp. 974\u2013988, 2009.",
        "ref_ids": [
          "28"
        ]
      },
      "Light field reconstruction using shearlet transform": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1509.08969",
        "ref_texts": ""
      },
      "Simultaneous video defogging and stereo reconstruction": {
        "authors": [],
        "url": "https://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Li_Simultaneous_Video_Defogging_2015_CVPR_paper.pdf",
        "ref_texts": "[43] G. Zhang, J. Jia, T.-T. Wong, and H. Bao. Consistent depth maps recovery from a video sequence. IEEE Trans. Pattern Anal. Mach. Intell. , 31(6):974\u2013988, 2009. 2,3,5,6,7,8",
        "ref_ids": [
          "43"
        ]
      },
      "Pixelnet: Representation of the pixels, by the pixels, and for the pixels": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1702.06506",
        "ref_texts": "[98] G. Zhang, J. Jia, T.-T. Wong, and H. Bao. Consistent depth maps recovery from a video sequence. IEEE Transactions on Pattern Analysis and Machine Intelligence , 31(6):974\u2013",
        "ref_ids": [
          "98"
        ]
      },
      "Fast depth densification for occlusion-aware augmented reality": {
        "authors": [],
        "url": "https://dl.acm.org/doi/pdf/10.1145/3272127.3275083",
        "ref_texts": "2014. Occluding Contours for Multi-view Stereo. Conference on Computer Vision and Pattern Recognition (2014), 4002\u20134009. Jan St\u00fchmer, Stefan Gumhold, and Daniel Cremers. 2010. Real-time Dense Geometry from a Handheld Camera. Proceedings of the 32Nd DAGM Conference on Pattern Recognition (2010), 11\u201320. Richard Szeliski. 2006. Locally Adapted Hierarchical Basis Preconditioning. ACM Trans. Graph. 25, 3 (2006), 1135\u20131143. Chamara Saroj Weerasekera, Thanuja Dharmasiri, Ravi Garg, Tom Drummond, and Ian Reid. 2018. Just-in-Time Reconstruction: Inpainting Sparse Maps using Single View Depth Predictors as Priors. arXiv preprint arXiv:1805.04239 (2018). Guofeng Zhang, Jiaya Jia, Tien-Tsin Wong, and Hujun Bao. 2009. Consistent Depth Maps Recovery from a Video Sequence. Transactions on Pattern Analysis and Machine Intelligence (TPAMI) 31, 6 (2009), 974\u2013988. Yinda Zhang and Thomas Funkhouser. 2018. Deep Depth Completion of a Single RGB-D Image. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition . 175\u2013185. ACM Transactions on Graphics, Vol. 37, No. 6, Article 194. Publication date: November 2018.",
        "ref_ids": [
          "2014"
        ]
      },
      "Point cloud noise and outlier removal for image-based 3D reconstruction": {
        "authors": [],
        "url": "http://disneyresearch.s3.amazonaws.com/wp-content/uploads/20161014174414/Point-Cloud-Noise-and-Outlier-Removal-for-Image-Based-3D-Reconstruction-Paper.pdf",
        "ref_texts": "[45] G. Zhang, J. Jia, T. Wong, and H. Bao. Consistent depth maps recovery from a video sequence. IEEE Transactions on Pattern Analysis and Machine Intelligence , 31(6):974\u2013988, 2009. 2,5,6",
        "ref_ids": [
          "45"
        ]
      },
      "Graph-based segmentation for colored 3D laser point clouds": {
        "authors": [],
        "url": "https://april.eecs.umich.edu/media/pdfs/strom2010.pdf",
        "ref_texts": "[19] G. Zhang, J. Jia, T.-T. Wong, and H. Bao. Consistent depth maps recovery from a video sequence. Pattern Analysis and Machine Intelligence, IEEE Transactions on , 31(6):974 \u2013988, june 2009.",
        "ref_ids": [
          "19"
        ]
      },
      "Light field image compression using generative adversarial network-based view synthesis": {
        "authors": [],
        "url": "https://hpc.pku.edu.cn/docs/pdf/a20191230083.pdf",
        "ref_texts": "[13] G. Zhang, J. Jia, T.-T. Wong, and H. Bao, \u201cConsistent depth maps recovery from a video sequence,\u201d IEEE Trans. Pattern Anal. Mach. Intell. , vol. 31, no. 6, pp. 974\u2013988, Jun. 2009.",
        "ref_ids": [
          "13"
        ]
      },
      "Multi-touch authentication using hand geometry and behavioral information": {
        "authors": [],
        "url": "https://sites.coecis.cornell.edu/muri/files/2019/08/Zhang-4-Multi-Touch-Oakland.pdf",
        "ref_texts": ""
      },
      "Multi-viewpoint panorama construction with wide-baseline images": {
        "authors": [],
        "url": "http://www.cad.zju.edu.cn/home/gfzhang/projects/panorama/pano-tip-print.pdf",
        "ref_texts": "[11] G. Zhang, J. Jia, T.-T. Wong, and H. Bao, \u201cConsistent depth maps recovery from a video sequence,\u201d IEEE Trans. Pattern Anal. Mach. Intell. , vol. 31, no. 6, pp. 974\u2013988, Jun. 2009.",
        "ref_ids": [
          "11"
        ]
      },
      "Efficient 3D object segmentation from densely sampled light fields with applications to 3D reconstruction": {
        "authors": [],
        "url": "http://disneyresearch.s3.amazonaws.com/wp-content/uploads/20160607202116/Efficient-3D-Object-Segmentation-from-Densely-Sampled-Light-Fields-with-Applications-to-3D-Reconstruction-Paper.pdf",
        "ref_texts": "2792\u20132799. Guofeng Zhang, Jiaya Jia, Tien-Tsin Wong, and Hujun Bao. 2009. Consistent depth maps recovery from a video sequence. IEEE Trans. Pattern Anal. Mach. Intell. 31, 6, 974\u2013988. Received September 2015; revised January 2016; accepted January 2016 ACM Transactions on Graphics, V ol. 35, No. 3, Article 22, Publication date: March 2016."
      },
      "Controlling unmanned aerial vehicles to avoid obstacle collision": {
        "authors": [],
        "url": "https://patentimages.storage.googleapis.com/de/74/20/dd0258949bccaf/US10665115.pdf"
      },
      "Quality index for stereoscopic images by separately evaluating adding and subtracting": {
        "authors": [
          "Jiachen Yang",
          "Yancong Lin",
          "Zhiqun Gao",
          "Zhihan Lv",
          "Wei Wei",
          "Houbing Song"
        ],
        "url": "https://journals.plos.org/plosone/article/file?id=10.1371/journal.pone.0145800&type=printable",
        "ref_texts": "3. Zhang G, Jia J, Wong TT, Bao H. Consistent depth maps recovery from a video sequence. Pattern Analysis and Machine Intelligence, IEEE Transactions on. 2009; 31(6):974 \u2013988. doi: 10.1109/TPAMI.",
        "ref_ids": [
          "3"
        ]
      },
      "Fast and accurate depth estimation from sparse light fields": {
        "authors": [
          "Tiffany Mc"
        ],
        "url": "https://arxiv.org/pdf/1812.06856",
        "ref_texts": "[28] G. Zhang, J. Jia, T. T. Wong, H. Bao, \"Consistent depth maps recovery from a video sequence\", IEEE Trans. Pattern Anal. Mach. Intell. , vol. 31, no. 6, pp. 974 -988, 2009. ",
        "ref_ids": [
          "28"
        ]
      },
      "Photogeometric scene flow for high-detail dynamic 3d reconstruction": {
        "authors": [
          "Paulo F. U",
          "Tomas Simon",
          "Yaser Sheikh",
          "Iain Matthews"
        ],
        "url": "https://openaccess.thecvf.com/content_iccv_2015/papers/Gotardo_Photogeometric_Scene_Flow_ICCV_2015_paper.pdf",
        "ref_texts": "[34] G. Zhang, J. Jia, T.-T. Wong, and H. Bao. Consistent depth maps recovery from a video sequence. IEEE Trans. PAMI , 31(6):974\u2013988, 2009. 5",
        "ref_ids": [
          "34"
        ]
      },
      "Spatio-temporal video segmentation of static scenes and its applications": {
        "authors": [],
        "url": "https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=ff326f2fa60f756f2bd51ea8575d3bb0bf42cfdc",
        "ref_texts": "4 IEEE TRANSACTIONS ON MULTIMEDIA, VOL. 17, NO. 1, JANUARY 2015 are dif ficult to achieve high-quality segmentation results and usually produce inaccurate obj ect boundaries due to the motion ambiguity and the dif ficulty of accurate optical flow estimation. Some works combined color and motion cues for spatio-temporal segmentation. Khan and Shah [13] proposed a MAPframework for video segmentation combining multiple cues in-cluding spatial location, color and motion. For video segmentation, both spatial and temporal dimensions should be considered. Most approaches handled these twotypes of dimensions separatel y. For example, many approaches [16], [17] first performed spatial segmentation of each frame, and then performed temporal grouping to obtain spatio-tem-poral volumes. Due to the complexity of color, motion andocclusions in a video, it is challenging for spatial segmentationto produce very consistent segments in different images, sothe obtained spatio-temporal segments by temporal groupingwill easily contain obvious artif acts. Some methods [18]\u2013[22] employed an online scheme to obtain consistent segmentsacross frames, that each frame was segmented according to thesegmentation information propagated from previous frames.Zitnick et al. [15] proposed to comb ine segmentation and optical flow estimation together to produce consistent segments for a pair of images. V\u00e1zquez-Reina et al. [23] proposed to extract multiple super-pixel flow trajectories as segmentation hypotheses and temporally segment the video by the compe-tition of the trajectories. Galasso et al. [24] proposed a novel spectral clustering framework by incorporating motion based superpixel af finities. Chang et al. [22] developed a temporal superpixel video representation by modeling temporal flow through bilateral Gaussian process. However, it is dif ficult for all these methods to handle signi ficant occlusions, where large groups of segments appear or disappear. Our method uses amatching graph to initialize volume segments, which is similarto the super-pixel flow hypothesis in [23]. Different from [23], our method achieves more consistent spatio-temporal volumesegmentation in an iterative optimization way, and betterhandles the occlusion problem by incorporating 3D depth in-formation. Recently, Abramov et al. [25] proposed a real-time spatio-temporal segmentation method for color/depth videos captured by a Kinect, which is quite similar to our depth-basedscheme. However, [25] only used depths to improve interactionweights and temporal consistency was enhanced by opticalflow, while our segmentation uses depth information for collecting multi-view statistics t o ensure temporal consistency. Some space-time segmentation methods [11], [12] were proposed to combine spatial and temporal grouping together, bytreating the image sequence a s a 3D space-time volume and attempting a segmentation of pixel volumes. These methods typ-ically constructed a weighted graph by taking each pixel as anode and connecting the pixels in the spatio-temporal neighbor-hood of each other. Normalized cuts was typically used to par-tition the spatio-temporal volume. Some space-time segmenta-tion methods de fined a high dimensional feature vector for each pixel by integrating multiple c ues (such as color, space, motion, and time), and clustered these feature points via mean shiftanalysis [26], [27], GMM [28], o r hybrid strategy [29]. Grundmann et al. [30] proposed an ef ficient hierarchical graph-based spatio-temporal segmentation over 3D video volume, and Xuet al. [31] extended it to a streaming framework. Lezama et al.[32] extended [30] by incorporating long-range motion cues with occlusion reasoning. Howe ver, these space-time methods construct a volume representation on the entire video, which in-evitably costs huge memory for a long sequence. Besides, all these methods are sensitive to large displacement with signi ficant occlusions. Especially if an object temporarily disappears due to occlusion or out-of-view, it is quite challenging for thesemethods to cluster the corresponding regions into the same seg-ment. Our work is also closely related to joint segmentation techniques [33], [34], which simultaneously segmented the recon-structed 3D points and the registered 2D images. Given themultiple view images, they aimed to semantically organize therecovered 3D points and obtain semantic object segmentation,which required user assistance. In contrast, our method can au-tomatically obtain a set of spatio-temporally consistent volumesegments from a video sequence. Gallup et al. [35] proposed to use temporal video segmentation for reconstruction of more general scene containing non-planar structures, which is similar to our method. However, this method requires complicat ed learning for segmentation of piecewise planar and non-planar regions. In comparison,our method can achieve highly consistent spatio-temporalvideo segmentation without any learning priors. By utilizingthe depth redundancy in multiple frames, our spatio-temporalsegmentation is rather robust to occlusions and out-of-view.More importantly, our reconstructed geometry models have 3Dsegmentation labeling and can be used for many other applications such as 3D/video editing, which may not be achieved by previous 3D reconstruction methods. In summary, spatio-temporal segmentation is still a very challenging problem. Previous approaches generally have dif ficulties in handling large di splacement with signi ficant occlusions. In this paper, we show that by associating multiple frames on theinferred dense depth maps, surpr isingly spatio-temporal consistent segments can be obtain ed from video sequences. The high-quality segmentation results can bene fit many other applications, such as 3D reconstruction, video editing, and non-pho-torealistic rendering. B. Video Editing With the increasing prevalence of digital video cameras, video editing has been steadil y gaining in importance. Many video editing techniques have been developed during the pastdecades. The main dif ficulty of video editing is how to maintain the temporal coherence among temporally neighboring frames.Sand and Teller [36] proposed to spatio-temporally align onevideo with another with simila r camera trajectories for performing some video editing operations, such as backgroundsubtraction and video composi tion. Several techniques have been proposed to treat video as a space-time volume data, which successfully demonstrated its cap ability for video stylization [37], segmentation [38], completion [39] and summarization[40]. However, these techniques are typically limited to thevideos captured by stationary cameras. For handling more com-plex cases (e.g., the camera can freely move), we generally needto recover depth/3D, motion and even layer information. With JIANG et al. : SPATIO-TEMPORAL VIDEO SEGMENTATION OF STATIC SCENES AND ITS APPLICATIONS 5 the recent advances of structurefrom-motion and multi-view stereo techniques, a few tech niques have been proposed to perform video editing based on high-quality depth information.Xiao et al. [41] proposed a video composition technique which can extract a static 3D object from a sequence and seamlesslyinsert it to another sequence. Bhat et al. [42] proposed to use some high resolution photos to enhance a video of a staticscene, based on multiview stereo and image-based renderingtechniques. Zhang et al. [43] presented a very impressive video editing system based on dense depth recovery and layer sepa-ration, which can create various kinds of re filming effects from one or multiple input videos. In general, these methods rely onthe correspondences computed by depth or motion informationto maintain the temporal coherence, and may have accumula-tion error or drift problem for a long sequence. In comparison,with spatio-temporal segmentation and 3D representation, wecan directly perform video editing in a 3D way, so that theoperations are much simpler than those in a 2D way, and thetemporal coherence is maintained more easily. III. O URAPPROACH Given a video sequence of frames, our objective is to estimate a set of spatio-temporal volume segments , and fuse the volume segments to reconstruct a complete 3D scene, where is the volume segment number. For a pixel in frame ,w ed e n o t e if . The color of pixel is denoted as ,d efin e di nL u vc o l o r space. Denoting by the depth value of pixel , the disparity is defined as by convention. Our system overview is shown in Fig. 1. We assume that a depth map is available for each frame of the input video. Thedepth data could be got by using a depth camera or multi-viewstereo techniques [2], [3], [44] . In our experiments, we start by using the structure-from-motion (SFM) method proposed in[45] to recover the camera motion parameters from the inputvideo sequence. The set of camera parameters for frame is denoted as ,w h e r e is the intrinsic matrix, is the rotation matrix, and is the translation vector. With the recovered camera poses, we then employ the multi-viewstereo method of Zhang et al. [3 ]t or e c o v e ras e to fc o n s i s t e n t depth maps. With the computed depth maps, we first perform spatial segmentation for each frame with probabilistic boundary,and then iteratively optimize th e segmentation results by enforcing the temporal coherence constraints among multiple tem-poral frames. The spatio-temporal segmentation can be usedfor many applications such as 3D reconstruction, video editing,stylization and semantic segmentation. IV. S PATIAL SEGMENTATION WITH PROBABILISTIC BOUNDARY Directly obtaining spatio-temporal volume segments in a video is dif ficult due to the large number of unknowns and the possible geometric and motion ambiguities in the segmenta-tion. Therefore, we design an ite rative optimization scheme to achieve spatio-temporal video se gmentation. For initialization, instead of directly segmenting each frame independently, wefirst compute the probabilistic boundary map by collecting the statistics of segment boundaries among multiple frames.Then we perform spatial segmentation for each frame indepenFig. 1. System overview. dently with the computed probabilistic boundary maps. Ourexperimental results demonstr ate that much more consistent segmentation results can be obtained than those of directlyusing mean shift algorithm. A. Probabilistic Boundary Wefirst use mean shift algorithm [6] to segment each frame independently with the same parameters. The 2D segments inframe are denoted as ,w h e r e denotes the number of segments in frame produced by mean shift. For a pixel in frame ,w ed e n o t e if . Fig. 2(b) shows the segmentation r esults of the selected frames, which are not consistent in different images. The segmentedboundaries are quite flickering, and a segment may span over multiple layers, which is obviously not good enough as a startingpoint for spatio-temporal segmentation. With the computed depths, we can project each pixel to other frames to find the correspondences. Considering a pixel in frame , with the estimated depth value , its projection in frame can be computed as follows: (1) where the superscript denotes the vector in the homogeneous coordinate system. The 2D point is computed by dividing by the third homogeneous coordinate. Then we compute the probabilistic boundary as follows: (2) where is a neighboring pixel of in frame ,a n d denotes the number of valid mapping. A mapping is de fin e dt ob e valid, if the projection points and in frame are neither occluded nor out-of-view. If is large, it is very likely that there is a boundary across pixels and . Compared to the traditional segmentation boundaries in a single image, ourprobabilistic boundary map is computed with multiple frames,which is robust to image noise and occasional segmentation errors. The computed probabilistic boundary maps are shownin Fig. 2(c), which are surprisingly consistent among differentframes. The reason is that mean shift segmentation can preserve object boundaries well. Alt hough the generated segment boundaries by mean shift may be o ccasionally inaccurate in one frame, it still has large chance to be accurate in other frames. Bycollecting the boundary statistics in multiple frames, the com-puted probabilistic boundaries can naturally preserve the object boundaries and maintain consistency in neighboring frames.",
        "ref_ids": [
          "13",
          "16",
          "17",
          "18",
          "22",
          "15",
          "23",
          "24",
          "22",
          "23",
          "23",
          "25",
          "25",
          "11",
          "12",
          "26",
          "27",
          "28",
          "29",
          "30",
          "31",
          "32",
          "30",
          "33",
          "34",
          "35",
          "36",
          "37",
          "38",
          "39",
          "40",
          "41",
          "42",
          "43",
          "2",
          "3",
          "44",
          "45",
          "6"
        ]
      },
      "Sampling based scene-space video processing": {
        "authors": [
          "Felix Klose"
        ],
        "url": "https://arxiv.org/pdf/2102.03011",
        "ref_texts": "2007. A gentle introduction to bilateral filtering and its applications. In ACM SIGGRAPH courses . PRITCH , Y., R AV-ACHA, A., AND PELEG , S. 2008. Nonchronological video synopsis and indexing. TPAMI . RICHARDT , C., S TOLL , C., D ODGSON , N. A., S EIDEL , H., AND THEOBALT , C. 2012. Coherent spatiotemporal filtering, upsampling and rendering of RGBZ videos. CGF (Eurographics) . SCHARSTEIN , D., AND SZELISKI , R. 2002. A taxonomy and evaluation of dense two-frame stereo correspondence algorithms. IJCV . SEITZ , S. M., C URLESS , B., D IEBEL , J., S CHARSTEIN , D., AND SZELISKI , R. 2006. A comparison and evaluation of multi-view stereo reconstruction algorithms. In CVPR . SHUM , H., C HAN , S., AND KANG , S. B. 2007. Image-based rendering . Springer.SUN, J., X U, Z., AND SHUM , H. 2008. Image super-resolution using gradient profile prior. In CVPR . SUNKAVALLI , K., J OSHI , N., K ANG , S. B., C OHEN , M. F., AND PFISTER , H. 2012. Video snapshots: Creating high-quality images from video clips. TVCG . TANSKANEN , P., K OLEV , K., M EIER , L., C AMPOSECO , F., SAURER , O., AND POLLEFEYS , M. 2013. Live metric 3D reconstruction on mobile phones. In ICCV . VAISH , V., G ARG, G., T ALVALA , E.-V., A NTUNEZ , E., WILBURN , B., H OROWITZ , M., AND LEVOY , M. 2005. Synthetic aperture focusing using a shear-warp factorization of the viewing transform. In CVPR Workshop . WILBURN , B., J OSHI , N., V AISH , V., T ALVALA , E., A NT\u00b4UNEZ , E. R., B ARTH , A., A DAMS , A., H OROWITZ , M., AND LEVOY , M. 2005. High performance imaging using large camera arrays. ACM Trans. Graphics (Proc. SIGGRAPH) . ZHANG , G., D ONG , Z., J IA, J., W AN, L., W ONG , T.-T., AND BAO, H. 2009. Refilming with depth-inferred videos. TVCG . ZHANG , G., J IA, J., W ONG , T., AND BAO, H. 2009. Consistent depth maps recovery from a video sequence. TPAMI . ZHANG , L., V ADDADI , S., J IN, H., AND NAYAR , S. K. 2009. Multiple view image denoising. In CVPR . ZITNICK , C. L., K ANG , S. B., U YTTENDAELE , M., W INDER , S. A. J., AND SZELISKI , R. 2004. High-quality video view interpolation using a layered representation. ACM Trans. Graphics (Proc. SIGGRAPH) . ZWICKER , M., P FISTER , H., VAN BAAR, J., AND GROSS , M.",
        "ref_ids": [
          "2007"
        ]
      },
      "Robust 3D reconstruction with an RGB-D camera": {
        "authors": [],
        "url": "https://scholar.archive.org/work/klqks6x4pfau7ickytlzvk4g7q/access/wayback/http://www.cad.zju.edu.cn/home/gfzhang/projects/StaticKinect/ObjectModeling-TIP.pdf",
        "ref_texts": "[2] G. Zhang, J. Jia, T.-T. Wong, and H. Bao, \u201cConsistent depth maps recovery from a video sequence,\u201d IEEE Trans. Pattern Anal. Mach. Intell. , vol. 31, no. 6, pp. 974\u2013988, Jun. 2009.",
        "ref_ids": [
          "2"
        ]
      },
      "Intrinsic depth: Improving depth transfer with intrinsic images": {
        "authors": [
          "Naejin Kong",
          "Michael J. Black"
        ],
        "url": "http://openaccess.thecvf.com/content_iccv_2015/papers/Kong_Intrinsic_Depth_Improving_ICCV_2015_paper.pdf",
        "ref_texts": "[32] G. F. Zhang, J. Y . Jia, T. T. Wong, and H. J. Bao. Consistent depth maps recovery from a video sequence. IEEE Trans. Pattern Anal. Mach. Intell. , 31(6):974\u2013988, June 2009. 2,3, 7,8",
        "ref_ids": [
          "32"
        ]
      },
      "Image-based air pollution estimation using hybrid convolutional neural network": {
        "authors": [
          "Jian Ma",
          "Kun Li",
          "Yahong Han",
          "Jingyu Yang"
        ],
        "url": "https://majian8.github.io/data/Image-based_Air_Pollution_Estimation_Using_Hybrid_Convolutional_Neural_Network.pdf",
        "ref_texts": "[10] G. Zhang, J. Jia, T. T. Wong, and H. Bao, \u201cConsistent depth maps recovery from a video sequence,\u201d IEEE Transactions on Pattern Analysis & Machine Intelligence , vol. 31, no. 6, p. 974, 2009.",
        "ref_ids": [
          "10"
        ]
      },
      "Depth2action: Exploring embedded depth for large-scale action recognition": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1608.04339",
        "ref_texts": "53. Zhang, G., Jia, J., Wong, T.T., Bao, H.: Consistent Depth Maps Recovery from a Video Sequence. TPAMI (2009)",
        "ref_ids": [
          "53"
        ]
      },
      "Adaptive road detection via context-aware label transfer": {
        "authors": [
          "Qi Wang"
        ],
        "url": "https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=34de65d0b39b490839bd69eab9fdf7756ea314fd",
        "ref_texts": "[9]G. Zhang, J. Jia, T.T. Wong, H. Bao, Consistent depth maps recovery from a video sequence, IEEE Trans. Pattern Anal. Mach. Intell. 31 (6) (2009) 974 \u2013988.",
        "ref_ids": [
          "9"
        ]
      },
      "Online convolutional dictionary learning for multimodal imaging": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1706.04256",
        "ref_texts": "[30]G. Zhang, J. Jia, T . T . Wong, and H. Bao, \u201cConsistent depth maps recovery from a video sequence,\u201d IEEE Transactions on Pattern Analysis and Machine Intelligence , vol. 31, no. 6, pp. 974\u2013988, 2009. Page 9 of 9",
        "ref_ids": [
          "30"
        ]
      },
      "Video stereolization: Combining motion analysis with user interaction": {
        "authors": [],
        "url": "https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=ae78de2de2131188e1a037c8071e01a323e3b9f6",
        "ref_texts": "[2] G. Zhang, J. Jia, T.-T. Wong, and H. Bao, \u201cConsistent depth maps recovery from a video sequence,\u201d Transactions on Pattern Analysis and Machine Intelligence , vol. 31, no. 6, 2009.",
        "ref_ids": [
          "2"
        ]
      },
      "Sfm-ttr: Using structure from motion for test-time refinement of single-view depth networks": {
        "authors": [
          "Sergio Izquierdo",
          "Javier Civera"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Izquierdo_SfM-TTR_Using_Structure_From_Motion_for_Test-Time_Refinement_of_Single-View_CVPR_2023_paper.pdf",
        "ref_texts": "[62] Guofeng Zhang, Jiaya Jia, Tien-Tsin Wong, and Hujun Bao. Consistent depth maps recovery from a video sequence. IEEE Transactions on pattern analysis and machine intelligence , 31(6):974\u2013988, 2009. 2",
        "ref_ids": [
          "62"
        ]
      },
      "Object recognition in 3D point cloud of urban street scene": {
        "authors": [],
        "url": "https://projet.liris.cnrs.fr/imagine/pub/proceedings/ACCV-2014/pages/workshop2/pdffiles/workshop2-paper3-accv2014finalpaper_Wbigdata3.pdf",
        "ref_texts": "5. Zhang, G., Jia, J., Wong, T.T., Bao, H.: Consistent depth maps recovery from a video sequence. Pattern Analysis and Machine Intelligence, IEEE Transactions on 31(2009) 974{988",
        "ref_ids": [
          "5"
        ]
      },
      "Combining color and depth for enhanced image segmentation and retargeting": {
        "authors": [],
        "url": "https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=4b3be9e4c5bf3316211cc5ccc9bf73e3d601fc6c",
        "ref_texts": "29. Zhang, G., Jia, J., Wong, T.-T., Bao, H.: Consistent depth maps recovery from a video sequence. IEEE Trans. Pattern Anal. Mach. Intell. 974\u2013988 (2009) Meir Johnathan Dahan is a researcher in a leading security company. He received his B.Sc. summa cum laude in computer science (2004) from Tel-Hai Academic College. He received his M.Sc. degree from Tel-Aviv University (2010)in the field of computer graphics and image processing. His main research area and interests are image synthesis and machine learning, in particular retargeting, probabilistic algorithms, and clustering. Nir Chen received his B.Sc. degree in Computer Science and Mathe-matics from Bar-Ilan University and his M.Sc. degree cum laude in Computer Science at IDC Israel. Nir has an extensive practical industry background with hi-tech companies such as National Semiconductor and artNet NetCom, where he worked as a computer engineer. His main research interests are computer graphics and specifically image segmentation and retargeting algorithms. Ariel Shamir is an associate Professor at the school of Computer Science at the Interdisciplinary Center in Israel. Prof. Shamir received his Ph.D. in computer science in 2000 from the Hebrew University in Jerusalem. He spent two years at the center for computational visualization at the University of Texasin Austin. During 2006, he held the position of visiting scientist at Mitsubishi Electric Research Labs in Cambridge MA. Prof. Shamir has numerous publications in journals and international refereed conferences, he has a broad commercial experience working with and consulting numerous companies. He is a member of the ACM SIGGRAPH, IEEE Computer and Eurographics societies. Daniel Cohen-Or is a professor at the School of Computer Science. He received his B.Sc. cum laude in both mathematics and computer science (1985), an M.Sc. cum laude in computer science (1986) from BenGurion University, and his Ph.D. degree from the Department of Computer Science (1991) at State University of New York at Stony Brook. He received the 2005 Eurographics Outstanding TechnicalContributions Award. His research interests are in computer graphics, in particular, rendering and modeling techniques. His main interest right now is in few areas: image synthesis, motion and transformations, shapes and surfaces, and surface reconstruction.",
        "ref_ids": [
          "29"
        ]
      },
      "Texture-aware dense image matching using ternary census transform": {
        "authors": [
          "Lawrence W. Fritz"
        ],
        "url": "https://ira.lib.polyu.edu.hk/bitstream/10397/65010/1/Hu_Texture-aware_dense_image.pdf",
        "ref_texts": "(4), pp. 834-846. Yoon, K., Kweon, I.S., 2006. Adaptive support-weight approach for correspondence search. IEEE Transactions on Pattern Analysis and Machine Intelligence , 28 (4), pp. 650-656. Zabih, R., Woodfill, J., 1994. Non-parametric local transforms for computing visual correspondence. In: 3rd European Conference on Computer Vision (ECCV1994) , Springer, Stockholm, Sweden, pp. 151-158. Zhang, G., Jia, J., Wong, T., Bao, H., 2009. Consistent depth maps recovery from a video sequence. IEEE Transactions on Pattern Analysis and Machine Intelligence , 31 (6), pp. 974-988. Zhu, Q., Wu, B., Wan, N., 2007. A filtering strategy for interest point detecting to improve repeatability and information content. Photogrammetric Engineering and Remote Sensing , 73 (5), pp. "
      },
      "Video de-fencing": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1210.2388",
        "ref_texts": "[20] G. Zhang, J. Jia, T.-T. Wong, and H. Bao, \u201cConsistent depth maps recovery from a video sequence,\u201d IEEE Transactions on Pattern Analysis and Machine Intelligence , vol. 31, no. 6, pp. 974\u2013988, 2009.",
        "ref_ids": [
          "20"
        ]
      },
      "Consistent binocular depth and scene flow with chained temporal profiles": {
        "authors": [],
        "url": "http://www.cse.cuhk.edu.hk/~leojia/papers/sceneflow_ijcv12.pdf",
        "ref_texts": "671\u2013684). Xu, L., Jia, J., & Matsushita, Y . (2010). Motion detail preserving optical flow estimation. In CVPR (pp. 1293\u20131300). Yoon, K. J., & Kweon, I. S. (2006). Adaptive support-weight approach for correspondence search. IEEE Transactions on Pattern Analysis and Machine Intelligence ,28, 650\u2013656. Zhang, Z., & Faugeras, O. D. (1992). Estimation of displacements from two 3-d frames obtained from stereo. IEEE Transactions on Pattern Analysis and Machine Intelligence ,14, 1141\u20131156. Zhang, Y ., & Kambhamettu, C. (2001). On 3d scene flow and structure estimation. In CVPR (V ol. 2, pp. 778\u2013785). Zhang, L., Curless, B., & Seitz, S. M. (2003). Spacetime stereo: shape recovery for dynamic scenes. In CVPR (V ol. 2, pp. 367\u2013374). Zhang, G., Jia, J., Wong, T. T., & Bao, H. (2009). Consistent depth maps recovery from a video sequence. IEEE Transactions on Pattern Analysis and Machine Intelligence ,31, 974\u2013988. Zimmer, H., Bruhn, A., Weickert, J., Valgaerts, L., Salgado, B. R. A., & Seidel, H. P. (2009). Complementary optic flow. In EMMCVPR"
      },
      "3d time-lapse reconstruction from internet photos": {
        "authors": [
          "Ricardo Martin",
          "David Gallup",
          "Steven M. Seitz"
        ],
        "url": "http://openaccess.thecvf.com/content_iccv_2015/papers/Martin-Brualla_3D_Time-Lapse_Reconstruction_ICCV_2015_paper.pdf",
        "ref_texts": "[23] G. Zhang, J. Jia, T.-T. Wong, and H. Bao. Consistent depth maps recovery from a video sequence. Pattern Analysis and Machine Intelligence, IEEE Transactions on , 31(6):974\u2013",
        "ref_ids": [
          "23"
        ]
      },
      "Depth from gradients in dense light fields for object reconstruction": {
        "authors": [],
        "url": "https://people.csail.mit.edu/changil/assets/depth-from-gradient-3dv-2016-yuecer-et-al-compressed.pdf",
        "ref_texts": "[41] G. Zhang, J. Jia, T. Wong, and H. Bao. Consistent depth maps recovery from a video sequence. PAMI , 31(6), 2009. 7,8",
        "ref_ids": [
          "41"
        ]
      },
      "Temporal consistent real-time stereo for intelligent vehicles": {
        "authors": [],
        "url": "https://hal.science/hal-00477279/file/elansari_paper_to_prl.pdf",
        "ref_texts": "[33] G. Zhang, J. Jia, T. Wong, and H. Bao. Consistent depth ma ps recovery from 572 a video sequence. IEEE Trans. Pattern Analysis and Machine Intelligence , 573",
        "ref_ids": [
          "33"
        ]
      },
      "3d reconstruction of dynamic scenes with multiple handheld cameras": {
        "authors": [
          "Hanqing Jiang",
          "Haomin Liu",
          "Ping Tan",
          "Guofeng Zhang",
          "Hujun Bao"
        ],
        "url": "https://projet.liris.cnrs.fr/imagine/pub/proceedings/ECCV-2012/papers/7573/75730601.pdf",
        "ref_texts": "16. Yang, W., Zhang, G., Bao, H., Kim, J., Lee, H.Y.: Consistent depth maps recovery from a trinocular video sequence. In: CVPR, pp. 1466\u20131473 (2012)",
        "ref_ids": [
          "16"
        ]
      },
      "Depth map completion by jointly exploiting blurry color images and sparse depth maps": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1711.09501",
        "ref_texts": "[43] Guofeng Zhang, Jiaya Jia, Tien-Tsin Wong, and Hujun Bao. Consistent depth maps recovery from a video sequence. IEEE Trans. Pattern Anal. Mach. Intell. , 31(6):974\u2013988, 2009. 2",
        "ref_ids": [
          "43"
        ]
      },
      "Introspection in system-level language frameworks: Meta-level vs. integrated": {
        "authors": [
          "Frederic Doucet",
          "Sandeep Shukla",
          "Rajesh Gupta"
        ],
        "url": "https://websrv.cecs.uci.edu/~papers/compendium94-03/papers/2003/date03/pdffiles/05a_4.pdf",
        "ref_texts": ""
      },
      "Spatio-temporal consistency in video disparity estimation": {
        "authors": [],
        "url": "https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=1154ce71e59cf44441f662124214dfae9397e287",
        "ref_texts": "[13] G. Zhang, J. Jia, T. T. Wong, and H. Bao, \u201cConsistent Depth Maps Recovery from a Video Sequence,\u201d PAMI , vol. 31, no. 6, pp. 974\u2013988, 2009.",
        "ref_ids": [
          "13"
        ]
      },
      "Scene understanding from a moving camera for object detection and free space estimation": {
        "authors": [],
        "url": "https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=2486203aa41279058e2d0da05f018a081b4db0c6",
        "ref_texts": "[3] G. Zhang, J. Jia, T.-T. Wong, H. Bao, and H. Bao, \u201cConsistent depth maps recovery from a video sequence.\u201d in PAMI , vol. 31, no. 6, 2009, pp. 974\u2013988.",
        "ref_ids": [
          "3"
        ]
      },
      "Simultaneous multi-body stereo and segmentation": {
        "authors": [],
        "url": "http://www.cad.zju.edu.cn/home/bao/pub/Simultaneous_Multi-Body_Stereo_and_Segmentation.pdf",
        "ref_texts": "[27] G.Zhang, J.Jia,T.-T.Wong, andH.Bao. Consistent depth maps recoveryfrom avideo sequence. IEEE Trans. Pattern Anal. Mach.Intell. ,31(6):974\u0096988, 2009. 3,4,6",
        "ref_ids": [
          "27"
        ]
      },
      "Active vision during coordinated head/eye movements in a humanoid robot": {
        "authors": [],
        "url": "https://aplab.bcs.rochester.edu/assets/download/PDFs/articles/KuangEtAl12b.pdf",
        "ref_texts": "[11] G. Zhang, J. Jia, T.-T. Wong, and H. Bao, \u201cConsistent depth maps recovery from a video sequence,\u201d IEEE Trans. Pattern Anal. Mach. Intell. , vol. 31, no. 6, pp. 974\u2013988, Jun. 2009.",
        "ref_ids": [
          "11"
        ]
      },
      "6d dynamic camera relocalization from single reference image": {
        "authors": [
          "Wei Feng",
          "Peng Tian",
          "Qian Zhang",
          "Jizhou Sun"
        ],
        "url": "https://openaccess.thecvf.com/content_cvpr_2016/papers/Feng_6D_Dynamic_Camera_CVPR_2016_paper.pdf",
        "ref_texts": "[37] G. Zhang, J. Jia, T.-T. Wong, and H. Bao. Consistent depth maps recovery from a video sequence. IEEE TPAMI , 31(6):974\u2013988, 2009.",
        "ref_ids": [
          "37"
        ]
      },
      "Consistent depth maps recovery from a trinocular video sequence": {
        "authors": [],
        "url": "http://www.cad.zju.edu.cn/home/gfzhang/projects/tridepthrecovery/1055.pdf",
        "ref_texts": "2.Related Work Two-vie wstereo matching hasbeen extensi velystudied during thepast decades [12, 14,4].However,two-vie w stereo matching hasinherent dif\u0002culty inhandling occlusions duetoinformation missing. Although some methods havebeen proposed toincorporate smoothness constraint orsegmentation prior toalleviate thisproblem, itisstill verychallenging torecoverhigh-quality depth maps from comple xnatural images with strong occlusions. Incontrast, multi-vie wstereo matching hasmore advantages in handling occlusions andimage noise, sothattherecovered depth maps could bemore accurate. Inrecent years, multiviewstereo hasachie vedsigni\u0002cant advances. Furuka waet al.[7]proposed aseed growing method toreconstruct accurate surfacemodel from asetof3Dpoints. Vuetal.[15] reconstructed high quality large-scale scenes inamesh optimization frame work. Although multi-vie wstereo matching hasbeen extensi velystudied, most multi-vie wstereo methodsarelimited tostatic scene reconstruction andtheproblem ofhowtoaccurately andconsistently recoverdense depth information ofdynamic scenes hasnotbeen suf\u0002ciently addressed. The typical solution fordepth recoveryofdynamic scenes istousemultiple synchronized cameras. Depths ofdynamic objects arerecovered bystereo matching on multiple synchronous camera frames andtemporal smoothFigure 1.Frame workovervie w. ness constraint based onoptical \u0003owisadded fordepth re\u0002nement. In[9],Larsen etal.incorporate motion estimation andmodify theBPalgorithm togenerate temporally consistent reconstruction results from multiple cameraviews.Some other methods [8,10]extract moving objects from knownorstationary background andincorporatesegmentation todepth re\u0002nement, which require more than three cameras forrobustdepth estimate. Recently , Zhang etal.[17]proposed arobustbilayer segmentation method which canaccurately detect andextract themoving object from avideo sequence takenbyamoving camera. However,thismethod requires amanual preprocessing for foreground color distrib ution learning. Several algorithms [18,2,16]fortemporally consistentdepth maps estimation havebeen developed. Zhang et al.[18] proposed apowerful bundle optimization frameworktorecoverspatio-temporally consistent depth maps forstatic scenes with asingle moving camera. Recently , Yangetal.[16] extended thismethod tohandle dynamic scene. However,their method only used veryfewneighbor ingframes fordepth optimization, andisrather sensiti veto optical \u0003owerrors andocclusions. Asaresult, their method required acamera array with relati vesmall baselines forrobustdepth estimate. Toovercome disadv antages ofprevious methods, wepropose anovelmethod forhigh-quality dense depth recoveryfrom atrinocular video sequence, which can generate accurate andconsistent depth maps forboth static anddynamic regions automatically .",
        "ref_ids": [
          "2"
        ]
      },
      "Depth maps interpolation from existing pairs of keyframes and depth maps for 3D video generation": {
        "authors": [],
        "url": "https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=cbc67ab2f1eaa042ff17d4fa28e6edd461632f6a",
        "ref_texts": "[7] G. Zhang, J. Jia, T. T. Wong an d H. Bao, \"Consistent Depth Maps Recovery from a Video Sequence\", IEEE Transactions on Pattern Analysis and Machine Intelligence , vol. 31, June 2009. ",
        "ref_ids": [
          "7"
        ]
      },
      "Space-time joint multi-layer segmentation and depth estimation": {
        "authors": [],
        "url": "https://openresearch.surrey.ac.uk/view/delivery/44SUR_INST/12138865330002346/13140631590002346",
        "ref_texts": "[29] G. Zhang, J. Jia, T.-T. Wong, and H. Bao. Consistent depth maps recovery from a video sequence. PAMI , 31(6):974 \u2013",
        "ref_ids": [
          "29"
        ]
      },
      "Fast spatio-temporal stereo for intelligent transportation systems": {
        "authors": [],
        "url": "https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=d95e4f679b6250faf8a190feac1082c173efd39a",
        "ref_texts": "23. Zhang G, Jia J, Wong T, Bao H (2009) Consistent depth maps recovery from a video sequence. IEEE Trans Pattern Anal MachIntell 31(6):974\u2013988Pattern Anal Applic (2014) 17:211\u2013221 221",
        "ref_ids": [
          "23"
        ]
      },
      "Depth estimation using a sliding camera": {
        "authors": [],
        "url": "http://ivg.au.tsinghua.edu.cn/paper/2016_Depth%20estimation%20using%20a%20sliding%20camera.pdf",
        "ref_texts": "[6] G. Zhang, J. Jia, T.-T. Wong, and H. Bao, \u201cConsistent depth maps recovery from a video sequence,\u201d IEEE Trans. Pattern Anal. Mach. Intell. , vol. 31, no. 6, pp. 974\u2013988, Jun. 2009.",
        "ref_ids": [
          "6"
        ]
      },
      "Dependency characterization in path-based approaches to architecture-based software reliability prediction": {
        "authors": [],
        "url": "https://repository.lib.ncsu.edu/bitstream/handle/1840.4/991/TR_1998_21.pdf?sequence=1",
        "ref_texts": ""
      },
      "Probabilistic disparity fusion for real-time motion-stereo": {
        "authors": [],
        "url": "https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=63d8f369be18fa5edffea6fdd6a7b3232ef9ca41",
        "ref_texts": "17.Zhang, G., Jia, J., Wong, T.T., Bao, H.: Consistent depth maps recovery from a video sequence. PAMI 31(2009) 974\u2013988",
        "ref_ids": [
          "17"
        ]
      },
      "Combining multi-view stereo and super resolution in a unified framework": {
        "authors": [],
        "url": "http://www.apsipa.org/proceedings_2012/papers/346.pdf",
        "ref_texts": "[9] Zhang, G., Jia, J., Wong, T.T., Bao, H.: Consistent depth maps recovery from a video sequence. IEEE Transactions on Pattern Analysi s and Machine Intelligence 31(2009) 974\u2013988",
        "ref_ids": [
          "9"
        ]
      },
      "Image-based visual perception and representation for collision avoidance": {
        "authors": [
          "Cevahir Cigla",
          "Roland Brockers",
          "Larry Matthies"
        ],
        "url": "http://openaccess.thecvf.com/content_cvpr_2017_workshops/w4/papers/Cigla_Image-Based_Visual_Perception_CVPR_2017_paper.pdf"
      },
      "Image processing device, image processing method, program, and integrated circuit": {
        "authors": [],
        "url": "https://patentimages.storage.googleapis.com/87/eb/60/c779a62f992f1d/US9401039.pdf",
        "ref_texts": ""
      },
      "Temporal consistent fast stereo matching for advanced driver assistance systems (ADAS)": {
        "authors": [
          "Mohamed E",
          "L A",
          "Abdelaziz B",
          "George Bebis"
        ],
        "url": "https://www.cse.unr.edu/~bebis/AnsariIV10.pdf",
        "ref_texts": "[16] G. Zhang, J. Jia, T. Wong, and H. Bao, \u201cConsistent depth maps recovery from a video sequence,\u201d IEEE Trans. Pattern Analysis and Machine Intelligence , vol. 31, no. 6, pp. 974\u2013988, 2009.",
        "ref_ids": [
          "16"
        ]
      },
      "A semi-local method for iterative depth-map refinement": {
        "authors": [],
        "url": "https://eprints.qut.edu.au/48517/1/ICRA_2012.pdf",
        "ref_texts": "[10] G. Zhang, J. Jia, T.-T. Wong, and H. Bao, \u201cConsistent depth maps recovery from a video sequence,\u201d IEEE Transactions on Pattern Analysis and Machine Intelligence , vol. 31, pp. 974\u2013988, 2009.",
        "ref_ids": [
          "10"
        ]
      },
      "Learning dense optical-flow trajectory patterns for video object extraction": {
        "authors": [
          "Chou Lu",
          "Chiang Frank",
          "Song Chen"
        ],
        "url": "https://projet.liris.cnrs.fr/imagine/pub/proceedings/AVSS-2010/data/4264a315.pdf",
        "ref_texts": "[24]G. Zhang, J. Y . Jia, T. T. Wong, and H. J. Bao. Consistent depth maps recovery from a video sequence. PAMI , 31(6):974\u2013988, June 2009. 4",
        "ref_ids": [
          "24"
        ]
      },
      "Depth reconstruction from single images using a convolutional neural network and a condition random field model": {
        "authors": [],
        "url": "https://www.mdpi.com/1424-8220/18/5/1318/pdf",
        "ref_texts": "3. Zhang, G.F.; Jia, J.Y.; Wong, T.-T.; Bao, H. Consistent depth maps recovery from a video sequence. IEEE Trans. Pattern Anal. Mach. Intell. 2009 ,31, 974\u2013988. [CrossRef] [PubMed]",
        "ref_ids": [
          "3"
        ]
      },
      "A real-time spatio-temporal stereo matching for road applications": {
        "authors": [
          "Mohamed El",
          "I M",
          "Abdelaziz B",
          "George Bebis"
        ],
        "url": "https://www.cse.unr.edu/~bebis/ElAnsari_ITSC2011.pdf",
        "ref_texts": "[17]G.Zhang,J.Jia,T.Wong,andH.Bao,\u201cConsistentdepthmaps recoveryfromavideosequence,\u201dIEEE Trans.PatternAnalysisand MachineIntelligence,vol.31,no.6,pp.974\u2013988 ,2009 .",
        "ref_ids": [
          "17"
        ]
      },
      "Impact of 3d ic on noc topologies: A wire delay consideration": {
        "authors": [],
        "url": "https://hal.science/hal-00938984/file/dsd-2013-v6-121-06-2013.pdf",
        "ref_texts": ""
      },
      "Block-based depth maps interpolation for efficient multiview content generation": {
        "authors": [
          "B L",
          "Thomson Press"
        ],
        "url": "https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=80b32805cf9426bb297426f40bf2981c7ca3754b",
        "ref_texts": "[11] G. Zhang, J. Jia, T. T. Wong, and H. Bao, \u201cConsistent depth maps recovery from a video sequence,\u201d IEEE Trans. Patt. Anal. Mach. Intell. , vol. 31, no. 6, pp. 974\u2013988, Jun. 2009.",
        "ref_ids": [
          "11"
        ]
      },
      "Signal processing methods for light field displays": {
        "authors": [
          "Robert Bregovic"
        ],
        "url": "https://researchportal.tuni.fi/files/47983899/BookchapterLFDisplays_v12.pdf",
        "ref_texts": "[84] G. Zhang, J. Jia, T. Wong, and H. Bao, \u201cConsistent Depth Maps Recovery from a Video Sequence,\u201d IEEE Trans. Pattern Analysis and Machine Intelligence , vol. 31, no. 6, pp. ",
        "ref_ids": [
          "84"
        ]
      },
      "Depth extraction from videos using geometric context and occlusion boundaries": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1510.07317",
        "ref_texts": "[27] Guofeng Zhang, Jiaya Jia, Tien-Tsin Wong, and Hujun Bao. Consistent depth maps recovery from a video sequence. PAMI , 2009.",
        "ref_ids": [
          "27"
        ]
      },
      "Semantic parsing of street scene images using 3d lidar point cloud": {
        "authors": [
          "Pouria Babahajiani",
          "Lixin Fan",
          "Moncef Gabbouj"
        ],
        "url": "https://www.cv-foundation.org/openaccess/content_iccv_workshops_2013/W21/papers/Babahajiani_Semantic_Parsing_of_2013_ICCV_paper.pdf",
        "ref_texts": "[18] G. Zhang, J. Jia, T.T. Wong, and H. Bao , \"Consistent Depth Maps Recovery from a Video Sequence,\" IEEE Transactions on Pattern Analysis and Machine Intelligence ",
        "ref_ids": [
          "18"
        ]
      },
      "High-dimensional camera shake removal with given depth map": {
        "authors": [],
        "url": "https://yuetao-nju-ece.github.io/papers/tip14-HighDim.pdf",
        "ref_texts": "[34] G. Zhang, J. Jia, T. Wong, and H. Bao, \u201cConsistent depth maps recovery from a video sequence,\u201d IEEE Trans. Pattern Anal. Mach. Intell. , vol. 31, no. 6, pp. 974\u2013988, Jun. 2009.",
        "ref_ids": [
          "34"
        ]
      },
      "A framework for estimating relative depth in video": {
        "authors": [],
        "url": "https://rshare.library.torontomu.ca/ndownloader/files/28122990",
        "ref_texts": "2.4.1 Automated Methods Automated methods generate depth maps without any guidance at all from a user. The complexity depends on the quality of the results and the current state of the art is lacking in many ways. Part of the problem is that automated methods cannot be (easily) corrected if any errors are spotted. The only way to afiect the outcome is to adjust the runtime settings and hope for the best. Some of the more image processing-based methods have used information in the image as a proxy for depth. For instance, Tam et al [62] used the Cr chroma channel in a YCbCr image as a depth map. Similarly, Angot et al [63] performed joint bilateral ffltering with a very simple depth map and an image so that the image edges would be visible in the depth map4. In both cases, the goal was not to create a real depth map, simply one that would look plausible. Another approach has been to use machine learning methods to use depth cues (shading, vanishing lines, etc) in an image. Make3D by Saxena et al [64] trained a classiffer using data from a laser range ffnder to determine how visual features were correlated to depth. Also, it is possible to learn depth from existing stereo sequences [65]. More recently, Karsch et al [66] and Konrad et al [67] have used nearest-neighbour matching to ffnd images with known depths and merge them together to obtain a depth map for an image with unknown depth. It should be pointed out that visual cues can also be used directly without any machine learning, such as what was done by Tian et al [68]. Computer vision methods can be applied directly to this problem too. Knorr et al [69] used SfM to obtain camera positions from a video and rendered novel views by warping existing frames. Something similar was done around the same time by Zhang et al [70]. However, neither method actually generated a depth map and so if the existing footage is not conducive to generating new frames then even if the reconstruction was good, the result will not. An example was provided in [70]. However, other methods have generated depth maps using SfM/MVS. The most well-known of these is the work by Zhang et al [71] on consistent depth recovery from video. They ffrst perform a sparse reconstruction using SfM and use MVS to estimate the dense disparity at each frame. A global optimization is used to enforce temporal and photometric consistency for the entire video. They used this method for depth-based efiects rendering [72] with a post-processing step to accommodate for errors in the depth maps caused by moving objects.",
        "ref_ids": [
          "62",
          "63",
          "64",
          "65",
          "66",
          "67",
          "68",
          "69",
          "70",
          "70",
          "71",
          "72"
        ]
      },
      "User directed multi-view-stereo": {
        "authors": [],
        "url": "https://jankautz.com/publications/InteractiveMVS_UCCV14.pdf",
        "ref_texts": "24. Zhang, G., Jia, J., Wong, T.T., Bao, H.: Consistent depth maps recovery from a video sequence. IEEE Transactions on Pattern Analysis and Machine Intelligence 31(2009) 974{988",
        "ref_ids": [
          "24"
        ]
      },
      "Independent thread video disparity estimation method and codec": {
        "authors": [],
        "url": "https://patentimages.storage.googleapis.com/c1/00/78/9d08739071a526/US9924196.pdf",
        "ref_texts": " Visual Correspondence Search \u201d , Computer Vision and Pattern Rec ognition , 2005 . CVPR 2005 . IEEE Computer Society Conference on (vol . 2 ) , Jun . 2005 , pp . 924 931 . Zhang , G . , et al . , \u201c Consistent Depth Maps Recovery from a Video Sequence \u201d , Pattern Analysis and Machine Intelligence , IEEE Trans "
      },
      "On the integrality ratio for asymmetric TSP": {
        "authors": [],
        "url": "https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=5cb2987f5c9059bd27a1031e4c83beb2cd7e330f",
        "ref_texts": ""
      },
      "Depth estimation for semi-automatic 2D to 3D conversion": {
        "authors": [],
        "url": "https://projet.liris.cnrs.fr/imagine/pub/proceedings/ACM-MULTIMEDIA-2012/mm/p817.pdf",
        "ref_texts": "[15] G. Zhang, J. Jia, T.-T. Wong, and H. Bao. Consistent depth maps recovery from a video sequence. Pattern Analysis and Machine Intelligence, IEEE Transactions on, 31(6):974 {988, June 2009.",
        "ref_ids": [
          "15"
        ]
      },
      "Iterative depth recovery for multi-view video synthesis from stereo videos": {
        "authors": [],
        "url": "http://www.apsipa.org/proceedings_2014/data/paper/1258.pdf",
        "ref_texts": "[3] G. Zhang, J. Jia, T.-T. Wong, and H. Bao, \u201cConsistent depth maps recovery from a video sequence,\u201d IEEE Trans. Pattern Anal. Mach. Intell., vol. 31, no. 6, pp. 974\u2013988, 2009.[4] J. Park, H. Kim, Y .-W. Tai, M. S. Brown, and I.-S. Kweon, \u201cHigh quality depth map upsampling for 3d-tof cameras.\u201d in ICCV, D. N. Metaxas, L. Quan, A. Sanfeliu, and L. J. V . Gool, Eds. IEEE, 2011, pp. 1623\u2013",
        "ref_ids": [
          "3",
          "4"
        ]
      },
      "\u9762\u5411\u590d\u6742\u4e09\u7ef4\u573a\u666f\u7684\u9ad8\u8d28\u91cf\u7eb9\u7406\u6620\u5c04": {
        "authors": [],
        "url": "http://cjc.ict.ac.cn/online/onlinepaper/jhq-2015112472520.pdf",
        "ref_texts": "recoveryfromavideosequence.IEEETransactionson"
      },
      "A memory-efficient and time-consistent filtering of depth map sequences": {
        "authors": [
          "Sergey Smirnov",
          "Atanas Gotchev",
          "Karen Egiazarian"
        ],
        "url": "https://trepo.tuni.fi/bitstream/handle/10024/128744/draft4.pdf?sequence=1",
        "ref_texts": "17 G. Zhang, J. Jia , T. Wong , H. Bao , Consistent Depth Maps Recovery from a Video Sequence. IEEE Trans. Pattern Anal. Mach. Intell. Vol. 31 , No.6, pp. 974 -988 (2009). "
      },
      "Efficient stereo matching for moving cameras and decalibrated rigs": {
        "authors": [],
        "url": "https://campar.cs.tum.edu/pub/unger2011iv/unger2011iv.pdf",
        "ref_texts": "[21] G. Zhang, J. Jia, T.-T. Wong, and H. Bao, \u201cConsistent depth maps recovery from a video sequence,\u201d PAMI , vol. 31, no. 6, pp. 974\u2013988, 2009.",
        "ref_ids": [
          "21"
        ]
      },
      "Visual fatigue reduction based on depth adjustment for DIBR system": {
        "authors": [],
        "url": "https://koreascience.kr/article/JAKO201217034922725.pdf",
        "ref_texts": "[17] G. Zhang, J. Jia, T.-T. Wong and H. Bao, \u201cConsisten t depth maps recovery from a video sequence,\u201d IEEE Transactions on Pattern Analysis and Machine I ntelligence , vol.31, no.6, pp.974-988, Jun.2009. Article (CrossRef Link) ",
        "ref_ids": [
          "17"
        ]
      },
      "Geometric computer vision: Omnidirectional visual and remotely sensed data analysis": {
        "authors": [],
        "url": "https://trepo.tuni.fi/bitstream/handle/10024/131379/978-952-03-1979-3.pdf?sequence=2",
        "ref_texts": ""
      },
      "Stereo fusion from multiple viewpoints": {
        "authors": [
          "Christian Unger",
          "Eric Wahl",
          "Peter Sturm",
          "Slobodan Ilic"
        ],
        "url": "https://campar.cs.tum.edu/pub/unger2012DAGM2/unger2012DAGM2.pdf",
        "ref_texts": "18. Zach, C.: Fast and high quality fusion of depth maps. In: 3DPVT (2008)19. Zhang, G., Jia, J., Wong, T.T., Bao, H.: Consistent depth maps recovery from a video sequence. PAMI 31(6), 974\u2013988 (2009)",
        "ref_ids": [
          "18"
        ]
      },
      "Watershed and random walks based depth estimation for semi-automatic 2D to 3D image conversion": {
        "authors": [],
        "url": "https://scholar.archive.org/work/bnkwugr74naqxeux6g37jckuqa/access/wayback/http://www.ee.cityu.edu.hk/~lmpo/publications/2012_ICSPCC_3DV.pdf",
        "ref_texts": "[15] G. Zhang, J . Jia, T .T. Wong and H . Bao. Consistent Depth Maps Recovery from a Video Sequence. IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 31(6):974 -988, 200 ",
        "ref_ids": [
          "15"
        ]
      },
      "Software evolution in componentware-a practical approach": {
        "authors": [],
        "url": "https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=60dceab2af0f6d3c08c820529853d4807dc0e59f",
        "ref_texts": ""
      },
      "A linear approach for depth and colour camera calibration using hybrid parameters": {
        "authors": [],
        "url": "http://eprints.bournemouth.ac.uk/23907/1/art_10.1007_s11390-016-1641-7.pdf",
        "ref_texts": "[7] Zhang G F, Jia J Y, Wong T T, Bao H J. Consistent depth maps recovery from a video sequence. IEEE Transactions on Pattern Anal. Mach. Intell. , 2009, 31(6): 974-988.",
        "ref_ids": [
          "7"
        ]
      },
      "Real-time quasi dense two-frames depth map for autonomous guided vehicles": {
        "authors": [],
        "url": "https://inria.hal.science/inria-00612341/file/Ducrot-all-IV01-2011.pdf",
        "ref_texts": "[8] Guofeng Zhang, Jiaya Jia, Tien-Tsin Wong and Hujun Bao, \"Consistent Depth Maps Recovery from a Video Sequence\", in IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI\u201909), 31(6):974-988, 2009.",
        "ref_ids": [
          "8"
        ]
      },
      "Segmentation and tracking of nonplanar templates to improve VSLAM": {
        "authors": [
          "Abdelsalam Masoud"
        ],
        "url": "https://repository.mines.edu/bitstream/handle/11124/17087/Masoud_mines_0052E_10676.pdf?sequence=1&isAllowed=y",
        "ref_texts": "[54] G. Zhang, J. Jia, T. Wong, and H. Bao. Consistent depth maps recovery from a video sequence. IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), Vol. 31,no. 6, pp.974-988 , 2009.",
        "ref_ids": [
          "54"
        ]
      },
      "Variety identification of rice seed based on three-dimensional reconstruction method of sequence images": {
        "authors": [],
        "url": "https://www.ingentaconnect.com/content/tcsae/tcsae/2014/00000030/00000007/art00022?crawler=true",
        "ref_texts": "[16] Zhang G, Jia J, Wong T, et al. Consistent depth maps recovery from a video sequence[J]. IEEE Trans. on Pattern Analysis and Machine Intelligence, 2009, 31(6): ",
        "ref_ids": [
          "16",
          "J"
        ]
      },
      "Uncalibrated dynamic stereo using parallax": {
        "authors": [],
        "url": "https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=468dc9cc5703f710ac911e21bd7af1522ec3ae78",
        "ref_texts": "[23] G. Zhang, J. Jia, T.-T. Wong, and H. Bao. Consistent depth maps recovery from a video sequence. IEEE Transactions on Pattern Analysis and Machine Intelligence , 31(6):974\u2013988, 2009.",
        "ref_ids": [
          "23"
        ]
      },
      "Structured depth prediction in challenging monocular video sequences": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1511.06070",
        "ref_texts": "[40] G. Zhang, J. Jia, T.-T. Wong, and H. Bao. Consistent depth maps recovery from a video sequence. PAMI , 2009.",
        "ref_ids": [
          "40"
        ]
      },
      "Hole-filling based on disparity map for DIBR": {
        "authors": [],
        "url": "https://koreascience.kr/article/JAKO201203939216147.pdf",
        "ref_texts": "[16] G. Zhang, J . Jia, T .-T. Wong, H . Bao, \u201cConsistent depth maps recovery from a video sequence ,\u201d IEEE Transactions on Pattern Analysis and Machine Intelligence , vol. 31, no. 6, pp. 974-988,2009 . Article ",
        "ref_ids": [
          "16"
        ]
      },
      "Temporally consistent depth map prediction using deep convolutional neural network and spatial-temporal conditional random field": {
        "authors": [],
        "url": "https://jcst.ict.ac.cn/en/article/pdf/preview/10.1007/s11390-017-1735-x.pdf",
        "ref_texts": "[6] Zhang G F, Jia J, Wong T T, Bao H J. Consistent depth maps recovery from a video sequence. IEEE Transactions on Pattern Analysis and Machine Intelligence , 2009, 31(6): 974-988.",
        "ref_ids": [
          "6"
        ]
      },
      "\u7535\u5f71 2D/3D \u8f6c\u6362\u6280\u672f\u6982\u8ff0": {
        "authors": [],
        "url": "https://www.jcad.cn/cn/article/pdf/preview/4011a0f2-dbba-4465-9dcb-0594379c1717.pdf",
        "ref_texts": ""
      },
      "Depth based image registration via 3D geometric segmentation": {
        "authors": [],
        "url": "https://www.cs.cityu.edu.hk/~dapengwu/mypapers/Depth-basedIR3DGS.pdf",
        "ref_texts": "[25] G. Zhang, J. Jia, T. Wong, and H. Bao, \u201cConsistent Depth Maps Recovery from a Video Sequence,\u201d IEEE Transactions on Pattern Analysis and Machine Intelligence , pp. 974\u2013988, 2009.",
        "ref_ids": [
          "25"
        ]
      },
      "Fast temporal filtering of depth maps": {
        "authors": [],
        "url": "https://otik.uk.zcu.cz/bitstream/11025/405/3/Matyunin_2011_WSCG_Poster_Papers.pdf",
        "ref_texts": "[ZJWB09] Guofeng Zhang, Jiaya Jia, Tien-Tsin Wong, and Hujun Bao. Consistent depth maps recovery from a video sequence. IEEE Transactions on Pattern Analysis and Machine Intelligence , 31(6):974\u2013",
        "ref_ids": [
          "ZJWB09"
        ]
      },
      "Tensor recovery from noisy and multi-level quantized measurements": {
        "authors": [
          "Ren Wang"
        ],
        "url": "https://link.springer.com/content/pdf/10.1186/s13634-020-00698-z.pdf",
        "ref_texts": "50. G.Zhang,J.Jia,T.-T.Wong,H.Bao,Consistentdepthmapsrecoveryfromavideosequence.IEEETrans.Pattern.Anal. Mach.Intell. 31(6),974\u2013988(2009)",
        "ref_ids": [
          "50"
        ]
      },
      "Recovering depth of a dynamic scene using real world motion prior": {
        "authors": [],
        "url": "https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=9160b76b18cfd97ad95fb84913e2cd74909729ae",
        "ref_texts": "[9] M. Pollefeys, D. Nistr, J. Frahm, A. Akbarzadeh, P. Mordohai, B. Clipp, C. Engels, D. Gallup, S. Kim, P. Merrell, C. Salmi, S Sinha, B. Talton, L. Wang, Q. Yang, H. Stewnius, R. Yang, G. Welch, and H. Towles, \u201cDetailed real-time urban 3d reconstruction from video.,\u201d IJCV , vol. 78, no. 2-3, pp. 143\u2013167, 2008.[10] Guofeng Zhang, Jiaya Jia, Tien-Tsin Wong, and Hujun Bao, \u201cConsistent depth maps recovery from a video sequence,\u201d PAMI , vol. 31, June 2009.",
        "ref_ids": [
          "9",
          "10"
        ]
      },
      "3D multimedia signal processing": {
        "authors": [],
        "url": "https://projet.liris.cnrs.fr/imagine/pub/proceedings/ACM-MULTIMEDIA-2012/mm/p1445.pdf",
        "ref_texts": "[19] G. Zhang, J. Jia, T.-T. Wong, and H. Bao. Consistent depth maps recovery from a video sequence. IEEE TPAMI, 31(6):974 \u2013988, 2009.",
        "ref_ids": [
          "19"
        ]
      },
      "Online Mapping and Perception Algorithms for Multi-robot Teams Operating in Urban Environments.": {
        "authors": [],
        "url": "https://deepblue.lib.umich.edu/bitstream/handle/2027.42/113516/jhstrom_1.pdf?sequence=1",
        "ref_texts": "[33] G. Zhang, J. Jia, T.-T. Wong, and H. Bao, \\Consistent depth maps recovery from a video sequence,\" Pattern Analysis and Machine Intelligence, IEEE Transactions on , vol. 31, no. 6, pp. 974{988, june 2009.",
        "ref_ids": [
          "33"
        ]
      },
      "Multi-view depth estimation and plane-sweeping rednering on graphic processor unit": {
        "authors": [],
        "url": "https://trepo.tuni.fi/bitstream/handle/10024/142067/JafariKianoush.pdf?sequence=2",
        "ref_texts": "[37] Zhang G, Jia J, Wong TT, Bao H. Consistent depth maps recovery from a video sequence. IEEE Transactions on pattern analysis and machine intelligence. ",
        "ref_ids": [
          "37"
        ]
      },
      "A Unified Probabilistic Framework for Real-Time Depth Map Fusion.": {
        "authors": [],
        "url": "https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=1babae1c11d354e4fc0d063679fba4c5a53ecfc5",
        "ref_texts": "1. Curless B, Levoy M, \u201cA volumetric method for building complex models from range images.,\u201d In: Proceedings of SIGGRAPH, pp 303-312,1996 2. Narayanan P, Rander P, Kanade T, Constructing virtual worlds using dense stereo. In: IEEE International Conference on Computer Vision,1998 3. Goesele M,Curless B, Seitz S, Multi-view stereo revisited. In: IEEE Conference on Computer Vision and Pattern Recognition, pp 2402-2409,2006 4. Zach C, Pock T,Bischof H,A globally optimal algorithm for robust tv-l1 range image integration. In: IEEE International Conference on Computer Vision, pp 1-8,2007 5. Bradley D, Boubekeur T, Heidrich W, \u201cAccurate multi-view reconstruction using robust binocular stereo and surface meshing,\u201d In: IEEE Conference on Computer Vision and Pattern Recognition, 2008 6. Campbell N, Vogiatzis G, Hernndez C, Cipolla R,\u201d Using multiple hypotheses to improve depth-maps formulti-view stereo,\u201d In: European Conference on Computer Vision, pp 766-779, 2008 7. Furukawa Y, Ponce J,\u201d Accurate, dense, and robust multiview stereopsis,\u201d IEEE Transactions on Pattern Analysis and Machine Intelligence 32:1362-1376,2010 8. Liu Y, Cao X, Dai Q, XuW, Continuous depth estimation for multi-view stereo. In: IEEE Conference on Computer Vision and Pattern Recognition, pp 2121-2128, 2009 9. Li J, Li E, Chen Y, Xu L, Zhang Y,Bundled depth-map merging for multi-view stereo. In: IEEE Conference on Computer Vision and Pattern Recognition, pp 2769-2776, 2010 10. Sato T, Kanbara M, Yokoya N, Takemura H, Dense 3-d reconstruction of an out-door scene by hundreds-baseline stereo using a hand-held video camera. Interna-tional Journal of Computer Vision 47:119-129, 2002 11. Pollefeys M, Van Gool L, Vergauwen M, Verbiest F, Cornelis K, Tops J, Koch R, Visual modeling with a hand-held camera. International Journal of Computer Vi-sion 59:207-232, 2004 12. Zhang G, Jia J, Wong TT, Bao H,Consistent depth maps recovery from a video sequence. IEEE Transactions on Pattern Analysis and Machine Intelligence 31:974-988, 2009 13. Zhu J, Wang L, Yang R, Davis J,Fusion of time-of-fight depth and stereo for high accuracy depth maps. In: IEEE Conference on Computer Vision and Pattern FRAMEWORK FOR REAL-TIME DEPTH MAP FUSION ",
        "ref_ids": [
          "1"
        ]
      },
      "Dense depth map generation using sparse depth data from normal flow": {
        "authors": [],
        "url": "https://projet.liris.cnrs.fr/imagine/pub/proceedings/ICIP-2014/Papers/1569914009.pdf",
        "ref_texts": "[3] G. Zhang, J. Jia, T.-T. Wong, and H. Bao, \u201cConsistent depth maps recovery from a video sequence,\u201d in Transactions on Pattern Analysis and Machine Intelligence . IEEE, 2009, vol. 31, pp. 974\u2013988.",
        "ref_ids": [
          "3"
        ]
      },
      "Global optimization for spatio-temporally consistent view synthesis": {
        "authors": [],
        "url": "http://www.apsipa.org/proceedings_2012/papers/220.pdf",
        "ref_texts": "[17] G. Zhang, J. Jia, T.-T. Wong, and H. Bao, \u201cConsistent depth maps recovery from a video sequence,\u201d IEEE Trans. Pattern Anal. Mach. Intell. , vol. 31, no. 6, pp. 974\u2013988, 2009.",
        "ref_ids": [
          "17"
        ]
      },
      "Automatic stereoscopic video generation based on virtual view synthesis": {
        "authors": [
          "Lin Zhong"
        ],
        "url": "https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=6d984ce957f39c9db5d1f6132e4f137113c440f6",
        "ref_texts": "[20] G. Zhang, J. Jia, T. Wong, H. Bao, Consistent depth maps recovery from a video sequence, IEEE Trans. Pattern Anal. Mach. Intell. 31 (6) (2009) 974 \u2013988.",
        "ref_ids": [
          "20"
        ]
      },
      "An efficient image editing method for perspective scenes": {
        "authors": [],
        "url": "https://www.jcad.cn/en/article/pdf/preview/c274d8cc-ea67-4435-bafa-e5a170daed33.pdf",
        "ref_texts": "[9] Zhang G F, Jia J Y , Wong T T, et al. Consistent depth maps recovery from a video sequence[J] . IEEE Transactions on Pattern Analysis and Machine Intelligence, 2009, 31(6): 974-988 [10] Chen Y D, Hao C Y , Cai Z M, et al. Live accurate and dense reconstruction from a handheld camera[J].Computer Animation and Virtual Worlds, 2013, 24(3/4): 387-397 ",
        "ref_ids": [
          "9",
          "J",
          "10",
          "J"
        ]
      },
      "Image Coding Using Depth Blurring for Aesthetically Acceptable Distortion": {
        "authors": [],
        "url": "https://www.eecs.qmul.ac.uk/~andrea/papers/2011_TIP_PopkinCavallaroHands_ImageCodingDepthBlurringAestheticallyAcceptableDistortion.pdf",
        "ref_texts": "[12] G. Zhang, J. Jia, T.-T. Wong and H. Bao, \u201cConsistent depth maps recovery from a video sequence,\u201d IEEE Trans. Pattern Anal. Mach. Intell. , vol. 31, no. 6, pp. 974\u2013988, Jun. 2009.",
        "ref_ids": [
          "12"
        ]
      },
      "An Approach of Automatic Reconstruction of Building Models for Virtual Cities from Open Resources": {
        "authors": [
          "Sumit Khairnar"
        ],
        "url": "https://scholar.uwindsor.ca/cgi/viewcontent.cgi?article=8961&context=etd",
        "ref_texts": "31. Zhang, G., Jia, J., Wong, T. T., & Bao, H. (2009). Consistent depth maps recovery from a video sequence. IEEE Transactions on pattern analysis and machine intelligence , 31(6), 974 -988. ",
        "ref_ids": [
          "31"
        ]
      },
      "A real-time system for 3D recovery of dynamic scenes based on multiple RGBD imagers": {
        "authors": [],
        "url": "https://journal.bit.edu.cn/zr/en/article/pdf/preview/20141112.pdf",
        "ref_texts": "[9]ZhangG,JiaJ,WongTT,etal.Consistentdepth mapsrecoveryfromavideosequence[J].IEEE TransactionsonPatternAnalysisandMachine Intelligence,2009,31:974988.",
        "ref_ids": [
          "9",
          "J"
        ]
      },
      "Image processing method and apparatus": {
        "authors": [],
        "url": "https://patentimages.storage.googleapis.com/ee/04/52/cf74e6126da905/US10382737.pdf"
      },
      "Space-variant picture coding": {
        "authors": [],
        "url": "https://qmro.qmul.ac.uk/xmlui/bitstream/handle/123456789/612/POPKINSpace-Variant2010.pdf?sequence=1",
        "ref_texts": "[143] G. Zhang, J. Jia, T.-T. Wong and H. Bao, \\Consistent depth maps recovery from a video sequence,\" IEEE Trans. Pattern Anal. Mach. Intell. , vol. 31, no. 6, pp. 974{988, Jun. 2009.",
        "ref_ids": [
          "143"
        ]
      },
      "Depth extraction from monocular video using bidirectional energy minimization and initial depth segmentation": {
        "authors": [
          "Jan Haspeslagh"
        ],
        "url": "https://biblio.ugent.be/publication/2975075/file/2975098.pdf",
        "ref_texts": "[9] G. Zhang, J. Jia, T.-T. Wong, and H. Bao, \u201cConsistent depth maps recovery from a video sequence,\u201d IEEE Trans. Pattern Anal. Mach. Intell. , vol. 31, pp. 974\u2013988, June 2009.",
        "ref_ids": [
          "9"
        ]
      },
      "METHODS FOR SOLVING REGULARIZED INVERSE PROBLEMS": {
        "authors": [],
        "url": "https://dial.uclouvain.be/pr/boreal/object/boreal%3A191756/datastream/PDF_01/view",
        "ref_texts": "2253. Yu, G., Sapiro, G., and Mallat, S. (2012). Solving inverse problems with piecewise linear estimators: From gaussian mixture models to structured sparsity. Transactions on Image Processing , 21(5):2481\u20132499. Yuan, M. and Lin, Y. (2006). Model selection and estimation in regression with grouped varibles. J. R. Statist. Soc. B , 68(1):49\u201367. Zeiler, M. D., Krishnan, D., Taylor, G. W., and Fergus, R. (2010). Deconvolutional networks. In Proc. IEEE Conf. Computer Vision and Pattern Recognition (CVPR) , pages 2528\u20132535, San Francisco, CA, USA. Zhang, G., Jia, J., Wong, T. T., and Bao, H. (2009). Consistent depth maps recovery from a video sequence. IEEE Transactions on Pattern Analysis and Machine Intelligence , 31(6):974\u2013988. Zhao, P . and Yu, B. (2006). On model selection consistency of Lasso. J. Mach. Learn. Res. , 7:2541\u20132563. APPENDIX A ELEMENTS OF CONVEX OPTIMIZATION In this appendix, we provide a brief theoretical background on selected topics in convex optimization. A lot of these standard definitions were copied, sometimes verbatim, from the thesis of Samuel Vaiter [2014]",
        "ref_ids": [
          "2253"
        ]
      },
      "Multi-view depth map sampling for 3D reconstruction of natural scene": {
        "authors": [],
        "url": "https://www.jcad.cn/en/article/pdf/preview/1bac11a1-dfec-43ff-96b8-11e2522feb39.pdf",
        "ref_texts": "[22] Zhang G F, Jia J Y, Wong T T, et al. Consistent depth maps recovery from a video sequence[J] . IEEE Transactions on Pattern Analysis and Machine In telligence, 2009, 31(6):974-988 ",
        "ref_ids": [
          "22",
          "J"
        ]
      },
      "Novel view-synthesis from multiple sources for conversion to 3DS": {
        "authors": [],
        "url": "https://vision.unipv.it/CV/materiale2015-16/fourthchoice/92790041.pdf",
        "ref_texts": "25. Zhang, G., Jia, J., Wong, T.T., Bao, H.: Consistent depth maps recovery from a video sequence. IEEE Trans. on Patt. Analysis and Machine Intell. 31(6), 974\u2013988",
        "ref_ids": [
          "25"
        ]
      },
      "Monocular depth estimation in images and sequences using occlusion cues": {
        "authors": [],
        "url": "https://upcommons.upc.edu/bitstream/handle/2117/95302/TGPV1de1.pdf",
        "ref_texts": "2000, pp. 523\u2013545 (see p. 19). Xiao, J., H. Cheng, et al. \u201cBilateral filtering-based optical flow estimation with occlusion detection\u201d. In: IEEE ECCV. 2006, pp. 211\u2013224 (see p. 66). Xiao, J. and M. Shah. \u201cMotion layer extraction in the presence of occlusion using graph cuts\u201d. In: IEEE TP AMI 27.10 2005, pp. 1644\u20131659 (see p. 174). Xiao, J., J. Hays, et al. \u201cSun database: Large-scale scene recognition from abbey to zoo\u201d. In:IEEE CVPR. IEEE. 2010, pp. 3485\u20133492 (see p. 93). Xu, C., S. Whitt, and J. J. Corso. \u201cFlattening Supervoxel Hierarchies by the Uniform Entropy Slice\u201d. In: IEEE ICCV. 2013 (see p. 114). Xu, C. and J. J. Corso. \u201cEvaluation of super-voxel methods for early video processing\u201d. In:IEEE CVPR. 2012, pp. 1202\u20131209 (see pp. 180, 185). Xu, L., J. Chen, and J. Jia. \u201cA segmentation based variational model for accurate optical flow estimation\u201d. In: IEEE ECCV. Vol. 1. Citeseer. 2008, pp. 671\u2013684 (see p. 60). Xu, L., J. Jia, and Y. Matsushita. \u201cMotion detail preserving optical flow estimation\u201d. In: IEEE CVPR. 2010, pp. 1293\u20131300 (see p. 63). Xu, Y., T. G \u00b4eraud, and L. Najman. \u201cMorphological filtering in shape spaces: Applications using tree-based image representations\u201d. In: Int. Conf. on Pattern Recognition. IEEE. 2012, pp. 485\u2013488 (see p. 97). Yan, J. and M. Pollefeys. \u201cA General Framework for Motion Segmentation: Independent, Articulated, Rigid, Non-rigid, Degenerate and Non-degenerate\u201d. In: IEEE ECCV. 2006, pp. 94\u2013106 (see pp. 169, 174). Yu, S. X. \u201cAngular embedding: From jarring intensity differences to perceived luminance\u201d. In: IEEE CVPR. 2009, pp. 2302\u20132309 (see p. 91). Zhang, G., J. Jia, T. T. Wong, et al. \u201cRecovering consistent video depth maps via bundle optimization\u201d. In: IEEE TP AMI 2008 (see p. 168). Zhang, G., J. Jia, W. Hua, et al. \u201cRobust bilayer segmentation and motion/depth estimation with a handheld camera.\u201d In: IEEE TP AMI 33.3 2011, pp. 603\u201317 (see pp. 37, 171). Zhang, G., J. Jia, T.-T. Wong, et al. \u201cConsistent Depth Maps Recovery from a Video Sequence\u201d. In: IEEE TP AMI 31.6 2009, pp. 974\u2013988 (see pp. 151, 168, 219, 220)."
      },
      "\u57fa\u4e8e\u591a\u89c6\u56fe\u6df1\u5ea6\u91c7\u6837\u7684\u81ea\u7136\u573a\u666f\u4e09\u7ef4\u91cd\u5efa": {
        "authors": [],
        "url": "https://www.jcad.cn/cn/article/pdf/preview/1bac11a1-dfec-43ff-96b8-11e2522feb39.pdf",
        "ref_texts": "[22] Zhang G F, Jia J Y, Wong T T, et al. Consistent depth maps recovery from a video sequence[J] . IEEE Transactions on Pattern Analysis and Machine In telligence, 2009, 31(6):974-988 ",
        "ref_ids": [
          "22",
          "J"
        ]
      },
      "Perceived Blur in Stereoscopic Video: Experiments and Applications": {
        "authors": [
          "Ankit K. Jain"
        ],
        "url": "https://escholarship.org/content/qt3250236n/qt3250236n_noSplash_ea90a18ea4d09a9c4c65c89a8040c83a.pdf",
        "ref_texts": "[90] G. Zhang, J. Jia, T.-T. Wong, and H. Bao, \\Consistent depth maps recovery from a video sequence,\" IEEE Trans. Pattern Anal. Mach. Intell. , vol. 31, no. 6, pp. 974{988, 2009.",
        "ref_ids": [
          "90"
        ]
      },
      "Adaptive Depth Guided Image Completion for Structure and Texture Synthesis": {
        "authors": [],
        "url": "https://rshare.library.torontomu.ca/articles/thesis/Adaptive_Depth_Guided_Image_Completion_for_Structure_and_Texture_Synthesis/14644374/1/files/28123077.pdf",
        "ref_texts": "[42] G. Zhang, J. Jia, T-T Wong, and H. Bao, \\Consistent depth maps recovery from a video sequence,\" Pattern Analysis and Machine Intelligence, IEEE Transactions on , vol. 31, no. 6, pp. 974{988, June 2009.",
        "ref_ids": [
          "42"
        ]
      },
      "Spatio-temporal segmentation with depth-inferred videos of static scenes": {
        "authors": [],
        "url": "https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=60ab71e267e9b7adf77239ae7f4ced9305d29cfd",
        "ref_texts": "4. Zhang, G., Jia, J., Wong, T.T., Bao, H.: Consistent depth maps recover y from a video sequence. IEEE Transactions on Pattern Analysis and Machine In telligence 31(2009) 974\u2013988",
        "ref_ids": [
          "4"
        ]
      },
      "Image guided cost aggregation for hierarchical depth map fusion": {
        "authors": [],
        "url": "https://www.scitepress.org/PublishedPapers/2013/42129/42129.pdf",
        "ref_texts": "2008. 19th International Conference on , pages 1\u20134. IEEE. Unger, C., Wahl, E., Sturm, P., Ilic, S., et al. (2010). Probabilistic disparity fusion for real-time motion-stereo. Citeseer. Veksler, O. (2003). Fast variable window for stereo correspondence using integral images. In Computer Vision and Pattern Recognition, 2003. Proceedings. 2003IEEE Computer Society Conference on , volume 1, pages I\u2013556. IEEE. Wang, L., Gong, M., Gong, M., and Yang, R. (2006). How far can we go with local optimization in real-time stereo matching. In 3D Data Processing, Visualization, and Transmission, Third International Symposium on , pages 129\u2013136. IEEE. Yang, R. and Pollefeys, M. (2003). Multi-resolution realtime stereo on commodity graphics hardware. In Computer Vision and Pattern Recognition, 2003. Proceedings. 2003 IEEE Computer Society Conference on, volume 1, pages I\u2013211. IEEE. Yoon, K. and Kweon, I. (2006). Adaptive support-weight approach for correspondence search. Pattern Analysis and Machine Intelligence, IEEE Transactions on , 28(4):650\u2013656. Zach, C. (2008). Fast and high quality fusion of depth maps. In Proceedings of the International Symposium on 3D Data Processing, Visualization and Transmission (3DPVT) , volume 1. Zach, C., Karner, K., and Bischof, H. (2004). Hierarchical disparity estimation with programmable 3d hardware. In Proc. of WSCG, Pilsen, Czech Republic , pages 275\u2013282. Zhang, G., Jia, J., Wong, T., and Bao, H. (2009). Consistent depth maps recovery from a video sequence. Pattern Analysis and Machine Intelligence, IEEE Transactions on , 31(6):974\u2013988. Zitnick, C., Kang, S., Uyttendaele, M., Winder, S., and Szeliski, R. (2004). High-quality video view interpolation using a layered representation. In ACM Transactions on Graphics (TOG) , volume 23, pages 600\u2013",
        "ref_ids": [
          "2008"
        ]
      },
      "Motion imitation with a handheld camera": {
        "authors": [],
        "url": "http://www.cad.zju.edu.cn/home/gfzhang/projects/imitation/imitation_final.pdf",
        "ref_texts": "[33] G. Zhang, J. Jia, T.-T. Wong, and H. Bao, \u201cConsistent dep th maps recovery from a video sequence,\u201d IEEE Trans. Pattern Anal. Mach. Intell., vol. 31, no. 6, pp. 974\u2013988, 2009.",
        "ref_ids": [
          "33"
        ]
      },
      "An Interactive Perspective Scene Completion Framework Guided by Complanate Mesh": {
        "authors": [],
        "url": "https://koreascience.kr/article/JAKO202011161036538.pdf",
        "ref_texts": "[1] G. F. Zhang, J. Y. Jia, T. T. Wong and H. J. Bao, \u201cConsistent depth maps recovery from a video sequence,\u201d IEEE Transactions on Pattern Analysis and Machine Intelligence , vol. 1, no. 31, pp. ",
        "ref_ids": [
          "1"
        ]
      },
      "\u57fa\u4e8e\u5168\u5c40\u4f18\u5316\u7684\u4fdd\u7ec6\u8282\u5206\u5c42\u591a\u89c6\u56fe\u7acb\u4f53\u5339\u914d": {
        "authors": [],
        "url": "https://www.jcad.cn/cn/article/pdf/preview/aba5df6b-ac51-4883-aebe-0ac2cd40c14f.pdf",
        "ref_texts": "[19]ZhangGF\u3002Jia JY,WongTT\u3002etal.Consistentdepthmaps recovery from avideosequence[J].IEEE Transactions on Pattern AnalysisandMachine Intelligence,2009\u300231(6):",
        "ref_ids": [
          "19",
          "J"
        ]
      },
      "\uacb0\ud569\ud615 \uc591\ubc29\ud5a5 \ud544\ud130\ub97c \uc774\uc6a9\ud55c \uae4a\uc774 \uc601\uc0c1\uc758 \ud6c4\ucc98\ub9ac \ud544\ud130\ub9c1 \ubc29\ubc95": {
        "authors": [],
        "url": "https://koreascience.kr/article/JAKO201113253031617.pdf",
        "ref_texts": "[15]G.Zhang,J.Jia,T.Wong,andH.Bao, \u201cConsistentDepthMapsRecoveryfroma VideoSequence,\u201dIEEETransactionson PatternAnalysisandMachineIntelligence, Vol.31,No.6,pp.974-988,2009.",
        "ref_ids": [
          "15"
        ]
      },
      "Exploring Temporal Information for Improved Video Understanding": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1905.10654",
        "ref_texts": "[199] Guofeng Zhang, Jiaya Jia, Tien-Tsin Wong, and Hujun Bao. Consistent Depth Maps Recovery from a Video Sequence. IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI) , 2009.",
        "ref_ids": [
          "199"
        ]
      },
      "Video stabilization: A synopsis of current challenges, methods and performance evaluation": {
        "authors": [],
        "url": "https://theses.hal.science/tel-03006243/file/edgalilee_th_2018_guilluy.pdf",
        "ref_texts": "[55] G. Zhang, J. Jia, T.-T. Wong, and H. Bao, \u201cConsistent depth maps recovery from a video sequence\u201d, IEEE Transactions on Pattern Analysis and Machine Intelligence , vol. 31, no. 6, pp. 974\u2013988, 2009.",
        "ref_ids": [
          "55"
        ]
      },
      "\u5355\u5e45 RGB-D \u56fe\u50cf\u672c\u5f81\u56fe\u50cf\u4ea4\u4e92\u5206\u89e3\u7b97\u6cd5": {
        "authors": [],
        "url": "https://www.jcad.cn/cn/article/pdf/preview/8dc069cc-9a61-41ea-a27d-ab2a647ded82.pdf",
        "ref_texts": "[22] Zhang G F, Jia J Y, Wong T T, et al. Consistent depth maps recovery from a video sequence[J] . IEEE Transactions on Pattern Analysis & Machine Inte lligence, 2009, 31(6): 974-988 ",
        "ref_ids": [
          "22",
          "J"
        ]
      },
      "Effective techniques for digital image processing": {
        "authors": [
          "Ba Thai"
        ],
        "url": "https://opal.latrobe.edu.au/articles/thesis/Effective_techniques_for_digital_image_processing/21845769/1/files/38768946.pdf",
        "ref_texts": "[168] G. Zhang, J. Jia, T.-T. Wong, and H. Bao, \u201cConsistent depth maps recovery from a video sequence,\u201d IEEE Trans. Pattern Anal. Mach. Intell. , vol. 31, no. 6, pp. 974\u2013988, 2009.",
        "ref_ids": [
          "168"
        ]
      },
      "FPGA Architecture for Real-time Depth Estimation System": {
        "authors": [],
        "url": "https://gvpress.com/journals/IJHIT/vol10_no1/29.pdf",
        "ref_texts": "[20] G. Zhang, J . Jia, T .-T. Wong and H. Bao, \u201cConsistent depth maps recovery from a video sequence\u201d, IEEE Transactions on Pattern Analysis and Machine Intelligence , vol. 31, no. 6 , (2009) , pp. 974-988. ",
        "ref_ids": [
          "20"
        ]
      },
      "Supplemental Material for Depth from Gradients in Dense Light Fields for Object Reconstruction": {
        "authors": [],
        "url": "https://igl.ethz.ch/projects/depth-from-gradient/Depth-from-Gradients-in-Dense-Light-Fields-for-Object-Reconstruction-supplemental.pdf",
        "ref_texts": "[2]G. Zhang, J. Jia, T. Wong, and H. Bao. Consistent depth maps recovery from a video sequence. PAMI , 31(6), 2009. 2",
        "ref_ids": [
          "2"
        ]
      },
      "Semantic segmentation of outdoor scenes using LIDAR cloud point": {
        "authors": [],
        "url": "https://trepo.tuni.fi/bitstream/handle/123456789/22883/Babahajiani.pdf?sequence=3",
        "ref_texts": "27) G. Zhang, J. Jia, T. Wong, H. Bao, Consistent depth maps recovery from a video sequence , Pattern Analysis and Mach ine Intelligence, IEEE Transactions on 31 "
      },
      "Review on Accurate Multiple View 3D Reconstruction Using Depth Map Merging": {
        "authors": [],
        "url": "https://scholar.archive.org/work/7tcp4qva5zgg3ewjcivwenai7a/access/wayback/http://spvryan.org/archive/issue5volume2/26.pdf",
        "ref_texts": ""
      },
      "Video disparity estimate space-time refinement method and codec": {
        "authors": [],
        "url": "https://patentimages.storage.googleapis.com/8b/19/a9/38b2e81e6efab4/US9659372.pdf",
        "ref_texts": " (2008) pp. 1-8; G. Zhang, J. Jia, T. T. Wong, and H. Bao, \u201cConsistent Depth Maps Recovery from a Video Sequence.\u201d "
      },
      "Spatio-Temporal Geometry Fusion for Multiple Hybrid Cameras using Moving Least Squares Surfaces": {
        "authors": [],
        "url": "https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=ac6cace45abbbea6b90d5e7e842d2ca727b8d8ac",
        "ref_texts": "[ZJWB09] ZHANG G., J IAJ., W ONG T.-T., B AOH.: Consistent depth maps recovery from a video sequence. IEEE TPAMI (2009).",
        "ref_ids": [
          "ZJWB09"
        ]
      },
      "Acceleration of monocular depth extraction for images": {
        "authors": [],
        "url": "https://etda.libraries.psu.edu/files/final_submissions/10458",
        "ref_texts": "[11] G. Zhang, J. Jia, T.-T. Wong, and H. Bao, \\Consistent depth maps recovery from a video sequence.,\" IEEE Trans. Pattern Anal. Mach. Intell. , vol. 31, no. 6, pp. 974{988, 2009.",
        "ref_ids": [
          "11"
        ]
      },
      "High-Quality Depth Recovery via Interactive Multi-View Stereo": {
        "authors": [],
        "url": "http://www.cad.zju.edu.cn/home/gfzhang/projects/depth-repair/3DV2014-paper54.pdf",
        "ref_texts": "[34] G. Zhang, J. Jia, T.-T. Wong, and H. Bao. Consistent depth maps recovery from a video sequence. IEEE Trans. Pattern Anal. Mach. Intell. , 31(6):974\u2013988, 2009.",
        "ref_ids": [
          "34"
        ]
      },
      "Occlusion-Aware Motion Deblurring for Bilayer Scenes": {
        "authors": [],
        "url": "https://s-space.snu.ac.kr/bitstream/10371/123063/1/000000018338.pdf",
        "ref_texts": "[20]G. Zhang, J. Jia, T.-T. Wong, and H. Bao, \u201cConsistent depth maps recovery from a video sequence,\u201d Pattern Analysis and Machine Intelligence, IEEE Transactions on , vol. 31, no. 6, pp. 974\u2013988, 2009.",
        "ref_ids": [
          "20"
        ]
      },
      "Towards automatic Stereoscopic Video Synthesis from a Casual Monocular video": {
        "authors": [],
        "url": "https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=5a7afb63bdf6eda25a00f70bb87abf9402ef9c34",
        "ref_texts": "[18] G. Zhang, J. Jia, T. Wong, and H. Bao, \u201cConsistent depth maps recovery from a video sequence.\u201d TPAMI , 2009.",
        "ref_ids": [
          "18"
        ]
      },
      "\u57fa\u4e8e\u5339\u914d\u6269\u6563\u7684\u591a\u89c6\u7a20\u5bc6\u6df1\u5ea6\u56fe\u4f30\u8ba1": {
        "authors": [],
        "url": "http://www.aas.net.cn/fileZDHXB/journal/article/zdhxb/2014/12/PDF/2014-12-2782.pdf",
        "ref_texts": "11Zhang G F, Jia J Y, Wong T T, Bao H J. Consistent depth maps recovery from a video sequence. IEEE Transactions on Pattern Analysis and Machine Intelligence , 2009, 31(6): 974\u00a1988"
      },
      "Depth-wise layering of 3d images using dense depth maps: a threshold based approach": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2010.01841",
        "ref_texts": ""
      },
      "Single View Modeling and View Synthesis": {
        "authors": [
          "Miao Liao"
        ],
        "url": "https://uknowledge.uky.edu/cgi/viewcontent.cgi?article=1831&context=gradschool_diss",
        "ref_texts": ""
      },
      "UNSUPERVISED LEARNING FOR TEMPORAL SEARCH SPACE REDUCTION IN THREE-DIMENSIONAL SCENE RECOVERY": {
        "authors": [],
        "url": "https://www.scitepress.org/PublishedPapers/2011/33084/33084.pdf",
        "ref_texts": "435. Zhang, G., Jia, J., Wong, T.-T., and Bao, H. (2009). Consistent depth maps recovery from a video sequence. In IEEE Transactions on Pattern Analysis and Machine Intelligence , volume 21, pages 974\u2013988.VISAPP 2011 International Conference on Computer Vision Theory and Applications 554",
        "ref_ids": [
          "435"
        ]
      },
      "Temporal Post-processing Method for Automatically Generated Depth Maps": {
        "authors": [],
        "url": "https://www.scitepress.org/PublishedPapers/2011/33188/33188.pdf",
        "ref_texts": "(2008b). Fast video super-resolution via classification. In International Conference on Image Processing, pages 349\u2013352. IEEE. Tam, W. J. and Zhang, L. (2004). Non-uniform smoothing of depth maps before image-based rendering. In Proceedings of Three-Dimensional TV , Video and Display III (ITCOM\u201904) , volume 5599, pages 173\u2013183. Vatolin, D., Noskov, A., and Grishin, S. (2009). MSU Brightness Independent PSNR (BI-PSNR). http://compression.ru/video/quality measure/metric plugins/bi-psnr en.htm. Zhang, G., Jia, J., Wong, T.-T., and Bao, H. (2008). Recovering consistent video depth maps via bundle optimization. In IEEE Conference on Computer Vision and Pattern Recognition , pages 1 \u2013 8.Zhang, G., Jia, J., Wong, T.-T., and Bao, H. (2009). Consistent depth maps recovery from a video sequence. IEEE Transactions on Pattern Analysis and Machine Intelligence , 31(6):974\u2013988.IMAGAPP 2011 International Conference on Imaging Theory and Applications 38"
      },
      "Multiview conversion of 2D cartoon images": {
        "authors": [],
        "url": "https://www.intlpress.com/site/pub/files/_fulltext/journals/cis/2016/0016/0004/CIS-2016-0016-0004-a002.pdf",
        "ref_texts": "[61] G. Zhang, J. Jia, T.-T. Wong, and H. Bao, Consistent depth maps recovery from a video sequence , IEEE Trans. Pattern Anal. Mach. Intell.",
        "ref_ids": [
          "61"
        ]
      },
      "Offline Swimmer Cap Tracking Using Trajectory Interpolation": {
        "authors": [
          "Jun Yang"
        ],
        "url": "https://scholar.archive.org/work/h5gwsj2ivnek7iaieczpperpj4/access/wayback/http://nicta.com.au/research/rps?sq_content_src=%2BdXJsPWh0dHBzJTNBJTJGJTJGcHVibGljYXRpb25zLmluc2lkZS5uaWN0YS5jb20uYXUlMkZzZWFyY2glMkZmdWxsdGV4dCUzRmlkJTNENjUmYWxsPTE%3D",
        "ref_texts": ""
      },
      "Estimation du champ dense de mouvement pour la g\u00e9n\u00e9ration semi-automatique de cartes de profondeur": {
        "authors": [],
        "url": "https://espace.etsmtl.ca/id/eprint/1969/1/ROCHELEAU_%C3%89tienne.pdf",
        "ref_texts": "9781118355114. doi : 10.1002/9781118583593.ch3. <http://doi.wiley.com/10.1002/9781118583593http://doi.wiley.com/10.1002/9781118583593.ch3>. Ward, B., Sing Bing Kang, And E. P . Bennett. jan 2011. \u00ab Depth Directo r : A System for Adding Depth to Movies \u00bb. IEEE Computer Graphics and Applications , vol. 31, n \u25e61, p. 36\u201348. Xu, X., L.-M. Po, K.-W. Cheung, K.-H. Ng, K.-M. Wong, And C.-W. Ting. aug 2012. \u00ab Watershed and Random Walks based depth estimation for semi-automatic 2D to 3D imageconversion \u00bb. In 2012 IEEE International Conference on Signal Processing, Communication and Computing (ICSPCC 2012) . p. 84\u201387. IEEE. Y ao, S.-J., L.-H. Wang, D.-X. Li, And M. Zhang. jul 2013. \u00ab A Real-Time Full HD 2D-to-3D Video Conversion System Based on FPGA \u00bb. In 2013 Seventh International Conference on Image and Graphics . p. 774\u2013778. IEEE. Zhang, G., J. Jia, T. T. Wong, And H. Bao. 2009. \u00ab Consistent depth maps recovery from a video sequence \u00bb. IEEE Transactions on Pattern Analysis and Machine Intelligence , vol. 31, n \u25e66, p. 974\u2013988.",
        "ref_ids": [
          "9781118355114"
        ]
      },
      "\u041c\u0435\u0442\u043e\u0434 \u043f\u043e\u0438\u0441\u043a\u0430 \u043d\u0435\u0441\u043e\u043e\u0442\u0432\u0435\u0442\u0441\u0442\u0432\u0438\u0439 \u0433\u0440\u0430\u043d\u0438\u0446 \u043e\u0431\u044a\u0435\u043a\u0442\u043e\u0432 \u043c\u0435\u0436\u0434\u0443 \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442\u043e\u043c 2D-3D \u043a\u043e\u043d\u0432\u0435\u0440\u0442\u0430\u0446\u0438\u0438 \u0438 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u0435\u043c\u044b\u043c\u0438 \u043a\u0430\u0440\u0442\u0430\u043c\u0438 \u0433\u043b\u0443\u0431\u0438\u043d\u044b": {
        "authors": [],
        "url": "https://cyberleninka.ru/article/n/metod-poiska-nesootvetstviy-granits-obektov-mezhdu-rezultatom-2d-3d-konvertatsii-i-ispolzuemymi-kartami-glubiny.pdf",
        "ref_texts": "[15] Consistent depth maps recovery from a video sequence / G. Zhang, J. Jia, T. Wong, H. Bao // Pattern Analysis and Machine Intelligence, IEEE Transactions on. \u2013 \u2013 2009. \u2013 \u2013 V ol. 31, no. 6. \u2013 \u2013 P. 974\u2013",
        "ref_ids": [
          "15"
        ]
      },
      "\u900f\u89c6\u573a\u666f\u7684\u56fe\u50cf\u586b\u8865\u65b9\u6cd5": {
        "authors": [],
        "url": "https://www.jcad.cn/cn/article/pdf/preview/c274d8cc-ea67-4435-bafa-e5a170daed33.pdf",
        "ref_texts": "[9] Zhang G F, Jia J Y , Wong T T, et al. Consistent depth maps recovery from a video sequence[J] . IEEE Transactions on Pattern Analysis and Machine Intelligence, 2009, 31(6): 974-988 [10] Chen Y D, Hao C Y , Cai Z M, et al. Live accurate and dense reconstruction from a handheld camera[J].Computer Animation and Virtual Worlds, 2013, 24(3/4): 387-397 ",
        "ref_ids": [
          "9",
          "J",
          "10",
          "J"
        ]
      },
      "Avalia\u00e7\u00e3o dos n\u00edveis de anticorpos, citocinas e mirnas em pacientes com rinite mediada e n\u00e3o mediada por anticorpos IgE": {
        "authors": [],
        "url": "http://repositorio.ufu.br/bitstream/123456789/16613/1/AvaliacaoNiveisAnticorpos.pdf",
        "ref_texts": ""
      },
      "Reconfiguration st\u00e9r\u00e9oscopique": {
        "authors": [],
        "url": "https://central.bac-lac.gc.ca/.item?id=MR88874&op=pdf&app=Library&oclc_number=910984169",
        "ref_texts": "[71] G. ZHANG, J. JIA, T.-T. WONG et H. BAO : Consistent depth maps recovery from a video sequence. IEEE Transactions on Pattern Analysis and Machine Intelligence, 31(6):974-988, juin 2009. ",
        "ref_ids": [
          "71"
        ]
      }
    }
  },
  {
    "title": "pyramid scene parsing network",
    "id": 6,
    "valid_pdf_number": "2343/3531",
    "matched_pdf_number": "0/2343",
    "matched_rate": 0.0,
    "citations": {
      "Lisa: Reasoning segmentation via large language model": {
        "authors": [
          "Xin Lai",
          "Zhuotao Tian",
          "Yukang Chen",
          "Yanwei Li",
          "Yuhui Yuan",
          "Shu Liu",
          "Jiaya Jia"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Lai_LISA_Reasoning_Segmentation_via_Large_Language_Model_CVPR_2024_paper.pdf",
        "ref_texts": "[59] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR, 2017. 2",
        "ref_ids": [
          "59"
        ]
      },
      "Change detection methods for remote sensing in the last decade: A comprehensive review": {
        "authors": [
          "Guangliang Cheng",
          "Yunmeng Huang",
          "Xiangtai Li",
          "Shuchang Lyu",
          "Zhaoyang Xu",
          "Hongbo Zhao",
          "Qi Zhao",
          "Shiming Xiang"
        ],
        "url": "https://www.mdpi.com/2072-4292/16/13/2355/pdf",
        "ref_texts": "95. Zhao, H.; Shi, J.; Qi, X.; Wang, X.; Jia, J. Pyramid Scene Parsing Network. In Proceedings of the CVPR 2017, Minneapolis, MN, USA, 17\u201322 June 2007; IEEE Computer Society: Piscataway, NJ, USA, 2017; pp. 6230\u20136239.",
        "ref_ids": [
          "95"
        ]
      },
      "Segment anything in high quality": {
        "authors": [],
        "url": "https://proceedings.neurips.cc/paper_files/paper/2023/file/5f828e38160f31935cfe9f67503ad17c-Paper-Conference.pdf",
        "ref_texts": "[55] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017.",
        "ref_ids": [
          "55"
        ]
      },
      "Drivegpt4: Interpretable end-to-end autonomous driving via large language model": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2310.01412",
        "ref_texts": "[3]H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in CVPR , 2017.",
        "ref_ids": [
          "3"
        ]
      },
      "Dataset diffusion: Diffusion-based synthetic data generation for pixel-level semantic segmentation": {
        "authors": [],
        "url": "https://proceedings.neurips.cc/paper_files/paper/2023/file/f2957e48240c1d90e62b303574871b47-Paper-Conference.pdf",
        "ref_texts": "[19] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , pages 6230\u20136239, 2016. 2",
        "ref_ids": [
          "19"
        ]
      },
      "Freemask: Synthetic images with dense annotations make stronger segmentation models": {
        "authors": [],
        "url": "https://proceedings.neurips.cc/paper_files/paper/2023/file/3ba7560b4c3e66d760fbdd472cf4a5a9-Paper-Conference.pdf",
        "ref_texts": "[74] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017. 3",
        "ref_ids": [
          "74"
        ]
      },
      "Introduction to artificial intelligence": {
        "authors": [],
        "url": "https://thuvienso.hoasen.edu.vn/bitstream/handle/123456789/10507/Contents.pdf?sequence=1&isAllowed=y",
        "ref_texts": ""
      },
      "See Say and Segment: Teaching LMMs to Overcome False Premises": {
        "authors": [
          "Han Wu",
          "Giscard Biamby",
          "David Chan",
          "Lisa Dunlap",
          "Ritwik Gupta",
          "Xudong Wang",
          "Joseph E. Gonzalez",
          "Trevor Darrell"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Wu_See_Say_and_Segment_Teaching_LMMs_to_Overcome_False_Premises_CVPR_2024_paper.pdf",
        "ref_texts": "[78] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017. 2",
        "ref_ids": [
          "78"
        ]
      },
      "How2comm: Communication-efficient and collaboration-pragmatic multi-agent perception": {
        "authors": [],
        "url": "https://proceedings.neurips.cc/paper_files/paper/2023/file/4f31327e046913c7238d5b671f5d820e-Paper-Conference.pdf",
        "ref_texts": "[58] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) , pages 2881\u20132890, 2017. 1",
        "ref_ids": [
          "58"
        ]
      },
      "Rethinking semi-supervised medical image segmentation: A variance-reduction perspective": {
        "authors": [],
        "url": "https://proceedings.neurips.cc/paper_files/paper/2023/file/1f7e6d5c84b0ed286d0e69b7d2c79b47-Paper-Conference.pdf",
        "ref_texts": "[34] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017.",
        "ref_ids": [
          "34"
        ]
      },
      "Fine-grained visual prompting": {
        "authors": [],
        "url": "https://proceedings.neurips.cc/paper_files/paper/2023/file/4e9fa6e716940a7cfc60c46e6f702f52-Paper-Conference.pdf",
        "ref_texts": "[67] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017.",
        "ref_ids": [
          "67"
        ]
      },
      "Knowledge diffusion for distillation": {
        "authors": [],
        "url": "https://proceedings.neurips.cc/paper_files/paper/2023/file/cdddf13f06182063c4dbde8cbd5a5c21-Paper-Conference.pdf",
        "ref_texts": "[54] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017. 8",
        "ref_ids": [
          "54"
        ]
      },
      "OA-CNNs: Omni-Adaptive Sparse CNNs for 3D Semantic Segmentation": {
        "authors": [
          "Bohao Peng",
          "Xiaoyang Wu",
          "Li Jiang",
          "Yukang Chen",
          "Hengshuang Zhao",
          "Zhuotao Tian",
          "Jiaya Jia"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Peng_OA-CNNs_Omni-Adaptive_Sparse_CNNs_for_3D_Semantic_Segmentation_CVPR_2024_paper.pdf",
        "ref_texts": "[72] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017. 7",
        "ref_ids": [
          "72"
        ]
      },
      "Global structure-aware diffusion process for low-light image enhancement": {
        "authors": [],
        "url": "https://proceedings.neurips.cc/paper_files/paper/2023/file/fc034d186280f55370b6aca7a3285a65-Paper-Conference.pdf",
        "ref_texts": "[62] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "62"
        ]
      },
      "Lightm-unet: Mamba assists in lightweight unet for medical image segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2403.05246",
        "ref_texts": "25. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: Proceedings of the IEEE conference on computer vision and pattern recognition. pp. 2881\u20132890 (2017)",
        "ref_ids": [
          "25"
        ]
      },
      "LLaFS: When Large Language Models Meet Few-Shot Segmentation": {
        "authors": [
          "Lanyun Zhu",
          "Tianrun Chen",
          "Deyi Ji",
          "Jieping Ye",
          "Jun Liu"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Zhu_LLaFS_When_Large_Language_Models_Meet_Few-Shot_Segmentation_CVPR_2024_paper.pdf",
        "ref_texts": "[69] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017. 1",
        "ref_ids": [
          "69"
        ]
      },
      "IDRNet: Intervention-driven relation network for semantic segmentation": {
        "authors": [],
        "url": "https://proceedings.neurips.cc/paper_files/paper/2023/file/a216c27f2f3160b1785c057fa510fdf1-Paper-Conference.pdf",
        "ref_texts": "[83] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "83"
        ]
      },
      "Polymax: General dense prediction with mask transformer": {
        "authors": [
          "Xuan Yang",
          "Liangzhe Yuan",
          "Kimberly Wilber",
          "Astuti Sharma",
          "Xiuye Gu",
          "Siyuan Qiao",
          "Stephanie Debats",
          "Huisheng Wang",
          "Hartwig Adam",
          "Mikhail Sirotenko",
          "Chieh Chen"
        ],
        "url": "https://openaccess.thecvf.com/content/WACV2024/papers/Yang_PolyMaX_General_Dense_Prediction_With_Mask_Transformer_WACV_2024_paper.pdf",
        "ref_texts": "[112] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017. 1",
        "ref_ids": [
          "112"
        ]
      },
      "Rs-mamba for large remote sensing image dense prediction": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2404.02668",
        "ref_texts": "[45] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "45"
        ]
      },
      "LSKNet: A foundation lightweight backbone for remote sensing": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2403.11735",
        "ref_texts": "[155] Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: CVPR",
        "ref_ids": [
          "155"
        ]
      },
      "Ue4-nerf: Neural radiance field for real-time rendering of large-scale scene": {
        "authors": [],
        "url": "https://proceedings.neurips.cc/paper_files/paper/2023/file/b94d8b035e2183e47afef9e2f299ba47-Paper-Conference.pdf",
        "ref_texts": "[48] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "48"
        ]
      },
      "Cpseg: Finer-grained image semantic segmentation via chain-of-thought language prompting": {
        "authors": [
          "Lei Li"
        ],
        "url": "https://openaccess.thecvf.com/content/WACV2024/papers/Li_CPSeg_Finer-Grained_Image_Semantic_Segmentation_via_Chain-of-Thought_Language_Prompting_WACV_2024_paper.pdf",
        "ref_texts": ""
      },
      "The artificial intelligence-based model ANORAK improves histopathological grading of lung adenocarcinoma": {
        "authors": [
          "Xiaoxi Pan"
        ],
        "url": "https://www.nature.com/articles/s43018-023-00694-w.pdf",
        "ref_texts": "15. Zhao, H., Shi, J., Qi, X., Wang, X. & Jia, J. Pyramid scene parsing network. In Proc. 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) 2881\u20132890 (IEEE, 2017).16. Lin, G., Milan, A., Shen, C. & Reid, I. RefineNet: multi-path refinement networks for high-resolution semantic segmentation. In Proc. 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) 1925\u20131934 (IEEE, 2017).",
        "ref_ids": [
          "15"
        ]
      },
      "Mask propagation for efficient video semantic segmentation": {
        "authors": [],
        "url": "https://proceedings.neurips.cc/paper_files/paper/2023/file/167bcf2af2cd08fcf75b932022db0311-Paper-Conference.pdf",
        "ref_texts": "[75] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In CVPR , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "75"
        ]
      },
      "Assessing generalisability of deep learning-based polyp detection and segmentation methods through a computer vision challenge": {
        "authors": [
          "Sharib Ali"
        ],
        "url": "https://www.nature.com/articles/s41598-024-52063-x.pdf",
        "ref_texts": ""
      },
      "Aims: All-inclusive multi-level segmentation for anything": {
        "authors": [],
        "url": "https://proceedings.neurips.cc/paper_files/paper/2023/file/3da292ced54290c19fc55d9dba3da793-Paper-Conference.pdf",
        "ref_texts": "[13] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017. 3",
        "ref_ids": [
          "13"
        ]
      },
      "Segvit v2: Exploring efficient and continual semantic segmentation with plain vision transformers": {
        "authors": [
          "Bowen Zhang"
        ],
        "url": "https://link.springer.com/content/pdf/10.1007/s11263-023-01894-8.pdf",
        "ref_texts": "181. Wang, Z., Liu, L., Kong, Y ., Guo, J., Tao, D. (2022). Online continual learning with contrastive vision transformer, in Proceedings European conference on computer vision (pp. 631\u2013650), Springer. Wang, W., Xie, E., Li, X., Fan, D.-P., Song, K., Liang, D., Lu, T., Luo, P., Shao, L. (2021). Pyramid vision transformer: A versatile backbonefor dense prediction without convolutions, in Proceedings of the ieee international conference on computer vision , pp. 568\u2013578. Wang, Z., Zhang, Z., Ebrahimi, S., Sun, R., Zhang, H., Lee, C.-Y ., Ren, X., Su, G., Perot, V ., Dy, J., et al. (2022). Dualprompt: Complemen-tary prompting for rehearsal-free continual learning, in Computer Vision-ECCV , 17th European Conference , Tel Aviv, Israel, October 23\u201327, 2022, Proceedings, Part XXVI (pp. 631\u2013648), Springer. Wang, Z., Zhang, Z., Lee, C.-Y ., Zhang, H., Sun, R., Ren, X., Su, G., Perot, V ., Dy, J., Pfister, T. (2022). Learning to prompt for continuallearning, in Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , pp. 139\u2013149. Wang, J., Sun, K., Cheng, T., Jiang, B., Deng, C., Zhao, Y ., Liu, D., Mu, Y ., Tan, M., Wang, X., et al. (2020). Deep high-resolutionrepresentation learning for visual recognition. IEEE Transactions on Pattern Analysis and Machine Intelligence, 43 (10), 3349\u20133364. Wei, L., Xie, L., Zhou, W., Li, H., Tian, Q. (2022). Mvp: Multimodalityguided visual pre-training, in Proceedings European conference on computer vision (pp. 337\u2013353), Springer. Wu, T., Caccia, M., Li, Z., Li, Y .-F., Qi, G., Haffari, G. (2022). Pretrained language model in continual learning: A comparative study,inProceedings of the international conference on learning representation . Wu, Y . -H., Liu, Y ., Zhan, X., Cheng, M. -M. (2022). P2t: Pyramid pooling transformer for scene understanding, IEEE transactions on pattern analysis and machine intelligence . Wu, T., Lu, Y ., Zhu, Y ., Zhang, C., Wu, M., Ma, Z., Guo, G. (2020). Ginet: Graph interaction network for scene parsing, in Proceedings European conference on computer vision (pp. 34\u201351), Springer. Xiao, T., Liu, Y ., Zhou, B., Jiang, Y ., Sun, J. (2018). Unified perceptual parsing for scene understanding, in Proceedings European conference on computer vision , pp. 418\u2013434. Xie, E., Wang, W., Yu, Z., Anandkumar, A., Alvarez, J.M., Luo, P.",
        "ref_ids": [
          "181"
        ]
      },
      "Regional style and color transfer": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2404.13880",
        "ref_texts": "[9] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in IEEE Conf. on Computer Vision and Pattern Recognition (CVPR) , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "9"
        ]
      },
      "Deep learning for iris recognition: A survey": {
        "authors": [],
        "url": "https://dl.acm.org/doi/pdf/10.1145/3651306",
        "ref_texts": "[206] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. 2017. Pyramid scene parsing network. In IEEE International Conference on Computer Vision andPattern Recognition (CVPR) .6230\u20136239.",
        "ref_ids": [
          "206"
        ]
      },
      "Holistic dynamic frequency transformer for image fusion and exposure correction": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2309.01183",
        "ref_texts": "[63] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and JiayaJia. Pyramidsceneparsingnetwork. In ProceedingsoftheIEEE conference on computer vision and pattern recognition , pages 2881\u2013",
        "ref_ids": [
          "63"
        ]
      },
      "Mixdehazenet: Mix structure block for image dehazing network": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2305.17654",
        "ref_texts": "[43] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u2013",
        "ref_ids": [
          "43"
        ]
      },
      "Advanced feature learning on point clouds using multi-resolution features and learnable pooling": {
        "authors": [
          "Kevin Tirta",
          "Hee Paek",
          "Hyun Kong"
        ],
        "url": "https://www.mdpi.com/2072-4292/16/11/1835/pdf",
        "ref_texts": "33. Zhao, H.; Shi, J.; Qi, X.; Wang, X.; Jia, J. Pyramid scene parsing network. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Honolulu, HI, USA, 21\u201326 July 2017; pp. 2881\u20132890.",
        "ref_ids": [
          "33"
        ]
      },
      "HEDNet: A hierarchical encoder-decoder network for 3d object detection in point clouds": {
        "authors": [],
        "url": "https://proceedings.neurips.cc/paper_files/paper/2023/file/a64e641fa00a7eb9500cb7e1835d0495-Paper-Conference.pdf",
        "ref_texts": "[24] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017.",
        "ref_ids": [
          "24"
        ]
      },
      "Omniseg3d: Omniversal 3d segmentation via hierarchical contrastive learning": {
        "authors": [
          "Haiyang Ying",
          "Yixuan Yin",
          "Jinzhi Zhang",
          "Fan Wang",
          "Tao Yu",
          "Ruqi Huang",
          "Lu Fang"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Ying_OmniSeg3D_Omniversal_3D_Segmentation_via_Hierarchical_Contrastive_Learning_CVPR_2024_paper.pdf",
        "ref_texts": "[63] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017. 3",
        "ref_ids": [
          "63"
        ]
      },
      "Panoptic-PartFormer++: A unified and decoupled view for panoptic part segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2301.00954",
        "ref_texts": "[7] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in CVPR , 2017. 1",
        "ref_ids": [
          "7"
        ]
      },
      "Asymformer: Asymmetrical cross-modal representation learning for mobile platform real-time rgb-d semantic segmentation": {
        "authors": [
          "Siqi Du",
          "Weixi Wang",
          "Renzhong Guo",
          "Ruisheng Wang",
          "Shengjun Tang"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024W/USM/papers/Du_AsymFormer_Asymmetrical_Cross-Modal_Representation_Learning_for_Mobile_Platform_Real-Time_RGB-D_CVPRW_2024_paper.pdf",
        "ref_texts": ""
      },
      "Maskconver: Revisiting pure convolution model for panoptic segmentation": {
        "authors": [
          "Abdullah Rashwan",
          "Jiageng Zhang",
          "Ali Taalimi",
          "Fan Yang",
          "Xingyi Zhou",
          "Chaochao Yan",
          "Chieh Chen",
          "Yeqing Li"
        ],
        "url": "https://openaccess.thecvf.com/content/WACV2024/papers/Rashwan_MaskConver_Revisiting_Pure_Convolution_Model_for_Panoptic_Segmentation_WACV_2024_paper.pdf",
        "ref_texts": "[87] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017. 7",
        "ref_ids": [
          "87"
        ]
      },
      "One-shot open affordance learning with foundation models": {
        "authors": [
          "Gen Li",
          "Deqing Sun",
          "Laura Sevilla",
          "Varun Jampani"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Li_One-Shot_Open_Affordance_Learning_with_Foundation_Models_CVPR_2024_paper.pdf",
        "ref_texts": "[64] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017. 6",
        "ref_ids": [
          "64"
        ]
      },
      "RVD: a handheld device-based fundus video dataset for retinal vessel segmentation": {
        "authors": [],
        "url": "https://proceedings.neurips.cc/paper_files/paper/2023/file/3a71ee306d6991f2f87dd414e0bdf851-Paper-Datasets_and_Benchmarks.pdf",
        "ref_texts": "[7]Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017.",
        "ref_ids": [
          "7"
        ]
      },
      "Unigs: Unified representation for image generation and segmentation": {
        "authors": [
          "Lu Qi",
          "Lehan Yang",
          "Weidong Guo",
          "Yu Xu",
          "Bo Du",
          "Varun Jampani",
          "Hsuan Yang"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Qi_UniGS_Unified_Representation_for_Image_Generation_and_Segmentation_CVPR_2024_paper.pdf",
        "ref_texts": "[75] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017. 1, 2",
        "ref_ids": [
          "75"
        ]
      },
      "FreeKD: Knowledge Distillation via Semantic Frequency Prompt": {
        "authors": [
          "Yuan Zhang",
          "Tao Huang",
          "Jiaming Liu",
          "Tao Jiang",
          "Kuan Cheng",
          "Shanghang Zhang"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Zhang_FreeKD_Knowledge_Distillation_via_Semantic_Frequency_Prompt_CVPR_2024_paper.pdf",
        "ref_texts": "[56] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , pages 2881\u20132890, 2017. 6",
        "ref_ids": [
          "56"
        ]
      },
      "Probabilistic contrastive learning for long-tailed visual recognition": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2403.06726",
        "ref_texts": "[5] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in CVPR , 2017. 1",
        "ref_ids": [
          "5"
        ]
      },
      "Behind every domain there is a shift: Adapting distortion-aware vision transformers for panoramic semantic segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2207.11860",
        "ref_texts": "[33] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in CVPR , 2017. 3, 8, 9",
        "ref_ids": [
          "33"
        ]
      },
      "Weakly-supervised contrastive learning for unsupervised object discovery": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2307.03376",
        "ref_texts": "[91] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "91"
        ]
      },
      "Improving facade parsing with vision transformers and line integration": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2309.15523",
        "ref_texts": "2018. 3d fac \u00b8ade labeling over complex scenarios: A case study using convolutional neural network and structure-from-motion. Remote Sensing 10, 1435. Ma, W., Ma, W., Xu, S., Zha, H., 2020. Pyramid alknet for semantic parsing of building facade image. IEEE Geoscience and Remote Sensing Letters 18, 1009\u20131013. Mahajan, D., Girshick, R., Ramanathan, V ., He, K., Paluri, M., Li, Y ., Bharambe, A., Van Der Maaten, L., 2018. Exploring the limits of weakly supervised pretraining, in: Proceedings of the European conference on computer vision (ECCV), pp. 181\u2013196. Mathias, M., Martinovi \u00b4c, A., Van Gool, L., 2016. Atlas: A three-layered approach to facade parsing. International Journal of Computer Vision 118, 22\u201348. Minaee, S., Boykov, Y ., Porikli, F., Plaza, A., Kehtarnavaz, N., Terzopoulos, D., 2021. Image segmentation using deep learning: A survey. TPAMI 44, 3523\u20133542. Neuhold, G., Ollmann, T., Rota Bulo, S., Kontschieder, P., 2017. The mapillary vistas dataset for semantic understanding of street scenes, in: Proceedings of the IEEE international conference on computer vision, pp. 4990\u20134999. Rahmani, K., Mayer, H., 2018. High quality facade segmentation based on structured random forest, region proposal network and rectangular fitting. ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial Information Sciences 4, 223\u2013230. Redmon, J., Divvala, S., Girshick, R., Farhadi, A., 2016. You only look once: Unified, real-time object detection, in: Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 779\u2013788. Ren, S., He, K., Girshick, R., Sun, J., 2015. Faster r-cnn: Towards real-time object detection with region proposal networks. Advances in neural information processing systems 28. Riemenschneider, H., B \u00b4odis-Szomor \u00b4u, A., Weissenberg, J., Van Gool, L., 2014. Learning where to classify in multi-view semantic segmentation, in: European Conference on Computer Vision, pp. 516\u2013532. Riemenschneider, H., Krispel, U., Thaller, W., Donoser, M., Havemann, S., Fellner, D., Bischof, H., 2012. Irregular lattices for complex shape grammar facade parsing, in: 2012 IEEE conference on computer vision and pattern recognition, IEEE. pp. 1640\u20131647. R\u00a8ohlig, M., Luboschik, M., Schumann, H., 2017. Visibility widgets for unveiling occluded data in 3d terrain visualization. Journal of Visual Languages & Computing 42, 86\u201398. Rohrbach, A., Rohrbach, M., Hu, R., Darrell, T., Schiele, B., 2016. Grounding of textual phrases in images by reconstruction, in: Computer Vision\u2013ECCV",
        "ref_ids": [
          "2018"
        ]
      },
      "A survey on open-vocabulary detection and segmentation: Past, present, and future": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2307.09220",
        "ref_texts": ""
      },
      "NCL++: Nested Collaborative Learning for long-tailed visual recognition": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2306.16709",
        "ref_texts": "[5] H. Zhao, J. Shi, X. Qi, X. Wang, J. Jia, Pyramid scene parsing network, in: CVPR, 2017. 1",
        "ref_ids": [
          "5"
        ]
      },
      "Satsynth: Augmenting image-mask pairs through diffusion models for aerial semantic segmentation": {
        "authors": [
          "Aysim Toker",
          "Marvin Eisenberger",
          "Daniel Cremers",
          "Laura Leal"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Toker_SatSynth_Augmenting_Image-Mask_Pairs_through_Diffusion_Models_for_Aerial_Semantic_CVPR_2024_paper.pdf",
        "ref_texts": "[71] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017. 2, 7, 1, 3",
        "ref_ids": [
          "71"
        ]
      },
      "Deep learning technique for human parsing: A survey and outlook": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2301.00394",
        "ref_texts": "206. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2881\u2013",
        "ref_ids": [
          "206"
        ]
      },
      "Multi-perspective traffic video description model with fine-grained refinement approach": {
        "authors": [
          "An To",
          "Nam Tran",
          "Bao Ho",
          "Loc Ha",
          "Tan Nguyen",
          "Chau Luong",
          "Duy Cao",
          "Triet Tran"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024W/AICity/papers/To_Multi-perspective_Traffic_Video_Description_Model_with_Fine-grained_Refinement_Approach_CVPRW_2024_paper.pdf",
        "ref_texts": "[42] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , pages 6230\u20136239, 2017. 6",
        "ref_ids": [
          "42"
        ]
      },
      "Open compound domain adaptation with object style compensation for semantic segmentation": {
        "authors": [],
        "url": "https://proceedings.neurips.cc/paper_files/paper/2023/file/c74a3a6f44a44b204e26b1a6d7fe4a66-Paper-Conference.pdf",
        "ref_texts": "[1]Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "1"
        ]
      },
      "Vanishing-point-guided video semantic segmentation of driving scenes": {
        "authors": [
          "Diandian Guo",
          "Ping Fan",
          "Tongyu Lu",
          "Christos Sakaridis",
          "Luc Van"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Guo_Vanishing-Point-Guided_Video_Semantic_Segmentation_of_Driving_Scenes_CVPR_2024_paper.pdf",
        "ref_texts": "[60] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In IEEE CVPR , 2017. 7",
        "ref_ids": [
          "60"
        ]
      },
      "Instance-adaptive and geometric-aware keypoint learning for category-level 6d object pose estimation": {
        "authors": [
          "Xiao Lin",
          "Wenfei Yang",
          "Yuan Gao",
          "Tianzhu Zhang"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Lin_Instance-Adaptive_and_Geometric-Aware_Keypoint_Learning_for_Category-Level_6D_Object_Pose_CVPR_2024_paper.pdf",
        "ref_texts": "[45] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings oftheIEEE conference oncomputer vision and pattern recognition, pages 2881\u20132890, 2017. 3",
        "ref_ids": [
          "45"
        ]
      },
      "Water body extraction from high spatial resolution remote sensing images based on enhanced U-Net and multi-scale information fusion": {
        "authors": [
          "Huidong Cao"
        ],
        "url": "https://www.nature.com/articles/s41598-024-67113-7.pdf",
        "ref_texts": ""
      },
      "Context-aware interaction network for rgb-t semantic segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2401.01624",
        "ref_texts": "[36] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proc. IEEE CVPR , Jul. 2017, pp. 6230\u20136239.",
        "ref_ids": [
          "36"
        ]
      },
      "Dynamic token-pass transformers for semantic segmentation": {
        "authors": [
          "Yuang Liu",
          "Qiang Zhou",
          "Jing Wang",
          "Zhibin Wang",
          "Fan Wang",
          "Jun Wang",
          "Wei Zhang"
        ],
        "url": "https://openaccess.thecvf.com/content/WACV2024/papers/Liu_Dynamic_Token-Pass_Transformers_for_Semantic_Segmentation_WACV_2024_paper.pdf",
        "ref_texts": "[42] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , pages 2881\u20132890, 2017. 2",
        "ref_ids": [
          "42"
        ]
      },
      "Deep learning techniques for in-crop weed recognition in large-scale grain production systems: a review": {
        "authors": [
          "Kun Hu"
        ],
        "url": "https://link.springer.com/content/pdf/10.1007/s11119-023-10073-1.pdf",
        "ref_texts": "415). IEEE. Yu, J., Schumann, A. W., Cao, Z., Sharpe, S. M., & Boyd, N. S. (2019a). Weed detection in perennial ryegrass with deep learning convolutional neural network. Frontiers in Plant Science, 2019, 10. Yu, J., Sharpe, S. M., Schumann, A. W., & Boyd, N. S. (2019b). Deep learning for image-based weed detection in turfgrass. European Journal of Agronomy, 104, 78\u201384. Zeiler, M. D., Krishnan, D., Taylor, G. W., & Fergus, R. (2010). Deconvolutional networks. In IEEE confer ence on computer vision and pattern recognition (pp. 2528\u20132535). IEEE. Zhao, H., Shi, J., Qi, X., Wang, X., & Jia, J. (2017). Pyramid scene parsing network. In IEEE conference on computer vision and pattern recognition (pp. 2881\u20132890). IEEE. Zheng, H., Fu, J., Zha, Z. J., & Luo, J. (2019). Looking for the devil in the details: Learning trilinear attention sampling network for fine-grained image recognition. In IEEE conference on computer vision and pattern recognition (pp. 5012\u20135021). IEEE. Zhuang, J., Li, X., Bagavathiannan, M., Jin, X., Yang, J., Meng, W., Li, T., Li, L., Wang, Y., Chen, Y., & Yu, J. (2022). Evaluation of different deep convolutional neural networks for detection of broadleaf weed seedlings in wheat. Pest Management Science, 78(2), 521\u2013529."
      },
      "Contextrast: Contextual Contrastive Learning for Semantic Segmentation": {
        "authors": [
          "Changki Sung",
          "Wanhee Kim",
          "Jungho An",
          "Wooju Lee",
          "Hyungtae Lim",
          "Hyun Myung"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Sung_Contextrast_Contextual_Contrastive_Learning_for_Semantic_Segmentation_CVPR_2024_paper.pdf",
        "ref_texts": "[53] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "53"
        ]
      },
      "Sfnet: Faster and accurate semantic segmentation via semantic flow": {
        "authors": [
          "Xiangtai Li"
        ],
        "url": "https://link.springer.com/content/pdf/10.1007/s11263-023-01875-x.pdf",
        "ref_texts": "(2019). Attention-guided unified network for panoptic segmenta-tion. In CVPR . Li, X., He, H., Li, X., Li, D., Cheng, G., Shi, J., Weng, L., Tong, Y ., & Lin, Z. (2021). Pointflow: Flowing semantics through points foraerial image segmentation. In CVPR . Li, X., Houlong, Z., Lei, H., Y unhai, T., Kuiyuan, Y . (2020). GFF: Gated fully fusion for semantic segmentation. In AAAI . Li, Q., Qi, X., & Torr, P . H. S. (2020). Unifying training and inference for panoptic segmentation. In CVPR . Li, B., Weinberger, K. Q., Belongie, S., Koltun, V ., & Ranftl, R. (2022). ICLR: Language-driven semantic segmentation. Li, H., Xiong, P ., & Fan, H. (2019). and Jian Sun. Dfanet: Deep feature aggregation for real-time semantic segmentation. In CVPR . Li, X., Y ou, A., Zhu, Z., Zhao, H., Yang, M., Yang, K., & Tong, Y . (2020). Semantic flow for fast and accurate scene parsing. In ECCV . Li, Y ., Zhao, H., Qi, X., Wang, L., Li, Z., Sun, J., & Jia, J. (2021). Fully convolutional networks for panoptic segmentation. In CVPR . Li, X., Zhong, Z., Jianlong, W., Yang, Y ., Lin, Z., & Liu, H. (2019). Expectation-maximization attention networks for semantic seg-mentation. In ICCV . Li, X., Zhou, Y ., Pan, Z., & Feng, J. (2019). Partial order pruning: for best speed/accuracy trade-off in neural architecture search. InCVPR . Lin, T.-Y ., Doll\u00e1r, P ., Girshick, R. B., He, K., Hariharan, B., & Belongie, S. J. (2017). Feature pyramid networks for object detection. InCVPR . Lin, T.-Y ., Maire, M., Belongie, S., Hays, J., Perona, P ., Ramanan, D., Doll\u00e1r, P ., & Zitnick, C. L. (2014). Microsoft coco: Commonobjects in context. In ECCV . Lin, G., Milan, A., Shen, C., & Reid, I. D. (2017). Refinenet: Multi-path refinement networks for high-resolution semantic segmentation. InCVPR . Liu, Z., Lin, Y ., Cao, Y ., Han, H., Wei, Y ., Zhang, Z., Lin, S., & Guo, B."
      },
      "Distilling Semantic Priors from SAM to Efficient Image Restoration Models": {
        "authors": [
          "Quan Zhang",
          "Xiaoyu Liu",
          "Wei Li",
          "Hanting Chen",
          "Junchao Liu",
          "Jie Hu",
          "Zhiwei Xiong",
          "Chun Yuan",
          "Yunhe Wang"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Zhang_Distilling_Semantic_Priors_from_SAM_to_Efficient_Image_Restoration_Models_CVPR_2024_paper.pdf"
      },
      "Multi-class segmentation from aerial views using recursive noise diffusion": {
        "authors": [
          "Benedikt Kolbeinsson",
          "Krystian Mikolajczyk"
        ],
        "url": "https://openaccess.thecvf.com/content/WACV2024/papers/Kolbeinsson_Multi-Class_Segmentation_From_Aerial_Views_Using_Recursive_Noise_Diffusion_WACV_2024_paper.pdf",
        "ref_texts": "[63] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017. 2",
        "ref_ids": [
          "63"
        ]
      },
      "Contextual hourglass network for semantic segmentation of high resolution aerial imagery": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1810.12813",
        "ref_texts": "[26] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in CVPR , 2017.",
        "ref_ids": [
          "26"
        ]
      },
      "Evaluation of stenoses using AI video models applied to coronary angiography": {
        "authors": [],
        "url": "https://www.nature.com/articles/s41746-024-01134-4.pdf",
        "ref_texts": "44. Zhao, H., Shi, J., Qi, X., Wang, X. & Jia, J. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition . 2881 \u20132890 (2021).",
        "ref_ids": [
          "44"
        ]
      },
      "LORS: Low-rank Residual Structure for Parameter-Efficient Network Stacking": {
        "authors": [
          "Jialin Li",
          "Qiang Nie",
          "Weifu Fu",
          "Yuhuan Lin",
          "Guangpin Tao",
          "Yong Liu",
          "Chengjie Wang"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Li_LORS_Low-rank_Residual_Structure_for_Parameter-Efficient_Network_Stacking_CVPR_2024_paper.pdf",
        "ref_texts": "[54] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017. 2",
        "ref_ids": [
          "54"
        ]
      },
      "HALSIE: Hybrid approach to learning segmentation by simultaneously exploiting image and event modalities": {
        "authors": [
          "Shristi Das",
          "Adarsh Kosta",
          "Chamika Liyanagedera",
          "Marco Apolinario",
          "Kaushik Roy"
        ],
        "url": "https://openaccess.thecvf.com/content/WACV2024/papers/Biswas_HALSIE_Hybrid_Approach_to_Learning_Segmentation_by_Simultaneously_Exploiting_Image_WACV_2024_paper.pdf",
        "ref_texts": "[12] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition , pp. 2881\u20132890, 2017. 2",
        "ref_ids": [
          "12"
        ]
      },
      "S  M-Net: Joint Learning of Semantic Segmentation and Stereo Matching for Autonomous Driving": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2401.11414",
        "ref_texts": "[15] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "15"
        ]
      },
      "FUSegNet: A deep convolutional neural network for foot ulcer segmentation": {
        "authors": [
          "Mrinal Kanti"
        ],
        "url": "https://arxiv.org/pdf/2305.02961",
        "ref_texts": "[39] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d Proceedings 30th IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2017, vol. 2017Janua, pp. 6230\u2013 6239, 2017. ",
        "ref_ids": [
          "39"
        ]
      },
      "Residual spatial fusion network for rgb-thermal semantic segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2306.10364",
        "ref_texts": "[23] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in CVPR , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "23"
        ]
      },
      "Learn to Rectify the Bias of CLIP for Unsupervised Semantic Segmentation": {
        "authors": [
          "Jingyun Wang",
          "Guoliang Kang"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Wang_Learn_to_Rectify_the_Bias_of_CLIP_for_Unsupervised_Semantic_CVPR_2024_paper.pdf",
        "ref_texts": "[60] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017. 1, 3[61] B. Zhou, Z. Hang, Francesco Xavier Puig Fernandez, S. Fidler, and A. Torralba. Scene parsing through ade20k dataset. In2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2017. 2, 6",
        "ref_ids": [
          "60",
          "61"
        ]
      },
      "AutoGO: automated computation graph optimization for neural network evolution": {
        "authors": [],
        "url": "https://proceedings.neurips.cc/paper_files/paper/2023/file/eb5d9195b201ec7ba66c8e20b396d349-Paper-Conference.pdf",
        "ref_texts": "[76] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "76"
        ]
      },
      "Harmonizing base and novel classes: A class-contrastive approach for generalized few-shot segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2303.13724",
        "ref_texts": "663{679). Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J. (2017). Pyramid scene parsing network. Cvpr. Zhao, X., Vemulapalli, R., Mansffeld, P.A., Gong, B., Green, B., Shapira, L., Wu, Y."
      },
      "Unsupervised domain adaptation for semantic segmentation with pseudo label self-refinement": {
        "authors": [
          "Xingchen Zhao",
          "Niluthpol Chowdhury",
          "Abhinav Rajvanshi",
          "Pang Chiu",
          "Supun Samarasekera"
        ],
        "url": "https://openaccess.thecvf.com/content/WACV2024/papers/Zhao_Unsupervised_Domain_Adaptation_for_Semantic_Segmentation_With_Pseudo_Label_Self-Refinement_WACV_2024_paper.pdf",
        "ref_texts": "[58] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2017. 1",
        "ref_ids": [
          "58"
        ]
      },
      "PaveSAM\u2013segment anything for pavement distress": {
        "authors": [
          "Neema Jakisa"
        ],
        "url": "https://arxiv.org/pdf/2409.07295?",
        "ref_texts": " International Journal of Transportation Science and Technology , 11(2), 298 \u2013309. https://doi.org/10.1016/j.ijtst.2021.04.008 Zhang, H., Qian, Z., Tan, Y., Xie , Y., & Li, M. (2022). Investigation of pavement crack detection based on deep learning method using weakly supervised instance segmentation framework. Construction and Building Materials , 358, 129117. https://doi.org/10.1016/j.conbuildmat.2022.129117 Zhang, Y., Gao, X., & Zhang, H. (2023). Deep Learning -Based Semantic Segmentation Methods for Pavement Cracks. Information , 14(3), Article 3. https://doi.org/10.3390/info14030182 Zhao, H., Shi, J., Qi, X., Wang, X., & Jia, J. (2016). Pyramid Scene Parsing Network . https://doi.org/10.48550/ARXIV.1612.01105 Zhou, Z., Siddiquee, M. M. R., Tajbakhsh, N., & Liang, J. (2018). UNet++: A Nested U -Net Architecture for Medical Image Segmentation. Deep Learning in Medical Image Analysis and Multimodal Learning for Clinical Decision Support\u202f: 4th International Workshop, DLMIA 2018, and 8th International Workshop, ML -CDS 2018, Held in Conjunction with MICCAI 2018, Granada, Spain, S , 11045 , 3\u201311. https://doi.org/10.1007/978 -3-030-00889 5_1 Zou, K. H., Warfield, S. K., Bharatha, A., Tempany, C. M. C., Kaus, M. R., Haker, S. J., Wells, W. M., Jolesz, F. A., & Kikinis, R. (2004). Statistical validation of image segmentation quality based on a spatial overlap index1. Academic Radiology , 11(2), 178 \u2013189. https://doi.org/10.1016/S1076 -6332(03)00671 -8 Zuo, Y., Wang, G., & Zuo, C. (2008). A Novel Image Segmentation Method of Pavement Surface Cracks Based on Fractal Theory. 2008 International Conference on Computational Intelligence and Security , 485 \u2013488. https://doi.org/10.1109/CIS.2008.206 "
      },
      "Contextual affinity distillation for image anomaly detection": {
        "authors": [
          "Jie Zhang",
          "Masanori Suganuma",
          "Takayuki Okatani"
        ],
        "url": "https://openaccess.thecvf.com/content/WACV2024/papers/Zhang_Contextual_Affinity_Distillation_for_Image_Anomaly_Detection_WACV_2024_paper.pdf",
        "ref_texts": "[39] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017. 3",
        "ref_ids": [
          "39"
        ]
      },
      "Corrmatch: Label propagation via correlation matching for semi-supervised semantic segmentation": {
        "authors": [
          "Boyuan Sun",
          "Yuqi Yang",
          "Le Zhang",
          "Ming Cheng",
          "Qibin Hou"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Sun_CorrMatch_Label_Propagation_via_Correlation_Matching_for_Semi-Supervised_Semantic_Segmentation_CVPR_2024_paper.pdf",
        "ref_texts": "[71] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , pages 2881\u20132890, 2017. 1",
        "ref_ids": [
          "71"
        ]
      },
      "Joint depth prediction and semantic segmentation with multi-view sam": {
        "authors": [
          "Mykhailo Shvets",
          "Dongxu Zhao",
          "Marc Niethammer",
          "Roni Sengupta",
          "Alexander C. Berg"
        ],
        "url": "https://openaccess.thecvf.com/content/WACV2024/papers/Shvets_Joint_Depth_Prediction_and_Semantic_Segmentation_With_Multi-View_SAM_WACV_2024_paper.pdf",
        "ref_texts": "[59] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017. 2, 3",
        "ref_ids": [
          "59"
        ]
      },
      "Roadformer+: Delivering rgb-x scene parsing through scale-aware information decoupling and advanced heterogeneous feature fusion": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2407.21631?",
        "ref_texts": "[24] H. Zhao et al. , \u201cPyramid scene parsing network,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "24"
        ]
      },
      "Using unreliable pseudo-labels for label-efficient semantic segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2306.02314",
        "ref_texts": "(2021b). Prototypical pseudo label denoising and target structure learning for domain adaptive semantic segmentation. In CVPR . Zhang, Q., Zhang, J., Liu, W., and Tao, D. (2019). Category anchorguided unsupervised domain adaptation for semantic segmentation. NeurIPS . Zhao, H., Shi, J., Qi, X., Wang, X., and Jia, J. (2017). Pyramid scene parsing network. In CVPR . Zhao, X., Vemulapalli, R., Mansfield, P. A., Gong, B., Green, B., Shapira, L., and Wu, Y . (2021). Contrastive learning for label efficient semantic segmentation. In ICCV . Zheng, S., Lu, J., Zhao, H., Zhu, X., Luo, Z., Wang, Y ., Fu, Y ., Feng, J., Xiang, T., Torr, P. H., et al. (2021). Rethinking semantic segmentation from a sequence-to-sequence perspective with transformers. InCVPR . Zhong, Y ., Yuan, B., Wu, H., Yuan, Z., Peng, J., and Wang, Y .-X."
      },
      "Evaluation of various deep learning algorithms for landslide and sinkhole detection from UAV imagery in a semi-arid environment": {
        "authors": [
          "Narges Kariminejad"
        ],
        "url": "https://link.springer.com/content/pdf/10.1007/s41748-024-00419-8.pdf",
        "ref_texts": "75:2467\u20132487 Ying X, Wang Q, Li X, Yu M, Jiang H, Gao J, Yu R (2019) Multiattention object detection model in remote sensing images based on multi-scale. IEEE Access 7:94508\u201394519 Yu B, Xu C, Chen F, Wang N, Wang L (2022) HADeenNet: a hierar chical-attention multi-scale deconvolution network for landslide detection. Int J Appl Earth Obs Geoinf 111:102853 Zhang Z, Liu Q, Wang Y (2018) Road extraction by deep residual U-Net. IEEE Geosci Remote Sens Lett 15:749\u2013753. https:// doi. org/ 10. 1109/ LGRS. 2018. 28029 44 Zhang Y, Yue P, Zhang G, Guan T, Lv M, Zhong D (2019) Augmented reality mapping of rock mass discontinuities and rockfall susceptibility based on unmanned aerial vehicle photogrammetry. Remote Sens 11:1311 Zhao H, Shi J, Qi X, Wang X, Jia J (2016) Pyramid scene parsing network. In: 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR). Honolulu, HI, USA, 2017, pp 6230\u20136239. https:// doi. org/ 10. 1109/ CVPR. 2017. 660"
      },
      "AllSpark: Reborn Labeled Features from Unlabeled in Transformer for Semi-Supervised Semantic Segmentation": {
        "authors": [
          "Haonan Wang",
          "Qixiang Zhang",
          "Yi Li",
          "Xiaomeng Li"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Wang_AllSpark_Reborn_Labeled_Features_from_Unlabeled_in_Transformer_for_Semi-Supervised_CVPR_2024_paper.pdf",
        "ref_texts": "[55] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , pages 2881\u20132890, 2017. 2",
        "ref_ids": [
          "55"
        ]
      },
      "Pulling target to source: A new perspective on domain adaptive semantic segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2305.13752",
        "ref_texts": "(2021). Prototypical pseudo label denoising and target structure learning for domain adaptive semantic segmentation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) . Zhang, Q., Zhang, J., Liu, W., and Tao, D. (2019). Category anchorguided unsupervised domain adaptation for semantic segmentation. Advances in Neural Information Processing Systems (NeurIPS) . Zhao, H., Shi, J., Qi, X., Wang, X., and Jia, J. (2017). Pyramid scene parsing network. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) . Zhao, Y ., Zhong, Z., Zhao, N., Sebe, N., and Lee, G. H. (2022). Stylehallucinated dual consistency learning for domain generalized semantic segmentation. In European Conference on Computer Vision (ECCV) . Springer. Zheng, Z. and Yang, Y . (2021). Rectifying pseudo label learning via uncertainty estimation for domain adaptive semantic segmentation. International Journal of Computer Vision (IJCV) . Zhou, B., Zhao, H., Puig, X., Fidler, S., Barriuso, A., and Torralba, A."
      },
      "Jaccard metric losses: Optimizing the jaccard index with soft labels": {
        "authors": [],
        "url": "https://proceedings.neurips.cc/paper_files/paper/2023/file/ee208bfc04b1bf6125a6a34baa1c28d3-Paper-Conference.pdf",
        "ref_texts": "[78] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid Scene Parsing Network. CVPR , 2017.",
        "ref_ids": [
          "78"
        ]
      },
      "Advances and challenges in deep learning-based change detection for remote sensing images: A review through various learning paradigms": {
        "authors": [
          "Lukang Wang",
          "Min Zhang",
          "Xu Gao",
          "Wenzhong Shi"
        ],
        "url": "https://www.mdpi.com/2072-4292/16/5/804/pdf",
        "ref_texts": "27. Zhao, H.; Shi, J.; Qi, X.; Wang, X.; Jia, J. Pyramid Scene Parsing Network. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Honolulu, HI, USA, 21\u201326 July 2017; pp. 2881\u20132890.",
        "ref_ids": [
          "27"
        ]
      },
      "Vision transformers with hierarchical attention": {
        "authors": [],
        "url": "https://link.springer.com/content/pdf/10.1007/s11633-024-1393-8.pdf",
        "ref_texts": "\u00a0H.\u00a0S.\u00a0Zhao,\u00a0 J.\u00a0P.\u00a0Shi,\u00a0X.\u00a0J.\u00a0Qi,\u00a0X.\u00a0G.\u00a0Wang,\u00a0 J.\u00a0Y.\u00a0Jia.\u00a0Pyramid\u00a0 scene\u00a0 parsing\u00a0 network.\u00a0 In\u00a0Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , Honolulu,\u00a0 USA,\u00a0 pp.\u00a06230\u20136239,\u00a0 2017.\u00a0 DOI:\u00a0 10.1109/CVPR.2017.660.[6]",
        "ref_ids": [
          "6"
        ]
      },
      "Materobot: Material recognition in wearable robotics for people with visual impairments": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2302.14595",
        "ref_texts": "[19] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2017, pp. 6230\u20136239.[20] K. He, X. Zhang, S. Ren, and J. Sun, \u201cDeep residual learning for image recognition,\u201d in 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2016, pp. 770\u2013778.",
        "ref_ids": [
          "19",
          "20"
        ]
      },
      "Understanding dark scenes by contrasting multi-modal observations": {
        "authors": [
          "Xiaoyu Dong",
          "Naoto Yokoya"
        ],
        "url": "https://openaccess.thecvf.com/content/WACV2024/papers/Dong_Understanding_Dark_Scenes_by_Contrasting_Multi-Modal_Observations_WACV_2024_paper.pdf"
      },
      "Caveseg: Deep semantic segmentation and scene parsing for autonomous underwater cave exploration": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2309.11038",
        "ref_texts": "[43] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid Scene Parsing Network,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "43"
        ]
      },
      "Unified Language-driven Zero-shot Domain Adaptation": {
        "authors": [
          "Senqiao Yang",
          "Zhuotao Tian",
          "Li Jiang",
          "Jiaya Jia"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Yang_Unified_Language-driven_Zero-shot_Domain_Adaptation_CVPR_2024_paper.pdf",
        "ref_texts": ""
      },
      "Sam2-adapter: Evaluating & adapting segment anything 2 in downstream tasks: Camouflage, shadow, medical image segmentation, and more": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2408.04579",
        "ref_texts": "[88] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017. 3",
        "ref_ids": [
          "88"
        ]
      },
      "Towards Automatic Power Battery Detection: New Challenge Benchmark Dataset and Baseline": {
        "authors": [
          "Xiaoqi Zhao",
          "Youwei Pang",
          "Zhenyu Chen",
          "Qian Yu",
          "Lihe Zhang",
          "Hanqi Liu",
          "Jiaming Zuo",
          "Huchuan Lu"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Zhao_Towards_Automatic_Power_Battery_Detection_New_Challenge_Benchmark_Dataset_and_CVPR_2024_paper.pdf"
      },
      "Boundary-guided lightweight semantic segmentation with multi-scale semantic context": {
        "authors": [],
        "url": "https://guangweigao.github.io/paper/TMM-BSCNet.pdf",
        "ref_texts": "[2] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proc. IEEE Conf. Comput. Vis. Pattern Recognit. , 2017, pp. 2881\u20132890. Authorized licensed use limited to: Nanjing Univ of Post & Telecommunications. Downloaded on April 26,2024 at 02:07:07 UTC from IEEE Xplore. Restrictions apply. ZHOU et al.: BOUNDARY-GUIDED LIGHTWEIGHT SEMANTIC SEGMENTATION WITH MULTI-SCALE SEMANTIC CONTEXT 7899",
        "ref_ids": [
          "2"
        ]
      },
      "L2T-DLN: learning to teach with dynamic loss network": {
        "authors": [],
        "url": "https://proceedings.neurips.cc/paper_files/paper/2023/file/8667f264f88c7938a73a53ab01eb1327-Paper-Conference.pdf",
        "ref_texts": "[40] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "40"
        ]
      },
      "Fire in focus: Advancing wildfire image segmentation by focusing on fire edges": {
        "authors": [
          "Guodong Wang",
          "Fang Wang",
          "Hongping Zhou",
          "Haifeng Lin"
        ],
        "url": "https://www.mdpi.com/1999-4907/15/1/217/pdf",
        "ref_texts": "29. Zhao, H.; Shi, J.; Qi, X.; Wang, X.; Jia, J. Pyramid Scene Parsing Network. In Proceedings of the 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Honolulu, HI, USA, 21\u201326 July 2017; pp. 6230\u20136239. Disclaimer/Publisher\u2019s Note: The statements, opinions and data contained in all publications are solely those of the individual author(s) and contributor(s) and not of MDPI and/or the editor(s). MDPI and/or the editor(s) disclaim responsibility for any injury to people or property resulting from any ideas, methods, instructions or products referred to in the content.",
        "ref_ids": [
          "29"
        ]
      },
      "Effective image tampering localization with multi-scale convnext feature fusion": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2208.13739",
        "ref_texts": ""
      },
      "Frozen CLIP: A Strong Backbone for Weakly Supervised Semantic Segmentation": {
        "authors": [
          "Bingfeng Zhang",
          "Siyue Yu",
          "Yunchao Wei",
          "Yao Zhao",
          "Jimin Xiao"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Zhang_Frozen_CLIP_A_Strong_Backbone_for_Weakly_Supervised_Semantic_Segmentation_CVPR_2024_paper.pdf",
        "ref_texts": "[62] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017. 3",
        "ref_ids": [
          "62"
        ]
      },
      "U-DIADS-Bib: a full and few-shot pixel-precise dataset for document layout analysis of ancient manuscripts": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2401.08425",
        "ref_texts": "[34] Zhao H, Shi J, Qi X, et al (2017) Pyramid scene parsing network. In: 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp 6230\u20136239, https: //doi.org/10.1109/CVPR.2017.660",
        "ref_ids": [
          "34"
        ]
      },
      "Unleash the potential of image branch for cross-modal 3d object detection": {
        "authors": [],
        "url": "https://proceedings.neurips.cc/paper_files/paper/2023/file/a1f0c0cd6caaa4863af5f12608edf63e-Paper-Conference.pdf",
        "ref_texts": "[59] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pp.",
        "ref_ids": [
          "59"
        ]
      },
      "Point-Supervised Semantic Segmentation of Natural Scenes via Hyperspectral Imaging": {
        "authors": [
          "Tianqi Ren",
          "Qiu Shen",
          "Ying Fu",
          "Shaodi You"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024W/PBDL/papers/Ren_Point-Supervised_Semantic_Segmentation_of_Natural_Scenes_via_Hyperspectral_Imaging_CVPRW_2024_paper.pdf",
        "ref_texts": "[47] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u2013",
        "ref_ids": [
          "47"
        ]
      },
      "NTO3D: Neural Target Object 3D Reconstruction with Segment Anything": {
        "authors": [
          "Xiaobao Wei",
          "Renrui Zhang",
          "Jiarui Wu",
          "Jiaming Liu",
          "Ming Lu",
          "Yandong Guo",
          "Shanghang Zhang"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Wei_NTO3D_Neural_Target_Object_3D_Reconstruction_with_Segment_Anything_CVPR_2024_paper.pdf",
        "ref_texts": "[63] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017. 2",
        "ref_ids": [
          "63"
        ]
      },
      "Learning local and global temporal contexts for video semantic segmentation": {
        "authors": [],
        "url": "https://yun-liu.github.io/papers/(TPAMI'2024)Learning%20Local%20and%20Global%20Temporal%20Contexts%20for%20Video%20Semantic%20Segmentation.pdf",
        "ref_texts": "[29] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in IEEE Conf. Comput. Vis. Pattern Recog. , 2017, pp. 2881\u2013",
        "ref_ids": [
          "29"
        ]
      },
      "Lr-fpn: Enhancing remote sensing object detection with location refined feature pyramid network": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2404.01614",
        "ref_texts": "[20] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "20"
        ]
      },
      "Acr-pose: Adversarial canonical representation reconstruction network for category level 6d object pose estimation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2111.10524",
        "ref_texts": "[54] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017. 6, 11",
        "ref_ids": [
          "54"
        ]
      },
      "Prototype as query for few shot semantic segmentation": {
        "authors": [
          "Leilei Cao"
        ],
        "url": "https://link.springer.com/content/pdf/10.1007/s40747-024-01539-4.pdf",
        "ref_texts": ""
      },
      "Exploring Regional Clues in CLIP for Zero-Shot Semantic Segmentation": {
        "authors": [
          "Yi Zhang",
          "Hao Guo",
          "Miao Wang",
          "Min Hu"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Zhang_Exploring_Regional_Clues_in_CLIP_for_Zero-Shot_Semantic_Segmentation_CVPR_2024_paper.pdf",
        "ref_texts": "[50] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In 2017 IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2017, Honolulu, HI, USA, July 21-26, 2017 , pages 6230\u20136239. IEEE Computer Society, 2017. 1",
        "ref_ids": [
          "50"
        ]
      },
      "MetaSegNet: Metadata-collaborative Vision-Language Representation Learning for Semantic Segmentation of Remote Sensing Images": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2312.12735",
        "ref_texts": "[48] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d presented at the Proceedings of the IEEE conference on computer vision and pattern recognition, 2017, pp. 2881\u2013 2890. ",
        "ref_ids": [
          "48"
        ]
      },
      "SANeRF-HQ: Segment Anything for NeRF in High Quality": {
        "authors": [
          "Yichen Liu",
          "Benran Hu",
          "Keung Tang",
          "Wing Tai"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Liu_SANeRF-HQ_Segment_Anything_for_NeRF_in_High_Quality_CVPR_2024_paper.pdf",
        "ref_texts": "[61] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid Scene Parsing Network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017. 2[62] Sixiao Zheng, Jiachen Lu, Hengshuang Zhao, Xiatian Zhu, Zekun Luo, Yabiao Wang, Yanwei Fu, Jianfeng Feng, Tao Xiang, Philip HS Torr, et al. Rethinking Semantic Segmentation from a Sequence-to-sequence Perspective with Transformers. In IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) , pages 6881\u20136890, 2021. 2",
        "ref_ids": [
          "61",
          "62"
        ]
      },
      "RepAn: Enhanced Annealing through Re-parameterization": {
        "authors": [
          "Xiang Fei",
          "Xiawu Zheng",
          "Yan Wang",
          "Fei Chao",
          "Chenglin Wu",
          "Liujuan Cao"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Fei_RepAn_Enhanced_Annealing_through_Re-parameterization_CVPR_2024_paper.pdf",
        "ref_texts": "[67] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 2881\u20132890, 2017. 8",
        "ref_ids": [
          "67"
        ]
      },
      "Open-World Semantic Segmentation Including Class Similarity": {
        "authors": [
          "Matteo Sodano",
          "Federico Magistri",
          "Lucas Nunes",
          "Jens Behley",
          "Cyrill Stachniss"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Sodano_Open-World_Semantic_Segmentation_Including_Class_Similarity_CVPR_2024_paper.pdf",
        "ref_texts": "[70] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid Scene Parsing Network. In Proc. of the IEEE/CVF Conf. on Computer Vision and Pattern Recognition (CVPR) , 2017. 3",
        "ref_ids": [
          "70"
        ]
      },
      "Remote intelligent perception system for multi-object detection": {
        "authors": [],
        "url": "https://www.frontiersin.org/articles/10.3389/fnbot.2024.1398703/pdf",
        "ref_texts": "10.1016/j.vehcom.2023.100725 Zhao, H., Shi, J., Qi, X., Wang, X., and Jia, J. (2017). Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition. Zheng, W ., Lu, S., Y ang, Y ., Yin, Z., and Yin, L. (2024). Lightweight transformer image feature extraction network. PeerJ Comput. Sci. 10:e1755. doi: 10.7717/peerj-cs.1755 Zhou, C., Huang, T., and Shuang, L. (2020). Image analysis system of intelligent smart home based on VR. IEEE Access 8, 147756\u2013147764. doi: 10.1109/ACCESS.2020.3012490"
      },
      "Addressing Background Context Bias in Few-Shot Segmentation through Iterative Modulation": {
        "authors": [
          "Lanyun Zhu",
          "Tianrun Chen",
          "Jianxiong Yin",
          "Simon See",
          "Jun Liu"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Zhu_Addressing_Background_Context_Bias_in_Few-Shot_Segmentation_through_Iterative_Modulation_CVPR_2024_paper.pdf",
        "ref_texts": "[46] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017. 1",
        "ref_ids": [
          "46"
        ]
      },
      "A Survey of Deep Learning Road Extraction Algorithms Using High-Resolution Remote Sensing Images": {
        "authors": [
          "Shaoyi Mo",
          "Yufeng Shi",
          "Qi Yuan",
          "Mingyue Li"
        ],
        "url": "https://www.mdpi.com/1424-8220/24/5/1708/pdf",
        "ref_texts": "38. Zhao, H.; Shi, J.; Qi, X.; Wang, X.; Jia, J. Pyramid Scene Parsing Network. arXiv 2017 , arXiv:1612.01105.",
        "ref_ids": [
          "38"
        ]
      },
      "Semantics-empowered space-air-ground-sea integrated network: New paradigm, frameworks, and challenges": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2402.14297",
        "ref_texts": "[112] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR) , Jul. 2017, pp. 6230\u20136239.",
        "ref_ids": [
          "112"
        ]
      },
      "Multi-sem fusion: multimodal semantic fusion for 3D object detection": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2212.05265",
        "ref_texts": "[49] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in IEEE conference on computer vision and pattern recognition , pp. 2881\u20132890, 2017. 4",
        "ref_ids": [
          "49"
        ]
      },
      "A construction waste landfill dataset of two districts in Beijing, China from high resolution satellite images": {
        "authors": [
          "Shaofu Lin"
        ],
        "url": "https://www.nature.com/articles/s41597-024-03240-0.pdf",
        "ref_texts": " 36. Zhao, H., Shi, J., Qi, X., Wang, X. & Jia, J. Pyramid Scene Parsing Network. in 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) 6230\u20136239, https://doi.org/10.1109/CVPR.2017.660 (2017)."
      },
      "SegSTRONG-C: Segmenting Surgical Tools Robustly On Non-adversarial Generated Corruptions--An EndoVis' 24 Challenge": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2407.11906",
        "ref_texts": "4.Zhao, H., Shi, J., Qi, X., Wang, X. & Jia, J. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , 2881\u20132890 (2017).",
        "ref_ids": [
          "4"
        ]
      },
      "NFMPAtt-Unet: Neighborhood fuzzy c-means multi-scale pyramid hybrid attention unet for medical image segmentation": {
        "authors": [
          "Xinpeng Zhao"
        ],
        "url": "http://weihuaxu.com/papers/2024/2024-NN-Xu-Zhao.pdf",
        "ref_texts": "12X. Zhao and W.H. Xu Zhang, P., Liu, W., Lei, Y., Wang, H., & Lu, H. (2020). RAPNet: Residual atrous pyramid network for importance-aware street scene parsing. IEEE Transactions on Image Processing ,29, 5010\u20135021. Zhao, H., Shi, J., Qi, X., Wang, X., & Jia, J. (2017). Pyramid scene parsing network. In2017 IEEE conference on computer vision and pattern recognition (pp. 2881\u20132890). IEEE.Zhou, Z., Rahman Siddiquee, M. M., Tajbakhsh, N., & Liang, J. (2018). Unet++: A nested u-net architecture for medical image segmentation. In 2018 deep learning in medical image analysis and multimodal learning for clinical decision support (pp. 3\u201311). Springer."
      },
      "Keeporiginalaugment: Single image-based better information-preserving data augmentation approach": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2405.06354",
        "ref_texts": "18. Zhao, H., Shi, J., Qi, X., Wang, X. & Jia, J. Pyramid scene parsing network. Proceedings Of The IEEE Conference On Computer Vision And Pattern Recognition . pp. 2881-2890 (2017)",
        "ref_ids": [
          "18"
        ]
      },
      "You only look at once for real-time and generic multi-task": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2310.01641",
        "ref_texts": "[33] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition , 2017, pp. 2881\u20132890. JOURNAL OF L ATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021 13",
        "ref_ids": [
          "33"
        ]
      },
      "Zero-shot Building Attribute Extraction from Large-Scale Vision and Language Models": {
        "authors": [
          "Fei Pan",
          "Sangryul Jeon",
          "Brian Wang",
          "Frank Mckenna",
          "Stella X. Yu"
        ],
        "url": "https://openaccess.thecvf.com/content/WACV2024/papers/Pan_Zero-Shot_Building_Attribute_Extraction_From_Large-Scale_Vision_and_Language_Models_WACV_2024_paper.pdf",
        "ref_texts": "[47] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 2881\u20132890, 2017. 3",
        "ref_ids": [
          "47"
        ]
      },
      "Maniclip: Multi-attribute face manipulation from text": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2210.00445",
        "ref_texts": "[34] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017. 4",
        "ref_ids": [
          "34"
        ]
      },
      "Frequency-Adaptive Dilated Convolution for Semantic Segmentation": {
        "authors": [
          "Linwei Chen",
          "Lin Gu",
          "Dezhi Zheng",
          "Ying Fu"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Chen_Frequency-Adaptive_Dilated_Convolution_for_Semantic_Segmentation_CVPR_2024_paper.pdf",
        "ref_texts": "[88] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of IEEE International Conference on Computer Vision , pages 2881\u20132890, 2017. 6",
        "ref_ids": [
          "88"
        ]
      },
      "Enhancing Ki-67 Cell Segmentation with Dual U-Net Models: A Step Towards Uncertainty-Informed Active Learning": {
        "authors": [
          "David Anglada",
          "Julia Sala",
          "Ferran Marques",
          "Philippe Salembier",
          "Montse Pardas"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024W/DEF-AI-MIA/papers/Anglada-Rotger_Enhancing_Ki-67_Cell_Segmentation_with_Dual_U-Net_Models_A_Step_CVPRW_2024_paper.pdf",
        "ref_texts": "[28] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017. 2",
        "ref_ids": [
          "28"
        ]
      },
      "Open-Set Domain Adaptation for Semantic Segmentation": {
        "authors": [
          "An Choe",
          "Hyung Shin",
          "Hee Park",
          "Jinwoo Choi",
          "Moon Park"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Choe_Open-Set_Domain_Adaptation_for_Semantic_Segmentation_CVPR_2024_paper.pdf",
        "ref_texts": "[24] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition (CVPR) , 2017.",
        "ref_ids": [
          "24"
        ]
      },
      "Double-Branch Multi-Scale Contextual Network: A Model for Multi-Scale Street Tree Segmentation in High-Resolution Remote Sensing Images": {
        "authors": [
          "Hongyang Zhang",
          "Shuo Liu"
        ],
        "url": "https://www.mdpi.com/1424-8220/24/4/1110/pdf",
        "ref_texts": "22. Zhao, H.; Shi, J.; Qi, X.; Wang, X.; Jia, J. Pyramid Scene Parsing Network. In Proceedings of the 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Honolulu, HI, USA, 21\u201326 July 2017; pp. 6230\u20136239.",
        "ref_ids": [
          "22"
        ]
      },
      "PanoRecon: Real-Time Panoptic 3D Reconstruction from Monocular Video": {
        "authors": [
          "Dong Wu",
          "Zike Yan",
          "Hongbin Zha"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Wu_PanoRecon_Real-Time_Panoptic_3D_Reconstruction_from_Monocular_Video_CVPR_2024_paper.pdf",
        "ref_texts": "[55] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. InProceedings of the IEEE conference on computer vision andpattern recognition , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "55"
        ]
      },
      "Efficient and accurate semi-supervised semantic segmentation for industrial surface defects": {
        "authors": [
          "Chenbo Shi"
        ],
        "url": "https://www.nature.com/articles/s41598-024-72579-6.pdf",
        "ref_texts": ""
      },
      "Bitpruning: Learning bitlengths for aggressive and accurate quantization": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2002.03090",
        "ref_texts": ""
      },
      "Image-to-Image Matching via Foundation Models: A New Perspective for Open-Vocabulary Semantic Segmentation": {
        "authors": [
          "Yuan Wang",
          "Rui Sun",
          "Naisong Luo",
          "Yuwen Pan",
          "Tianzhu Zhang"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Wang_Image-to-Image_Matching_via_Foundation_Models_A_New_Perspective_for_Open-Vocabulary_CVPR_2024_paper.pdf",
        "ref_texts": "[72] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017. 2",
        "ref_ids": [
          "72"
        ]
      },
      "Correlation-Decoupled Knowledge Distillation for Multimodal Sentiment Analysis with Incomplete Modalities": {
        "authors": [
          "Mingcheng Li",
          "Dingkang Yang",
          "Xiao Zhao",
          "Shuaibing Wang",
          "Yan Wang",
          "Kun Yang",
          "Mingyang Sun",
          "Dongliang Kou",
          "Ziyun Qian",
          "Lihua Zhang"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Li_Correlation-Decoupled_Knowledge_Distillation_for_Multimodal_Sentiment_Analysis_with_Incomplete_Modalities_CVPR_2024_paper.pdf",
        "ref_texts": "[68] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) , pages 2881\u20132890, 2017. 2",
        "ref_ids": [
          "68"
        ]
      },
      "The devil is in discretization discrepancy. Robustifying Differentiable NAS with Single-Stage Searching Protocol": {
        "authors": [
          "Konstanty Subbotko",
          "Wojciech Jablonski",
          "Piotr Bilinski"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024W/CVPR-NAS/papers/Subbotko_The_Devil_is_in_Discretization_Discrepancy._Robustifying_Differentiable_NAS_with_CVPRW_2024_paper.pdf",
        "ref_texts": "[44] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017. 7",
        "ref_ids": [
          "44"
        ]
      },
      "Augmentation-free Dense Contrastive Distillation for Efficient Semantic Segmentation": {
        "authors": [],
        "url": "https://proceedings.neurips.cc/paper_files/paper/2023/file/a12779b5e802668df1cbc73fa00da62f-Paper-Conference.pdf",
        "ref_texts": "[3]Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017.",
        "ref_ids": [
          "3"
        ]
      },
      "Visual Prompting for Generalized Few-shot Segmentation: A Multi-scale Approach": {
        "authors": [
          "Mir Rayat",
          "Imtiaz Hossain",
          "Mennatullah Siam",
          "Leonid Sigal",
          "James J. Little"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Hossain_Visual_Prompting_for_Generalized_Few-shot_Segmentation_A_Multi-scale_Approach_CVPR_2024_paper.pdf",
        "ref_texts": "[51] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In IEEE/CVF Conference on Computer 23479",
        "ref_ids": [
          "51"
        ]
      },
      "Learning precise affordances from egocentric videos for robotic manipulation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2408.10123",
        "ref_texts": "81.Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 2881\u20132890(2017)",
        "ref_ids": [
          "81"
        ]
      },
      "Temporally-Consistent Video Semantic Segmentation with Bidirectional Occlusion-guided Feature Propagation": {
        "authors": [
          "Razieh Kaviani",
          "Yuanxin Li",
          "Shuangquan Wang",
          "Hairong Qi"
        ],
        "url": "https://openaccess.thecvf.com/content/WACV2024/papers/Baghbaderani_Temporally-Consistent_Video_Semantic_Segmentation_With_Bidirectional_Occlusion-Guided_Feature_Propagation_WACV_2024_paper.pdf",
        "ref_texts": "[65] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017. 2",
        "ref_ids": [
          "65"
        ]
      },
      "MarsLS-Net: Martian Landslides Segmentation Network and Benchmark Dataset": {
        "authors": [
          "Sidike Paheding",
          "Abel A. Reyes",
          "Thomas Oommen"
        ],
        "url": "https://openaccess.thecvf.com/content/WACV2024/papers/Paheding_MarsLS-Net_Martian_Landslides_Segmentation_Network_and_Benchmark_Dataset_WACV_2024_paper.pdf",
        "ref_texts": "[48] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 2881\u20132890, 2017. 6,7",
        "ref_ids": [
          "48"
        ]
      },
      "Halsie: Hybrid approach to learning segmentation by simultaneously exploiting image and event modalities": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2211.10754",
        "ref_texts": "[12] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition , pp. 2881\u20132890, 2017. 2",
        "ref_ids": [
          "12"
        ]
      },
      "MFCA-Net: a deep learning method for semantic segmentation of remote sensing images": {
        "authors": [
          "Xiujuan Li"
        ],
        "url": "https://www.nature.com/articles/s41598-024-56211-1.pdf",
        "ref_texts": ""
      },
      "Scale-Space Hypernetworks for Efficient Biomedical Image Analysis": {
        "authors": [],
        "url": "https://proceedings.neurips.cc/paper_files/paper/2023/file/29f421fbdcc82aeb349d784d3aaccdb3-Paper-Conference.pdf",
        "ref_texts": "[74] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "74"
        ]
      },
      "ViT-AE++: improving vision transformer autoencoder for self-supervised medical image representations": {
        "authors": [],
        "url": "https://proceedings.mlr.press/v227/prabhakar24b/prabhakar24b.pdf",
        "ref_texts": "252, 2015. Haocheng Shen, Ruixuan Wang, Jianguo Zhang, and Stephen J McKenna. Boundary-aware fully convolutional network for brain tumor segmentation. In International Conference on Medical Image Computing and Computer-Assisted Intervention , pages 433\u2013441. Springer, 2017. Karen Simonyan and Andrew Zisserman. Very deep convolutional networks for large-scale image recognition, 2015. Sebastian R van der Voort, Fatih Incekara, Maarten MJ Wijnenga, Georgios Kapsas, Renske Gahrmann, Joost W Schouten, Hendrikus J Dubbink, Arnaud JPE Vincent, Martin J van den Bent, Pim J French, et al. The erasmus glioma database (egd): Structural mri scans, who 2016 subtypes, and segmentations of 774 patients with glioma. Data in brief , 37:107191, 2021. Dewen Zeng, Yawen Wu, Xinrong Hu, Xiaowei Xu, Haiyun Yuan, Meiping Huang, Jian Zhuang, Jingtong Hu, and Yiyu Shi. Positional contrastive learning for volumetric medical image segmentation. In International Conference on Medical Image Computing and Computer-Assisted Intervention , pages 221\u2013230. Springer, 2021. Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017. Zongwei Zhou, Vatsal Sodha, Md Mahfuzur Rahman Siddiquee, Ruibin Feng, Nima Tajbakhsh, Michael B Gotway, and Jianming Liang. Models genesis: Generic autodidactic models for 3d medical image analysis. In Medical Image Computing and ComputerAssisted Intervention , pages 384\u2013393, 2019."
      },
      "HAFormer: Unleashing the Power of Hierarchy-Aware Features for Lightweight Semantic Segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2407.07441",
        "ref_texts": "[30] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "30"
        ]
      },
      "Fish-Vista: A Multi-Purpose Dataset for Understanding & Identification of Traits from Images": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2407.08027",
        "ref_texts": "[61] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017.",
        "ref_ids": [
          "61"
        ]
      },
      "Towards the Uncharted: Density-Descending Feature Perturbation for Semi-supervised Semantic Segmentation": {
        "authors": [
          "Xiaoyang Wang",
          "Huihui Bai",
          "Limin Yu",
          "Yao Zhao",
          "Jimin Xiao"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Wang_Towards_the_Uncharted_Density-Descending_Feature_Perturbation_for_Semi-supervised_Semantic_Segmentation_CVPR_2024_paper.pdf",
        "ref_texts": "[55] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017. 1",
        "ref_ids": [
          "55"
        ]
      },
      "A simple image segmentation framework via in-context examples": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2410.04842",
        "ref_texts": "[ZSQ+17] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In IEEE Conf. Comput. Vis. Pattern Recog. , 2017.",
        "ref_ids": [
          "ZSQ\\+17"
        ]
      },
      "Cooperation Does Matter: Exploring Multi-Order Bilateral Relations for Audio-Visual Segmentation": {
        "authors": [
          "Qi Yang",
          "Xing Nie",
          "Tong Li",
          "Pengfei Gao",
          "Ying Guo",
          "Cheng Zhen",
          "Pengfei Yan",
          "Shiming Xiang"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Yang_Cooperation_Does_Matter_Exploring_Multi-Order_Bilateral_Relations_for_Audio-Visual_Segmentation_CVPR_2024_paper.pdf",
        "ref_texts": "[42] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , pages 6230\u20136239, 2017. 2",
        "ref_ids": [
          "42"
        ]
      },
      "Dynamic Knowledge Adapter with Probabilistic Calibration for Generalized Few-Shot Semantic Segmentation": {
        "authors": [
          "Jintao Tong",
          "Haichen Zhou",
          "Yicong Liu",
          "Yiman Hu",
          "Yixiong Zou"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024W/L3D-IVU/papers/Tong_Dynamic_Knowledge_Adapter_with_Probabilistic_Calibration_for_Generalized_Few-Shot_Semantic_CVPRW_2024_paper.pdf",
        "ref_texts": "[54] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017. 2",
        "ref_ids": [
          "54"
        ]
      },
      "Infer from What You Have Seen Before: Temporally-dependent Classifier for Semi-supervised Video Segmentation": {
        "authors": [
          "Jiafan Zhuang",
          "Zilei Wang",
          "Yixin Zhang",
          "Zhun Fan"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Zhuang_Infer_from_What_You_Have_Seen_Before_Temporally-dependent_Classifier_for_CVPR_2024_paper.pdf",
        "ref_texts": "[37] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017. 3",
        "ref_ids": [
          "37"
        ]
      },
      "Your Image is My Video: Reshaping the Receptive Field via Image-To-Video Differentiable AutoAugmentation and Fusion": {
        "authors": [
          "Sofia Casarin",
          "Cynthia I. Ugwu",
          "Sergio Escalera",
          "Oswald Lanz"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Casarin_Your_Image_is_My_Video_Reshaping_the_Receptive_Field_via_CVPR_2024_paper.pdf",
        "ref_texts": "[61] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017. 2, 6, 7",
        "ref_ids": [
          "61"
        ]
      },
      "Student-friendly knowledge distillation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2305.10893",
        "ref_texts": "[54] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890.",
        "ref_ids": [
          "54"
        ]
      },
      "Let Me Show You How It's Done-Cross-modal Knowledge Distillation as Pretext Task for Semantic Segmentation": {
        "authors": [
          "Rudhishna Narayanan",
          "Ronny Hansch"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024W/EarthVision/papers/Nair_Let_Me_Show_You_How_Its_Done_-_Cross-modal_Knowledge_CVPRW_2024_paper.pdf",
        "ref_texts": "[32] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , pages 6230\u20136239, 2017. 5",
        "ref_ids": [
          "32"
        ]
      },
      "MAD-UNet: A Multi-Region UAV Remote Sensing Network for Rural Building Extraction": {
        "authors": [
          "Hang Xue",
          "Ke Liu",
          "Yumeng Wang",
          "Yuxin Chen",
          "Caiyi Huang",
          "Pengfei Wang",
          "Lin Li"
        ],
        "url": "https://www.mdpi.com/1424-8220/24/8/2393/pdf",
        "ref_texts": "10. Zhao, H.; Shi, J.; Qi, X.; Wang, X.; Jia, J. Pyramid scene parsing network. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Honolulu, HI, USA, 21\u201326 July 2017; pp. 2881\u20132890.",
        "ref_ids": [
          "10"
        ]
      },
      "DeepDR: Deep Structure-Aware RGB-D Inpainting for Diminished Reality": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2312.00532",
        "ref_texts": "[91] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , pages 2881\u20132890, 2017. 3, 4",
        "ref_ids": [
          "91"
        ]
      },
      "Three-dimensional visualization of thyroid ultrasound images based on multi-scale features fusion and hierarchical attention": {
        "authors": [
          "Junyu Mi"
        ],
        "url": "https://link.springer.com/content/pdf/10.1186/s12938-024-01215-1.pdf",
        "ref_texts": ""
      },
      "InvPT++: Inverted Pyramid Multi-Task Transformer for Visual Scene Understanding": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2306.04842",
        "ref_texts": "[53] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in CVPR , 2017. 5",
        "ref_ids": [
          "53"
        ]
      },
      "UrbanSARFloods: Sentinel-1 SLC-Based Benchmark Dataset for Urban and Open-Area Flood Mapping": {
        "authors": [
          "Jie Zhao",
          "Zhitong Xiong",
          "Xiao Xiang"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024W/EarthVision/papers/Zhao_UrbanSARFloods_Sentinel-1_SLC-Based_Benchmark_Dataset_for_Urban_and_Open-Area_Flood_CVPRW_2024_paper.pdf",
        "ref_texts": "[50] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In 428",
        "ref_ids": [
          "50"
        ]
      },
      "Open Vocabulary Semantic Scene Sketch Understanding": {
        "authors": [
          "Ahmed Bourouis",
          "Judith E. Fan",
          "Yulia Gryaditskaya"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Bourouis_Open_Vocabulary_Semantic_Scene_Sketch_Understanding_CVPR_2024_paper.pdf",
        "ref_texts": "[64] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017. 2",
        "ref_ids": [
          "64"
        ]
      },
      "Query-guided Prototype Evolution Network for Few-Shot Segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2403.06488"
      },
      "What's Outside the Intersection? Fine-Grained Error Analysis for Semantic Segmentation Beyond IoU": {
        "authors": [
          "Maximilian Bernhard",
          "Roberto Amoroso",
          "Yannic Kindermann",
          "Lorenzo Baraldi",
          "Rita Cucchiara",
          "Volker Tresp",
          "Matthias Schubert"
        ],
        "url": "https://openaccess.thecvf.com/content/WACV2024/papers/Bernhard_Whats_Outside_the_Intersection_Fine-Grained_Error_Analysis_for_Semantic_Segmentation_WACV_2024_paper.pdf",
        "ref_texts": "[37] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017. 6",
        "ref_ids": [
          "37"
        ]
      },
      "Bidirectional feature fusion and enhanced alignment based multimodal semantic segmentation for remote sensing images": {
        "authors": [
          "Qianqian Liu",
          "Xili Wang"
        ],
        "url": "https://www.mdpi.com/2072-4292/16/13/2289/pdf",
        "ref_texts": "40. Zhao, H.; Shi, J.; Qi, X.; Wang, X.; Jia, J. Pyramid scene parsing network. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Honolulu, HI, USA, 21\u201326 July 2017; pp. 2881\u20132890. Remote Sens. 2024 ,16, 2289 21 of 21",
        "ref_ids": [
          "40"
        ]
      },
      "ShakingBot: dynamic manipulation for bagging": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2304.04558",
        "ref_texts": "[42] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition , pp. 2881\u20132890, 2017.",
        "ref_ids": [
          "42"
        ]
      },
      "SAM-CFFNet: SAM-based cross-feature fusion network for intelligent identification of landslides": {
        "authors": [
          "Laidian Xi",
          "Junchuan Yu",
          "Daqing Ge",
          "Yunxuan Pang",
          "Ping Zhou",
          "Changhong Hou",
          "Yichuan Li",
          "Yangyang Chen",
          "Yuanbiao Dong"
        ],
        "url": "https://www.mdpi.com/2072-4292/16/13/2334/pdf",
        "ref_texts": "70. Zhao, H.; Shi, J.; Qi, X.; Wang, X.; Jia, J. Pyramid scene parsing network. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Honolulu, HI, USA, 21\u201326 July 2017; pp. 2881\u20132890.",
        "ref_ids": [
          "70"
        ]
      },
      "FTUNet: A Feature-Enhanced Network for Medical Image Segmentation Based on the Combination of U-Shaped Network and Vision Transformer": {
        "authors": [
          "Yuefei Wang"
        ],
        "url": "https://link.springer.com/content/pdf/10.1007/s11063-024-11533-z.pdf",
        "ref_texts": "34. Zhao H, Shi J, Qi X, et al (2017) Pyramid scene parsing network. In: Proceedings of the IEEE conference on computer vision and pattern recognition, pp 2881\u20132890",
        "ref_ids": [
          "34"
        ]
      },
      "Multi-Branch Attention Fusion Network for Cloud and Cloud Shadow Segmentation": {
        "authors": [
          "Hongde Gu",
          "Guowei Gu",
          "Yi Liu",
          "Haifeng Lin",
          "Yao Xu"
        ],
        "url": "https://www.mdpi.com/2072-4292/16/13/2308/pdf",
        "ref_texts": "12. Zhao, H.; Shi, J.; Qi, X.; Wang, X.; Jia, J. Pyramid scene parsing network. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Honolulu, HI, USA, 21\u201326 July 2017; pp. 2881\u20132890.",
        "ref_ids": [
          "12"
        ]
      },
      "AutoMMLab: Automatically Generating Deployable Models from Language Instructions for Computer Vision Tasks": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2402.15351",
        "ref_texts": "[79] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017. 17",
        "ref_ids": [
          "79"
        ]
      },
      "360BEV: Panoramic Semantic Mapping for Indoor Bird's-Eye View": {
        "authors": [
          "Zhifeng Teng",
          "Jiaming Zhang",
          "Kailun Yang",
          "Kunyu Peng",
          "Hao Shi",
          "Simon Reiss",
          "Ke Cao",
          "Rainer Stiefelhagen"
        ],
        "url": "https://openaccess.thecvf.com/content/WACV2024/papers/Teng_360BEV_Panoramic_Semantic_Mapping_for_Indoor_Birds-Eye_View_WACV_2024_paper.pdf",
        "ref_texts": "[40] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017. 2",
        "ref_ids": [
          "40"
        ]
      },
      "Classwise-sam-adapter: Parameter efficient fine-tuning adapts segment anything to sar domain for semantic segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2401.02326",
        "ref_texts": "[28] J. Fu, J. Liu, H. Tian, Y . Li, Y . Bao, Z. Fang, and H. Lu, \u201cDual attention network for scene segmentation,\u201d in IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2019, Long Beach, CA, USA, June 16-20, 2019 . Computer Vision Foundation / IEEE, 2019, pp. 3146\u20133154. [Online]. Available: http://openaccess.thecvf.com/content CVPR 2019/html/Fu Dual Attention Network forScene Segmentation CVPR 2019 paper.html [29] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in 2017 IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2017, Honolulu, HI, USA, July 21-26, 2017 . IEEE Computer Society, 2017, pp. 6230\u20136239. [Online]. Available: https://doi.org/10.1109/CVPR.2017.660",
        "ref_ids": [
          "28",
          "Online",
          "29",
          "Online"
        ]
      },
      "Event-guided Low-light Video Semantic Segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2411.00639",
        "ref_texts": "[73] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017. 1",
        "ref_ids": [
          "73"
        ]
      },
      "Darksam: Fooling segment anything model to segment nothing": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2409.17874?",
        "ref_texts": "[42] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR\u201917) , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "42"
        ]
      },
      "Uncertainty-weighted Loss Functions for Improved Adversarial Attacks on Semantic Segmentation": {
        "authors": [
          "Kira Maag",
          "Asja Fischer"
        ],
        "url": "https://openaccess.thecvf.com/content/WACV2024/papers/Maag_Uncertainty-Weighted_Loss_Functions_for_Improved_Adversarial_Attacks_on_Semantic_Segmentation_WACV_2024_paper.pdf",
        "ref_texts": "[34] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017. 2, 4",
        "ref_ids": [
          "34"
        ]
      },
      "Network pruning via resource reallocation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2103.01847",
        "ref_texts": ""
      },
      "Research on Improved Road Visual Navigation Recognition Method Based on DeepLabV3+ in Pitaya Orchard": {
        "authors": [
          "Lixue Zhu",
          "Wenqian Deng",
          "Yingjie Lai",
          "Xiaogeng Guo",
          "Shiang Zhang"
        ],
        "url": "https://www.mdpi.com/2073-4395/14/6/1119/pdf",
        "ref_texts": "26. Zhao, H.; Shi, J.; Qi, X.; Wang, X.; Jia, J. Pyramid Scene Parsing Network. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Honolulu, HI, USA, 21\u201326 July 2017; pp. 2881\u20132890.",
        "ref_ids": [
          "26"
        ]
      },
      "Controluda: Controllable diffusion-assisted unsupervised domain adaptation for cross-weather semantic segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2402.06446",
        "ref_texts": ""
      },
      "Pick-or-Mix: Dynamic Channel Sampling for ConvNets": {
        "authors": [
          "Ashish Kumar",
          "Daneul Kim",
          "Jaesik Park",
          "Laxmidhar Behera"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Kumar_Pick-or-Mix_Dynamic_Channel_Sampling_for_ConvNets_CVPR_2024_paper.pdf",
        "ref_texts": "[39] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017. 8",
        "ref_ids": [
          "39"
        ]
      },
      "Fine-tuning vision foundation model for crack segmentation in civil infrastructures": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2312.04233",
        "ref_texts": "[16] H. Zhao, J. Shi, X. Qi, X. Wang, J. Jia, Pyramid Scene Parsing Network, in: 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), IEEE, Honolulu, HI, 2017: pp. 6230 -6239. https://doi.org/10.1109/CVPR.2017.660 . ",
        "ref_ids": [
          "16"
        ]
      },
      "Spatial analysis by current multiplexed imaging technologies for the molecular characterisation of cancer tissues": {
        "authors": [
          "Takashi Semba"
        ],
        "url": "https://www.nature.com/articles/s41416-024-02882-6.pdf",
        "ref_texts": "57. Zhao H, Shi J, Qi X, Wang X, Jia J. Pyramid scene parsing network. In: 2017 IEEE conference on computer vision and pattern recognition (CVPR), Honolulu, HI,USA, 2017, pp. 6230 \u20139.",
        "ref_ids": [
          "57"
        ]
      },
      "Pyramid fusion transformer for semantic segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2201.04019",
        "ref_texts": "[39] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition , 2017, pp. 2881\u20132890. 3, 4, 7",
        "ref_ids": [
          "39"
        ]
      },
      "Rgb-based category-level object pose estimation via decoupled metric scale recovery": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2309.10255",
        "ref_texts": "[29] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "29"
        ]
      },
      "Hybrid mamba for few-shot segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2409.19613",
        "ref_texts": "[62] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "62"
        ]
      },
      "Onboard data prioritization using multi-class image segmentation for nanosatellites": {
        "authors": [
          "Keenan Chatar",
          "Kentaro Kitamura",
          "Mengu Cho"
        ],
        "url": "https://www.mdpi.com/2072-4292/16/10/1729/pdf",
        "ref_texts": "13. Zhao, H.; Shi, J.; Qi, X.; Wang, X.; Jia, J. Pyramid scene parsing network. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Honolulu, HI, USA, 21\u201326 July 2017; pp. 2881\u20132890.",
        "ref_ids": [
          "13"
        ]
      },
      "OVExp: Open Vocabulary Exploration for Object-Oriented Navigation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2407.09016",
        "ref_texts": "[34] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , 2017.",
        "ref_ids": [
          "34"
        ]
      },
      "Predicting neighborhood-level residential carbon emissions from Street View images using computer vision and machine learning": {
        "authors": [
          "Wanqi Shi",
          "Yeyu Xiang",
          "Yuxuan Ying",
          "Yuqin Jiao",
          "Rui Zhao",
          "Waishan Qiu"
        ],
        "url": "https://www.mdpi.com/2072-4292/16/8/1312/pdf",
        "ref_texts": "133. Zhao, H.; Shi, J.; Qi, X.; Wang, X.; Jia, J. Pyramid Scene Parsing Network. arXiv 2017 , arXiv:1612.01105. Remote Sens. 2024 ,16, 1312 23 of 23",
        "ref_ids": [
          "133"
        ]
      },
      "Segmentation and vascular vectorization for coronary artery by geometry-based cascaded neural network": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2305.04208",
        "ref_texts": "[35] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid Scene Parsing Network. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "35"
        ]
      },
      "Generalized Few-Shot Meets Remote Sensing: Discovering Novel Classes in Land Cover Mapping via Hybrid Semantic Segmentation Framework": {
        "authors": [
          "Zhuohong Li",
          "Fangxiao Lu",
          "Jiaqi Zou",
          "Lei Hu",
          "Hongyan Zhang"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024W/L3D-IVU/papers/Li_Generalized_Few-Shot_Meets_Remote_Sensing_Discovering_Novel_Classes_in_Land_CVPRW_2024_paper.pdf",
        "ref_texts": "[48] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017. 6",
        "ref_ids": [
          "48"
        ]
      },
      "Overtaking mechanisms based on augmented intelligence for autonomous driving: Datasets, methods, and challenges": {
        "authors": [],
        "url": "https://napier-repository.worktribe.com/preview/3643801/Overtaking%20Mechanisms%20Based%20on%20Augmented%20Intelligence%20for%20Autonomous%20Driving%20Datasets_%20Methods_%20and%20Challenges_compressed.pdf",
        "ref_texts": "[152] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "152"
        ]
      },
      "Rethinking automatic segmentation of gross target volume from a decoupling perspective": {
        "authors": [
          "Jun Shi"
        ],
        "url": "http://home.ustc.edu.cn/~slruan/pdf/CMIG2024_Jun_Shi.pdf",
        "ref_texts": "2. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J., 2017. Pyramid scene parsing network. In: Proc. IEEE Conf. Comput. Vis. Pattern Recognit.. pp. 2881\u20132890, URL: https://doi .org/10.1109/cvpr.2017.660. Zhou, S., Nie, D., Adeli, E., Yin, J., Lian, J., Shen, D., 2019a. High-resolution encoder\u2013 decoder networks for low-contrast medical image segmentation. IEEE Trans. Imag. Process. 29, 461\u2013475, URL: https://doi.org/10.1109/tip.2019.2919937. Zhou, Z., Siddiquee, M., Tajbakhsh, N., Liang, J., 2019b. Unet++: Redesigning skip connections to exploit multiscale features in image segmentation. IEEE Trans. Med. Imaging 39 (6), 1856\u20131867, URL: https://doi.org/10.1109/tmi.2019.2959609. Zhou, L., Wang, S., Sun, K., Zhou, T., Yan, F., Shen, D., 2022. Three-dimensional affinity learning based multi-branch ensemble network for breast tumor segmentation in MRI. Pattern Recognit. 129, 108723, URL: https://doi.org/10.1016/j.patcog.2022.",
        "ref_ids": [
          "2"
        ]
      },
      "FusionHeightNet: A Multi-Level Cross-Fusion Method from Multi-Source Remote Sensing Images for Urban Building Height Estimation": {
        "authors": [
          "Chao Ma",
          "Yueting Zhang",
          "Jiayi Guo",
          "Guangyao Zhou",
          "Xiurui Geng"
        ],
        "url": "https://www.mdpi.com/2072-4292/16/6/958/pdf",
        "ref_texts": "31. Zhao, H.; Shi, J.; Qi, X.; Wang, X.; Jia, J. Pyramid scene parsing network. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Honolulu, HI, USA, 21\u201326 July 2017; pp. 2881\u20132890.",
        "ref_ids": [
          "31"
        ]
      },
      "Passive Snapshot Coded Aperture Dual-Pixel RGB-D Imaging": {
        "authors": [
          "Bhargav Ghanekar",
          "Salman Siddique",
          "Pranav Sharma",
          "Shreyas Singh",
          "Vivek Boominathan",
          "Kaushik Mitra",
          "Ashok Veeraraghavan"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Ghanekar_Passive_Snapshot_Coded_Aperture_Dual-Pixel_RGB-D_Imaging_CVPR_2024_paper.pdf",
        "ref_texts": "[37] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017. 4",
        "ref_ids": [
          "37"
        ]
      },
      "Memorize What Matters: Emergent Scene Decomposition from Multitraverse": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2405.17187",
        "ref_texts": "[75] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In IEEE Conf. Comput. Vis. Pattern Recog. , pages 2881\u20132890, 2017. 7",
        "ref_ids": [
          "75"
        ]
      },
      "Research on Retinal Vessel Segmentation Algorithm Based on a Modified U-Shaped Network": {
        "authors": [
          "Xialan He",
          "Ting Wang",
          "Wankou Yang"
        ],
        "url": "https://www.mdpi.com/2076-3417/14/1/465/pdf",
        "ref_texts": "36. Zhao, H.; Shi, J.; Qi, X.; Wang, X.; Jia, J. Pyramid Scene Parsing Network. In Proceedings of the 30TH IEEE Conference On Computer Vision And Pattern Recognition (CVPR 2017), Honolulu, HI, USA, 21\u201326 July 2017; pp. 6230\u20136239.",
        "ref_ids": [
          "36"
        ]
      },
      "DRNet: Disentanglement and recombination network for few-shot semantic segmentation": {
        "authors": [],
        "url": "https://figshare.le.ac.uk/articles/journal_contribution/DRNet_Disentanglement_and_recombination_network_for_few-shot_semantic_segmentation/25040030/1/files/44178269.pdf",
        "ref_texts": "[12] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition, 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "12"
        ]
      },
      "LEFormer: A hybrid CNN-transformer architecture for accurate lake extraction from remote sensing imagery": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2308.04397"
      },
      "Open-vocabulary remote sensing image semantic segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2409.07683",
        "ref_texts": "[2] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proc. IEEE Conf. Comput. Vis. Pattern Recog. , 2017, pp.",
        "ref_ids": [
          "2"
        ]
      },
      "DSCA-PSPNet: Dynamic spatial-channel attention pyramid scene parsing network for sugarcane field segmentation in satellite imagery": {
        "authors": [],
        "url": "https://www.frontiersin.org/articles/10.3389/fpls.2023.1324491/pdf",
        "ref_texts": "\u201cUnderstanding convolution for semantic segmentation, \u201din2018 IEEE winter conference on applications of computer vision (WACV) , 1451 \u20131460. Wang, H., Chen, X., Zhang, T., Xu, Z., and Li, J. (2022). CCTNet: Coupled CNN and transformer network for crop segmentation of remote sensing images. Remote Sens. 14, 1956. doi: 10.3390/rs14091956 Weiss, M., Jacob, F., and Duveiller, G. (2020). Remote sensing for agricultural applications: A metareview. Remote Sens. Environ. 236, 111402. doi: 10.1016/ j.rse.2019.111402 Woo, S., Park, J., Lee, J.-Y., and Kweon, I. S. (2018). \u201cCbam: Convolutional block attention module, \u201dinProceedings of the European conference on computer vision (ECCV) ,3\u201319. Xie, Y., Zheng, S., Wang, H., Qiu, Y., Lin, X., and Shi, Q. (2023). Edge detection with direction guided postprocessing for farmland parcel extraction. IEEE J. Sel. Top. Appl. Earth Obs. Remote Sens . doi: 10.1109/JSTARS.2023.3253779 Yu, F., and Koltun, V. (2015). Multi-scale context aggregation by dilated convolutions. arXiv. Prepr. arXiv1511.07122 . Zhang, Z., and Zhang, S. (2021). Towards understanding residual and dilated dense neural networks via convolutional sparse coding. Nat. Sci. Rev. 3, nwaa159. Zhang, X., Li, W., Gao, C., Yang, Y., and Chang, K. (2023). Hyperspectral pathology image classi fication using dimension-driven multi-path attention residual network. Expert Syst. Appl. 230, 120615. doi: 10.1016/j.eswa.2023.120615 Zhao, H., Shi, J., Qi, X., Wang, X., and Jia, J. (2017). \u201cPyramid scene parsing network, \u201dinProceedings of the IEEE conference on computer vision and pattern recognition , 2881 \u20132890.Yuan et al. 10.3389/fpls.2023.1324491 Frontiers in Plant Science frontiersin.org 16"
      },
      "Improving U-net network for semantic segmentation of corns and weeds during corn seedling stage in field": {
        "authors": [
          "Jiapeng Cui"
        ],
        "url": "https://www.frontiersin.org/journals/plant-science/articles/10.3389/fpls.2024.1344958/pdf",
        "ref_texts": "11, 29868 \u201329882. doi: 10.1109/ACCESS.2023.3258439 Wang, A., Zhang, W., and Wei, X. (2019). A review on weed detection using groundbased machine vision and image processing techniques. Comput. Electron. Agric. 158, 226\u2013240. doi: 10.1016/j.compag.2019.02.005 Wu, X., Aravecchia, S., Lottes, P., Stachniss, C., and Pradalier, C. (2020). Robotic weed control using automated weed and crop classi fication. J. Field Robot. 37, 322 \u2013340. doi:10.1002/rob.21938 Wu, Y., Yuzhe, H., and Wang, Y. (2023). Multi-class weed recognition using hybrid CNN-SVM classi fier.Sensors (Basel) 23, 7153. doi: 10.3390/s23167153 Wu, H., Wang, Y., Zhao, P., and Qian, M. (2023). Small-target weed-detection model based on YOLO-V4 with improved backbone and neck structures. Precis. Agric. 24, 2149 \u20132170. doi: 10.1007/s11119-023-10035-7 Xie, S., Girshick, R., Dolla \u0301r, P., Tu, Z., and He, K. (2017). \u201cAggregated Residual Transformations for Deep Neural Networks. \u201dinIEEE Conference on Computer Vision and Pattern Recognition (CVPR) , Honolulu, HI, USA 2017, 5987 \u20135995. doi: 10.1109/ CVPR.2017.634 Xie, B., Jin, Y., Faheem, M., Gao, W., Liu, J., Jiang, H., et al. (2023). Research progress of autonomous navigation technology for multi-agricultural scenes. Comput. Electron. Agric. 211, 107963. doi: 10.1016/j.compag.2023.107963 Yang, L., Xu, S., Yu, X., Long, H., Zhang, H., and Zhu, Y. (2023). A new model based on improved VGG16 for corn weed identi fication. Front. Plant Sci. 14. doi: 10.3389/ fpls.2023.1205151 Yu, H., Men, Z., Bi, C., and Liu, H. (2022). Research on field soybean weed identi fication based on an improved UNet model combined with a channel attention mechanism. Front. Plant Sci. 13. doi: 10.3389/fpls.2022.890051 Zhang, J., Gong, J., Zhang, Y., Mostafa, K., and Yuan, G. (2023). Weed identi fication in maize fields based on improved Swin-Unet. Agronomy 13, 1846. doi: 10.3390/ agronomy13071846 Zhang, Z., Li, S., Jia, J., Zheng, Z., and Tian, H. (2022). Application of convolution neural network algorithm based on intelligent sensor network in target recognition ofcorn weeder at seedling stage. J. Sens. 2022, 2748862. doi: 10.1155/2022/2748862 Zhao, H., Shi, J., Qi, X., Wang, X., and Jia, J. (2017). \u201cPyramid scene parsing network. \u201dinIEEE Conference on Computer Vision and Pattern Recognition (CVPR) , Honolulu, HI, USA, 2017, pp. 6230 \u20136239. doi: 10.1109/CVPR.2017.660 Zhao, Y., Ye, F., and Fu, Y. (2023). Research progress on the action mechanism of herbicide safeners: A review. J. Agric. Food Chem. 71, 3639 \u20133650. doi: 10.1021/ acs.jafc.2c08815 Zou, K., Liao, Q., Zhang, F., Che, X., and Zhang, C. (2022). A segmentation network for smart weed management in wheat fields. Comput. Electron. Agric. 202, 107303. doi:10.1016/j.compag.2022.107303Cui et al. 10.3389/fpls.2024.1344958 Frontiers in Plant Science frontiersin.org 16"
      },
      "Glass segmentation with multi scales and primary prediction guiding": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2402.08571",
        "ref_texts": "[46] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017. 2, 7",
        "ref_ids": [
          "46"
        ]
      },
      "A deep learning based platform for remote sensing images change detection integrating crowdsourcing and active learning": {
        "authors": [
          "Zhibao Wang",
          "Jie Zhang",
          "Lu Bai",
          "Huan Chang",
          "Yuanlin Chen",
          "Ying Zhang",
          "Jinhua Tao"
        ],
        "url": "https://www.mdpi.com/1424-8220/24/5/1509/pdf",
        "ref_texts": "47. Zhao, H.; Shi, J.; Qi, X.; Wang, X.; Jia, J. Pyramid scene parsing network. In Proceedings of the 2017 IEEE Conference on Computer Vision and Pattern Recognition, Honolulu, HI, USA, 21\u201326 July 2017; pp. 2881\u20132890. [CrossRef]",
        "ref_ids": [
          "47"
        ]
      },
      "Linknet-spectral-spatial-temporal transformer based on few-shot learning for mangrove loss detection with small dataset": {
        "authors": [
          "Ilham Adi",
          "Ilham Jamaluddin",
          "Nong Chen",
          "Nu Lai",
          "Chin Fan"
        ],
        "url": "https://www.mdpi.com/2072-4292/16/6/1078/pdf",
        "ref_texts": "59. Zhao, H.; Shi, J.; Qi, X.; Wang, X.; Jia, J. Pyramid Scene Parsing Network. In Proceedings of the 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Honolulu, HI, USA, 21\u201326 July 2017.",
        "ref_ids": [
          "59"
        ]
      },
      "Development, deployment and scaling of operating room-ready artificial intelligence for real-time surgical decision support": {
        "authors": [
          "Sergey Protserov"
        ],
        "url": "https://www.nature.com/articles/s41746-024-01225-2.pdf",
        "ref_texts": "13. Zhao, H., Jianping, S., Xiaojuan, Q., Wang, X. & Jiaya, J. Pyramid scene parsing network. ArXiv https://doi.org/10.48550/arXiv.1612.",
        "ref_ids": [
          "13"
        ]
      },
      "Deep learning algorithms for bladder cancer segmentation on multi-parametric MRI": {
        "authors": [
          "Kazim Z. Gumus",
          "Julien Nicolas",
          "Dheeraj R. Gopireddy",
          "Jose Dolz",
          "Seyed Behzad",
          "Mark Bandyk"
        ],
        "url": "https://www.mdpi.com/2072-6694/16/13/2348/pdf",
        "ref_texts": "25. Zhao, H.; Shi, J.; Qi, X.; Wang, X.; Jia, J. Pyramid Scene Parsing Network. arXiv 2016 , arXiv:1612.01105.",
        "ref_ids": [
          "25"
        ]
      },
      "Learning to Prompt Segment Anything Models": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2401.04651",
        "ref_texts": "[63] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017. 2",
        "ref_ids": [
          "63"
        ]
      },
      "EUNet: Edge-UNet for Accurate Building Extraction and Edge Emphasis in Gaofen-7 Images": {
        "authors": [
          "Ruijie Han",
          "Xiangtao Fan",
          "Jian Liu"
        ],
        "url": "https://www.mdpi.com/2072-4292/16/13/2397/pdf",
        "ref_texts": "43. Zhao, H.; Shi, J.; Qi, X.; Wang, X.; Jia, J. Pyramid Scene Parsing Network. In Proceedings of the 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Honolulu, HI, USA, 21\u201326 July 2017; pp. 6230\u20136239. Remote Sens. 2024 ,16, 2397 21 of 21",
        "ref_ids": [
          "43"
        ]
      },
      "PMFSNet: Polarized Multi-scale Feature Self-attention Network For Lightweight Medical Image Segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2401.07579",
        "ref_texts": "[3] H. Zhao, J. Shi, X. Qi, X. Wang, J. Jia, Pyramid scene parsing network, in: Proceedings of the IEEE conference on computer vision and pattern recognition, 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "3"
        ]
      },
      "DA-DRN: A degradation-aware deep Retinex network for low-light image enhancement": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2110.01809",
        "ref_texts": "[12] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "12"
        ]
      },
      "Spectrally segmented-enhanced neural network for precise land cover object classification in hyperspectral imagery": {
        "authors": [
          "Touhid Islam",
          "Rashedul Islam",
          "Palash Uddin",
          "Anwaar Ulhaq"
        ],
        "url": "https://www.mdpi.com/2072-4292/16/5/807/pdf",
        "ref_texts": "34. Zhao, H.; Shi, J.; Qi, X.; Wang, X.; Jia, J. Pyramid Scene Parsing Network. arXiv 2017 , arXiv:1612.01105.",
        "ref_ids": [
          "34"
        ]
      },
      "Conformal Semantic Image Segmentation: Post-hoc Quantification of Predictive Uncertainty": {
        "authors": [
          "Luca Mossina",
          "Joseba Dalmau",
          "Leo Andeol"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024W/SAIAD/papers/Mossina_Conformal_Semantic_Image_Segmentation_Post-hoc_Quantification_of_Predictive_Uncertainty_CVPRW_2024_paper.pdf",
        "ref_texts": "[65] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2017. 7",
        "ref_ids": [
          "65"
        ]
      },
      "Spotlight text detector: Spotlight on candidate regions like a camera": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2409.16820",
        "ref_texts": "[50] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "50"
        ]
      },
      "Deep Learning-Based Detection of Human Blastocyst Compartments with Fractal Dimension Estimation": {
        "authors": [
          "Muhammad Arsalan",
          "Adnan Haider",
          "Jin Seong",
          "Jung Soo",
          "Kang Ryoung"
        ],
        "url": "https://www.mdpi.com/2504-3110/8/5/267/pdf",
        "ref_texts": "47. Zhao, H.; Shi, J.; Qi, X.; Wang, X.; Jia, J. Pyramid Scene Parsing Network. In Proceedings of the 2017 IEEE Conference on Computer Vision and Pattern Recognition, Honolulu, HI, USA, 21\u201326 July 2017; pp. 2881\u20132890.",
        "ref_ids": [
          "47"
        ]
      },
      "An Urban Built Environment Analysis Approach for Street View Images Based on Graph Convolutional Neural Networks": {
        "authors": [
          "Changmin Liu",
          "Yang Wang",
          "Weikang Li",
          "Liufeng Tao",
          "Sheng Hu",
          "Mengqi Hao"
        ],
        "url": "https://www.mdpi.com/2076-3417/14/5/2108/pdf",
        "ref_texts": "35. Zhao, H.; Shi, J.; Qi, X.; Wang, X.; Jia, J. Pyramid scene parsing network. In Proceedings of the IEEE Conference On Computer Vision and Pattern Recognition, Honolulu, HI, USA, 21\u201326 July 2017; pp. 2881\u20132890.",
        "ref_ids": [
          "35"
        ]
      },
      "Transferable and Principled Efficiency for Open-Vocabulary Segmentation": {
        "authors": [
          "Jingxuan Xu",
          "Wuyang Chen",
          "Yao Zhao",
          "Yunchao Wei"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Xu_Transferable_and_Principled_Efficiency_for_Open-Vocabulary_Segmentation_CVPR_2024_paper.pdf",
        "ref_texts": "[50] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017. 1",
        "ref_ids": [
          "50"
        ]
      },
      "Dual-attention transformer-based hybrid network for multi-modal medical image segmentation": {
        "authors": [],
        "url": "https://www.nature.com/articles/s41598-024-76234-y.pdf",
        "ref_texts": ""
      },
      "BRAU-Net++: U-Shaped Hybrid CNN-Transformer Network for Medical Image Segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2401.00722",
        "ref_texts": "[18] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proc. IEEE Conf. Comput. Vis. Pattern Recognit. , Honolulu, HI, USA, 2017, pp. 6230\u20136239.",
        "ref_ids": [
          "18"
        ]
      },
      "MarsSeg: Mars Surface Semantic Segmentation with Multi-level Extractor and Connector": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2404.04155",
        "ref_texts": "[36] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2017, pp. 6230\u20136239.",
        "ref_ids": [
          "36"
        ]
      },
      "Possam: Panoptic open-vocabulary segment anything": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2403.09620",
        "ref_texts": "84. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: CVPR (2017) 4",
        "ref_ids": [
          "84"
        ]
      },
      "Mask-Pyramid Network: A Novel Panoptic Segmentation Method": {
        "authors": [
          "Fei Xian",
          "Man Po",
          "Jing Xiong",
          "Zhi Zhao",
          "Yin Yu",
          "Wai Cheung"
        ],
        "url": "https://www.mdpi.com/1424-8220/24/5/1411/pdf",
        "ref_texts": "2. Zhao, H.; Shi, J.; Qi, X.; Wang, X.; Jia, J. Pyramid scene parsing network. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Honolulu, HI, USA, 21\u201326 July 2017; pp. 2881\u20132890.",
        "ref_ids": [
          "2"
        ]
      },
      "Benchmarking Neural Radiance Fields for Autonomous Robots: An Overview": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2405.05526",
        "ref_texts": "[130] H. Zhao, J. Shi, X. Qi, X. Wang, J. Jia, Pyramid scene parsing network,in:ProceedingsoftheIEEEconferenceoncomputervision and pattern recognition, 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "130"
        ]
      },
      "Practical Region-level Attack against Segment Anything Models": {
        "authors": [
          "Yifan Shen",
          "Zhengyuan Li",
          "Gang Wang"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024W/TCV2024/papers/Shen_Practical_Region-level_Attack_against_Segment_Anything_Models_CVPRW_2024_paper.pdf",
        "ref_texts": "[46] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017. 2",
        "ref_ids": [
          "46"
        ]
      },
      "Deep learning for 3D vascular segmentation in hierarchical phase contrast tomography: a case study on kidney": {
        "authors": [],
        "url": "https://www.nature.com/articles/s41598-024-77582-5.pdf",
        "ref_texts": " 92. Zhao, H., Shi, J., Qi, X., Wang, X. & Jia, J. Pyramid scene parsing network. in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , 2881\u20132890 (2017)."
      },
      "Enhancing Semi-Supervised Semantic Segmentation of Remote Sensing Images via Feature Perturbation-Based Consistency Regularization Methods": {
        "authors": [
          "Firstname Lastname",
          "Firstname Lastname",
          "Firstname Lastname"
        ],
        "url": "https://www.mdpi.com/1424-8220/24/3/730/pdf",
        "ref_texts": "21. Zhao, H.; Shi, J.; Qi, X.; Wang, X.; Jia, J. Pyramid Scene Parsing Network. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Honolulu, HI, USA, 21\u201326 July 2017; pp. 2881\u20132890.",
        "ref_ids": [
          "21"
        ]
      },
      "UDTIRI: An online open-source intelligent road inspection benchmark suite": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2304.08842",
        "ref_texts": "[49] H. Zhao et al. , \u201cPyramid scene parsing network,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "49"
        ]
      },
      "Research on image classification and semantic segmentation model based on convolutional neural network": {
        "authors": [],
        "url": "https://drpress.org/ojs/index.php/jceim/article/download/20887/20446",
        "ref_texts": "[24] Lan, G., Han, D. J., Hashemi, A., Aggarwal , V., & Brinton, C. G. (2024). Asynchronous Federated Reinforcement Learning with Policy Gradient Updates: Algorithm Design and Convergence Analysis. arXiv preprint arXiv:2404.08003. [25] Zhao H, Shi J, Qi X, et al. Pyramid Scene Parsing Network[C]. Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. IEEE, 2017: 2881 -2890. ",
        "ref_ids": [
          "24",
          "25",
          "C"
        ]
      },
      "A Multi-Source Data Fusion Network for Wood Surface Broken Defect Segmentation": {
        "authors": [
          "Yuhang Zhu",
          "Zhezhuang Xu",
          "Ye Lin",
          "Dan Chen",
          "Zhijie Ai",
          "Hongchuan Zhang"
        ],
        "url": "https://www.mdpi.com/1424-8220/24/5/1635/pdf",
        "ref_texts": "41. Zhao, H.; Shi, J.; Qi, X.; Wang, X.; Jia, J. Pyramid scene parsing network. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Honolulu, HI, USA, 21\u201326 July 2017; pp. 6230\u20136239.",
        "ref_ids": [
          "41"
        ]
      },
      "Uplifting Range-View-based 3D Semantic Segmentation in Real-Time with Multi-Sensor Fusion": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2407.09697",
        "ref_texts": "[18] H.Zhao,J.Shi,X.Qi,X.Wang,J.Jia,Pyramidsceneparsingnetwork, In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 2881-2890, 2017.",
        "ref_ids": [
          "18"
        ]
      },
      "Implicit contrastive representation learning with guided stop-gradient": {
        "authors": [],
        "url": "https://proceedings.neurips.cc/paper_files/paper/2023/file/6274172f7d981a8d58bbfd52342a9d1f-Paper-Conference.pdf",
        "ref_texts": "12 Tongzhou Wang and Phillip Isola. Understanding contrastive representation learning through alignment and uniformity on the hypersphere. In International Conference on Machine Learning , pages 9929\u20139939. PMLR, 2020. Xiao Wang, Haoqi Fan, Yuandong Tian, Daisuke Kihara, and Xinlei Chen. On the importance of asymmetry for siamese representation learning. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 16570\u201316579, 2022. Yuxin Wu, Alexander Kirillov, Francisco Massa, Wan-Yen Lo, and Ross Girshick. Detectron2. https://github.com/facebookresearch/detectron2 , 2019. Zhirong Wu, Yuanjun Xiong, Stella X Yu, and Dahua Lin. Unsupervised feature learning via nonparametric instance discrimination. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 3733\u20133742, 2018. Jianxiong Xiao, James Hays, Krista A Ehinger, Aude Oliva, and Antonio Torralba. Sun database: Large-scale scene recognition from abbey to zoo. In 2010 IEEE computer society conference on computer vision and pattern recognition , pages 3485\u20133492. IEEE, 2010. Tete Xiao, Yingcheng Liu, Bolei Zhou, Yuning Jiang, and Jian Sun. Unified perceptual parsing for scene understanding. In Proceedings of the European conference on computer vision (ECCV) , pages 418\u2013434, 2018. Mang Ye, Xu Zhang, Pong C Yuen, and Shih-Fu Chang. Unsupervised embedding learning via invariant and spreading instance feature. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 6210\u20136219, 2019. Yang You, Igor Gitman, and Boris Ginsburg. Large batch training of convolutional networks. arXiv preprint arXiv:1708.03888 , 2017. Jure Zbontar, Li Jing, Ishan Misra, Yann LeCun, and St\u00e9phane Deny. Barlow twins: Self-supervised learning via redundancy reduction. In International Conference on Machine Learning , pages 12310\u201312320. PMLR, 2021. Richard Zhang, Phillip Isola, and Alexei A Efros. Colorful image colorization. In European conference on computer vision , pages 649\u2013666. Springer, 2016. Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017. Bolei Zhou, Hang Zhao, Xavier Puig, Sanja Fidler, Adela Barriuso, and Antonio Torralba. Scene parsing through ade20k dataset. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , 2017. Bolei Zhou, Hang Zhao, Xavier Puig, Tete Xiao, Sanja Fidler, Adela Barriuso, and Antonio Torralba. Semantic understanding of scenes through the ade20k dataset. International Journal on Computer Vision , 2018. Bolei Zhou, Hang Zhao, Xavier Puig, Tete Xiao, Sanja Fidler, Adela Barriuso, and Antonio Torralba. Semantic understanding of scenes through the ade20k dataset. International Journal of Computer Vision , 127:302\u2013321, 2019."
      },
      "Bpkd: Boundary privileged knowledge distillation for semantic segmentation": {
        "authors": [
          "Liyang Liu",
          "Zihan Wang",
          "Minh Hieu",
          "Bowen Zhang",
          "Jinchao Ge",
          "Yifan Liu"
        ],
        "url": "https://openaccess.thecvf.com/content/WACV2024/papers/Liu_BPKD_Boundary_Privileged_Knowledge_Distillation_for_Semantic_Segmentation_WACV_2024_paper.pdf",
        "ref_texts": "[67] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017. 2, 5, 6",
        "ref_ids": [
          "67"
        ]
      },
      "Centering the value of every modality: Towards efficient and resilient modality-agnostic semantic segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2407.11344",
        "ref_texts": "93. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: Proceedings of the IEEE conference on computer vision and pattern recognition. pp. 2881\u20132890 (2017)",
        "ref_ids": [
          "93"
        ]
      },
      "Bilateral Reference for High-Resolution Dichotomous Image Segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2401.03407",
        "ref_texts": "[55] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In IEEE / CVF Computer Vision and Pattern Recognition Conference , 2017. 3",
        "ref_ids": [
          "55"
        ]
      },
      "Mask2Former with Improved Query for Semantic Segmentation in Remote-Sensing Images": {
        "authors": [
          "Shichen Guo",
          "Qi Yang",
          "Shiming Xiang",
          "Shuwen Wang",
          "Xuezhi Wangs"
        ],
        "url": "https://www.mdpi.com/2227-7390/12/5/765/pdf",
        "ref_texts": "9. Zhao, H.; Shi, J.; Qi, X.; Wang, X.; Jia, J. Pyramid scene parsing network. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Honolulu, HI, USA, 21\u201326 July 2017; pp. 2881\u20132890.",
        "ref_ids": [
          "9"
        ]
      },
      "Visualizing Routes With AI-Discovered Street-View Patterns": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2404.00431",
        "ref_texts": "[23] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "23"
        ]
      },
      "Segmentation of Low-Light Optical Coherence Tomography Angiography Images under the Constraints of Vascular Network Topology": {
        "authors": [
          "Zhi Li",
          "Gaopeng Huang",
          "Binfeng Zou",
          "Wenhao Chen",
          "Tianyun Zhang",
          "Zhaoyang Xu",
          "Kunyan Cai",
          "Tingyu Wang",
          "Yaoqi Sun",
          "Yaqi Wang",
          "Kai Jin",
          "Xingru Huang"
        ],
        "url": "https://www.mdpi.com/1424-8220/24/3/774/pdf",
        "ref_texts": "37. Zhao, H.; Shi, J.; Qi, X.; Wang, X.; Jia, J. Pyramid Scene Parsing Network. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Honolulu, HI, USA, 22\u201325 July 2017; pp. 2881\u20132890.",
        "ref_ids": [
          "37"
        ]
      },
      "TSI-Siamnet: A Siamese network for cloud and shadow detection based on time-series cloudy images": {
        "authors": [],
        "url": "http://pure.lancaster.ac.uk/portal/services/downloadRegister/415092541/Final.pdf",
        "ref_texts": " satellite ima gery. IEEE J. Sel. Top. Appl. Earth Obs. Remote Sens. 8, 4197 \u20134205. 836 https://doi.org/10.1109/JSTARS.2015.2431676 . 837 Zhang, J., Wang, H., Wang, Y ., Zhou, Q., Li, Y., 2021. Deep network based on up and down 838 blocks using wavelet transform and successive multi -scale spatial attention for cloud 839 detection . Remote Sens. Environ. 261, 112483. https://doi.org/10.1016/j.rse.2021.112483 . 840 Zhang, J., Zhou, Q., Wu, J., Wang, Y ., Wang, H., Li, Y ., Chai, Y ., Liu, Y ., 2020. A Cloud 841 Detection Method Using Convolutional Neural Network Based on Gabor Transform and 842 Attention Mechanism with Dark Channel Subnet for Remote Sensing Image. Remote 843 Sens. 12, 3261. https://doi.org/10.3390/rs12193261 . 844 Zhang, Z., Liu, Q., Wang, Y ., 2018. Road Extraction by Deep Residual U -Net. IEEE Geosci. 845 Remote Sens. Lett. 15, 749 \u2013753. https://doi.org/10.1109/LGRS.2018.2802944 . 846 Zhao, C., Zhang, X., Luo H., Zhong, S., Tang, Lei., Peng, J., Fan, J., 2022. Semi -Supervised 847 Cloud detection for Remote Sensing Imagery via Self -Training. In: 2022 IEEE 848 International Conference on Artificial Intelligence and Computer Applications (ICAICA). 849 IEEE, pp. 311 -316. https://doi.org/10.1109/ICAICA54878.2022.9844616. 850 Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J., 2017. Pyramid Scene Parsing Ne twork. In: 2017 IEEE 851 Conference on Computer Vision and Pattern Recognition (CVPR) . IEEE, pp. 2881 -2890. 852 https://doi.org/10.48550/arXiv.1612.01105. 853 Zhu, X., Helmer, E.H., 2018. An automatic method for screening clouds and cloud shadows in 854 optical satellite image time series in cloudy regions. Remote Sens. Environ. 214, 135 \u2013153. 855 https://doi.org/10.1016/j.rse.2018.05.024 . 856 "
      },
      "Mma-net: Multiple morphology-aware network for automated cobb angle measurement": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2309.13817",
        "ref_texts": "[16] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "16"
        ]
      },
      "A Study of Kale Recognition Based on Semantic Segmentation": {
        "authors": [
          "Huarui Wu",
          "Wang Guo",
          "Chang Liu",
          "Xiang Sun"
        ],
        "url": "https://www.mdpi.com/2073-4395/14/5/894/pdf",
        "ref_texts": "6. Zhao, H.; Shi, J.; Qi, X.; Wang, X.; Jia, J. Pyramid Scene Parsing Network. In Proceedings of the 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Honolulu, HI, USA, 21\u201326 July 2017; IEEE: Piscataway, NJ, USA, 2017.",
        "ref_ids": [
          "6"
        ]
      },
      "A Dual-Branch Fusion Network Based on Reconstructed Transformer for Building Extraction in Remote Sensing Imagery": {
        "authors": [
          "Yitong Wang",
          "Shumin Wang",
          "Aixia Dou"
        ],
        "url": "https://www.mdpi.com/1424-8220/24/2/365/pdf",
        "ref_texts": "46. Zhao, H.; Shi, J.; Qi, X.; Wang, X.; Jia, J. Pyramid Scene Parsing Network. In Proceedings of the 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Honolulu, HI, USA, 21\u201326 July 2017; pp. 6230\u20136239.",
        "ref_ids": [
          "46"
        ]
      },
      "Spatial attention guided cgan for improved salient object detection": {
        "authors": [
          "Gayathri Dhara"
        ],
        "url": "https://www.frontiersin.org/journals/computer-science/articles/10.3389/fcomp.2024.1420965/pdf",
        "ref_texts": ""
      },
      "Exploring Reliable Matching with Phase Enhancement for Night-time Semantic Segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2408.13838"
      },
      "BEFUnet: A Hybrid CNN-Transformer Architecture for Precise Medical Image Segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2402.08793",
        "ref_texts": "[52] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "52"
        ]
      },
      "BSBP-RWKV: Background Suppression with Boundary Preservation for Efficient Medical Image Segmentation": {
        "authors": [],
        "url": "https://openreview.net/pdf?id=ULD5RCk0oo",
        "ref_texts": "[43] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. 2017. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition . 2881\u20132890.",
        "ref_ids": [
          "43"
        ]
      },
      "Scale Propagation Network for Generalizable Depth Completion": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2410.18408",
        "ref_texts": "[51] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "51"
        ]
      },
      "A deep image classification model based on prior feature knowledge embedding and application in medical diagnosis": {
        "authors": [
          "Chen Xu"
        ],
        "url": "https://www.nature.com/articles/s41598-024-63818-x.pdf",
        "ref_texts": ""
      },
      "High-speed detector for low-powered devices in aerial grasping": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2402.14591",
        "ref_texts": "[21] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2017.",
        "ref_ids": [
          "21"
        ]
      },
      "Generalizable Entity Grounding via Assistance of Large Language Model": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2402.02555",
        "ref_texts": "[48] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017. 2",
        "ref_ids": [
          "48"
        ]
      },
      "Maize leaf disease recognition using PRF-SVM integration: a breakthrough technique": {
        "authors": [
          "Prabhnoor Bachhal"
        ],
        "url": "https://www.nature.com/articles/s41598-024-60506-8.pdf",
        "ref_texts": " 43. Zhao, H., Shi, J., Qi, X., Wang, X. and Jia, J. Pyramid scene parsing network. In\u00a0 Proceedings of the IEEE conference on computer vision and pattern recognition2881\u20132890, (2017)."
      },
      "Graph-Segmenter: graph transformer with boundary-aware attention for semantic segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2308.07592",
        "ref_texts": "25. Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Computer Vision and Pattern Recognition , pages 2881\u20132890. IEEE, 2017.",
        "ref_ids": [
          "25"
        ]
      },
      "Instance Segmentation of Underwater Images by Using Deep Learning": {
        "authors": [
          "Jianfeng Chen",
          "Shidong Zhu",
          "Weilin Luo"
        ],
        "url": "https://www.mdpi.com/2079-9292/13/2/274/pdf",
        "ref_texts": "18. Zhao, H.; Shi, J.; Qi, X.; Wang, X.; Jia, J. Pyramid scene parsing network. In Proceedings of the 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Honolulu, HI, USA, 21\u201326 July 2017; pp. 2881\u20132890.",
        "ref_ids": [
          "18"
        ]
      },
      "RAP-SAM: Towards Real-Time All-Purpose Segment Anything": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2401.10228",
        "ref_texts": "[96] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017. 2",
        "ref_ids": [
          "96"
        ]
      },
      "RCNet: Deep Recurrent Collaborative Network for Multi-View Low-Light Image Enhancement": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2409.04363",
        "ref_texts": "[3] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "3"
        ]
      },
      "SEA-NET: medical image segmentation network based on spiral squeeze-and-excitation and attention modules": {
        "authors": [
          "Liangli Xiong"
        ],
        "url": "https://link.springer.com/content/pdf/10.1186/s12880-024-01194-8.pdf",
        "ref_texts": ""
      },
      "Fully automated kidney image biomarker prediction in ultrasound scans using Fast-Unet++": {
        "authors": [
          "Mostafa Ghelich"
        ],
        "url": "https://www.nature.com/articles/s41598-024-55106-5.pdf",
        "ref_texts": ""
      },
      "ResU-Former: Advancing Remote Sensing Image Segmentation with Swin Residual Transformer for Precise Global\u2013Local Feature Recognition and Visual\u2013Semantic \u2026": {
        "authors": [
          "Hanlu Li",
          "Lei Li",
          "Liangyu Zhao",
          "Fuxiang Liu"
        ],
        "url": "https://www.mdpi.com/2079-9292/13/2/436/pdf",
        "ref_texts": "38. Zhao, H.; Shi, J.; Qi, X.; Wang, X.; Jia, J. Pyramid scene parsing network. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Honolulu, HI, USA, 21\u201326 July 2017; pp. 2881\u20132890.",
        "ref_ids": [
          "38"
        ]
      },
      "Attention-guided Feature Distillation for Semantic Segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2403.05451",
        "ref_texts": "2022b. Masked generative distillation. In European Conference on Computer Vision , 53\u201369. Springer. Zagoruyko, S.; and Komodakis, N. 2016. Paying more attention to attention: Improving the performance of convolutional neural networks via attention transfer. arXiv preprint arXiv:1612.03928 . Zhao, H.; Gong, K.; Sun, X.; Dong, J.; and Yu, H. 2021. Similarity transfer for knowledge distillation. arXiv preprint arXiv:2103.10047 . Zhao, H.; Shi, J.; Qi, X.; Wang, X.; and Jia, J. 2017. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , 2881\u2013"
      },
      "Softmax-free linear transformers": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2207.03341",
        "ref_texts": "(2016) Rethinking the inception architecture for computer vision. In: IEEE Conference on Computer Vision and Pattern Recognition, pp 2818\u20132826 Tay Y, Dehghani M, Abnar S, Shen Y, Bahri D, Pham P, Rao J, Yang L, Ruder S, Metzler D (2020) Long range arena: A benchmark for efficient transformers. In: International Conference on Learning Representations Tay Y, Dehghani M, Bahri D, Metzler D (2023) Efficient transformers: A survey. ACM Computing Surveys 55(6):109:1\u2013109:28 Touvron H, Cord M, Douze M, Massa F, Sablayrolles A, J\u00b4 egou H (2021a) Training data-efficient image transformers & distillation through attention. In: International Conference on Machine Learning, PMLR, pp 10347\u201310357 Touvron H, Cord M, Sablayrolles A, Synnaeve G, J\u00b4 egou H (2021b) Going deeper with image transformers. In: IEEE Conference on Computer Vision and Pattern Recognition, pp 32\u201342 Touvron H, Cord M, J\u00b4 egou H (2022) Deit iii: Revenge of the vit. In: European Conference on Computer Vision, pp 516\u2013533 Tsai YHH, Bai S, Yamada M, Morency LP, Salakhutdinov R (2019) Transformer dissection: A unified understanding of transformer\u2019s attention via the lens of kernel. In: Conference on Empirical Methods in Natural Language Processing and International Joint Conference on Natural Language Processing (EMNLPIJCNLP), pp 4344\u20134353 Vaswani A, Shazeer N, Parmar N, Uszkoreit J, Jones L, Gomez AN, Kaiser L, Polosukhin I (2017) Attention is all you need. Advances in Neural Information Processing Systems 30 Von Luxburg U (2007) A tutorial on spectral clustering. Statistics and computing 17:395\u2013416 Wang S, Li BZ, Khabsa M, Fang H, Ma H (2020) Linformer: Self-attention with linear complexity. arXiv preprint arXiv:200604768 Wang W, Xie E, Li X, Fan DP, Song K, Liang D, Lu T, Luo P, Shao L (2021) Pyramid vision transformer: A versatile backbone for dense prediction without convolutions. In: IEEE International Conference on Computer Vision, pp 568\u2013578 Wang W, Xie E, Li X, Fan DP, Song K, Liang D, Lu T, Luo P, Shao L (2022) Pvt v2: Improved baselines with pyramid vision transformer. Computational Vi22 Jiachen Lu1, et al. sual Media 8(3):415\u2013424 Wang X, Girshick R, Gupta A, He K (2018) Non-local neural networks. In: IEEE Conference on Computer Vision and Pattern Recognition, pp 7794\u20137803 Wightman R (2019) Pytorch image models. https:// github.com/rwightman/pytorch-image-models Williams C, Seeger M (2000) Using the nystr\u00a8 om method to speed up kernel machines. Advances in Neural Information Processing Systems 13 Xiao T, Liu Y, Zhou B, Jiang Y, Sun J (2018) Unified perceptual parsing for scene understanding. In: European Conference on Computer Vision, pp 418\u2013434 Xie S, Girshick R, Doll\u00b4 ar P, Tu Z, He K (2017) Aggregated residual transformations for deep neural networks. In: IEEE Conference on Computer Vision and Pattern Recognition, pp 1492\u20131500 Xiong Y, Zeng Z, Chakraborty R, Tan M, Fung G, Li Y, Singh V (2021) Nystr\u00a8 omformer: A nystr\u00a8 ombased algorithm for approximating self-attention. In: AAAI Conference on Artificial Intelligence, vol 35, pp 14138\u201314148 Xu W, Xu Y, Chang T, Tu Z (2021) Co-scale convattentional image transformers. In: Proceedings of the IEEE/CVF International Conference on Computer Vision, pp 9981\u20139990 Yoshida Y, Miyato T (2017) Spectral norm regularization for improving the generalizability of deep learning. arXiv preprint arXiv:170510941 Yuan L, Chen Y, Wang T, Yu W, Shi Y, Jiang ZH, Tay FE, Feng J, Yan S (2021) Tokens-to-token vit: Training vision transformers from scratch on imagenet. In: IEEE International Conference on Computer Vision, pp 558\u2013567 Yuan Y, Chen X, Wang J (2020) Object-contextual representations for semantic segmentation. In: European Conference on Computer Vision, pp 173\u2013190 Yun S, Han D, Oh SJ, Chun S, Choe J, Yoo Y (2019) Cutmix: Regularization strategy to train strong classifiers with localizable features. In: IEEE International Conference on Computer Vision, pp 6023\u20136032 Zhang H, Ciss\u00b4 e M, Dauphin YN, Lopez-Paz D (2018) mixup: Beyond empirical risk minimization. In: International Conference on Learning Representations Zhang L, Xu D, Arnab A, Torr PH (2020) Dynamic graph message passing networks. In: IEEE Conference on Computer Vision and Pattern Recognition, pp 3726\u20133735 Zhang P, Dai X, Yang J, Xiao B, Yuan L, Zhang L, Gao J (2021) Multi-scale vision longformer: A new vision transformer for high-resolution image encoding. In: IEEE International Conference on Computer Vision, pp 2998\u20133008Zhao H, Shi J, Qi X, Wang X, Jia J (2017) Pyramid scene parsing network. In: IEEE Conference on Computer Vision and Pattern Recognition, pp 2881\u20132890 Zhao H, Jia J, Koltun V (2020) Exploring self-attention for image recognition. In: IEEE Conference on Computer Vision and Pattern Recognition, pp 10076\u2013"
      },
      "Active Generation for Image Classification": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2403.06517",
        "ref_texts": "47. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: Proceedings of the IEEE conference on computer vision and pattern recognition. pp. 2881\u20132890 (2017)",
        "ref_ids": [
          "47"
        ]
      },
      "Mobile-Seed: Joint Semantic Segmentation and Boundary Detection for Mobile Robots": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2311.12651",
        "ref_texts": "[22] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proc. of the IEEE/CVF Conf. on Computer Vision and Pattern Recognition (CVPR) , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "22"
        ]
      },
      "ODFormer: Semantic fundus image segmentation using transformer for optic nerve head detection": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2405.09552",
        "ref_texts": "[22] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "22"
        ]
      },
      "Solving partial differential equations using large-data models: a literature review": {
        "authors": [
          "Abdul Mueed"
        ],
        "url": "https://link.springer.com/content/pdf/10.1007/s10462-024-10784-5.pdf",
        "ref_texts": "503\u2013506 Zhao H, Shi J, Qi X, Wang X, Jia J (2017) Pyramid scene parsing network. In: IEEE conference on computer vision and pattern recognition, pp 6230\u20136239 Publisher\u2019s Note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations."
      },
      "Semantic segmentation of longitudinal thermal images for identification of hot and cool spots in urban areas": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2310.04247",
        "ref_texts": "[24] H. Zhao, J. Shi, X. Qi, X. Wang, J. Jia, Pyramid scene parsing network, in: Proceedings of the IEEE conference on computer vision and pattern recognition, 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "24"
        ]
      },
      "Incremental convolutional transformer for baggage threat detection": {
        "authors": [
          "Taimur Hassan"
        ],
        "url": "https://repository-api.adu.ac.ae/server/api/core/bitstreams/dd3f0b09-d32f-4da9-9672-9a1208f6051c/content",
        "ref_texts": "[37] H. Zhao, J. Shi, X. Qi, X. Wang, J. Jia, Pyramid scene parsing network, in: CVPR, 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "37"
        ]
      },
      "Weakly supervised training of universal visual concepts for multi-domain semantic segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2212.10340",
        "ref_texts": "[26] Zhao H, Shi J, Qi X, Wang X, Jia J. Pyramid scene parsing network. In: Proceedings of the IEEE conference on computer vision and pattern recognition; 2017. p. 2881\u20132890.",
        "ref_ids": [
          "26"
        ]
      },
      "MSDNet: Multi-Scale Decoder for Few-Shot Semantic Segmentation via Transformer-Guided Prototyping": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2409.11316",
        "ref_texts": "[32] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "32"
        ]
      },
      "Deep learning implementation of image segmentation in agricultural applications: a comprehensive review": {
        "authors": [
          "Lian Lei"
        ],
        "url": "https://link.springer.com/content/pdf/10.1007/s10462-024-10775-6.pdf",
        "ref_texts": "1 3Page 57 of 59 149 Wang X, Wang S, Ning C, Zhou H (2021b) Enhanced feature pyramid network with deep semantic embedding for remote sensing scene classification. IEEE Trans Geosci Remote Sens 59(9):7918\u20137932. https:// doi. org/ 10. 1109/ TGRS. 2020. 30446 55 Wang Z, Zhang S (2018) Segmentation of corn leaf disease based on fully convolution neural network. Acad J Comput Inform Sci 1(1). https:// doi. org/ 10. 25236/ AJCIS. 010002 Weyler J, Quakernack J, Lottes P, Behley J, Stachniss C (2022) Joint plant and leaf instance segmentation on fieldscale UAV imagery. IEEE Robot Autom Lett 7(2):3787\u20133794. https:// doi. org/ 10. 1109/ LRA. 2022. 31474 62 Wu J, Jiang Y, Bai S, Zhang W, Bai X (2022a) SeqFormer: sequential transformer for video instance segmentation. arXiv http:// arxiv. org/ abs/ 2112. 08275 Wu J, Wen C, Chen H, Ma Z, Zhang T, Su H, Yang C (2022b) DS-DETR: a model for tomato leaf disease segmentation and damage evaluation. Agronomy 12(9):2023. https:// doi. org/ 10. 3390/ agron omy12 092023 Wu T, Lu Y, Zhu Y, Zhang C, Wu M, Ma Z, Guo G (2020) GINet: Graph interaction network for scene parsing. In: Computer Vision\u2013ECCV 2020: 16th European Conference, Glasgow, UK, August 23\u201328, "
      },
      "A refreshed similarity-based upsampler for direct high-ratio feature upsampling": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2407.02283",
        "ref_texts": "[37] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "37"
        ]
      },
      "CD-MAE: Contrastive Dual-Masked Autoencoder Pre-Training Model for PCB CT Image Element Segmentation": {
        "authors": [
          "Baojie Song",
          "Jian Chen",
          "Shuhao Shi",
          "Jie Yang",
          "Chen Chen",
          "Kai Qiao",
          "Bin Yan"
        ],
        "url": "https://www.mdpi.com/2079-9292/13/6/1006/pdf",
        "ref_texts": "28. Zhao, H.; Shi, J.; Qi, X.; Wang, X.; Jia, J. Pyramid scene parsing network. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Honolulu, HI, USA, 21\u201326 July 2017; pp. 2881\u20132890.",
        "ref_ids": [
          "28"
        ]
      },
      "Enhanced multi-scale networks for semantic segmentation": {
        "authors": [
          "Tianping Li"
        ],
        "url": "https://link.springer.com/content/pdf/10.1007/s40747-023-01279-x.pdf",
        "ref_texts": "22. Zhao H, Shi J, Qi X et al (2017) Pyramid scene parsing network. In: Proceedings of the IEEE conference on computer vision and pattern recognition, pp 2881\u20132890",
        "ref_ids": [
          "22"
        ]
      },
      "Adversarial robustness improvement for X-ray bone segmentation using synthetic data created from computed tomography scans": {
        "authors": [],
        "url": "https://www.nature.com/articles/s41598-024-73363-2.pdf",
        "ref_texts": ""
      },
      "Convolutional neural networks rarely learn shape for semantic segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2305.06568",
        "ref_texts": "[5] H. Zhao, J. Shi, X. Qi, X. Wang, J. Jia, Pyramid scene parsing network, in: Proceedings of the IEEE conference on computer vision and pattern recognition, 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "5"
        ]
      },
      "Comprehensive walkability assessment of urban pedestrian environments using big data and deep learning techniques": {
        "authors": [],
        "url": "https://www.nature.com/articles/s41598-024-78041-x.pdf",
        "ref_texts": ""
      },
      "Semantic Segmentation of Remote Sensing Images Depicting Environmental Hazards in High-Speed Rail Network Based on Large-Model Pre-Classification": {
        "authors": [
          "Qi Dong",
          "Xiaomei Chen",
          "Lili Jiang",
          "Lin Wang",
          "Jiachong Chen",
          "Ying Zhao"
        ],
        "url": "https://www.mdpi.com/1424-8220/24/6/1876/pdf",
        "ref_texts": "34. Zhao, H.; Shi, J.; Qi, X.; Wang, X.; Jia, J. Pyramid scene parsing network. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Honolulu, HI, USA, 21\u201326 July 2017; pp. 2881\u20132890.",
        "ref_ids": [
          "34"
        ]
      },
      "A knowledge-based data-driven (KBDD) framework for all-day identification of cloud types using satellite remote sensing": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2312.00308",
        "ref_texts": "1594438 . Zhang, Q., Shen, Z., Pokhrel, Y ., Farinotti, D., Singh, V . P., Xu, C.-Y ., Wu, W., & Wang, G. (2023). Oceanic climate changes threaten the sustainability of Asia\u2019s water tower. Nature ,611, 87\u201393. doi: 10.1038/ s41586-022-05643-8 . Zhang, Z., Liu, Q., & Wang, Y . (2018). Road extraction by deep residual U-Net. IEEE Geosci. Remote Sens. Lett. ,15, 749\u2013753. doi: 10.1109/LGRS.2018.2802944 . Zhao, H., Shi, J., Qi, X., Wang, X., & Jia, J. (2017). Pyramid scene parsing network. In 2017 IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR) (pp. 6230\u20136239). doi: 10.1109/CVPR.2017.660 . Zhao, Z., Zhang, F., Wu, Q., Li, Z., Tong, X., Li, J., & Han, W. (2023). Cloud identification and properties retrieval of the fengyun-4a satellite using a resunet model. IEEE Trans. Geosci. Remote Sens. ,61, 1\u201318. doi: 10.1109/TGRS."
      },
      "Learn what you want to unlearn: Unlearning inversion attacks against machine unlearning": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2404.03233",
        "ref_texts": "[48] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "48"
        ]
      },
      "GLE-net: global-local information enhancement for semantic segmentation of remote sensing images": {
        "authors": [],
        "url": "https://www.nature.com/articles/s41598-024-76622-4.pdf",
        "ref_texts": ""
      },
      "AgMTR: Agent Mining Transformer for Few-Shot Segmentation in Remote Sensing": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2409.17453?",
        "ref_texts": "10(2):270\u2013294 Zhao H, Shi J, Qi X, Wang X, Jia J (2017) Pyramid scene parsing network. In: Proceedings of the IEEE conference on computer vision and pattern recognition, pp 2881\u20132890 Zhong Q, Chen L, Qian Y (2020) Few-shot learning for remote sensing image retrieval with maml. In: 2020 IEEE International Conference on Image Processing (ICIP), IEEE, pp 2446\u20132450 Zhu J, Yang K, Guan N, Yi X, Qiu C (2023) Hcpnet: Learning discriminative prototypes for few-shot remote sensing image scene classification. International Journal of Applied Earth Observation and Geoinformation 123:103447"
      },
      "Robust detection and refinement of saliency identification": {
        "authors": [
          "Abram W. Makram"
        ],
        "url": "https://www.nature.com/articles/s41598-024-61105-3.pdf",
        "ref_texts": ""
      },
      "Multi-scale feature alignment for continual learning of unlabeled domains": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2302.01287",
        "ref_texts": ""
      },
      "Stitchfusion: Weaving any visual modalities to enhance multimodal semantic segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2408.01343",
        "ref_texts": "2017. Rethinking atrous convolution for semantic image segmentation. arXiv preprint arXiv:1706.05587 . Chen, L.-C.; Zhu, Y .; Papandreou, G.; Schroff, F.; and Adam, H. 2018. Encoder-decoder with atrous separable convolution for semantic image segmentation. In Proceedings of the European conference on computer vision (ECCV) , 801\u2013818. Dong, S.; Zhou, W.; Xu, C.; and Yan, W. 2023. EGFNet: Edge-aware guidance fusion network for RGB\u2013thermal urban scene parsing. IEEE Transactions on Intelligent Transportation Systems . Dosovitskiy, A.; Beyer, L.; Kolesnikov, A.; Weissenborn, D.; Zhai, X.; Unterthiner, T.; Dehghani, M.; Minderer, M.; Heigold, G.; Gelly, S.; et al. 2020. An image is worth 16x16 words: Transformers for image recognition at scale. arXiv preprint arXiv:2010.11929 . Fu, J.; Liu, J.; Tian, H.; Li, Y .; Bao, Y .; Fang, Z.; and Lu, H. 2019. Dual attention network for scene segmentation. InProceedings of the IEEE/CVF conference on computer vision and pattern recognition , 3146\u20133154. Ha, Q.; Watanabe, K.; Karasawa, T.; Ushiku, Y .; and Harada, T. 2017. MFNet: Towards real-time semantic segmentation for autonomous vehicles with multi-spectral scenes. In 2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) , 5108\u20135115. IEEE. Hazirbas, C.; Ma, L.; Domokos, C.; and Cremers, D. 2016. Fusenet: Incorporating depth into semantic segmentation via fusion-based cnn architecture. In Asian conference on computer vision , 213\u2013228. Springer. He, Q. 2024. Prompting Multi-Modal Image Segmentation with Semantic Grouping. In Proceedings of the AAAI Conference on Artificial Intelligence , volume 38, 2094\u20132102. Huang, Z.; Wang, X.; Huang, L.; Huang, C.; Wei, Y .; and Liu, W. 2019. Ccnet: Criss-cross attention for semantic segmentation. In Proceedings of the IEEE/CVF international conference on computer vision , 603\u2013612. Joze, H. R. V .; Shaban, A.; Iuzzolino, M. L.; and Koishida, K. 2020. MMTM: Multimodal transfer module for CNN fusion. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , 13289\u201313299. Kaykobad, M. R.; and et al. 2023. Multimodal Transformer for Material Segmentation. arXiv e-prints , arXiv\u20132309.Liang, Y .; Wakaki, R.; Nobuhara, S.; and Nishino, K. 2022. Multimodal material segmentation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , 19800\u201319808. Liu, J.; Liu, Z.; Wu, G.; Ma, L.; Liu, R.; Zhong, W.; Luo, Z.; and Fan, X. 2023. Multi-interactive feature learning and a full-time multi-modality benchmark for image fusion and segmentation. In Proceedings of the IEEE/CVF international conference on computer vision , 8115\u20138124. Liu, Z.; Lin, Y .; Cao, Y .; Hu, H.; Wei, Y .; Zhang, Z.; Lin, S.; and Guo, B. 2021. Swin transformer: Hierarchical vision transformer using shifted windows. In Proceedings of the IEEE/CVF International Conference on Computer Vision, 10012\u201310022. Long, J.; Shelhamer, E.; and Darrell, T. 2015. Fully convolutional networks for semantic segmentation. In Proceedings of the IEEE conference on computer vision and pattern recognition , 3431\u20133440. Ronneberger, O.; Fischer, P.; and Brox, T. 2015. U-net: Convolutional networks for biomedical image segmentation. In International Conference on Medical image computing and computer-assisted intervention , 234\u2013241. Springer. Shivakumar, S. S.; Rodrigues, N.; Zhou, A.; Miller, I. D.; Kumar, V .; and Taylor, C. J. 2020. Pst900: Rgb-thermal calibration, dataset and segmentation network. In 2020 IEEE international conference on robotics and automation (ICRA) , 9441\u20139447. IEEE. Xie, E.; Wang, W.; Yu, Z.; Anandkumar, A.; Alvarez, J. M.; and Luo, P. 2021. SegFormer: Simple and efficient design for semantic segmentation with transformers. volume 34, 12077\u201312090. Zhang, J.; Liu, H.; Yang, K.; Hu, X.; Liu, R.; and Stiefelhagen, R. 2023a. CMX: Cross-modal fusion for RGB-X semantic segmentation with transformers. IEEE Transactions on Intelligent Transportation Systems . Zhang, J.; Liu, R.; Shi, H.; Yang, K.; Rei\u00df, S.; Peng, K.; Fu, H.; Wang, K.; and Stiefelhagen, R. 2023b. Delivering arbitrary-modal semantic segmentation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , 1136\u20131147. Zhao, H.; Shi, J.; Qi, X.; Wang, X.; and Jia, J. 2017. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , 2881\u2013",
        "ref_ids": [
          "2017"
        ]
      },
      "Pixel-Level Domain Adaptation: A New Perspective for Enhancing Weakly Supervised Semantic Segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2408.02039",
        "ref_texts": "[5] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in CVPR , 2017. sourcetarget BaselinePLDA(ours)++",
        "ref_ids": [
          "5"
        ]
      },
      "ISAR: A Benchmark for Single-and Few-Shot Object Instance Segmentation and Re-Identification": {
        "authors": [
          "Nicolas Gorlo",
          "Kenneth Blomqvist",
          "Francesco Milano",
          "Roland Siegwart"
        ],
        "url": "https://openaccess.thecvf.com/content/WACV2024/papers/Gorlo_ISAR_A_Benchmark_for_Single-_and_Few-Shot_Object_Instance_Segmentation_WACV_2024_paper.pdf",
        "ref_texts": "[91] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017. 1",
        "ref_ids": [
          "91"
        ]
      },
      "Towards Robust Semantic Segmentation against Patch-Based Attack via Attention Refinement": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2401.01750",
        "ref_texts": "[28] Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: CVPR, pp. 6230\u20136239 (2017)",
        "ref_ids": [
          "28"
        ]
      },
      "Investigation of Customized Medical Decision Algorithms Utilizing Graph Neural Networks": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2405.17460",
        "ref_texts": "[25] Zhao, Hengshuang, et al. \"Pyramid scene parsing network.\" Proceedings of the IEEE conference on computer vision and pattern recognition. 2017. ",
        "ref_ids": [
          "25"
        ]
      },
      "FADE: A Task-Agnostic Upsampling Operator for Encoder\u2013Decoder Architectures": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2407.13500",
        "ref_texts": "(2014) On the properties of neural machine translation: Encoder-decoder approaches. arXiv Comput Res Repository Dai Y, Lu H, Shen C (2021) Learning affinity-aware upsampling for deep image matting. In: Proc. IEEE Conf. Comput. Vis. Patt. Recogn., pp 6841\u20136850 Dong C, Loy CC, He K, Tang X (2015) Image superresolution using deep convolutional networks. IEEE Trans Pattern Anal Mach Intell 38(2):295\u2013307 Eigen D, Puhrsch C, Fergus R (2014) Depth map prediction from a single image using a multi-scale deep network. In: Proc. Annu. Conf. Neural Inf. Process. Syst., pp 2366\u20132374 Everingham M, Van Gool L, Williams CK, Winn J, Zisserman A (2010) The pascal visual object classes (VOC) challenge. Int J Comput Vis 88(2):303\u2013338 Girshick R, Donahue J, Darrell T, Malik J (2014) Rich feature hierarchies for accurate object detection and FADE: A Task-Agnostic Upsampling Operator for Encoder-Decoder Architectures 21 semantic segmentation. In: Proc. IEEE Conf. Comput. Vis. Patt. Recogn., pp 580\u2013587 He K, Sun J, Tang X (2010) Guided image filtering. In: Proc. Eur. Conf. Comput. Vis., Springer, pp 1\u201314 He K, Zhang X, Ren S, Sun J (2016) Deep residual learning for image recognition. In: Proc. IEEE Conf. Comput. Vis. Patt. Recogn., pp 770\u2013778 He K, Gkioxari G, Doll\u00b4 ar P, Girshick R (2017) Mask R-CNN. In: Proc. IEEE Int. Conf. Comput. Vis., pp 2961\u20132969 Huang S, Lu Z, Cheng R, He C (2021) Fapn: Featurealigned pyramid network for dense image prediction. In: Proc. IEEE Int. Conf. Comput. Vis., pp 864\u2013873 Ignatov A, Timofte R, Denna M, Younes A (2021) Real-time quantized image super-resolution on mobile npus, mobile ai 2021 challenge: Report. In: Proc. IEEE Conf. Comput. Vis. Patt. Recogn. Workshops, pp 2525\u20132534 Kirillov A, Wu Y, He K, Girshick R (2020) Pointrend: Image segmentation as rendering. In: Proc. IEEE Conf. Comput. Vis. Patt. Recogn., pp 9799\u20139808 Kirillov A, Mintun E, Ravi N, Mao H, Rolland C, Gustafson L, Xiao T, Whitehead S, Berg AC, Lo WY, Dollar P, Girshick R (2023) Segment anything. In: Proc. IEEE Int. Conf. Comput. Vis., pp 4015\u20134026 Lee JH, Han MK, Ko DW, Suh IH (2019) From big to small: Multi-scale local planar guidance for monocular depth estimation. arXiv Comput Res Repository Li X, Li X, Zhang L, Cheng G, Shi J, Lin Z, Tan S, Tong Y (2020a) Improving semantic segmentation via decoupled body and edge supervision. In: Proc. Eur. Conf. Comput. Vis., Springer, pp 435\u2013452 Li X, You A, Zhu Z, Zhao H, Yang M, Yang K, Tan S, Tong Y (2020b) Semantic flow for fast and accurate scene parsing. In: Proc. Eur. Conf. Comput. Vis., Springer, pp 775\u2013793 Li X, Zhao H, Han L, Tong Y, Tan S, Yang K (2020c) Gated fully fusion for semantic segmentation. In: Proc. AAAI Conf. Artificial Intell., vol 34, pp 11418\u2013"
      },
      "A Multi-Path Semantic Segmentation Network Based on Convolutional Attention Guidance": {
        "authors": [
          "Chenyang Feng",
          "Shu Hu",
          "Yi Zhang"
        ],
        "url": "https://www.mdpi.com/2076-3417/14/5/2024/pdf",
        "ref_texts": "12. Zhao, H.; Shi, J.; Qi, X.; Wang, X.; Jia, J. Pyramid scene parsing network. In Proceedings of the 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Honolulu, HI, USA, 21\u201326 July 2017; pp. 2881\u20132890.",
        "ref_ids": [
          "12"
        ]
      },
      "Patchrefinenet: Improving binary segmentation by incorporating signals from optimal patch-wise binarization": {
        "authors": [
          "Savinay Nagendra",
          "Daniel Kifer"
        ],
        "url": "https://openaccess.thecvf.com/content/WACV2024/papers/Nagendra_PatchRefineNet_Improving_Binary_Segmentation_by_Incorporating_Signals_From_Optimal_Patch-Wise_WACV_2024_paper.pdf",
        "ref_texts": "[68] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017. 3, 4, 7",
        "ref_ids": [
          "68"
        ]
      },
      "Sensitivity Decouple Learning for Image Compression Artifacts Reduction": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2405.09291",
        "ref_texts": "[75] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR) , 2017.",
        "ref_ids": [
          "75"
        ]
      },
      "Automatic Detection of Collapsed Buildings after the 6 February 2023 T\u00fcrkiye Earthquakes Using Post-Disaster Satellite Images with Deep Learning-Based Semantic \u2026": {
        "authors": [],
        "url": "https://www.mdpi.com/2075-5309/14/3/582/pdf",
        "ref_texts": "12. Zhao, H.; Shi, J.; Qi, X.; Wang, X.; Jia, J. Pyramid scene parsing network. In Proceedings-30th IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2017 ; Institute of Electrical and Electronics Engineers Inc.: New York, NY, USA, 2017; pp. 6230\u20136239.",
        "ref_ids": [
          "12"
        ]
      },
      "Cascade-CLIP: Cascaded Vision-Language Embeddings Alignment for Zero-Shot Semantic Segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2406.00670",
        "ref_texts": "11 Cascade-CLIP: Cascaded Vision-Language Embeddings Alignment for Zero-Shot Semantic Segmentation Zeng, Y ., Zhang, X., and Li, H. Multi-grained vision language pre-training: Aligning texts with visual concepts. InICML , pp. 25994\u201326009, 2022. Zhang, B., Tian, Z., Tang, Q., Chu, X., Wei, X., Shen, C., et al. Segvit: Semantic segmentation with plain vision transformers. In NeurIPS , pp. 4971\u20134982, 2022. Zhao, H., Shi, J., Qi, X., Wang, X., and Jia, J. Pyramid scene parsing network. In CVPR , 2017. Zheng, S., Lu, J., Zhao, H., Zhu, X., Luo, Z., Wang, Y ., Fu, Y ., Feng, J., Xiang, T., Torr, P. H., et al. Rethinking semantic segmentation from a sequence-to-sequence perspective with transformers. In CVPR , pp. 6881\u20136890, 2021. Zhou, C., Loy, C. C., and Dai, B. Extract free dense labels from clip. In ECCV , pp. 696\u2013712, 2022a. Zhou, K., Yang, J., Loy, C. C., and Liu, Z. Learning to prompt for vision-language models. IJCV , 130(9):2337\u2013"
      },
      "Framework-agnostic Semantically-aware Global Reasoning for Segmentation": {
        "authors": [
          "Mir Rayat",
          "Imtiaz Hossain",
          "Leonid Sigal",
          "James J. Little"
        ],
        "url": "https://openaccess.thecvf.com/content/WACV2024/papers/Hossain_Framework-Agnostic_Semantically-Aware_Global_Reasoning_for_Segmentation_WACV_2024_paper.pdf",
        "ref_texts": "[67] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , pages 2881\u20132890, 2017. 3",
        "ref_ids": [
          "67"
        ]
      },
      "LM-DeeplabV3+: A Lightweight Image Segmentation Algorithm Based on Multi-Scale Feature Interaction": {
        "authors": [
          "Xinyu Hou",
          "Peng Chen",
          "Haishuo Gu"
        ],
        "url": "https://www.mdpi.com/2076-3417/14/4/1558/pdf",
        "ref_texts": "13. Zhao, H.; Shi, J.; Qi, X.; Wang, X.; Jia, J. Pyramid Scene Parsing Network. In Proceedings of the 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Honolulu, HI, USA, 21\u201326 July 2017; pp. 6230\u20136239. [CrossRef]",
        "ref_ids": [
          "13"
        ]
      },
      "Cross-modality cerebrovascular segmentation based on pseudo-label generation via paired data": {
        "authors": [
          "Zhanqiang Guo"
        ],
        "url": "http://ivg.au.tsinghua.edu.cn/~jfeng/pubs/Guo_CMIG24_SegmentViaPairData.pdf",
        "ref_texts": "14Z. Guo et al. Sankaranarayanan, S., Balaji, Y., Jain, A., Lim, S.N., Chellappa, R., 2018. Learning from synthetic data: Addressing domain shift for semantic segmentation. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. pp. 3752\u20133761. Shao, S., Wang, T., Mumtaz, A., Song, C., Yao, C., 2022. Predicting cardiovascular and cerebrovascular events based on instantaneous high-order singular entropy and deep belief network. IEEE J. Biomed. Health Inform 27 (4), 1670\u20131680. Sharan, L., Romano, G., Koehler, S., Kelm, H., Karck, M., DeSimone, R., Engelhardt, S., 2022. Mutually improved endoscopic image synthesis and landmark detection in unpaired image-to-image translation. IEEE J. Biomed. Health Inform 27 (1), 374\u2013385. Shit, S., Paetzold, J.C., Sekuboyina, A., Ezhov, I., Unger, A., Zhylka, A., Pluim, J.P.W., Bauer, U., Menze, B.H., 2021. ClDice-a novel topology-preserving loss function for tubular structure segmentation. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. pp. 16560\u201316569. Sun, Y., Yuan, P., Sun, Y., 2020. MM-GAN: 3D MRI data augmentation for medical image segmentation via generative adversarial networks. In: IEEE International Conference on Knowledge Graph. ICKG, IEEE, pp. 227\u2013234. Taher, F., Soliman, A., Kandil, H., Mahmoud, A., Shalaby, A., Gimel\u2019farb, G., El-Baz, A., 2020. Accurate segmentation of cerebrovasculature from TOF-mra images using appearance descriptors. IEEE Access 8, 96139\u201396149. Tetteh, G., Efremov, V., Forkert, N.D., Schneider, M., Kirschke, J., Weber, B., Zimmer, C., et al., 2020. Deepvesselnet: Vessel segmentation, centerline prediction, and bifurcation detection in 3-D angiographic volumes. Front. Neurosci. 14, 592352. Toldo, M., Maracani, A., Michieli, U., Zanuttigh, P., 2020. Unsupervised domain adaptation in semantic segmentation: a review. Technologies 8 (2), 35. Tzeng, E., Hoffman, J., Saenko, K., Darrell, T., 2017. Adversarial discriminative domain adaptation. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. pp. 7167\u20137176. Weng, W., Ding, H., Bai, J., Zhou, W., Wang, G., 2023. Cerebrovascular segmentation in phase-contrast magnetic resonance angiography by a radon projection composition network. Comput. Med. Imag. Graph 107, 102228. Wu, J., Gu, R., Dong, G., Wang, G., Zhang, S., 2022. FPL-UDA: Filtered pseudo label-based unsupervised cross-modality adaptation for vestibular schwannoma segmentation. In: International Symposium on Biomedical Imaging. IEEE, pp. 1\u20135.Xing, F., Bennett, T., Ghosh, D., 2019. Adversarial domain adaptation and pseudolabeling for cross-modality microscopy image quantification. In: International Conference on Medical Image Computing and Computer-Assisted Intervention. Springer, pp. 740\u2013749. Xu, X., Chen, Y., Wu, J., Lu, J., Ye, Y., Huang, Y., Dou, X., et al., 2023. A novel one-to-multiple unsupervised domain adaptation framework for abdominal organ segmentation. Med. Image Anal 88, 102873. Xu, R., Chen, Z., Zuo, W., Yan, J., Lin, L., 2018. Deep cocktail network: Multi-source unsupervised domain adaptation with category shift. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. pp. 3964\u20133973. Yao, K., Su, Z., Huang, K., Yang, X., Sun, J., Hussain, A., Coenen, F., 2022. A novel 3D unsupervised domain adaptation framework for cross-modality medical image segmentation. IEEE J. Biomed. Health Inform 26 (10), 4976\u20134986. Yasugi, M., Hossain, B., Nii, M., Kobashi, S., 2018. Relationship between cerebral aneurysm development and cerebral artery shape. J. Adv. Comput. Intell. Intell. Inform 22 (2), 249\u2013255. Zhang, B., Liu, S., Zhou, S., Yang, J., Wang, C., Li, N., Wu, Z., Xia, J., 2020a. Cerebrovascular segmentation from TOF-MRA using model-and data-driven method via sparse labels. Neurocomputing 380, 162\u2013179. Zhang, H., Xia, L., Song, R., Yang, J., Hao, H., Liu, J., Zhao, Y., 2020b. Cerebrovascular segmentation in MRA via reverse edge attention network. In: International Conference on Medical Image Computing and Computer-Assisted Intervention. Springer, pp. 66\u201375. Zhang, Z., Yang, L., Zheng, Y., 2018. Translating and segmenting multimodal medical volumes with cycle-and shape-consistency generative adversarial network. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. pp. 9242\u20139251. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J., 2017. Pyramid scene parsing network. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. pp. 2881\u20132890. Zhu, J.Y., Park, T., Isola, P., Efros, A.A., 2017. Unpaired image-to-image translation using cycle-consistent adversarial networks. In: Proceedings of the IEEE International Conference on Computer Vision. pp. 2223\u20132232."
      },
      "Divide and Conquer: Improving Multi-Camera 3D Perception With 2D Semantic-Depth Priors and Input-Dependent Queries": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2408.06901?",
        "ref_texts": "[26] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d Proceedings of the IEEE conference on Computer Vision and Pattern Recognition (CVPR) , pp. 2881\u20132890, 2017.",
        "ref_ids": [
          "26"
        ]
      },
      "SolarFormer: Multi-scale transformer for solar PV profiling": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2310.20057",
        "ref_texts": "[42] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "42"
        ]
      },
      "Semantic and Spatial Adaptive Pixel-level Classifier for Semantic Segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2405.06525",
        "ref_texts": "[59] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017. 1, 3",
        "ref_ids": [
          "59"
        ]
      },
      "Video Generalized Semantic Segmentation via Non-Salient Feature Reasoning and Consistency": {
        "authors": [],
        "url": "https://hal.science/hal-04506025/document",
        "ref_texts": "[35] H.Zhao,J.Shi,X.Qi,X.Wang,J.Jia,Pyramidsceneparsingnetwork, in: Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "35"
        ]
      },
      "Trainable Highly-expressive Activation Functions": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2407.07564",
        "ref_texts": "69. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: CVPR (2017)",
        "ref_ids": [
          "69"
        ]
      },
      "C-LiSA: A Hierarchical Hybrid Transformer Model using Orthogonal Cross Attention for Satellite Image Cloud Segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2311.17475",
        "ref_texts": "[24] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2017, pp. 6230\u20136239.",
        "ref_ids": [
          "24"
        ]
      },
      "Robust unsupervised domain adaptation by retaining confident entropy via edge concatenation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2310.07149",
        "ref_texts": ".https://doi.org/10.48550/arXiv.1511.0712 . Yu, F., Zhang, M., Dong, H., Hu, S., Dong, B., & Zhang, L. (2021). Dast: Unsupervised domain adaptation in semantic segmentation based on discriminator attention and self-training. In Proceedings of the AAAI Conference on Artificial Intelligence (pp. 10754\u201310762). volume 35. Yu, Z., Feng, C., Liu, M.-Y ., & Ramalingam, S. (2017). Casenet: Deep category-aware semantic edge detection. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (pp. 5964\u20135973). Yu, Z., Liu, W., Zou, Y ., Feng, C., Ramalingam, S., Kumar, B., & Kautz, J. (2018). Simultaneous edge alignment and learning. In Proceedings of the European Conference on Computer Vision (pp. 388\u2013404). Zhang, X., Chen, Y ., Shen, Z., Shen, Y ., Zhang, H., & Zhang, Y . (2022). Confidence-and-refinement adaptation model for cross-domain semantic segmentation. IEEE Transactions on Intelligent Transportation Systems ,23, 9529\u20139542. https://doi.org/10.1109/TITS.2022.3140481 . Zhang, Y . (2021). A survey of unsupervised domain adaptation for visual recognition. arXiv preprint arXiv:2112.06745 , .https://doi.org/10.48550/arXiv.2112.06745 . Zhang, Y ., David, P., Foroosh, H., & Gong, B. (2020). A curriculum domain adaptation approach to the semantic segmentation of urban scenes. IEEE Transactions on Pattern Analysis and Machine Intelligence ,42, 1823\u20131841. https://doi.org/10.1109/TPAMI.2019.2903401 . Zhang, Y ., David, P., & Gong, B. (2017). Curriculum domain adaptation for semantic segmentation of urban scenes. In Proceedings of the IEEE International Conference on Computer Vision (pp. 2020\u20132030). Zhao, H., Shi, J., Qi, X., Wang, X., & Jia, J. (2017). Pyramid scene parsing network. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (pp. 2881\u20132890). Zhao, Z.-Q., Zheng, P., Xu, S.-t., & Wu, X. (2019). Object detection with deep learning: A review. IEEE Transactions on Neural Networks and Learning Systems ,30, 3212\u20133232. https://doi.org/10.1109/TNNLS.2018.2876865 . Zhou, W., Wang, Y ., Chu, J., Yang, J., Bai, X., & Xu, Y . (2021). A ffinity space adaptation for semantic segmentation across domains. IEEE Transactions on Image Processing ,30, 2549\u20132561. https://doi.org/10.1109/TIP."
      },
      "Position adaptive residual block and knowledge complement strategy for point cloud analysis": {
        "authors": [
          "Shichao Zhang"
        ],
        "url": "https://link.springer.com/content/pdf/10.1007/s10462-024-10754-x.pdf",
        "ref_texts": "1013\u20131020 Thomas H, Qi CR, Deschaud JE, Marcotegui B, Goulette F, Guibas LJ (2019) Kpconv: Flexible and deformable convolution for point clouds. In: Proceedings of the IEEE/CVF international confer ence on computer vision, pp 6411\u20136420 Wang Y, Sun Y, Liu Z, Sarma SE, Bronstein MM, Solomon JM (2019) Dynamic graph cnn for learning on point clouds. Acm Trans Graph (tog) 38(5):1\u201312 Wang Y, Shi T, Yun P, Tai L, Liu M (2018) Pointseg: real-time semantic segmentation based on 3d lidar point cloud. arXiv preprint arXiv: 1807. 06288 Wang W, Xie E, Li X, Fan D-P, Song K, Liang D, Lu T, Luo P, Shao L (2021) Pyramid vision transformer: a versatile backbone for dense prediction without convolutions. In: Proceedings of the IEEE/CVF international conference on computer vision, pp 568\u2013578 Wijaya KT, Paek D-H, Kong S-H (2022) Advanced feature learning on point clouds using multi-resolution features and learnable pooling. arXiv preprint arXiv: 2205. 09962 Wu W, Qi Z, Fuxin L (2019) Pointconv: deep convolutional networks on 3d point clouds. In: Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pp 9621\u20139630 Wu Z, Song S, Khosla A, Yu F, Zhang L, Tang X, Xiao J (2015) 3d shapenets: a deep representation for volumetric shapes. In: Proceedings of the IEEE conference on computer vision and pattern recognition, pp 1912\u20131920 Xiang T, Zhang C, Song Y, Yu J, Cai W (2021) Walk in the cloud: learning curves for point clouds shape analysis. In: Proceedings of the IEEE/CVF international conference on computer vision, pp 915\u2013924 Xu M, Ding R, Zhao H, Qi X (2021) Paconv: position adaptive convolution with dynamic kernel assembling on point clouds. In: Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pp 3173\u20133182 Xu C, Wu B, Wang Z, Zhan W, Vajda P, Keutzer K, Tomizuka M (2020) Squeezesegv3: Spatially-adaptive convolution for efficient point-cloud segmentation. In: Computer vision\u2013ECCV 2020: 16th European conference, Glasgow, UK, August 23\u201328, 2020, Proceedings, Part XXVIII 16, pp 1\u201319 . Springer Yan X, Zheng C, Li Z, Wang S, Cui S (2020) Pointasnl: robust point clouds processing using nonlocal neural networks with adaptive sampling. In: Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pp 5589\u20135598 Zhang R, Wang L, Wang Y, Gao P, Li H, Shi J (2023) Parameter is not all you need: starting from nonparametric networks for 3d point cloud analysis. arXiv preprint arXiv: 2303. 08134 Zhao Y, Bai L, Huang X (2021) Fidnet: Lidar point cloud semantic segmentation with fully interpolation decoding. In: 2021 IEEE/RSJ international conference on intelligent robots and systems (IROS), IEEE, pp 4453\u20134458 Zhao H, Jiang L, Jia J, Torr PH, Koltun V(2021) Point transformer. In: Proceedings of the IEEE/CVF inter national conference on computer vision, pp 16259\u201316268 Zhao H, Shi J, Qi X, Wang X, Jia J (2017) Pyramid scene parsing network. In: Proceedings of the IEEE conference on computer vision and pattern recognition, pp 2881\u20132890 Zhou H, Zhu X, Song X, Ma Y, Wang Z, Li H, Lin D (2020) Cylinder3d: an effective 3d framework for driving-scene lidar semantic segmentation. arXiv preprint arXiv: 2008. 01550 Publisher\u2019s Note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations."
      },
      "Downstream-Pretext Domain Knowledge Traceback for Active Learning": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2407.14720",
        "ref_texts": "[55] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "55"
        ]
      },
      "An Efficient Multi-Scale Attention Feature Fusion Network for 4k Video Frame Interpolation": {
        "authors": [
          "Xin Ning",
          "Yuhang Li",
          "Ziwei Feng",
          "Jinhua Liu",
          "Youdong Ding"
        ],
        "url": "https://www.mdpi.com/2079-9292/13/6/1037/pdf",
        "ref_texts": "24. Zhao, H.; Shi, J.; Qi, X.; Wang, X.; Jia, J. Pyramid scene parsing network. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Honolulu, HI, USA, 21\u201326 July 2017; pp. 2881\u20132890.",
        "ref_ids": [
          "24"
        ]
      },
      "Full-Scale Aggregated MobileUNet: An Improved U-Net Architecture for SAR Oil Spill Detection": {
        "authors": [
          "Ting Chen",
          "Lena Chang",
          "Hua Wang"
        ],
        "url": "https://www.mdpi.com/1424-8220/24/12/3724/pdf",
        "ref_texts": "19. Zhao, H.; Shi, J.; Qi, X.; Wang, X.; Jia, J. Pyramid Scene Parsing Network. In Proceedings of the 2017 IEEE Conference on Computer Vision and Pattern Recognition, Honolulu, HI, USA, 21\u201326 July 2017.",
        "ref_ids": [
          "19"
        ]
      },
      "NAS-ASDet: An adaptive design method for surface defect detection network using neural architecture search": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2311.10952",
        "ref_texts": "[19] H. Zhao, J. Shi, X. Qi, X. Wang, J. Jia, Pyramid scene parsing network, in: Proceedings of the IEEE conference on computer vision and pattern recognition, 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "19"
        ]
      },
      "A highly efficient tunnel lining crack detection model based on Mini-Unet": {
        "authors": [],
        "url": "https://www.nature.com/articles/s41598-024-79919-6.pdf",
        "ref_texts": ""
      },
      "Class-level multiple distributions representation are necessary for semantic segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2303.08029",
        "ref_texts": "[42] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "42"
        ]
      },
      "Semantic segmentation of microbial alterations based on SegFormer": {
        "authors": [],
        "url": "https://www.frontiersin.org/journals/plant-science/articles/10.3389/fpls.2024.1352935/pdf",
        "ref_texts": "204, 107553. doi: 10.1016/j.compag.2022.107553 Wu, J., Wen, C., Chen, H., Ma, Z., Zhang, T., Su, H., et al. (2022). DS-DETR: A model for tomato leaf disease segmen tation and damage evaluation. Agronomy 12. doi:10.3390/agronomy12092023 Xie, E., Wang, W., Yu, Z., Anandkumar, A., Alvarez, J. M., and Luo, P. (2021). SegFormer: Simple and ef ficient design for semantic segmentation with transformers. Adv. Neural Inf. Process Syst. 34, 12077 \u201312090. Yang, R., Guo, Y., Hu, Z., Gao, R., and Yang, H. (2023). Semantic segmentation of cucumber leaf disease spots based on ECA-SegFormer. Agriculture 13 (8), 1513. Yao, N., Ni, F., Wu, M., Wang, H., Li, G., and Sung, W. K. (2022). Deep learningbased segmentation of peach diseases using convolutional neural network. Front. Plant Sci.13, 876357. doi: 10.3389/fpls.2022.876357 Yin, C., Zeng, T., Zhang, H., Fu, W., Wang, L., and Yao, S. (2022). Maize small leaf spot classi fication based on improved deep convolutional neural networks with a multiscale attention mechanism. Agronomy 12, 906. Yong, L. Z., Khairunniza-Bejo, S., Jahari, M., and Muharam, F. M. (2023). Automatic disease detection of basal stem rot using deep learning and hyperspectral imaging.Agriculture 13, 69. doi: 10.3390/agriculture13010069 Zhang, X., Cen, C., Li, F., Liu, M., and Mu, W. (2023). CRFormer: Cross-Resolution Transformer for segmentation of grape leaf diseases with context mining. Expert Syst. Appl. 229, 120324. doi: 10.1016/j.eswa.2023.120324 Zhao, H., Shi, J., Qi, X., Wang, X., and Jia, J. (2017). \u201cPyramid scene parsing network \u201din Proceedings of the IEEE conference on computer vision and pattern recognition , 2881 \u20132890. Zhao, J., Fang, Y., Chu, G., Yan, H., Hu, L., and Huang, L. (2020). Identi fication of LeafScale Wheat Powdery Mildew (Blumeria graminis f. sp. Tritici) Combining HyperspectralImaging and an SVM Classi fier.Plants 9, 936. doi: 10.3390/plants9080936 Zhao, S., Liu, J., and Wu, S. (2022). Multiple disease detection method for greenhouse-cultivated strawberry based on multiscale feature fusion Faster R_CNN.Comput. Electron. Agric. 199, 107176. doi: 10.1016/j.compag.2022.107176 Zheng, S., Lu, J., Zhao, H., Zhu, X., Luo, Z., Wang, Y., et al. (2021). \u201cRethinking semantic segmentation from a sequence-to-sequence perspective with transformers, \u201din Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition,Nashville, TN, USA, 20 \u201325. (IEEE), 6881 \u20136890.Elmessery et al."
      },
      "AATCT-IDS: A benchmark Abdominal Adipose Tissue CT Image Dataset for image denoising, semantic segmentation, and radiomics evaluation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2308.08172",
        "ref_texts": "[42] H. Zhao, J. Shi, X. Qi, X. Wang, J. Jia, Pyramid scene parsing network, in: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "42"
        ]
      },
      "Lightweight Model Pre-Training Via Language Guided Knowledge Distillation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2406.11689",
        "ref_texts": "[58] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "58"
        ]
      },
      "Deep Learning-based Segmentation for Complex Scene Understanding": {
        "authors": [],
        "url": "https://era.library.ualberta.ca/items/c56b129a-bf03-4ccc-bc4d-07c385b0f77a/download/65ab9b4c-2978-4bf9-8467-0c8cbf8512d1",
        "ref_texts": "[20] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "20"
        ]
      },
      "Joint Learning of Blind Super-Resolution and Crack Segmentation for Realistic Degraded Images": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2302.12491",
        "ref_texts": "[50] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in CVPR , 2017.",
        "ref_ids": [
          "50"
        ]
      },
      "An estimation method for multidimensional urban street walkability based on panoramic semantic segmentation and domain adaptation": {
        "authors": [
          "Jiaxuan Li"
        ],
        "url": "http://www.sei.ynu.edu.cn/7jiaEAAIlun.pdf",
        "ref_texts": "1376\u20131386. Zhang, Yang, David, Philip, Foroosh, Hassan, Gong, Boqing, 2019. A curriculum domain adaptation approach to the semantic segmentation of urban scenes. IEEE Trans. Pattern Anal. Mach. Intell. 42 (8), 1823\u20131841. Zhang, Jiaming, Yang, Kailun, Shi, Hao, Rei\u00df, Simon, Peng, Kunyu, Ma, Chaoxiang, Fu, Haodong, Torr, Philip HS, Wang, Kaiwei, Stiefelhagen, Rainer, 2022. Behind every domain there is a shift: Adapting distortion-aware vision transformers for panoramic semantic segmentation. arXiv preprint arXiv:2207.11860. Zhao, Chenbo, Ogawa, Yoshiki, Chen, Shenglong, Oki, Takuya, Sekimoto, Yoshihide, 2023. Quantitative land price analysis via computer vision from street view images. Eng. Appl. Artif. Intell. 123, 106294. Zhao, Hengshuang, Shi, Jianping, Qi, Xiaojuan, Wang, Xiaogang, Jia, Jiaya, 2017. Pyramid scene parsing network. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. pp. 2881\u20132890. Zhou, Hao, He, Shenjing, Cai, Yuyang, Wang, Miao, Su, Shiliang, 2019. Social inequalities in neighborhood visual walkability: Using street view imagery and deep learning technologies to facilitate healthy city planning. Sustain. Cities Soc."
      },
      "LT-DeepLab: an improved DeepLabV3+ cross-scale segmentation algorithm for Zanthoxylum bungeanum Maxim leaf-trunk diseases in real-world environments": {
        "authors": [],
        "url": "https://www.frontiersin.org/journals/plant-science/articles/10.3389/fpls.2024.1423238/pdf",
        "ref_texts": "249, 123546. doi: 10.1016/j.eswa.2024.123546 Zhao, H., Shi, J., Qi, X., Wang, X., and Jia, J. (2017). \u201cPyramid scene parsing network, \u201din2017 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) , Piscataway, NJ: IEEE. Zhou, H., Peng, Y., Zhang, R., He, Y., Li, L., and Xiao, W. (2024). GS-deepLabV3+: A mountain tea disease segmentation network based on improved shuf fle attention and gated multidimensional feature extraction. Crop Prot. 183, 106762. doi: 10.1016/ j.cropro.2024.106762 Zhu, Y., Liu, S., Wu, X., Gao, L., and Xu, Y. (2024). Multi-class segmentation of navel orange surface defects based on improved deeplabv3+. J. Agric. Eng. 55, 263 \u2013275. doi: 10.4081/jae.2024.1564 Zhu, S., Ma, W., Lu, J., Ren, B., Wang, C., and Wang, J. (2023). A novel approach for apple leaf disease image segmentatio n in complex scenes based on two-stage DeepLabv3+ with adaptive loss. Comput. Electron. Agric. 204, 107539. doi: 10.1016/ j.compag.2022.107539Yang et al. 10.3389/fpls.2024.1423238 Frontiers in Plant Science frontiersin.org 17"
      },
      "An accurate semantic segmentation model for bean seedlings and weeds identification based on improved ERFnet": {
        "authors": [
          "Haozhang Gao"
        ],
        "url": "https://www.nature.com/articles/s41598-024-61981-9.pdf",
        "ref_texts": ""
      },
      "Transformers-based architectures for stroke segmentation: A review": {
        "authors": [
          "Yalda Zafari"
        ],
        "url": "https://link.springer.com/content/pdf/10.1007/s10462-024-10900-5.pdf",
        "ref_texts": "15(5):749\u2013753 Zhang L, Song R, Wang Y et\u00a0 al. (2020) Ischemic stroke lesion segmentation using multi-plane information fusion. IEEE Access 8:45715\u201345725 Zhang H, Chen H (2023) Efficient 3d transformer with cluster-based domain-adversarial learning for 3d medical image segmentation. In: 2023 IEEE 20th International Symposium on Biomedical Imaging (ISBI), IEEE, pp 1\u20135 Zhang Y, Liu H, Hu Q (2021) Transfuse: Fusing transformers and cnns for medical image segmentation. In: Medical Image Computing and Computer Assisted Intervention\u2013MICCAI 2021: 24th International Conference, Strasbourg, France, September 27\u2013October 1, 2021, Proceedings, Part I 24, Springer, pp 14\u201324 Zhang Y, Liu S, Li C, et\u00a0al. (2022) Application of deep learning method on ischemic stroke lesion segmentation. Journal of Shanghai Jiaotong University (Science) pp 1\u201313 Zhao H, Shi J, Qi X, et\u00a0al. (2017) Pyramid scene parsing network. In: Proceedings of the IEEE conference on computer vision and pattern recognition, pp 2881\u20132890 Zhou HY, Guo J, Zhang Y, et\u00a0al. (2021) nnformer: Interleaved transformer for volumetric segmentation. arXiv preprint arXiv: 2109. 03201 Zhou SK, Rueckert D, Fichtinger G (2019) Handbook of medical image computing and computer assisted inter vention. Academic Press Zhou Y, Huang W, Dong P et\u00a0al. (2019) D-unet: a dimension-fusion u shape network for chronic stroke lesion segmentation. IEEE/ACM Trans Comput Biol Bioinf 18(3):940\u2013950 Zhu X, Su W, Lu L, et\u00a0al. (2020) Deformable detr: Deformable transformers for end-to-end object detection. arXiv preprint arXiv: 2010. 04159"
      },
      "Prior-guided attention fusion transformer for multi-lesion segmentation of diabetic retinopathy": {
        "authors": [
          "Chenfangqian Xu"
        ],
        "url": "https://www.nature.com/articles/s41598-024-71650-6.pdf",
        "ref_texts": ""
      },
      "Transformers for Remote Sensing: A Systematic Review and Analysis": {
        "authors": [
          "Ruikun Wang",
          "Lei Ma",
          "Guangjun He",
          "Brian Alan",
          "Ziyun Yan",
          "Ming Chang",
          "Ying Liang"
        ],
        "url": "https://www.mdpi.com/1424-8220/24/11/3495/pdf",
        "ref_texts": "17. Zhao, H.; Shi, J.; Qi, X.; Wang, X.; Jia, J. Pyramid Scene Parsing Network. In Proceedings of the 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Honolulu, HI, USA, 21\u201326 July 2017; pp. 6230\u20136239.",
        "ref_ids": [
          "17"
        ]
      },
      "AMFNet: Attention-Guided Multi-Scale Fusion Network for Bi-Temporal Change Detection in Remote Sensing Images": {
        "authors": [
          "Zisen Zhan",
          "Hongjin Ren",
          "Min Xia",
          "Haifeng Lin",
          "Xiaoya Wang",
          "Xin Li"
        ],
        "url": "https://www.mdpi.com/2072-4292/16/10/1765/pdf",
        "ref_texts": "52. Zhao, H.; Shi, J.; Qi, X.; Wang, X.; Jia, J. Pyramid scene parsing network. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Honolulu, HI, USA, 21\u201326 June 2017; pp. 2881\u20132890. Remote Sens. 2024 ,16, 1765 21 of 21",
        "ref_ids": [
          "52"
        ]
      },
      "UP-CrackNet: Unsupervised Pixel-Wise Road Crack Detection via Adversarial Image Restoration": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2401.15647",
        "ref_texts": "[58] H. Zhao et al. , \u201cPyramid scene parsing network,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) . IEEE, 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "58"
        ]
      },
      "SERNet-Former: Semantic Segmentation by Efficient Residual Network with Attention-Boosting Gates and Attention-Fusion Networks": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2401.15741",
        "ref_texts": "[48] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In CVPR , pages 2881\u20132890, 2017. 7",
        "ref_ids": [
          "48"
        ]
      },
      "An improved semantic segmentation algorithm for high-resolution remote sensing images based on DeepLabv3+": {
        "authors": [
          "Yan Wang"
        ],
        "url": "https://www.nature.com/articles/s41598-024-60375-1.pdf",
        "ref_texts": ""
      },
      "Multi-Scale Fusion Siamese Network Based on Three-Branch Attention Mechanism for High-Resolution Remote Sensing Image Change Detection": {
        "authors": [
          "Yan Li",
          "Liguo Weng",
          "Min Xia",
          "Kai Hu",
          "Haifeng Lin"
        ],
        "url": "https://www.mdpi.com/2072-4292/16/10/1665/pdf",
        "ref_texts": "54. Zhao, H.; Shi, J.; Qi, X.; Wang, X.; Jia, J. Pyramid scene parsing network. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Honolulu, HI, USA, 21\u201326 July 2017; pp. 2881\u20132890.",
        "ref_ids": [
          "54"
        ]
      },
      "Spreading anomaly semantic segmentation and 3D reconstruction of binder jet additive manufacturing powder bed images": {
        "authors": [
          "Alexander Gourley"
        ],
        "url": "https://link.springer.com/content/pdf/10.1007/s00170-024-14311-2.pdf",
        "ref_texts": ""
      },
      "LSSF-Net: Lightweight segmentation with self-awareness, spatial attention, and focal modulation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2409.01572",
        "ref_texts": "[24] H. Zhao, J. Shi, X. Qi, X. Wang, J. Jia, Pyramid scene parsing network, in: Proceedings of the IEEE conference on computer vision and pattern recognition, 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "24"
        ]
      },
      "TinyWT: A Large-Scale Wind Turbine Dataset of Satellite Images for Tiny Object Detection": {
        "authors": [
          "Mingye Zhu",
          "Zhicheng Yang",
          "Hang Zhou",
          "Chen Du",
          "Andy Wong",
          "Yibing Wei",
          "Zhuo Deng",
          "Mei Han",
          "Hsin Lai"
        ],
        "url": "https://openaccess.thecvf.com/content/WACV2024W/CV4EO/papers/Zhu_TinyWT_A_Large-Scale_Wind_Turbine_Dataset_of_Satellite_Images_for_WACVW_2024_paper.pdf",
        "ref_texts": "[77] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017. 3, 7",
        "ref_ids": [
          "77"
        ]
      },
      "Deeppyramid+: medical image segmentation using pyramid view fusion and deformable pyramid reception": {
        "authors": [
          "Negin Ghamsarian"
        ],
        "url": "https://link.springer.com/content/pdf/10.1007/s11548-023-03046-2.pdf",
        "ref_texts": "17. Zhao H, Shi J, Qi X, Wang X, Jia J (2017) Pyramid scene parsing network. In: Proceedings of the IEEE conference on computervision and pattern recognition (CVPR)18. Chen L-C, Papandreou G, Kokkinos I, Murphy K, Yuille AL (2018) Deeplab: Semantic image segmentation with deep convolutionalnets, atrous convolution, and fully connected crfs. IEEE Trans Pat-tern Anal Mach Intell 40(4):834\u2013848",
        "ref_ids": [
          "17"
        ]
      },
      "Generating 10-Meter Resolution Land Use and Land Cover Products Using Historical Landsat Archive Based on Super Resolution Guided Semantic Segmentation \u2026": {
        "authors": [
          "Dawei Wen",
          "Shihao Zhu",
          "Yuan Tian",
          "Xuehua Guan",
          "Yang Lu"
        ],
        "url": "https://www.mdpi.com/2072-4292/16/12/2248/pdf",
        "ref_texts": "4.2. Comparison with Other Models In order to further evaluate the performance of the proposed method, we conducted a comparative analysis with DFSRSSN which is optimized by multi-task loss (DFSRSSN_MTL) and three state-of-the-art semantic segmentation methods. DFSRSSN_MTL has the same network with DFSRRSN but was optimized in a different way. SR and semantic segmentation (SM) modules were trained simultaneously to minimize the total sum of SR and SM loss. The three well-known semantic segmentation methods involve Multiattention Network (MANet) [47], Pyramid Scene Parsing Network (PSPNet) [48], and DeepLabV3+ [49]. MANet utilizes self-attention modules to aggregate relevant contextual features hierarchiRemote Sens. 2024 ,16, 2248 14 of 17 cally and a multi-scale strategy is designed to incorporate semantic information at different levels [47]. In PSPNet, the pyramid pooling module is designed to aggregate contextual information of different scales [50]. DeepLabV3+ employs dilated convolution to enlarge the receptive field of filters and introduces feature pyramid network to combine features at different spatial resolutions [51]. All these methods concentrate on extracting multi-scale information for better semantic segmentation performance. And they use bicubic Landsat images of 10 m as input. Overall performance in terms of OAand Kappa are in presented in Table 6. Bold values indicate the best accuracies, and the second-best ones are underlined. Our proposed model outperforms the three classics, fully segmentation methods that do not produce an SR image for dataset I. DFSRSSN_MTL has OAof 83.39% (the second best) and Kappa of 75.89% (the best). DFSRSSN achieved OAof 83.29% (the best) and Kappa of 75.92% (the best). While DFSRSSN_MTL is the best and DFSRSSN is the second best for dataset III (Kassel, Germany), PSPNet is the best for datasets II and IV . As for dataset V , MANet is the best, followed by DeepLabV3+ and DFSRSSN_MTL. Therefore, it is concluded that for overall performance our proposed method can achieve the best for data with similar distribution as training dataset and other more advanced semantic segmentation models have better transferability due to effective multi-scale feature extraction ability. The incorporation of our proposed architecture with these semantic segmentation models can be considered in further work. Table 6. Overall accuracy (OA) (%) and Kappa (%) of the proposed and compared methods. DatasetDFSRSSN DFSRSSN_MTL MANet PSPNet DeepLabV3+ OA Kappa OA Kappa OA Kappa OA Kappa OA Kappa I 83.29 75.92 83.39 75.89 81.71 73.18 79.95 70.93 81.16 72.59 II 68.17 56.08 68.62 56.03 68.87 55.93 69.57 56.69 66.34 53.35 III 73.71 60.02 73.94 60.19 71.11 54.90 72.84 57.82 67.57 50.12 IV 72.90 57.67 73.31 58.38 72.57 55.51 76.04 60.86 66.27 45.73 V 70.19 39.55 72.77 39.84 80.65 52.18 70.56 41.41 77.52 49.60 Furthermore, to evaluate the performance of different classes, we present F1 score values considering that P Aand UAare often contradictory and F1 score conveys the balance between P Aand UA. F1 score values of two major LULC types (tree cover and cropland), and built-up areas using different models are presented in Table 7. Compared with other LULC types, built-up areas have more abundant fine spatial details, i.e., scattered roads and isolated buildings, making it more imperative to use higher spatial resolution images to characterize its extent. Therefore, F1 score values for built-up can reveal whether spatial details are fully exploited and presented in semantic segmentation results. DFSRSSN and DFSRSSN_MTL outperformed other models in tree cover classification for dataset I, III, and IV . As for cropland classification, the best is DFSRSSN_MTL in datasets I and III, PSPNet in datasets II and IV , and MANet in dataset V . Our proposed method generally has much higher F1 score values for built-up area, for example 53.34% using DFSRSSN_MTL (the best) and 48.35% using DFSRSSN (the second best) vs. 41.75% using PSPNet (the third best). Table 7. F1 score values of the proposed and compared methods for tree cover, cropland, and built-up (%). DatasetDFSRSSN DFSRSSN_MTL MANet PSPNet DeepLabV3+",
        "ref_ids": [
          "47",
          "48",
          "49",
          "47",
          "50",
          "51"
        ]
      },
      "Exploiting Scale-Variant Attention for Segmenting Small Medical Objects": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2407.07720",
        "ref_texts": "[27] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "27"
        ]
      },
      "A Comparative Analysis of CNN-based Deep Learning Models for Landslide Detection": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2408.01692",
        "ref_texts": "[20] Zhao, H.; Shi, J.; Qi, X.; Wang, X.; Jia, J. Pyramid scene parsing network. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Honolulu, HI, USA, 21\u201316 July 2017; pp.",
        "ref_ids": [
          "20"
        ]
      },
      "Approaching expert-level accuracy for differentiating ACL tear types on MRI with deep learning": {
        "authors": [
          "Yang Xue"
        ],
        "url": "https://www.nature.com/articles/s41598-024-51666-8.pdf",
        "ref_texts": ""
      },
      "Infproto-Powered Adaptive Classifier and Agnostic Feature Learning for Single Domain Generalization in Medical Images": {
        "authors": [
          "Xiaoqing Guo"
        ],
        "url": "https://link.springer.com/content/pdf/10.1007/s11263-024-02158-9.pdf",
        "ref_texts": "(pp. 19988\u201319997). V\u00e1zquez, D., Bernal, J., S\u00e1nchez, F. J., et al. (2017). A benchmark for endoluminal scene segmentation of colonoscopy images. Journal of Healthcare Engineering, 2017 , 4037190. V olpi, R., Namkoong, H., Sener, O., et al. (2018). Generalizing to unseen domains via adversarial data augmentation. In: NeurIPS, pp 5339\u20135349. Wang, J., Sun, K., Cheng, T., Jiang, B., Deng, C., Zhao, Y ., Liu, D., Mu, Y ., Tan, M., & Wang, X. (2020). Deep high-resolution representa-tion learning for visual recognition. IEEE Transactions on Pattern Analysis and Machine Intelligence, 43 (10), 3349\u20133364. Wang, J., Jin, Y ., Wang, L., et al. (2021). Efficient global-local memory for real-time instrument segmentation of robotic surgical video. InMICCAI (pp. 341\u2013351). Wang, W., Yin, B., Yao, T., et al. (2021). Delving into data: Effectively substitute training for black-box attack. In Proceedings of the CVPR (pp. 4761\u20134770). Wang, Y ., Huang, G., Song, S., Pan, X., Xia, Y ., & Wu, C. (2021). Regularizing deep networks with semantic data augmentation. IEEE Transactions on Pattern Analysis and Machine Intelligence, 44 (7), 3733\u20133748. Xu, Q., Zhang, R., Zhang, Y ., et al. (2021). A fourier-based framework for domain generalization. In CVPR (pp. 14383\u201314392). Xu, W., Xian, Y ., Wang, J., et al. (2020). Attribute prototype network for zero-shot learning. In NeurIPS (pp. 21969\u201321980). Yang, B., Liu, C., Li, B., et al. (2020). Prototype mixture models for few-shot semantic segmentation. In ECCV .Zhang, L., Wang, X., Yang, D., et al. (2020). Generalizing deep learning for medical image segmentation to unseen domains via deepstacked transformation. IEEE Transactions on Medical Imaging, 39(7), 2531\u20132540. Zhang, R., Li, G., Li, Z., et al. (2020). Adaptive context selection for polyp segmentation. In MICCAI (pp. 253\u2013262). Zhang, Y ., David, P ., Foroosh, H., et al. (2019). A curriculum domain adaptation approach to the semantic segmentation of urban scenes.IEEE Transactions on Pattern Analysis and Machine Intelligence,42(8), 1823\u20131841. Zhao, H., Shi, J., Qi, X., et al. (2017). Pyramid scene parsing network. InCVPR (pp. 2881\u20132890). Zhao, L., Liu. T., Peng, X., et al. (2020). Maximum-entropy adversarial data augmentation for improved generalization and robustness. InNeurIPS . Zhao, L., Peng, X., Chen, Y ., et al. (2020). Knowledge as priors: Cross-modal knowledge generalization for datasets without supe-rior knowledge. In CVPR (pp. 6528\u20136537). Zhao, X., Zhang, L., & Lu, H. (2021). Automatic polyp segmentation via multi-scale subtraction network. In MICCAI (pp. 120\u2013130). Zhou, Z., Siddiquee, M. M. R., Tajbakhsh, N., et al. (2019). Unet++: Redesigning skip connections to exploit multiscale features in image segmentation. IEEE Transactions on Medical Imaging, 39(6), 1856\u20131867. Publisher\u2019s Note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations."
      },
      "Dual-Task Network for Terrace and Ridge Extraction: Automatic Terrace Extraction via Multi-Task Learning": {
        "authors": [
          "Jun Zhang",
          "Jun Zhang",
          "Xiao Huang",
          "Weixun Zhou",
          "Huyan Fu",
          "Yuyan Chen",
          "Zhenghao Zhan"
        ],
        "url": "https://www.mdpi.com/2072-4292/16/3/568/pdf",
        "ref_texts": "43. Zhao, H.; Shi, J.; Qi, X.; Wang, X.; Jia, J. Pyramid scene parsing network. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Honolulu, HI, USA, 21\u201326 July 2017; pp. 2881\u20132890.",
        "ref_ids": [
          "43"
        ]
      },
      "MFPANet: Multi-Scale Feature Perception and Aggregation Network for High-Resolution Snow Depth Estimation": {
        "authors": [
          "Liling Zhao",
          "Junyu Chen",
          "Muhammad Shahzad",
          "Min Xia",
          "Haifeng Lin"
        ],
        "url": "https://www.mdpi.com/2072-4292/16/12/2087/pdf",
        "ref_texts": "35. Zhao, H.; Shi, J.; Qi, X.; Wang, X.; Jia, J. Pyramid scene parsing network. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Honolulu, HI, USA, 21\u201326 July 2017; pp. 2881\u20132890.",
        "ref_ids": [
          "35"
        ]
      },
      "DALNet: A rail detection network based on dynamic anchor line": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2308.11381",
        "ref_texts": "[34] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "34"
        ]
      },
      "Boundary and Relation Distillation for Semantic Segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2401.13174",
        "ref_texts": "[93] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , pages 2881\u20132890, 2017. 1, 2, 5, 6, 7, 8",
        "ref_ids": [
          "93"
        ]
      },
      "ReCLIP++: Learn to Rectify the Bias of CLIP for Unsupervised Semantic Segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2408.06747",
        "ref_texts": "[10] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "10"
        ]
      },
      "Exploration of an Open Vocabulary Model on Semantic Segmentation for Street Scene Imagery": {
        "authors": [
          "Zichao Zeng",
          "Jan Boehm"
        ],
        "url": "https://www.mdpi.com/2220-9964/13/5/153/pdf",
        "ref_texts": "24. Zhao, H.; Shi, J.; Qi, X.; Wang, X.; Jia, J. Pyramid scene parsing network. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Honolulu, HI, USA, 21\u201326 July 2017; pp. 2881\u20132890.",
        "ref_ids": [
          "24"
        ]
      },
      "Knowledge Distillation Based on Fitting Ground-Truth Distribution of Images": {
        "authors": [
          "Jianze Li",
          "Zhenhua Tang",
          "Kai Chen",
          "Zhenlei Cui"
        ],
        "url": "https://www.mdpi.com/2076-3417/14/8/3284/pdf",
        "ref_texts": "8. Zhao, H.; Shi, J.; Qi, X.; Wang, X.; Jia, J. Pyramid scene parsing network. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Honolulu, HI, USA, 21\u201326 July 2017; pp. 2881\u20132890.",
        "ref_ids": [
          "8"
        ]
      },
      "Dynamic acoustic compensation and adaptive focal training for personalized speech enhancement": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2211.12097",
        "ref_texts": "[31] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In Proceedings of CVPR , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "31"
        ]
      },
      "Automating global landslide detection with heterogeneous ensemble deep-learning classification": {
        "authors": [
          "Dario Grana"
        ],
        "url": "https://arxiv.org/pdf/2310.05959",
        "ref_texts": " short author name: Preprint submitted to Elsevier 17 Yang, Z., Li, L., Xu, X., Kailkhura, B., Xie, T., Li, B., 2022. on the Certified Robustness for Ensemble Models and Beyond. I CLR 2022 10th International Conference on Learning Representations. Youssef, A.M., Pourghasemi, H.R., 2021. Landsl ide susceptibility mapping using machine learning algorithms and comparison of their performance at Abha Basin, Asir Region, Saudi Arabia. Geoscience Frontiers 12, 639 \u2013655. https://doi.org/10.1016/j.gsf.2020.05 .010 Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J., 2017. Pyramid scene parsing network. Proceedings 30th IEEE Conference on Computer Vision and Pattern Recognition, CVPR "
      },
      "STransU2Net: Transformer based hybrid model for building segmentation in detailed satellite imagery": {
        "authors": [
          "Guangjie Liu",
          "Kuo Diao",
          "Jinlong Zhu",
          "Qi Wang",
          "Meng Li"
        ],
        "url": "https://journals.plos.org/plosone/article/file?id=10.1371/journal.pone.0299732&type=printable",
        "ref_texts": "24. Zhao H,ShiJ,QiX,Wang X,JiaJ.Pyramid scene parsing network. In:Proceedings oftheIEEE conference oncomputer vision andpattern recogni tion;2017. p.2881\u20132 890.",
        "ref_ids": [
          "24"
        ]
      },
      "ABNet: An Aggregated Backbone Network Architecture for Fine Landcover Classification": {
        "authors": [
          "Bo Si",
          "Zhennan Wang",
          "Zhoulu Yu",
          "Ke Wang"
        ],
        "url": "https://www.mdpi.com/2072-4292/16/10/1725/pdf",
        "ref_texts": "36. Zhao, H.S.; Shi, J.P .; Qi, X.J.; Wang, X.G.; Jia, J.Y. Pyramid Scene Parsing Network. In Proceedings of the 30th IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), Honolulu, HI, USA, 21\u201326 July 2017; pp. 6230\u20136239.",
        "ref_ids": [
          "36"
        ]
      },
      "A segmentation network for farmland ridge based on encoder-decoder architecture in combined with strip pooling module and ASPP": {
        "authors": [
          "Qingqing Hong"
        ],
        "url": "https://www.frontiersin.org/articles/10.3389/fpls.2024.1328075/pdf",
        "ref_texts": "(Singapore: Institute of Electrical and Electronics Engineers Inc.). doi: 10.1109/ IC3I46837.2019.9055569 Punithavathi, R., Rani, A. D. C., Sughashini, K. R., Kurangi, C., Nirmala, M., Ahmed, H. F. T., et al. (2023). Computer vision and deep learning-enabled weed detectionmodel for precision agriculture. Comput. Syst. Sci. Eng. 44 (3), 2759 \u20132774. doi:10.32604/csse.2023.027647 Ren, C., Guo, Z., Ren, H., Jeong, D., Kim, D.-K., Zhang, S., et al. (2023). Prostate segmentation in MRI using transformer encoder and decoder framework. IEEE Access 1, 101630 \u2013101643. doi: 10.1109/access.2023.3313420 Shunying, W., Ya \u2019nan, Z., Xianzeng, Y., Li, F., Tianjun, W., and Jiancheng, L. (2023). BSNet: Boundary-semantic-fusion network for farmland parcel mapping in high-resolution satellite images. Comput. Electron. Agric. 206, 107683. doi: 10.1016/ j.compag.2023.107683 Sun, W., Sheng, W., Zhou, R., Zhu, Y., Chen, A., Zhao, S., et al. (2022). Deep edge enhancement-based semantic segmentation network for farmland segmentation with satellite imagery. Comput. Electron. Agric. 202, 107273. doi: 10.1016/ j.compag.2022.107273 Wang, Y., Gu, L., Jiang, T., and Gao, F. (2023). MDE-UNet: A multitask deformable UNet combined enhancement network for farmland boundary segmentation. IEEE Geosci. Remote Sens. Lett. 20, 1 \u20135. doi: 10.1109/LGRS.2023.3252048 Wang, J., Li, X., Wang, X., Zhou, S., and Luo, Y. (2023). Farmland quality assessment using deep fully convolutional neural networks. Environ. Monit. Assess. 195(1), 1239. doi:10.1007/s10661-022-10848-5 Wang, S., Su, D., Jiang, Y., Tan, Y., Qiao, Y., Yang, S., et al. (2023). Fusing vegetation index and ridge segmentation for robust vision based autonomous navigation of agricultural robots in vegetable farms. Comput. Electron. Agric. 213, 108235. doi:10.1016/j.compag.2023.108235 Xiao, G., Zhu, X., Hou, C., and Xia, X. (2019). Extraction and analysis of abandoned farmland: A case study of Qingyun and Wudi counties in Shandong Province. J. Geograph. Sci. 29, 581 \u2013597. doi: 10.1007/s11442-019-1616-z Xu, L., Ming, D., Zhou, W., Bao, H., Chen, Y., and Ling, X. (2019). Farmland extraction from high spatial resolution remote sensing images based on strati fied scale pre-estimation. Remote Sens. 11(2), 108. doi: 10.3390/rs11020108 Yang, M., Yu, K., Zhang, C., Li, Z., and Yang, K. (2018). \u201cDenseASPP for semantic segmentation in street scenes, \u201din2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition . (Salt Lake City, UT, USA: IEEE Computer Society), 3684 \u20133692. doi:10.1109/CVPR.2018.00388 Zhang, X., Wang, R., Liu, B., Wang, Y., Yang, L., Zhao, J., et al. (2023). Optimization of ridge \u2013furrow mulching ratio enhances precipitation collection before silking to improve maize yield in a semi \u2013arid region. Agric. Water Manage. 275, 108041. doi:10.1016/j.agwat.2022.108041 Zhang, X., Yang, Y., Li, Z., Ning, X., Qin, Y., and Cai, W. (2021). An improved encoder-decoder network based on strip pool method applied to segmentation offarmland vacancy field.Entropy 23(4), 435. doi: 10.3390/e23040435 Zhao, H., Shi, J., Qi, X., Wang, X., and Jia, J. (2017). \u201cPyramid scene parsing network, \u201dinProceedings 30th IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2017 . 6230 \u20136239 (Honolulu, HI, USA: Institute of Electrical and Electronics Engineers Inc.). doi: 10.1109/CVPR.2017.660 Zhou, Q., Qiang, Y., Mo, Y., Wu, X., and Latecki, L. J. (2022). \u201cBANet: boundaryassistant encoder-decoder network for semantic segmentation, \u201dinIEEE Transactions on Intelligent Transportation Systems (IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC), Vol. 23. 25259 \u201325270. doi: 10.1109/TITS.2022.3194213 Zou, K., Liao, Q., Zhang, F., Che, X., and Zhang, C. (2022). A segmentation network for smart weed management in wheat fields. Comput. Electron. Agric. 202, 107303. doi:10.1016/j.compag.2022.107303Hong et al. 10.3389/fpls.2024.1328075 Frontiers in Plant Science frontiersin.org 12"
      },
      "\u57fa\u4e8e\u6a21\u5f0f\u7ea6\u675f\u7684\u6cb9\u5c42\u5355\u5143\u667a\u80fd\u81ea\u52a8\u5bf9\u6bd4\u65b9\u6cd5": {
        "authors": [],
        "url": "https://www.cup.edu.cn/geosci/docs/2024-07/3be3769c4a7244e8b8421e72d81b2d06.pdf",
        "ref_texts": ""
      },
      "A comprehensive survey on pretrained foundation models: A history from bert to chatgpt": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2302.09419",
        "ref_texts": "[303] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in CVPR , 2017.",
        "ref_ids": [
          "303"
        ]
      },
      "Transformers in medical imaging: A survey": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2201.09873",
        "ref_texts": "[120] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of theIEEE conference oncomputer vision and pattern recognition , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "120"
        ]
      },
      "Open-vocabulary semantic segmentation with mask-adapted clip": {
        "authors": [
          "Feng Liang",
          "Bichen Wu",
          "Xiaoliang Dai",
          "Kunpeng Li",
          "Yinan Zhao",
          "Hang Zhang",
          "Peizhao Zhang",
          "Peter Vajda",
          "Diana Marculescu"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Liang_Open-Vocabulary_Semantic_Segmentation_With_Mask-Adapted_CLIP_CVPR_2023_paper.pdf",
        "ref_texts": "[41] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. InProceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017. 1",
        "ref_ids": [
          "41"
        ]
      },
      "PIDNet: A real-time semantic segmentation network inspired by PID controllers": {
        "authors": [
          "Jiacong Xu",
          "Zixiang Xiong",
          "Shankar P. Bhattacharyya"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Xu_PIDNet_A_Real-Time_Semantic_Segmentation_Network_Inspired_by_PID_Controllers_CVPR_2023_paper.pdf",
        "ref_texts": "[59] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017. 1, 2, 5, 8",
        "ref_ids": [
          "59"
        ]
      },
      "Revisiting weak-to-strong consistency in semi-supervised semantic segmentation": {
        "authors": [
          "Lihe Yang",
          "Lei Qi",
          "Litong Feng",
          "Wayne Zhang",
          "Yinghuan Shi"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2023/papers/Yang_Revisiting_Weak-to-Strong_Consistency_in_Semi-Supervised_Semantic_Segmentation_CVPR_2023_paper.pdf",
        "ref_texts": "[77] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017. 1",
        "ref_ids": [
          "77"
        ]
      },
      "Spherical transformer for lidar-based 3d recognition": {
        "authors": [
          "Xin Lai",
          "Yukang Chen",
          "Fanbin Lu",
          "Jianhui Liu",
          "Jiaya Jia"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2023/papers/Lai_Spherical_Transformer_for_LiDAR-Based_3D_Recognition_CVPR_2023_paper.pdf",
        "ref_texts": "[83] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017. 2",
        "ref_ids": [
          "83"
        ]
      },
      "Seggpt: Segmenting everything in context": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2304.03284",
        "ref_texts": "[54] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In IEEE Conf. Comput. Vis. Pattern Recog. , 2017. 2",
        "ref_ids": [
          "54"
        ]
      },
      "Vitaev2: Vision transformer advanced by exploring inductive bias for image recognition and beyond": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2202.10108",
        "ref_texts": "(2021) Multi-scale vision longformer: A new vision transformer for high-resolution image encoding. In: Proceedings of the IEEE/CVF International Conference on Computer Vision, pp 2998\u20133008 Zhang Q, Xu Y, Zhang J, Tao D (2022) Vsa: Learning variedsize window attention in vision transformers. In: Proceedings of the European conference on computer vision Zhao H, Shi J, Qi X, Wang X, Jia J (2017) Pyramid scene parsing network. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp 2881\u20132890 Zheng S, Lu J, Zhao H, Zhu X, Luo Z, Wang Y, Fu Y, Feng J, Xiang T, Torr PH, et al (2021) Rethinking semantic 22 Qiming Zhang, et al. segmentation from a sequence-to-sequence perspective with transformers. In: Proceedings of the IEEE/CVF Conference onComputerVisionandPatternRecognition,pp6881\u20136890 Zhou B, Zhao H, Puig X, Fidler S, Barriuso A, Torralba A"
      },
      "Multi-interactive feature learning and a full-time multi-modality benchmark for image fusion and segmentation": {
        "authors": [
          "Jinyuan Liu",
          "Zhu Liu",
          "Guanyao Wu",
          "Long Ma",
          "Risheng Liu",
          "Wei Zhong",
          "Zhongxuan Luo",
          "Xin Fan"
        ],
        "url": "https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Multi-interactive_Feature_Learning_and_a_Full-time_Multi-modality_Benchmark_for_Image_ICCV_2023_paper.pdf",
        "ref_texts": "[1] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In IEEE/CVF CVPR , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "1"
        ]
      },
      "Sam-adapter: Adapting segment anything in underperformed scenes": {
        "authors": [
          "Tianrun Chen",
          "Lanyun Zhu",
          "Chaotao Deng",
          "Runlong Cao",
          "Yan Wang",
          "Shangzhan Zhang",
          "Zejian Li",
          "Lingyun Sun",
          "Ying Zang",
          "Papa Mao"
        ],
        "url": "https://openaccess.thecvf.com/content/ICCV2023W/VCL/papers/Chen_SAM-Adapter_Adapting_Segment_Anything_in_Underperformed_Scenes_ICCVW_2023_paper.pdf",
        "ref_texts": "[52] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "52"
        ]
      },
      "Hiformer: Hierarchical multi-scale representations using transformers for medical image segmentation": {
        "authors": [
          "Moein Heidari",
          "Amirhossein Kazerouni",
          "Milad Soltany",
          "Reza Azad",
          "Ehsan Khodapanah",
          "Julien Cohen",
          "Dorit Merhof"
        ],
        "url": "https://openaccess.thecvf.com/content/WACV2023/papers/Heidari_HiFormer_Hierarchical_Multi-Scale_Representations_Using_Transformers_for_Medical_Image_Segmentation_WACV_2023_paper.pdf",
        "ref_texts": "[56] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "56"
        ]
      },
      "Segclip: Patch aggregation with learnable centers for open-vocabulary semantic segmentation": {
        "authors": [],
        "url": "https://proceedings.mlr.press/v202/luo23a/luo23a.pdf",
        "ref_texts": "18144, 2022a. Xu, M., Zhang, Z., Wei, F., Lin, Y ., Cao, Y ., Hu, H., and Bai, X. A simple baseline for open vocabulary semantic segmentation with pre-trained vision-language model. ECCV , 2022b. Yao, L., Huang, R., Hou, L., Lu, G., Niu, M., Xu, H., Liang, X., Li, Z., Jiang, X., and Xu, C. FILIP: fine-grained interactive language-image pre-training. In ICLR , 2022. Zabari, N. and Hoshen, Y . Semantic segmentation inthe-wild without seeing any segmentation examples. arXiv:2112.03185 , 2021. Zeng, Y ., Zhang, X., and Li, H. Multi-grained vision language pre-training: Aligning texts with visual concepts. InICML , volume 162, pp. 25994\u201326009, 2022. Zhao, H., Shi, J., Qi, X., Wang, X., and Jia, J. Pyramid scene parsing network. In CVPR , pp. 6230\u20136239, 2017. Zheng, S., Lu, J., Zhao, H., Zhu, X., Luo, Z., Wang, Y ., Fu, Y ., Feng, J., Xiang, T., Torr, P. H., and Zhang, L. Rethinking semantic segmentation from a sequence-tosequence perspective with transformers. In CVPR , 2021. Zhong, Y ., Yang, J., Zhang, P., Li, C., Codella, N., Li, L. H., Zhou, L., Dai, X., Yuan, L., Li, Y ., and Gao, J. Regionclip: Region-based language-image pretraining. In CVPR , pp."
      },
      "Hierarchical dense correlation distillation for few-shot segmentation": {
        "authors": [
          "Bohao Peng",
          "Zhuotao Tian",
          "Xiaoyang Wu",
          "Chengyao Wang",
          "Shu Liu",
          "Jingyong Su",
          "Jiaya Jia"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2023/papers/Peng_Hierarchical_Dense_Correlation_Distillation_for_Few-Shot_Segmentation_CVPR_2023_paper.pdf",
        "ref_texts": "[52] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017. 1, 6",
        "ref_ids": [
          "52"
        ]
      },
      "Efficientvit: Lightweight multi-scale attention for high-resolution dense prediction": {
        "authors": [
          "Han Cai",
          "Junyan Li",
          "Muyan Hu",
          "Chuang Gan",
          "Song Han"
        ],
        "url": "https://openaccess.thecvf.com/content/ICCV2023/papers/Cai_EfficientViT_Lightweight_Multi-Scale_Attention_for_High-Resolution_Dense_Prediction_ICCV_2023_paper.pdf",
        "ref_texts": "[58] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017. 1, 7, 9",
        "ref_ids": [
          "58"
        ]
      },
      "SAM Fails to Segment Anything?--SAM-Adapter: Adapting SAM in Underperformed Scenes: Camouflage, Shadow, Medical Image Segmentation, and More": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2304.09148",
        "ref_texts": "[22] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "22"
        ]
      },
      "Techniques and challenges of image segmentation: A review": {
        "authors": [
          "Ying Yu",
          "Chunping Wang",
          "Qiang Fu",
          "Renke Kou",
          "Fuyu Huang",
          "Boxiong Yang",
          "Tingting Yang",
          "Mingliang Gao"
        ],
        "url": "https://www.mdpi.com/2079-9292/12/5/1199/pdf",
        "ref_texts": "72. Zhao, H.S.; Shi, J.P .; Qi, X.J.; Jia, J.Y. Pyramid Scene Parsing Network. arXiv 2017 , arXiv:1612.01105v2. [CrossRef]",
        "ref_ids": [
          "72"
        ]
      },
      "Depthformer: Exploiting long-range correlation and local information for accurate monocular depth estimation": {
        "authors": [],
        "url": "https://link.springer.com/content/pdf/10.1007/s11633-023-1458-0.pdf",
        "ref_texts": "\u00a0H.\u00a0S.\u00a0Zhao,\u00a0 J.\u00a0P.\u00a0Shi,\u00a0X.\u00a0J.\u00a0Qi,\u00a0X.\u00a0G.\u00a0Wang,\u00a0 J.\u00a0Y.\u00a0Jia.\u00a0Pyramid\u00a0 scene\u00a0 parsing\u00a0 network.\u00a0 In\u00a0Proceedings of IEEE Conference on Computer Vision and Pattern Recognition , IEEE,\u00a0 Honolulu,\u00a0 USA,\u00a0 pp.\u00a06230\u20136239,\u00a0 2017.\u00a0 DOI:\u00a0 10.1109/ CVPR.2017.660.[9]",
        "ref_ids": [
          "9"
        ]
      },
      "Ddp: Diffusion model for dense visual prediction": {
        "authors": [
          "Yuanfeng Ji",
          "Zhe Chen",
          "Enze Xie",
          "Lanqing Hong",
          "Xihui Liu",
          "Zhaoqiang Liu",
          "Tong Lu",
          "Zhenguo Li",
          "Ping Luo"
        ],
        "url": "http://openaccess.thecvf.com/content/ICCV2023/papers/Ji_DDP_Diffusion_Model_for_Dense_Visual_Prediction_ICCV_2023_paper.pdf",
        "ref_texts": "[88] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , pages 2881\u20132890, 2017. 1",
        "ref_ids": [
          "88"
        ]
      },
      "Sepico: Semantic-guided pixel contrast for domain adaptive semantic segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2204.08808",
        "ref_texts": "[45] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in CVPR , 2017, pp. 6230\u20136239.",
        "ref_ids": [
          "45"
        ]
      },
      "CMX: Cross-modal fusion for RGB-X semantic segmentation with transformers": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2203.04838",
        "ref_texts": "[6] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in CVPR , 2017.",
        "ref_ids": [
          "6"
        ]
      },
      "Normalization techniques in training dnns: Methodology, analysis and application": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2009.12836",
        "ref_texts": "[132] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in CVPR , 2017.",
        "ref_ids": [
          "132"
        ]
      },
      "Delivering arbitrary-modal semantic segmentation": {
        "authors": [
          "Jiaming Zhang",
          "Ruiping Liu",
          "Hao Shi",
          "Kailun Yang",
          "Simon Reiss",
          "Kunyu Peng",
          "Haodong Fu",
          "Kaiwei Wang",
          "Rainer Stiefelhagen"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Zhang_Delivering_Arbitrary-Modal_Semantic_Segmentation_CVPR_2023_paper.pdf",
        "ref_texts": "[93] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017. 2,3,6",
        "ref_ids": [
          "93"
        ]
      },
      "Open vocabulary semantic segmentation with patch aligned contrastive learning": {
        "authors": [
          "Jishnu Mukhoti",
          "Yu Lin",
          "Omid Poursaeed",
          "Rui Wang",
          "Ashish Shah",
          "Philip H",
          "Nam Lim"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2023/papers/Mukhoti_Open_Vocabulary_Semantic_Segmentation_With_Patch_Aligned_Contrastive_Learning_CVPR_2023_paper.pdf",
        "ref_texts": "[62] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017. 2",
        "ref_ids": [
          "62"
        ]
      },
      "Nerflets: Local radiance fields for efficient structure-aware 3d scene representation from 2d supervision": {
        "authors": [
          "Xiaoshuai Zhang",
          "Abhijit Kundu",
          "Thomas Funkhouser",
          "Leonidas Guibas",
          "Hao Su",
          "Kyle Genova"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2023/papers/Zhang_Nerflets_Local_Radiance_Fields_for_Efficient_Structure-Aware_3D_Scene_Representation_CVPR_2023_paper.pdf",
        "ref_texts": "[58] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR, 2017. 2,6,7",
        "ref_ids": [
          "58"
        ]
      },
      "Multi-level logit distillation": {
        "authors": [
          "Ying Jin",
          "Jiaqi Wang",
          "Dahua Lin"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Jin_Multi-Level_Logit_Distillation_CVPR_2023_paper.pdf",
        "ref_texts": "[37] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In IEEE Conference on Computer Vision and Pattern Recognition, 2017. 1",
        "ref_ids": [
          "37"
        ]
      },
      "Bevsegformer: Bird's eye view semantic segmentation from arbitrary camera rigs": {
        "authors": [
          "Lang Peng",
          "Zhirong Chen",
          "Zhangjie Fu",
          "Pengpeng Liang",
          "Erkang Cheng"
        ],
        "url": "https://openaccess.thecvf.com/content/WACV2023/papers/Peng_BEVSegFormer_Birds_Eye_View_Semantic_Segmentation_From_Arbitrary_Camera_Rigs_WACV_2023_paper.pdf",
        "ref_texts": "[34] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "34"
        ]
      },
      "Mseg3d: Multi-modal 3d semantic segmentation for autonomous driving": {
        "authors": [
          "Jiale Li",
          "Hang Dai",
          "Hao Han",
          "Yong Ding"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2023/papers/Li_MSeg3D_Multi-Modal_3D_Semantic_Segmentation_for_Autonomous_Driving_CVPR_2023_paper.pdf",
        "ref_texts": "[63] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , pages 6230\u20136239, 2017. 1",
        "ref_ids": [
          "63"
        ]
      },
      "Levit-unet: Make faster encoders with transformer for medical image segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2107.08623",
        "ref_texts": "[9]H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2017, pp. 6230\u20136239.",
        "ref_ids": [
          "9"
        ]
      },
      "Semask: Semantically masked transformers for semantic segmentation": {
        "authors": [
          "Jitesh Jain",
          "Anukriti Singh",
          "Nikita Orlov",
          "Zilong Huang",
          "Jiachen Li",
          "Steven Walton",
          "Humphrey Shi"
        ],
        "url": "https://openaccess.thecvf.com/content/ICCV2023W/NIVT/papers/Jain_SeMask_Semantically_Masked_Transformers_for_Semantic_Segmentation_ICCVW_2023_paper.pdf",
        "ref_texts": "[51] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017. 2,7",
        "ref_ids": [
          "51"
        ]
      },
      "Tube-Link: A flexible cross tube framework for universal video segmentation": {
        "authors": [
          "Xiangtai Li",
          "Haobo Yuan",
          "Wenwei Zhang",
          "Guangliang Cheng",
          "Jiangmiao Pang",
          "Chen Change"
        ],
        "url": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Tube-Link_A_Flexible_Cross_Tube_Framework_for_Universal_Video_Segmentation_ICCV_2023_paper.pdf",
        "ref_texts": "[65] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017. 6, 7",
        "ref_ids": [
          "65"
        ]
      },
      "Understanding imbalanced semantic segmentation through neural collapse": {
        "authors": [
          "Zhisheng Zhong",
          "Jiequan Cui",
          "Yibo Yang",
          "Xiaoyang Wu",
          "Xiaojuan Qi",
          "Xiangyu Zhang",
          "Jiaya Jia"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2023/papers/Zhong_Understanding_Imbalanced_Semantic_Segmentation_Through_Neural_Collapse_CVPR_2023_paper.pdf",
        "ref_texts": "[75] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017.",
        "ref_ids": [
          "75"
        ]
      },
      "Unsupervised domain adaptation of object detectors: A survey": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2105.13502",
        "ref_texts": "[13] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "13"
        ]
      },
      "Learning mask-aware clip representations for zero-shot segmentation": {
        "authors": [],
        "url": "https://proceedings.neurips.cc/paper_files/paper/2023/file/6ffe484a646db13891bb6435ca39d667-Paper-Conference.pdf"
      },
      "Automated knowledge distillation via monte carlo tree search": {
        "authors": [
          "Lujun Li",
          "Peijie Dong",
          "Zimian Wei",
          "Ya Yang"
        ],
        "url": "http://openaccess.thecvf.com/content/ICCV2023/papers/Li_Automated_Knowledge_Distillation_via_Monte_Carlo_Tree_Search_ICCV_2023_paper.pdf",
        "ref_texts": "[84] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "84"
        ]
      },
      "Xnet: Wavelet-based low and high frequency fusion networks for fully-and semi-supervised semantic segmentation of biomedical images": {
        "authors": [
          "Yanfeng Zhou",
          "Jiaxing Huang",
          "Chenlong Wang",
          "Le Song",
          "Ge Yang"
        ],
        "url": "http://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_XNet_Wavelet-Based_Low_and_High_Frequency_Fusion_Networks_for_Fully-_ICCV_2023_paper.pdf",
        "ref_texts": "[65] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "65"
        ]
      },
      "Deep fusion transformer network with weighted vector-wise keypoints voting for robust 6d object pose estimation": {
        "authors": [
          "Jun Zhou",
          "Kai Chen",
          "Linlin Xu",
          "Qi Dou",
          "Jing Qin"
        ],
        "url": "http://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_Deep_Fusion_Transformer_Network_with_Weighted_Vector-Wise_Keypoints_Voting_for_ICCV_2023_paper.pdf",
        "ref_texts": "[65] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017. 6",
        "ref_ids": [
          "65"
        ]
      },
      "A survey on label-efficient deep image segmentation: Bridging the gap between weak supervision and dense prediction": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2207.01223",
        "ref_texts": "[13] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in CVPR , 2017.",
        "ref_ids": [
          "13"
        ]
      },
      "Exploring open-vocabulary semantic segmentation from clip vision encoder distillation only": {
        "authors": [
          "Jun Chen",
          "Deyao Zhu",
          "Guocheng Qian",
          "Bernard Ghanem",
          "Zhicheng Yan",
          "Chenchen Zhu",
          "Fanyi Xiao",
          "Sean Chang",
          "Mohamed Elhoseiny"
        ],
        "url": "http://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Exploring_Open-Vocabulary_Semantic_Segmentation_from_CLIP_Vision_Encoder_Distillation_Only_ICCV_2023_paper.pdf",
        "ref_texts": "[55] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017. 1, 2",
        "ref_ids": [
          "55"
        ]
      },
      "Seggpt: Towards segmenting everything in context": {
        "authors": [
          "Xinlong Wang",
          "Xiaosong Zhang",
          "Yue Cao",
          "Wen Wang",
          "Chunhua Shen",
          "Tiejun Huang"
        ],
        "url": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_SegGPT_Towards_Segmenting_Everything_in_Context_ICCV_2023_paper.pdf",
        "ref_texts": "[58] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In IEEE Conf. Comput. Vis. Pattern Recog. , 2017. 2",
        "ref_ids": [
          "58"
        ]
      },
      "Generative semantic segmentation": {
        "authors": [
          "Jiaqi Chen",
          "Jiachen Lu",
          "Xiatian Zhu",
          "Li Zhang"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2023/papers/Chen_Generative_Semantic_Segmentation_CVPR_2023_paper.pdf",
        "ref_texts": "[55] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017. 2, 6",
        "ref_ids": [
          "55"
        ]
      },
      "Unmasking anomalies in road-scene segmentation": {
        "authors": [
          "Shyam Nandan",
          "Fabio Cermelli",
          "Dario Fontanel",
          "Carlo Masone",
          "Barbara Caputo"
        ],
        "url": "http://openaccess.thecvf.com/content/ICCV2023/papers/Nandan_Unmasking_Anomalies_in_Road-Scene_Segmentation_ICCV_2023_paper.pdf",
        "ref_texts": "[52] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017. 2",
        "ref_ids": [
          "52"
        ]
      },
      "Large scale visual food recognition": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2103.16107",
        "ref_texts": "[103] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in CVPR , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "103"
        ]
      },
      "Fastinst: A simple query-based model for real-time instance segmentation": {
        "authors": [
          "Junjie He",
          "Pengyu Li",
          "Yifeng Geng",
          "Xuansong Xie"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2023/papers/He_FastInst_A_Simple_Query-Based_Model_for_Real-Time_Instance_Segmentation_CVPR_2023_paper.pdf",
        "ref_texts": "[48] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017. 1, 3",
        "ref_ids": [
          "48"
        ]
      },
      "Fedseg: Class-heterogeneous federated learning for semantic segmentation": {
        "authors": [
          "Jiaxu Miao",
          "Zongxin Yang",
          "Leilei Fan",
          "Yi Yang"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Miao_FedSeg_Class-Heterogeneous_Federated_Learning_for_Semantic_Segmentation_CVPR_2023_paper.pdf",
        "ref_texts": "[62] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017. 3",
        "ref_ids": [
          "62"
        ]
      },
      "Continual semantic segmentation with automatic memory sample selection": {
        "authors": [
          "Lanyun Zhu",
          "Tianrun Chen",
          "Jianxiong Yin",
          "Simon See",
          "Jun Liu"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2023/papers/Zhu_Continual_Semantic_Segmentation_With_Automatic_Memory_Sample_Selection_CVPR_2023_paper.pdf",
        "ref_texts": "[53] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017. 2",
        "ref_ids": [
          "53"
        ]
      },
      "Satlaspretrain: A large-scale dataset for remote sensing image understanding": {
        "authors": [
          "Favyen Bastani",
          "Piper Wolters",
          "Ritwik Gupta",
          "Joe Ferdinando",
          "Aniruddha Kembhavi"
        ],
        "url": "http://openaccess.thecvf.com/content/ICCV2023/papers/Bastani_SatlasPretrain_A_Large-Scale_Dataset_for_Remote_Sensing_Image_Understanding_ICCV_2023_paper.pdf",
        "ref_texts": "[59] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid Scene Parsing Network. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) , pages 6230\u20136239, 2017.",
        "ref_ids": [
          "59"
        ]
      },
      "D-former: A u-shaped dilated transformer for 3d medical image segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2201.00462",
        "ref_texts": "[7] Zhao, H., Shi, J., Qi, X., et al. : Pyramid scene parsing network. In: CVPR",
        "ref_ids": [
          "7"
        ]
      },
      "Conflict-based cross-view consistency for semi-supervised semantic segmentation": {
        "authors": [
          "Zicheng Wang",
          "Zhen Zhao",
          "Xiaoxia Xing",
          "Dong Xu",
          "Xiangyu Kong",
          "Luping Zhou"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2023/papers/Wang_Conflict-Based_Cross-View_Consistency_for_Semi-Supervised_Semantic_Segmentation_CVPR_2023_paper.pdf",
        "ref_texts": "[52] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017. 2",
        "ref_ids": [
          "52"
        ]
      },
      "A survey on deep learning for skin lesion segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2206.00356",
        "ref_texts": "2021-2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), IEEE. pp. 1135\u20131139. Xu, R., Wang, C., Xu, S., Meng, W., Zhang, X., 2021. DC-Net: Dual context network for 2D medical image segmentation, in: International Conference on Medical Image Computing and Computer-Assisted Intervention, Springer. pp. 503\u2013513. Xue, Y ., Xu, T., Huang, X., 2018. Adversarial learning with multi-scale loss for skin lesion segmentation, in: 2018 IEEE 15th International Symposium on Biomedical Imaging (ISBI 2018), IEEE. pp. 859\u2013863. Yan, Y ., Kawahara, J., Hamarneh, G., 2019. Melanoma recognition via visual attention, in: International Conference on Information Processing in Medical Imaging, Springer. pp. 793\u2013804. Yang, C.H., Ren, J.H., Huang, H.C., Chuang, L.Y ., Chang, P.Y ., 2021. Deep hybrid convolutional neural network for segmentation of melanoma skin lesion. Computational Intelligence and Neuroscience 2021. Yang, X., Li, H., Wang, L., Yeo, S.Y ., Su, Y ., Zeng, Z., 2018. Skin lesion analysis by multi-target deep neural networks, in: 2018 40th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC), IEEE. pp. 1263\u20131266. Yerushalmy, J., 1947. Statistical problems in assessing methods of medical diagnosis, with special reference to X-ray techniques. Public Health Reports (1896-1970) 62, 1432\u20131449. Yi, X., Walia, E., Babyn, P., 2019. Generative Adversarial Network in Medical Imaging: A Review. Medical Image Analysis 58, 101552. Yu, B., Yu, L., Tian, S., Wu, W., Zhang, D., Kang, X., 2022. mCA-Net: modified comprehensive attention convolutional neural network for skin lesion segmentation. Computer Methods in Biomechanics and Biomedical Engineering: Imaging & Visualization 10, 85\u201395. Yu, F., Koltun, V ., 2016. Multi-scale context aggregation by dilated convolutions. international conference on learning representations . Yu, L., Chen, H., Dou, Q., Qin, J., Heng, P.A., 2017a. Automated melanoma recognition in dermoscopy images via very deep residual networks. IEEE transactions on medical imaging 36, 994\u20131004. Yu, Y ., Gong, Z., Zhong, P., Shan, J., 2017b. Unsupervised representation learning with deep convolutional neural network for remote sensing images, in: International Conference on Image and Graphics, pp. 97\u2013108. Yuan, Y ., Chao, M., Lo, Y .C., 2017. Automatic skin lesion segmentation using deep fully convolutional networks with jaccard distance. IEEE transactions on medical imaging 36, 1876\u20131886. Yuan, Y ., Lo, Y .C., 2019. Improving Dermoscopic Image Segmentation with Enhanced Convolutional-Deconvolutional Networks. IEEE Journal of Biomedical and Health Informatics 23, 519\u2013526. Zafar, K., Gilani, S.O., Waris, A., Ahmed, A., Jamil, M., Khan, M.N., Sohail Kashif, A., 2020. Skin lesion segmentation from dermoscopic images using convolutional neural network. Sensors 20, 1601. Zeng, G., Zheng, G., 2018. Multi-scale fully convolutional densenets for automated skin lesion segmentation in dermoscopy images, in: International Conference Image Analysis and Recognition, Springer. pp. 513\u2013521. Zhang, G., Shen, X., Chen, S., Liang, L., Luo, Y ., Yu, J., Lu, J., 2019a. DSM: A deep supervised multi-scale network learning for skin cancer segmentation. IEEE Access 7, 140936\u2013140945. Zhang, H., Fritts, J.E., Goldman, S.A., 2008. Image Segmentation Evaluation: A Survey of Unsupervised Methods. Computer Vision and Image Understanding 110, 260\u2013280. Zhang, J., Petitjean, C., Ainouz, S., 2020a. Kappa loss for skin lesion segmentation in fully convolutional network, in: 2020 IEEE 17th International Symposium on Biomedical Imaging (ISBI), IEEE. pp. 2001\u20132004. Zhang, L., Tanno, R., Bronik, K., Jin, C., Nachev, P., Barkhof, F., Ciccarelli, O., Alexander, D.C., 2020b. Learning to segment when experts disagree, in: International Conference on Medical Image Computing and Computer-Assisted Intervention, Springer. pp. 179\u2013190. Zhang, L., Yang, G., Ye, X., 2019b. Automatic skin lesion segmentation by coupling deep fully convolutional networks and shallow network with textons. Journal of Medical Imaging 6, 024001. Zhang, R., Liu, S., Yu, Y ., Li, G., 2021a. Self-supervised correction learning for semi-supervised biomedical image segmentation, in: International Conference on Medical Image Computing and Computer-Assisted Intervention, Springer. pp. 134\u2013144. Zhang, X., Zhou, X., Lin, M., Sun, J., 2018. Shu ffleNet: An Extremely E fficient Convolutional Neural Network for Mobile Devices, in: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 6848\u20136856. Zhang, Y ., Chen, Z., Yu, H., Yao, X., Li, H., 2022a. Feature fusion for segmentation and classification of skin lesions, in: 2022 IEEE 19th International Symposium on Biomedical Imaging (ISBI), IEEE. pp. 1\u20135. Zhang, Y ., Liu, H., Hu, Q., 2021b. TransFuse: Fusing Transformers and CNNs for medical image segmentation, in: International Conference on Medical Image Computing and Computer-Assisted Intervention, Springer. pp. 14\u201324. Zhang, Y ., Yang, Q., 2022. A survey on multi-task learning. IEEE Transactions on Knowledge and Data Engineering . Zhang, Z., Tian, C., Gao, X., Wang, C., Feng, X., Bai, H.X., Jiao, Z., 2022b. Dynamic prototypical feature representation learning framework for semi-supervised skin lesion segmentation. Neurocomputing 507, 369\u2013382. Zhao, C., Shuai, R., Ma, L., Liu, W., Wu, M., 2021. Segmentation of dermoscopy images based on deformable 3D convolution and ResU-NeXt ++. Medical & Biological Engineering & Computing 59, 1815\u20131832. Zhao, H., Jia, J., Koltun, V ., 2020. Exploring self-attention for image recognition, in: Proceedings of the IEEE /CVF Conference on Computer 54 Vision and Pattern Recognition, pp. 10076\u201310085. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J., 2017. Pyramid Scene Parsing Network, in: Proceedings of the 2017 IEEE Conference on Computer Vision and Pattern Recognition, pp. 2881\u20132890. Zhao, M., Kawahara, J., Abhishek, K., Shamanian, S., Hamarneh, G., 2022a. Skin3d: Detection and longitudinal tracking of pigmented skin lesions in 3D total-body textured meshes. Medical Image Analysis 77, 102329. Zhao, Z., Lu, W., Zeng, Z., Xu, K., Veeravalli, B., Guan, C., 2022b. Self-supervised assisted active learning for skin lesion segmentation, in: 2022 44th Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC), IEEE. pp. 5043\u20135046. URL: https: //doi.org /10.1109 /embc48229.2022.9871734, doi: 10.1109/embc48229.2022.9871734 . Zheng, S., Lu, J., Zhao, H., Zhu, X., Luo, Z., Wang, Y ., Fu, Y ., Feng, J., Xiang, T., Torr, P.H., et al., 2021. Rethinking semantic segmentation from a sequence-to-sequence perspective with transformers, in: Proceedings of the IEEE /CVF Conference on Computer Vision and Pattern Recognition, pp. 6881\u20136890. Zhou, B., Khosla, A., Lapedriza, A., Oliva, A., Torralba, A., 2016. Learning deep features for discriminative localization, in: Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 2921\u20132929. Zhu, L., Feng, S., Zhu, W., Chen, X., 2020. ASNet: An adaptive scale network for skin lesion segmentation in dermoscopy images, in: Medical Imaging 2020: Biomedical Applications in Molecular, Structural, and Functional Imaging, International Society for Optics and Photonics. SPIE. pp. 226\u2013231. Zhu, Q., 2020. On the Performance of Matthews Correlation Coe fficient (MCC) for Imbalanced Dataset. Pattern Recognition Letters 136, 71\u201380. Zijdenbos, A.P., Dawant, B.M., Margolin, R.A., Palmer, A.C., 1994. Morphometric Analysis of White Matter Lesions in MR Images: Method and Validation. IEEE Transactions on Medical Imaging 13, 716\u2013724. Zortea, M., Skr\u00f8vseth, S.O., Schopf, T.R., Kirchesch, H.M., Godtliebsen, F., 2011. Automatic segmentation of dermoscopic images by iterative classification. International journal of biomedical imaging 2011. Zou, K.H., Warfield, S.K., Bharatha, A., Tempany, C.M., Kaus, M.R., Haker, S.J., Wells III, W.M., Jolesz, F.A., Kikinis, R., 2004. Statistical Validation of Image Segmentation Quality Based on a Spatial Overlap Index. Academic Radiology 11, 178\u2013189. Zunair, H., Hamza, A.B., 2021. Sharp U-Net: Depthwise convolutional network for biomedical image segmentation. Computers in Biology and Medicine 136, 104699."
      },
      "Learning orthogonal prototypes for generalized few-shot semantic segmentation": {
        "authors": [
          "Ao Liu",
          "Yiheng Zhang",
          "Zhaofan Qiu",
          "Hongtao Xie",
          "Yongdong Zhang",
          "Ting Yao"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2023/papers/Liu_Learning_Orthogonal_Prototypes_for_Generalized_Few-Shot_Semantic_Segmentation_CVPR_2023_paper.pdf",
        "ref_texts": "[50] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017. 2, 5[51] Zhen Zhu, Mengde Xu, Song Bai, Tengteng Huang, and Xiang Bai. Asymmetric non-local neural networks for semantic segmentation. In ICCV , 2019. 2",
        "ref_ids": [
          "50",
          "51"
        ]
      },
      "Local-global context aware transformer for language-guided video segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2203.09773",
        "ref_texts": ""
      },
      "Clip-s4: Language-guided self-supervised semantic segmentation": {
        "authors": [
          "Wenbin He",
          "Suphanut Jamonnak",
          "Liang Gou",
          "Liu Ren"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2023/papers/He_CLIP-S4_Language-Guided_Self-Supervised_Semantic_Segmentation_CVPR_2023_paper.pdf",
        "ref_texts": "[48] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , pages 6230\u20136239, 2017. 1, 5, 6, 7",
        "ref_ids": [
          "48"
        ]
      },
      "A billion-scale foundation model for remote sensing images": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2304.05215",
        "ref_texts": "[127] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "127"
        ]
      },
      "Advances in deep concealed scene understanding": {
        "authors": [
          "Ping Fan"
        ],
        "url": "https://link.springer.com/content/pdf/10.1007/s44267-023-00019-6.pdf",
        "ref_texts": "2. Zhao,H.,Shi,J.,Qi,X.,Wang,X.,&Jia,J.(2017).Pyramidsceneparsing network.In ProceedingsoftheIEEEconferenceoncomputervisionand patternrecognition (pp.6230\u20136239).LosAlamitos:IEEE.",
        "ref_ids": [
          "2"
        ]
      },
      "Radar-camera fusion for object detection and semantic segmentation in autonomous driving: A comprehensive review": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2304.10410",
        "ref_texts": "[140] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "140"
        ]
      },
      "Rethinking the correlation in few-shot segmentation: A buoys view": {
        "authors": [
          "Yuan Wang",
          "Rui Sun",
          "Tianzhu Zhang"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2023/papers/Wang_Rethinking_the_Correlation_in_Few-Shot_Segmentation_A_Buoys_View_CVPR_2023_paper.pdf",
        "ref_texts": "[44] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017. 2",
        "ref_ids": [
          "44"
        ]
      },
      "Kd-zero: Evolving knowledge distiller for any teacher-student pairs": {
        "authors": [],
        "url": "https://proceedings.neurips.cc/paper_files/paper/2023/file/dbc8ce0fdfcd55172d73fb05dbae07fc-Paper-Conference.pdf",
        "ref_texts": "[78] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017. 9",
        "ref_ids": [
          "78"
        ]
      },
      "Detecting human-object contact in images": {
        "authors": [
          "Yixin Chen",
          "Sai Kumar",
          "Michael J. Black",
          "Dimitrios Tzionas"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Chen_Detecting_Human-Object_Contact_in_Images_CVPR_2023_paper.pdf",
        "ref_texts": "[65] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Computer Vision and Pattern Recognition (CVPR) , pages 2881\u20132890, 2017. 6, 7",
        "ref_ids": [
          "65"
        ]
      },
      "MIANet: Aggregating unbiased instance and general information for few-shot semantic segmentation": {
        "authors": [
          "Yong Yang",
          "Qiong Chen",
          "Yuan Feng",
          "Tianlin Huang"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2023/papers/Yang_MIANet_Aggregating_Unbiased_Instance_and_General_Information_for_Few-Shot_Semantic_CVPR_2023_paper.pdf",
        "ref_texts": "[40] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017. 2, 6",
        "ref_ids": [
          "40"
        ]
      },
      "Open-vocabulary semantic segmentation with decoupled one-pass network": {
        "authors": [
          "Cong Han",
          "Yujie Zhong",
          "Dengjie Li",
          "Kai Han",
          "Lin Ma"
        ],
        "url": "https://openaccess.thecvf.com/content/ICCV2023/papers/Han_Open-Vocabulary_Semantic_Segmentation_with_Decoupled_One-Pass_Network_ICCV_2023_paper.pdf",
        "ref_texts": "[43] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , pages 6230\u20136239, 2016.",
        "ref_ids": [
          "43"
        ]
      },
      "Self-regularized prototypical network for few-shot semantic segmentation": {
        "authors": [
          "Henghui Ding",
          "Hui Zhang",
          "Xudong Jiang"
        ],
        "url": "https://arxiv.org/pdf/2210.16829",
        "ref_texts": "[42] H. Zhao, J. Shi, X. Qi, X. Wang, J. Jia, Pyramid scene parsing network, in: Proceedings of the IEEE conference on computer vision and pattern recognition, 2017, pp. 2881{2890.",
        "ref_ids": [
          "42"
        ]
      },
      "Balancing logit variation for long-tailed semantic segmentation": {
        "authors": [
          "Yuchao Wang",
          "Jingjing Fei",
          "Haochen Wang",
          "Wei Li",
          "Tianpeng Bao",
          "Liwei Wu",
          "Rui Zhao",
          "Yujun Shen"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2023/papers/Wang_Balancing_Logit_Variation_for_Long-Tailed_Semantic_Segmentation_CVPR_2023_paper.pdf",
        "ref_texts": "[109] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In IEEE Conf. Comput. Vis. Pattern Recog. , 2017. 1, 2, 4, 5",
        "ref_ids": [
          "109"
        ]
      },
      "Double branch parallel network for segmentation of buildings and waters in remote sensing images": {
        "authors": [
          "Jing Chen",
          "Min Xia",
          "Dehao Wang",
          "Haifeng Lin"
        ],
        "url": "https://www.mdpi.com/2072-4292/15/6/1536/pdf",
        "ref_texts": "24. Zhao, H.; Shi, J.; Qi, X.; Wang, X.; Jia, J. Pyramid scene parsing network. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Honolulu, HI, USA, 21\u201326 July 2017; pp. 2881\u20132890.",
        "ref_ids": [
          "24"
        ]
      },
      "Logicseg: Parsing visual semantics with neural logic learning and reasoning": {
        "authors": [
          "Liulei Li",
          "Wenguan Wang",
          "Yi Yang"
        ],
        "url": "http://openaccess.thecvf.com/content/ICCV2023/papers/Li_LogicSeg_Parsing_Visual_Semantics_with_Neural_Logic_Learning_and_Reasoning_ICCV_2023_paper.pdf",
        "ref_texts": "[146] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017. 7",
        "ref_ids": [
          "146"
        ]
      },
      "Hunting sparsity: Density-guided contrastive learning for semi-supervised semantic segmentation": {
        "authors": [
          "Xiaoyang Wang",
          "Bingfeng Zhang",
          "Limin Yu",
          "Jimin Xiao"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_Hunting_Sparsity_Density-Guided_Contrastive_Learning_for_Semi-Supervised_Semantic_Segmentation_CVPR_2023_paper.pdf",
        "ref_texts": "[46] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017. 1",
        "ref_ids": [
          "46"
        ]
      },
      "Norm: Knowledge distillation via n-to-one representation matching": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2305.13803",
        "ref_texts": "12 Published as a conference paper at ICLR 2023 Guodong Xu, Ziwei Liu, Xiaoxiao Li, and Chen Change Loy. Knowledge distillation meets selfsupervision. In ECCV , 2020. Chuanguang Yang, Helong Zhou, Zhulin An, Xue Jiang, Yongjun Xu, and Qian Zhang. Cross-image relational knowledge distillation for semantic segmentation. In CVPR , 2022a. Jing Yang, Brais Martinez, Adrian Bulat, and Georgios Tzimiropoulos. Knowledge distillation via softmax regression representation learning. In ICLR , 2021. Zhendong Yang, Zhe Li, Xiaohu Jiang, Yuan Gong, Zehuan Yuan, Danpei Zhao, and Chun Yuan. Focal and global knowledge distillation for detectors. In CVPR , 2022b. Zhendong Yang, Zhe Li, Mingqi Shao, Dachuan Shi, Zehuan Yuan, and Chun Yuan. Masked generative distillation. In ECCV , 2022c. Zhendong Yang, Zhe Li, Ailing Zeng, Zexian Li, Chun Yuan, and Yu Li. Vitkd: Practical guidelines for vit feature knowledge distillation. arXiv preprint arXiv:2209.02432 , 2022d. Anbang Yao and Dawei Sun. Knowledge transfer via dense cross-layer mutual-distillation. In ECCV , 2020. Junho Yim, Donggyu Joo, Jihoon Bae, and Junmo Kim. A gift from knowledge distillation: Fast optimization, network minimization and transfer learning. In CVPR , 2017. Sukmin Yin, Jonjing Park, Kimin Li, and Jinwoo Shin. Regularizing class-wise predictions via self-knowledge distillation. In CVPR , 2020. Kaiyu Yue, Jiangfan Deng, and Feng Zhou. Matching guided distillation. In ECCV , 2020. Sergey Zagoruyko and Nikos Komodakis. Paying more attention to attention: Improving the performance of convolutional neural networks via attention transfer. In ICLR , 2017. Hongyi Zhang, Cisse Moustapha, N Dauphin Yann, and Lopez-Paz David. mixup: Beyond empirical risk minimization. In ICLR , 2018a. Linfeng Zhang and Kaisheng Ma. Improve object detection with feature-based knowledge distillation: Towards accurate and efficient detectors. In ICLR , 2021. Ying Zhang, Tao Xiang, Timothy M Hospedales, and Huchuan Lu. Deep mutual learning. In CVPR , 2018b. Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017. Denny Zhou, Mao Ye, Chen Chen, Tianjian Meng, Mingxing Tan, Xiaodan Sun, Quoc Le, Qiang Liu, and Dale Schuurmans. Go wide, then narrow: Efficient training of deep thin networks. In ICML , 2020. Jinghao Zhou, Chen Wei, Huiyu Wang, Wei Shen, Cihang Xie, Alan Yuille, and Tao Kong. ibot: Image bert pre-training with online tokenizer. In ICLR , 2022."
      },
      "Explicit attention-enhanced fusion for RGB-thermal perception tasks": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2303.15710",
        "ref_texts": "[54] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "54"
        ]
      },
      "Refign: Align and refine for adaptation of semantic segmentation to adverse conditions": {
        "authors": [
          "David Bruggemann",
          "Christos Sakaridis",
          "Prune Truong",
          "Luc Van"
        ],
        "url": "https://openaccess.thecvf.com/content/WACV2023/papers/Bruggemann_Refign_Align_and_Refine_for_Adaptation_of_Semantic_Segmentation_to_WACV_2023_paper.pdf",
        "ref_texts": "[72] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017.",
        "ref_ids": [
          "72"
        ]
      },
      "Deep depth estimation from thermal image": {
        "authors": [
          "Ukcheol Shin",
          "Jinsun Park",
          "In So"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2023/papers/Shin_Deep_Depth_Estimation_From_Thermal_Image_CVPR_2023_paper.pdf",
        "ref_texts": "[58] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017. 5",
        "ref_ids": [
          "58"
        ]
      },
      "Tta-cope: Test-time adaptation for category-level object pose estimation": {
        "authors": [
          "Taeyeop Lee",
          "Jonathan Tremblay",
          "Valts Blukis",
          "Bowen Wen",
          "Uk Lee",
          "Inkyu Shin",
          "Stan Birchfield",
          "In So",
          "Jin Yoon"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Lee_TTA-COPE_Test-Time_Adaptation_for_Category-Level_Object_Pose_Estimation_CVPR_2023_paper.pdf",
        "ref_texts": "[53] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) , pages 2881\u20132890, 2017. 6",
        "ref_ids": [
          "53"
        ]
      },
      "Both style and distortion matter: Dual-path unsupervised domain adaptation for panoramic semantic segmentation": {
        "authors": [
          "Xu Zheng",
          "Jinjing Zhu",
          "Yexin Liu",
          "Zidong Cao",
          "Chong Fu",
          "Lin Wang"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Zheng_Both_Style_and_Distortion_Matter_Dual-Path_Unsupervised_Domain_Adaptation_for_CVPR_2023_paper.pdf",
        "ref_texts": "[52] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017. 6",
        "ref_ids": [
          "52"
        ]
      },
      "Self-calibrated cross attention network for few-shot segmentation": {
        "authors": [
          "Qianxiong Xu",
          "Wenting Zhao",
          "Guosheng Lin",
          "Cheng Long"
        ],
        "url": "http://openaccess.thecvf.com/content/ICCV2023/papers/Xu_Self-Calibrated_Cross_Attention_Network_for_Few-Shot_Segmentation_ICCV_2023_paper.pdf",
        "ref_texts": "[48] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017. 1",
        "ref_ids": [
          "48"
        ]
      },
      "Focus on query: Adversarial mining transformer for few-shot segmentation": {
        "authors": [],
        "url": "https://proceedings.neurips.cc/paper_files/paper/2023/file/6447714b83edcbed61dbe10371dd7ae5-Paper-Conference.pdf",
        "ref_texts": "[18] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "18"
        ]
      },
      "Open-vocabulary panoptic segmentation with embedding modulation": {
        "authors": [
          "Xi Chen",
          "Shuang Li",
          "Nam Lim",
          "Antonio Torralba",
          "Hengshuang Zhao"
        ],
        "url": "https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Open-vocabulary_Panoptic_Segmentation_with_Embedding_Modulation_ICCV_2023_paper.pdf",
        "ref_texts": "[51] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017.",
        "ref_ids": [
          "51"
        ]
      },
      "Generalized parametric contrastive learning": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2209.12400",
        "ref_texts": "[5] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in CVPR , 2017.",
        "ref_ids": [
          "5"
        ]
      },
      "Multiscale attention networks for pavement defect detection": {
        "authors": [
          "Junde Chen",
          "Yuxin Wen",
          "Yaser Ahangari",
          "Defu Zhang",
          "Adan Zeb"
        ],
        "url": "https://digitalcommons.chapman.edu/cgi/viewcontent.cgi?article=1182&context=engineering_articles",
        "ref_texts": "[42] Zhao, Hengshuang, et al. \u201cPyramid scene parsing network.\u201d Proceedings of the IEEE conference on computer vision and pattern recognition. 2017.",
        "ref_ids": [
          "42"
        ]
      },
      "Poda: Prompt-driven zero-shot domain adaptation": {
        "authors": [
          "Mohammad Fahes",
          "Hung Vu",
          "Andrei Bursuc",
          "Patrick Perez"
        ],
        "url": "https://openaccess.thecvf.com/content/ICCV2023/papers/Fahes_PODA_Prompt-driven_Zero-shot_Domain_Adaptation_ICCV_2023_paper.pdf",
        "ref_texts": "[57] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017. 1",
        "ref_ids": [
          "57"
        ]
      },
      "Domain generalization via balancing training difficulty and model capability": {
        "authors": [
          "Xueying Jiang",
          "Jiaxing Huang",
          "Sheng Jin",
          "Shijian Lu"
        ],
        "url": "https://openaccess.thecvf.com/content/ICCV2023/papers/Jiang_Domain_Generalization_via_Balancing_Training_Difficulty_and_Model_Capability_ICCV_2023_paper.pdf",
        "ref_texts": "[58] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 2881\u20132890, 2017.",
        "ref_ids": [
          "58"
        ]
      },
      "Mdu-net: Multi-scale densely connected u-net for biomedical image segmentation": {
        "authors": [
          "Jiawei Zhang"
        ],
        "url": "https://arxiv.org/pdf/1812.00352",
        "ref_texts": ""
      },
      "Deep learning approaches for wildland fires remote sensing: Classification, detection, and segmentation": {
        "authors": [
          "Rafik Ghali",
          "Moulay A. Akhloufi"
        ],
        "url": "https://www.mdpi.com/2072-4292/15/7/1821/pdf",
        "ref_texts": "143. Zhao, H.; Shi, J.; Qi, X.; Wang, X.; Jia, J. Pyramid Scene Parsing Network. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Honolulu, HI, USA, 21\u201326 July 2017; pp. 2881\u20132890.",
        "ref_ids": [
          "143"
        ]
      },
      "A deep learning based dual encoder\u2013decoder framework for anatomical structure segmentation in chest X-ray images": {
        "authors": [
          "Ihsan Ullah"
        ],
        "url": "https://www.nature.com/articles/s41598-023-27815-w.pdf",
        "ref_texts": ""
      },
      "CAVER: Cross-modal view-mixed transformer for bi-modal salient object detection": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2112.02363",
        "ref_texts": "[60] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in CVPR , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "60"
        ]
      },
      "Multispectral video semantic segmentation: A benchmark dataset and baseline": {
        "authors": [
          "Wei Ji",
          "Jingjing Li",
          "Cheng Bian",
          "Zongwei Zhou",
          "Jiaying Zhao",
          "Alan L. Yuille",
          "Li Cheng"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2023/papers/Ji_Multispectral_Video_Semantic_Segmentation_A_Benchmark_Dataset_and_Baseline_CVPR_2023_paper.pdf",
        "ref_texts": "[76] Qiang Zhang, Shenlu Zhao, Yongjiang Luo, Dingwen Zhang, Nianchang Huang, and Jungong Han. Abmdrnet: Adaptive-weighted bi-directional modality difference reduction network for rgb-t semantic segmentation. In CVPR , pages 2633\u20132642, 2021. 2, 3, 6[77] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , pages 2881\u20132890, 2017. 2, 6, 7",
        "ref_ids": [
          "76",
          "77"
        ]
      },
      "Video dehazing via a multi-range temporal alignment network with physical prior": {
        "authors": [
          "Jiaqi Xu",
          "Xiaowei Hu",
          "Lei Zhu",
          "Qi Dou",
          "Jifeng Dai",
          "Yu Qiao",
          "Ann Heng"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Xu_Video_Dehazing_via_a_Multi-Range_Temporal_Alignment_Network_With_Physical_CVPR_2023_paper.pdf",
        "ref_texts": "[60] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017. 7",
        "ref_ids": [
          "60"
        ]
      },
      "A multi-centre polyp detection and segmentation dataset for generalisability assessment": {
        "authors": [
          "Sharib Ali"
        ],
        "url": "https://www.nature.com/articles/s41597-023-01981-y.pdf",
        "ref_texts": ""
      },
      "A deep learning method for optimizing semantic segmentation accuracy of remote sensing images based on improved UNet": {
        "authors": [
          "Xiaolei Wang"
        ],
        "url": "https://www.nature.com/articles/s41598-023-34379-2.pdf",
        "ref_texts": ""
      },
      "Mcanet: A multi-branch network for cloud/snow segmentation in high-resolution remote sensing images": {
        "authors": [
          "Kai Hu",
          "Enwei Zhang",
          "Min Xia",
          "Liguo Weng",
          "Haifeng Lin"
        ],
        "url": "https://www.mdpi.com/2072-4292/15/4/1055/pdf",
        "ref_texts": "43. Zhao, H.; Shi, J.; Qi, X.; Wang, X.; Jia, J. Pyramid scene parsing network. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Honolulu, HI, USA, 21\u201326 July 2017; pp. 2881\u20132890.",
        "ref_ids": [
          "43"
        ]
      },
      "Dreamteacher: Pretraining image backbones with deep generative models": {
        "authors": [
          "Daiqing Li",
          "Huan Ling",
          "Amlan Kar",
          "David Acuna",
          "Seung Wook",
          "Karsten Kreis",
          "Antonio Torralba",
          "Sanja Fidler"
        ],
        "url": "http://openaccess.thecvf.com/content/ICCV2023/papers/Li_DreamTeacher_Pretraining_Image_Backbones_with_Deep_Generative_Models_ICCV_2023_paper.pdf",
        "ref_texts": "[83] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017. 4,13",
        "ref_ids": [
          "83"
        ]
      },
      "DCN-T: Dual context network with transformer for hyperspectral image classification": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2304.09915",
        "ref_texts": "[88] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in CVPR , 2017, pp. 6230\u20136239.",
        "ref_ids": [
          "88"
        ]
      },
      "Multi-level attention interactive network for cloud and snow detection segmentation": {
        "authors": [
          "Li Ding",
          "Min Xia",
          "Haifeng Lin",
          "Kai Hu"
        ],
        "url": "https://www.mdpi.com/2072-4292/16/1/112/pdf",
        "ref_texts": "49. Zhao, H.; Shi, J.; Qi, X.; Wang, X.; Jia, J. Pyramid scene parsing network. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Honolulu, HI, USA, 21\u201326 July 2017; pp. 2881\u20132890. Disclaimer/Publisher\u2019s Note: The statements, opinions and data contained in all publications are solely those of the individual author(s) and contributor(s) and not of MDPI and/or the editor(s). MDPI and/or the editor(s) disclaim responsibility for any injury to people or property resulting from any ideas, methods, instructions or products referred to in the content.",
        "ref_ids": [
          "49"
        ]
      },
      "Multi-branch deep learning framework for land scene classification in satellite imagery": {
        "authors": [
          "Sultan Daud",
          "Saleh Basalamah"
        ],
        "url": "https://www.mdpi.com/2072-4292/15/13/3408/pdf",
        "ref_texts": "63. Zhao, H.; Shi, J.; Qi, X.; Wang, X.; Jia, J. Pyramid scene parsing network. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Honolulu, HI, USA, 21\u201326 July 2017; pp. 2881\u20132890.",
        "ref_ids": [
          "63"
        ]
      },
      "Multi-target knowledge distillation via student self-reflection": {
        "authors": [
          "Jianping Gou"
        ],
        "url": "https://link.springer.com/content/pdf/10.1007/s11263-023-01792-z.pdf",
        "ref_texts": "1874 International Journal of Computer Vision (2023) 131:1857\u20131874 Zhang, S., Liu, H., Hopcroft, J. E., & He, K. (2022). Class-aware Information for Logit-based Knowledge Distillation. arXiv preprintarXiv:2211.14773 . Zhang, L., Shi, Y ., Shi, Z., Ma, K., & Bao, C. (2020). Task-oriented feature distillation. In NeurIPS (pp. 14759\u201314771). Zhang, L., Song, J., Gao, A., Chen, J., Bao, C., & Ma, K. (2019). Be your own teacher: Improve the performance of convolutional neuralnetworks via self distillation. In ICCV (pp. 3713\u20133722). Zhang, Y ., Xiang, T., Hospedales, T. M., & Lu, H. (2018). Deep mutual learning. In CVPR (pp. 4320\u20134328). Zhang, L., Bao, C., & Ma, K. (2022). Self-distillation: Towards efficient and compact neural networks. IEEE Transactions on Pattern Analysis and Machine Intelligence, 44 (8), 4388\u20134403. Zhao, B., Cui, Q., Song, R., Qiu, Y ., & Liang, J. (2022). Decoupled knowledge distillation. In CVPR (pp. 11953\u201311962). Zhao, H., Shi, J., Qi, X., Wang, X., & Jia, J. (2017). Pyramid scene parsing network. In CVPR (pp. 2881\u20132890).Zhao, T., Han, J., Yang, L., Wang, B., & Zhang, D. (2021). SODA: Weakly supervised temporal action localization based on astutebackground response and self-distillation learning. International Journal of Computer Vision, 129 (8), 2474\u20132498. Zheng, L., Shen, L., Tian, L., Wang, S., Wang, J., & Tian, Q. (2015). Scalable person reidentification: A benchmark. In ICCV (pp."
      },
      "Seeing beyond the patch: Scale-adaptive semantic segmentation of high-resolution remote sensing imagery based on reinforcement learning": {
        "authors": [
          "Yinhe Liu",
          "Sunan Shi",
          "Junjue Wang",
          "Yanfei Zhong"
        ],
        "url": "https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Seeing_Beyond_the_Patch_Scale-Adaptive_Semantic_Segmentation_of_High-resolution_Remote_ICCV_2023_paper.pdf",
        "ref_texts": "[50] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "50"
        ]
      },
      "A dragon fruit picking detection method based on YOLOv7 and PSP-Ellipse": {
        "authors": [
          "Jialiang Zhou",
          "Yueyue Zhang",
          "Jinpeng Wang"
        ],
        "url": "https://www.mdpi.com/1424-8220/23/8/3803/pdf",
        "ref_texts": "27. Zhao, H.; Shi, J.; Qi, X.; Wang, X.; Jia, J. Pyramid Scene Parsing Network. arXiv 2017 , arXiv:1612.01105.",
        "ref_ids": [
          "27"
        ]
      },
      "Learning and aggregating lane graphs for urban automated driving": {
        "authors": [
          "Martin Buchner",
          "Jannik Zurn",
          "George Todoran",
          "Abhinav Valada",
          "Wolfram Burgard"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2023/papers/Buchner_Learning_and_Aggregating_Lane_Graphs_for_Urban_Automated_Driving_CVPR_2023_paper.pdf",
        "ref_texts": "[33] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017. 3, 16",
        "ref_ids": [
          "33"
        ]
      },
      "Prototypical kernel learning and open-set foreground perception for generalized few-shot semantic segmentation": {
        "authors": [
          "Kai Huang",
          "Feigege Wang",
          "Ye Xi",
          "Yutao Gao"
        ],
        "url": "https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_Prototypical_Kernel_Learning_and_Open-set_Foreground_Perception_for_Generalized_Few-shot_ICCV_2023_paper.pdf",
        "ref_texts": "[45] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 2881\u20132890, 2017. 6, 7",
        "ref_ids": [
          "45"
        ]
      },
      "Towards online domain adaptive object detection": {
        "authors": [
          "Vibashan V",
          "Poojan Oza",
          "Vishal M. Patel"
        ],
        "url": "https://openaccess.thecvf.com/content/WACV2023/papers/VS_Towards_Online_Domain_Adaptive_Object_Detection_WACV_2023_paper.pdf",
        "ref_texts": "[72] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "72"
        ]
      },
      "Hierarchical neural memory network for low latency event processing": {
        "authors": [
          "Ryuhei Hamaguchi",
          "Yasutaka Furukawa",
          "Masaki Onishi",
          "Ken Sakurada"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2023/papers/Hamaguchi_Hierarchical_Neural_Memory_Network_for_Low_Latency_Event_Processing_CVPR_2023_paper.pdf",
        "ref_texts": ""
      },
      "Rba: Segmenting unknown regions rejected by all": {
        "authors": [
          "Nazir Nayal",
          "Misra Yavuz",
          "Joao F. Henriques",
          "Fatma Guney"
        ],
        "url": "http://openaccess.thecvf.com/content/ICCV2023/papers/Nayal_RbA_Segmenting_Unknown_Regions_Rejected_by_All_ICCV_2023_paper.pdf",
        "ref_texts": "[80] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017. 2",
        "ref_ids": [
          "80"
        ]
      },
      "Uncertainty-aware vision-based metric cross-view geolocalization": {
        "authors": [
          "Florian Fervers",
          "Sebastian Bullinger",
          "Christoph Bodensteiner",
          "Michael Arens",
          "Rainer Stiefelhagen"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Fervers_Uncertainty-Aware_Vision-Based_Metric_Cross-View_Geolocalization_CVPR_2023_paper.pdf",
        "ref_texts": "[55] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017. 4",
        "ref_ids": [
          "55"
        ]
      },
      "Stochastic segmentation with conditional categorical diffusion models": {
        "authors": [
          "Lukas Zbinden",
          "Lars Doorenbos",
          "Theodoros Pissas",
          "Adrian Thomas",
          "Raphael Sznitman",
          "Pablo Marquez"
        ],
        "url": "http://openaccess.thecvf.com/content/ICCV2023/papers/Zbinden_Stochastic_Segmentation_with_Conditional_Categorical_Diffusion_Models_ICCV_2023_paper.pdf",
        "ref_texts": "[55] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017. 2[56] Roland S Zimmermann, Lukas Schott, Yang Song, Benjamin A Dunn, and David A Klindt. Score-based generative classifiers. arXiv preprint arXiv:2110.00473 , 2021. 1",
        "ref_ids": [
          "55",
          "56"
        ]
      },
      "MSFANet: Multi-scale strip feature attention network for cloud and cloud shadow segmentation": {
        "authors": [
          "Kai Chen",
          "Xin Dai",
          "Min Xia",
          "Liguo Weng",
          "Kai Hu",
          "Haifeng Lin"
        ],
        "url": "https://www.mdpi.com/2072-4292/15/19/4853/pdf",
        "ref_texts": "13. Zhao, H.; Shi, J.; Qi, X.; Wang, X.; Jia, J. Pyramid scene parsing network. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Honolulu, HI, USA, 21\u201326 July 2017; pp. 2881\u20132890.",
        "ref_ids": [
          "13"
        ]
      },
      "Generating aligned pseudo-supervision from non-aligned data for image restoration in under-display camera": {
        "authors": [
          "Ruicheng Feng",
          "Chongyi Li",
          "Huaijin Chen",
          "Shuai Li",
          "Jinwei Gu",
          "Chen Change"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2023/papers/Feng_Generating_Aligned_Pseudo-Supervision_From_Non-Aligned_Data_for_Image_Restoration_in_CVPR_2023_paper.pdf",
        "ref_texts": "[50] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017. 5",
        "ref_ids": [
          "50"
        ]
      },
      "Featenhancer: Enhancing hierarchical features for object detection and beyond under low-light vision": {
        "authors": [
          "Khurram Azeem",
          "Goutham Kallempudi",
          "Didier Stricker",
          "Muhammad Zeshan"
        ],
        "url": "http://openaccess.thecvf.com/content/ICCV2023/papers/Hashmi_FeatEnHancer_Enhancing_Hierarchical_Features_for_Object_Detection_and_Beyond_Under_ICCV_2023_paper.pdf",
        "ref_texts": "[69] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , July 2017.",
        "ref_ids": [
          "69"
        ]
      },
      "Dynamic token pruning in plain vision transformers for semantic segmentation": {
        "authors": [
          "Quan Tang",
          "Bowen Zhang",
          "Jiajun Liu",
          "Fagui Liu",
          "Yifan Liu"
        ],
        "url": "https://openaccess.thecvf.com/content/ICCV2023/papers/Tang_Dynamic_Token_Pruning_in_Plain_Vision_Transformers_for_Semantic_Segmentation_ICCV_2023_paper.pdf",
        "ref_texts": "[29] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. InProc. IEEE Conf. Comp. Vis. Patt. Recogn. , pages 2881\u2013",
        "ref_ids": [
          "29"
        ]
      },
      "Learning a graph neural network with cross modality interaction for image fusion": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2308.03256",
        "ref_texts": "[45] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. 2017. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition . 2881\u20132890.",
        "ref_ids": [
          "45"
        ]
      },
      "Tomato maturity recognition with convolutional transformers": {
        "authors": [
          "Asim Khan"
        ],
        "url": "https://www.nature.com/articles/s41598-023-50129-w.pdf",
        "ref_texts": ""
      },
      "CRSNet: Cloud and cloud shadow refinement segmentation networks for remote sensing imagery": {
        "authors": [
          "Chao Zhang",
          "Liguo Weng",
          "Li Ding",
          "Min Xia",
          "Haifeng Lin"
        ],
        "url": "https://www.mdpi.com/2072-4292/15/6/1664/pdf",
        "ref_texts": "24. Zhao, H.; Shi, J.; Qi, X.; Wang, X.; Jia, J. Pyramid Scene Parsing Network. arXiv 2016 , arXiv:1612.01105. Remote Sens. 2023 ,15, 1664 18 of 19",
        "ref_ids": [
          "24"
        ]
      },
      "Deep-learning-based approaches for semantic segmentation of natural scene images: A review": {
        "authors": [
          "Busra Emek",
          "Mehmet Serdar",
          "Gazi Erkan",
          "Fatih Ekinci",
          "Tunc Asuroglu",
          "Koray Acici"
        ],
        "url": "https://www.mdpi.com/2079-9292/12/12/2730/pdf",
        "ref_texts": "90. Zhao, H.; Shi, J.; Qi, X.; Wang, X.; Jia, J. Pyramid scene parsing network. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Venice, Italy, 22\u201329 October 2017; pp. 2881\u20132890.",
        "ref_ids": [
          "90"
        ]
      },
      "Learning across domains and devices: Style-driven source-free domain adaptation in clustered federated learning": {
        "authors": [
          "Donald Shenaj",
          "Eros Fani",
          "Marco Toldo",
          "Debora Caldarola",
          "Antonio Tavera",
          "Umberto Michieli",
          "Marco Ciccone",
          "Pietro Zanuttigh",
          "Barbara Caputo"
        ],
        "url": "https://openaccess.thecvf.com/content/WACV2023/papers/Shenaj_Learning_Across_Domains_and_Devices_Style-Driven_Source-Free_Domain_Adaptation_in_WACV_2023_paper.pdf",
        "ref_texts": "[74] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In IEEE Conf. Comput. Vis. Pattern Recog. , July 2017.",
        "ref_ids": [
          "74"
        ]
      },
      "Deep learning approaches for wildland fires using satellite remote sensing data: Detection, mapping, and prediction": {
        "authors": [
          "Rafik Ghali",
          "Moulay A. Akhloufi"
        ],
        "url": "https://www.mdpi.com/2571-6255/6/5/192/pdf",
        "ref_texts": "82. Zhao, H.; Shi, J.; Qi, X.; Wang, X.; Jia, J. Pyramid Scene Parsing Network. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Honolulu, HI, 21\u201326 July 2017; pp. 2881\u20132890.",
        "ref_ids": [
          "82"
        ]
      },
      "Protoseg: Interpretable semantic segmentation with prototypical parts": {
        "authors": [
          "Mikolaj Sacha",
          "Dawid Rymarczyk",
          "Lukasz Struski",
          "Jacek Tabor",
          "Bartosz Zielinski"
        ],
        "url": "https://openaccess.thecvf.com/content/WACV2023/papers/Sacha_ProtoSeg_Interpretable_Semantic_Segmentation_With_Prototypical_Parts_WACV_2023_paper.pdf",
        "ref_texts": "[79] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "79"
        ]
      },
      "Residual pattern learning for pixel-wise out-of-distribution detection in semantic segmentation": {
        "authors": [
          "Yuyuan Liu",
          "Choubo Ding",
          "Yu Tian",
          "Guansong Pang",
          "Vasileios Belagiannis",
          "Ian Reid",
          "Gustavo Carneiro"
        ],
        "url": "http://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Residual_Pattern_Learning_for_Pixel-Wise_Out-of-Distribution_Detection_in_Semantic_Segmentation_ICCV_2023_paper.pdf",
        "ref_texts": "[44] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "44"
        ]
      },
      "Ultra-high resolution segmentation with ultra-rich context: A novel benchmark": {
        "authors": [
          "Deyi Ji",
          "Feng Zhao",
          "Hongtao Lu",
          "Mingyuan Tao",
          "Jieping Ye"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2023/papers/Ji_Ultra-High_Resolution_Segmentation_With_Ultra-Rich_Context_A_Novel_Benchmark_CVPR_2023_paper.pdf",
        "ref_texts": "[19] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017. 2, 7, 8",
        "ref_ids": [
          "19"
        ]
      },
      "CFCG: Semi-Supervised Semantic Segmentation via Cross-Fusion and Contour Guidance Supervision": {
        "authors": [
          "Shuo Li",
          "Yue He",
          "Weiming Zhang",
          "Wei Zhang",
          "Xiao Tan",
          "Junyu Han",
          "Errui Ding",
          "Jingdong Wang"
        ],
        "url": "https://openaccess.thecvf.com/content/ICCV2023/papers/Li_CFCG_Semi-Supervised_Semantic_Segmentation_via_Cross-Fusion_and_Contour_Guidance_Supervision_ICCV_2023_paper.pdf",
        "ref_texts": "[36] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u2013",
        "ref_ids": [
          "36"
        ]
      },
      "Local feature search network for building and water segmentation of remote sensing image": {
        "authors": [
          "Zhanming Ma",
          "Min Xia",
          "Liguo Weng",
          "Haifeng Lin"
        ],
        "url": "https://www.mdpi.com/2071-1050/15/4/3034/pdf",
        "ref_texts": "21. Zhao, H.; Shi, J.; Qi, X.; Wang, X.; Jia, J. Pyramid scene parsing network. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Honolulu, HI, USA, 21\u201326 July 2017; pp. 2881\u20132890.",
        "ref_ids": [
          "21"
        ]
      },
      "To adapt or not to adapt? real-time adaptation for semantic segmentation": {
        "authors": [
          "Marc Botet",
          "Pier Luigi",
          "Theodoros Panagiotakopoulos",
          "Joao Frederico",
          "Linus Harenstam",
          "Hossein Azizpour",
          "Hedvig Kjellstrom",
          "Daniel Cremers",
          "Matteo Poggi"
        ],
        "url": "http://openaccess.thecvf.com/content/ICCV2023/papers/Colomer_To_Adapt_or_Not_to_Adapt_Real-Time_Adaptation_for_Semantic_ICCV_2023_paper.pdf",
        "ref_texts": "[72] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017.",
        "ref_ids": [
          "72"
        ]
      },
      "Combining implicit-explicit view correlation for light field semantic segmentation": {
        "authors": [
          "Ruixuan Cong",
          "Da Yang",
          "Rongshan Chen",
          "Sizhe Wang",
          "Zhenglong Cui",
          "Hao Sheng"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Cong_Combining_Implicit-Explicit_View_Correlation_for_Light_Field_Semantic_Segmentation_CVPR_2023_paper.pdf"
      },
      "LPMSNet: Location pooling multi-scale network for cloud and cloud shadow segmentation": {
        "authors": [],
        "url": "https://www.mdpi.com/2072-4292/15/16/4005/pdf",
        "ref_texts": "10. Zhao, H.; Shi, J.; Qi, X.; Wang, X.; Jia, J. Pyramid scene parsing network. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Honolulu, HI, USA, 21\u201326 July 2017; pp. 2881\u20132890.",
        "ref_ids": [
          "10"
        ]
      },
      "Multi-supervised feature fusion attention network for clouds and shadows detection": {
        "authors": [
          "Huiwen Ji",
          "Min Xia",
          "Dongsheng Zhang",
          "Haifeng Lin"
        ],
        "url": "https://www.mdpi.com/2220-9964/12/6/247/pdf",
        "ref_texts": "61. Zhao, H.; Shi, J.; Qi, X.; Wang, X.; Jia, J. Pyramid scene parsing network. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Honolulu, HI, USA, 21\u201326 July 2017; pp. 2881\u20132890.",
        "ref_ids": [
          "61"
        ]
      },
      "On calibrating semantic segmentation models: analyses and an algorithm": {
        "authors": [
          "Dongdong Wang",
          "Boqing Gong",
          "Liqiang Wang"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2023/papers/Wang_On_Calibrating_Semantic_Segmentation_Models_Analyses_and_an_Algorithm_CVPR_2023_paper.pdf",
        "ref_texts": ""
      },
      "Fully attentional networks with self-emerging token labeling": {
        "authors": [
          "Bingyin Zhao",
          "Zhiding Yu",
          "Shiyi Lan",
          "Yutao Cheng",
          "Anima Anandkumar",
          "Yingjie Lao",
          "Jose M. Alvarez"
        ],
        "url": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_Fully_Attentional_Networks_with_Self-emerging_Token_Labeling_ICCV_2023_paper.pdf",
        "ref_texts": "[59] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , pages 2881\u20132890, 2017. 7[60] Byeongho Heo, Sangdoo Yun, Dongyoon Han, Sanghyuk Chun, Junsuk Choe, and Seong Joon Oh. Rethinking spatial dimensions of vision transformers. In ICCV , pages 11936\u2013",
        "ref_ids": [
          "59",
          "60"
        ]
      },
      "Learning off-road terrain traversability with self-supervisions only": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2305.18896",
        "ref_texts": "[10] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition (CVPR) , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "10"
        ]
      },
      "Unsupervised domain adaptation semantic segmentation of high-resolution remote sensing imagery with invariant domain-level prototype memory": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2208.07722",
        "ref_texts": ""
      },
      "Fast-SNN: fast spiking neural network by converting quantized ANN": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2305.19868",
        "ref_texts": "[75] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proc. IEEE Conf. Comput. Vis. Pattern Recognit. , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "75"
        ]
      },
      "Comformer: Continual learning in semantic and panoptic segmentation": {
        "authors": [
          "Fabio Cermelli",
          "Matthieu Cord",
          "Arthur Douillard"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2023/papers/Cermelli_CoMFormer_Continual_Learning_in_Semantic_and_Panoptic_Segmentation_CVPR_2023_paper.pdf",
        "ref_texts": "[60] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2017.",
        "ref_ids": [
          "60"
        ]
      },
      "Segment anything is a good pseudo-label generator for weakly supervised semantic segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2305.01275",
        "ref_texts": "[44] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In IEEE Conf. Comput. Vis. Pattern Recog. , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "44"
        ]
      },
      "Continuous pseudo-label rectified domain adaptive semantic segmentation with implicit neural representations": {
        "authors": [
          "Rui Gong",
          "Qin Wang",
          "Martin Danelljan",
          "Dengxin Dai",
          "Luc Van"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2023/papers/Gong_Continuous_Pseudo-Label_Rectified_Domain_Adaptive_Semantic_Segmentation_With_Implicit_Neural_CVPR_2023_paper.pdf",
        "ref_texts": "[78] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017. 1",
        "ref_ids": [
          "78"
        ]
      },
      "Recent advances in plant disease severity assessment using convolutional neural networks": {
        "authors": [
          "Tingting Shi"
        ],
        "url": "https://www.nature.com/articles/s41598-023-29230-7.pdf",
        "ref_texts": ""
      },
      "Structtoken: Rethinking semantic segmentation with structural prior": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2203.12612"
      },
      "A multi-objective semantic segmentation algorithm based on improved U-Net networks": {
        "authors": [
          "Xuejie Hao",
          "Lizeyan Yin",
          "Xiuhong Li",
          "Le Zhang",
          "Rongjin Yang"
        ],
        "url": "https://www.mdpi.com/2072-4292/15/7/1838/pdf",
        "ref_texts": "13. Zhao, H.; Shi, J.; Qi, X.; Wang, X.; Jia, J. Pyramid Scene Parsing Network. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Honolulu, HI, USA, 21\u201326 July 2017; pp. 2881\u20132890.",
        "ref_ids": [
          "13"
        ]
      },
      "Transformers pay attention to convolutions leveraging emerging properties of ViTs by dual attention-image network": {
        "authors": [
          "Yousef Yeganeh",
          "Azade Farshad",
          "Peter Weinberger",
          "Ahmad Ahmadi",
          "Ehsan Adeli",
          "Nassir Navab"
        ],
        "url": "https://openaccess.thecvf.com/content/ICCV2023W/CVAMD/papers/Yeganeh_Transformers_Pay_Attention_to_Convolutions_Leveraging_Emerging_Properties_of_ViTs_ICCVW_2023_paper.pdf",
        "ref_texts": "[95] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 2881\u20132890, 2017. 3",
        "ref_ids": [
          "95"
        ]
      },
      "A strong baseline for generalized few-shot semantic segmentation": {
        "authors": [
          "Sina Hajimiri",
          "Malik Boudiaf",
          "Ismail Ben",
          "Jose Dolz"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2023/papers/Hajimiri_A_Strong_Baseline_for_Generalized_Few-Shot_Semantic_Segmentation_CVPR_2023_paper.pdf",
        "ref_texts": "[38] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017. 6",
        "ref_ids": [
          "38"
        ]
      },
      "Multi-label self-supervised learning with scene images": {
        "authors": [
          "Ke Zhu",
          "Minghao Fu",
          "Jianxin Wu"
        ],
        "url": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_Multi-Label_Self-Supervised_Learning_with_Scene_Images_ICCV_2023_paper.pdf",
        "ref_texts": "[49] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "49"
        ]
      },
      "Segment anything model (sam) meets glass: Mirror and transparent objects cannot be easily detected": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2305.00278",
        "ref_texts": "6 Segment Anything Model meets Glass Enze Xie, Wenjia Wang, Wenhai Wang, Mingyu Ding, Chunhua Shen, and Ping Luo. Segmenting transparent objects in the wild. In Computer Vision\u2013ECCV 2020: 16th European Conference, Glasgow, UK, August 23\u201328, 2020, Proceedings, Part XIII 16 , pages 696\u2013711. Springer, 2020. Ran Margolin, Lihi Zelnik-Manor, and Ayellet Tal. How to evaluate foreground maps? In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 248\u2013255, 2014. Radhakrishna Achanta, Sheila Hemami, Francisco Estrada, and Sabine Susstrunk. Frequency-tuned salient region detection. In 2009 IEEE conference on computer vision and pattern recognition , pages 1597\u20131604. IEEE, 2009. Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017. Alexander Kirillov, Yuxin Wu, Kaiming He, and Ross Girshick. Pointrend: Image segmentation as rendering. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , pages 9799\u20139808, 2020. Nian Liu, Junwei Han, and Ming-Hsuan Yang. Picanet: Learning pixel-wise contextual attention for saliency detection. InProceedings of the IEEE conference on computer vision and pattern recognition , pages 3089\u20133098, 2018. Xiaowei Hu, Lei Zhu, Chi-Wing Fu, Jing Qin, and Pheng-Ann Heng. Direction-aware spatial context features for shadow detection. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 7454\u20137462, 2018. Lei Zhu, Zijun Deng, Xiaowei Hu, Chi-Wing Fu, Xuemiao Xu, Jing Qin, and Pheng-Ann Heng. Bidirectional feature pyramid network with recurrent attention residual modules for shadow detection. In Proceedings of the European Conference on Computer Vision (ECCV) , pages 121\u2013136, 2018. Xuebin Qin, Zichen Zhang, Chenyang Huang, Chao Gao, Masood Dehghan, and Martin Jagersand. Basnet: Boundaryaware salient object detection. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , pages 7479\u20137489, 2019. Youwei Pang, Xiaoqi Zhao, Lihe Zhang, and Huchuan Lu. Multi-scale interactive network for salient object detection. InProceedings of the IEEE/CVF conference on computer vision and pattern recognition , pages 9413\u20139422, 2020. Deng-Ping Fan, Ge-Peng Ji, Guolei Sun, Ming-Ming Cheng, Jianbing Shen, and Ling Shao. Camouflaged object detection. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , pages 2777\u20132787, 2020. Jiaying Lin, Yuen Hei Yeung, and Rynson WH Lau. Exploiting semantic relations for glass surface detection. In Advances in Neural Information Processing Systems . Hengshuang Zhao, Xiaojuan Qi, Xiaoyong Shen, Jianping Shi, and Jiaya Jia. Icnet for real-time semantic segmentation on high-resolution images. In Proceedings of the European conference on computer vision (ECCV) , pages 405\u2013420, 2018. Qibin Hou, Ming-Ming Cheng, Xiaowei Hu, Ali Borji, Zhuowen Tu, and Philip HS Torr. Deeply supervised salient object detection with short connections. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 3203\u20133212, 2017. Shuhan Chen, Xiuli Tan, Ben Wang, and Xuelong Hu. Reverse attention for salient object detection. In Proceedings of the European conference on computer vision (ECCV) , pages 234\u2013250, 2018. Huankang Guan, Jiaying Lin, and Rynson WH Lau. Learning semantic associations for mirror detection. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 5941\u20135950, 2022. Changqian Yu, Jingbo Wang, Changxin Gao, Gang Yu, Chunhua Shen, and Nong Sang. Context prior for scene segmentation. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , pages 12416\u201312425, 2020. Yunpeng Chen, Marcus Rohrbach, Zhicheng Yan, Yan Shuicheng, Jiashi Feng, and Yannis Kalantidis. Graph-based global reasoning networks. In CVPR , pages 433\u2013442, 2019."
      },
      "Elevation estimation-driven building 3-D reconstruction from single-view remote sensing imagery": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2301.04581",
        "ref_texts": "[60] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "60"
        ]
      },
      "Gnesf: Generalizable neural semantic fields": {
        "authors": [],
        "url": "https://proceedings.neurips.cc/paper_files/paper/2023/file/72d32f4fe0b7af03732bd227bf1c4a5f-Paper-Conference.pdf",
        "ref_texts": "[54] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "54"
        ]
      },
      "Label-guided knowledge distillation for continual semantic segmentation on 2d images and 3d point clouds": {
        "authors": [
          "Ze Yang",
          "Ruibo Li",
          "Evan Ling",
          "Chi Zhang",
          "Yiming Wang",
          "Dezhao Huang",
          "Keng Teck",
          "Minhoe Hur",
          "Guosheng Lin"
        ],
        "url": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Label-Guided_Knowledge_Distillation_for_Continual_Semantic_Segmentation_on_2D_Images_ICCV_2023_paper.pdf",
        "ref_texts": "[63] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017. 1, 2",
        "ref_ids": [
          "63"
        ]
      },
      "Image segmentation keras: Implementation of segnet, fcn, unet, pspnet and other models in keras": {
        "authors": [
          "Divam Gupta"
        ],
        "url": "https://arxiv.org/pdf/2307.13215",
        "ref_texts": "[10] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017. 1",
        "ref_ids": [
          "10"
        ]
      },
      "Scratching visual transformer's back with uniform attention": {
        "authors": [
          "Nam Hyeon",
          "Kim Yu",
          "Byeongho Heo",
          "Dongyoon Han",
          "Seong Joon",
          "Hyun Oh"
        ],
        "url": "https://openaccess.thecvf.com/content/ICCV2023/papers/Hyeon-Woo_Scratching_Visual_Transformers_Back_with_Uniform_Attention_ICCV_2023_paper.pdf",
        "ref_texts": "[65] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017. 8",
        "ref_ids": [
          "65"
        ]
      },
      "Review of visual simultaneous localization and mapping based on deep learning": {
        "authors": [
          "Yao Zhang",
          "Yiquan Wu",
          "Kang Tong",
          "Huixian Chen",
          "Yubin Yuan"
        ],
        "url": "https://www.mdpi.com/2072-4292/15/11/2740/pdf",
        "ref_texts": "109. Zhao, H.; Shi, J.; Qi, X.; Wang, X.; Jia, J. Pyramid Scene Parsing Network. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Honolulu, HI, USA, 21\u201326 July 2017; pp. 6230\u20136239.",
        "ref_ids": [
          "109"
        ]
      },
      "Leverage interactive affinity for affordance learning": {
        "authors": [
          "Hongchen Luo",
          "Wei Zhai",
          "Jing Zhang",
          "Yang Cao",
          "Dacheng Tao"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Luo_Leverage_Interactive_Affinity_for_Affordance_Learning_CVPR_2023_paper.pdf",
        "ref_texts": "[67] Wei Zhai, Hongchen Luo, Jing Zhang, Yang Cao, and Dacheng Tao. One-shot object affordance detection in the wild. International Journal of Computer Vision , 130(10):2472\u20132500, 2022. 2, 3, 5[68] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017. 5, 6, 8",
        "ref_ids": [
          "67",
          "68"
        ]
      },
      "Cfpnet-m: A light-weight encoder-decoder based network for multimodal biomedical image real-time segmentation": {
        "authors": [
          "Lou Ange"
        ],
        "url": "https://arxiv.org/pdf/2105.04075",
        "ref_texts": "[54] H. Zhao, J. Shi, . Qi, . Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition , pp. 2881 \u20132890, 2017. ",
        "ref_ids": [
          "54"
        ]
      },
      "Dental caries detection using a semi-supervised learning approach": {
        "authors": [
          "Adnan Qayyum"
        ],
        "url": "https://www.nature.com/articles/s41598-023-27808-9.pdf",
        "ref_texts": ""
      },
      "Detecting building changes with off-nadir aerial images": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2301.10922",
        "ref_texts": "37 Zhao, Hengshuang and Shi, Jianping and Qi, Xiaojuan and Wang, Xiaogang and Jia, Jiaya. Pyramid scene parsing network. IN: Proceedings of the IEEE conference on computer vision and pattern recognition, 2017. 2881\u20132890"
      },
      "Towards open-world segmentation of parts": {
        "authors": [
          "Yu Pan",
          "Qing Liu",
          "Lun Chao",
          "Brian Price"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Pan_Towards_Open-World_Segmentation_of_Parts_CVPR_2023_paper.pdf",
        "ref_texts": "[47] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017. 2",
        "ref_ids": [
          "47"
        ]
      },
      "AST: Adaptive Self-supervised Transformer for optical remote sensing representation": {
        "authors": [
          "Qibin He"
        ],
        "url": "https://research.utwente.nl/files/420750419/1-s2.0-S0924271623000928-main.pdf",
        "ref_texts": "59 (8), 6549\u20136561. Wang, W., Yao, L., Chen, L., Lin, B., Cai, D., He, X., Liu, W., 2021. CrossFormer: A versatile vision transformer hinging on cross-scale attention. arXiv preprint arXiv:2108.00154. Wang, D., Zhang, J., Du, B., Xia, G.-S., Tao, D., 2022. An empirical study of remote sensing pretraining. IEEE Trans. Geosci. Remote Sens.. Waqas Zamir, S., Arora, A., Gupta, A., Khan, S., Sun, G., Shahbaz Khan, F., Zhu, F., Shao, L., Xia, G.-S., Bai, X., 2019. Isaid: A large-scale dataset for instance segmentation in aerial images. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops. pp. 28\u201337. Woo, S., Park, J., Lee, J.-Y., Kweon, I.S., 2018. Cbam: Convolutional block attention module. In: Proceedings of the European Conference on Computer Vision. ECCV, pp. 3\u201319. Xia, G.-S., Hu, J., Hu, F., Shi, B., Bai, X., Zhong, Y., Zhang, L., Lu, X., 2017. AID: A benchmark data set for performance evaluation of aerial scene classification. IEEE Trans. Geosci. Remote Sens. 55 (7), 3965\u20133981. Xiao, T., Liu, Y., Zhou, B., Jiang, Y., Sun, J., 2018. Unified perceptual parsing for scene understanding. In: Proceedings of the European Conference on Computer Vision. ECCV, pp. 418\u2013434. Xu, K., Huang, H., Deng, P., Li, Y., 2021. Deep feature aggregation framework driven by graph convolutional network for scene classification in remote sensing. IEEE Trans. Neural Netw. Learn. Syst.. Yang, Y., Newsam, S., 2010. Bag-of-visual-words and spatial extensions for land-use classification. In: Proceedings of the 18th SIGSPATIAL International Conference on Advances in Geographic Information Systems. pp. 270\u2013279. Yang, X., Yan, J., Liao, W., Yang, X., Tang, J., He, T., 2022. Scrdet++: Detecting small, cluttered and rotated objects via instance-level feature denoising and rotation loss smoothing. IEEE Trans. Pattern Anal. Mach. Intell.. Yang, M., Yu, K., Zhang, C., Li, Z., Yang, K., 2018. Denseaspp for semantic segmentation in street scenes. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. pp. 3684\u20133692. Yu, Y., Liu, F., 2018. A two-stream deep fusion framework for high-resolution aerial scene classification. Comput. Intell. Neurosci. 2018. Yuan, Y., Chen, X., Wang, J., 2020. Object-contextual representations for semantic segmentation. In: European Conference on Computer Vision. Springer, pp. 173\u2013190. Zeng, D., Chen, S., Chen, B., Li, S., 2018. Improving remote sensing scene classification by integrating global-context and local-object features. Remote Sens. 10 (5), 734. Zhang, X., An, W., Sun, J., Wu, H., Zhang, W., Du, Y., 2021. Best representation branch model for remote sensing image scene classification. IEEE J. Sel. Top. Appl. Earth Obs. Remote Sens. 14, 9768\u20139780. Zhang, R., Isola, P., Efros, A.A., 2016. Colorful image colorization. In: European Conference on Computer Vision. Springer, pp. 649\u2013666. Zhang, W., Tang, P., Zhao, L., 2019. Remote sensing image scene classification using CNN-CapsNet. Remote Sens. 11 (5), 494. Zhang, J., Xie, C., Xu, X., Shi, Z., Pan, B., 2020. A contextual bidirectional enhancement method for remote sensing image object detection. IEEE J. Sel. Top. Appl. Earth Obs. Remote Sens. 13, 4518\u20134531. Zhao, Q., Lyu, S., Li, Y., Ma, Y., Chen, L., 2021a. MGML: Multigranularity multilevel feature ensemble network for remote sensing scene classification. IEEE Trans. Neural Netw. Learn. Syst.. Zhao, Q., Ma, Y., Lyu, S., Chen, L., 2021b. Embedded self-distillation in compact multibranch ensemble network for remote sensing scene classification. arXiv preprint arXiv:2104.00222. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J., 2017. Pyramid scene parsing network. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. pp. 2881\u20132890. Zheng, Z., Zhong, Y., Wang, J., Ma, A., 2020. Foreground-aware relation network for geospatial object segmentation in high spatial resolution remote sensing imagery. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 4096\u20134105."
      },
      "A small-target forest fire smoke detection model based on deformable transformer for end-to-end object detection": {
        "authors": [
          "Jingwen Huang",
          "Jiashun Zhou",
          "Huizhou Yang",
          "Yunfei Liu",
          "Han Liu"
        ],
        "url": "https://www.mdpi.com/1999-4907/14/1/162/pdf",
        "ref_texts": "34. Zhao, H.; Shi, J.; Qi, X.; Wang, X.; Jia, J. Pyramid Scene Parsing Network. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Honolulu, HI, USA, 21\u201326 July 2017; pp. 6230\u20136239.",
        "ref_ids": [
          "34"
        ]
      },
      "DiGA: Distil to generalize and then adapt for domain adaptive semantic segmentation": {
        "authors": [
          "Fengyi Shen",
          "Akhil Gurram",
          "Ziyuan Liu",
          "He Wang",
          "Alois Knoll"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2023/papers/Shen_DiGA_Distil_To_Generalize_and_Then_Adapt_for_Domain_Adaptive_CVPR_2023_paper.pdf",
        "ref_texts": ""
      },
      "MFBP-UNet: A network for pear leaf disease segmentation in natural agricultural environments": {
        "authors": [
          "Haoyu Wang",
          "Jie Ding",
          "Sifan He",
          "Cheng Feng",
          "Cheng Zhang",
          "Guohua Fan",
          "Yunzhi Wu",
          "Youhua Zhang"
        ],
        "url": "https://www.mdpi.com/2223-7747/12/18/3209/pdf",
        "ref_texts": "20. Zhao, H.; Shi, J.; Qi, X.; Wang, X.; Jia, J. Pyramid scene parsing network. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Honolulu, HI, USA, 21\u201326 July 2017; pp. 2881\u20132890.",
        "ref_ids": [
          "20"
        ]
      },
      "Self-pair: Synthesizing changes from single source for object change detection in remote sensing imagery": {
        "authors": [
          "Minseok Seo",
          "Hakjin Lee",
          "Yongjin Jeon",
          "Junghoon Seo"
        ],
        "url": "https://openaccess.thecvf.com/content/WACV2023/papers/Seo_Self-Pair_Synthesizing_Changes_From_Single_Source_for_Object_Change_Detection_WACV_2023_paper.pdf",
        "ref_texts": "[32] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 2881\u20132890, 2017.",
        "ref_ids": [
          "32"
        ]
      },
      "Learning to detect mirrors from videos via dual correspondences": {
        "authors": [
          "Jiaying Lin",
          "Xin Tan",
          "Rynson W"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Lin_Learning_To_Detect_Mirrors_From_Videos_via_Dual_Correspondences_CVPR_2023_paper.pdf",
        "ref_texts": "[46] Miao Zhang, Jie Liu, Yifei Wang, Yongri Piao, Shunyu Yao, Wei Ji, Jingjing Li, Huchuan Lu, and Zhongxuan Luo. Dynamic context-sensitive filtering network for video salient object detection. In ICCV , pages 1553\u20131563, 2021. 3[47] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , pages 2881\u20132890, 2017. 6,7",
        "ref_ids": [
          "46",
          "47"
        ]
      },
      "A dynamic effective class balanced approach for remote sensing imagery semantic segmentation of imbalanced data": {
        "authors": [
          "Zheng Zhou",
          "Change Zheng",
          "Xiaodong Liu",
          "Ye Tian",
          "Xiaoyi Chen",
          "Xuexue Chen",
          "Zixun Dong"
        ],
        "url": "https://www.mdpi.com/2072-4292/15/7/1768/pdf",
        "ref_texts": "24. Zhao, H.; Shi, J.; Qi, X.; Wang, X.; Jia, J. Pyramid Scene Parsing Network. In Proceedings of the 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Honolulu, HI, USA, 21\u201326 July 2017; pp. 6230\u20136239.",
        "ref_ids": [
          "24"
        ]
      },
      "Augmentation matters: A simple-yet-effective approach to semi-supervised semantic segmentation": {
        "authors": [
          "Zhen Zhao",
          "Lihe Yang",
          "Sifan Long",
          "Jimin Pi",
          "Luping Zhou",
          "Jingdong Wang"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2023/papers/Zhao_Augmentation_Matters_A_Simple-Yet-Effective_Approach_to_Semi-Supervised_Semantic_Segmentation_CVPR_2023_paper.pdf",
        "ref_texts": "[53] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017. 1",
        "ref_ids": [
          "53"
        ]
      },
      "Exchanging dual-encoder\u2013decoder: A new strategy for change detection with semantic guidance and spatial localization": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2311.11302",
        "ref_texts": "[42] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "42"
        ]
      },
      "An approach for plant leaf image segmentation based on YOLOV8 and the improved DEEPLABV3+": {
        "authors": [
          "Tingting Yang",
          "Suyin Zhou",
          "Aijun Xu",
          "Junhua Ye",
          "Jianxin Yin"
        ],
        "url": "https://www.mdpi.com/2223-7747/12/19/3438/pdf",
        "ref_texts": "18. Zhao, H.; Shi, J.; Qi, X.; Wang, X.; Jia, J. Pyramid scene parsing network. In Proceedings of the 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Honolulu, HI, USA, 21\u201326 July 2016. [CrossRef] Plants 2023 ,12, 3438 17 of 17",
        "ref_ids": [
          "18"
        ]
      },
      "MCAFNet: A multiscale channel attention fusion network for semantic segmentation of remote sensing images": {
        "authors": [
          "Min Yuan",
          "Dingbang Ren",
          "Qisheng Feng",
          "Zhaobin Wang",
          "Yongkang Dong",
          "Fuxiang Lu",
          "Xiaolin Wu"
        ],
        "url": "https://www.mdpi.com/2072-4292/15/2/361/pdf",
        "ref_texts": "11. Zhao, H.; Shi, J.; Qi, X.; Wang, X.; Jia, J. Pyramid scene parsing network. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Honolulu, HI, USA, 21\u201326 July 2017; pp. 2881\u20132890.",
        "ref_ids": [
          "11"
        ]
      },
      "A diagnostic classification of lung nodules using multiple-scale residual network": {
        "authors": [
          "Hongfeng Wang"
        ],
        "url": "https://www.nature.com/articles/s41598-023-38350-z.pdf",
        "ref_texts": ""
      },
      "Boosting night-time scene parsing with learnable frequency": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2208.14241",
        "ref_texts": "[5] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition , pp. 2881\u20132890, 2017.",
        "ref_ids": [
          "5"
        ]
      },
      "Discriminative kernel convolution network for multi-label ophthalmic disease detection on imbalanced fundus image dataset": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2207.07918",
        "ref_texts": "[34] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "34"
        ]
      },
      "MU-Net: Embedding MixFormer into Unet to Extract Water Bodies from Remote Sensing Images": {
        "authors": [
          "Yonghong Zhang",
          "Huanyu Lu",
          "Guangyi Ma",
          "Huajun Zhao",
          "Donglin Xie",
          "Sutong Geng",
          "Wei Tian",
          "Kenny Thiam",
          "Choy Lim",
          "Kam Sian"
        ],
        "url": "https://www.mdpi.com/2072-4292/15/14/3559/pdf",
        "ref_texts": "28. Zhao, H.; Shi, J.; Qi, X.; Wang, X.; Jia, J. Pyramid Scene Parsing Network. In Proceedings of the 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Honolulu, HI, USA, 21\u201326 July 2017; pp. 6230\u20136239.",
        "ref_ids": [
          "28"
        ]
      },
      "Cospgd: a unified white-box adversarial attack for pixel-wise prediction tasks": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2302.02213",
        "ref_texts": "1611.05431 . Xu, X., Zhao, H., and Jia, J. Dynamic divide-and-conquer adversarial training for robust semantic segmentation. In2021 IEEE/CVF International Conference on Computer Vision (ICCV) , pp. 7466\u20137475, 2021. doi: 10.1109/ ICCV48922.2021.00739. Zamir, S. W., Arora, A., Khan, S., Hayat, M., Khan, F. S., and Yang, M.-H. Restormer: Efficient transformer for high-resolution image restoration. In CVPR , 2022. Zhang, J., Chen, L., Liu, B., Ouyang, B., Xie, Q., Zhu, J., Li, W., and Meng, Y . 3d adversarial attacks beyond point cloud, 2021. URL https://arxiv.org/ abs/2104.12146 . Zhao, H. semseg. https://github.com/hszhao/ semseg , 2019. Zhao, H., Shi, J., Qi, X., Wang, X., and Jia, J. Pyramid scene parsing network. In CVPR , 2017. Zhou, B., Zhao, H., Puig, X., Fidler, S., Barriuso, A., and Torralba, A. Scene parsing through ade20k dataset. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , 2017."
      },
      "LDFA: Latent diffusion face anonymization for self-driving applications": {
        "authors": [
          "Marvin Klemp",
          "Kevin Rosch",
          "Royden Wagner",
          "Jannik Quehl",
          "Martin Lauer"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2023W/E2EAD/papers/Klemp_LDFA_Latent_Diffusion_Face_Anonymization_for_Self-Driving_Applications_CVPRW_2023_paper.pdf",
        "ref_texts": "[34] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "34"
        ]
      },
      "Lightweight and progressively-scalable networks for semantic segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2207.13600",
        "ref_texts": "(2019) Customizable architecture search for semantic segmentation. In: 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pp 11633\u201311642, DOI 10.1109/CVPR.2019.01191 Zhao H, Shi J, Qi X, Wang X, Jia J (2017) Pyramid scene parsing network. In: 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp 6230\u20136239, DOI 10.1109/CVPR.2017.660 Zhao H, Qi X, Shen X, Shi J, Jia J (2018) Icnet for real-time semantic segmentation on high-resolution images. In: European Conference on Computer Vision (ECCV)"
      },
      "A medical image segmentation method based on improved UNet 3+ network": {
        "authors": [
          "Yang Xu",
          "Shike Hou",
          "Xiangyu Wang",
          "Duo Li",
          "Lu Lu"
        ],
        "url": "https://www.mdpi.com/2075-4418/13/3/576/pdf",
        "ref_texts": "9. Zhao, H.S.; Shi, J.P .; Qi, X.J.; Wang, X.G.; Jia, J.Y. Pyramid Scene Parsing Network. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Honolulu, HI, USA, 21\u201326 July 2017; pp. 6230\u20136239.",
        "ref_ids": [
          "9"
        ]
      },
      "A hybrid algorithm with Swin transformer and convolution for cloud detection": {
        "authors": [
          "Chengjuan Gong",
          "Tengfei Long",
          "Ranyu Yin",
          "Weili Jiao",
          "Guizhou Wang"
        ],
        "url": "https://www.mdpi.com/2072-4292/15/21/5264/pdf",
        "ref_texts": "55. Zhao, H.; Shi, J.; Qi, X.; Wang, X.; Jia, J. Pyramid Scene Parsing Network. arXiv 2017 , arXiv:1612.01105.",
        "ref_ids": [
          "55"
        ]
      },
      "RescueNet: a high resolution UAV semantic segmentation dataset for natural disaster damage assessment": {
        "authors": [
          "Maryam Rahnemoonfar"
        ],
        "url": "https://www.nature.com/articles/s41597-023-02799-4.pdf",
        "ref_texts": ""
      },
      "Self-adversarial disentangling for specific domain adaptation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2108.03553"
      },
      "On the real-world adversarial robustness of real-time semantic segmentation models for autonomous driving": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2201.01850",
        "ref_texts": "[8] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2017, pp. 6230\u20136239.",
        "ref_ids": [
          "8"
        ]
      },
      "Subjective and objective measures of streetscape perceptions: Relationships with property value in Shanghai": {
        "authors": [],
        "url": "https://www.preprints.org/manuscript/202103.0506/download/final_file",
        "ref_texts": "1741. https://doi.org/10.3390/su11061741 Yin, L., Cheng, Q., Wang, Z., & Shao, Z. (2015). \u2018Big data\u2019 for pedestrian volume: Exploring the use of Google Street View images for pedestrian counts. Applied Geography , 63, 337\u2013345. https://doi.org/10.1016/j.apgeog.2015.07.010 Yin, L., & Wang, Z. (2016). Measuring visual enclosure for street walkability: Using machine learning algorithms and Google Street View imagery. Applied Geography , 76, 147\u2013153. https://doi.org/10.1016/j.apgeog.2016.09.024 Zeng, L., Lu, J., Li, W., & Li, Y. (2018). A fast approach for large-scale Sky View Factor estimation using street view images. Building and Environment , 135, 74\u201384. https://doi.org/10.1016/j.buildenv.2018.03.009 Zhang, F., Zhou, B., Liu, L., Liu, Y., Fung, H. H., Lin, H., & Ratti, C. (2018). Measuring human perceptions of a large-scale urban region using machine learning. Landscape and Urban Planning , 180, 148\u2013160. https://doi.org/10.1016/j.landurbplan.2018.08.020 Zhang, Y., & Dong, R. (2018). Impacts of Street-Visible Greenery on Housing Prices: Evidence from a Hedonic Price Model and a Massive Street View Image Dataset in Beijing. ISPRS International Journal of GeoInformation , 7(3), 104. https://doi.org/10.3390/ijgi7030104 Zhao, H., Shi, J., Qi, X., Wang, X., & Jia, J. (2016). Pyramid Scene Parsing Network . https://arxiv.org/abs/1612.01105v2 Zhou, H., He, S., Cai, Y., Wang, M., & Su, S. (2019). Social inequalities in neighborhood visual walkability: Using street view imagery and deep learning technologies to facilitate healthy city planning. Sustainable Cities and Society, 50, 101605. https://doi.org/10.1016/j.scs.2019.101605 ",
        "ref_ids": [
          "1741"
        ]
      },
      "Research on road scene understanding of autonomous vehicles based on multi-task learning": {
        "authors": [
          "Jinghua Guo",
          "Jingyao Wang",
          "Huinian Wang",
          "Baoping Xiao",
          "Zhifei He",
          "Lubin Li"
        ],
        "url": "https://www.mdpi.com/1424-8220/23/13/6238/pdf",
        "ref_texts": "19. Zhao, H.; Shi, J.; Qi, X.; Wang, X.; Jia, J. Pyramid scene parsing network. In Proceedings of the 2017 IEEE Conference on Computer Vision and Pattern Recognition, Honolulu, HI, USA, 21\u201326 July 2017; pp. 2881\u20132890.",
        "ref_ids": [
          "19"
        ]
      },
      "Large-scale date palm tree segmentation from multiscale uav-based and aerial images using deep vision transformers": {
        "authors": [
          "Mohamed Barakat",
          "Helmi Zulhaidi",
          "Mohd Shafri",
          "Rami Al",
          "Abdallah Shanableh",
          "Faten Nahas",
          "Saeed Al"
        ],
        "url": "https://www.mdpi.com/2504-446X/7/2/93/pdf",
        "ref_texts": "35. Zhao, H.; Shi, J.; Qi, X.; Wang, X.; Jia, J. Pyramid scene parsing network. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR 2017), Honolulu, HI, USA, 21\u201326 July 2017; pp. 6230\u20136239.",
        "ref_ids": [
          "35"
        ]
      },
      "RoadFormer: road extraction using a swin transformer combined with a spatial and channel separable convolution": {
        "authors": [
          "Xiangzeng Liu",
          "Ziyao Wang",
          "Jinting Wan",
          "Juli Zhang",
          "Yue Xi",
          "Ruyi Liu",
          "Qiguang Miao"
        ],
        "url": "https://www.mdpi.com/2072-4292/15/4/1049/pdf",
        "ref_texts": "20. Zhao, H.; Shi, J.; Qi, X.; Wang, X.; Jia, J. Pyramid Scene Parsing Network. In Proceedings of the 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Honolulu, HI, USA, 21\u201326 July 2017; pp. 6230\u20136239.",
        "ref_ids": [
          "20"
        ]
      },
      "MLMRS-Net: Electroencephalography (EEG) motion artifacts removal using a multi-layer multi-resolution spatially pooled 1D signal reconstruction network": {
        "authors": [
          "Sakib Mahmud"
        ],
        "url": "https://link.springer.com/content/pdf/10.1007/s00521-022-08111-6.pdf",
        "ref_texts": "72. Zhao H, Shi J, Qi X, Wang X, Jia J (2017) Pyramid scene parsing network. In: Proceedings of the IEEE conference on computer vision and pattern recognition , pp 2881\u20132890",
        "ref_ids": [
          "72"
        ]
      },
      "Improving nighttime driving-scene segmentation via dual image-adaptive learnable filters": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2207.01331"
      },
      "MapPrior: Bird's-Eye View Map Layout Estimation with Generative Models": {
        "authors": [
          "Xiyue Zhu",
          "Vlas Zyrianov",
          "Zhijian Liu",
          "Shenlong Wang"
        ],
        "url": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_MapPrior_Birds-Eye_View_Map_Layout_Estimation_with_Generative_Models_ICCV_2023_paper.pdf",
        "ref_texts": "[85] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017. 2",
        "ref_ids": [
          "85"
        ]
      },
      "Pixel difference convolutional network for rgb-d semantic segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2302.11951",
        "ref_texts": "[44] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "44"
        ]
      },
      "Scotch and soda: A transformer video shadow detection framework": {
        "authors": [
          "Lihao Liu",
          "Jean Prost",
          "Lei Zhu",
          "Nicolas Papadakis",
          "Pietro Lio",
          "Bibiane Schonlieb",
          "Angelica I. Aviles"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2023/papers/Liu_SCOTCH_and_SODA_A_Transformer_Video_Shadow_Detection_Framework_CVPR_2023_paper.pdf",
        "ref_texts": "[42] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017. 2, 6",
        "ref_ids": [
          "42"
        ]
      },
      "Environment semantics aided wireless communications: A case study of mmWave beam prediction and blockage prediction": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2301.05837",
        "ref_texts": "[23] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit.",
        "ref_ids": [
          "23"
        ]
      },
      "Prediction calibration for generalized few-shot semantic segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2210.08290",
        "ref_texts": "[2] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in CVPR , 2017.",
        "ref_ids": [
          "2"
        ]
      },
      "Road extraction with satellite images and partial road maps": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2303.12394",
        "ref_texts": "[45] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "45"
        ]
      },
      "Peanut: Predicting and navigating to unseen targets": {
        "authors": [
          "Albert J. Zhai",
          "Shenlong Wang"
        ],
        "url": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhai_PEANUT_Predicting_and_Navigating_to_Unseen_Targets_ICCV_2023_paper.pdf",
        "ref_texts": "[46] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017. 5, 7",
        "ref_ids": [
          "46"
        ]
      },
      "Children's dental panoramic radiographs dataset for caries segmentation and dental disease detection": {
        "authors": [
          "Yifan Zhang"
        ],
        "url": "https://www.nature.com/articles/s41597-023-02237-5.pdf",
        "ref_texts": "\u2022\tPSPNet 24. Pyramid Scene Parsing Network (PSPNet) is applied to scene parsing tasks and is often used to do semantic segmentation, which introduces more contextual information in the semantic segmentation algo-rithm achieved by global mean pooling manipulation and feature fusion to avoid many missegmentations."
      },
      "Quantifying atomically dispersed catalysts using deep learning assisted microscopy": {
        "authors": [],
        "url": "https://www.osti.gov/pages/servlets/purl/2439857",
        "ref_texts": "(22) Zhao, H.; Shi, J.; Qi, X.; Wang, X.; Jia, J. Pyramid Scene Parsing Network. 2016. https://doi.org/10.48550/ARXIV.1612.01105."
      },
      "Detection of colorectal polyps from colonoscopy using machine learning: A survey on modern techniques": {
        "authors": [
          "Khaled E",
          "Valliappan Raman",
          "Patrick Then",
          "Caslon Chua"
        ],
        "url": "https://www.mdpi.com/1424-8220/23/3/1225/pdf",
        "ref_texts": "45. Zhao, H.; Shi, J.; Qi, X.; Wang, X.; Jia, J. Pyramid scene parsing network. In Proceedings of the 30th IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2017, Honolulu, HI, USA, 21\u201326 July 2017; pp. 6230\u20136239. [CrossRef]",
        "ref_ids": [
          "45"
        ]
      },
      "Leveraging deep learning techniques to obtain efficacious segmentation results": {
        "authors": [],
        "url": "http://ojs.bonviewpress.com/index.php/AAES/article/download/1220/585",
        "ref_texts": "(2021). Toward accurate and reliable iris segmentation usinguncertainty learning. arXiv preprint:2110.10334 . Wei, Y., Zeng, A., Zhang, X., & Huang, H. (2022). RAG-Net: ResNet-50 attention gate network for accurate irissegmentation. IET Image Processing ,16(11), 3057 \u20133066.Woo, S., Park, J., Lee, J. Y., & Kweon, I. S. (2018). CBAM: Convolutional block attention module. In Proceedings of the European Conference on Computer Vision ,3\u201319. Yu, F., & Koltun, V. (2015). Multi-scale context aggregation by dilated convolutions. arXiv preprint:1511.07122 . Zhang, S., Yang, J., & Schiele, B. (2018). Occluded pedestrian detection through guided attention in CNNs. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , 6995 \u20137003. Zhang, W., Lu, X., Gu, Y., Liu, Y., Meng, X., & Li, J. (2019). A robust iris segmentation scheme based on improved U-net. IEEE Access ,7, 85082 \u201385089. Zhang, Z., Fidler, S., & Urtasun, R. (2016). Instance-level segmentation for autonomous driving with deep denselyconnected MRFs. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , 669 \u2013677. Zhao, H., Shi, J., Qi, X., Wang, X., & Jia, J. (2017). Pyramid scene parsing network. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , 2881 \u20132890. Zhao, L., Zhou, D., Jin, X., & Zhu, W. (2022). nn-TransUNet: An automatic deep learning pipeline for heart MRIsegmentation. Life,12(10), 1570. Zhao, X., Wu, Y., Song, G., Li, Z., Zhang, Y., & Fan, Y. (2018). A deep learning model integrating FCNNs and CRFs forbrain tumor segmentation. Medical Image Analysis, 43 , 98\u2013111. Zhao, Z., & Kumar, A. (2017). Towards more accurate iris recognition using deeply learned spatially corresponding features. In Proceedings of the IEEE International Conference on Computer Vision , 3809 \u20133818. Zhou, C., & Yuan, J. (2018). Bi-box regression for pedestrian detection and occlusion estimation. In Proceedings of the European Conference on Computer Vision , 135 \u2013151. Zhou, Z., Rahman Siddiquee, M. M., Tajbakhsh, N., & Liang, J."
      },
      "Denoising diffusion semantic segmentation with mask prior modeling": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2306.01721",
        "ref_texts": "[85] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017. 1, 2, 3, 4, 7",
        "ref_ids": [
          "85"
        ]
      },
      "FBC-ANet: A semantic segmentation model for UAV forest fire images combining boundary enhancement and context awareness": {
        "authors": [
          "Lin Zhang",
          "Mingyang Wang",
          "Yunhong Ding",
          "Tingting Wan",
          "Bo Qi",
          "Yutian Pang"
        ],
        "url": "https://www.mdpi.com/2504-446X/7/7/456/pdf",
        "ref_texts": "30. Zhao, H.; Shi, J.; Qi, X.; Wang, X.; Jia, J. Pyramid Scene Parsing Network. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Honolulu, HI, USA, 21\u201326 July 2017; pp. 6230\u20136239.",
        "ref_ids": [
          "30"
        ]
      },
      "Monopgc: Monocular 3d object detection with pixel geometry contexts": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2302.10549",
        "ref_texts": "[39] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in IEEE Conf. on Computer Vision and Pattern Recognition (CVPR) , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "39"
        ]
      },
      "Classification and segmentation of OCT images for age-related macular degeneration based on dual guidance networks": {
        "authors": [
          "Shengyong Diao"
        ],
        "url": "http://www.mipav.net/MIPAV%20Papers/dsy_BSPC.pdf",
        "ref_texts": "[36] H. Zhao, J. Shi, X. Qi, X. Wang, Pyramid scene parsing network, Computer Vision Pattern Recognition 1 (2016) 6230\u20136239. ",
        "ref_ids": [
          "36"
        ]
      },
      "Lightweight deep learning methods for panoramic dental X-ray image segmentation": {
        "authors": [
          "Songyue Lin"
        ],
        "url": "https://link.springer.com/content/pdf/10.1007/s00521-022-08102-7.pdf",
        "ref_texts": "40. Zhao H, Shi J, Qi X, Wang X, Jia J (2017) Pyramid scene parsing network. In: Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 2881\u20132890Neural Computing and Applications (2023) 35:8295\u20138306 8305",
        "ref_ids": [
          "40"
        ]
      },
      "Towards Deeply Unified Depth-aware Panoptic Segmentation with Bi-directional Guidance Learning": {
        "authors": [
          "Junwen He",
          "Yifan Wang",
          "Lijun Wang",
          "Huchuan Lu",
          "Bin Luo",
          "Yan He",
          "Peng Lan",
          "Yifeng Geng",
          "Xuansong Xie"
        ],
        "url": "http://openaccess.thecvf.com/content/ICCV2023/papers/He_Towards_Deeply_Unified_Depth-aware_Panoptic_Segmentation_with_Bi-directional_Guidance_Learning_ICCV_2023_paper.pdf",
        "ref_texts": "[59] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017. 2",
        "ref_ids": [
          "59"
        ]
      },
      "Mixed receptive fields augmented YOLO with multi-path spatial pyramid pooling for steel surface defect detection": {
        "authors": [
          "Kewen Xia",
          "Zhongliang Lv",
          "Chuande Zhou",
          "Guojun Gu",
          "Zhiqiang Zhao",
          "Kang Liu",
          "Zelun Li"
        ],
        "url": "https://www.mdpi.com/1424-8220/23/11/5114/pdf",
        "ref_texts": "35. Zhao, H.; Shi, J.; Qi, X.; Wang, X.; Jia, J. Pyramid scene parsing network. In Proceedings of the 2017 IEEE Conference on Computer Vision and Pattern Recognition(CVPR), Honolulu, HI, USA, 21\u201326 July 2017; pp. 2881\u20132890.",
        "ref_ids": [
          "35"
        ]
      },
      "Deep learning methods for semantic segmentation in remote sensing with small data: A survey": {
        "authors": [
          "Anzhu Yu",
          "Yujun Quan",
          "Ru Yu",
          "Wenyue Guo",
          "Xin Wang",
          "Danyang Hong",
          "Haodi Zhang",
          "Junming Chen",
          "Qingfeng Hu",
          "Peipei He"
        ],
        "url": "https://www.mdpi.com/2072-4292/15/20/4987/pdf",
        "ref_texts": "11. Zhao, H.; Shi, J.; Qi, X.; Wang, X.; Jia, J. Pyramid Scene Parsing Network. arXiv 2017 , arXiv:1612.01105.",
        "ref_ids": [
          "11"
        ]
      },
      "Few shot semantic segmentation: a review of methodologies and open challenges": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2304.05832",
        "ref_texts": "[138] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. 2017. Pyramid scene parsing network. In IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) .",
        "ref_ids": [
          "138"
        ]
      },
      "CaraNet: context axial reverse attention network for segmentation of small medical objects": {
        "authors": [
          "Lou Ange"
        ],
        "url": "https://arxiv.org/pdf/2108.07368",
        "ref_texts": "[15] Zhao, H., Shi, J., Qi, X., Wang, X., & Jia, J. (2017). Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 2881 -2890). ",
        "ref_ids": [
          "15"
        ]
      },
      "Boosting semantic segmentation from the perspective of explicit class embeddings": {
        "authors": [
          "Yuhe Liu",
          "Chuanjian Liu",
          "Kai Han",
          "Quan Tang",
          "Zengchang Qin"
        ],
        "url": "http://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Boosting_Semantic_Segmentation_from_the_Perspective_of_Explicit_Class_Embeddings_ICCV_2023_paper.pdf",
        "ref_texts": "[56] Wenwei Zhang, Jiangmiao Pang, Kai Chen, and Chen Change Loy. K-net: Towards unified image segmentation. Advances in Neural Information Processing Systems , 34:10326\u201310338, 2021. 1, 2, 5, 6, 7[57] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017. 7",
        "ref_ids": [
          "56",
          "57"
        ]
      },
      "Draw: Defending camera-shooted raw against image manipulation": {
        "authors": [
          "Xiaoxiao Hu",
          "Qichao Ying",
          "Zhenxing Qian",
          "Sheng Li",
          "Xinpeng Zhang"
        ],
        "url": "http://openaccess.thecvf.com/content/ICCV2023/papers/Hu_DRAW_Defending_Camera-shooted_RAW_Against_Image_Manipulation_ICCV_2023_paper.pdf",
        "ref_texts": ""
      },
      "Semantic segmentation in aerial imagery using multi-level contrastive learning with local consistency": {
        "authors": [
          "Maofeng Tang",
          "Konstantinos Georgiou",
          "Hairong Qi",
          "Cody Champion",
          "Marc Bosch"
        ],
        "url": "https://openaccess.thecvf.com/content/WACV2023/papers/Tang_Semantic_Segmentation_in_Aerial_Imagery_Using_Multi-Level_Contrastive_Learning_With_WACV_2023_paper.pdf",
        "ref_texts": "[44] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "44"
        ]
      },
      "MFTSC: A semantically constrained method for urban building height estimation using multiple source images": {
        "authors": [
          "Yuhan Chen",
          "Qingyun Yan",
          "Weimin Huang"
        ],
        "url": "https://www.mdpi.com/2072-4292/15/23/5552/pdf",
        "ref_texts": "52. Zhao, H.; Shi, J.; Qi, X.; Wang, X.; Jia, J. Pyramid scene parsing network. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Honolulu, HI, USA, 21\u201326 July 2017; pp. 2881\u20132890.",
        "ref_ids": [
          "52"
        ]
      },
      "Delving into shape-aware zero-shot semantic segmentation": {
        "authors": [
          "Xinyu Liu",
          "Beiwen Tian",
          "Zhen Wang",
          "Rui Wang",
          "Kehua Sheng",
          "Bo Zhang",
          "Hao Zhao",
          "Guyue Zhou"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2023/papers/Liu_Delving_Into_Shape-Aware_Zero-Shot_Semantic_Segmentation_CVPR_2023_paper.pdf",
        "ref_texts": "[61] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017. 1",
        "ref_ids": [
          "61"
        ]
      },
      "A novel medical decision-making system based on multi-scale feature enhancement for small samples": {
        "authors": [
          "Keke He",
          "Yue Qin",
          "Fangfang Gou",
          "Jia Wu"
        ],
        "url": "https://www.mdpi.com/2227-7390/11/9/2116/pdf",
        "ref_texts": "52. Zhao, H.; Shi, J.; Qi, X.; Wang, X.; Jia, J. Pyramid Scene Parsing Network. In Proceedings of the 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Honolulu, HI, USA, 21\u201326 July 2017; pp. 6230\u20136239.",
        "ref_ids": [
          "52"
        ]
      },
      "Patchzero: Defending against adversarial patch attacks by detecting and zeroing the patch": {
        "authors": [
          "Ke Xu",
          "Yao Xiao",
          "Zhaoheng Zheng",
          "Kaijie Cai",
          "Ram Nevatia"
        ],
        "url": "https://openaccess.thecvf.com/content/WACV2023/papers/Xu_PatchZero_Defending_Against_Adversarial_Patch_Attacks_by_Detecting_and_Zeroing_WACV_2023_paper.pdf",
        "ref_texts": "[50] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "50"
        ]
      },
      "Independent component alignment for multi-task learning": {
        "authors": [
          "Dmitry Senushkin",
          "Nikolay Patakin",
          "Arseny Kuznetsov",
          "Anton Konushin"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Senushkin_Independent_Component_Alignment_for_Multi-Task_Learning_CVPR_2023_paper.pdf",
        "ref_texts": "[57] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , pages 6230\u20136239, 2017.",
        "ref_ids": [
          "57"
        ]
      },
      "Msi: Maximize support-set information for few-shot segmentation": {
        "authors": [
          "Seonghyeon Moon",
          "Samuel S. Sohn",
          "Honglu Zhou",
          "Sejong Yoon",
          "Vladimir Pavlovic",
          "Muhammad Haris",
          "Mubbasir Kapadia"
        ],
        "url": "https://openaccess.thecvf.com/content/ICCV2023/papers/Moon_MSI_Maximize_Support-Set_Information_for_Few-Shot_Segmentation_ICCV_2023_paper.pdf",
        "ref_texts": "[38] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid Scene Parsing Network. In Proceedings of IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) , pages 6230\u20136239, 2017. 1",
        "ref_ids": [
          "38"
        ]
      },
      "Disentangle then Parse: Night-time Semantic Segmentation with Illumination Disentanglement": {
        "authors": [
          "Zhixiang Wei",
          "Lin Chen",
          "Tao Tu",
          "Pengyang Ling",
          "Huaian Chen",
          "Yi Jin"
        ],
        "url": "http://openaccess.thecvf.com/content/ICCV2023/papers/Wei_Disentangle_then_Parse_Night-time_Semantic_Segmentation_with_Illumination_Disentanglement_ICCV_2023_paper.pdf",
        "ref_texts": "[54] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017. 2,6",
        "ref_ids": [
          "54"
        ]
      },
      "Extraction of vascular wall in carotid ultrasound via a novel boundary-delineation network": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2207.13868",
        "ref_texts": "[21] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201din ProceedingsoftheIEEEconferenceoncomputervision and pattern recognition , pp. 2881\u20132890, 2017.",
        "ref_ids": [
          "21"
        ]
      },
      "A multi-scale interactive U-Net for pulmonary vessel segmentation method based on transfer learning": {
        "authors": [
          "Rencheng Wu"
        ],
        "url": "https://hexo-img.obs.cn-east-3.myhuaweicloud.com/img/202302111237006.pdf",
        "ref_texts": "[27] H. Zhao, J. Shi, X. Qi, X. Wang, J. Jia, Pyramid Scene Parsing Network, IEEE Computer Society, 2016.",
        "ref_ids": [
          "27"
        ]
      },
      "Semantic-aware video compression for automotive cameras": {
        "authors": [],
        "url": "https://wrap.warwick.ac.uk/175063/1/WRAP-Semantic-aware-video-compression-automotive-cameras-23.pdf",
        "ref_texts": "[36] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in in Proc. IEEE Conf. Comput. Vis. Pattern Recognit. , 2017, pp. 2881\u20132890. IEEE TRANSACTIONS ON INTELLIGENT VEHICLES, VOL. , NO. , 2022 11",
        "ref_ids": [
          "36"
        ]
      },
      "Artificial intelligence-aided diagnosis solution by enhancing the edge features of medical images": {
        "authors": [
          "Baolong Lv",
          "Feng Liu",
          "Yulin Li",
          "Jianhua Nie",
          "Fangfang Gou",
          "Jia Wu"
        ],
        "url": "https://www.mdpi.com/2075-4418/13/6/1063/pdf",
        "ref_texts": "58. Zhao, H.; Shi, J.; Qi, X.; Wang, X.; Jia, J. Pyramid scene parsing network. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Honolulu, HI, USA, 21\u201326 July 2017; pp. 2881\u20132890.",
        "ref_ids": [
          "58"
        ]
      },
      "Truly scale-equivariant deep nets with fourier layers": {
        "authors": [],
        "url": "https://proceedings.neurips.cc/paper_files/paper/2023/file/1343edb2739a61a6e20bd8764e814b50-Paper-Conference.pdf",
        "ref_texts": "[53] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In Proc. CVPR , 2017. 1",
        "ref_ids": [
          "53"
        ]
      },
      "MBCNet: Multi-branch collaborative change-detection network based on Siamese structure": {
        "authors": [
          "Dehao Wang",
          "Liguo Weng",
          "Min Xia",
          "Haifeng Lin"
        ],
        "url": "https://www.mdpi.com/2072-4292/15/9/2237/pdf",
        "ref_texts": "35. Zhao, H.; Shi, J.; Qi, X.; Wang, X.; Jia, J. Pyramid scene parsing network. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Honolulu, HI, USA, 21\u201326 July 2017; pp. 2881\u20132890.",
        "ref_ids": [
          "35"
        ]
      },
      "Dejavu: Conditional regenerative learning to enhance dense prediction": {
        "authors": [
          "Shubhankar Borse",
          "Debasmit Das",
          "Hyojin Park",
          "Hong Cai",
          "Risheek Garrepalli",
          "Fatih Porikli"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2023/papers/Borse_DejaVu_Conditional_Regenerative_Learning_To_Enhance_Dense_Prediction_CVPR_2023_paper.pdf",
        "ref_texts": "[95] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017. 2",
        "ref_ids": [
          "95"
        ]
      },
      "Dense 2D-3D Indoor Prediction with Sound via Aligned Cross-Modal Distillation": {
        "authors": [
          "Heeseung Yun",
          "Joonil Na",
          "Gunhee Kim"
        ],
        "url": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yun_Dense_2D-3D_Indoor_Prediction_with_Sound_via_Aligned_Cross-Modal_Distillation_ICCV_2023_paper.pdf",
        "ref_texts": "[54] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017. 4, 7",
        "ref_ids": [
          "54"
        ]
      },
      "Probabilistic prompt learning for dense prediction": {
        "authors": [
          "Hyeongjun Kwon",
          "Taeyong Song",
          "Somi Jeong",
          "Jin Kim",
          "Jinhyun Jang",
          "Kwanghoon Sohn"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2023/papers/Kwon_Probabilistic_Prompt_Learning_for_Dense_Prediction_CVPR_2023_paper.pdf",
        "ref_texts": "[55] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017. 6",
        "ref_ids": [
          "55"
        ]
      },
      "Continual learning for image segmentation with dynamic query": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2311.17450",
        "ref_texts": "[23] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "23"
        ]
      },
      "Research on land cover classification of multi-source remote sensing data based on improved U-net network": {
        "authors": [
          "Guanjin Zhang"
        ],
        "url": "https://www.nature.com/articles/s41598-023-43317-1.pdf",
        "ref_texts": ""
      },
      "Masked autoencoders are stronger knowledge distillers": {
        "authors": [
          "Shanshan Lao",
          "Guanglu Song",
          "Boxiao Liu",
          "Yu Liu",
          "Yujiu Yang"
        ],
        "url": "https://openaccess.thecvf.com/content/ICCV2023/papers/Lao_Masked_Autoencoders_Are_Stronger_Knowledge_Distillers_ICCV_2023_paper.pdf"
      },
      "Compact interactive dual-branch network for real-time semantic segmentation": {
        "authors": [
          "Yongsheng Dong"
        ],
        "url": "https://link.springer.com/content/pdf/10.1007/s40747-023-01063-x.pdf",
        "ref_texts": "40. Zhao H, Shi J, Qi X, Wang X, Jia J (2017) Pyramid scene parsing network. In: Proceedings of the IEEE conference on computervision and pattern recognition (CVPR), pp 2881\u20132890",
        "ref_ids": [
          "40"
        ]
      },
      "FRNet: Frustum-range networks for scalable LiDAR segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2312.04484",
        "ref_texts": "[38] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in IEEE/CVF Conference on Computer Vision and Pattern Recognition , 2017, pp. 2881\u20132890. 1",
        "ref_ids": [
          "38"
        ]
      },
      "Not just learning from others but relying on yourself: A new perspective on few-shot segmentation in remote sensing": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2310.12452",
        "ref_texts": "[50] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "50"
        ]
      },
      "Long-range correlation supervision for land-cover classification from remote sensing images": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2309.04225",
        "ref_texts": "[38] H. Zhao, J. Shi, X. Qi et al., \u201cPyramid Scene Parsing Network,\u201d in Proc. IEEE Int. Conf. Comput. Vi s. Pattern Recog. , 2017, pp. 2881 -2890. ",
        "ref_ids": [
          "38"
        ]
      },
      "Neural architecture search for dense prediction tasks in computer vision": {
        "authors": [
          "Rohit Mohan"
        ],
        "url": "https://link.springer.com/content/pdf/10.1007/s11263-023-01785-y.pdf",
        "ref_texts": "(2021). DCNAs: Densely connected neural architecture search forsemantic image segmentation. arXiv:2003.11883 Zhang, X., Zhou, X., Lin, M., & Sun, J. (2018). Shufflenet: An extremely efficient convolutional neural network for mobile devices. In The IEEE conference on computer vision and pattern recognition(CVPR) Zhang, Y ., Lin, Z., Jiang, J., Zhang, Q., Wang, Y ., Xue, H., Zhang, C., & Yang, Y . (2020). Deeper insights into weight sharing in neural architecture search . arXiv preprint arXiv:2001.01431 Zhang, Y ., Qiu, Z., Liu, J., Yao, T., Liu, D., & Mei, T. (2019). Customizable architecture search for semantic segmentation. In The IEEE conference on computer vision and pattern recognition (CVPR) . Zhao, H., Shi, J., Qi, X., Wang, X., & Jia, J. (2017). Pyramid scene parsing network. In 2017 IEEE conference on computer vision and pattern recognition (CVPR) (pp. 6230\u20136239). https://doi.org/"
      },
      "Parsing is all you need for accurate gait recognition in the wild": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2308.16739",
        "ref_texts": "[53] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. 2017. Pyramid Scene Parsing Network. In CVPR . 6230\u20136239.[54] Jinkai Zheng, Xinchen Liu, Xiaoyan Gu, Yaoqi Sun, Chuang Gan, Jiyong Zhang, Wu Liu, and Chenggang Yan. 2022. Gait Recognition in the Wild with Multi-hop Temporal Switch. In ACM MM . 6136\u20136145.",
        "ref_ids": [
          "53",
          "54"
        ]
      },
      "UPOCR: Towards unified pixel-level ocr interface": {
        "authors": [],
        "url": "https://openreview.net/pdf?id=rEZ24oJhbn",
        "ref_texts": "(CVPR) , pp. 19152\u201319162, 2022. Ye, J., Hu, A., Xu, H., Ye, Q., Yan, M., Dan, Y ., Zhao, C., Xu, G., Li, C., Tian, J., et al. mPLUG-DocOwl: Modularized multimodal large language model for document understanding. arXiv preprint arXiv:2307.02499 , 2023a. Ye, J., Hu, A., Xu, H., Ye, Q., Yan, M., Xu, G., Li, C., Tian, J., Qian, Q., Zhang, J., Jin, Q., He, L., Lin, X. A., and Huang, F. UReader: Universal OCR-free visuallysituated language understanding with multimodal large language model. In Conf. Empir. Methods Nat. Lang. Process. (EMNLP) , 2023b. Ye, Q., Xu, H., Xu, G., Ye, J., Yan, M., Zhou, Y ., Wang, J., Hu, A., Shi, P., Shi, Y ., et al. mPLUG-Owl: Modularization empowers large language models with multimodality. arXiv preprint arXiv:2304.14178 , 2023c.Yu, H., Wang, X., Niu, K., Li, B., and Xue, X. Scene text segmentation with text-focused Transformers. In Proc. ACM Int. Conf. Multimedia (ACM MM) , pp. 2898\u20132907, 2023. Zdenek, J. and Nakayama, H. Erasing scene text with weak supervision. In Proc. IEEE Winter Conf. Appl. Comput. Vis. (WACV) , pp. 2238\u20132246, 2020. Zhang, R., Han, J., Zhou, A., Hu, X., Yan, S., Lu, P., Li, H., Gao, P., and Qiao, Y . LLaMA-Adapter: Efficient fine-tuning of language models with zero-init attention. InProc. Int. Conf. Learn. Represent. (ICLR) , 2024. Zhang, S., Liu, Y ., Jin, L., Huang, Y ., and Lai, S. EnsNet: Ensconce text in the wild. In Proc. AAAI Conf. Artif. Intell. (AAAI) , pp. 801\u2013808, 2019. Zhang, Y ., Gong, K., Zhang, K., Li, H., Qiao, Y ., Ouyang, W., and Yue, X. Meta-Transformer: A unified framework for multimodal learning. arXiv preprint arXiv:2307.10802 , 2023. Zhao, H., Shi, J., Qi, X., Wang, X., and Jia, J. Pyramid scene parsing network. In Proc. IEEE Conf. Comput. Vis. Pattern Recog. (CVPR) , pp. 2881\u20132890, 2017. Zhou, P., Han, X., Morariu, V . I., and Davis, L. S. Learning rich features for image manipulation detection. In Proc. IEEE Conf. Comput. Vis. Pattern Recog. (CVPR) , pp."
      },
      "Deep image matting: A comprehensive survey": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2304.04672",
        "ref_texts": "[137] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. Proceedings of the IEEE Computer Vision and Pattern Recognition , 2016.",
        "ref_ids": [
          "137"
        ]
      },
      "The Role of Subjective Perceptions and Objective Measurements of the Urban Environment in Explaining House Prices in Greater London: A Multi-Scale Urban \u2026": {
        "authors": [
          "Sijie Yang",
          "Kimon Krenz",
          "Waishan Qiu",
          "Wenjing Li"
        ],
        "url": "https://www.mdpi.com/2220-9964/12/6/249/pdf",
        "ref_texts": "79. Zhao, H.; Shi, J.; Qi, X.; Wang, X.; Jia, J. Pyramid scene parsing network. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Honolulu, HI, USA, 21\u201326 July 2017; pp. 2881\u20132890.",
        "ref_ids": [
          "79"
        ]
      },
      "Traditional village building extraction based on improved Mask R-CNN: a case study of Beijing, China": {
        "authors": [
          "Wenke Wang",
          "Yang Shi",
          "Jie Zhang",
          "Lujin Hu",
          "Shuo Li",
          "Ding He",
          "Fei Liu"
        ],
        "url": "https://www.mdpi.com/2072-4292/15/10/2616/pdf",
        "ref_texts": "42. Zhao, H.; Shi, J.; Qi, X.; Wang, X.; Jia, J. Pyramid scene parsing network. In Proceedings of the 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Honolulu, HI, USA, 21\u201326 July 2017; pp. 6230\u20136239. [CrossRef]",
        "ref_ids": [
          "42"
        ]
      },
      "Simultaneously short-and long-term temporal modeling for semi-supervised video semantic segmentation": {
        "authors": [
          "Jiangwei Lao",
          "Weixiang Hong",
          "Xin Guo",
          "Yingying Zhang",
          "Jian Wang",
          "Jingdong Chen",
          "Wei Chu"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Lao_Simultaneously_Short-_and_Long-Term_Temporal_Modeling_for_Semi-Supervised_Video_Semantic_CVPR_2023_paper.pdf",
        "ref_texts": "[39] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017. 2, 5, 6, 7",
        "ref_ids": [
          "39"
        ]
      },
      "Improving breast cancer detection and diagnosis through semantic segmentation using the Unet3+ deep learning framework": {
        "authors": [
          "Taukir Alam",
          "Chung Shia",
          "Rong Hsu",
          "Taimoor Hassan"
        ],
        "url": "https://www.mdpi.com/2227-9059/11/6/1536/pdf",
        "ref_texts": "34. Zhao, H.; Shi, J.; Qi, X.; Wang, X.; Jia, J. Pyramid scene parsing network. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Honolulu, Hawaii, 21\u201326 July 2017; pp. 2881\u20132890.",
        "ref_ids": [
          "34"
        ]
      },
      "Slime: Segment like me": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2309.03179",
        "ref_texts": "11 Published as a conference paper at ICLR 2024 Xinlong Wang, Xiaosong Zhang, Yue Cao, Wen Wang, Chunhua Shen, and Tiejun Huang. Seggpt: Segmenting everything in context. arXiv preprint arXiv:2304.03284 , 2023. Zhitong Xiong, Haopeng Li, and Xiao Xiang Zhu. Doubly deformable aggregation of covariance matrices for few-shot segmentation. In European Conference on Computer Vision , pp. 133\u2013150. Springer, 2022. Jian-Wei Zhang, Yifan Sun, Yi Yang, and Wei Chen. Feature-proxy transformer for few-shot segmentation. Advances in Neural Information Processing Systems , 35:6575\u20136588, 2022. Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pp."
      },
      "Improved PSPNet-based water shoreline detection in complex inland river scenarios": {
        "authors": [
          "Yuheng Yin"
        ],
        "url": "https://link.springer.com/content/pdf/10.1007/s40747-022-00793-8.pdf",
        "ref_texts": "27. Zhao H, Shi J, Qi X, Wang X, Jia J(2017) Pyramid scene parsing network. In: Proceedings of the IEEE conference on computervision and pattern recognition, pp 2881\u20132890. https://doi.org/10.",
        "ref_ids": [
          "27"
        ]
      },
      "The ability of Segmenting Anything Model (SAM) to segment ultrasound images": {
        "authors": [],
        "url": "https://www.jstage.jst.go.jp/article/bst/17/3/17_2023.01128/_pdf",
        "ref_texts": "23. Zhao H, Shi J, Qi X, Wang X, Jia J. Pyramid scene parsing network. In: Proceedings IEEE Conference Comp Vision Pattern Recog. 2017; 2881-2890.",
        "ref_ids": [
          "23"
        ]
      },
      "Segrefiner: Towards model-agnostic segmentation refinement with discrete diffusion process": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2312.12425",
        "ref_texts": "[60] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "60"
        ]
      },
      "Motion-state Alignment for Video Semantic Segmentation": {
        "authors": [
          "Jinming Su",
          "Ruihong Yin",
          "Shuaibin Zhang",
          "Junfeng Luo"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2023W/PVUW/papers/Su_Motion-State_Alignment_for_Video_Semantic_Segmentation_CVPRW_2023_paper.pdf",
        "ref_texts": "[38] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017. 6",
        "ref_ids": [
          "38"
        ]
      },
      "Urban scene semantic segmentation with low-cost coarse annotation": {
        "authors": [
          "Anurag Das",
          "Yongqin Xian",
          "Yang He",
          "Zeynep Akata",
          "Bernt Schiele"
        ],
        "url": "https://openaccess.thecvf.com/content/WACV2023/papers/Das_Urban_Scene_Semantic_Segmentation_With_Low-Cost_Coarse_Annotation_WACV_2023_paper.pdf",
        "ref_texts": "[45] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "45"
        ]
      },
      "Weakly supervised semantic segmentation via alternate self-dual teaching": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2112.09459",
        "ref_texts": "[50] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in CVPR , 2017, pp. 2881\u20132890. 5",
        "ref_ids": [
          "50"
        ]
      },
      "Efficient on-device training via gradient filtering": {
        "authors": [
          "Yuedong Yang",
          "Guihong Li",
          "Radu Marculescu"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Yang_Efficient_On-Device_Training_via_Gradient_Filtering_CVPR_2023_paper.pdf",
        "ref_texts": "[32] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017. 6",
        "ref_ids": [
          "32"
        ]
      },
      "Building fa\u00e7ade color distribution, color harmony and diversity in relation to street functions: using street view images and deep learning": {
        "authors": [
          "Yujia Zhai",
          "Ruoyu Gong",
          "Junzi Huo",
          "Binbin Fan"
        ],
        "url": "https://www.mdpi.com/2220-9964/12/6/224/pdf",
        "ref_texts": "43. Zhao, H.; Shi, J.; Qi, X.; Wang, X.; Jia, J. Pyramid scene parsing network. In Proceedings of the the IEEE Conference on Computer Vision and Pattern Recognition, Honolulu, HI, USA, 21\u201326 July 2017; pp. 2881\u20132890.",
        "ref_ids": [
          "43"
        ]
      },
      "A meaningful learning method for zero-shot semantic segmentation": {
        "authors": [],
        "url": "http://scis.scichina.com/en/2023/210103.pdf",
        "ref_texts": "23 Zhao H, Shi J, Qi X, et al. Pyramid scene parsing network. In : Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2017. 2881\u20132890"
      },
      "Structvpr: Distill structural knowledge with weighting samples for visual place recognition": {
        "authors": [
          "Yanqing Shen",
          "Sanping Zhou",
          "Jingwen Fu",
          "Ruotong Wang",
          "Shitao Chen",
          "Nanning Zheng"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2023/papers/Shen_StructVPR_Distill_Structural_Knowledge_With_Weighting_Samples_for_Visual_Place_CVPR_2023_paper.pdf",
        "ref_texts": ""
      },
      "Dynamic-resolution model learning for object pile manipulation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2306.16700",
        "ref_texts": "[72] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "72"
        ]
      },
      "Zero-guidance segmentation using zero segment labels": {
        "authors": [
          "Pitchaporn Rewatbowornwong",
          "Nattanat Chatthee",
          "Ekapol Chuangsuwanich",
          "Supasorn Suwajanakorn"
        ],
        "url": "https://openaccess.thecvf.com/content/ICCV2023/papers/Rewatbowornwong_Zero-guidance_Segmentation_Using_Zero_Segment_Labels_ICCV_2023_paper.pdf",
        "ref_texts": "[38] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "38"
        ]
      },
      "Wavelet integrated convolutional neural network for thin cloud removal in remote sensing images": {
        "authors": [
          "Yue Zi",
          "Haidong Ding",
          "Fengying Xie",
          "Zhiguo Jiang",
          "Xuedong Song"
        ],
        "url": "https://www.mdpi.com/2072-4292/15/3/781/pdf",
        "ref_texts": "30. Zhao, H.; Shi, J.; Qi, X.; Wang, X.; Jia, J. Pyramid scene parsing network. In Proceedings of the 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Honolulu, HI, USA, 21\u201326 July 2017; pp. 2881\u20132890. [CrossRef]",
        "ref_ids": [
          "30"
        ]
      },
      "Joint liver and hepatic lesion segmentation in MRI using a hybrid CNN with transformer layers": {
        "authors": [
          "Georg Hille",
          "Shubham Agrawal",
          "Pavan Tummala",
          "Christian Wybranski",
          "Maciej Pech",
          "Alexey Surov",
          "Sylvia Saalfeld"
        ],
        "url": "https://arxiv.org/pdf/2201.10981",
        "ref_texts": "24. Zhang, Y ., Peng, C., Peng, L., Huang, H., Tong, R., Lin, L., Li, J., Chen, Y .W., Chen, Q., Hu, H., Peng, Z., 2021b. Multi-phase liver tumor segmentation with spatial aggregation and uncertain region inpainting, in: International Conference on Medical Image Computing and Computer-Assisted Intervention, Springer. pp. 68\u201377. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J., 2017. Pyramid scene parsing network, in: Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 2881\u20132890. Zhao, J., Li, D., Xiao, X., Accorsi, F., Marshall, H., Cossetto, T., Kim, D., McCarthy, D., Dawson, C., Knezevic, S., et al., 2021. United adversarial learning for liver tumor segmentation and detection of multi-modality noncontrast mri. Medical Image Analysis 73, 102154.",
        "ref_ids": [
          "24"
        ]
      },
      "RCDNet: An interpretable rain convolutional dictionary network for single image deraining": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2107.06808",
        "ref_texts": "[103] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "103"
        ]
      },
      "Agg-net: Attention guided gated-convolutional network for depth image completion": {
        "authors": [
          "Dongyue Chen",
          "Tingxuan Huang",
          "Zhimin Song",
          "Shizhuo Deng",
          "Tong Jia"
        ],
        "url": "https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_AGG-Net_Attention_Guided_Gated-Convolutional_Network_for_Depth_Image_Completion_ICCV_2023_paper.pdf",
        "ref_texts": "[32] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2017. 2",
        "ref_ids": [
          "32"
        ]
      },
      "Component segmentation of engineering drawings using Graph Convolutional Networks": {
        "authors": [
          "Wentai Zhang",
          "Joe Joseph",
          "Yue Yin",
          "Liuyue Xie",
          "Tomotake Furuhata",
          "Soji Yamakawa",
          "Kenji Shimada",
          "Levent Burak"
        ],
        "url": "https://arxiv.org/pdf/2212.00290",
        "ref_texts": "31 Veli\u0014 ckovi\u0013 c, P., Cucurull, G., Casanova, A., Romero, A., Lio, P., Bengio, Y., 2017. Graph attention networks. arXiv preprint arXiv:1710.10903. Wang, J., Sun, K., Cheng, T., Jiang, B., Deng, C., Zhao, Y., Liu, D., Mu, Y., Tan, M., Wang, X., et al., 2020. Deep high-resolution representation learning for visual recognition. IEEE transactions on pattern analysis and machine intelligence 43 (10), 3349{3364. Wang, W., Bao, H., Dong, L., Wei, F., 2021. Vlmo: Uniffed visionlanguage pre-training with mixture-of-modality-experts. arXiv preprint arXiv:2111.02358. Welling, M., Kipf, T. N., 2016. Semi-supervised classiffcation with graph convolutional networks. In: J. International Conference on Learning Representations (ICLR 2017). Xiaojin, Z., Zoubin, G., 2002. Learning from labeled and unlabeled data with label propagation. Tech. Rep., Technical Report CMU-CALD-02{107, Carnegie Mellon University. Xie, L., Lu, Y., Furuhata, T., Yamakawa, S., Zhang, W., Regmi, A., Kara, L., Shimada, K., 2022. Graph neural network-enabled manufacturing method classiffcation from engineering drawings. Computers in Industry 142, 103697. Yang, L., Zhuang, J., Fu, H., Wei, X., Zhou, K., Zheng, Y., 2021. Sketchgnn: Semantic sketch segmentation with graph neural networks. ACM Transactions on Graphics (TOG) 40 (3), 1{13. Yang, Z., Cohen, W., Salakhudinov, R., 2016. Revisiting semi-supervised learning with graph embeddings. In: International conference on machine learning. PMLR, pp. 40{48. Zhang, T. Y., Suen, C. Y., 1984. A fast parallel algorithm for thinning digital patterns. Communications of the ACM 27 (3), 236{239. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J., 2017. Pyramid scene parsing network. In: Proceedings of the IEEE conference on computer vision and pattern recognition. pp. 2881{2890. Zhu, X., 2005. Semi-supervised learning with graphs. Carnegie Mellon University."
      },
      "Recent advancements in deep learning applications and methods for autonomous navigation: A comprehensive review": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2302.11089",
        "ref_texts": "[240] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. InProceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "240"
        ]
      },
      "Deep learning based occluded person re-identification: A survey": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2207.14452",
        "ref_texts": "[99] H. Zhao et al. Pyramid scene parsing network. In CVPR , pp. 2881\u2013",
        "ref_ids": [
          "99"
        ]
      },
      "FlameTransNet: Advancing forest flame segmentation with fusion and augmentation techniques": {
        "authors": [
          "Beiqi Chen",
          "Di Bai",
          "Haifeng Lin",
          "Wanguo Jiao"
        ],
        "url": "https://www.mdpi.com/1999-4907/14/9/1887/pdf",
        "ref_texts": "41. Zhao, H.; Shi, J.; Qi, X.; Wang, X.; Jia, J. Pyramid Scene Parsing Network. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Honolulu, HI, USA, 21\u201326 July 2017. Forests 2023 ,14, 1887 20 of 20",
        "ref_ids": [
          "41"
        ]
      },
      "Enhancing building segmentation in remote sensing images: Advanced multi-scale boundary refinement with MBR-HRNet": {
        "authors": [
          "Geding Yan",
          "Haitao Jing",
          "Hui Li",
          "Huanchao Guo",
          "Shi He"
        ],
        "url": "https://www.mdpi.com/2072-4292/15/15/3766/pdf",
        "ref_texts": "49. Zhao, H.; Shi, J.; Qi, X.; Wang, X.; Jia, J. Pyramid scene parsing network. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Honolulu, HI, USA, 21\u201326 July 2017; pp. 2881\u20132890.",
        "ref_ids": [
          "49"
        ]
      },
      "Manipulating identical filter redundancy for efficient pruning on deep and complicated cnn": {
        "authors": [],
        "url": "https://eprints.whiterose.ac.uk/201659/1/CSGD_tnnls___final_.pdf",
        "ref_texts": "[64] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in 2017 IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2017, Honolulu, HI, USA, July 21-26, 2017 . IEEE Computer Society, 2017, pp. 6230\u20136239. [Online]. Available: https://doi.org/10.1109/CVPR.2017.660",
        "ref_ids": [
          "64",
          "Online"
        ]
      },
      "Unsupervised underwater image enhancement via content-style representation disentanglement": {
        "authors": [
          "Pengli Zhu"
        ],
        "url": "https://mspslab.cn/pdfs/URD-UIE.pdf",
        "ref_texts": "11 (2), 447. Ulyanov, Dmitry, Vedaldi, Andrea, Lempitsky, Victor, 2017. Improved texture networks: Maximizing quality and diversity in feed-forward stylization and texture synthesis. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. pp. 6924\u20136932. Wang, Qi, Liu, Zhaoying, Zhang, Ting, Alasmary, Hisham, Waqas, Muhammad, Halim, Zahid, Li, Yujian, 2023a. Deep convolutional cross-connected kernel mapping support vector machine based on SelectDropout. Inform. Sci.. Wang, Tian, Liu, Zhaoying, Zhang, Ting, Hussain, Syed Fawad, Waqas, Muhammad, Li, Yujian, 2022. Adaptive feature fusion for time series classification. Knowl.-Based Syst. 243, 108459. Wang, Ting-Chun, Liu, Ming-Yu, Zhu, Jun-Yan, Tao, Andrew, Kautz, Jan, Catanzaro, Bryan, 2018. High-resolution image synthesis and semantic manipulation with conditional gans. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. pp. 8798\u20138807. Wang, Junting, Ye, Xiufen, Liu, Yusong, Mei, Xinkui, Hou, Jun, 2023b. Underwater selfsupervised monocular depth estimation and its application in image enhancement. Eng. Appl. Artif. Intell. 120, 105846. Yan, Shuaizheng, Chen, Xingyu, Wu, Zhengxing, Wang, Jian, Lu, Yue, Tan, Min, Yu, Junzhi, 2021. Hybrur: A hybrid physical-neural solution for unsupervised underwater image restoration. arXiv preprint arXiv:2107.02660. Yang, Miao, Sowmya, Arcot, 2015. An underwater color image quality evaluation metric. IEEE Trans. Image Process. 24 (12), 6062\u20136071. Ye, Xinchen, Xu, Hongcan, Ji, Xiang, Xu, Rui, 2018. Underwater image enhancement using stacked generative adversarial networks. In: Pacific Rim Conference on Multimedia. Springer, pp. 514\u2013524.Zhang, Weidong, Dong, Lili, Zhang, Tong, Xu, Wenhai, 2021a. Enhancing underwater image via color correction and bi-interval contrast enhancement. Signal Process., Image Commun. 90, 116030. Zhang, Ting, Gao, Zihang, Liu, Zhaoying, Hussain, Syed Fawad, Waqas, Muhammad, Halim, Zahid, Li, Yujian, 2023a. Infrared ship target segmentation based on adversarial domain adaptation. Knowl.-Based Syst. 265, 110344. Zhang, Ting, Waqas, Muhammad, Fang, Yu, Liu, Zhaoying, Halim, Zahid, Li, Yujian, Chen, Sheng, 2023b. Weakly-supervised butterfly detection based on saliency map. Pattern Recognit. 109313. Zhang, Ting, Waqas, Muhammad, Shen, Hao, Liu, Zhaoying, Zhang, Xiangyu, Li, Yujian, Halim, Zahid, Chen, Sheng, 2021b. A neural network architecture optimizer based on DARTS and generative adversarial learning. Inform. Sci. 581, 448\u2013468. Zhao, Hengshuang, Shi, Jianping, Qi, Xiaojuan, Wang, Xiaogang, Jia, Jiaya, 2017. Pyramid scene parsing network. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. pp. 2881\u20132890. Zhou, Jingchun, Pang, Lei, Zhang, Dehuan, Zhang, Weishi, 2023a. Underwater image enhancement method via multi-interval subhistogram perspective equalization. IEEE J. Ocean. Eng.. Zhou, Jingchun, Sun, Jiaming, Zhang, Weishi, Lin, Zifan, 2023b. Multi-view underwater image enhancement method via embedded fusion mechanism. Eng. Appl. Artif. Intell. 121, 105946. Zhou, Xingyi, Wang, Dequan, Kr\u00e4henb\u00fchl, Philipp, 2019. Objects as points. arXiv preprint arXiv:1904.07850. Zhou, Jingchun, Yang, Tongyu, Chu, Weishen, Zhang, Weishi, 2022a. Underwater image restoration via backscatter pixel prior and color compensation. Eng. Appl. Artif. Intell. 111, 104785. Zhou, Jingchun, Yang, Tongyu, Chu, Weishen, Zhang, Weishi, 2022b. Underwater image restoration via backscatter pixel prior and color compensation. Eng. Appl. Artif. Intell. 111, 104785. Zhou, Jingchun, Yang, Tongyu, Zhang, Weishi, 2023c. Underwater vision enhancement technologies: A comprehensive review, challenges, and recent trends. Appl. Intell."
      },
      "SBSS: Stacking-based semantic segmentation framework for very high-resolution remote sensing image": {
        "authors": [
          "Tiffany Mc"
        ],
        "url": "https://arxiv.org/pdf/2212.07623",
        "ref_texts": "[22] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid Scene Parsing Network,\u201d in 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , Jul. 2017, vol. 2017Janua, pp. 6230\u2013 6239, doi: ",
        "ref_ids": [
          "22"
        ]
      },
      "Ensemble-based blackbox attacks on dense prediction": {
        "authors": [
          "Zikui Cai",
          "Yaoteng Tan",
          "Salman Asif"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Cai_Ensemble-Based_Blackbox_Attacks_on_Dense_Prediction_CVPR_2023_paper.pdf",
        "ref_texts": "[60] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017. 4",
        "ref_ids": [
          "60"
        ]
      },
      "RCCT-ASPPNet: dual-encoder remote image segmentation based on transformer and ASPP": {
        "authors": [
          "Yazhou Li",
          "Zhiyou Cheng",
          "Chuanjian Wang",
          "Jinling Zhao",
          "Linsheng Huang"
        ],
        "url": "https://www.mdpi.com/2072-4292/15/2/379/pdf",
        "ref_texts": "22. Zhao, H.; Shi, J.; Qi, X.; Wang, X.; Jia, J. Pyramid Scene Parsing Network. In Proceedings of the 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Honolulu, HI, USA, 21\u201326 July 2017; pp. 6230\u20136239. Remote Sens. 2023 ,15, 379 16 of 16",
        "ref_ids": [
          "22"
        ]
      },
      "Pfenet++: Boosting few-shot semantic segmentation with the noise-filtered context-aware prior mask": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2109.13788",
        "ref_texts": "[84] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017.",
        "ref_ids": [
          "84"
        ]
      },
      "GPS-GLASS: learning nighttime semantic segmentation using daytime video and GPS data": {
        "authors": [
          "Hongjae Lee",
          "Changwoo Han",
          "Sang Yoo",
          "Won Jung"
        ],
        "url": "https://openaccess.thecvf.com/content/ICCV2023W/BRAVO/papers/Lee_GPS-GLASS_Learning_Nighttime_Semantic_Segmentation_Using_Daytime_Video_and_GPS_ICCVW_2023_paper.pdf",
        "ref_texts": "[47] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "47"
        ]
      },
      "Gradient-semantic compensation for incremental semantic segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2307.10822",
        "ref_texts": "[4] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition (CVPR) , 2017, pp. 2881\u20132890. 1, 2",
        "ref_ids": [
          "4"
        ]
      },
      "Semarflow: Injecting semantics into unsupervised optical flow estimation for autonomous driving": {
        "authors": [
          "Shuai Yuan",
          "Shuzhi Yu",
          "Hannah Kim",
          "Carlo Tomasi"
        ],
        "url": "https://openaccess.thecvf.com/content/ICCV2023/papers/Yuan_SemARFlow_Injecting_Semantics_into_Unsupervised_Optical_Flow_Estimation_for_Autonomous_ICCV_2023_paper.pdf",
        "ref_texts": "[86] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 2881\u20132890, 2017. 3",
        "ref_ids": [
          "86"
        ]
      },
      "Meta omnium: A benchmark for general-purpose learning-to-learn": {
        "authors": [
          "Ondrej Bohdal",
          "Yinbing Tian",
          "Yongshuo Zong",
          "Ruchika Chavhan",
          "Da Li",
          "Henry Gouk",
          "Li Guo",
          "Timothy Hospedales"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Bohdal_Meta_Omnium_A_Benchmark_for_General-Purpose_Learning-To-Learn_CVPR_2023_paper.pdf",
        "ref_texts": "[81] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017. 5",
        "ref_ids": [
          "81"
        ]
      },
      "ADD: An automatic desensitization fisheye dataset for autonomous driving": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2308.07590",
        "ref_texts": "[78] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, et al. Pyramid scene parsing network. In Proceedings of Computer Vision and Pattern Recognition (CVPR) , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "78"
        ]
      },
      "Detecting road obstacles by erasing them": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2012.13633",
        "ref_texts": "[8] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid Scene Parsing Network,\u201d in Conference onComputer Vision and Pattern Recognition, 2017. 1, 3, 6, 7",
        "ref_ids": [
          "8"
        ]
      },
      "LiteST-Net: a hybrid model of lite swin transformer and convolution for building extraction from remote sensing image": {
        "authors": [
          "Wei Yuan",
          "Xiaobo Zhang",
          "Jibao Shi",
          "Jin Wang"
        ],
        "url": "https://www.mdpi.com/2072-4292/15/8/1996/pdf",
        "ref_texts": "14. Zhao, H.; Shi, J.; Qi, X.; Wang, X.; Jia, J. Pyramid scene parsing network. In Proceedings of the 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Honolulu, HI, USA, 21\u201326 July 2017; pp. 6230\u20136239.",
        "ref_ids": [
          "14"
        ]
      },
      "Detection and Mapping of Chestnut Using Deep Learning from High-Resolution UAV-Based RGB Imagery": {
        "authors": [
          "Yifei Sun",
          "Zhenbang Hao",
          "Zhanbao Guo",
          "Zhenhu Liu",
          "Jiaxing Huang"
        ],
        "url": "https://www.mdpi.com/2072-4292/15/20/4923/pdf",
        "ref_texts": "49. Zhao, H.; Shi, J.; Qi, X.; Wang, X.; Jia, J. Pyramid scene parsing network. In Proceedings of the 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Honolulu, HI, USA, 21\u201326 July 2017.",
        "ref_ids": [
          "49"
        ]
      },
      "Atmospheric transmission and thermal inertia induced blind road segmentation with a large-scale dataset tbrsd": {
        "authors": [
          "Junzhang Chen",
          "Xiangzhi Bai"
        ],
        "url": "http://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Atmospheric_Transmission_and_Thermal_Inertia_Induced_Blind_Road_Segmentation_with_ICCV_2023_paper.pdf",
        "ref_texts": "[38] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "38"
        ]
      },
      "Mask-guided modality difference reduction network for RGB-T semantic segmentation": {
        "authors": [
          "Wenli Liang"
        ],
        "url": "https://research.tue.nl/files/277223282/1_s2.0_S0925231222015314_main.pdf",
        "ref_texts": "[27] H. Zhao, J. Shi, X. Qi, X. Wang, J. Jia, Pyramid scene parsing network, CVPR, 2017, pp. 2881\u20132890 .",
        "ref_ids": [
          "27"
        ]
      },
      "Online distillation with continual learning for cyclic domain shifts": {
        "authors": [
          "Joachim Houyon",
          "Anthony Cioppa",
          "Yasir Ghunaim",
          "Motasem Alfarra",
          "Anais Halin",
          "Maxim Henry",
          "Bernard Ghanem",
          "Marc Van"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2023W/CLVision/papers/Houyon_Online_Distillation_With_Continual_Learning_for_Cyclic_Domain_Shifts_CVPRW_2023_paper.pdf",
        "ref_texts": "[46] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In IEEE/CVF Conf. Comput. Vis. Pattern Recognit. (CVPR) , pages 6230\u20136239, Honolulu, HI, USA, Jul. 2017. Inst. Electr. Electron. Eng. (IEEE). 2",
        "ref_ids": [
          "46"
        ]
      },
      "CNN and Transformer Fusion for Remote Sensing Image Semantic Segmentation": {
        "authors": [
          "Xin Chen",
          "Dongfen Li",
          "Mingzhe Liu",
          "Jiaru Jia"
        ],
        "url": "https://www.mdpi.com/2072-4292/15/18/4455/pdf",
        "ref_texts": "29. Zhao, H.; Shi, J.; Qi, X.; Wang, X.; Jia, J. Pyramid scene parsing network. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition 2017, Honolulu, HI, USA, 21\u201326 July 2017; pp. 2881\u20132890.",
        "ref_ids": [
          "29"
        ]
      },
      "Stereopose: Category-level 6d transparent object pose estimation from stereo images via back-view nocs": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2211.01644",
        "ref_texts": "[41] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "41"
        ]
      },
      "Rfenet: Towards reciprocal feature evolution for glass segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2307.06099",
        "ref_texts": "[Zhao et al. , 2017 ]Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u2013",
        "ref_ids": [
          "Zhao et al\\. , 2017 "
        ]
      },
      "Semi-supervised remote sensing image semantic segmentation method based on deep learning": {
        "authors": [
          "Linhui Li",
          "Wenjun Zhang",
          "Xiaoyan Zhang",
          "Mahmoud Emam",
          "Weipeng Jing"
        ],
        "url": "https://www.mdpi.com/2079-9292/12/2/348/pdf",
        "ref_texts": "19. Zhao, H.; Shi, J.; Qi, X.; Wang, X.; Jia, J. Pyramid Scene Parsing Network. arXiv 2017 , arxiv:1612.01105.",
        "ref_ids": [
          "19"
        ]
      },
      "replicAnt: a pipeline for generating annotated images of animals in complex environments using Unreal Engine": {
        "authors": [
          "Fabian Plum"
        ],
        "url": "https://www.nature.com/articles/s41467-023-42898-9.pdf",
        "ref_texts": "64. Zhao, H. et al. Pyramid scene parsing network. CVPR. Preprint at https://arxiv.org/abs/1612.01105 (2017).",
        "ref_ids": [
          "64"
        ]
      },
      "TCUNet: A Lightweight Dual-Branch Parallel Network for Sea\u2013Land Segmentation in Remote Sensing Images": {
        "authors": [
          "Xuan Xiong",
          "Xiaopeng Wang",
          "Jiahua Zhang",
          "Baoxiang Huang",
          "Runfeng Du"
        ],
        "url": "https://www.mdpi.com/2072-4292/15/18/4413/pdf",
        "ref_texts": "26. Zhao, H.; Shi, J.; Qi, X.; Wang, X.; Jia, J. Pyramid Scene Parsing Network. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Honolulu, HI, USA, 21\u201326 July 2017; pp. 2881\u20132890.",
        "ref_ids": [
          "26"
        ]
      },
      "Less is more: Learning from synthetic data with fine-grained attributes for person re-identification": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2109.10498",
        "ref_texts": "[4] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , pages 2881\u20132890, 2017. 5",
        "ref_ids": [
          "4"
        ]
      },
      "Boundary-guided semantic context network for water body extraction from remote sensing images": {
        "authors": [
          "Jie Yu",
          "Yang Cai",
          "Xin Lyu",
          "Zhennan Xu",
          "Xinyuan Wang",
          "Yiwei Fang",
          "Wenxuan Jiang",
          "Xin Li"
        ],
        "url": "https://www.mdpi.com/2072-4292/15/17/4325/pdf",
        "ref_texts": "26. Zhao, H.; Shi, J.; Qi, X.; Wang, X.; Jia, J. Pyramid Scene Parsing Network. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Honolulu, HI, USA, 21\u201326 July 2017; pp. 6230\u20136239.",
        "ref_ids": [
          "26"
        ]
      },
      "AIR-PV: A benchmark dataset for photovoltaic panel extraction in optical remote sensing imagery": {
        "authors": [],
        "url": "https://link.springer.com/content/pdf/10.1007/s11432-022-3663-1.pdf",
        "ref_texts": "7 Zhao H, Shi J, Qi X, et al. Pyramid scene parsing network. In: Proceedings of IEEE Conference on Computer Vision and Pattern Recognition, 2017. 17355193"
      },
      "MaxViT-UNet: Multi-axis attention for medical image segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2305.08396",
        "ref_texts": "[85] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "85"
        ]
      },
      "Attribution-aware weight transfer: A warm-start initialization for class-incremental semantic segmentation": {
        "authors": [
          "Dipam Goswami",
          "Rene Schuster",
          "Didier Stricker"
        ],
        "url": "https://openaccess.thecvf.com/content/WACV2023/papers/Goswami_Attribution-Aware_Weight_Transfer_A_Warm-Start_Initialization_for_Class-Incremental_Semantic_Segmentation_WACV_2023_paper.pdf",
        "ref_texts": "[54] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Conference on Computer Vision and Pattern Recognition (CVPR) , 2017.",
        "ref_ids": [
          "54"
        ]
      },
      "Modified ResNet-152 network with hybrid pyramidal pooling for local change detection": {
        "authors": [],
        "url": "https://www.giet.edu/wp-content/uploads/2024/08/Publication14.pdf",
        "ref_texts": ""
      },
      "Rethinking evaluation metrics of open-vocabulary segmentaion": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2311.03352",
        "ref_texts": "[76] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017. 3",
        "ref_ids": [
          "76"
        ]
      },
      "Achelous: A fast unified water-surface panoptic perception framework based on fusion of monocular camera and 4d mmwave radar": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2307.07102",
        "ref_texts": "[40] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia, \u201cPyramid scene parsing network,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "40"
        ]
      },
      "Trosd: A new rgb-d dataset for transparent and reflective object segmentation in practice": {
        "authors": [],
        "url": "https://discovery.ucl.ac.uk/id/eprint/10166326/1/TCSVT-TianyuSun-accepted.pdf",
        "ref_texts": "[1] M. Cordts, M. Omran, S. Ramos, T. Rehfeld, M. Enzweiler, R. Be-nenson, U. Franke, S. Roth, and B. Schiele, \u201cThe cityscapes datasetfor semantic urban scene understanding,\u201d inProceedings of the IEEEconference on computer vision and pattern recognition, 2016, pp. 3213\u20133223.[2] S. Song, S. P. Lichtenberg, and J. Xiao, \u201cSun rgb-d: A rgb-d sceneunderstanding benchmark suite,\u201d inProceedings of the IEEE conferenceon computer vision and pattern recognition, 2015, pp. 567\u2013576.[3] X. Yang, H. Mei, K. Xu, X. Wei, B. Yin, and R. W. Lau, \u201cWhere is mymirror?\u201d inProceedings of the IEEE/CVF International Conference onComputer Vision, 2019, pp. 8809\u20138818.[4] H. Mei, X. Yang, Y . Wang, Y . Liu, S. He, Q. Zhang, X. Wei, andR. W. Lau, \u201cDon\u2019t hit me! glass detection in real-world scenes,\u201d inProceedings of the IEEE/CVF Conference on Computer Vision andPattern Recognition, 2020, pp. 3687\u20133696.[5] V . Seib, A. Barthen, P. Marohn, and D. Paulus, \u201cFriend or foe: exploitingsensor failures for transparent object localization and classification,\u201d in2016 International Conference on Robotics and Machine Vision, vol.10253. SPIE, 2017, pp. 94\u201398.Page 30 of 32IEEE Transactions on Circuits and Systems for Video Technology123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960 IEEE TRANSACTIONS ON CIRCUITS AND SYSTEMS FOR VIDEO TECHNOLOGY12[6] S. Sajjan, M. Moore, M. Pan, G. Nagaraja, J. Lee, A. Zeng, andS. Song, \u201cClear grasp: 3d shape estimation of transparent objects formanipulation,\u201d in2020 IEEE International Conference on Robotics andAutomation (ICRA). IEEE, 2020, pp. 3634\u20133642.[7] K. He, G. Gkioxari, P. Doll\u00b4ar, and R. Girshick, \u201cMask r-cnn,\u201d inProceedings of the IEEE international conference on computer vision,2017, pp. 2961\u20132969.[8] E. Xie, W. Wang, W. Wang, M. Ding, C. Shen, and P. Luo, \u201cSegmentingtransparent objects in the wild,\u201d inEuropean conference on computervision. Springer, 2020, pp. 696\u2013711.[9] A. Kalra, V . Taamazyan, S. K. Rao, K. Venkataraman, R. Raskar, andA. Kadambi, \u201cDeep polarization cues for transparent object segmenta-tion,\u201d inProceedings of the IEEE/CVF Conference on Computer Visionand Pattern Recognition, 2020, pp. 8602\u20138611.[10] W. Shi, J. Xu, D. Zhu, G. Zhang, X. Wang, J. Li, and X. Zhang, \u201cRGB-Dsemantic segmentation and label-oriented voxelgrid fusion for accurate3D semantic mapping,\u201dIEEE Transactions on Circuits and Systems forVideo Technology, vol. 32, no. 1, pp. 183\u2013197, 2022.[11] J. Long, E. Shelhamer, and T. Darrell, \u201cFully convolutional networksfor semantic segmentation,\u201d inProceedings of the IEEE conference oncomputer vision and pattern recognition, 2015, pp. 3431\u20133440.[12] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsingnetwork,\u201d inProceedings of the IEEE conference on computer visionand pattern recognition, 2017, pp. 2881\u20132890.[13] G. Lin, A. Milan, C. Shen, and I. Reid, \u201cRefinenet: Multi-path refinementnetworks for high-resolution semantic segmentation,\u201d inProceedings ofthe IEEE conference on computer vision and pattern recognition, 2017,pp. 1925\u20131934.[14] L.-C. Chen, G. Papandreou, F. Schroff, and H. Adam, \u201cRethinkingatrous convolution for semantic image segmentation,\u201darXiv preprintarXiv:1706.05587, 2017.[15] Y . Yuan, L. Huang, J. Guo, C. Zhang, X. Chen, and J. Wang,\u201cOcnet: Object context network for scene parsing,\u201darXiv preprintarXiv:1809.00916, 2018.[16] Z. Zhu, M. Xu, S. Bai, T. Huang, and X. Bai, \u201cAsymmetric non-local neural networks for semantic segmentation,\u201d inProceedings ofthe IEEE/CVF International Conference on Computer Vision, 2019, pp.593\u2013602.[17] M. Everingham, S. Eslami, L. Van Gool, C. K. Williams, J. Winn,and A. Zisserman, \u201cThe pascal visual object classes challenge: Aretrospective,\u201dInternational journal of computer vision, vol. 111, no. 1,pp. 98\u2013136, 2015.[18] G. Li, Z. Liu, L. Ye, Y . Wang, and H. Ling, \u201cCross-modal weightingnetwork for rgb-d salient object detection,\u201d inComputer Vision\u2013ECCV2020: 16th European Conference, Glasgow, UK, August 23\u201328, 2020,Proceedings, Part XVII 16. Springer, 2020, pp. 665\u2013681.[19] G. Li, Z. Liu, and H. Ling, \u201cIcnet: Information conversion networkfor rgb-d based salient object detection,\u201dIEEE Transactions on ImageProcessing, vol. 29, pp. 4873\u20134884, 2020.[20] G. Li, Z. Liu, M. Chen, Z. Bai, W. Lin, and H. Ling, \u201cHierarchicalalternate interaction network for rgb-d salient object detection,\u201dIEEETransactions on Image Processing, vol. 30, pp. 3528\u20133542, 2021.[21] Y . Yang, Q. Qin, Y . Luo, Y . Liu, Q. Zhang, and J. Han, \u201cBi-directionalprogressive guidance network for RGB-D salient object detection,\u201dIEEETransactions on Circuits and Systems for Video Technology, vol. 32,no. 8, pp. 5346\u20135360, 2022.[22] W. Wang and U. Neumann, \u201cDepth-aware cnn for rgb-d segmenta-tion,\u201d inProceedings of the European Conference on Computer Vision(ECCV), 2018, pp. 135\u2013150.[23] J. Jiao, Y . Wei, Z. Jie, H. Shi, R. W. Lau, and T. S. Huang, \u201cGeometry-aware distillation for indoor semantic segmentation,\u201d inProceedings ofthe IEEE/CVF conference on computer vision and pattern recognition,2019, pp. 2869\u20132878.[24] Z. Zhang, Z. Cui, C. Xu, Y . Yan, N. Sebe, and J. Yang, \u201cPattern-affinitivepropagation across depth, surface normal and semantic segmentation,\u201dinProceedings of the IEEE/CVF conference on computer vision andpattern recognition, 2019, pp. 4106\u20134115.[25] C. R. Qi, H. Su, K. Mo, and L. J. Guibas, \u201cPointnet: Deep learning onpoint sets for 3d classification and segmentation,\u201d inProceedings of theIEEE conference on computer vision and pattern recognition, 2017, pp.652\u2013660.[26] H. Fan, X. Yu, Y . Ding, Y . Yang, and M. Kankanhalli, \u201cPstnet: Pointspatio-temporal convolution on point cloud sequences,\u201darXiv preprintarXiv:2205.13713, 2022.[27] H. Thomas, C. R. Qi, J.-E. Deschaud, B. Marcotegui, F. Goulette, andL. J. Guibas, \u201cKpconv: Flexible and deformable convolution for pointclouds,\u201d inProceedings of the IEEE/CVF international conference oncomputer vision, 2019, pp. 6411\u20136420.[28] F. Li, J. Ma, Z. Tian, J. Ge, H.-N. Liang, Y . Zhang, and T. Wen, \u201cMirror-yolo: An attention-based instance segmentation and detection model formirrors,\u201darXiv preprint arXiv:2202.08498, 2022.[29] H. Mei, B. Dong, W. Dong, P. Peers, X. Yang, Q. Zhang, and X. Wei,\u201cDepth-aware mirror segmentation,\u201d inProceedings of the IEEE/CVFConference on Computer Vision and Pattern Recognition, 2021, pp.3044\u20133053.[30] \u201cStructure support,\u201dURL: https://structure.io/help/structure-sensor.[31] A. Dai, A. X. Chang, M. Savva, M. Halber, T. Funkhouser, andM. Nie\u00dfner, \u201cScannet: Richly-annotated 3d reconstructions of indoorscenes,\u201d inProceedings of the IEEE conference on computer vision andpattern recognition, 2017, pp. 5828\u20135839.[32] K. Wada, \u201cLabelme: image polygonal annotation with python. 2016,\u201dURL: https://github.com/wkentaro/labelme, 2016.[33] J. Lin, Z. He, and R. W. Lau, \u201cRich context aggregation with reflectionprior for glass surface detection,\u201d inProceedings of the IEEE/CVFConference on Computer Vision and Pattern Recognition, 2021, pp.13 415\u201313 424.[34] J. Lin, Y . H. Yeung, and R. W. Lau, \u201cDepth-aware glass surface detectionwith cross-modal context mining,\u201darXiv preprint arXiv:2206.11250,2022.[35] J. Lin, G. Wang, and R. W. Lau, \u201cProgressive mirror detection,\u201d inProceedings of the IEEE/CVF Conference on Computer Vision andPattern Recognition, 2020, pp. 3697\u20133705.[36] J. Tan, W. Lin, A. X. Chang, and M. Savva, \u201cMirror3d: Depth refinementfor mirror surfaces,\u201d inProceedings of the IEEE/CVF Conference onComputer Vision and Pattern Recognition, 2021, pp. 15 990\u201315 999.[37] H. Wang, D. Huang, K. Jia, and Y . Wang, \u201cHierarchical image segmenta-tion ensemble for objectness in RGB-D images,\u201dIEEE Transactions onCircuits and Systems for Video Technology, vol. 29, no. 1, pp. 93\u2013103,2019.[38] W. Gao, G. Liao, S. Ma, G. Li, Y . Liang, and W. Lin, \u201cUnifiedinformation fusion network for multi-modal RGB-D and RGB-T salientobject detection,\u201dIEEE Transactions on Circuits and Systems for VideoTechnology, vol. 32, no. 4, pp. 2091\u20132106, 2022.[39] K. He, X. Zhang, S. Ren, and J. Sun, \u201cDeep residual learning for imagerecognition,\u201d inProceedings of the IEEE conference on computer visionand pattern recognition, 2016, pp. 770\u2013778.[40] H. He, X. Li, G. Cheng, J. Shi, Y . Tong, G. Meng, V . Prinet, andL. Weng, \u201cEnhanced boundary learning for glass-like object segmen-tation,\u201d inProceedings of the IEEE/CVF International Conference onComputer Vision, 2021, pp. 15 859\u201315 868.[41] Z. Liu, Y . Tan, Q. He, and Y . Xiao, \u201cSwinNet: Swin transformerdrives edge-aware RGB-D and RGB-T salient object detection,\u201dIEEETransactions on Circuits and Systems for Video Technology, vol. 32,no. 7, pp. 4486\u20134497, 2022.[42] J. Kim, M. Kim, H. Kang, and K. H. Lee, \u201cU-gat-it: Unsupervised gener-ative attentional networks with adaptive layer-instance normalization forimage-to-image translation,\u201d inInternational Conference on LearningRepresentations, 2019.[43] X. Shu, J. Yang, R. Yan, and Y . Song, \u201cExpansion-squeeze-excitationfusion network for elderly activity recognition,\u201dIEEE Transactions onCircuits and Systems for Video Technology, vol. 32, no. 8, pp. 5281\u20135292, 2022.[44] X. Shu, B. Xu, L. Zhang, and J. Tang, \u201cMulti-granularity anchor-contrastive representation learning for semi-supervised skeleton-basedaction recognition,\u201dIEEE Transactions on Pattern Analysis and MachineIntelligence, 2022.[45] L. Chen, H. Zhang, J. Xiao, L. Nie, J. Shao, W. Liu, and T.-S.Chua, \u201cSca-cnn: Spatial and channel-wise attention in convolutionalnetworks for image captioning,\u201d inProceedings of the IEEE conferenceon computer vision and pattern recognition, 2017, pp. 5659\u20135667.[46] J. Zhang, K. Yang, A. Constantinescu, K. Peng, K. M\u00a8uller, andR. Stiefelhagen, \u201cTrans4Trans: Efficient transformer for transparentobject and semantic scene segmentation in real-world navigation assis-tance,\u201dIEEE Transactions on Intelligent Transportation Systems, 2022.[47] W. Wang, E. Xie, X. Li, D.-P. Fan, K. Song, D. Liang, T. Lu, P. Luo,and L. Shao, \u201cPyramid vision transformer: A versatile backbone fordense prediction without convolutions,\u201d inProceedings of the IEEE/CVFinternational conference on computer vision, 2021, pp. 568\u2013578.[48] J. Fu, J. Liu, H. Tian, Y . Li, Y . Bao, Z. Fang, and H. Lu, \u201cDual attentionnetwork for scene segmentation,\u201d inProceedings of the IEEE/CVFconference on computer vision and pattern recognition, 2019, pp. 3146\u20133154.Page 31 of 32IEEE Transactions on Circuits and Systems for Video Technology123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960 IEEE TRANSACTIONS ON CIRCUITS AND SYSTEMS FOR VIDEO TECHNOLOGY13[49] A. Valada, R. Mohan, and W. Burgard, \u201cSelf-supervised model adap-tation for multimodal semantic segmentation,\u201dInternational Journal ofComputer Vision, vol. 128, no. 5, pp. 1239\u20131285, 2020.[50] W. Zhou, E. Yang, J. Lei, and L. Yu, \u201cFrnet: Feature reconstructionnetwork for rgb-d indoor scene parsing,\u201dIEEE Journal of SelectedTopics in Signal Processing, vol. 16, no. 4, pp. 677\u2013687, 2022.[51] D. Seichter, S. Fischedick, M. K\u00a8ohler, and H.-M. Gross, \u201cEfficientmulti-task rgb-d scene analysis for indoor environments,\u201darXiv preprintarXiv:2207.04526, 2022.[52] C. Hazirbas, L. Ma, C. Domokos, and D. Cremers, \u201cFusenet: Incorporat-ing depth into semantic segmentation via fusion-based cnn architecture,\u201dinAsian conference on computer vision. Springer, 2016, pp. 213\u2013228.[53] J. Jiang, L. Zheng, F. Luo, and Z. Zhang, \u201cRednet: Residual encoder-decoder network for indoor rgb-d semantic segmentation,\u201darXiv preprintarXiv:1806.01054, 2018.[54] O. Russakovsky, J. Deng, H. Su, J. Krause, S. Satheesh, S. Ma,Z. Huang, A. Karpathy, A. Khosla, M. Bernsteinet al., \u201cImagenet largescale visual recognition challenge,\u201dInternational journal of computervision, vol. 115, no. 3, pp. 211\u2013252, 2015.[55] C. G. Bampis, Z. Li, and A. C. Bovik, \u201cSpatiotemporal feature integra-tion and model fusion for full reference video quality assessment,\u201dIEEETransactions on Circuits and Systems for Video Technology, vol. 29,no. 8, pp. 2256\u20132270, 2019.[56] Y . Wang, F. Sun, W. Huang, F. He, and D. Tao, \u201cChannel exchangingnetworks for multimodal and multitask dense image prediction,\u201dIEEETransactions on Pattern Analysis and Machine Intelligence, 2022. Tianyu Sunreceived the B.S. degree in 2021 fromthe Department of Electronic Engineering, TsinghuaUniversity, where he is currently pursuing the M.S.degree. His research interests include 3D vision andsemantic segmentation. Guodong Zhangreceived the B.S. degree fromthe College of Communication Engineering, JilinUniversity, in 2018. He received the M.S. degreefrom the Department of Electronic Engineering, Ts-inghua University, in 2021. His research interestsinclude deep learning, RGB-D image, and semanticsegmentation. Wenming Yangreceived his Ph.D. degree in infor-mation and communication engineering from Zhe-jiang University in 2006. He is an Associate Pro-fessor in Tsinghua Shenzhen International GraduateSchool/Department of Electronic Engineering, Ts-inghua University. His research interests include im-age processing, pattern recognition, computer visionand AI in medicine. Jing-Hao Xuereceived the Dr.Eng. degree in sig-nal and information processing from Tsinghua Uni-versity in 1998 and the Ph.D. degree in statisticsfrom the University of Glasgow in 2008. He is aProfessor in the Department of Statistical Scienceat University College London. His research interestsinclude statistical pattern recognition, machine learn-ing and computer vision. He is an Associate Editorof the IEEE Transactions on Circuits and Systemsfor Video Technology, the IEEE Transactions onCybernetics, and the IEEE Transactions on NeuralNetworks and Learning Systems. Guijin Wangreceived the B.S. and Ph.D. degrees(with honor) from the Department of ElectronicEngineering, Tsinghua University, in 1998 and 2003respectively, both in signal and information pro-cessing. He is a Professor with the Departmentof Electronic Engineering, Tsinghua University. Hewas an Associate Editor of IEEE Signal ProcessingMagazine. His research interests focus on computa-tional imaging, pose recognition, intelligent human-machine UI, intelligent surveillance, industry inspec-tion, and AI for Big medical data.Page 32 of 32IEEE Transactions on Circuits and Systems for Video Technology123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960",
        "ref_ids": [
          "1",
          "2",
          "3",
          "4",
          "5",
          "6",
          "7",
          "8",
          "9",
          "10",
          "11",
          "12",
          "13",
          "14",
          "15",
          "16",
          "17",
          "18",
          "19",
          "20",
          "21",
          "22",
          "23",
          "24",
          "25",
          "26",
          "27",
          "28",
          "29",
          "30",
          "31",
          "32",
          "33",
          "34",
          "35",
          "36",
          "37",
          "38",
          "39",
          "40",
          "41",
          "42",
          "43",
          "44",
          "45",
          "46",
          "47",
          "48",
          "49",
          "50",
          "51",
          "52",
          "53",
          "54",
          "55",
          "56"
        ]
      },
      "A tumor MRI image segmentation framework based on class-correlation pattern aggregation in medical decision-making system": {
        "authors": [
          "Hui Wei",
          "Baolong Lv",
          "Feng Liu",
          "Haojun Tang",
          "Fangfang Gou",
          "Jia Wu"
        ],
        "url": "https://www.mdpi.com/2227-7390/11/5/1187/pdf",
        "ref_texts": "61. Zhao, H.; Shi, J.; Qi, X.; Wang, X.; Jia, J. Pyramid scene parsing network. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Honolulu, HI, USA, 21\u201326 July 2017; pp. 2881\u20132890.",
        "ref_ids": [
          "61"
        ]
      },
      "Pruning parameterization with bi-level optimization for efficient semantic segmentation on the edge": {
        "authors": [
          "Changdi Yang",
          "Pu Zhao",
          "Yanyu Li",
          "Wei Niu",
          "Jiexiong Guan",
          "Hao Tang",
          "Minghai Qin",
          "Bin Ren",
          "Xue Lin",
          "Yanzhi Wang"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Yang_Pruning_Parameterization_With_Bi-Level_Optimization_for_Efficient_Semantic_Segmentation_on_CVPR_2023_paper.pdf",
        "ref_texts": "[71] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017. 2, 6, 7",
        "ref_ids": [
          "71"
        ]
      },
      "RockSeg: A Novel Semantic Segmentation Network Based on a Hybrid Framework Combining a Convolutional Neural Network and Transformer for Deep Space Rock \u2026": {
        "authors": [
          "Lili Fan",
          "Jiabin Yuan",
          "Xuewei Niu",
          "Keke Zha",
          "Weiqi Ma"
        ],
        "url": "https://www.mdpi.com/2072-4292/15/16/3935/pdf",
        "ref_texts": "24. Zhao, H.; Shi, J.; Qi, X.; Wang, X.; Jia, J. Pyramid scene parsing network. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Honolulu, HI, USA, 21\u201326 July 2017; pp. 2881\u20132890.",
        "ref_ids": [
          "24"
        ]
      },
      "Formula-driven supervised learning in computer vision: a literature survey": {
        "authors": [
          "Abdul Mueed",
          "Mahmoud Hassaballah",
          "Adel Binbusayyis"
        ],
        "url": "https://www.mdpi.com/2076-3417/13/2/723/pdf",
        "ref_texts": "8. Zhao, H.; Shi, J.; Qi, X.; Wang, X.; Jia, J. Pyramid Scene Parsing Network. In Proceedings of the 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Honolulu, Hawaii, USA, 21\u201326 July 2017; pp. 6230\u20136239. [CrossRef]",
        "ref_ids": [
          "8"
        ]
      },
      "Symfm6d: Symmetry-aware multi-directional fusion for multi-view 6d object pose estimation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2307.00306",
        "ref_texts": "[58] H. Zhao et al. , \u201cPyramid scene parsing network,\u201d in CVPR , 2017, pp.",
        "ref_ids": [
          "58"
        ]
      },
      "Transformer scale gate for semantic segmentation": {
        "authors": [
          "Hengcan Shi",
          "Munawar Hayat",
          "Jianfei Cai"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2023/papers/Shi_Transformer_Scale_Gate_for_Semantic_Segmentation_CVPR_2023_paper.pdf",
        "ref_texts": "[46] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 2881\u20132890, 2017. 1, 3, 7",
        "ref_ids": [
          "46"
        ]
      },
      "Maskomaly: Zero-shot mask anomaly segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2305.16972",
        "ref_texts": "[52] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "52"
        ]
      },
      "Deep learning for visual SLAM: the state-of-the-art and future trends": {
        "authors": [
          "Margarita N. Favorskaya"
        ],
        "url": "https://www.mdpi.com/2079-9292/12/9/2006/pdf",
        "ref_texts": "89. Zhao, H.; Shi, J.; Qi, X.; Wangh, X.; Jia, J. Pyramid scene parsing network. In Proceedings of the 2017 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW 2017), Honolulu, HI, USA, 21\u201326 July 2017; pp. 2881\u20132890.",
        "ref_ids": [
          "89"
        ]
      },
      "U-Net v2: Rethinking the skip connections of U-Net for medical image segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2311.17791",
        "ref_texts": "[2] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia, \u201cPyramid scene parsing network,\u201d inCVPR , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "2"
        ]
      },
      "A lightweight siamese neural network for building change detection using remote sensing images": {
        "authors": [
          "Haiping Yang",
          "Yuanyuan Chen",
          "Wei Wu",
          "Shiliang Pu",
          "Xiaoyang Wu",
          "Qiming Wan",
          "Wen Dong"
        ],
        "url": "https://www.mdpi.com/2072-4292/15/4/928/pdf",
        "ref_texts": "48. Zhao, H.; Shi, J.; Qi, X.; Wang, X.; Jia, J. Pyramid Scene Parsing Network. In Proceedings of the 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Honolulu, HI, USA, 21\u201326 July 2017; pp. 6230\u20136239.",
        "ref_ids": [
          "48"
        ]
      },
      "Dilated-unet: A fast and accurate medical image segmentation approach using a dilated transformer and u-net architecture": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2304.11450",
        "ref_texts": "[51] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017. 3",
        "ref_ids": [
          "51"
        ]
      },
      "Semicvt: Semi-supervised convolutional vision transformer for semantic segmentation": {
        "authors": [
          "Huimin Huang",
          "Shiao Xie",
          "Lanfen Lin",
          "Ruofeng Tong",
          "Wei Chen",
          "Yuexiang Li",
          "Hong Wang",
          "Yawen Huang",
          "Yefeng Zheng"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2023/papers/Huang_SemiCVT_Semi-Supervised_Convolutional_Vision_Transformer_for_Semantic_Segmentation_CVPR_2023_paper.pdf",
        "ref_texts": "[44] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on Computer Vision and Pattern Recognition , pages 2881\u20132890, 2017. 1",
        "ref_ids": [
          "44"
        ]
      },
      "Coupling global context and local contents for weakly-supervised semantic segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2304.09059",
        "ref_texts": "[25] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2017.",
        "ref_ids": [
          "25"
        ]
      },
      "Efficient hand segmentation for rehabilitation tasks using a convolution neural network with attention": {
        "authors": [
          "H Pallab",
          "Jyoti Dutta"
        ],
        "url": "http://www.macdorman.com/kfm/writings/pubs/Dutta-2023-Hand-Segmentation-for-Rehabilitation-ESWA.pdf",
        "ref_texts": "1109/ACCESS.2019.2900991. Zhao, H., Shi, J., Qi, X., Wang, X., & Jia, J. (2017). Pyramid scene parsing network. In2017 IEEE conference on computer vision and pattern recognition (pp. 6230\u20136239). http://dx.doi.org/10.1109/CVPR.2017.660. Zhuoran, S., Mingyuan, Z., Haiyu, Z., Shuai, Y., & Hongsheng, L. (2021). Efficient attention: Attention with linear complexities. In 2021 IEEE winter conference on applications of computer vision (pp. 3530\u20133538). http://dx.doi.org/10.1109/ WACV48630.2021.00357."
      },
      "Restnet: Boosting cross-domain few-shot segmentation with residual transformation network": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2308.13469",
        "ref_texts": "[43] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "43"
        ]
      },
      "Leveraging topology for domain adaptive road segmentation in satellite and aerial imagery": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2309.15625",
        "ref_texts": "[38] H. Zhao, J. Shi, X. Qi, X. Wang, J. Jia, Pyramid scene parsing network, in: IEEE Conf. on Computer Vision and Pattern Recognition (CVPR), 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "38"
        ]
      },
      "Pruning-guided curriculum learning for semi-supervised semantic segmentation": {
        "authors": [
          "Heejo Kong",
          "Hee Lee",
          "Suneung Kim",
          "Whan Lee"
        ],
        "url": "https://openaccess.thecvf.com/content/WACV2023/papers/Kong_Pruning-Guided_Curriculum_Learning_for_Semi-Supervised_Semantic_Segmentation_WACV_2023_paper.pdf",
        "ref_texts": "[52] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2017.",
        "ref_ids": [
          "52"
        ]
      },
      "Lightweight attention network for very high-resolution image semantic segmentation": {
        "authors": [],
        "url": "https://iris.unitn.it/bitstream/11572/401461/1/TGRS3272614.pdf",
        "ref_texts": ""
      },
      "Semanticrt: A large-scale dataset and method for robust semantic segmentation in multispectral images": {
        "authors": [
          "Wei Ji"
        ],
        "url": "https://scholar.archive.org/work/t7wwq55sibaxzj2mcfj5lg7egq/access/wayback/https://dl.acm.org/doi/pdf/10.1145/3581783.3611738",
        "ref_texts": "[75] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. 2017. Pyramid scene parsing network. In CVPR. 2881\u20132890.",
        "ref_ids": [
          "75"
        ]
      },
      "Semantically structured image compression via irregular group-based decoupling": {
        "authors": [
          "Ruoyu Feng",
          "Yixin Gao",
          "Xin Jin",
          "Runsen Feng",
          "Zhibo Chen"
        ],
        "url": "https://openaccess.thecvf.com/content/ICCV2023/papers/Feng_Semantically_Structured_Image_Compression_via_Irregular_Group-Based_Decoupling_ICCV_2023_paper.pdf",
        "ref_texts": "[71] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , pages 2881\u20132890, 2017. 8",
        "ref_ids": [
          "71"
        ]
      },
      "Building a Winning Team: Selecting Source Model Ensembles using a Submodular Transferability Estimation Approach": {
        "authors": [
          "Vimal K",
          "Saketh Bachu",
          "Tanmay Garg",
          "Niveditha Lakshmi",
          "Raghavan Konuru",
          "Vineeth N"
        ],
        "url": "https://openaccess.thecvf.com/content/ICCV2023/papers/B_Building_a_Winning_Team_Selecting_Source_Model_Ensembles_using_a_ICCV_2023_paper.pdf",
        "ref_texts": "[60] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In 2017 IEEE Conference on Computer Vision and Pattern Recognition, pages 6230\u20136239, 2017. 1",
        "ref_ids": [
          "60"
        ]
      },
      "Semantic segmentation of urban building surface materials using multi-scale contextual attention network": {
        "authors": [
          "Fan Xu"
        ],
        "url": "https://felix-rz.github.io/pdf/2023_Semantic.pdf",
        "ref_texts": "Assouline, D., Mohajeri, N., Scartezzini, J.L., 2015. A machine learning methodology for estimating roof-top photovoltaic solar energy potential in Switzerland. In: Proceedings of International Conference CISBAT 2015 Future Buildings and Districts Sustainability from Nano To Urban Scale. (CONF), LESO-PB, EPFL, pp. 555\u2013560. Assouline, D., Mohajeri, N., Scartezzini, J.L., 2017. Quantifying rooftop photovoltaic solar energy potential: A machine learning approach. Sol. Energy 141, 278\u2013296. Bell, S., Upchurch, P., Snavely, N., Bala, K., 2013. OpenSurfaces: A richly annotated catalog of surface appearance. ACM Trans. Graph. 32 (4), 1\u201317. Bell, S., Upchurch, P., Snavely, N., Bala, K., 2015. Material recognition in the wild with the materials in context database. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. pp. 3479\u20133487. Boccalatte, A., Fossa, M., M\u00e9n\u00e9zo, C., 2020. Best arrangement of BIPV surfaces for future NZEB districts while considering urban heat island effects and the reduction of reflected radiation from solar fa\u00e7ades. Renew. Energy 160, 686\u2013697. Calcabrini, A., Ziar, H., Isabella, O., Zeman, M., 2019. A simplified skyline-based method for estimating the annual solar energy potential in urban environments. Nature Energy 4 (3), 206\u2013215. Chen, L.C., Papandreou, G., Schroff, F., Adam, H., 2017. Rethinking atrous convolution for semantic image segmentation. arXiv preprint arXiv:1706.05587. Chen, L.C., Yang, Y., Wang, J., Xu, W., Yuille, A.L., 2016. Attention to scale: Scaleaware semantic image segmentation. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. pp. 3640\u20133649. Chen, L.C., Zhu, Y., Papandreou, G., Schroff, F., Adam, H., 2018. Encoder-decoder with atrous separable convolution for semantic image segmentation. In: Proceedings of the European Conference on Computer Vision. ECCV, pp. 801\u2013818. Choi, Y., Suh, J., Kim, S.M., 2019. GIS-based solar radiation mapping, site evaluation, and potential assessment: A review. Appl. Sci. 9 (9), 1960. Dai, M., Meyers, G., Tingley, D.D., Mayfield, M., 2019. Initial investigations into using an ensemble of deep neural networks for building fa\u00e7ade image semantic segmentation. In: Remote Sensing Technologies and Applications in Urban Environments IV, Vol. 11157. International Society for Optics and Photonics, 1115708. Dana, K.J., Van Ginneken, B., Nayar, S.K., Koenderink, J.J., 1999. Reflectance and texture of real-world surfaces. ACM Trans. Graph. 18 (1), 1\u201334. Dehwah, A.H., Asif, M., Rahman, M.T., 2018. Prospects of PV application in unregulated building rooftops in developing countries: A perspective from Saudi Arabia. Energy Build. 171, 76\u201387. Electrical, Department, M.S., 2021. Hong Kong Energy End-use Data. https: //www.emsd.gov.hk/en/energy_efficiency/energy_end_use_data_and_consumption_ indicators/hong_kong_energy_end_use_data/data/index.html. Fritz, M., Hayman, E., Caputo, B., Eklundh, J.O., 2004. The kth-Tips Database. Citeseer. Gadde, R., Marlet, R., Paragios, N., 2016. Learning grammars for architecture-specific facade parsing. Int. J. Comput. Vis. 117 (3), 290\u2013316. Gassar, A.A.A., Cha, S.H., 2021. Review of geographic information systems-based rooftop solar photovoltaic potential estimation approaches at urban scales. Appl. Energy 291, 116817.Gu, J., Dong, C., 2021. Interpreting super-resolution networks with local attribution maps. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 9199\u20139208. He, K., Zhang, X., Ren, S., Sun, J., 2016. Deep residual learning for image recognition. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. pp. 770\u2013778. HO, D.C., Lo, S., Yiu, C., Yau, L., 2004. A survey of materials used in external wall finishes in Hong Kong. Ol. 15 Issue 2 December 2004. Jakubiec, J.A., Reinhart, C.F., 2013. A method for predicting city-wide electricity gains from photovoltaic panels based on LiDAR and GIS data combined with hourly daysim simulations. Sol. Energy 93, 127\u2013143. Kong, G., Fan, H., 2020. Enhanced facade parsing for street-level images using convolutional neural networks. IEEE Trans. Geosci. Remote Sens. 59 (12), 10519\u201310531. Korc, F., F\u00f6rstner, W., 2009. eTRIMS Image Database for Interpreting Images of ManMade Scenes. Tech. Rep. TR-IGG-P-2009-01, Dept. of Photogrammetry, University of Bonn. Li, Y., Ding, D., Liu, C., Wang, C., 2016. A pixel-based approach to estimation of solar energy potential on building roofs. Energy Build. 129, 563\u2013573. Lin, T.Y., Doll\u00e1r, P., Girshick, R., He, K., Hariharan, B., Belongie, S., 2017. Feature pyramid networks for object detection. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. pp. 2117\u20132125. Liu, H., Zhang, J., Zhu, J., Hoi, S.C., 2017. Deepfacade: A deep learning approach to facade parsing. IJCAI. Ma, W., Ma, W., Xu, S., Zha, H., 2020. Pyramid ALKNet for semantic parsing of building facade image. IEEE Geosci. Remote Sens. Lett. 18 (6), 1009\u20131013. Mallikarjuna, P., Targhi, A.T., Fritz, M., Hayman, E., Caputo, B., Eklundh, J.O., 2006. The kth-tips2 database. Comput. Vis. Active Percept. Lab., Stockholm, Sweden 11. Park, S., Kim, Y., Ferrier, N.J., Collis, S.M., Sankaran, R., Beckman, P.H., 2021. Prediction of solar irradiance and photovoltaic solar energy product based on cloud coverage estimation using machine learning methods. Atmosphere 12 (3), 395. Paszke, A., Gross, S., Massa, F., Lerer, A., Bradbury, J., Chanan, G., Killeen, T., Lin, Z., Gimelshein, N., Antiga, L., et al., 2019. Pytorch: An imperative style, high-performance deep learning library. Adv. Neural Inf. Process. Syst. 32. Redweik, P., Catita, C., Brito, M., 2013. Solar energy potential on roofs and facades in an urban landscape. Sol. Energy 97, 332\u2013341. Richter, M.L., Byttner, W., Krumnack, U., Wiedenroth, A., Schallner, L., Shenk, J., 2021."
      },
      "System configuration and navigation of a guide dog robot: Toward animal guide dog-level guiding work": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2210.13368",
        "ref_texts": ""
      },
      "Cross-modality features fusion for synthetic aperture radar image segmentation": {
        "authors": [],
        "url": "https://figshare.le.ac.uk/articles/journal_contribution/Cross-modality_features_fusion_for_synthetic_aperture_radar_image_segmentation/23976180/1/files/42038892.pdf",
        "ref_texts": "[21] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proc IEEE Comput Soc Conf Comput Vision Pattern Recognit , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "21"
        ]
      },
      "Classification of emotional stress and physical stress using a multispectral based deep feature extraction model": {
        "authors": [
          "Kan Hong"
        ],
        "url": "https://www.nature.com/articles/s41598-023-29903-3.pdf",
        "ref_texts": ""
      },
      "Learning to zoom and unzoom": {
        "authors": [
          "Chittesh Thavamani",
          "Mengtian Li",
          "Francesco Ferroni",
          "Deva Ramanan"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2023/papers/Thavamani_Learning_To_Zoom_and_Unzoom_CVPR_2023_paper.pdf",
        "ref_texts": "[29] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017. 2,7,8",
        "ref_ids": [
          "29"
        ]
      },
      "PRSeg: A lightweight patch rotate MLP decoder for semantic segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2305.00671",
        "ref_texts": "[62] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u2013",
        "ref_ids": [
          "62"
        ]
      },
      "Latent Graph Attention for Enhanced Spatial Context": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2307.04149",
        "ref_texts": "[17] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In IEEE Conference on Computer Vision and Pattern Recognition , pages 2881\u20132890, 2017. 3, 8",
        "ref_ids": [
          "17"
        ]
      },
      "Sparse model soups: A recipe for improved pruning via model averaging": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2306.16788",
        "ref_texts": "13 Published as a conference paper at ICLR 2024 Hidenori Tanaka, Daniel Kunin, Daniel L. K. Yamins, and Surya Ganguli. Pruning neural networks without any data by iteratively conserving synaptic flow. Advances in Neural Information Processing Systems 2020 , June 2020. Cuong Tran, Ferdinando Fioretto, Jung-Eun Kim, and Rakshit Naidu. Pruning has a disparate impact on model accuracy. In Alice H. Oh, Alekh Agarwal, Danielle Belgrave, and Kyunghyun Cho (eds.), Advances in Neural Information Processing Systems , 2022. URL https://openreview. net/forum?id=11nMVZK0WYM . Zhengzhong Tu, Hossein Talebi, Han Zhang, Feng Yang, Peyman Milanfar, Alan Bovik, and Yinxiao Li. Maxvit: Multi-axis vision transformer. In Computer Vision\u2013ECCV 2022: 17th European Conference, Tel Aviv, Israel, October 23\u201327, 2022, Proceedings, Part XXIV , pp. 459\u2013479. Springer, 2022. Johannes von Oswald, Seijin Kobayashi, Alexander Meulemans, Christian Henning, Benjamin F. Grewe, and Jo \u02dcao Sacramento. Neural networks with late-phase weights. Published as a conference paper at ICLR 2021 , July 2020. Tim Whitaker and Darrell Whitley. Prune and tune ensembles: Low-cost ensemble learning with sparse independent subnetworks. February 2022. Mitchell Wortsman, Ali Farhadi, and Mohammad Rastegari. Discovering neural wirings. In H. Wallach, H. Larochelle, A. Beygelzimer, F. d 'Alch \u00b4e-Buc, E. Fox, and R. Garnett (eds.), Advances in Neural Information Processing Systems , volume 32. Curran Associates, Inc., 2019. URL https://proceedings.neurips.cc/paper/2019/file/ d010396ca8abf6ead8cacc2c2f2f26c7-Paper.pdf . Mitchell Wortsman, Gabriel Ilharco, Samir Ya Gadre, Rebecca Roelofs, Raphael Gontijo-Lopes, Ari S Morcos, Hongseok Namkoong, Ali Farhadi, Yair Carmon, Simon Kornblith, et al. Model soups: averaging weights of multiple fine-tuned models improves accuracy without increasing inference time. In International Conference on Machine Learning , pp. 23965\u201323998. PMLR, 2022a. Mitchell Wortsman, Gabriel Ilharco, Jong Wook Kim, Mike Li, Simon Kornblith, Rebecca Roelofs, Raphael Gontijo Lopes, Hannaneh Hajishirzi, Ali Farhadi, Hongseok Namkoong, et al. Robust fine-tuning of zero-shot models. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pp. 7959\u20137971, 2022b. Lu Yin, Shiwei Liu, Fang Meng, Tianjin Huang, Vlado Menkovski, and Mykola Pechenizkiy. Lottery pools: Winning more by interpolating tickets without increasing training or inference cost. August 2022a. Lu Yin, Vlado Menkovski, Meng Fang, Tianjin Huang, Yulong Pei, Mykola Pechenizkiy, Decebal Constantin Mocanu, and Shiwei Liu. Superposing many tickets into one: A performance booster for sparse neural network training. May 2022b. Sergey Zagoruyko and Nikos Komodakis. Wide residual networks. arXiv preprint arXiv:1605.07146 , May 2016. Chiyuan Zhang, Samy Bengio, Moritz Hardt, Benjamin Recht, and Oriol Vinyals. Understanding deep learning requires rethinking generalization. arXiv preprint arXiv:1611.03530 , November 2016. Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pp."
      },
      "Conv-trans dual network for landslide detection of multi-channel optical remote sensing images": {
        "authors": [
          "Xin Chen"
        ],
        "url": "https://www.frontiersin.org/articles/10.3389/feart.2023.1182145/pdf",
        "ref_texts": "10,279.doi: 10.3390/rs10020279 Zhao,H.,Shi,J.,Qi,X.,Wang,X.,andJia,J.(2017).\u201cPyramidsceneparsingnetwork,\u201d inProceedings of the IEEE conference on computer vision and pattern recognition , 2881\u20132890. Zheng, S., Lu, J., Zhao, H., Zhu, X., Luo, Z., Wang, Y., et al. (2021). \u201cRethinking semantic segmentation from a sequence-to-sequence perspective with transformers,\u201d inProceedings of the IEEE/CVF conference on computer vision and pattern recognition , 6881\u20136890. Frontiers in Earth Science 14 frontiersin.org "
      },
      "Efficient semantic segmentation by altering resolutions for compressed videos": {
        "authors": [
          "Yubin Hu",
          "Yuze He",
          "Yanghao Li",
          "Jisheng Li",
          "Yuxing Han",
          "Jiangtao Wen",
          "Jin Liu"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Hu_Efficient_Semantic_Segmentation_by_Altering_Resolutions_for_Compressed_Videos_CVPR_2023_paper.pdf",
        "ref_texts": "[55] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In 2017 IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2017, Honolulu, HI, USA, July 21-26, 2017 , pages 6230\u20136239. IEEE Computer Society, 2017. 1, 2, 5, 6",
        "ref_ids": [
          "55"
        ]
      },
      "Dual-branch-UNnet: A dual-branch convolutional neural network for medical image segmentation": {
        "authors": [],
        "url": "https://researchrepository.ul.ie/articles/journal_contribution/Dual-branch-UNnet_A_dual-branch_convolutional_neural_network_for_medical_image_segmentation/24325061/1/files/42746429.pdf",
        "ref_texts": "21. Zhao, H. S., Shi, J. P ., Qi, X. J., Wang, X. G., Jia, J. Y . (2017). Pyramid scene parsing network. Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , no. 1612, pp. 6320\u20136329. Hawaii, USA.",
        "ref_ids": [
          "21"
        ]
      },
      "Detect any shadow: Segment anything for video shadow detection": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2305.16698",
        "ref_texts": "[62] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "62"
        ]
      },
      "Segmentation of industrial burner flames: a comparative study from traditional image processing to machine and deep learning": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2306.14789",
        "ref_texts": "2009 IEEE Conference on Computer Vision and Pattern Recognition , IEEE, Miami, FL, 248\u2013255. Fan, H., Cong, Y ., Xia, Y ., Shao, W., Wang, Y ., 2014. Flame front detection and curvature calculation using level set. Proceeding of the 11th World Congress on Intelligent Control and Automation , IEEE, 2918\u20132922. Gro\u00dfkopf, J., Matthes, J., V ogelbacher, M., Waibel, P., 2021. Evaluation of deep learning-based segmentation methods for industrial burner flames. Energies , 14(6), 1716. He, K., Zhang, X., Ren, S., Sun, J., 2016. Deep residual learning for image recognition. Proceedings of the IEEE conference on computer vision and pattern recognition , 770\u2013778. Hearst, M. A., Dumais, S. T., Osuna, E., Platt, J., Scholkopf, B., 1998. Support vector machines. IEEE Intelligent Systems and their applications , 13(4), 18\u201328. Howard, A., Sandler, M., Chu, G., Chen, L.-C., Chen, B., Tan, M., Wang, W., Zhu, Y ., Pang, R., Vasudevan, V . et al., 2019. Searching for mobilenetv3. Proceedings of the IEEE/CVF international conference on computer vision , 1314\u20131324. Jamali, M., Samavi, S., Nejati, M., Mirmahboub, B., 2013. Outdoor fire detection based on color and motion characteristics.2013 21st Iranian Conference on Electrical Engineering (ICEE) , IEEE, 1\u20136. Landgraf, S., K \u00a8uhnlein, L., Hillemann, M., Hoyer, M., Keller, S., Ulrich, M., 2022. Evaluation of self-supervised learning approaches for semantic segmentation of industrial burner flames. The International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences , XLIIIB2-2022, 601\u2013607. Lee, S. U., Chung, S. Y ., Park, R. H., 1990. A comparative performance study of several global thresholding techniques for segmentation. Computer Vision, Graphics, and Image Processing , 52(2), 171\u2013190. Li, Y ., Wang, L., 2020. Flame image segmentation algorithm based on motion and color saliency. Communications, Signal Processing, and Systems: Proceedings of the 2018 CSPS Volume II: Signal Processing 7th , Springer, 184\u2013191. Liang, J.-X., Zhao, J.-F., Sun, N., Shi, B.-J., 2022. Random forest feature selection and back propagation neural network to detect fire using video. Journal of Sensors , 2022, 1\u201310. Long, J., Shelhamer, E., Darrell, T., 2015. Fully convolutional networks for semantic segmentation. Proceedings of the IEEE conference on computer vision and pattern recognition , 3431\u20133440.Matthes, J., Waibel, P., V ogelbacher, M., Gehrmann, H.-J., Keller, H., 2019. A new camera-based method for measuring the flame stability of non-oscillating and oscillating combustions. Experimental Thermal and Fluid Science , 105, 27\u201334. McClelland, J. L., Rumelhart, D. E., Group, P. R. et al., 1987. Parallel Distributed Processing, Volume 2: Explorations in the Microstructure of Cognition: Psychological and Biological Models . 2, MIT press. MVTec Software GmbH, 2023. HALCON operator reference. Paszke, A., Gross, S., Massa, F., Lerer, A., Bradbury, J., Chanan, G., Killeen, T., Lin, Z., Gimelshein, N., Antiga, L., Desmaison, A., K \u00a8opf, A., Yang, E., DeVito, Z., Raison, M., Tejani, A., Chilamkurthy, S., Steiner, B., Fang, L., Bai, J., Chintala, S., 2019. PyTorch: An Imperative Style, HighPerformance Deep Learning Library. arXiv:1912.01703 . Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V ., Thirion, B., Grisel, O., Blondel, M., Prettenhofer, P., Weiss, R., Dubourg, V . et al., 2011. Scikit-learn: Machine learning in Python. the Journal of machine Learning research , 12, 2825\u20132830. Robbins, H., Monro, S., 1951. A stochastic approximation method. The annals of mathematical statistics , 400\u2013407. Ronneberger, O., Fischer, P., Brox, T., 2015. U-net: Convolutional networks for biomedical image segmentation. Medical Image Computing and Computer-Assisted Intervention\u2013 MICCAI 2015: 18th International Conference, Munich, Germany, October 5-9, 2015, Proceedings, Part III 18 , Springer, 234\u2013241. Steger, C., Ulrich, M., Wiedemann, C., 2018. Machine Vision Algorithms and Applications . John Wiley & Sons. Van der Walt, S., Sch \u00a8onberger, J. L., Nunez-Iglesias, J., Boulogne, F., Warner, J. D., Yager, N., Gouillart, E., Yu, T., 2014. scikit-image: image processing in Python. PeerJ , 2, e453. Wang, S., He, Y ., Zou, J., Duan, B., Wang, J., 2014. A flame detection synthesis algorithm. Fire Technology , 50, 959\u2013975. Wang, Z., Peng, T., Lu, Z., 2022. Comparative research on forest fire image segmentation algorithms based on fully convolutional neural networks. Forests , 13(7), 1133. Zhang, Z., Zhao, J., Yuan, Z., Zhang, D., Han, S., Qu, C., 2009. Color based segmentation and shape based matching of forest flames from monocular images. 2009 International Conference on Multimedia Information Networking and Security , 1, IEEE, 625\u2013628. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J., 2017. Pyramid scene parsing network. Proceedings of the IEEE conference on computer vision and pattern recognition , 2881\u20132890. Zhao, J., Zhang, Z., Han, S., Qu, C., Yuan, Z., Zhang, D., 2011. SVM based forest fire detection using static and dynamic features. Computer Science and Information Systems , 8(3), 821\u2013841. Zhong, Z., Wang, M., Shi, Y ., Gao, W., 2018. A convolutional neural network-based flame detection method in video sequence. Signal, Image and Video Processing , 12, 1619\u20131627. APPENDIX Figure 5. More qualitative comparisons between the input image in the first row, the ground truth in the second row, the segmentation results of GTH in the third row, RF in the fourth row, and DL3+ (RN18-I) in the last row."
      },
      "NOC: High-Quality Neural Object Cloning with 3D Lifting of Segment Anything": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2309.12790",
        "ref_texts": "[63] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017. 2",
        "ref_ids": [
          "63"
        ]
      },
      "Panoramic panoptic segmentation: Insights into surrounding parsing for mobile agents via unsupervised contrastive learning": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2206.10711",
        "ref_texts": "[24] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proc. CVPR , 2017, pp. 6230\u20136239.",
        "ref_ids": [
          "24"
        ]
      },
      "Boosting salient object detection with transformer-based asymmetric bilateral U-Net": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2108.07851",
        "ref_texts": "[78] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in IEEE Conf. Comput. Vis. Pattern Recog. (CVPR) , 2017, pp.",
        "ref_ids": [
          "78"
        ]
      },
      "Avatar knowledge distillation: self-ensemble teacher paradigm with uncertainty": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2305.02722",
        "ref_texts": "[57] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. 2017. Pyramid scene parsing network. In CVPR . 2881\u20132890.",
        "ref_ids": [
          "57"
        ]
      },
      "End-to-end video matting with trimap propagation": {
        "authors": [
          "Lun Huang",
          "Sui Lee"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Huang_End-to-End_Video_Matting_With_Trimap_Propagation_CVPR_2023_paper.pdf",
        "ref_texts": "[56] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 2881\u20132890, 2017. 3",
        "ref_ids": [
          "56"
        ]
      },
      "Robust double-encoder network for rgb-d panoptic segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2210.02834",
        "ref_texts": "[44] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid Scene Parsing Network. In Proc. of the IEEE/CVF Conf. on Computer Vision and Pattern Recognition (CVPR) , 2017.",
        "ref_ids": [
          "44"
        ]
      },
      "Rethinking lightweight salient object detection via network depth-width tradeoff": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2301.06679",
        "ref_texts": "[37] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "37"
        ]
      },
      "RGB-D salient object detection via convolutional capsule network based on feature extraction and integration": {
        "authors": [
          "Kun Xu"
        ],
        "url": "https://www.nature.com/articles/s41598-023-44698-z.pdf",
        "ref_texts": ""
      },
      "FsaNet: Frequency self-attention for semantic segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2211.15595",
        "ref_texts": "[22] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "22"
        ]
      },
      "Automatic high resolution wire segmentation and removal": {
        "authors": [
          "Mang Tik",
          "Xuaner Zhang",
          "Zijun Wei",
          "Yuqian Zhou",
          "Eli Shechtman",
          "Connelly Barnes",
          "Zhe Lin",
          "Florian Kainz",
          "Sohrab Amirghodsi",
          "Humphrey Shi"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2023/papers/Chiu_Automatic_High_Resolution_Wire_Segmentation_and_Removal_CVPR_2023_paper.pdf",
        "ref_texts": "[48] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 2881\u20132890, 2017. 2",
        "ref_ids": [
          "48"
        ]
      },
      "Flare7k++: Mixing synthetic and real datasets for nighttime flare removal and beyond": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2306.04236",
        "ref_texts": "[45] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In IEEE Conference on Computer Vision and Pattern Recognition , 2017.",
        "ref_ids": [
          "45"
        ]
      },
      "Watt for what: Rethinking deep learning's energy-performance relationship": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2310.06522",
        "ref_texts": "62. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: Proceedings of the IEEE conference on computer vision and pattern recognition. pp. 2881\u20132890 (2017) 6",
        "ref_ids": [
          "62"
        ]
      },
      "Oil spill identification based on dual attention UNet model using synthetic aperture radar images": {
        "authors": [
          "Amira S. Mahmoud"
        ],
        "url": "https://link.springer.com/content/pdf/10.1007/s12524-022-01624-6.pdf",
        "ref_texts": "(21), 9427\u20139447. Zeng, K., & Wang, Y. (2020). A deep convolutional neural network for oil spill detection from spaceborne SAR images. Remote Sensing, 12 (6), 1015. Zhang, K., Zhong, G., Dong, J., Wang, S., & Wang, Y. (2019). Stock market prediction based on generative adversarial network.Procedia Computer Science, 147 , 400\u2013406. Zhang, X., Jin, J., Lan, Z., Li, C., Fan, M., Wang, Y., Xin, Yu., & Zhang, Y. (2020). ICENET: A semantic segmentation deepnetwork for river ice by fusing positional and channel-wiseattentive features. Remote Sensing, 12 (2), 221. Zhang, Y., Yu Li, X., Liang, S., & Tsou, J. (2017). Comparison of oil spill classifications using fully and compact polarimetric SARimages. Applied Sciences, 7 (2), 193. Zhao, H., Shi, J., Qi, X., Wang, X. and Jia, J. (2017). Pyramid scene parsing network. Paper presented at the Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. Zhu, L., Zhan, S., & Zhang, H. (2019). Stacked U-shape networks with channel-wise attention for image super-resolution. Neurocomputing, 345 , 58\u201366. Publisher\u2019s Note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.Journal of the Indian Society of Remote Sensing (January 2023) 51(1):121\u2013133 133"
      },
      "Multimodal transformer for material segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2309.04001",
        "ref_texts": "[54] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "54"
        ]
      },
      "Efficient and effective methods for mixed precision neural network quantization for faster, energy-efficient inference": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2301.13330",
        "ref_texts": "1\u201316. Springer, 2020. Zafrir, O., Boudoukh, G., Izsak, P., and Wasserblat, M. Q8bert: Quantized 8bit bert. In 2019 Fifth Workshop on Energy Efficient Machine Learning and Cognitive Computing-NeurIPS Edition (EMC2-NIPS) , pp. 36\u201339. IEEE, 2019. Zhang, D., Yang, J., Ye, D., and Hua, G. Lq-nets: Learned quantization for highly accurate and compact deep neural networks. InProceedings of the European conference on computer vision (ECCV) , pp. 365\u2013382, 2018. Zhang, W., Hou, L., Yin, Y ., Shang, L., Chen, X., Jiang, X., and Liu, Q. Ternarybert: Distillation-aware ultra-low bit bert. arXiv preprint arXiv:2009.12812 , 2020. Zhao, H., Shi, J., Qi, X., Wang, X., and Jia, J. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pp. 2881\u20132890, 2017. Zhou, S., Wu, Y ., Ni, Z., Zhou, X., Wen, H., and Zou, Y . Dorefanet: Training low bitwidth convolutional neural networks with low bitwidth gradients. arXiv preprint arXiv:1606.06160 , 2016. Zhou, Y ., Moosavi-Dezfooli, S.-M., Cheung, N.-M., and Frossard, P. Adaptive quantization for deep neural network. In Proceedings of the AAAI Conference on Artificial Intelligence , volume 32, 2018. Zhu, C., Han, S., Mao, H., and Dally, W. J. Trained ternary quantization. arXiv preprint arXiv:1612.01064 , 2016. Efficient and Effective Methods for Mixed Precision Neural Network Quantization for Faster, Energy-efficient Inference Figure 6. Accuracy drop in 80 random pairs of ResNet-50 layers is additive, justifying the assumptions of the optimization methodology (See text for details). A. Demonstration of additivity of layer-wise accuracy estimates Two experiments were conducted to test the assumption that layerwise accuracy estimates can be combined linearly to determine overall network accuracy. This assumption is implicit in the use of the knapsack optimization algorithm. The first experiment directly tests whether the drop in accuracy when quantizing two layers at a time, L1andL2, is the same as the sum of accuracy decline when each is quantized alone. Specifically start with a 4-bit ResNet-50 network fine-tuned with Quantization Aware Training as described in the methods. Then, for each layer, measure DpLq, the Top-1 training set accuracy drop when that layer\u2019s precision is dropped from 4-bit to 2-bit, with no further fine-tuning. For 80 random pairs of layers,\u0103L1, L2\u0105, 1) predict the accuracy drop as DpL1q`DpL2q, and 2) measure the actual drop in training set accuracy with both layers reduced to 2 bits, with no further fine-tuning. Figure 6 plots the predicted versus actual accuracy drop. The two measures are strongly correlated (R=0.98), indicating that the assumption of linearity required by the optimization methodology is justified. The second experiment is a more stringent test of linearity; instead of testing pairs-wise linearity, it tests the linearity of arbitrary combinations of layers by testing whether an accurate linear regression model can be constructed to predict the network accuracy given only the precision choices for all layers. Specifically, to test if a linear regression model can predict the accuracy of mixed precision models given the layer-wise precision settings: 1) Train 135 stratified random mixed-precision ResNet-50 networks for 30 epochs as described in the methods section, i.e. 3 networks each for 2, 3, . . . , 46 randomly chosen layers at 2-bit, in an otherwise 4-bit network. 2) For each training run record a) the precision of each layer as 48-element binary vector, where 0 and 1 indicate 2 and 4 bits, respectively, and b) the final accuracy on the validation set. 3) Divide the 135 samples into training/hold-out set randomly (90%/10%). 4) Perform linear regression on the training set. 5) Use the model to predict the network accuracy on the training samples and hold-out set to compare with the actual scores. Figure 7 shows the actual Top-1 accuracy on the benchmark versus the linear regression model\u2019s prediction for the samples used to create the model (left), and the hold-out set (right). The figure shows that the overall network accuracy can be modeled very well as a linear combination of the individual layer accuracy contributions (R=0.9996 on the model training data; R=0.9994 on the hold-out data). This provides further evidence for linearity required by the knapsack solver used herein. Efficient and Effective Methods for Mixed Precision Neural Network Quantization for Faster, Energy-efficient Inference Figure 7. A linear regression model accurately predicts the overall network accuracy given the individual layer precision settings, further justifying the linearity assumption of the optimization methodology (See text for details). B. On the quality of the EAGL and ALPS solutions It would be ideal to be able to compare the EAGL and ALPS solutions against a ground-truth measure. Although exhaustive search to provide such is infeasible, an additional experiment was conducted using ResNet-50 in an attempt to measure how well the EAGL and ALPS solutions compare with the strongest, although impractical, layer selection metric that we could construct. Given the accuracy of the regression model in Section A in determining the overall accuracy of the network given the layer precisions, the linear coefficient for layer lin the model was used as Gl, providing an alternative layer selection metric. The frontier was then found using the same knapsack optimization procedure as for EAGL and ALPS described above. Each method was trained for 30 epochs at each budget (N=6 for each datapoint). It can be argued that this provides very good solutions since 1) As was shown in Figure 7 and described in the previous section, the regression model coefficients accurately reflect the layer-wise contributions to total network accuracy (hold-out set residual error standard deviation=0.068%), and 2) the knapsack optimizer will provide an \u03f5-optimal solution to the problem subject to the quality of the layerwise accuracy estimates. Figure 8 shows the results of this experiment, where the mean and standard-deviation of the Top-1 accuracy of mixedprecision networks are shown for each of 8 computational budgets. Note that ALPS and EAGL are very close to the frontier provided by the accurate regression model, supporting the quality of the solutions provided by the proposed methods, which are computationally tractable7. Perhaps there is little room for improvement beyond that of ALPS and EAGL. C. Re-implementation of HA WQ-v3 To compare EAGL and ALPS results with those of HAWQ-v3 in a 2and 4-bit mixed precision network, it was necessary to use the author\u2019s implementation for comparison, since 2/4 bit results were not reported for ResNet50 with the constraint that both weights and inputs to a convolutional layer had to have the same precision. Furthermore, no results were reported for PSPNet. For a commensurate comparison, HAWQ-v3 was evaluated using the same initial checkpoint and network used in our ALPS and EAGL experiments. Additionally, the 0-1 Knapsack optimization algorithm was used to make precision choices given the layer-wise metric used in (Dong et al., 2019). Specifically, their Pyhessian implementation (Yao et al., 2020) was used 7It took approximately 1,080 A100 GPU hours to create the regression model for ResNet-50, making it impractical as a layer selection method in practice. Efficient and Effective Methods for Mixed Precision Neural Network Quantization for Faster, Energy-efficient Inference Figure 8. EAGL and ALPS frontiers are very close to a frontier generated using the coefficients from an accurate regression model on ResNet-50, a computationally expensive, but arguably stronger accuracy-aware method (see text for details). to calculate the average Hessian trace of each layer and estimate the accuracy gain for keeping layers at 4-bit as TracepHq||Q4pWq\u00b4Q2pWq||2"
      },
      "Complementary bi-directional feature compression for indoor 360deg semantic segmentation with self-distillation": {
        "authors": [
          "Zishuo Zheng",
          "Chunyu Lin",
          "Lang Nie",
          "Kang Liao",
          "Zhijie Shen",
          "Yao Zhao"
        ],
        "url": "https://openaccess.thecvf.com/content/WACV2023/papers/Zheng_Complementary_Bi-Directional_Feature_Compression_for_Indoor_360deg_Semantic_Segmentation_With_WACV_2023_paper.pdf",
        "ref_texts": "[44] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "44"
        ]
      },
      "Crop classification in high-resolution remote sensing images based on multi-scale feature fusion semantic segmentation model": {
        "authors": [],
        "url": "https://www.frontiersin.org/journals/plant-science/articles/10.3389/fpls.2023.1196634/pdf",
        "ref_texts": "381. doi: 10.1108/IR-06-2021-0118 Xie, J., He, N., Fang, L., and Ghamisi, P. (2021). Multiscale densely-connected fusion networks for hyperspectral images classi fication. IEEE Trans. Circuits Syst. Video Technol. 31 (1), 246 \u2013259. doi: 10.1109/TCSVT.2020.2975566 Xu, J., Yang, J., Xiong, X., Li, H., and Lin, T. (2021). Towards interpreting multitemporal deep learning models in crop mapping. Remote Sens. Environ. 264, 112599. doi:10.1016/j.rse.2021.112599 Y u ,F . ,a n dK o l t u n ,V .(2 0 1 6 ) .M u l t i s cale context aggre gation by dilated convolutions. arXiv:1511.07122 . doi: 10.48550/arXiv.1511.07122 Yuan, Z., Liu, Z., Zhu, C., Qi, J., and Zhao, D. (2021). Object detection in remote sensing images viamulti-feature pyramid network with receptive field block. Remote Sens. 13 (5), 862. doi: 10.3390/rs13050862 Y u a n ,L . ,Y u a n ,J . ,a n dZ h a n g ,D .(2 0 1 9 ) .R e m o t es e n s i n gi m a g ec l a s s i fication based on DeepLab-v3+. Laser Optoelectronics Prog. 56 (15), 152801. doi: 10.3788/LOP56.152801 Zhao, H., Shi, J., Qi, X., Wang, X., and Jia, J. (2017). \u201cPyramid scene parsing network, \u201dinProceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) . 2881 \u20132890. Zhong, L., Hu, L., and Zhou, H. (2018). Deep learning based multi-temporal crop classi fication. Remote Sens. Environ. 221, 430 \u2013443. doi: 10.1016/j.rse.2018.11.032Lu et al. 10.3389/fpls.2023.1196634 Frontiers in Plant Science frontiersin.org 16",
        "ref_ids": [
          "381"
        ]
      },
      "Superpixel transformers for efficient semantic segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2309.16889",
        "ref_texts": "[54] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017.",
        "ref_ids": [
          "54"
        ]
      },
      "Efficient multi-task scene analysis with rgb-d transformers": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2306.05242",
        "ref_texts": "[38] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid Scene Parsing Network,\u201d in Proc. of CVPR , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "38"
        ]
      },
      "WSNet: towards an effective method for wound image segmentation": {
        "authors": [
          "Subba Reddy",
          "Vijay Rowtula",
          "Shahid Mohammed",
          "Minghsun Liu",
          "Manish Gupta"
        ],
        "url": "https://openaccess.thecvf.com/content/WACV2023/papers/Oota_WSNet_Towards_an_Effective_Method_for_Wound_Image_Segmentation_WACV_2023_paper.pdf",
        "ref_texts": "[43] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017.",
        "ref_ids": [
          "43"
        ]
      },
      "Attention mechanisms in computer vision: A survey": {
        "authors": [],
        "url": "https://link.springer.com/content/pdf/10.1007/s41095-022-0271-y.pdf",
        "ref_texts": "[157] Zhao, H. S.; Shi, J. P.; Qi, X. J.; Wang, X. G.; Jia, J. Y. Pyramid scene parsing network. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 6230\u20136239, 2017.",
        "ref_ids": [
          "157"
        ]
      },
      "Masked-attention mask transformer for universal image segmentation": {
        "authors": [
          "Bowen Cheng",
          "Ishan Misra",
          "Alexander G. Schwing",
          "Alexander Kirillov",
          "Rohit Girdhar"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2022/papers/Cheng_Masked-Attention_Mask_Transformer_for_Universal_Image_Segmentation_CVPR_2022_paper.pdf",
        "ref_texts": "[63] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017.",
        "ref_ids": [
          "63"
        ]
      },
      "Segnext: Rethinking convolutional attention design for semantic segmentation": {
        "authors": [],
        "url": "https://proceedings.neurips.cc/paper_files/paper/2022/file/08050f40fff41616ccfc3080e60a301a-Paper-Conference.pdf",
        "ref_texts": "[106] Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 2881\u20132890 (2017)",
        "ref_ids": [
          "106"
        ]
      },
      "Swin-unet: Unet-like pure transformer for medical image segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2105.05537",
        "ref_texts": "14. H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \\Pyramid scene parsing network,\" in2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2017, pp. 6230{6239. Swin-Unet: Unet-like Pure Transformer for Medical Image Segmentation 13",
        "ref_ids": [
          "14"
        ]
      },
      "Decoupled knowledge distillation": {
        "authors": [
          "Borui Zhao",
          "Quan Cui",
          "Renjie Song",
          "Yiyu Qiu",
          "Jiajun Liang"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2022/papers/Zhao_Decoupled_Knowledge_Distillation_CVPR_2022_paper.pdf",
        "ref_texts": "[45] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017. 1",
        "ref_ids": [
          "45"
        ]
      },
      "Toward fast, flexible, and robust low-light image enhancement": {
        "authors": [
          "Long Ma",
          "Tengyu Ma",
          "Risheng Liu",
          "Xin Fan",
          "Zhongxuan Luo"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2022/papers/Ma_Toward_Fast_Flexible_and_Robust_Low-Light_Image_Enhancement_CVPR_2022_paper.pdf",
        "ref_texts": "[38] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceeding of the IEEE Conference on Computer Vision and Pattern Recognition , pages 2881\u20132890, 2017. 8",
        "ref_ids": [
          "38"
        ]
      },
      "Groupvit: Semantic segmentation emerges from text supervision": {
        "authors": [
          "Jiarui Xu",
          "Shalini De",
          "Sifei Liu",
          "Wonmin Byeon",
          "Thomas Breuel",
          "Jan Kautz",
          "Xiaolong Wang"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_GroupViT_Semantic_Segmentation_Emerges_From_Text_Supervision_CVPR_2022_paper.pdf",
        "ref_texts": "[90] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017. 8",
        "ref_ids": [
          "90"
        ]
      },
      "Denseclip: Language-guided dense prediction with context-aware prompting": {
        "authors": [
          "Yongming Rao",
          "Wenliang Zhao",
          "Guangyi Chen",
          "Yansong Tang",
          "Zheng Zhu",
          "Guan Huang",
          "Jie Zhou",
          "Jiwen Lu"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2022/papers/Rao_DenseCLIP_Language-Guided_Dense_Prediction_With_Context-Aware_Prompting_CVPR_2022_paper.pdf",
        "ref_texts": "[57] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , pages 2881\u20132890, 2017. 3, 6",
        "ref_ids": [
          "57"
        ]
      },
      "Daformer: Improving network architectures and training strategies for domain-adaptive semantic segmentation": {
        "authors": [
          "Lukas Hoyer",
          "Dengxin Dai",
          "Luc Van"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2022/papers/Hoyer_DAFormer_Improving_Network_Architectures_and_Training_Strategies_for_Domain-Adaptive_Semantic_CVPR_2022_paper.pdf",
        "ref_texts": "[89] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In IEEE Conf. Comput. Vis. Pattern Recog. , pages 2881\u20132890, 2017. 2",
        "ref_ids": [
          "89"
        ]
      },
      "Resnest: Split-attention networks": {
        "authors": [
          "Hang Zhang",
          "Chongruo Wu",
          "Zhongyue Zhang",
          "Yi Zhu",
          "Haibin Lin",
          "Zhi Zhang",
          "Yue Sun",
          "Tong He",
          "Jonas Mueller",
          "Mu Li",
          "Alexander Smola"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2022W/ECV/papers/Zhang_ResNeSt_Split-Attention_Networks_CVPRW_2022_paper.pdf",
        "ref_texts": "[69] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2017. 8[70] Hengshuang Zhao, Yi Zhang, Shu Liu, Jianping Shi, Chen Change Loy, Dahua Lin, and Jiaya Jia. PSANet: Pointwise Spatial Attention Network for Scene Parsing. In European Conference on Computer Vision (ECCV) , 2018. 8",
        "ref_ids": [
          "69",
          "70"
        ]
      },
      "Semi-supervised semantic segmentation using unreliable pseudo-labels": {
        "authors": [
          "Yuchao Wang",
          "Haochen Wang",
          "Yujun Shen",
          "Jingjing Fei",
          "Wei Li",
          "Guoqiang Jin",
          "Liwei Wu",
          "Rui Zhao",
          "Xinyi Le"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Semi-Supervised_Semantic_Segmentation_Using_Unreliable_Pseudo-Labels_CVPR_2022_paper.pdf",
        "ref_texts": "[47] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In IEEE Conf. Comput. Vis. Pattern Recog. , 2017. 1, 8",
        "ref_ids": [
          "47"
        ]
      },
      "UNetFormer: A UNet-like transformer for efficient semantic segmentation of remote sensing urban scene imagery": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2109.08937",
        "ref_texts": "48 Processing Systems 34. Xing, J., Sieber, R., Caelli, T., 2018. A scale -invariant change detection method for land use/cover change research. ISPRS Journal of Photogrammetry and Remote Sensing 141, 252264. Xu, W., Xu, Y ., Chang, T., Tu, Z., 2021. CoScale Con v-Attentional Image Transformers. Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV), 99819990. Yang, M.Y ., Kumaar, S., Lyu, Y ., Nex, F., 2021a. Real -time Semantic Segmentation with Context Aggregation Network. ISPRS Journal of Photogrammetry and Remote Sensing 178, 124134. Yang, X., Li, S., Chen, Z., Chanussot, J., Jia, X., Zhang, B., Li, B., Chen, P., 2021b. An attentionfused network for semantic segmentation of very -high-resolution remote sensing imagery. ISPRS Journal of P hotogrammetry and Remote Sensing 177, 238262. Yin, H., Pflugmacher, D., Li, A., Li, Z., Hostert, P., 2018. Land use and land cover change in Inner Mongolia -understanding the effects of China's re -vegetation programs. Remote Sensing of Environment 204, 918930. Yu, C., Gao, C., Wang, J., Yu, G., Shen, C., Sang, N., 2020. Bisenet v2: Bilateral network with guided aggregation for real -time semantic segmentation. arXiv preprint arXiv:2004.02147. Yu, C., Wang, J., Peng, C., Gao, C., Yu, G., Sang, N., 2018. Bise net: Bilateral segmentation network for real -time semantic segmentation, Proceedings of the European conference on computer vision (ECCV), pp. 325341. Yuan, Y ., Chen, X., Wang, J., 2020. Object -contextual representations for semantic segmentation, Compute r Vision \u2013ECCV 2020: 16th European Conference, Glasgow, UK, August 23\u201328, 2020, Proceedings, Part VI 16. Springer, pp. 173190. Yue, K., Yang, L., Li, R., Hu, W., Zhang, F., Li, W., 2019. TreeUNet: Adaptive Tree convolutional neural networks for subdecimeter aerial image segmentation. ISPRS Journal of Photogrammetry and Remote Sensing 156, 1 -13. Zhang, C., Atkinson, P.M., George, C., Wen, Z., Diazgranados, M., Gerard, F., 2020a. Identifying and mapping individual plants in a highly diverse highelevation eco system using UA V imagery and deep learning. ISPRS Journal of Photogrammetry and Remote Sensing 169, 280291. Zhang, C., Harrison, P.A., Pan, X., Li, H., Sargent, I., Atkinson, P.M., 2020b. Scale Sequence Joint Deep Learning (SS -JDL) for land use and land cover classification. Remote Sensing of Environment 237, 111593. Zhang, C., Jiang, W.S., Zhang, Y ., Wang, W., Zhao, Q., Wang, C.J., 2022. Transformer and CNN Hybrid Deep Neural Network for Semantic Segmentation of Very -high-resolution Remote Sensing Imagery . IEEE Transactions on Geoscience and Remote Sensing. Zhang, Q., Yang, Y ., 2021. ResT: An Efficient Transformer for Visual Recognition. arXiv preprint arXiv:2105.13677. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J., 2017a. Pyramid scene parsing network, Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 28812890. Zhao, W., Du, S., 2016. Learning multiscale and deep representations for classifying remotely sensed imagery. ISPRS Journal of Photogrammetry and Remote Sensing 113, 155 -165. Zhao, W., Du, S., Wang, Q., Emery, W.J., 2017b. Contextually guided veryhigh-resolution imagery classification with semantic segments. ISPRS Journal of Photogrammetry and Remote Sensing 132, 4860. Zheng, S., Lu, J., Zhao, H., Zhu, X., Luo, Z., Wang, Y ., Fu, Y ., Feng, J., Xiang, T., Torr, P.H., 2021. "
      },
      "Extract free dense labels from clip": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2112.01071",
        "ref_texts": "55. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: CVPR (2017)",
        "ref_ids": [
          "55"
        ]
      },
      "Kitti-360: A novel dataset and benchmarks for urban scene understanding in 2d and 3d": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2109.13410",
        "ref_texts": "[115] R. Zhang, P . Isola, A. A. Efros, E. Shechtman, and O. Wang, \u201cThe unreasonable effectiveness of deep features as a perceptual metric,\u201d in CVPR , 2018. 14, [116] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in CVPR , 2017. 7, 9, 12, 14, 15, [117] X. Zhu, Y. Xiong, J. Dai, L. Yuan, and Y. Wei, \u201cDeep feature flow for video recognition,\u201d in CVPR , 2017. 4",
        "ref_ids": [
          "115",
          "116",
          "117"
        ]
      },
      "Rethinking semantic segmentation: A prototype view": {
        "authors": [
          "Tianfei Zhou",
          "Wenguan Wang",
          "Ender Konukoglu",
          "Luc Van"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2022/papers/Zhou_Rethinking_Semantic_Segmentation_A_Prototype_View_CVPR_2022_paper.pdf",
        "ref_texts": "[135] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017. 1, 5, 7",
        "ref_ids": [
          "135"
        ]
      },
      "Panoptic neural fields: A semantic object-aware neural scene representation": {
        "authors": [
          "Abhijit Kundu",
          "Kyle Genova",
          "Xiaoqi Yin",
          "Alireza Fathi",
          "Caroline Pantofaru",
          "Leonidas J. Guibas",
          "Andrea Tagliasacchi",
          "Frank Dellaert",
          "Thomas Funkhouser"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2022/papers/Kundu_Panoptic_Neural_Fields_A_Semantic_Object-Aware_Neural_Scene_Representation_CVPR_2022_paper.pdf",
        "ref_texts": "[64] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017. 7",
        "ref_ids": [
          "64"
        ]
      },
      "Neural window fully-connected crfs for monocular depth estimation": {
        "authors": [
          "Weihao Yuan",
          "Xiaodong Gu",
          "Zuozhuo Dai",
          "Siyu Zhu",
          "Ping Tan"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2022/papers/Yuan_Neural_Window_Fully-Connected_CRFs_for_Monocular_Depth_Estimation_CVPR_2022_paper.pdf",
        "ref_texts": "[45] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 2881\u20132890, 2017. 2, 5",
        "ref_ids": [
          "45"
        ]
      },
      "Ds-transunet: Dual swin transformer u-net for medical image segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2106.06716",
        "ref_texts": "[45] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "45"
        ]
      },
      "Contextual transformer networks for visual recognition": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2107.12292",
        "ref_texts": ""
      },
      "Beyond transmitting bits: Context, semantics, and task-oriented communications": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2207.09353",
        "ref_texts": "[54] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , July 2017.",
        "ref_ids": [
          "54"
        ]
      },
      "Image data augmentation for deep learning: A survey": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2204.08610",
        "ref_texts": "[Zhao et al. , 2017 ]Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR) , 2017.",
        "ref_ids": [
          "Zhao et al\\. , 2017 "
        ]
      },
      "Multiview transformers for video recognition": {
        "authors": [
          "Shen Yan",
          "Xuehan Xiong",
          "Anurag Arnab",
          "Zhichao Lu",
          "Mi Zhang",
          "Chen Sun",
          "Cordelia Schmid"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2022/papers/Yan_Multiview_Transformers_for_Video_Recognition_CVPR_2022_paper.pdf",
        "ref_texts": "[84] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017. 1, 2",
        "ref_ids": [
          "84"
        ]
      },
      "Topformer: Token pyramid transformer for mobile semantic segmentation": {
        "authors": [
          "Wenqiang Zhang",
          "Zilong Huang",
          "Guozhong Luo",
          "Tao Chen",
          "Xinggang Wang",
          "Wenyu Liu",
          "Gang Yu",
          "Chunhua Shen"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_TopFormer_Token_Pyramid_Transformer_for_Mobile_Semantic_Segmentation_CVPR_2022_paper.pdf",
        "ref_texts": "[57] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In IEEE Conf. Comput. Vis. Pattern Recog. , 2017. 5",
        "ref_ids": [
          "57"
        ]
      },
      "2dpass: 2d priors assisted semantic segmentation on lidar point clouds": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2207.04397",
        "ref_texts": "21. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: Proceedings of the IEEE conference on computer vision and pattern recognition.",
        "ref_ids": [
          "21"
        ]
      },
      "Separable self-attention for mobile vision transformers": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2206.02680",
        "ref_texts": "[40] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "40"
        ]
      },
      "State of the art in defect detection based on machine vision": {
        "authors": [
          "Zhonghe Ren"
        ],
        "url": "https://link.springer.com/content/pdf/10.1007/s40684-021-00343-6.pdf",
        "ref_texts": ""
      },
      "Real-time scene text detection with differentiable binarization and adaptive scale fusion": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2202.10304",
        "ref_texts": "[64] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In Proc. Conf. Comput. Vision Pattern Recognition , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "64"
        ]
      },
      "Understanding the robustness in vision transformers": {
        "authors": [],
        "url": "https://proceedings.mlr.press/v162/zhou22m/zhou22m.pdf",
        "ref_texts": "10347\u201310357. PMLR, 2021a. Touvron, H., Cord, M., Sablayrolles, A., Synnaeve, G., and J\u00b4egou, H. Going deeper with image transformers. In ICCV , pp. 32\u201342, 2021b. U.C. Berkeley. Reorganization: Grouping, contour detection, segmentation, ecological statistics. https://www2.eecs.berkeley.edu/ Research/Projects/CS/vision/grouping/ . Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, \u0141., and Polosukhin, I. Attention is all you need. NeurIPS , 30, 2017. Wang, W., Xie, E., Li, X., Fan, D.-P., Song, K., Liang, D., Lu, T., Luo, P., and Shao, L. Pyramid vision transformer: A versatile backbone for dense prediction without convolutions. In CVPR , pp. 568\u2013578, 2021. Wang, Y ., Xu, Z., Wang, X., Shen, C., Cheng, B., Shen, H., and Xia, H. End-to-end video instance segmentation with transformers. CVPR , 2020. Wightman, R. Pytorch image models. https://github. com/rwightman/pytorch-image-models , 2019.Wu, Z., Shen, C., and Van Den Hengel, A. Wider or deeper: Revisiting the resnet model for visual recognition. Pattern Recognition , 90:119\u2013133, 2019. Xie, E., Wang, W., Yu, Z., Anandkumar, A., Alvarez, J. M., and Luo, P. Segformer: Simple and efficient design for semantic segmentation with transformers. In NeurIPS , 2021. Yang, A. Y ., Wright, J., Ma, Y ., and Sastry, S. S. Unsupervised segmentation of natural images via lossy data compression. Computer Vision and Image Understanding , 110(2):212\u2013225, 2008. Yu, F. and Koltun, V . Multi-scale context aggregation by dilated convolutions. ICLR , 2016. Yuan, L., Chen, Y ., Wang, T., Yu, W., Shi, Y ., Tay, F. E., Feng, J., and Yan, S. Tokens-to-token vit: Training vision transformers from scratch on imagenet. ICCV , 2021. Zelnik-Manor, L. and Perona, P. Self-tuning spectral clustering. In NIPS , 2004. Zhao, H., Shi, J., Qi, X., Wang, X., and Jia, J. Pyramid scene parsing network. In CVPR , pp. 2881\u20132890, 2017. Zhao, H., Qi, X., Shen, X., Shi, J., and Jia, J. Icnet for realtime semantic segmentation on high-resolution images. InECCV , pp. 405\u2013420, 2018. Zheng, M., Gao, P., Wang, X., Li, H., and Dong, H. End-toend object detection with adaptive clustering transformer. BMVC , 2020. Zheng, S., Lu, J., Zhao, H., Zhu, X., Luo, Z., Wang, Y ., Fu, Y ., Feng, J., Xiang, T., and Torr, P. H. Rethinking semantic segmentation from a sequence-to-sequence perspective with transformers. In CVPR , pp. 6881\u20136890, 2021. Zhou, D., Kang, B., Jin, X., Yang, L., Lian, X., Hou, Q., and Feng, J. Deepvit: Towards deeper vision transformer. arXiv:2103.11886 , 2021a. Zhou, D., Shi, Y ., Kang, B., Yu, W., Jiang, Z., Li, Y ., Jin, X., Hou, Q., and Feng, J. Refiner: Refining self-attention for vision transformers. arXiv preprint arXiv:2106.03714 , 2021b. Zhu, C., Ping, W., Xiao, C., Shoeybi, M., Goldstein, T., Anandkumar, A., and Catanzaro, B. Long-short transformer: Efficient transformers for language and vision. InNeurIPS , 2021. Zhu, X., Su, W., Lu, L., Li, B., Wang, X., and Dai, J. Deformable detr: Deformable transformers for end-to-end object detection. ICLR , 2020. Understanding The Robustness in Vision Transformers A. Supplementary Details A.1. Proof on the relationship between the Information Bottleneck and Self-Attention Given a distribution X\u223c N(X\u2032, \u03f5)withXbeing the observed noisy input and X\u2032the target clean code, IB seeks a mapping f(Z|X)such that Zcontains the relevant information in Xfor predicting X\u2032. This goal is formulated as the following information-theoretic optimization problem q\u2217 IB(z|x) = arg min q(z|x)I(X, Z)\u2212\u03b2I(Z, X\u2032), (8) subject to the Markov constraint Z\u2194X\u2194X\u2032.\u03b2is a free parameter that trades-off the information compression by the first term and the relevant information maintaining by the second. The information bottleneck approach can be applied for solving unsupervised clustering problems. Here we choose Xto be the data point with index ithat will be clustered into clusters with indices c. As mentioned above, we assume the following data distribution: p(x|i)\u221dexp\u0014"
      },
      "Learning what not to segment: A new perspective on few-shot segmentation": {
        "authors": [
          "Chunbo Lang",
          "Gong Cheng",
          "Binfei Tu",
          "Junwei Han"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2022/papers/Lang_Learning_What_Not_To_Segment_A_New_Perspective_on_Few-Shot_CVPR_2022_paper.pdf",
        "ref_texts": "[68] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017. 2, 4, 6",
        "ref_ids": [
          "68"
        ]
      },
      "St++: Make self-training work better for semi-supervised semantic segmentation": {
        "authors": [
          "Lihe Yang",
          "Wei Zhuo",
          "Lei Qi",
          "Yinghuan Shi",
          "Yang Gao"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_ST_Make_Self-Training_Work_Better_for_Semi-Supervised_Semantic_Segmentation_CVPR_2022_paper.pdf",
        "ref_texts": "[60] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017. 1, 5",
        "ref_ids": [
          "60"
        ]
      },
      "Decoupling zero-shot semantic segmentation": {
        "authors": [
          "Jian Ding",
          "Nan Xue",
          "Song Xia",
          "Dengxin Dai"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2022/papers/Ding_Decoupling_Zero-Shot_Semantic_Segmentation_CVPR_2022_paper.pdf",
        "ref_texts": "[62] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , pages 2881\u20132890, 2017. 1",
        "ref_ids": [
          "62"
        ]
      },
      "Hrda: Context-aware high-resolution domain-adaptive semantic segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2204.13132.pdf?trk=public_post_comment-text",
        "ref_texts": "90. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: CVPR. pp. 2881\u20132890 (2017) 4",
        "ref_ids": [
          "90"
        ]
      },
      "Knowledge distillation from a stronger teacher": {
        "authors": [],
        "url": "https://proceedings.neurips.cc/paper_files/paper/2022/file/da669dfd3c36c93905a17ddba01eef06-Paper-Conference.pdf",
        "ref_texts": "[54] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017. 1, 8 Checklist 1. For all authors...",
        "ref_ids": [
          "54"
        ]
      },
      "Volo: Vision outlooker for visual recognition": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2106.13112.pdf?trk=public_post_comment-text",
        "ref_texts": "[74] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "74"
        ]
      },
      "Clrnet: Cross layer refinement network for lane detection": {
        "authors": [
          "Tu Zheng",
          "Yifei Huang",
          "Yang Liu",
          "Wenjian Tang",
          "Zheng Yang",
          "Deng Cai",
          "Xiaofei He"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2022/papers/Zheng_CLRNet_Cross_Layer_Refinement_Network_for_Lane_Detection_CVPR_2022_paper.pdf",
        "ref_texts": "[32] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017. 4",
        "ref_ids": [
          "32"
        ]
      },
      "Cross-image relational knowledge distillation for semantic segmentation": {
        "authors": [
          "Chuanguang Yang",
          "Helong Zhou",
          "Zhulin An",
          "Xue Jiang",
          "Yongjun Xu",
          "Qian Zhang"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_Cross-Image_Relational_Knowledge_Distillation_for_Semantic_Segmentation_CVPR_2022_paper.pdf",
        "ref_texts": "[51] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "51"
        ]
      },
      "Perturbed and strict mean teachers for semi-supervised semantic segmentation": {
        "authors": [
          "Yuyuan Liu",
          "Yu Tian",
          "Yuanhong Chen",
          "Fengbei Liu",
          "Vasileios Belagiannis",
          "Gustavo Carneiro"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Perturbed_and_Strict_Mean_Teachers_for_Semi-Supervised_Semantic_Segmentation_CVPR_2022_paper.pdf",
        "ref_texts": "[43] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017. 2",
        "ref_ids": [
          "43"
        ]
      },
      "Yolop: You only look once for panoptic driving perception": {
        "authors": [],
        "url": "https://link.springer.com/content/pdf/10.1007/s11633-022-1339-y.pdf",
        "ref_texts": "\u00a0H.\u00a0S.\u00a0Zhao,\u00a0 J.\u00a0P.\u00a0Shi,\u00a0X.\u00a0J.\u00a0Qi,\u00a0X.\u00a0G.\u00a0Wang,\u00a0 J.\u00a0Y.\u00a0Jia.\u00a0Pyramid\u00a0 scene\u00a0 parsing\u00a0 network.\u00a0 In\u00a0Proceedings of IEEE Conference on Computer Vision and Pattern Recognition , IEEE,\u00a0 Honolulu,\u00a0 USA,\u00a0 pp.\u00a06230\u20136239,\u00a0 2017.\u00a0 DOI:\u00a0 10.1109/ CVPR.2017.660.[4]",
        "ref_ids": [
          "4"
        ]
      },
      "Deep hierarchical semantic segmentation": {
        "authors": [
          "Liulei Li",
          "Tianfei Zhou",
          "Wenguan Wang",
          "Jianwu Li",
          "Yi Yang"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2022/papers/Li_Deep_Hierarchical_Semantic_Segmentation_CVPR_2022_paper.pdf",
        "ref_texts": "[105] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017. 2, 6",
        "ref_ids": [
          "105"
        ]
      },
      "EPSANet: An efficient pyramid squeeze attention block on convolutional neural network": {
        "authors": [
          "Hu Zhang",
          "Keke Zu",
          "Jian Lu",
          "Yuru Zou",
          "Deyu Meng"
        ],
        "url": "https://openaccess.thecvf.com/content/ACCV2022/papers/Zhang_EPSANet_An_Efficient_Pyramid_Squeeze_Attention_Block_on_Convolutional_Neural_ACCV_2022_paper.pdf",
        "ref_texts": "7. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 6230\u20136239",
        "ref_ids": [
          "7"
        ]
      },
      "Advancing plain vision transformer toward remote sensing foundation model": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2208.03987",
        "ref_texts": "[86] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in CVPR , 2017, pp. 6230\u20136239.",
        "ref_ids": [
          "86"
        ]
      },
      "Segvit: Semantic segmentation with plain vision transformers": {
        "authors": [],
        "url": "https://proceedings.neurips.cc/paper_files/paper/2022/file/20189b1aaa8edbb6d8bd6c1067ab5f3f-Paper-Conference.pdf",
        "ref_texts": "[11] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proc. IEEE Conf. Comp. Vis. Patt. Recogn. , 2017.",
        "ref_ids": [
          "11"
        ]
      },
      "Neural 3d scene reconstruction with the manhattan-world assumption": {
        "authors": [
          "Haoyu Guo",
          "Sida Peng",
          "Haotong Lin",
          "Qianqian Wang",
          "Guofeng Zhang",
          "Hujun Bao",
          "Xiaowei Zhou"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2022/papers/Guo_Neural_3D_Scene_Reconstruction_With_the_Manhattan-World_Assumption_CVPR_2022_paper.pdf",
        "ref_texts": "[57] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017. 2",
        "ref_ids": [
          "57"
        ]
      },
      "Masked generative distillation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2205.01529",
        "ref_texts": "38. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: Proceedings of the IEEE conference on computer vision and pattern recognition. pp. 2881\u20132890 (2017)",
        "ref_ids": [
          "38"
        ]
      },
      "Detecting camouflaged object in frequency domain": {
        "authors": [
          "Yijie Zhong",
          "Bo Li",
          "Lv Tang",
          "Senyun Kuang",
          "Shuang Wu",
          "Shouhong Ding"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2022/papers/Zhong_Detecting_Camouflaged_Object_in_Frequency_Domain_CVPR_2022_paper.pdf",
        "ref_texts": "[61] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , pages 6230\u20136239, 2017.",
        "ref_ids": [
          "61"
        ]
      },
      "L2g: A simple local-to-global knowledge transfer framework for weakly supervised semantic segmentation": {
        "authors": [
          "Tao Jiang",
          "Yuqi Yang",
          "Qibin Hou",
          "Yunchao Wei"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2022/papers/Jiang_L2G_A_Simple_Local-to-Global_Knowledge_Transfer_Framework_for_Weakly_Supervised_CVPR_2022_paper.pdf",
        "ref_texts": "[64] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In IEEE Conf. Comput. Vis. Pattern Recog. , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "64"
        ]
      },
      "Learning multiple adverse weather removal via two-stage knowledge learning and multi-contrastive regularization: Toward a unified model": {
        "authors": [
          "Ting Chen",
          "Kai Huang",
          "Che Tsai",
          "Hsiang Yang",
          "Jiun Ding",
          "Yen Kuo"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Learning_Multiple_Adverse_Weather_Removal_via_Two-Stage_Knowledge_Learning_and_CVPR_2022_paper.pdf",
        "ref_texts": "[57] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017. 4",
        "ref_ids": [
          "57"
        ]
      },
      "Edter: Edge detection with transformer": {
        "authors": [
          "Mengyang Pu",
          "Yaping Huang",
          "Yuming Liu",
          "Qingji Guan",
          "Haibin Ling"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2022/papers/Pu_EDTER_Edge_Detection_With_Transformer_CVPR_2022_paper.pdf",
        "ref_texts": "[70] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In IEEE Conf. Comput. Vis. Pattern Recog. , pages 6230\u20136239, 2017. 2",
        "ref_ids": [
          "70"
        ]
      },
      "Restr: Convolution-free referring image segmentation using transformers": {
        "authors": [
          "Namyup Kim",
          "Dongwon Kim",
          "Cuiling Lan",
          "Wenjun Zeng",
          "Suha Kwak"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2022/papers/Kim_ReSTR_Convolution-Free_Referring_Image_Segmentation_Using_Transformers_CVPR_2022_paper.pdf",
        "ref_texts": "[52] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , July 2017.",
        "ref_ids": [
          "52"
        ]
      },
      "Self-support few-shot semantic segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2207.11549",
        "ref_texts": "91. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: CVPR (2017) 4",
        "ref_ids": [
          "91"
        ]
      },
      "Panoptic nerf: 3d-to-2d label transfer for panoptic urban scene segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2203.15224",
        "ref_texts": "[65] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 2881\u20132890, 2017. 2, 6, 7, 8",
        "ref_ids": [
          "65"
        ]
      },
      "Gmmseg: Gaussian mixture based generative semantic segmentation models": {
        "authors": [],
        "url": "https://proceedings.neurips.cc/paper_files/paper/2022/file/cb1c4782f159b55380b4584671c4fd88-Paper-Conference.pdf",
        "ref_texts": "[3]Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017. 1, 3, 8",
        "ref_ids": [
          "3"
        ]
      },
      "An empirical study of remote sensing pretraining": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2204.02825",
        "ref_texts": "[87] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in CVPR , 2017, pp. 6230\u20136239.",
        "ref_ids": [
          "87"
        ]
      },
      "Focalclick: Towards practical interactive image segmentation": {
        "authors": [
          "Xi Chen",
          "Zhiyan Zhao",
          "Yilei Zhang",
          "Manni Duan",
          "Donglian Qi",
          "Hengshuang Zhao"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2022/papers/Chen_FocalClick_Towards_Practical_Interactive_Image_Segmentation_CVPR_2022_paper.pdf",
        "ref_texts": "[47] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017.",
        "ref_ids": [
          "47"
        ]
      },
      "Thin-plate spline motion model for image animation": {
        "authors": [
          "Jian Zhao",
          "Hui Zhang"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2022/papers/Zhao_Thin-Plate_Spline_Motion_Model_for_Image_Animation_CVPR_2022_paper.pdf",
        "ref_texts": "[36] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017. 2",
        "ref_ids": [
          "36"
        ]
      },
      "Salient object detection via integrity learning": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2101.07663",
        "ref_texts": "[65] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in IEEE Conf. Comput. Vis. Pattern Recog. , 2017, pp.",
        "ref_ids": [
          "65"
        ]
      },
      "Deep reinforcement learning in computer vision: a comprehensive survey": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2108.11510",
        "ref_texts": "[425] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881{2890, 2017.",
        "ref_ids": [
          "425"
        ]
      },
      "P2T: Pyramid pooling transformer for scene understanding": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2106.12011",
        "ref_texts": "[37] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in IEEE Conf. Comput. Vis. Pattern Recog. , 2017, pp. 2881\u2013",
        "ref_ids": [
          "37"
        ]
      },
      "Learning non-target knowledge for few-shot semantic segmentation": {
        "authors": [
          "Yuanwei Liu",
          "Nian Liu",
          "Qinglong Cao",
          "Xiwen Yao",
          "Junwei Han",
          "Ling Shao"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Learning_Non-Target_Knowledge_for_Few-Shot_Semantic_Segmentation_CVPR_2022_paper.pdf",
        "ref_texts": "[45] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , pages 2881\u20132890, 2017. 2",
        "ref_ids": [
          "45"
        ]
      },
      "Sparse instance activation for real-time instance segmentation": {
        "authors": [
          "Tianheng Cheng",
          "Xinggang Wang",
          "Shaoyu Chen",
          "Wenqiang Zhang",
          "Qian Zhang",
          "Chang Huang",
          "Zhaoxiang Zhang",
          "Wenyu Liu"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2022/papers/Cheng_Sparse_Instance_Activation_for_Real-Time_Instance_Segmentation_CVPR_2022_paper.pdf",
        "ref_texts": "[48] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017. 3, 4",
        "ref_ids": [
          "48"
        ]
      },
      "Feature erasing and diffusion network for occluded person re-identification": {
        "authors": [
          "Zhikang Wang",
          "Feng Zhu",
          "Shixiang Tang",
          "Rui Zhao",
          "Lihuo He",
          "Jiangning Song"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Feature_Erasing_and_Diffusion_Network_for_Occluded_Person_Re-Identification_CVPR_2022_paper.pdf",
        "ref_texts": "[37] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , pages 2881\u20132890, 2017. 2",
        "ref_ids": [
          "37"
        ]
      },
      "Pp-liteseg: A superior real-time semantic segmentation model": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2204.02681",
        "ref_texts": "[29] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017. 1, 2, 3",
        "ref_ids": [
          "29"
        ]
      },
      "A survey on long-tailed visual recognition": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2205.13775",
        "ref_texts": "193. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2881\u20132890 (2017) 25",
        "ref_ids": [
          "193"
        ]
      },
      "A novel transformer based semantic segmentation scheme for fine-resolution remote sensing images": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2104.12137",
        "ref_texts": "[2] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \"Pyramid scene parsing network,\" in Proceedings of the IEEE conference on computer vision and pattern recognition , 2017, pp. 28812890. ",
        "ref_ids": [
          "2"
        ]
      },
      "Toward semantic communications: Deep learning-based image semantic coding": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2208.04094",
        "ref_texts": "[53] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In IEEE Conf. Comput. Vis. Pattern Recog. (CVPR) , pages 2881\u20132890, 2017. August 9, 2022 DRAFT",
        "ref_ids": [
          "53"
        ]
      },
      "General facial representation learning in a visual-linguistic manner": {
        "authors": [
          "Yinglin Zheng",
          "Hao Yang",
          "Ting Zhang",
          "Jianmin Bao",
          "Dongdong Chen",
          "Yangyu Huang",
          "Lu Yuan",
          "Dong Chen",
          "Ming Zeng",
          "Fang Wen"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2022/papers/Zheng_General_Facial_Representation_Learning_in_a_Visual-Linguistic_Manner_CVPR_2022_paper.pdf",
        "ref_texts": "[106] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u00b12890, 2017. 7",
        "ref_ids": [
          "106"
        ]
      },
      "Learning trajectory-aware transformer for video super-resolution": {
        "authors": [
          "Chengxu Liu",
          "Huan Yang",
          "Jianlong Fu",
          "Xueming Qian"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Learning_Trajectory-Aware_Transformer_for_Video_Super-Resolution_CVPR_2022_paper.pdf",
        "ref_texts": ""
      },
      "Prototypical contrast adaptation for domain adaptive semantic segmentation": {
        "authors": [],
        "url": "https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136940036.pdf",
        "ref_texts": "49. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. pp. 2881\u20132890 (2017)",
        "ref_ids": [
          "49"
        ]
      },
      "Feature aggregation and propagation network for camouflaged object detection": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2212.00990",
        "ref_texts": "[55] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proc. IEEE Conf. Comput. Vis. Pattern Recognit. , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "55"
        ]
      },
      "RTFormer: Efficient design for real-time semantic segmentation with transformer": {
        "authors": [],
        "url": "https://proceedings.neurips.cc/paper_files/paper/2022/file/30e10e671c5e43edb67eb257abb6c3ea-Paper-Conference.pdf",
        "ref_texts": "[50] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "50"
        ]
      },
      "Lite vision transformer with enhanced self-attention": {
        "authors": [
          "Chenglin Yang",
          "Yilin Wang",
          "Jianming Zhang",
          "He Zhang",
          "Zijun Wei",
          "Zhe Lin",
          "Alan Yuille"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_Lite_Vision_Transformer_With_Enhanced_Self-Attention_CVPR_2022_paper.pdf",
        "ref_texts": "[67] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 2881\u20132890, 2017. 4,6",
        "ref_ids": [
          "67"
        ]
      },
      "Camouflaged object detection via context-aware cross-level fusion": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2207.13362",
        "ref_texts": "[65] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "65"
        ]
      },
      "Dense cross-query-and-support attention weighted mask aggregation for few-shot segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2207.08549",
        "ref_texts": "52. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 2881\u20132890 (2017)",
        "ref_ids": [
          "52"
        ]
      },
      "Semi-supervised semantic segmentation with error localization network": {
        "authors": [
          "Donghyeon Kwon",
          "Suha Kwak"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2022/papers/Kwon_Semi-Supervised_Semantic_Segmentation_With_Error_Localization_Network_CVPR_2022_paper.pdf",
        "ref_texts": "[50] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , pages 6230\u20136239, July 2017. 1, 3",
        "ref_ids": [
          "50"
        ]
      },
      "Class-balanced pixel-level self-labeling for domain adaptive semantic segmentation": {
        "authors": [
          "Ruihuang Li",
          "Shuai Li",
          "Chenhang He",
          "Yabin Zhang",
          "Xu Jia",
          "Lei Zhang"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Class-Balanced_Pixel-Level_Self-Labeling_for_Domain_Adaptive_Semantic_Segmentation_CVPR_2022_paper.pdf",
        "ref_texts": "[53] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017. 1, 2",
        "ref_ids": [
          "53"
        ]
      },
      "Video k-net: A simple, strong, and unified baseline for video segmentation": {
        "authors": [
          "Xiangtai Li",
          "Wenwei Zhang",
          "Jiangmiao Pang",
          "Kai Chen",
          "Guangliang Cheng",
          "Yunhai Tong",
          "Chen Change"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Video_K-Net_A_Simple_Strong_and_Unified_Baseline_for_Video_CVPR_2022_paper.pdf",
        "ref_texts": "[70] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017. 2, 7",
        "ref_ids": [
          "70"
        ]
      },
      "Large-scale video panoptic segmentation in the wild: A benchmark": {
        "authors": [
          "Jiaxu Miao",
          "Xiaohan Wang",
          "Yu Wu",
          "Wei Li",
          "Xu Zhang",
          "Yunchao Wei",
          "Yi Yang"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2022/papers/Miao_Large-Scale_Video_Panoptic_Segmentation_in_the_Wild_A_Benchmark_CVPR_2022_paper.pdf",
        "ref_texts": "[74] Wenwei Zhang, Jiangmiao Pang, Kai Chen, and Chen Change Loy. K-net: Towards unified image segmentation. In NeurIPS , 2021. 1, 2[75] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In IEEE CVPR , 2017. 2",
        "ref_ids": [
          "74",
          "75"
        ]
      },
      "Landslide4sense: Reference benchmark data and deep learning models for landslide detection": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2206.00515",
        "ref_texts": "[84] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proc. IEEE Conf. Comput. Vis. Pattern Recognit. , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "84"
        ]
      },
      "Bending reality: Distortion-aware transformers for adapting to panoramic semantic segmentation": {
        "authors": [
          "Jiaming Zhang",
          "Kailun Yang",
          "Chaoxiang Ma",
          "Simon Reiss",
          "Kunyu Peng",
          "Rainer Stiefelhagen"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Bending_Reality_Distortion-Aware_Transformers_for_Adapting_to_Panoramic_Semantic_Segmentation_CVPR_2022_paper.pdf",
        "ref_texts": "[93] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017. 2, 6",
        "ref_ids": [
          "93"
        ]
      },
      "Fast camouflaged object detection via edge-based reversible re-calibration network": {
        "authors": [
          "Peng Ji",
          "Lei Zhu",
          "Mingchen Zhuge",
          "Keren Fu"
        ],
        "url": "https://arxiv.org/pdf/2111.03216",
        "ref_texts": "[19] H. Zhao, J. Shi, X. Qi, X. Wang, J. Jia, Pyramid scene parsing network, in: IEEE Conf. Comput. Vis. Pattern Recog., 2017, pp. 6230{6239.",
        "ref_ids": [
          "19"
        ]
      },
      "Highly accurate dichotomous image segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2203.03041",
        "ref_texts": "[115] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In CVPR , 2017. 9, 25, 26",
        "ref_ids": [
          "115"
        ]
      },
      "Adaptive early-learning correction for segmentation from noisy annotations": {
        "authors": [
          "Sheng Liu",
          "Kangning Liu",
          "Weicheng Zhu",
          "Yiqiu Shen",
          "Carlos Fernandez"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Adaptive_Early-Learning_Correction_for_Segmentation_From_Noisy_Annotations_CVPR_2022_paper.pdf",
        "ref_texts": "[65] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , 2017.",
        "ref_ids": [
          "65"
        ]
      },
      "Segpgd: An effective and efficient adversarial attack for evaluating and boosting segmentation robustness": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2207.12391",
        "ref_texts": "56. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: CVPR (2017)",
        "ref_ids": [
          "56"
        ]
      },
      "Raw high-definition radar for multi-task learning": {
        "authors": [
          "Julien Rebut",
          "Arthur Ouaknine",
          "Waqas Malik",
          "Patrick Perez"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2022/papers/Rebut_Raw_High-Definition_Radar_for_Multi-Task_Learning_CVPR_2022_paper.pdf",
        "ref_texts": "[45] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017. 4",
        "ref_ids": [
          "45"
        ]
      },
      "Few-shot object detection: A survey": {
        "authors": [],
        "url": "https://dl.acm.org/doi/pdf/10.1145/3519022",
        "ref_texts": ""
      },
      "Glass segmentation using intensity and spectral polarization cues": {
        "authors": [
          "Haiyang Mei",
          "Bo Dong",
          "Wen Dong",
          "Jiaxi Yang",
          "Hwan Baek",
          "Felix Heide",
          "Pieter Peers",
          "Xiaopeng Wei",
          "Xin Yang"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2022/papers/Mei_Glass_Segmentation_Using_Intensity_and_Spectral_Polarization_Cues_CVPR_2022_paper.pdf",
        "ref_texts": "[47] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017. 5, 6",
        "ref_ids": [
          "47"
        ]
      },
      "Open-world semantic segmentation via contrasting and clustering vision-language embedding": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2207.08455",
        "ref_texts": "50. Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "50"
        ]
      },
      "RigNet: Repetitive image guided network for depth completion": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2107.13802",
        "ref_texts": "58. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: CVPR. pp. 2881\u20132890 (2017) 6",
        "ref_ids": [
          "58"
        ]
      },
      "Avoiding negative transfer for semantic segmentation of remote sensing images": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2106.15754",
        "ref_texts": "[4] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in CVPR , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "4"
        ]
      },
      "Semantic-guided zero-shot learning for low-light image/video enhancement": {
        "authors": [
          "Shen Zheng",
          "Gaurav Gupta"
        ],
        "url": "https://openaccess.thecvf.com/content/WACV2022W/RWS/papers/Zheng_Semantic-Guided_Zero-Shot_Learning_for_Low-Light_ImageVideo_Enhancement_WACVW_2022_paper.pdf",
        "ref_texts": "[53] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "53"
        ]
      },
      "Dynamic prototype convolution network for few-shot semantic segmentation": {
        "authors": [
          "Jie Liu",
          "Yanqi Bao",
          "Sen Xie",
          "Huan Xiong",
          "Jakob Sonke",
          "Efstratios Gavves"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Dynamic_Prototype_Convolution_Network_for_Few-Shot_Semantic_Segmentation_CVPR_2022_paper.pdf",
        "ref_texts": "[40] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017. 2",
        "ref_ids": [
          "40"
        ]
      },
      "RGBT salient object detection: A large-scale dataset and benchmark": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2007.03262",
        "ref_texts": "[48] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proceedings of IEEE Conference on Computer Vision and Pattern Recognition , 2017.",
        "ref_ids": [
          "48"
        ]
      },
      "Inverted pyramid multi-task transformer for dense scene understanding": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2203.07997",
        "ref_texts": "53. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: CVPR (2017) 7",
        "ref_ids": [
          "53"
        ]
      },
      "Expansion and shrinkage of localization for weakly-supervised semantic segmentation": {
        "authors": [],
        "url": "https://proceedings.neurips.cc/paper_files/paper/2022/file/66738d21d3cddb8717ca52deff5a5546-Paper-Conference.pdf",
        "ref_texts": "[64] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "64"
        ]
      },
      "EDN: Salient object detection via extremely-downsampled network": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2012.13093",
        "ref_texts": "[43] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in IEEE Conf. Comput. Vis. Pattern Recog. (CVPR) , 2017, pp.",
        "ref_ids": [
          "43"
        ]
      },
      "CE-FPN: enhancing channel information for object detection": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2103.10643",
        "ref_texts": "[35] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition , 2017, pp. 2881\u20132890.[36] Z. Chen, S. Huang, and D. Tao, \u201cContext refinement for object detection,\u201d in Proceedings of the European conference on computer vision (ECCV) , 2018, pp. 71\u201386.",
        "ref_ids": [
          "35",
          "36"
        ]
      },
      "DecoupleNet: Decoupled network for domain adaptive semantic segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2207.09988",
        "ref_texts": "87. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: CVPR (2017)",
        "ref_ids": [
          "87"
        ]
      },
      "RGB-T semantic segmentation with location, activation, and sharpening": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2210.14530",
        "ref_texts": "[9] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proc. IEEE CVPR , Jul. 2017, pp. 6230\u20136239.",
        "ref_ids": [
          "9"
        ]
      },
      "FCCDN: Feature constraint network for VHR image change detection": {
        "authors": [
          "Pan Chen",
          "Danfeng Hong",
          "Zhengchao Chen",
          "Xuan Yang",
          "Baipeng Li",
          "Bing Zhang"
        ],
        "url": "https://arxiv.org/pdf/2105.10860",
        "ref_texts": "[47] H. Zhao, J. Shi, X. Qi, X. Wang, J. Jia, Pyramid scene parsing network, in: Proceedings of the IEEE conference on computer vision and pattern recognition, 2017, pp. 2881{2890.",
        "ref_ids": [
          "47"
        ]
      },
      "Hyperbolic image segmentation": {
        "authors": [
          "Mina Ghadimi",
          "Julian Schoep",
          "Erman Acar",
          "Pascal Mettes"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2022/papers/Atigh_Hyperbolic_Image_Segmentation_CVPR_2022_paper.pdf",
        "ref_texts": "[52] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017. 2",
        "ref_ids": [
          "52"
        ]
      },
      "Cat: Cross attention in vision transformer": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2106.05786",
        "ref_texts": "[21] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "21"
        ]
      },
      "Beyond self-attention: External attention using two linear layers for visual tasks": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2105.02358",
        "ref_texts": "[52] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in CVPR , 2017, pp. 6230\u20136239.",
        "ref_ids": [
          "52"
        ]
      },
      "Learning multi-view aggregation in the wild for large-scale 3d semantic segmentation": {
        "authors": [
          "Damien Robert",
          "Bruno Vallet",
          "Loic Landrieu"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2022/papers/Robert_Learning_Multi-View_Aggregation_in_the_Wild_for_Large-Scale_3D_Semantic_CVPR_2022_paper.pdf",
        "ref_texts": ""
      },
      "Coarse-to-fine feature mining for video semantic segmentation": {
        "authors": [
          "Guolei Sun",
          "Yun Liu",
          "Henghui Ding",
          "Thomas Probst",
          "Luc Van"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2022/papers/Sun_Coarse-To-Fine_Feature_Mining_for_Video_Semantic_Segmentation_CVPR_2022_paper.pdf",
        "ref_texts": "[98] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In IEEE CVPR , pages 2881\u20132890, 2017. 1, 2, 3, 7",
        "ref_ids": [
          "98"
        ]
      },
      "Lesion-aware dynamic kernel for polyp segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2301.04904",
        "ref_texts": "26. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: Proceedingsof the IEEE Conference on Computer Vision and Pattern Recognition. pp. 2881\u20132890 (2017)",
        "ref_ids": [
          "26"
        ]
      },
      "Structural and statistical texture knowledge distillation for semantic segmentation": {
        "authors": [
          "Deyi Ji",
          "Haoran Wang",
          "Mingyuan Tao",
          "Jianqiang Huang",
          "Sheng Hua",
          "Hongtao Lu"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2022/papers/Ji_Structural_and_Statistical_Texture_Knowledge_Distillation_for_Semantic_Segmentation_CVPR_2022_paper.pdf",
        "ref_texts": "[50] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "50"
        ]
      },
      "Half-UNet: A simplified U-Net architecture for medical image segmentation": {
        "authors": [
          "Shengzhou Xu"
        ],
        "url": "https://www.frontiersin.org/articles/10.3389/fninf.2022.911679/pdf",
        "ref_texts": ""
      },
      "Online convolutional re-parameterization": {
        "authors": [
          "Mu Hu",
          "Junyi Feng",
          "Jiashen Hua",
          "Baisheng Lai",
          "Jianqiang Huang",
          "Xiaojin Gong",
          "Sheng Hua"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2022/papers/Hu_Online_Convolutional_Re-Parameterization_CVPR_2022_paper.pdf",
        "ref_texts": "[44] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017. 1, 8",
        "ref_ids": [
          "44"
        ]
      },
      "Hybridnets: End-to-end perception network": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2203.09035",
        "ref_texts": "32. H. Zhao, J. Shi, X. Qi, X. Wang and J. Jia, \"Pyramid Scene Parsing Network,\" in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2017, pp. ",
        "ref_ids": [
          "32"
        ]
      },
      "Context-aware mixup for domain adaptive semantic segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2108.03557",
        "ref_texts": "[4] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "4"
        ]
      },
      "Image dehazing transformer with transmission-aware 3d position embedding": {
        "authors": [
          "Le Guo",
          "Qixin Yan",
          "Saeed Anwar",
          "Runmin Cong",
          "Wenqi Ren",
          "Chongyi Li"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2022/papers/Guo_Image_Dehazing_Transformer_With_Transmission-Aware_3D_Position_Embedding_CVPR_2022_paper.pdf",
        "ref_texts": "[35] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In ICCV , pages 2881\u20132890, 2017. 4",
        "ref_ids": [
          "35"
        ]
      },
      "LMFFNet: A well-balanced lightweight network for fast and accurate semantic segmentation": {
        "authors": [],
        "url": "https://www.fst.um.edu.mo/personal/wp-content/uploads/2023/06/LMFFNet.pdf",
        "ref_texts": "[1] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR) , Jul. 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "1"
        ]
      },
      "Lawin transformer: Improving semantic segmentation transformer with multi-scale representations via large window attention": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2201.01615",
        "ref_texts": "[50] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017. 1, 2, 6, 8",
        "ref_ids": [
          "50"
        ]
      },
      "Universal adversarial examples in remote sensing: Methodology and benchmark": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2202.07054",
        "ref_texts": "[54] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proc. IEEE Conf. Comput. Vis. Pattern Recognit. , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "54"
        ]
      },
      "Self-supervised monocular depth and ego-motion estimation in endoscopy: Appearance flow to the rescue": {
        "authors": [
          "Shuwei Shao",
          "Zhongcai Pei",
          "Weihai Chen",
          "Wentao Zhu",
          "Xingming Wu",
          "Dianmin Sun",
          "Baochang Zhang"
        ],
        "url": "https://arxiv.org/pdf/2112.08122",
        "ref_texts": "1099. Wang, Y ., Yang, Y ., Yang, Z., Zhao, L., Wang, P., Xu, W., 2018. Occlusion aware unsupervised learning of optical flow, in: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 4884\u20134893. Wang, Z., Bovik, A.C., Sheikh, H.R., Simoncelli, E.P., 2004. Image quality assessment: from error visibility to structural similarity. IEEE transactions on image processing 13, 600\u2013612. Xu, D., Ricci, E., Ouyang, W., Wang, X., Sebe, N., 2017. Multi-scale continuous crfs as sequential deep networks for monocular depth estimation, in: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 5354\u20135362. Xu, D., Wang, W., Tang, H., Liu, H., Sebe, N., Ricci, E., 2018. Structured attention guided convolutional neural fields for monocular depth estimation, in: Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 3917\u20133925. Yang, N., Stumberg, L.v., Wang, R., Cremers, D., 2020. D3vo: Deep depth, deep pose and deep uncertainty for monocular visual odometry, in: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 1281\u20131292. Yang, Z., Wang, P., Wang, Y ., Xu, W., Nevatia, R., 2018. Lego: Learning edge with geometry all at once by watching videos, in: Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 225\u2013234. Yin, Z., Shi, J., 2018. Geonet: Unsupervised learning of dense depth, optical flow and camera pose, in: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 1983\u20131992. Zhan, H., Garg, R., Saroj Weerasekera, C., Li, K., Agarwal, H., Reid, I., 2018. Unsupervised learning of monocular depth estimation and visual odometry with deep feature reconstruction, in: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 340\u2013349. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J., 2017. Pyramid scene parsing network, in: Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 2881\u20132890. Zhou, J., Wang, Y ., Qin, K., Zeng, W., 2019. Unsupervised high-resolution depth learning from videos with dual networks, in: Proceedings of the IEEE /CVF International Conference on Computer Vision, pp. 6872\u20136881. Zhou, T., Brown, M., Snavely, N., Lowe, D.G., 2017. Unsupervised learning of depth and ego-motion from video, in: Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 1851\u20131858. Zhu, W., Huang, Y ., Xu, D., Qian, Z., Fan, W., Xie, X., 2021. Test-time training for deformable multi-scale image registration. Zhu, X., Xiong, Y ., Dai, J., Yuan, L., Wei, Y ., 2017. Deep feature flow for video recognition, in: Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 2349\u20132358.",
        "ref_ids": [
          "1099"
        ]
      },
      "DDU-Net: Dual-decoder-U-Net for road extraction using high-resolution remote sensing images": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2201.06750",
        "ref_texts": "[14] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proc. 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , Los Alamitos, USA, Jul. 2017, pp. 6230\u2013",
        "ref_ids": [
          "14"
        ]
      },
      "Reslt: Residual learning for long-tailed recognition": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2101.10633.pdf?amp=1",
        "ref_texts": "[17] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in CVPR , 2017.",
        "ref_ids": [
          "17"
        ]
      },
      "Dmt: Dynamic mutual training for semi-supervised learning": {
        "authors": [
          "Zhengyang Feng",
          "Qianyu Zhou",
          "Qiqi Gu",
          "Xin Tan",
          "Guangliang Cheng",
          "Xuequan Lu",
          "Jianping Shi",
          "Lizhuang Ma"
        ],
        "url": "https://arxiv.org/pdf/2004.08514",
        "ref_texts": "[4] H. Zhao, J. Shi, X. Qi, X. Wang, J. Jia, Pyramid scene parsing network, in: Computer Vision and Pattern Recognition, 2017, pp. 2881{2890.",
        "ref_ids": [
          "4"
        ]
      },
      "TransKD: Transformer knowledge distillation for efficient semantic segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2202.13393",
        "ref_texts": "[27] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in CVPR , 2017.",
        "ref_ids": [
          "27"
        ]
      },
      "Pin the memory: Learning to generalize semantic segmentation": {
        "authors": [
          "Jin Kim",
          "Jiyoung Lee",
          "Jungin Park",
          "Dongbo Min",
          "Kwanghoon Sohn"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2022/papers/Kim_Pin_the_Memory_Learning_To_Generalize_Semantic_Segmentation_CVPR_2022_paper.pdf",
        "ref_texts": ""
      },
      "Bridging composite and real: towards end-to-end deep image matting": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2010.16188",
        "ref_texts": "2979 Xue S, Agarwala A, Dorsey J, Rushmeier H (2012) Understanding and improving the realism of image composites. ACM Transactions on Graphics 31(4):1{10 Yu Q, Zhang J, Zhang H, Wang Y, Lin Z, Xu N, Bai Y, Yuille A (2021) Mask guided matting via progressive reffnement network. In: Proceedings IEEE Conference on Computer Vision and Pattern Recognition Zhang J, Tao D (2020) Empowering things with intelligence: a survey of the progress, challenges, and opportunities in artiffcial intelligence of things. IEEE Internet of Things Journal 8(10):7789{7817 Zhang J, Chen Z, Tao D (2021) Towards high performance human keypoint detection. International Journal of Computer Vision 129(9):2639{2662 Zhang Q, Zhang J, Liu W, Tao D (2019a) Category anchor-guided unsupervised domain adaptation for semantic segmentation. Advances in Neural Information Processing Systems 32:435{445 Zhang Y, Gong L, Fan L, Ren P, Huang Q, Bao H, Xu W (2019b) A late fusion cnn for digital matting. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp 7469{7478 Zhao H, Shi J, Qi X, Wang X, Jia J (2017) Pyramid scene parsing network. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp 2881{2890 Zheng Y, Kambhamettu C, Yu J, Bauer T, Steiner K (2008) Fuzzymatte: A computationally eflcient scheme for interactive matting. In: Proceedings IEEE Conference on Computer Vision and Pattern Recognition, pp 1{8"
      },
      "A lightweight neural network with multiscale feature enhancement for liver CT segmentation": {
        "authors": [
          "Mohammed Yusuf"
        ],
        "url": "https://www.nature.com/articles/s41598-022-16828-6.pdf",
        "ref_texts": ""
      },
      "Evaluating the robustness of semantic segmentation for autonomous driving against real-world adversarial patch attacks": {
        "authors": [
          "Federico Nesti",
          "Giulio Rossolini",
          "Saasha Nair",
          "Alessandro Biondi",
          "Giorgio Buttazzo"
        ],
        "url": "http://openaccess.thecvf.com/content/WACV2022/papers/Nesti_Evaluating_the_Robustness_of_Semantic_Segmentation_for_Autonomous_Driving_Against_WACV_2022_paper.pdf",
        "ref_texts": "[44] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid Scene Parsing Network. arXiv e-prints , page arXiv:1612.01105, Dec. 2016.",
        "ref_ids": [
          "44"
        ]
      },
      "Deep learning-based high-accuracy quantitation for lumbar intervertebral disc degeneration from MRI": {
        "authors": [
          "Dong Zheng"
        ],
        "url": "https://www.nature.com/articles/s41467-022-28387-5.pdf",
        "ref_texts": "41. Zhao, H., Shi, J., Qi, X., Wang, X. & Jia, J. Pyramid scene parsing network. Proc. 30th IEEE Conf. Comput. Vis. Pattern Recognit., CVPR 2017 2017 , 6230 \u20136239 (2017). Acknowledgements This study was supported by the National Key R&D Program of China (2020YFE0201600) and the National Natural Science Foundation of China (81930116, 81804115, 81873317,and 81730107). Author contributions Guarantor of integrity of the entire study, Y.L.S. and Y.J.W.; study concepts/study design ordata acquisition or data analysis/interpretation, all authors; paper drafting or paper revisionfor important intellectual content, all authors; approval of the final version of the submitted paper, all authors; agrees to ensure any questions related to the work are appropriately resolved, all authors; literature research, H.D.Z., M.C.Y., M.Y., and X.J.C.; clinical studies,Y.L.S., D.W.K., M.C.Y., J.C., Y.P.L., and X.F.M.; experimental studies, Y.Z.T., H.S.W., andG.J.Y.; statistical analysis, H.D.Z., M.Y., and X.J.C.; and paper revision, all authors. Competing interests The authors declare no competing interests.Additional information Supplementary information The online version contains supplementary material available at https://doi.org/10.1038/s41467-022-28387-5 . Correspondence and requests for materials should be addressed to Ying-Zhong Tian or Yong-Jun Wang. Peer review information Nature Communications thanks the anonymous reviewer(s) for their contribution to the peer review of this work. Peer reviewer reports are available. Reprints and permission information is available at http://www.nature.com/reprints Publisher \u2019s note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional af filiations. Open Access This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you giveappropriate credit to the original author(s) and the source, provide a link to the CreativeCommons license, and indicate if changes were made. The images or other third partymaterial in this article are included in the article \u2019s Creative Commons license, unless indicated otherwise in a credit line to the material. If material is not included in the article \u2019s Creative Commons license and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly fromthe copyright holder. To view a copy of this license, visit http://creativecommons.org/ licenses/by/4.0/ .",
        "ref_ids": [
          "41"
        ]
      },
      "Category-level 6d object pose and size estimation using self-supervised deep prior deformation networks": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2207.05444",
        "ref_texts": "31. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: Proceedings of the IEEE conference on computer vision and pattern recognition. pp. 2881\u20132890 (2017) 7, 10",
        "ref_ids": [
          "31"
        ]
      },
      "LFRSNet: A robust light field semantic segmentation network combining contextual and geometric features": {
        "authors": [],
        "url": "https://www.frontiersin.org/articles/10.3389/fenvs.2022.996513/pdf",
        "ref_texts": "30, 5956 \u20135968. doi:10.1109/tip.2021.3079805 Zhang, Y., Sheng, H., Wu, Y., Wang, S., Lyu, W., Ke, W., et al. (2020). Long-term tracking with deep tracklet association. IEEE Trans. Image Process. 29, 6694 \u20136706. doi:10.1109/tip.2020.2993073Zhang, Z., Cui, Z., Xu, C., Yan, Y., Sebe, N., and Yang, J. (2019). \u201cPattern-af finitive propagation across depth, surface normal and semantic segmentation, \u201din IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 4101 \u20134110. Zhao, H., Shi, J., Qi, X., Wang, X., and Jia, J. (2017). \u201cPyramid scene parsing network, \u201din IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 6230 \u20136239. Zheng, S., Lu, J., Zhao, H., Zhu, X., Luo, Z., Wang, Y., et al. (2021). \u201cRethinking semantic segmentation from a sequence-to-sequence perspective withtransformers, \u201din IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 6877 \u20136886. Zhu, X., Xiong, Y., Dai, J., Yuan, L., and Wei, Y. (2017). \u201cDeep feature flow for video recognition, \u201din IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 4141 \u20134150. Zhuang, J., Wang, Z., and Wang, B. (2021). Video semantic segmentation with distortion-aware feature correction. IEEE Trans. Circuits Syst. Video Technol. 31 (8), 3128 \u20133139. doi:10.1109/tcsvt.2020.3037234 Frontiers in Environmental Science frontiersin.org 14Yang et al. 10.3389/fenvs.2022.996513"
      },
      "Tubeformer-deeplab: Video mask transformer": {
        "authors": [
          "Dahun Kim",
          "Jun Xie",
          "Huiyu Wang",
          "Siyuan Qiao",
          "Qihang Yu",
          "Seok Kim",
          "Hartwig Adam",
          "In So",
          "Chieh Chen"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2022/papers/Kim_TubeFormer-DeepLab_Video_Mask_Transformer_CVPR_2022_paper.pdf",
        "ref_texts": "[84] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017. 2",
        "ref_ids": [
          "84"
        ]
      },
      "Unsupervised hierarchical semantic segmentation with multiview cosegmentation and clustering transformers": {
        "authors": [
          "Wei Ke",
          "Jing Hwang",
          "Yunhui Guo",
          "Xudong Wang",
          "Stella X. Yu"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2022/papers/Ke_Unsupervised_Hierarchical_Semantic_Segmentation_With_Multiview_Cosegmentation_and_Clustering_Transformers_CVPR_2022_paper.pdf",
        "ref_texts": "[70] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017. 13, 17",
        "ref_ids": [
          "70"
        ]
      },
      "Source-free open compound domain adaptation in semantic segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2106.03422",
        "ref_texts": "[40] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017.",
        "ref_ids": [
          "40"
        ]
      },
      "Semi-supervised semantic segmentation via gentle teaching assistant": {
        "authors": [],
        "url": "https://proceedings.neurips.cc/paper_files/paper/2022/file/12d286282e1be5431ea05262a21f415c-Paper-Conference.pdf",
        "ref_texts": "[52] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In IEEE Conference on Computer Vision and Pattern Recognition , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "52"
        ]
      },
      "Weakly supervised 3d scene segmentation with region-level boundary awareness and instance discrimination": {
        "authors": [],
        "url": "https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136880036.pdf",
        "ref_texts": "63. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: Proceedings of the IEEE conference on computer vision and pattern recognition (CVPR). pp. 2881\u20132890 (2017) 3, 8",
        "ref_ids": [
          "63"
        ]
      },
      "Yolopv2: Better, faster, stronger for panoptic driving perception": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2208.11434.pdf?trk=public_post_comment-text",
        "ref_texts": "[28] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "28"
        ]
      },
      "Teachaugment: Data augmentation optimization using teacher knowledge": {
        "authors": [
          "Teppei Suzuki"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2022/papers/Suzuki_TeachAugment_Data_Augmentation_Optimization_Using_Teacher_Knowledge_CVPR_2022_paper.pdf",
        "ref_texts": "[59] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017. 5, 7",
        "ref_ids": [
          "59"
        ]
      },
      "Microstructure segmentation with deep learning encoders pre-trained on a large microscopy dataset": {
        "authors": [
          "Joshua Stuckner"
        ],
        "url": "https://www.nature.com/articles/s41524-022-00878-5.pdf",
        "ref_texts": "56. Zhao, H., Shi, J., Qi, X., Wang, X. & Jia, J. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition2881 \u20132890 (2017).",
        "ref_ids": [
          "56"
        ]
      },
      "One model to edit them all: Free-form text-driven image manipulation with semantic modulations": {
        "authors": [],
        "url": "https://proceedings.neurips.cc/paper_files/paper/2022/file/a0a53fefef4c2ad72d5ab79703ba70cb-Paper-Conference.pdf",
        "ref_texts": "[59] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In IEEE/CVF Conference on Computer Vision and Pattern Recognition , 2017.",
        "ref_ids": [
          "59"
        ]
      },
      "Revisiting consistency regularization for semi-supervised change detection in remote sensing images": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2204.08454",
        "ref_texts": "56.Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: Proceedings of the IEEE conference on computer vision and pattern recognition. pp. 2881\u20132890 (2017) 7 Supplementary Materials for Revisiting Consistency Regularization for Semi-supervised Change Detection in Remote Sensing Images Wele Gedara Chaminda Bandara and Vishal M. Patel Johns Hopkins University, USA",
        "ref_ids": [
          "56"
        ]
      },
      "Uncertainty-aware contrastive distillation for incremental semantic segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2203.14098",
        "ref_texts": "[5] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in CVPR , 2017.",
        "ref_ids": [
          "5"
        ]
      },
      "Adversarial erasing framework via triplet with gated pyramid pooling layer for weakly supervised semantic segmentation": {
        "authors": [],
        "url": "https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136890323.pdf",
        "ref_texts": "60. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: Proceedings of the IEEE conference on computer vision and pattern recognition. pp. 2881\u20132890 (2017)",
        "ref_ids": [
          "60"
        ]
      },
      "ScaleFormer: revisiting the transformer-based backbones from a scale-wise perspective for medical image segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2207.14552",
        "ref_texts": "[Shelhamer et al., 2015] Evan Shelhamer, Jonathan Long ,Trevor Darrell . Fully Convolutional Networks for Semantic Segmentation. The IEEE Conference on Com-puter Vision and Pattern Recognition (CVPR), 2015. [Ronneberger et al., 2015] Olaf Ronneberger, Philipp Fischer, Thomas Brox. U-Net: Convolutional Networks for Bio-medical Image Segmentation. Medical Image Computing and Computer-Assisted Intervention (MICCAI), 2015. [Chen et al., 2017] Liang-Chieh Chen, George Papandreou, Florian Schroff, et al. Rethinking atrous convolution for semantic image segmentation. arXiv preprint arXiv:1706.05587, 2017. [Huang et al., 2020] Huimin Huang, Han Zheng, Lanfen Lin, et al. Medical Image Segmentation with Deep Atlas Prior. IEEE Trans. Medical Imaging 40.12: 3519-3530, 2021. [Luo et al., 2016] Wenjie Luo, Yujia Li, Raquel Urtasun, et al. Understanding the effective receptive field in deep con-volutional neural networks. In NIPS, 2016. \u2028\t[Dosovitskiy et al., 2020] Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, et al. An image is worth 16x16 words: Transformers for image recognition at scale. arXiv preprint arXiv:2010.11929, 2020. .[Cao et al., 2021] Hu Cao, Yueyue Wang, Joy Chen,et al. Swin-Unet: Unet-like Pure Transformer for Medical Im-age Segmentation. arXiv:2105.05537, 2021. [Huang et al., 2021] Xiaohong Huang, Zhifang Deng, Dan-dan Li, et al. MISSFormer: An Effective Medical Image Segmentation Transformer. arXiv:2109.07162, 2021. [Chen et al., 2021] Jieneng Chen, Yongyi Lu, Qihang Yu, et al. Transunet: Transformers make strong encoders for medical image segmentation. arXiv:102.04306, 2021. [Guo et al., 2021] Jianyuan Guo, Kai Han, Han Wu, Chang Xu, et al. Cmt: Convolutional neural networks meet vision transformers. arXiv:2107.06263, 2021. [Zhao et al., 2017] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, et al. Pyramid scene parsing network. The IEEE Con-ference on Computer Vision and Pattern Recognition (CVPR), 2017. [Zhou et al.,2020] Zongwei Zhou, Md Mahfuzur Rahman Siddiquee, Nima Tajbakhsh, et al. UNet++: Redesigning ",
        "ref_ids": [
          "Shelhamer et al\\., 2015",
          "Ronneberger et al\\., 2015",
          "Chen et al\\., 2017",
          "Huang et al\\., 2020",
          "Luo et al\\., 2016",
          "Dosovitskiy et al\\., 2020",
          "Cao et al\\., 2021",
          "Huang et al\\., 2021",
          "Chen et al\\., 2021",
          "Guo et al\\., 2021",
          "Zhao et al\\., 2017",
          "Zhou et al\\.,2020"
        ]
      },
      "Isdnet: Integrating shallow and deep networks for efficient ultra-high resolution segmentation": {
        "authors": [
          "Shaohua Guo",
          "Liang Liu",
          "Zhenye Gan",
          "Yabiao Wang",
          "Wuhao Zhang",
          "Chengjie Wang",
          "Guannan Jiang",
          "Wei Zhang",
          "Ran Yi",
          "Lizhuang Ma",
          "Ke Xu"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2022/papers/Guo_ISDNet_Integrating_Shallow_and_Deep_Networks_for_Efficient_Ultra-High_Resolution_CVPR_2022_paper.pdf",
        "ref_texts": "[40] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017. 1, 3, 7",
        "ref_ids": [
          "40"
        ]
      },
      "Ga-nav: Efficient terrain segmentation for robot navigation in unstructured outdoor environments": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2103.04233",
        "ref_texts": "[5] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "5"
        ]
      },
      "Unbiased subclass regularization for semi-supervised semantic segmentation": {
        "authors": [
          "Dayan Guan",
          "Jiaxing Huang",
          "Aoran Xiao",
          "Shijian Lu"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2022/papers/Guan_Unbiased_Subclass_Regularization_for_Semi-Supervised_Semantic_Segmentation_CVPR_2022_paper.pdf",
        "ref_texts": "[69] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017. 1, 2, 7, 8",
        "ref_ids": [
          "69"
        ]
      },
      "Boundary-aware context neural network for medical image segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2005.00966",
        "ref_texts": "[35] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proc. IEEE Int. Conf. Comput. Vis. Pattern Recognit. , Jul.",
        "ref_ids": [
          "35"
        ]
      },
      "Partial class activation attention for semantic segmentation": {
        "authors": [
          "Ao Liu",
          "Hongtao Xie",
          "Hai Xu",
          "Yongdong Zhang",
          "Qi Tian"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Partial_Class_Activation_Attention_for_Semantic_Segmentation_CVPR_2022_paper.pdf",
        "ref_texts": "[40] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017. 1, 2, 5, 8",
        "ref_ids": [
          "40"
        ]
      },
      "Trans4Trans: Efficient transformer for transparent object and semantic scene segmentation in real-world navigation assistance": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2108.09174",
        "ref_texts": "[51] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in CVPR , 2017.",
        "ref_ids": [
          "51"
        ]
      },
      "Beyond the prototype: Divide-and-conquer proxies for few-shot segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2204.09903",
        "ref_texts": "[Zhao et al. , 2017 ]Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. InProc. IEEE Int. Conf. Comput. Vis. Pattern Recognit. , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "Zhao et al\\. , 2017 "
        ]
      },
      "Open world entity segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2107.14228",
        "ref_texts": "[90] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In CVPR , 2017.",
        "ref_ids": [
          "90"
        ]
      },
      "Semantic diffusion network for semantic segmentation": {
        "authors": [],
        "url": "https://proceedings.neurips.cc/paper_files/paper/2022/file/396446770f5e8496ca1feb02079d4fb7-Paper-Conference.pdf",
        "ref_texts": "[15] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, Jiaya Jia: Pyramid scene parsing network. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (2017)",
        "ref_ids": [
          "15"
        ]
      },
      "FBSNet: A fast bilateral symmetrical network for real-time semantic segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2109.00699",
        "ref_texts": "[8] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in CVPR , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "8"
        ]
      },
      "Learning semantic associations for mirror detection": {
        "authors": [
          "Huankang Guan",
          "Jiaying Lin",
          "Rynson W"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2022/papers/Guan_Learning_Semantic_Associations_for_Mirror_Detection_CVPR_2022_paper.pdf",
        "ref_texts": "[54] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR 2017 . 4, 6[55] Jia-Xing Zhao, Jiang-Jiang Liu, Deng-Ping Fan, Yang Cao, Jufeng Yang, and Ming-Ming Cheng. Egnet:edge guidance network for salient object detection. In ICCV 2019 . 6, 7",
        "ref_ids": [
          "54",
          "55"
        ]
      },
      "Category-level 6d object pose estimation in the wild: A semi-supervised learning approach and a new dataset": {
        "authors": [],
        "url": "https://proceedings.neurips.cc/paper_files/paper/2022/file/afe99e55be23b3523818da1fefa33494-Paper-Conference.pdf",
        "ref_texts": "[56] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017. 5",
        "ref_ids": [
          "56"
        ]
      },
      "Learning implicit feature alignment function for semantic segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2206.08655",
        "ref_texts": "55. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: Proceedings of the IEEE conference on computer vision and pattern recognition. pp. 2881\u20132890 (2017) 4, 6, 10, 13, 14",
        "ref_ids": [
          "55"
        ]
      },
      "NightLab: A dual-level architecture with hardness detection for segmentation at night": {
        "authors": [
          "Xueqing Deng",
          "Peng Wang",
          "Xiaochen Lian",
          "Shawn Newsam"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2022/papers/Deng_NightLab_A_Dual-Level_Architecture_With_Hardness_Detection_for_Segmentation_at_CVPR_2022_paper.pdf",
        "ref_texts": "[60] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid Scene Parsing Network. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2017. 3, 6",
        "ref_ids": [
          "60"
        ]
      },
      "A unified query-based paradigm for point cloud understanding": {
        "authors": [
          "Zetong Yang",
          "Li Jiang",
          "Yanan Sun",
          "Bernt Schiele",
          "Jiaya Jia"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2022/papers/Yang_A_Unified_Query-Based_Paradigm_for_Point_Cloud_Understanding_CVPR_2022_paper.pdf",
        "ref_texts": "[70] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017. 2, 8",
        "ref_ids": [
          "70"
        ]
      },
      "Knowledge distillation as efficient pre-training: Faster convergence, higher data-efficiency, and better transferability": {
        "authors": [
          "Ruifei He",
          "Shuyang Sun",
          "Jihan Yang",
          "Song Bai",
          "Xiaojuan Qi"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2022/papers/He_Knowledge_Distillation_As_Efficient_Pre-Training_Faster_Convergence_Higher_Data-Efficiency_and_CVPR_2022_paper.pdf",
        "ref_texts": "[73] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017.",
        "ref_ids": [
          "73"
        ]
      },
      "Mining relations among cross-frame affinities for video semantic segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2207.10436",
        "ref_texts": "52. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: IEEE CVPR. pp. 2881\u20132890 (2017) 1, 4, 13",
        "ref_ids": [
          "52"
        ]
      },
      "Saliency guided inter-and intra-class relation constraints for weakly supervised semantic segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2206.09554",
        "ref_texts": "[32] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proc. IEEE Conference on Computer Vision and Pattern Recognition , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "32"
        ]
      },
      "Unsupervised multi-view object segmentation using radiance field propagation": {
        "authors": [],
        "url": "https://proceedings.neurips.cc/paper_files/paper/2022/file/70de9e3948645a1be2de657f14d85c6d-Paper-Conference.pdf",
        "ref_texts": "[50] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In The IEEE / CVF Computer Vision and Pattern Recognition Conference , 2017.",
        "ref_ids": [
          "50"
        ]
      },
      "Class-guided swin transformer for semantic segmentation of remote sensing imagery": {
        "authors": [],
        "url": "https://wrap.warwick.ac.uk/170267/7/WRAP-class-guided-swin-transformer-semantic-segmentation-remote-sensing-imagery-Li-2022.pdf",
        "ref_texts": "[2] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \"Pyramid scene parsing network,\" in Proceedings of the IEEE conference on computer vision and pattern recognition, 2017, pp. 28812890. ",
        "ref_ids": [
          "2"
        ]
      },
      "Generalized few-shot semantic segmentation": {
        "authors": [
          "Zhuotao Tian",
          "Xin Lai",
          "Li Jiang",
          "Shu Liu",
          "Michelle Shu",
          "Hengshuang Zhao",
          "Jiaya Jia"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2022/papers/Tian_Generalized_Few-Shot_Semantic_Segmentation_CVPR_2022_paper.pdf",
        "ref_texts": "[64] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017. 1, 2, 4, 7",
        "ref_ids": [
          "64"
        ]
      },
      "Efficient semantic segmentation via self-attention and self-distillation": {
        "authors": [],
        "url": "https://discovery.ucl.ac.uk/id/eprint/10141780/1/ShuminAn-T-ITS-accepted.pdf",
        "ref_texts": "[6] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "6"
        ]
      },
      "Adaptive agent transformer for few-shot segmentation": {
        "authors": [],
        "url": "https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136890035.pdf"
      },
      "Gfnet: Geometric flow network for 3d point cloud semantic segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2207.02605",
        "ref_texts": "14 Published in Transactions on Machine Learning Research (09/2022) Yue Wang, Yongbin Sun, Ziwei Liu, Sanjay E Sarma, Michael M Bronstein, and Justin M Solomon. Dynamic graph cnn for learning on point clouds. ACM Transactions On Graphics (TOG) , 38(5):1\u201312, 2019. Bichen Wu, Alvin Wan, Xiangyu Yue, and Kurt Keutzer. Squeezeseg: Convolutional neural nets with recurrent crf for real-time road-object segmentation from 3d lidar point cloud. In IEEE International Conference on Robotics and Automation (ICRA) , pp. 1887\u20131893, 2018. Bichen Wu, Xuanyu Zhou, Sicheng Zhao, Xiangyu Yue, and Kurt Keutzer. Squeezesegv2: Improved model structure and unsupervised domain adaptation for road-object segmentation from a lidar point cloud. In IEEE International Conference on Robotics and Automation (ICRA) , pp. 4376\u20134382, 2019. Chenfeng Xu, Bichen Wu, Zining Wang, Wei Zhan, Peter Vajda, Kurt Keutzer, and Masayoshi Tomizuka. Squeezesegv3: Spatially-adaptive convolution for efficient point-cloud segmentation. In European Conference on Computer Vision (ECCV) , pp. 1\u201319, 2020. Jianyun Xu, Ruixiang Zhang, Jian Dou, Yushi Zhu, Jie Sun, and Shiliang Pu. Rpvnet: A deep and efficient range-point-voxel fusion network for lidar point cloud segmentation. In IEEE/CVF International Conference on Computer Vision (ICCV) , pp. 16024\u201316033, 2021. Xu Yan, Jiantao Gao, Jie Li, Ruimao Zhang, Zhen Li, Rui Huang, and Shuguang Cui. Sparse single sweep lidar point cloud segmentation via learning contextual shape priors from scene completion. arXiv preprint arXiv:2012.03762 , 2020a. XuYan, ChaodaZheng, ZhenLi, ShengWang, andShuguangCui. Pointasnl: Robustpointcloudsprocessing using nonlocal neural networks with adaptive sampling. In IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) , pp. 5589\u20135598, 2020b. Xu Yan, Jiantao Gao, Chaoda Zheng, Chao Zheng, Ruimao Zhang, Shuguang Cui, and Zhen Li. 2dpass: 2d priors assisted semantic segmentation on lidar point clouds. In European Conference on Computer Vision (ECCV), 2022. Lei Yang, Yanhong Liu, Jinzhu Peng, and Zize Liang. A novel system for off-line 3d seam extraction and path planning based on point cloud segmentation for arc welding robot. Robotics and Computer-Integrated Manufacturing , 64:101929, 2020. Maosheng Ye, Rui Wan, Shuangjie Xu, Tongyi Cao, and Qifeng Chen. Drinet++: Efficient voxel-as-point point cloud segmentation. arXiv preprint arXiv:2111.08318 , 2021. Feihu Zhang, Jin Fang, Benjamin Wah, and Philip Torr. Deep fusionnet for point cloud semantic segmentation. In European Conference on Computer Vision (ECCV) , pp. 644\u2013663, 2020a. YangZhang, ZixiangZhou, PhilipDavid, XiangyuYue, ZerongXi, BoqingGong, andHassanForoosh. Polarnet: An improved grid representation for online lidar point clouds semantic segmentation. In IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) , pp. 9601\u20139610, 2020b. HengshuangZhao,JianpingShi,XiaojuanQi,XiaogangWang,andJiayaJia. Pyramidsceneparsingnetwork. InIEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) , pp. 2881\u20132890, 2017. Xinge Zhu, Hui Zhou, Tai Wang, Fangzhou Hong, Yuexin Ma, Wei Li, Hongsheng Li, and Dahua Lin. Cylindrical and asymmetrical 3d convolution networks for lidar segmentation. In IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) , pp. 9939\u20139948, 2021."
      },
      "Learning from future: A novel self-training framework for semantic segmentation": {
        "authors": [],
        "url": "https://proceedings.neurips.cc/paper_files/paper/2022/file/1e97fb8a7c9737e9e9f4e0389b25efe8-Paper-Conference.pdf",
        "ref_texts": "[59] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In IEEE Conf. Comput. Vis. Pattern Recog. , 2017.",
        "ref_ids": [
          "59"
        ]
      },
      "Pyramid architecture for multi-scale processing in point cloud segmentation": {
        "authors": [
          "Dong Nie",
          "Rui Lan",
          "Ling Wang",
          "Xiaofeng Ren"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2022/papers/Nie_Pyramid_Architecture_for_Multi-Scale_Processing_in_Point_Cloud_Segmentation_CVPR_2022_paper.pdf",
        "ref_texts": "[59] H. Zhao et al. Pyramid scene parsing network. In CVPR , pages 2881\u20132890, 2017. 1",
        "ref_ids": [
          "59"
        ]
      },
      "Densely nested top-down flows for salient object detection": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2102.09133",
        "ref_texts": "33 Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881{2890, 2017."
      },
      "You should look at all objects": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2207.07889",
        "ref_texts": "48. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: Proceedings of the IEEE conference on computer vision and pattern recognition. pp. 2881\u20132890 (2017)",
        "ref_ids": [
          "48"
        ]
      },
      "Msanet: Multi-similarity and attention guidance for boosting few-shot segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2206.09667",
        "ref_texts": "[68] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017. 2",
        "ref_ids": [
          "68"
        ]
      },
      "Panoptic-partformer: Learning a unified model for panoptic part segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2204.04655",
        "ref_texts": "73. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: CVPR (2017)",
        "ref_ids": [
          "73"
        ]
      },
      "Semantic image segmentation: Two decades of research": {
        "authors": [],
        "url": "https://www.nowpublishers.com/article/DownloadSummary/CGV-095",
        "ref_texts": "\u201cExtracting Relationships by Multi-Domain Matching\u201d. In: NeurIPS. Li, Y., Y. Yang, W. Zhou, and T. M. Hospedales. (2019b). \u201cFeatureCritic Networks for Heterogeneous Domain Generalization\u201d. In: ICML. Li, Y., L. Yuan, and N. Vasconcelos. (2019c). \u201cBidirectional Learning for Domain Adaptation of Semantic Segmentation\u201d. In: CVPR. Li, Z., Z. Chen, F. Yang, W. Li, Y. Zhu, C. Zhao, R. Deng, L. Wu, R. Zhao, M. Tang, and J. Wang. (2021c). \u201cMST: Masked SelfSupervised Transformer for Visual Representation\u201d. In: NeurIPS. Li, Z., Y. Gan, X. Liang, Y. Yu, H. Cheng, and L. Lin. (2016). \u201cLSTMCF: Unifying Context Modeling and Fusion with LSTMs for RGB-D Scene Labeling\u201d. In: ECCV. Lian, Q., F. Lv, L. Duan, and B. Gong. (2019). \u201cConstructing Selfmotivated Pyramid Curriculums for Cross-Domain Semantic Segmentation: A Non-Adversarial Approach\u201d. In: ICCV. Liang, J., D. Hu, and J. Feng. (2020). \u201cDo We Really Need to Access the Source Data? Source Hypothesis Transfer for Unsupervised Domain Adaptation\u201d. In: ICML. Liang, S., Y. Li, and R. Srikant. (2018a). \u201cEnhancing The Reliability of Out-of-distribution Image Detection in Neural Networks\u201d. In: ICLR. Full text available at: http://dx.doi.org/10.1561/0600000095 References. 139 Liang, X., X. Shen, J. Feng, L. Lin, and S. Yan. (2016). \u201cSemantic Object Parsing with Graph LSTM\u201d. In: ECCV. Liang, X., Y. Wei, X. Shen, J. Yang, L. Lin, and S. Yan. (2018b)."
      },
      "Cdgnet: Class distribution guided network for human parsing": {
        "authors": [
          "Kunliang Liu",
          "Ouk Choi",
          "Jianming Wang",
          "Wonjun Hwang"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2022/papers/Liu_CDGNet_Class_Distribution_Guided_Network_for_Human_Parsing_CVPR_2022_paper.pdf",
        "ref_texts": "[44] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In CVPR , pages 7450\u20137459, Jun. 2019. 1, 2",
        "ref_ids": [
          "44"
        ]
      },
      "UDA-COPE: Unsupervised domain adaptation for category-level object pose estimation": {
        "authors": [
          "Taeyeop Lee",
          "Uk Lee",
          "Inkyu Shin",
          "Jaesung Choe",
          "Ukcheol Shin",
          "In So",
          "Jin Yoon"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2022/papers/Lee_UDA-COPE_Unsupervised_Domain_Adaptation_for_Category-Level_Object_Pose_Estimation_CVPR_2022_paper.pdf",
        "ref_texts": "[41] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) , pages 2881\u20132890, 2017. 2",
        "ref_ids": [
          "41"
        ]
      },
      "Semi-Supervised Semantic Segmentation in Earth Observation: The MiniFrance suite, dataset analysis and multi-task network study": {
        "authors": [
          "Javiera Castillo"
        ],
        "url": "https://link.springer.com/content/pdf/10.1007/s10994-020-05943-y.pdf",
        "ref_texts": "7708\u20137720. Xia, G. S., Bai, X., Ding, J., Zhu, Z., Belongie, S., Luo, J., et\u00a0al. (2018). DOTA: A large-scale dataset for object detection in aerial images. In Proceedings of the IEEE conference on computer vision and pattern recognition (CVPR) (pp. 3974\u20133983). Xia, J., Chanussot, J., Du, P., & He, X. (2013). (Semi-) supervised probabilistic principal component analy sis for hyperspectral remote sensing image classification. IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing, 7(6), 2224\u20132236. Xia, X., & Kulis, B. (2017). W-Net: A deep model for fully unsupervised image segmentation. arXiv e-prints arXiv: 1711. 08506. Zhang, R., Albrecht, C., Zhang, W., Cui, X., Finkler, U., Kung, D., & Lu, S. (2020). Map generation from large scale incomplete and inaccurate data labels. arXiv preprint arXiv: 2005. 10053. Zhao, H., Shi, J., Qi, X., Wang, X., & Jia, J. (2017) Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition (CVPR) (pp. 2881\u20132890). Zhu, R., Yan, L., Mo, N., & Liu, Y. (2019). Semi-supervised center-based discriminative adversarial learning for cross-domain scene-level land-cover classification of aerial images. ISPRS Journal of Photogrammetry and Remote Sensing, 155, 72\u201389. Zhu, X. X., Tuia, D., Mou, L., Xia, G. S., Zhang, L., Xu, F., & Fraundorfer, F. (2017). Deep learning in remote sensing: A comprehensive review and list of resources. IEEE Geoscience and Remote Sensing Magazine, 5(4), 8\u201336. Publisher\u2019s Note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations. Authors and Affiliations Javiera\u00a0Castillo\u2011Navarro1,2 \u00a0\u00b7 Bertrand\u00a0Le\u00a0Saux3\u00a0\u00b7 Alexandre\u00a0Boulch4\u00a0\u00b7 Nicolas\u00a0Audebert5\u00a0\u00b7 S\u00e9bastien\u00a0Lef\u00e8vre2"
      },
      "Fully convolutional networks for panoptic segmentation with point-based supervision": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2108.07682",
        "ref_texts": "[21] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in IEEE Conference on Computer Vision and Pattern Recognition , 2017.",
        "ref_ids": [
          "21"
        ]
      },
      "Progressive glass segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2209.02280",
        "ref_texts": "[14] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in CVPR , 2017.",
        "ref_ids": [
          "14"
        ]
      },
      "SAPNet: Segmentation-aware progressive network for perceptual contrastive deraining": {
        "authors": [
          "Shen Zheng",
          "Changjie Lu",
          "Yuxiong Wu",
          "Gaurav Gupta"
        ],
        "url": "https://openaccess.thecvf.com/content/WACV2022W/VAQ/papers/Zheng_SAPNet_Segmentation-Aware_Progressive_Network_for_Perceptual_Contrastive_Deraining_WACVW_2022_paper.pdf",
        "ref_texts": "[57] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "57"
        ]
      },
      "Predicting the effect of street environment on residents' mood states in large urban areas using machine learning and street view images": {
        "authors": [],
        "url": "https://eprints.gla.ac.uk/260536/1/260536.pdf",
        "ref_texts": "3.2. Research framework 150 Fig. 2 illustrates this study\u2019s three main stages . First, street view images of the study area 151 were collected via Tencent Street View through an Application Programming Interface (API) and 152 OpenStreetMap (OSM). Sample images were then selected manually and randomly for use in 153 assess ing the perceptual m ood states of street environments. Data on s ix mood state indicators 154 were collected through an online platform from local participants , who scored two-image 155 comparisons. Second, the mood state score of each image was quantified using the strength of 156 schedule method , and , for training the machine learning models , the binary label method was used 157 for image classification. Street -view element extraction was then processed through pyramid scene 158 parsing network (PSPNet) to obtain objective and accurate image segmentation. Third, five 159 machine learning algor ithms were applied to test the model s\u2019 accuracy and generalizability , and 160 "
      },
      "Image coding for machines with omnipotent feature learning": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2207.01932",
        "ref_texts": "86. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: CVPR. pp. 2881\u20132890 (2017)",
        "ref_ids": [
          "86"
        ]
      },
      "National Land Use Regression Model for NO2 Using Street View Imagery and Satellite Observations": {
        "authors": [
          "Meng Qi",
          "Kuldeep Dixit",
          "Julian D. Marshall",
          "Wenwen Zhang",
          "Steve Hankey"
        ],
        "url": "https://par.nsf.gov/servlets/purl/10405094",
        "ref_texts": "(49) Zhao, H. S.; Shi, J. P.; Qi, X. J.; Wang, X. G.; Jia, J. Y. In Pyramid Scene Parsing Network, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2017; pp 2881\u22122890."
      },
      "Graph convolution based cross-network multiscale feature fusion for deep vessel segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2301.02393",
        "ref_texts": "[17] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "17"
        ]
      },
      "High quality segmentation for ultra high-resolution images": {
        "authors": [
          "Tiancheng Shen",
          "Yuechen Zhang",
          "Lu Qi",
          "Jason Kuen",
          "Xingyu Xie",
          "Jianlong Wu",
          "Zhe Lin",
          "Jiaya Jia"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2022/papers/Shen_High_Quality_Segmentation_for_Ultra_High-Resolution_Images_CVPR_2022_paper.pdf",
        "ref_texts": "[55] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , pages 2881\u20132890, 2017. 1, 2, 6, 8",
        "ref_ids": [
          "55"
        ]
      },
      "Review of object instance segmentation based on deep learning": {
        "authors": [],
        "url": "https://www.spiedigitallibrary.org/journals/journal-of-electronic-imaging/volume-31/issue-4/041205/Review-of-object-instance-segmentation-based-on-deep-learning/10.1117/1.JEI.31.4.041205.pdf",
        "ref_texts": "12. H. Zhoa et al., \u201cPyramid scene parsing network, \u201dinProc. 30th IEEE/CVF Conf. Comput. Vision and Pattern Recognit. , Honolulu, pp. 6230 \u20136239 (2017).",
        "ref_ids": [
          "12"
        ]
      },
      "Efficient point cloud segmentation with geometry-aware sparse networks": {
        "authors": [],
        "url": "https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136990193.pdf",
        "ref_texts": "57. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: CVPR. pp. 2881\u20132890 (2017)",
        "ref_ids": [
          "57"
        ]
      },
      "Watermark vaccine: Adversarial attacks to prevent watermark removal": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2207.08178",
        "ref_texts": "57. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: CVPR (2017)",
        "ref_ids": [
          "57"
        ]
      },
      "Mask matching transformer for few-shot segmentation": {
        "authors": [],
        "url": "https://proceedings.neurips.cc/paper_files/paper/2022/file/053a18c03e0844d0c484ba2861f8ae6c-Paper-Conference.pdf",
        "ref_texts": "[37] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "37"
        ]
      },
      "Multi-label iterated learning for image classification with label ambiguity": {
        "authors": [
          "Sai Rajeswar",
          "Pau Rodriguez",
          "Soumye Singhal",
          "David Vazquez",
          "Aaron Courville"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2022/papers/Rajeswar_Multi-Label_Iterated_Learning_for_Image_Classification_With_Label_Ambiguity_CVPR_2022_paper.pdf",
        "ref_texts": "[70] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In CVPR , 2017.",
        "ref_ids": [
          "70"
        ]
      },
      "Terrapn: Unstructured terrain navigation using online self-supervised learning": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2202.12873",
        "ref_texts": "[36] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "36"
        ]
      },
      "Deep covariance alignment for domain adaptive remote sensing image segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2401.04412",
        "ref_texts": "[9] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR) , Jun. 2017, pp. 6230\u20136239.",
        "ref_ids": [
          "9"
        ]
      },
      "Interclass prototype relation for few-shot segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2211.08681",
        "ref_texts": "48. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: CVPR. pp. 6230\u20136239 (2017)",
        "ref_ids": [
          "48"
        ]
      },
      "Adversarially-aware robust object detector": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2207.06202",
        "ref_texts": "37.Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: Conference on Computer Vision and Pattern Recognition (CVPR). pp. 6230\u20136239",
        "ref_ids": [
          "37"
        ]
      },
      "Understanding the Tricks of Deep Learning in Medical Image Segmentation: Challenges and Future Directions": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2209.10307",
        "ref_texts": "[71] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2017.",
        "ref_ids": [
          "71"
        ]
      },
      "AIParsing: Anchor-free instance-level human parsing": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2207.06854",
        "ref_texts": "[72] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proc. IEEE Conf. CVPR , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "72"
        ]
      },
      "Dyrep: Bootstrapping training with dynamic re-parameterization": {
        "authors": [
          "Tao Huang",
          "Shan You",
          "Bohan Zhang",
          "Yuxuan Du",
          "Fei Wang",
          "Chen Qian",
          "Chang Xu"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2022/papers/Huang_DyRep_Bootstrapping_Training_With_Dynamic_Re-Parameterization_CVPR_2022_paper.pdf",
        "ref_texts": "[33] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017. 1, 7",
        "ref_ids": [
          "33"
        ]
      },
      "Exploiting semantic relations for glass surface detection": {
        "authors": [],
        "url": "https://proceedings.neurips.cc/paper_files/paper/2022/file/8d162f48c816af5f8c114eb437e8b28b-Paper-Conference.pdf",
        "ref_texts": "[48] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017.",
        "ref_ids": [
          "48"
        ]
      },
      "Eco-tr: Efficient correspondences finding via coarse-to-fine refinement": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2209.12213",
        "ref_texts": "57. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: Proceedings of the IEEE conference on computer vision and pattern recognition. pp. 2881\u20132890 (2017)",
        "ref_ids": [
          "57"
        ]
      },
      "An improved DeepLab v3+ deep learning network applied to the segmentation of grape leaf black rot spots": {
        "authors": [],
        "url": "https://www.frontiersin.org/articles/10.3389/fpls.2022.795410/pdf",
        "ref_texts": "2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , July 2017, 636\u2013644. Zagoruyko, S., and Komodakis, N. (2016). Wide residual networks. in British Machine Vision Conference (BMVC), September 2016, 87.1\u201387.12. Zhao, H., Shi, J., Qi, X., Wang, X., and Jia, J. (2017). Pyramid scene parsing network. in Proceedings of 30th IEEE Conference on Computer Vision and Pattern Recognition, CVPR, January 2017, 6230\u20136239. Zhou, R., Kaneko, S., Tanaka, F., Kayamori, M., and Shimizu, M. (2014). Disease detection of Cercospora leaf spot in sugar beet by robust template matching. Comput. Electron. Agric. 108, 58\u201370. doi: 10.1016/j.compag.2014. "
      },
      "Banet: Boundary-assistant encoder-decoder network for semantic segmentation": {
        "authors": [
          "Quan Zhou",
          "Yong Qiang",
          "Yuwei Mo",
          "Xiaofu Wu",
          "Longin Jan"
        ],
        "url": "https://par.nsf.gov/servlets/purl/10356319",
        "ref_texts": ""
      },
      "Hierarchical normalization for robust monocular depth estimation": {
        "authors": [],
        "url": "https://proceedings.neurips.cc/paper_files/paper/2022/file/5b4a459db23e6db9be2a128380953d96-Paper-Conference.pdf",
        "ref_texts": "[43] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proc. IEEE Conf. Comp. Vis. Patt. Recogn. , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "43"
        ]
      },
      "MASS: Multi-attentional semantic segmentation of LiDAR data for dense top-view understanding": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2107.00346",
        "ref_texts": "[28] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proc. CVPR , 2017, pp. 6230\u20136239.",
        "ref_ids": [
          "28"
        ]
      },
      "A simple single-scale vision transformer for object detection and instance segmentation": {
        "authors": [],
        "url": "https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136700697.pdf",
        "ref_texts": ""
      },
      "Tensor pooling-driven instance segmentation framework for baggage threat recognition": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2108.09603",
        "ref_texts": "49. H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \\Pyramid Scene Parsing Network,\" in IEEE International Conference on Computer Vision and Pattern Recognition (CVPR) , pp. 2881{2890, 2017.",
        "ref_ids": [
          "49"
        ]
      },
      "Decoupled multi-task learning with cyclical self-regulation for face parsing": {
        "authors": [
          "Qingping Zheng",
          "Jiankang Deng",
          "Zheng Zhu",
          "Ying Li",
          "Stefanos Zafeiriou"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2022/papers/Zheng_Decoupled_Multi-Task_Learning_With_Cyclical_Self-Regulation_for_Face_Parsing_CVPR_2022_paper.pdf",
        "ref_texts": "[45] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017. 2, 3, 4, 6, 7, 8",
        "ref_ids": [
          "45"
        ]
      },
      "UCTNet: Uncertainty-aware cross-modal transformer network for indoor RGB-D semantic segmentation": {
        "authors": [],
        "url": "https://par.nsf.gov/servlets/purl/10467720",
        "ref_texts": "56. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: Proceedings of the IEEE conference on computer vision and pattern recognition. pp. 2881\u20132890 (2017)",
        "ref_ids": [
          "56"
        ]
      },
      "Revisiting image pyramid structure for high resolution salient object detection": {
        "authors": [
          "Taehun Kim",
          "Kunhee Kim",
          "Joonyeong Lee",
          "Dongmin Cha",
          "Jiho Lee",
          "Daijin Kim"
        ],
        "url": "https://openaccess.thecvf.com/content/ACCV2022/papers/Kim_Revisiting_Image_Pyramid_Structure_for_High_Resolution_Salient_Object_Detection_ACCV_2022_paper.pdf",
        "ref_texts": "13. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: CVPR. (2017) 2881\u20132890 4, 10",
        "ref_ids": [
          "13"
        ]
      },
      "Perceptual artifacts localization for inpainting": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2208.03357",
        "ref_texts": "74. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: Proceedings of the IEEE conference on computer vision and pattern recognition. pp. 2881\u20132890 (2017) 6, 7, 17",
        "ref_ids": [
          "74"
        ]
      },
      "A dense material segmentation dataset for indoor and outdoor scene parsing": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2207.10614",
        "ref_texts": "44. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: Proceedings of the IEEE conference on computer vision and pattern recognition. pp. 2881\u20132890 (2017)",
        "ref_ids": [
          "44"
        ]
      },
      "Beyond monocular deraining: Parallel stereo deraining network via semantic prior": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2105.03830",
        "ref_texts": "73. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)",
        "ref_ids": [
          "73"
        ]
      },
      "A multi-task framework for infrared small target detection and segmentation": {
        "authors": [
          "Tiffany Mc"
        ],
        "url": "https://arxiv.org/pdf/2206.06923",
        "ref_texts": "[16] Zhao H, Shi J, Qi X, Wang X, Jia J. Pyramid scene parsing network. Proceedings of the IEEE c onference on computer vision and pattern recognition, 2017, p. 2881\u2013 90. ",
        "ref_ids": [
          "16"
        ]
      },
      "Rainy WCity: A Real Rainfall Dataset with Diverse Conditions for Semantic Driving Scene Understanding.": {
        "authors": [
          "Xian Zhong",
          "Shidong Tu",
          "Xianzheng Ma",
          "Kui Jiang",
          "Wenxin Huang",
          "Zheng Wang"
        ],
        "url": "https://www.ijcai.org/proceedings/2022/0243.pdf",
        "ref_texts": "[Zhao et al., 2017 ]Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR, pages 6230\u20136239, 2017.",
        "ref_ids": [
          "Zhao et al\\., 2017 "
        ]
      },
      "A survey on object instance segmentation": {
        "authors": [
          "Rabi Sharma"
        ],
        "url": "https://link.springer.com/content/pdf/10.1007/s42979-022-01407-3.pdf",
        "ref_texts": ""
      },
      "Auxadapt: Stable and efficient test-time adaptation for temporally consistent video semantic segmentation": {
        "authors": [
          "Yizhe Zhang",
          "Shubhankar Borse",
          "Hong Cai",
          "Fatih Porikli"
        ],
        "url": "https://openaccess.thecvf.com/content/WACV2022/papers/Zhang_AuxAdapt_Stable_and_Efficient_Test-Time_Adaptation_for_Temporally_Consistent_Video_WACV_2022_paper.pdf",
        "ref_texts": "[43] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , 2017.",
        "ref_ids": [
          "43"
        ]
      },
      "Semantic segmentation for thermal images: A comparative survey": {
        "authors": [
          "Zulfiye Kutuk",
          "Gorkem Algan"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2022W/PBVS/papers/Kutuk_Semantic_Segmentation_for_Thermal_Images_A_Comparative_Survey_CVPRW_2022_paper.pdf",
        "ref_texts": "[39] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017. 3",
        "ref_ids": [
          "39"
        ]
      },
      "On the road to online adaptation for semantic image segmentation": {
        "authors": [
          "Riccardo Volpi",
          "Pau De",
          "Diane Larlus",
          "Gabriela Csurka"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2022/papers/Volpi_On_the_Road_to_Online_Adaptation_for_Semantic_Image_Segmentation_CVPR_2022_paper.pdf",
        "ref_texts": "[103] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid Scene Parsing Network. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2017. 2",
        "ref_ids": [
          "103"
        ]
      },
      "E2EK: End-to-end regression network based on keypoint for 6D pose estimation": {
        "authors": [],
        "url": "https://uwe-repository.worktribe.com/index.php/preview/9655564/E2EK_RAL_finalversion_plain.pdf",
        "ref_texts": "[28] H. Zhao, J. Shi, X. Qi , et al. , \u201dPyramid scene parsing network.\u201d in Proc. IEEE Conf. Comput. Vis. Pattern Recognit., 2017. pp. 2881-2890.",
        "ref_ids": [
          "28"
        ]
      },
      "A transformer-based decoder for semantic segmentation with multi-level context mining": {
        "authors": [],
        "url": "https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136880617-supp.pdf",
        "ref_texts": "5. Zhao, H., Shi, J., Qi, X., et. al: Pyramid scene parsing network. In: CVPR (2017)",
        "ref_ids": [
          "5"
        ]
      },
      "Automatic scoring of COVID-19 severity in X-ray imaging based on a novel deep learning workflow": {
        "authors": [
          "Viacheslav V. Danilov"
        ],
        "url": "https://www.nature.com/articles/s41598-022-15013-z.pdf",
        "ref_texts": ""
      },
      "One-shot object affordance detection in the wild": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2108.03658",
        "ref_texts": "436 Wang H, Yang Y, Cao X, Zhen X, Snoek C, Shao L (2021a) Variational prototype inference for fewshot semantic segmentation. In: Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision, pp 525{534 Wang J, Sun K, Cheng T, Jiang B, Deng C, Zhao Y, Liu D, Mu Y, Tan M, Wang X, et al. (2020) Deep highresolution representation learning for visual recognition. IEEE transactions on pattern analysis and machine intelligence Wang K, Oramas J, Tuytelaars T (2021b) Minmaxcam: Improving object coverage for cambasedweakly supervised object localization. arXiv preprint arXiv:210414375 Wang X, Girdhar R, Gupta A (2017) Binge watching: Scaling afiordance learning from sitcoms. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp 2596{2605 Wang YX, Hebert M (2016) Learning to learn: Model regression networks for easy small sample learning. In: European Conference on Computer Vision, Springer, pp 616{634 Wei P, Xie D, Zheng N, Zhu SC (2017) Inferring human attention by learning latent intentions. In: IJCAI, pp 1297{1303 Wu S, Yang J, Wang X, Li X (2019a) Iou-balanced loss functions for single-stage object detection. arXiv preprint arXiv:190805641 Wu Z, Su L, Huang Q (2019b) Cascaded partial decoder for fast and accurate salient object detection. In: CVPR Xu B, Li J, Wong Y, Zhao Q, Kankanhalli MS (2019) Interact as you intend: Intention-driven humanobject interaction detection. IEEE Transactions on Multimedia 22(6):1423{1432 Yamanobe N, Wan W, Ramirez-Alpizar IG, Petit D, Tsuji T, Akizuki S, Hashimoto M, Nagata K, Harada K (2017) A brief review of afiordance in robotic manipulation research. Advanced Robotics 31(1920):1086{1101 Yan S, Xiong Y, Lin D (2018) Spatial temporal graph convolutional networks for skeleton-based action recognition. In: Thirty-second AAAI conference on artiffcial intelligence One-Shot Object Afiordance Detection in the Wild 27 Zhang C, Lin G, Liu F, Yao R, Shen C (2019) Canet: Class-agnostic segmentation networks with iterative reffnement and attentive few-shot learning. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp 5217{5226 Zhang J, Tao D (2020) Empowering things with intelligence: A survey of the progress, challenges, and opportunities in artiffcial intelligence of things. IEEE Internet of Things Journal Zhang J, Chen Z, Tao D (2021) Towards high performance human keypoint detection. International Journal of Computer Vision pp 1{24 Zhao H, Shi J, Qi X, Wang X, Jia J (2017) Pyramid scene parsing network. In: CVPR Zhao JX, Liu JJ, Fan DP, Cao Y, Yang J, Cheng MM"
      },
      "Label-only membership inference attacks and defenses in semantic segmentation models": {
        "authors": [
          "Gregory Hampshire"
        ],
        "url": "https://opus.lib.uts.edu.au/bitstream/10453/155042/2/Binder2.pdf",
        "ref_texts": "[21] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in CVPR . IEEE Computer Society, 2017, pp. 6230\u20136239.",
        "ref_ids": [
          "21"
        ]
      },
      "A comprehensive review of modern object segmentation approaches": {
        "authors": [],
        "url": "https://www.nowpublishers.com/article/DownloadSummary/CGV-097",
        "ref_texts": "(2020d). \u201cPolarNet: An Improved Grid Representation for Online LiDAR Point Clouds Semantic Segmentation\u201d. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Zhang, Z., X. Zhang, C. Peng, X. Xue, and J. Sun. (2018b). \u201cExfuse: Enhancing feature fusion for semantic segmentation\u201d. In: Proceedings of the European Conference on Computer Vision (ECCV). 269\u2013284. Zhang, Z., Z. Cui, C. Xu, Y. Yan, N. Sebe, and J. Yang. (2019). \u201cPatternaffinitive propagation across depth, surface normal and semantic segmentation\u201d. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition . 4106\u20134115. Zhang, Z., L. Yang, and Y. Zheng. (2018c). \u201cTranslating and segmenting multimodal medical volumes with cycle-and shape-consistency generative adversarial network\u201d. In: Proceedings of the IEEE conference on computer vision and pattern Recognition . 9242\u20139251. Zhao, H., L. Jiang, J. Jia, P. H. Torr, and V. Koltun. (2021). \u201cPoint transformer\u201d. In: Proceedings of the IEEE/CVF International Conference on Computer Vision . 16259\u201316268. Zhao, H., X. Qi, X. Shen, J. Shi, and J. Jia. (2018a). \u201cIcnet for real-time semantic segmentation on high-resolution images\u201d. In: Proceedings of the European conference on computer vision (ECCV) . 405\u2013420. Zhao, H., J. Shi, X. Qi, X. Wang, and J. Jia. (2017). \u201cPyramid scene parsing network\u201d. In: Proceedings of the IEEE conference on computer vision and pattern recognition. 2881\u20132890. Zhao, H., Y. Zhang, S. Liu, J. Shi, C. C. Loy, D. Lin, and J. Jia."
      },
      "Semantic scene segmentation for robotics": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2401.07589",
        "ref_texts": "[65] H. Zhao, J. Shi, X. Qi, X. Wang, J. Jia, Pyramid scene parsing network, in: Proceedings of the IEEE conference on computer vision and pattern recognition, 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "65"
        ]
      },
      "ATLANTIS: A benchmark for semantic segmentation of waterbody images": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2111.11567",
        "ref_texts": "[50] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In IEEE Conf. Comput. Vis. Pattern Recog. , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "50"
        ]
      },
      "On efficient real-time semantic segmentation: a survey": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2206.08605",
        "ref_texts": "[60] H. Zhao, J. Shi, X. Qi, X. Wang and J. Jia, \"Pyramid scene parsing network,\" in Proceedings of the IEEE conference on computer vision and pattern recognition , 2017. ",
        "ref_ids": [
          "60"
        ]
      },
      "Cross-domain few-shot semantic segmentation": {
        "authors": [
          "Shai Avidan"
        ],
        "url": "https://people.cs.vt.edu/~ctlu/Publication/2022/ECCV22-Shuo.pdf",
        "ref_texts": "52. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2881\u20132890 (2017)",
        "ref_ids": [
          "52"
        ]
      },
      "Prior attention network for multi-lesion segmentation in medical images": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2110.04735",
        "ref_texts": "[5]H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition , pp. 2881\u20132890, 2017.",
        "ref_ids": [
          "5"
        ]
      },
      "Quaternion-valued correlation learning for few-shot semantic segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2305.07283",
        "ref_texts": "[2] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proc. IEEE Conf. Comput. Vis. Pattern Recognit. , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "2"
        ]
      },
      "Adversarial patch attacks and defences in vision-based tasks: A survey": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2206.08304",
        "ref_texts": "[109] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in CVPR , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "109"
        ]
      },
      "Rbc: Rectifying the biased context in continual semantic segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2203.08404",
        "ref_texts": "[49] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017. 3",
        "ref_ids": [
          "49"
        ]
      },
      "Prompt-matched semantic segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2208.10159",
        "ref_texts": "[56] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In IEEE conference on computer vision and pattern recognition, pages 2881\u20132890, 2017. 2, 5",
        "ref_ids": [
          "56"
        ]
      },
      "PP-matting: high-accuracy natural image matting": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2204.09433",
        "ref_texts": "[43] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017. 3",
        "ref_ids": [
          "43"
        ]
      },
      "Undoing the damage of label shift for cross-domain semantic segmentation": {
        "authors": [
          "Yahao Liu",
          "Jinhong Deng",
          "Jiale Tao",
          "Tong Chu",
          "Lixin Duan",
          "Wen Li"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Undoing_the_Damage_of_Label_Shift_for_Cross-Domain_Semantic_Segmentation_CVPR_2022_paper.pdf",
        "ref_texts": "[50] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , July 2017. 2",
        "ref_ids": [
          "50"
        ]
      },
      "Self-training for class-incremental semantic segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2012.03362",
        "ref_texts": "[19] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , 2017, pp. 2881\u20132890.[20] J. He, Z. Deng, L. Zhou, Y . Wang, and Y . Qiao, \u201cAdaptive pyramid context network for semantic segmentation,\u201d in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , 2019, pp. 7519\u20137528.",
        "ref_ids": [
          "19",
          "20"
        ]
      },
      "Deep learning applications for acute stroke management": {
        "authors": [],
        "url": "https://www.nmr.mgh.harvard.edu/lfi/pdf/Chavva-Annals%20of%20Neurology-2022.pdf",
        "ref_texts": "34. Zhao, H., J. Shi, X. Qi, X. Wang and J. Jia Pyramid scene parsing network. in Proceedings of the IEEE conference on computer vision and pattern recognition . 2017.",
        "ref_ids": [
          "34"
        ]
      },
      "UrbanWatch: A 1-meter resolution land cover and land use database for 22 major cities in the United States": {
        "authors": [
          "Yindan Zhang"
        ],
        "url": "https://pages.charlotte.edu/gang-chen/wp-content/uploads/sites/184/2022/06/Zhang-et-al-2022-RSE-UrbanWatch_s.pdf",
        "ref_texts": "2020. Deep learning in environmental remote sensing: achievements and challenges. Remote Sens. Environ. 241, 111716. Zhang, K., Batterman, S., 2013. Air pollution and health risks due to vehicle traffic. Sci. Total Environ. 450, 307\u2013316. Zhang, X., Li, H., 2018. Urban resilience and urban sustainability: what we know and what do not know? Cities 72, 141\u2013148. Zhang, P., Gong, M., Su, L., Liu, J., Li, Z., 2016. Change detection based on deep feature representation and mapping transformation for multi-spatial-resolution remote sensing images. ISPRS J. Photogramm. Remote Sens. 116, 24\u201341. Zhang, D., Liu, J., Zhu, H., Liu, Y., Wang, L., Wang, P., Xiong, H., 2019. Job2Vec: Job title benchmarking with collective multi-view representation learning. In: Proceedings of the 28th ACM International Conference on Information and Knowledge Management, pp. 2763\u20132771. Zhang, Y., Chen, G., Vukomanovic, J., Singh, K.K., Liu, Y., Holden, S., Meentemeyer, R. K., 2020. Recurrent shadow attention model (RSAM) for shadow removal in highresolution urban land-cover mapping. Remote Sens. Environ. 247, 111945. Zhao, W., Du, S., 2016. Spectral\u2013spatial feature extraction for hyperspectral image classification: a dimension reduction and deep learning approach. IEEE Trans. Geosci. Remote Sens. 54 (8), 4544\u20134554. Zhao, W., Guo, Z., Yue, J., Zhang, X., Luo, L., 2015. On combining multiscale deep learning features for the classification of hyperspectral remote sensing imagery. Int. J. Remote Sens. 36 (13), 3368\u20133379. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J., 2017. Pyramid scene parsing network. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2881\u20132890. Zhao, W., Bo, Y., Chen, J., Tiede, D., Blaschke, T., Emery, W.J., 2019. Exploring semantic elements for urban scene recognition: deep integration of high-resolution imagery and OpenStreetMap (OSM). ISPRS J. Photogramm. Remote Sens. 151, 237\u2013250. Zhu, X., 2005. Semi-Supervised Learning with Graphs. Ph.D. Thesis. Department of Psychology, Carnegie Mellon Univ., Pittsburgh, PA. Y. Zhang et al. ",
        "ref_ids": [
          "2020"
        ]
      },
      "Large-field contextual feature learning for glass detection": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2209.04639",
        "ref_texts": "[13] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in CVPR , 2017.",
        "ref_ids": [
          "13"
        ]
      },
      "Domain adaptive semantic segmentation via regional contrastive consistency regularization": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2110.05170",
        "ref_texts": ""
      },
      "Siamdoge: Domain generalizable semantic segmentation using siamese network": {
        "authors": [],
        "url": "https://par.nsf.gov/servlets/purl/10496275",
        "ref_texts": "65. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: CVPR. pp. 2881\u20132890 (2017) 1,8",
        "ref_ids": [
          "65"
        ]
      },
      "High-quality entity segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2211.05776",
        "ref_texts": "[61] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017. 3",
        "ref_ids": [
          "61"
        ]
      },
      "DuARE: Automatic road extraction with aerial images and trajectory data at Baidu maps": {
        "authors": [
          "Jianzhong Yang"
        ],
        "url": "https://scholar.archive.org/work/f32uluaufvfzhlaf2gacabow5m/access/wayback/https://dl.acm.org/doi/pdf/10.1145/3534678.3539029",
        "ref_texts": "[42] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. 2017. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition. 2881\u20132890.",
        "ref_ids": [
          "42"
        ]
      },
      "Panopticdepth: A unified framework for depth-aware panoptic segmentation": {
        "authors": [
          "Naiyu Gao",
          "Fei He",
          "Jian Jia",
          "Yanhu Shan",
          "Haoyang Zhang",
          "Xin Zhao",
          "Kaiqi Huang"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2022/papers/Gao_PanopticDepth_A_Unified_Framework_for_Depth-Aware_Panoptic_Segmentation_CVPR_2022_paper.pdf",
        "ref_texts": "[23] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017.",
        "ref_ids": [
          "23"
        ]
      },
      "Sparse and complete latent organization for geospatial semantic segmentation": {
        "authors": [
          "Fengyu Yang",
          "Chenyang Ma"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_Sparse_and_Complete_Latent_Organization_for_Geospatial_Semantic_Segmentation_CVPR_2022_paper.pdf",
        "ref_texts": "[56] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. InCVPR , 2017. 1,2,6",
        "ref_ids": [
          "56"
        ]
      },
      "Masked distillation with receptive tokens": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2205.14589",
        "ref_texts": "11 Published as a conference paper at ICLR 2023 Chuanguang Yang, Helong Zhou, Zhulin An, Xue Jiang, Yongjun Xu, and Qian Zhang. Cross-image relational knowledge distillation for semantic segmentation. arXiv preprint arXiv:2204.06986 , 2022. Ze Yang, Shaohui Liu, Han Hu, Liwei Wang, and Stephen Lin. Reppoints: Point set representation for object detection. In Proceedings of the IEEE/CVF International Conference on Computer Vision , pp. 9657\u20139666, 2019. Zhendong Yang, Zhe Li, Xiaohu Jiang, Yuan Gong, Zehuan Yuan, Danpei Zhao, and Chun Yuan. Focal and global knowledge distillation for detectors. arXiv preprint arXiv:2111.11837 , 2021. Shan You, Chang Xu, Chao Xu, and Dacheng Tao. Learning from multiple teacher networks. In Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining , pp. 1285\u20131294, 2017. Shan You, Tao Huang, Mingmin Yang, Fei Wang, Chen Qian, and Changshui Zhang. Greedynas: Towards fast one-shot nas with greedy supernet. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pp. 1999\u20132008, 2020. Linfeng Zhang and Kaisheng Ma. Improve object detection with feature-based knowledge distillation: Towards accurate and efficient detectors. In International Conference on Learning Representations , 2020. Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pp."
      },
      "Deep multi-branch aggregation network for real-time semantic segmentation in street scenes": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2203.04037",
        "ref_texts": "[7] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR) , Jul. 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "7"
        ]
      },
      "Global-reasoned multi-task learning model for surgical scene understanding": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2201.11957",
        "ref_texts": "[3] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d arXiv preprint arXiv:1612.01105 , 2016.",
        "ref_ids": [
          "3"
        ]
      },
      "Latent discriminant deterministic uncertainty": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2207.10130",
        "ref_texts": "85. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: CVPR (2017) 13 Latent Discriminant deterministic Uncertainty Supplementary Material Gianni Franchi1\u2020, Xuanlong Yu1,2\u2020, Andrei Bursuc3, Emanuel Aldea2, Severine Dubuisson4, and David Filliat1",
        "ref_ids": [
          "85"
        ]
      },
      "Delving into high-quality synthetic face occlusion segmentation datasets": {
        "authors": [
          "Kenny T. R",
          "Liming Jiang",
          "Chen Change"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2022W/VDU/papers/Voo_Delving_Into_High-Quality_Synthetic_Face_Occlusion_Segmentation_Datasets_CVPRW_2022_paper.pdf",
        "ref_texts": "[39] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , 2017. 2, 6, 7, 8",
        "ref_ids": [
          "39"
        ]
      },
      "Image super-resolution with deep dictionary": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2207.09228",
        "ref_texts": "58. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: CVPR (2017)",
        "ref_ids": [
          "58"
        ]
      },
      "Efficient multi-task rgb-d scene analysis for indoor environments": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2207.04526",
        "ref_texts": "[5] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proc. of CVPR , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "5"
        ]
      },
      "DooDLeNet: Double DeepLab enhanced feature fusion for thermal-color semantic segmentation": {
        "authors": [
          "Oriel Frigo",
          "Lucien Martin",
          "Catherine Wacongne"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2022W/V4AS/papers/Frigo_DooDLeNet_Double_DeepLab_Enhanced_Feature_Fusion_for_Thermal-Color_Semantic_Segmentation_CVPRW_2022_paper.pdf",
        "ref_texts": "[9] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 2881\u20132890, 2017. 2",
        "ref_ids": [
          "9"
        ]
      },
      "Deep learning in agriculture: a review": {
        "authors": [],
        "url": "http://ebooks.pubstmlibrary.com/id/eprint/784/1/30311-Article%20Text-56769-1-10-20220315.pdf",
        "ref_texts": " Abbreviation Models/Algorithms CNN Convolution Neural Network RNN Recurrent Neural Network GAN Generative Adversarial Network LSTM Long Short -Term Memory Network DBN Deep Belief Network DCNN Deep Convolution Neural Networks MCNN Multilayer Convolution Neural Network DNN Deep Neural Network ResNet Residual Network R-FCN Region -based Fully Convolutional Network R-CNN Region Based Convolutional Neural Network DRL Deep Reinforcement Learning DenseNet Densely Connected Convolutional Networks PSPNet Pyramid Scene Parsing Network IRRCNN Inception Recurrent Residual Convolutional Neural Network IRCNN Inception Recurrent Convolutional Neural Network DCRN Densely Connected Recurrent Convolutional Network R2U-Net Recurrent Residual Convolutional Neural Network based on U -Net model NLP Natural Language Processing DRQN Deep Recurrent Q -Network BPNN Back -propagation Neural Network IndRNN Independently Recurrent Neural Network DNN_JOA Deep Neural Network with Jaya Algorithm ConvXGB Convolutional eXtreme Gradient Boosting SDG Stochastic Gradient Descent MLNN Multilayer Neural Network "
      },
      "The detection method of potato foliage diseases in complex background based on instance segmentation and semantic segmentation": {
        "authors": [
          "Xiaofei Fan"
        ],
        "url": "https://www.frontiersin.org/journals/plant-science/articles/10.3389/fpls.2022.899754/pdf",
        "ref_texts": "10865 Zhao, H., Shi, J., Qi, X., Wang, X., and Jia, J. (2016). Pyramid scene parsing network. IEEE Comput. Soc. doi: 10.1109/CVPR.20"
      },
      "Progressive multiscale consistent network for multiclass fundus lesion segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2205.15720",
        "ref_texts": "[47] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "47"
        ]
      },
      "FCP-Net: A feature-compression-pyramid network guided by game-theoretic interactions for medical image segmentation": {
        "authors": [],
        "url": "https://nrl.northumbria.ac.uk/id/eprint/48067/8/IEEE%20Biomedical%20Imaging%20Clean%20Copy%20new.pdf",
        "ref_texts": "[26] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \"Pyramid scene parsing network,\" in Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR) , ",
        "ref_ids": [
          "26"
        ]
      },
      "Multi-exit semantic segmentation networks": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2106.03527",
        "ref_texts": "75. Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid Scene Parsing Network. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "75"
        ]
      },
      "TransCL: Transformer makes strong and flexible compressive learning": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2207.11972",
        "ref_texts": "[75] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "75"
        ]
      },
      "Drive&segment: Unsupervised semantic segmentation of urban scenes via cross-modal distillation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2203.11160",
        "ref_texts": "59. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: CVPR (2017)",
        "ref_ids": [
          "59"
        ]
      },
      "MCIBI++: Soft mining contextual information beyond image for semantic segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2209.04471",
        "ref_texts": "[4] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "4"
        ]
      },
      "A multi-modality ovarian tumor ultrasound image dataset for unsupervised cross-domain semantic segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2207.06799",
        "ref_texts": "4471\u20134480. Zeng, G., Lerch, T.D., Schmaranzer, F., et al., 2021. Semantic consistent unsupervised domain adaptation for cross-modality medical image segmentation, in: Medical Image Computing and Computer Assisted Intervention, pp. 201\u2013210. Zeng, G., Schmaranzer, F., Lerch, T.D., et al., 2020. Entropy guided unsupervised domain adaptation for cross-center hip cartilage segmentationfromMRI,in:MedicalImageComputingandComputerAssisted Intervention, pp. 447\u2013456. Zhan, B., Song, E., et al., 2023. Segmenting medical images via explicit\u2013implicit attention aggregation. Knowledge-Based Systems 279, 110932. Zhang, Y., Chen, H., Wei, Y., et al., 2019. From whole slide imaging to microscopy: Deep microscopy adaptation network for histopathology cancer image classification, in: Medical Image Computing and Computer Assisted Intervention, pp. 360\u2013368. Zhang, Y., Liu, H., Hu, Q., 2021. Transfuse: Fusing transformers and cnnsformedicalimagesegmentation,in:MedicalImageComputingand Computer Assisted Intervention, pp. 14\u201324. Zhao, H., Shi, J., Qi, X., et al., 2017. Pyramid scene parsing network, in: IEEE Conference on Computer Vision and Pattern Recognition, pp."
      },
      "Deep learning approach based on superpixel segmentation assisted labeling for automatic pressure ulcer diagnosis": {
        "authors": [
          "Che Wei",
          "Mesakh Christian",
          "Dun Hao",
          "Feipei Lai",
          "Tom J. Liu",
          "Yo Shen",
          "Wei Jen"
        ],
        "url": "https://journals.plos.org/plosone/article/file?id=10.1371/journal.pone.0264139&type=printable",
        "ref_texts": "32. Zhao H,ShiJ,QiX,Wang X,JiaJ,editors. Pyramid scene parsing network. Proceedings oftheIEEE conferen ceoncomputer vision andpattern recognition; 2017.",
        "ref_ids": [
          "32"
        ]
      },
      "A lightweight network for accurate coronary artery segmentation using x-ray angiograms": {
        "authors": [
          "Xiaoguang Zhou",
          "Xiangdong Xu",
          "Danqun Xiong"
        ],
        "url": "https://www.frontiersin.org/articles/10.3389/fpubh.2022.892418/pdf",
        "ref_texts": "60. Zhao H, Shi J, Qi X, Wang X, Jia J. Pyramid Scene Parsing Network. CVPR. (2017). p. 6230\u20139. doi: 10.1109/CVPR.2017.",
        "ref_ids": [
          "60"
        ]
      },
      "U-hrnet: delving into improving semantic representation of high resolution network for dense prediction": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2210.07140",
        "ref_texts": "[83] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In IEEE Conference on Computer Vision and Pattern Recognition, July 2017. 3, 6, 7",
        "ref_ids": [
          "83"
        ]
      },
      "Cerberus transformer: Joint semantic, affordance and attribute parsing": {
        "authors": [
          "Xiaoxue Chen",
          "Tianyu Liu",
          "Hao Zhao",
          "Guyue Zhou",
          "Qin Zhang"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Cerberus_Transformer_Joint_Semantic_Affordance_and_Attribute_Parsing_CVPR_2022_paper.pdf"
      },
      "Efficient joint-dimensional search with solution space regularization for real-time semantic segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2208.05271",
        "ref_texts": "38. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 2881{",
        "ref_ids": [
          "38"
        ]
      },
      "Attention guided global enhancement and local refinement network for semantic segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2204.04363",
        "ref_texts": "[8] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "8"
        ]
      },
      "Autoloss-zero: Searching loss functions from scratch for generic tasks": {
        "authors": [
          "Hao Li",
          "Tianwen Fu",
          "Jifeng Dai",
          "Hongsheng Li",
          "Gao Huang",
          "Xizhou Zhu"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2022/papers/Li_AutoLoss-Zero_Searching_Loss_Functions_From_Scratch_for_Generic_Tasks_CVPR_2022_paper.pdf",
        "ref_texts": "[65] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017. 1,6,7",
        "ref_ids": [
          "65"
        ]
      },
      "Surgical tool datasets for machine learning research: a survey": {
        "authors": [
          "Mark Rodrigues"
        ],
        "url": "https://link.springer.com/content/pdf/10.1007/s11263-022-01640-6.pdf",
        "ref_texts": "10.1016/j.knosys.2021.106775 . Zhang, J., & Gao, X. (2020). Object extraction via deep learningbased marker-free tracking framework of surgical instrumentsfor laparoscope-holder robots. International Journal of Computer Assisted Radiology and Surgery, 15, 1335. Zhao, Z., Cai, T., Chang, F., & Cheng, X. (2019a). Real-time surgical instrument detection in robot-assisted surgery using a convolu-tional neural network cascade. Healthcare Technology Letters,6 , 6. Zhao, Z., Chen, Z., V oros, S., & Cheng, X. (2019b). Real-time tracking of surgical instruments based on spatio-temporal context and deeplearning. Computer Assisted Surgery,24 , 20\u201329. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J. (2016). Pyramid scene parsing network. In 2017 IEEE conference on computer vision and pattern recognition (CVPR) (pp. 6230\u20136239). https://doi.org/10."
      },
      "Modified UNet Model for Brain Stroke Lesion Segmentation on Computed Tomography Images.": {
        "authors": [
          "Azhar Tursynova"
        ],
        "url": "https://cdn.techscience.cn/ueditor/files/cmc/TSP_CMC-71-3/TSP_CMC_20998/TSP_CMC_20998.pdf",
        "ref_texts": "[45] H. Zhao, J. Shi, X. Qi, X. Wang and J. Jia, \u201cPyramid scene parsing network,\u201d in Proc. of theIEEE ConferenceonComputerVisionandPatternRecognition , Honolulu, HI, USA, pp. 2881\u20132890, 2017.",
        "ref_ids": [
          "45"
        ]
      },
      "Graph reasoning transformer for image parsing": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2209.09545",
        "ref_texts": "[89] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2017.",
        "ref_ids": [
          "89"
        ]
      },
      "Self-supervised point cloud representation learning via separating mixed shapes": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2109.00452",
        "ref_texts": "[16] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in CVPR , 2017.",
        "ref_ids": [
          "16"
        ]
      },
      "Pooling revisited: Your receptive field is suboptimal": {
        "authors": [
          "Hwan Jang",
          "Sanghyeok Chu",
          "Joonhyuk Kim",
          "Bohyung Han"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2022/papers/Jang_Pooling_Revisited_Your_Receptive_Field_Is_Suboptimal_CVPR_2022_paper.pdf",
        "ref_texts": "[45] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. InCVPR , 2017. 8",
        "ref_ids": [
          "45"
        ]
      },
      "Bridging multi-scale context-aware representation for object detection": {
        "authors": [
          "Boying Wang",
          "Ruyi Ji",
          "Libo Zhang",
          "Yanjun Wu"
        ],
        "url": "https://isrc.iscas.ac.cn/zhanglibo/pdfs/2022/IEEE_Transactions_on_Circuits_and_Systems_for_Video_Technology_2022.pdf",
        "ref_texts": "[70] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR) , Jul. 2017, pp. 6230\u20136239.",
        "ref_ids": [
          "70"
        ]
      },
      "Wireless transmission of images with the assistance of multi-level semantic information": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2202.04754",
        "ref_texts": "[22] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition , pp. 2881\u20132890, 2017.",
        "ref_ids": [
          "22"
        ]
      },
      "Real-time semantic segmentation with parallel multiple views feature augmentation": {
        "authors": [
          "Jun Qiao"
        ],
        "url": "https://openreview.net/pdf?id=nnJk8QsD0x"
      },
      "One-trimap video matting": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2207.13353",
        "ref_texts": "66.Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: CVPR. pp. 2881\u20132890 (2017) 19",
        "ref_ids": [
          "66"
        ]
      },
      "Self-supervised geometric correspondence for category-level 6d object pose estimation in the wild": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2210.07199"
      },
      "Semi-supervised learning for weed and crop segmentation using UAV imagery": {
        "authors": [],
        "url": "https://www.frontiersin.org/journals/plant-science/articles/10.3389/fpls.2022.927368/pdf",
        "ref_texts": "1, 2016; 761\u2013769. Y ang, L., Zhuo, W ., Qi, L., Shi, Y., and Gao, Y. (2021). ST++: make self-training work better for semi-supervised semantic segmentation. arXiv [Preprint arXiv:2106.05095]. Y ou, J., Liu, W ., and Lee, J. (2020). A DNN based semantic segmentation for detecting weed and crop. Comput. Electron. Agric. 178:105750. doi: 10.1016/j. compag.2020.105750 Zhao, H., Shi, J., Qi, X., Wang, X., and Jia, J., (2017). Pyramid scene parsing network, in Proceedings of the IEEE Conference on Computer Visuion Pattern Recognition . July 22-July 25, 2017; 2881\u20132890. Zhu, J. Y ., Park, T., Isola, P ., and Efros, A. A. (2017). \u201cUnpaired image-toimage translation using cycle-consistent adversarial networks. \u201d in Proceedings of the IEEE International Conference on Computer Vision . October 22-29, "
      },
      "Continual semantic segmentation via structure preserving and projected feature alignment": {
        "authors": [],
        "url": "https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136890341.pdf",
        "ref_texts": "47. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: CVPR (2017)",
        "ref_ids": [
          "47"
        ]
      },
      "Semaffinet: Semantic-affine transformation for point cloud segmentation": {
        "authors": [
          "Ziyi Wang",
          "Yongming Rao",
          "Xumin Yu",
          "Jie Zhou",
          "Jiwen Lu"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2022/papers/Wang_SemAffiNet_Semantic-Affine_Transformation_for_Point_Cloud_Segmentation_CVPR_2022_paper.pdf",
        "ref_texts": "[69] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , pages 2881\u20132890, 2017. 1",
        "ref_ids": [
          "69"
        ]
      },
      "Semantic segmentation guided real-world super-resolution": {
        "authors": [
          "Andreas Aakerberg",
          "Anders S. Johansen",
          "Kamal Nasrollahi",
          "Thomas B. Moeslund"
        ],
        "url": "https://openaccess.thecvf.com/content/WACV2022W/RWS/papers/Aakerberg_Semantic_Segmentation_Guided_Real-World_Super-Resolution_WACVW_2022_paper.pdf",
        "ref_texts": "[38] Hengshuang Z., Jianping S., Xiaojuan Q., Xiaogang W., and Jiaya J. Pyramid scene parsing network. In CVPR , 2017.",
        "ref_ids": [
          "38"
        ]
      },
      "A2SPPNet: Attentive atrous spatial pyramid pooling network for salient object detection": {
        "authors": [],
        "url": "https://yun-liu.github.io/papers/(TMM'2022)A2SPPNet%20-%20Attentive%20Atrous%20Spatial%20Pyramid%20Pooling%20Network%20for%20Salient%20Object%20Detection.pdf",
        "ref_texts": "[33] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in IEEE Conf. Comput. Vis. Pattern Recog. (CVPR) , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "33"
        ]
      },
      "A lightweight multi-scale context network for salient object detection in optical remote sensing images": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2205.08959",
        "ref_texts": "[23] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "23"
        ]
      },
      "Bidirectional self-training with multiple anisotropic prototypes for domain adaptive semantic segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2204.07730",
        "ref_texts": "[1]Vijay Badrinarayanan, Alex Kendall, and Roberto Cipolla. 2017. Segnet: A deepconvolutional encoder-decoder architecture for image segmentation.IEEE trans-actions on pattern analysis and machine intelligence39, 12 (2017), 2481\u20132495.[2]L\u00e9on Bottou. 2010. Large-scale machine learning with stochastic gradient descent.InProceedings of COMPSTAT\u20192010. Springer, 177\u2013186.[3]Liang-Chieh Chen, George Papandreou, Iasonas Kokkinos, Kevin Murphy, andAlan L Yuille. 2017. Deeplab: Semantic image segmentation with deep convolu-tional nets, atrous convolution, and fully connected crfs.IEEE transactions onpattern analysis and machine intelligence40, 4 (2017), 834\u2013848.[4]Liang-Chieh Chen, George Papandreou, Florian Schro\uffff, and Hartwig Adam. 2017.Rethinking atrous convolution for semantic image segmentation.arXiv preprintarXiv:1706.05587(2017).[5]Liang-Chieh Chen, Yukun Zhu, George Papandreou, Florian Schro\uffff, and HartwigAdam. 2018. Encoder-decoder with atrous separable convolution for semanticimage segmentation. InProceedings of the European conference on computer vision(ECCV). 801\u2013818.[6]Ting Chen, Simon Kornblith, Kevin Swersky, Mohammad Norouzi, and Geo\uffffrey EHinton. 2020. Big self-supervised models are strong semi-supervised learners.Advances in neural information processing systems33 (2020), 22243\u201322255.[7]Ekin D Cubuk, Barret Zoph, Jonathon Shlens, and Quoc V Le. 2020. Randaugment:Practical automated data augmentation with a reduced search space. InProceed-ings of the IEEE/CVF Conference on Computer Vision and Pattern RecognitionWorkshops. 702\u2013703.[8]Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei. 2009. Imagenet:A large-scale hierarchical image database. In2009 IEEE conference on computervision and pattern recognition. Ieee, 248\u2013255.[9]Terrance DeVries and Graham W Taylor. 2017. Improved regularization ofconvolutional neural networks with cutout.arXiv preprint arXiv:1708.04552(2017).[10]Richard O Duda, Peter E Hart, et al.1973.Pattern classi\uffffcation and scene analysis.Vol. 3. Wiley New York.[11]Yaroslav Ganin, Evgeniya Ustinova, Hana Ajakan, Pascal Germain, HugoLarochelle, Fran\u00e7ois Laviolette, Mario Marchand, and Victor Lempitsky. 2016.Domain-adversarial training of neural networks.The journal of machine learningresearch17, 1 (2016), 2096\u20132030.[12]Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. 2016. Deep residuallearning for image recognition. InProceedings of the IEEE conference on computervision and pattern recognition. 770\u2013778.[13]Judy Ho\uffffman, Eric Tzeng, Taesung Park, Jun-Yan Zhu, Phillip Isola, Kate Saenko,Alexei Efros, and Trevor Darrell. 2018. Cycada: Cycle-consistent adversarialdomain adaptation. InInternational conference on machine learning. PMLR, 1989\u20131998.[14]Jiaxing Huang, Dayan Guan, Aoran Xiao, and Shijian Lu. 2021. Fsdr: Frequencyspace domain randomization for domain generalization. InProceedings of theIEEE/CVF Conference on Computer Vision and Pattern Recognition. 6891\u20136902.[15]Guoliang Kang, Lu Jiang, Yi Yang, and Alexander G Hauptmann. 2019. Contrastiveadaptation network for unsupervised domain adaptation. InProceedings of theIEEE/CVF Conference on Computer Vision and Pattern Recognition. 4893\u20134902.[16]Taeksoo Kim, Moonsu Cha, Hyunsoo Kim, Jung Kwon Lee, and Jiwon Kim. 2017.Learning to discover cross-domain relations with generative adversarial networks.InInternational conference on machine learning. PMLR, 1857\u20131865.[17]Yunsheng Li, Lu Yuan, and Nuno Vasconcelos. 2019. Bidirectional learning fordomain adaptation of semantic segmentation. InProceedings of the IEEE/CVFConference on Computer Vision and Pattern Recognition. 6936\u20136945.[18]Jonathan Long, Evan Shelhamer, and Trevor Darrell. 2015. Fully convolutionalnetworks for semantic segmentation. InProceedings of the IEEE conference oncomputer vision and pattern recognition. 3431\u20133440.[19]Mingsheng Long, Zhangjie Cao, Jianmin Wang, and Michael I Jordan. 2018.Conditional adversarial domain adaptation.Advances in neural informationprocessing systems31 (2018).[20]Yawei Luo, Ping Liu, Tao Guan, Junqing Yu, and Yi Yang. 2019. Signi\uffffcance-aware information bottleneck for domain adaptive semantic segmentation. InProceedings of the IEEE/CVF International Conference on Computer Vision. 6778\u20136787.[21]Yawei Luo, Ping Liu, Tao Guan, Junqing Yu, and Yi Yang. 2020. Adversarialstyle mining for one-shot unsupervised domain adaptation.Advances in NeuralInformation Processing Systems33 (2020), 20612\u201320623.[22]Yawei Luo, Ping Liu, Liang Zheng, Tao Guan, Junqing Yu, and Yi Yang. 2021.Category-level adversarial adaptation for semantic segmentation using puri\uffffedfeatures.IEEE Transactions on Pattern Analysis and Machine Intelligence(2021).[23]Yawei Luo, Liang Zheng, Tao Guan, Junqing Yu, and Yi Yang. 2019. Taking acloser look at domain shift: Category-level adversaries for semantics consistentdomain adaptation. InProceedings of the IEEE/CVF Conference on Computer Visionand Pattern Recognition. 2507\u20132516.[24]Haoyu Ma, Xiangru Lin, Zifeng Wu, and Yizhou Yu. 2021. Coarse-to-Fine DomainAdaptive Semantic Segmentation with Photometric Alignment and Category-Center Regularization. InProceedings of the IEEE/CVF Conference on ComputerVision and Pattern Recognition. 4051\u20134060.[25]Ke Mei, Chuang Zhu, Jiaqi Zou, and Shanghang Zhang. 2020. Instance adaptiveself-training for unsupervised domain adaptation. InComputer Vision\u2013ECCV2020: 16th European Conference, Glasgow, UK, August 23\u201328, 2020, Proceedings,Part XXVI 16. Springer, 415\u2013430.[26]Fei Pan, Inkyu Shin, Francois Rameau, Seokju Lee, and In So Kweon. 2020. Un-supervised intra-domain adaptation for semantic segmentation through self-supervision. InProceedings of the IEEE/CVF Conference on Computer Vision andPattern Recognition. 3764\u20133773.[27]Douglas A Reynolds and Richard C Rose. 1995. Robust text-independent speakeridenti\uffffcation using Gaussian mixture speaker models.IEEE transactions on speechand audio processing3, 1 (1995), 72\u201383.[28]Stephan R Richter, Vibhav Vineet, Stefan Roth, and Vladlen Koltun. 2016. Playingfor data: Ground truth from computer games. InEuropean conference on computervision. Springer, 102\u2013118.[29]German Ros, Laura Sellart, Joanna Materzynska, David Vazquez, and Antonio MLopez. 2016. The synthia dataset: A large collection of synthetic images forsemantic segmentation of urban scenes. InProceedings of the IEEE conference oncomputer vision and pattern recognition. 3234\u20133243.[30]Kuniaki Saito, Kohei Watanabe, Yoshitaka Ushiku, and Tatsuya Harada. 2018.Maximum classi\uffffer discrepancy for unsupervised domain adaptation. InProceed-ings of the IEEE conference on computer vision and pattern recognition. 3723\u20133732.[31]Hidetoshi Shimodaira. 2000. Improving predictive inference under covariateshift by weighting the log-likelihood function.Journal of statistical planning andinference90, 2 (2000), 227\u2013244.[32]Antti Tarvainen and Harri Valpola. 2017. Mean teachers are better role models:Weight-averaged consistency targets improve semi-supervised deep learningresults.Advances in neural information processing systems30 (2017).[33]Yi-Hsuan Tsai, Wei-Chih Hung, Samuel Schulter, Kihyuk Sohn, Ming-Hsuan Yang,and Manmohan Chandraker. 2018. Learning to adapt structured output space forsemantic segmentation. InProceedings of the IEEE conference on computer visionand pattern recognition. 7472\u20137481.[34]Tuan-Hung Vu, Himalaya Jain, Maxime Bucher, Matthieu Cord, and PatrickP\u00e9rez. 2019. Advent: Adversarial entropy minimization for domain adaptation insemantic segmentation. InProceedings of the IEEE/CVF Conference on ComputerVision and Pattern Recognition. 2517\u20132526.[35]Yisen Wang, Xingjun Ma, Zaiyi Chen, Yuan Luo, Jinfeng Yi, and James Bailey. 2019.Symmetric cross entropy for robust learning with noisy labels. InProceedings ofthe IEEE/CVF International Conference on Computer Vision. 322\u2013330.[36]Yuxi Wang, Junran Peng, and ZhaoXiang Zhang. 2021. Uncertainty-aware pseudolabel re\uffffnery for domain adaptive semantic segmentation. InProceedings of theIEEE/CVF International Conference on Computer Vision. 9092\u20139101.[37]Boyu Yang, Chang Liu, Bohao Li, Jianbin Jiao, and Qixiang Ye. 2020. Prototypemixture models for few-shot semantic segmentation. InEuropean Conference onComputer Vision. Springer, 763\u2013778.[38]Yanchao Yang and Stefano Soatto. 2020. Fda: Fourier domain adaptation forsemantic segmentation. InProceedings of the IEEE/CVF Conference on ComputerVision and Pattern Recognition. 4085\u20134095.[39]Kai Zhang, Yifan Sun, Rui Wang, Haichang Li, and Xiaohui Hu. 2021. Multiple Fu-sion Adaptation: A Strong Framework for Unsupervised Semantic SegmentationAdaptation.arXiv preprint arXiv:2112.00295(2021).[40]Pan Zhang, Bo Zhang, Ting Zhang, Dong Chen, Yong Wang, and Fang Wen. 2021.Prototypical pseudo label denoising and target structure learning for domainadaptive semantic segmentation. InProceedings of the IEEE/CVF Conference onComputer Vision and Pattern Recognition. 12414\u201312424.[41]Qiming Zhang, Jing Zhang, Wei Liu, and Dacheng Tao. 2019. Category anchor-guided unsupervised domain adaptation for semantic segmentation.arXivpreprint arXiv:1910.13049(2019).[42]Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia.2017. Pyramid Scene Parsing Network. InProceedings of the IEEE Conference onComputer Vision and Pattern Recognition (CVPR).[43]Zhun Zhong, Liang Zheng, Zhiming Luo, Shaozi Li, and Yi Yang. 2019. Invariancematters: Exemplar memory for domain adaptive person re-identi\uffffcation. InProceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition.598\u2013607.[44]Bo Zong, Qi Song, Martin Renqiang Min, Wei Cheng, Cristian Lumezanu, DaekiCho, and Haifeng Chen. 2018. Deep autoencoding gaussian mixture model forunsupervised anomaly detection. InInternational conference on learning represen-tations.[45]Yang Zou, Zhiding Yu, BVK Kumar, and Jinsong Wang. 2018. Unsuperviseddomain adaptation for semantic segmentation via class-balanced self-training. InProceedings of the European conference on computer vision (ECCV). 289\u2013305. MM \u201922, October 10\u201314, 2022, Lisboa, PortugalYulei Lu, et al.Appendix. A PARAMETER ANALYSIS OF KTo analyze the e\uffffectiveness of multiple prototypes, we use GMMs with di\ufffferent (the number of clusters) to generate pseudo-labels duringtraining, and the results are shown in Tab.6. We \uffffnd that as increases, the performance of self-training gradually improves. When isincreased to6, the mIoU achieves57.3%. Further increasing the number of can no longer improve performance. In conclusion, a larger value can usually stimulates a stronger GMM\u2019s ability to \ufffft thede factodistribution, yet =8is enough to match the distribution in thistask. Accordingly, we choose the value of =8in the experiment. These experimental results do not contain consistency regularization inorder to pinpoint the pure e\uffffect of .Table 6: The detailed results of self-training under di\ufffferent parameter on GTA->Cityscapes.Kroadside.buil.wallfencepolelightsignvege.terr.skypers.ridercartruckbustrainmotorbikemIoU187.9 51.1 83.4 38.9 34.6 40.1 48.2 46.6 86.8 35.9 85.4 66.2 36.5 89.4 41.3 54.2 43.1 39.0 57.4 56.1282.3 42.8 82.3 39.9 39.3 38.9 49.5 47.9 87.3 39.7 82.9 66.5 37.3 89.5 41.2 58.7 55.6 39.5 56.0 56.7486.8 51.2 82.0 43.0 38.0 42.4 48.8 50.3 86.4 38.0 86.4 64.0 36.0 88.5 42.7 53.1 53.9 32.7 55.0 56.8685.9 47.5 83.0 41.3 37.2 43.4 51.8 49.2 87.4 41.0 84.9 67.1 38.4 90.0 46.0 57.7 47.4 34.4 55.4 57.3888.4 47.9 85.3 38.1 36.0 41.8 49.7 47.2 86.2 38.6 79.2 67.7 38.9 89.5 49.7 62.5 47.4 37.9 57.6 57.3Appendix. B DETAILED ABLATION STUDYTable 7: The detailed IoU results of ablation study on GTA->Cityscapes.baselineSTMMAPs-PLAconsistencydistillationroadside.buil.wallfencepolelightsignvege.terr.skypers.ridercartruckbustrainmotorbikemIoUX76.8 34.6 68.2 22.7 21.4 40.1 44.1 26.5 85.4 29.4 74.6 67.4 27.6 87.9 37.7 47.5 34.3 29.2 24.7 46.3XX75.6 38.1 70.5 24.7 25.2 40.3 43.2 27.8 84.9 30.9 77.2 66.7 33.7 87.7 38.9 49.5 33.9 28.6 39.4 48.3XX87.1 47.1 84.0 38.0 39.0 41.5 49.4 48.2 86.7 39.0 79.2 67.7 37.2 88.7 43.8 59.9 42.1 36.2 57.2 56.4XXX88.4 47.9 85.3 38.1 36.0 41.8 49.7 47.2 86.2 38.6 79.2 67.7 38.9 89.5 49.7 62.5 47.4 37.9 57.6 57.3XXXX86.2 48.4 83.5 43.8 38.2 41.8 49.5 54.7 87.9 41.7 84.7 63.9 34.4 89.1 49.1 62.2 43.8 37.1 56.6 57.7XXXXX89.2 54.9 84.4 44.1 39.3 41.6 53.9 53.5 88.4 45.1 82.3 69.4 41.8 90.4 56.4 68.8 51.2 47.8 60.4 61.2Appendix. C T-SNE VISUALIZATION OF LATENT SPACE BEFORE SELF-TRAININGIn Fig.7, we show the 2D visualization results of features from \u201ctruck\u201d and \u201cbus\u201d. It can be seen that the features of semantic segmentationhave the characteristics of large variance and multi-class clusters in the latent space. Figure 7: 2D visualization of the truck and bus features based on T-SNE. Each category shows3clusters obtained by GMMclustering, which are represented by di\ufffferent colors. All the features are extracted from GTA dataset with the warmup model. Bidirectional Self-Training with Multiple Anisotropic Prototypes for Domain Adaptive Semantic Segmentation MM \u201922, October 10\u201314, 2022, Lisboa, PortugalAppendix. D MORE PSEUDO-LABEL COMPARISON AND QUALITATIVE RESULTS",
        "ref_ids": [
          "1",
          "2",
          "3",
          "4",
          "5",
          "6",
          "7",
          "8",
          "9",
          "10",
          "11",
          "12",
          "13",
          "14",
          "15",
          "16",
          "17",
          "18",
          "19",
          "20",
          "21",
          "22",
          "23",
          "24",
          "25",
          "26",
          "27",
          "28",
          "29",
          "30",
          "31",
          "32",
          "33",
          "34",
          "35",
          "36",
          "37",
          "38",
          "39",
          "40",
          "41",
          "42",
          "43",
          "44",
          "45"
        ]
      },
      "Mixed-UNet: Refined class activation mapping for weakly-supervised semantic segmentation with multi-scale inference": {
        "authors": [
          "Peiwu Qin"
        ],
        "url": "https://www.frontiersin.org/articles/10.3389/fcomp.2022.1036934/pdf",
        "ref_texts": ""
      },
      "Adversarial Vision Transformer for Medical Image Semantic Segmentation with Limited Annotations.": {
        "authors": [],
        "url": "https://bmvc2022.mpi-inf.mpg.de/1002.pdf",
        "ref_texts": "[53] Hengshuang Zhao et al. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "53"
        ]
      },
      "Ml-bpm: Multi-teacher learning with bidirectional photometric mixing for open compound domain adaptation in semantic segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2207.09045",
        "ref_texts": "35. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: CVPR. pp. 2881\u20132890 (2017)",
        "ref_ids": [
          "35"
        ]
      },
      "Cyclic differentiable architecture search": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2006.10724",
        "ref_texts": "[139] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in CVPR , 2017, pp. 2881\u20132890. 14",
        "ref_ids": [
          "139"
        ]
      },
      "Multi-granularity distillation scheme towards lightweight semi-supervised semantic segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2208.10169",
        "ref_texts": "61. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: CVPR (2017)",
        "ref_ids": [
          "61"
        ]
      },
      "Low-light image and video enhancement: A comprehensive survey and beyond": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2212.10772",
        "ref_texts": "[110] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "110"
        ]
      },
      "Pixel-by-pixel cross-domain alignment for few-shot semantic segmentation": {
        "authors": [
          "Antonio Tavera",
          "Fabio Cermelli",
          "Carlo Masone",
          "Barbara Caputo"
        ],
        "url": "https://openaccess.thecvf.com/content/WACV2022/papers/Tavera_Pixel-by-Pixel_Cross-Domain_Alignment_for_Few-Shot_Semantic_Segmentation_WACV_2022_paper.pdf",
        "ref_texts": "[55] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In IEEE Conf. Comput. Vis. Pattern Recog. , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "55"
        ]
      },
      "Recursivemix: Mixed learning with history": {
        "authors": [],
        "url": "https://proceedings.neurips.cc/paper_files/paper/2022/file/37e44c4b5321605735be9761f9b758fc-Paper-Conference.pdf",
        "ref_texts": "[72] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017. 1, 8",
        "ref_ids": [
          "72"
        ]
      },
      "Channel exchanging networks for multimodal and multitask dense image prediction": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2112.02252",
        "ref_texts": "[73] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in CVPR , 2017. 6",
        "ref_ids": [
          "73"
        ]
      },
      "Surrogate-assisted multiobjective neural architecture search for real-time semantic segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2208.06820",
        "ref_texts": "[63] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2017.",
        "ref_ids": [
          "63"
        ]
      },
      "RFMask: A simple baseline for human silhouette segmentation with radio signals": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2201.10175",
        "ref_texts": "[14] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "14"
        ]
      },
      "Knowledge distillation driven instance segmentation for grading prostate cancer": {
        "authors": [
          "Taimur Hassan"
        ],
        "url": "https://naoufelwerghi.com/wp-content/uploads/2023/12/2022_Hassan_Comput.-Biol.-Med.pdf",
        "ref_texts": "[63] H. Zhao, J. Shi, X. Qi, X. Wang, J. Jia, Pyramid scene parsing network, in: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "63"
        ]
      },
      "Multi-channel attention selection gans for guided image-to-image translation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2002.01048",
        "ref_texts": "[48] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in CVPR , 2017. 5 IEEE TRANSACTIONS ON PATTERN ANAL YSIS AND MACHINE INTELLIGENCE 16",
        "ref_ids": [
          "48"
        ]
      },
      "Multicenter study on COVID-19 lung computed tomography segmentation with varying glass ground opacities using unseen deep learning artificial intelligence \u2026": {
        "authors": [
          "Jasjit S. Suri"
        ],
        "url": "https://link.springer.com/content/pdf/10.1007/s10916-022-01850-y.pdf",
        "ref_texts": "2. Zhao, H.; Shi, J.; Qi, X.; W ang, X.; Jia, J. Pyramid scene parsing network. In Proceedings of the Proceedings of the IEEE conference on computer vision and pattern recognition, 2017; pp. 2881\u20132890.",
        "ref_ids": [
          "2"
        ]
      },
      "TW-Net: Transformer weighted network for neonatal brain MRI segmentation": {
        "authors": [
          "Shengjie Zhang",
          "Bohan Ren",
          "Ziqi Yu",
          "Haibo Yang",
          "Xiaoyang Han",
          "Xiang Chen",
          "Yuan Zhou",
          "Dinggang Shen",
          "Yong Zhang"
        ],
        "url": "https://zhouyuanzxcv.github.io/files/papers/Zhang%20et%20al_2022_TW-Net.pdf",
        "ref_texts": "[21] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "21"
        ]
      },
      "Joint attention-guided feature fusion network for saliency detection of surface defects": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2402.02797",
        "ref_texts": "[48] S.-H. Gao, Y .-Q. Tan, M.-M. Cheng, C. Lu, Y . Chen, and S. Yan, \u201cHighly efficient salient object detection with 100k parameters,\u201d in Proceedings of European Conference on Computer Vision , 2020.[49] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pp. 6230\u20136239, 2017.",
        "ref_ids": [
          "48",
          "49"
        ]
      },
      "DCANet: differential convolution attention network for RGB-D semantic segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2210.06747",
        "ref_texts": "[62] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u2013",
        "ref_ids": [
          "62"
        ]
      },
      "Deep depth from focus with differential focus volume": {
        "authors": [
          "Fengting Yang",
          "Xiaolei Huang",
          "Zihan Zhou"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2022/papers/Yang_Deep_Depth_From_Focus_With_Differential_Focus_Volume_CVPR_2022_paper.pdf",
        "ref_texts": "[53] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , pages 2881\u20132890, 2017. 4",
        "ref_ids": [
          "53"
        ]
      },
      "Smoothing matters: Momentum transformer for domain adaptive semantic segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2203.07988",
        "ref_texts": "[55] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017. 2",
        "ref_ids": [
          "55"
        ]
      },
      "Learning shadow correspondence for video shadow detection": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2208.00150",
        "ref_texts": "53. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: CVPR (2017)",
        "ref_ids": [
          "53"
        ]
      },
      "Learning depth from focus in the wild": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2207.09658",
        "ref_texts": "42. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR) (2017)",
        "ref_ids": [
          "42"
        ]
      },
      "How do computers see landscapes? comparisons of eye-level greenery assessments between computer and human perceptions": {
        "authors": [
          "Pongsakorn Suppakittpaisarn"
        ],
        "url": "https://uehh.hku.hk/wp-content/uploads/2022/08/Direction-7_How-do-computers-see-landscapes.pdf",
        "ref_texts": "8Yu, T., & Wang, R. (2016). Scene parsing using graph matching on street-view data. Computer Vision and Image Understanding, 145, 70\u201380. Zang, P., Liu, X., Zhao, Y., Guo, H., Lu, Y., & Xue, C. Q. (2020). Eye-level street greenery and walking behaviors of older adults. International Journal of Environmental Research and Public Health, 17(17), 6130. Zhao, H., Shi, J., Qi, X., Wang, X., & Jia, J. (2017). Pyramid scene parsing network. on Computer Vision and Pattern Recognition (CVPR). P. Suppakittpaisarn et al. "
      },
      "Online easy example mining for weakly-supervised gland segmentation from histology images": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2206.06665",
        "ref_texts": "23. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: Proceedings of the IEEE conference on computer vision and pattern recognition. pp. 2881\u20132890 (2017)",
        "ref_ids": [
          "23"
        ]
      },
      "Enabling detailed action recognition evaluation through video dataset augmentation": {
        "authors": [],
        "url": "https://proceedings.neurips.cc/paper_files/paper/2022/file/ff52407b80dde0f0f45814db2738464c-Paper-Datasets_and_Benchmarks.pdf",
        "ref_texts": "[72] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017.",
        "ref_ids": [
          "72"
        ]
      },
      "Cpgnet: Cascade point-grid fusion network for real-time lidar semantic segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2204.09914",
        "ref_texts": "[7] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "7"
        ]
      },
      "Pp-humanseg: Connectivity-aware portrait segmentation with a large-scale teleconferencing video dataset": {
        "authors": [
          "Lutao Chu",
          "Yi Liu",
          "Zewu Wu",
          "Shiyu Tang",
          "Guowei Chen",
          "Yuying Hao",
          "Juncai Peng",
          "Zhiliang Yu",
          "Zeyu Chen",
          "Baohua Lai",
          "Haoyi Xiong"
        ],
        "url": "https://openaccess.thecvf.com/content/WACV2022W/HADCV/papers/Chu_PP-HumanSeg_Connectivity-Aware_Portrait_Segmentation_With_a_Large-Scale_Teleconferencing_Video_Dataset_WACVW_2022_paper.pdf",
        "ref_texts": "[33] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "33"
        ]
      },
      "Evaluating transformer-based semantic segmentation networks for pathological image segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2108.11993",
        "ref_texts": "[14] Zhao, H., Shi, J., Qi, X., Wang, X., and Jia, J., \\Pyramid scene parsing network,\" in [Proceedings of the IEEE conference on computer vision and pattern recognition ], 2881{2890 (2017).",
        "ref_ids": [
          "14",
          "Proceedings of the IEEE conference on computer vision and pattern recognition "
        ]
      },
      "Unsupervised low-light image enhancement with decoupled networks": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2005.02818",
        "ref_texts": "[50] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in CVPR , 2017.",
        "ref_ids": [
          "50"
        ]
      },
      "MAFNet: Segmentation of road potholes with multimodal attention fusion network for autonomous vehicles": {
        "authors": [
          "Zhen Feng",
          "Yanning Guo",
          "Qing Liang",
          "Usman Maqbool",
          "Hengli Wang",
          "Ming Liu",
          "Yuxiang Sun"
        ],
        "url": "https://labsun.org/pub/TIM2022_mafnet.pdf",
        "ref_texts": "[35] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing 760 network,\u201d in Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR) , 761 Los Alamitos, CA, USA, Jul. 2017, pp. 6230\u20136239. 762",
        "ref_ids": [
          "35"
        ]
      },
      "Trust, but verify: Cross-modality fusion for hd map change detection": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2212.07312",
        "ref_texts": "[67] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , July 2017. 15 Appendix In this appendix, we provide additional details about our dataset and experiments. In Section (A), we provide an ablation study on the influence of input crop size on model performance. In Section (B), we discuss additional implementation details about our training, data augmentation, and occlusion-based map rendering process. In Section (C), we discuss the paired positive-negative logs we include. In Section (D), we describe our evaluation metric. In Section (E), we provide additional experimental analysis of different models and rendering viewpoints. In Section (F), we provide additional details about how we generate orthoimagery. In Section (G), we offer additional examples from our test set. In Section (H), we give examples of other types of temporary map changes which we do not annotate or evaluate within our dataset. In Section (I) we provide further analysis of the frequency of map changes. In Section (J), we give additional details about our synthetic map perturbation protocol. In Section (K), we provide a datasheet for the dataset. Appendix A: Influence of Input Crop Size In this section, we perform an ablation on input crop size, as discussed in Section 5.1 of the main text. In the main paper, we set our input crop size to 224\u0002224px for all experiments mentioned therein. In this section, we present an ablation to measure the influence of input crop size. Again, we find the ego-view model is the best-performing model, as measured on its own field of view. Perhaps surprisingly, we find that an RGB image at234\u0002234px resolution (\u0018164K pixel values/image) is sufficient to capture significant detail. In Table 7, we present an ablation where we find that for BEV models, higher resolution (i.e. 468\u0002468px) does improve mAcc by 2%mAcc, although requiring almost 4x the GPU memory during training and significantly longer training times. However, for ego-view models, a higher crop size is quite detrimental, reducing visibility-based mAcc by around 7%. Table 7: Controlled evaluation of the influence of input crop size (for ego-view and BEV), on TbV-Beta . MODALITIES VISIBILITY -BASED BEV PROXIMITY VISIBILITY -BASED EVAL. @ 20 M EVAL. @20 M EVAL. @20 M RESOLUTION BACKBONE ARCH. V IEWPOINT RGB S EMANTICS MAP VAL TEST ISCHANGED NOCHANGE TEST ISCHANGED NOCHANGE MACC MACC ACC ACC MACC ACC ACC",
        "ref_ids": [
          "67"
        ]
      },
      "Certified defences against adversarial patch attacks on semantic segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2209.05980",
        "ref_texts": "11 Published as a conference paper at ICLR 2023 Jan Hendrik Metzen and Maksym Yatsura. Efficient certified defenses against patch attacks on image classifiers. In International Conference on Learning Representations (ICLR) , 2021. URL https://openreview.net/forum?id=hr-3PMvDpil . Muzammal Naseer, Salman Khan, and Fatih Porikli. Local gradients smoothing: Defense against localized adversarial attacks. In IEEE Winter Conference on Applications of Computer Vision (WACV) , 2019. URL https://doi.org/10.1109/WACV.2019.00143 . Federico Nesti, Giulio Rossolini, Saasha Nair, Alessandro Biondi, and Giorgio C. Buttazzo. Evaluating the robustness of semantic segmentation for autonomous driving against real-world adversarial patch attacks. 2022 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV) , pp. 2826\u20132835, 2022. Hadi Salman, Saachi Jain, Eric Wong, and Aleksander Madry. Certified patch robustness via smoothed vision transformers, 2021. arXiv:2110.07719. Ramprasaath R. Selvaraju, Michael Cogswell, Abhishek Das, Ramakrishna Vedantam, Devi Parikh, and Dhruv Batra. Grad-CAM: Visual Explanations from Deep Networks via Gradient-Based Localization. International Journal of Computer Vision , October 2019. ISSN 1573-1405. Yuhang Song, Chao Yang, Yeji Shen, Peng Wang, Qin Huang, and C.-C. Jay Kuo. Spg-net: Segmentation prediction and guidance network for image inpainting. In BMVC , 2018. Roman Suvorov, Elizaveta Logacheva, Anton Mashikhin, Anastasia Remizova, Arsenii Ashukha, Aleksei Silvestrov, Naejin Kong, Harshith Goka, Kiwoong Park, and Victor S. Lempitsky. Resolution-robust large mask inpainting with fourier convolutions. 2022 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV) , pp. 3172\u20133182, 2022. Pascal Vincent, Hugo Larochelle, Isabelle Lajoie, Yoshua Bengio, and Pierre-Antoine Manzagol. Stacked denoising autoencoders: Learning useful representations in a deep network with a local denoising criterion. Journal of Machine Learning Research , 11(110):3371\u20133408, 2010. URL http://jmlr.org/papers/v11/vincent10a.html . Tong Wu, Liang Tong, and Yevgeniy V orobeychik. Defending against physically realizable attacks on image classification. In International Conference on Learning Representations (ICLR) , 2020. URLhttps://arxiv.org/abs/1909.09552 . Chong Xiang and Prateek Mittal. Detectorguard: Provably securing object detectors against localized patch hiding attacks. In ACM Conference on Computer and Communications Security (CCS) , 2021a. Chong Xiang and Prateek Mittal. Patchguard++: Efficient provable attack detection against adversarial patches, 2021b. arXiv:2104.12609. Chong Xiang, Arjun Nitin Bhagoji, Vikash Sehwag, and Prateek Mittal. Patchguard: A provably robust defense against adversarial patches via small receptive fields and masking. In 30th USENIX Security Symposium (USENIX Security) , 2021. Chong Xiang, Saeed Mahloujifar, and Prateek Mittal. Patchcleanser: Certifiably robust defense against adversarial patches for any image classifier. In 31st USENIX Security Symposium (USENIX Security) , 2022a. Chong Xiang, Alexander Valtchanov, Saeed Mahloujifar, and Prateek Mittal. Objectseeker: Certifiably robust object detection against patch hiding attacks via patch-agnostic masking, 2022b. arXiv:2202.01811. Zhanyuan Zhang, Benson Yuan, Michael McCoyd, and David Wagner. Clipped BagNet: Defending Against Sticker Attacks with Clipped Bag-of-features. In 3rd Deep Learning and Security Workshop (DLS) , 2020. Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) , 2017."
      },
      "Car: Class-aware regularizations for semantic segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2203.07160",
        "ref_texts": "36. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: IEEE Conference on Computer Vision and Pattern Recognition (2017)",
        "ref_ids": [
          "36"
        ]
      },
      "Object level depth reconstruction for category level 6d object pose estimation from monocular rgb image": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2204.01586",
        "ref_texts": "38. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: Proceedings of the IEEE conference on computer vision and pattern recognition. pp. 2881{2890 (2017)",
        "ref_ids": [
          "38"
        ]
      },
      "BTS: a bi-lingual benchmark for text segmentation in the wild": {
        "authors": [
          "Xixi Xu",
          "Zhongang Qi",
          "Jianqi Ma",
          "Honglun Zhang",
          "Ying Shan",
          "Xiaohu Qie"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_BTS_A_Bi-Lingual_Benchmark_for_Text_Segmentation_in_the_Wild_CVPR_2022_paper.pdf",
        "ref_texts": "[71] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In IEEE Computer Society , 2016. 3",
        "ref_ids": [
          "71"
        ]
      },
      "Wsss4luad: Grand challenge on weakly-supervised tissue semantic segmentation for lung adenocarcinoma": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2204.06455",
        "ref_texts": "[71] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "71"
        ]
      },
      "Learning semantic segmentation from multiple datasets with label shifts": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2202.14030",
        "ref_texts": "[57] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017. 1",
        "ref_ids": [
          "57"
        ]
      },
      "FogAdapt: Self-supervised domain adaptation for semantic segmentation of foggy images": {
        "authors": [
          "Javed Iqbal",
          "Rehan Hafiz",
          "Mohsen Ali"
        ],
        "url": "https://arxiv.org/pdf/2201.02588",
        "ref_texts": "[5] H. Zhao, J. Shi, X. Qi, X. Wang, J. Jia, Pyramid scene parsing network, in: IEEE Conf. on Computer Vision and Pattern Recognition (CVPR), 2017, pp. 2881\u20132890. 1",
        "ref_ids": [
          "5"
        ]
      },
      "Unsupervised black-box model domain adaptation for brain tumor segmentation": {
        "authors": [
          "Jonghye Woo"
        ],
        "url": "https://www.frontiersin.org/articles/10.3389/fnins.2022.837646/pdf",
        "ref_texts": ""
      },
      "Submesoscale oceanic eddy detection in SAR images using context and edge association network": {
        "authors": [
          "Linghui Xia"
        ],
        "url": "https://www.frontiersin.org/articles/10.3389/fmars.2022.1023624/pdf",
        "ref_texts": "01431161.2015.1084431 Yan, Z., Chong, J., Zhao, Y., Sun, K., Wang, Y., and Li, Y. (2019). Multifeature fusion neural network for oceanic phenomena detection in sar images. Sensors 20, 210. doi: 10.3390/s20010210 Zhang, D., Gade, M., and Zhang, J. (2020). \u201cSar eddy detection using mask-rcnn and edge enhancement, \u201dinIGARSS 2020-2020 IEEE international geoscience and remote sensing symposium (Electr Network: IEEE) 1604 \u20131607. doi: 10.1109/ IGARSS39084.2020.9323808 Zhao, H., Shi, J., Qi, X., Wang, X., and Jia, J. (2017). \u201cPyramid scene parsing network, \u201dinProceedings of the IEEE conference on computer vision and pattern recognition (Honolulu, USA: IEEE) 2881 \u20132890.Xia et al. 10.3389/fmars.2022.1023624 Frontiers in Marine Science frontiersin.org 16"
      },
      "Scale-aware network with modality-awareness for RGB-D indoor semantic segmentation": {
        "authors": [],
        "url": "https://orca.cardiff.ac.uk/id/eprint/149167/1/SAMD.pdf",
        "ref_texts": "[9] X. Q. X. W. J. J. Hengshuang Zhao, Jianping Shi, Pyramid scene 519 parsing network, in: CVPR, 2017. 520",
        "ref_ids": [
          "9"
        ]
      },
      "Real-time semantic segmentation via spatial-detail guided context propagation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2005.11034",
        "ref_texts": "[15] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "15"
        ]
      },
      "A pixel-level meta-learner for weakly supervised few-shot semantic segmentation": {
        "authors": [
          "Hao Lee",
          "En Yang",
          "Chiang Frank"
        ],
        "url": "http://openaccess.thecvf.com/content/WACV2022/papers/Lee_A_Pixel-Level_Meta-Learner_for_Weakly_Supervised_Few-Shot_Semantic_Segmentation_WACV_2022_paper.pdf",
        "ref_texts": "[58] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017. 2",
        "ref_ids": [
          "58"
        ]
      },
      "UnMICST: Deep learning with real augmentation for robust segmentation of highly multiplexed images of human tissues": {
        "authors": [
          "Clarence Yapp"
        ],
        "url": "https://www.nature.com/articles/s42003-022-04076-3.pdf",
        "ref_texts": "47. Zhao, H., Shi, J., Qi, X., Wang, X. & Jia, J. Pyramid scene parsing network. Proceedings of the IEEE conference on computer vision and pattern recognition , 2881 \u20132890 (2017).",
        "ref_ids": [
          "47"
        ]
      },
      "Weakly-supervised convolutional neural networks for vessel segmentation in cerebral angiography": {
        "authors": [
          "Arvind Vepa",
          "Andrew Choi",
          "Noor Nakhaei",
          "Wonjun Lee",
          "Noah Stier",
          "Andrew Vu",
          "Greyson Jenkins",
          "Xiaoyan Yang",
          "Manjot Shergill",
          "Moira Desphy",
          "Kevin Delao",
          "Mia Levy",
          "Cristopher Garduno",
          "Lacy Nelson",
          "Wandi Liu",
          "Fan Hung",
          "Fabien Scalzo"
        ],
        "url": "https://openaccess.thecvf.com/content/WACV2022/papers/Vepa_Weakly-Supervised_Convolutional_Neural_Networks_for_Vessel_Segmentation_in_Cerebral_Angiography_WACV_2022_paper.pdf",
        "ref_texts": "[38] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "38"
        ]
      },
      "Space squeeze reasoning and low-rank bilinear feature fusion for surgical image segmentation": {
        "authors": [
          "Liang Ni",
          "Bin Bian",
          "Zhen Li",
          "Hu Zhou",
          "Qi Li",
          "Guang Hou"
        ],
        "url": "https://openreview.net/pdf?id=VpabzrRCuCo",
        "ref_texts": "[31] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proc. IEEE Conf. Comput. Vis. Pattern Recognit. , 2017, pp. 6230\u20136239.",
        "ref_ids": [
          "31"
        ]
      },
      "Automated food intake tracking requires depth-refined semantic segmentation to rectify visual-volume discordance in long-term care homes": {
        "authors": [
          "Kaylen J. Pfisterer"
        ],
        "url": "https://www.nature.com/articles/s41598-021-03972-8.pdf",
        "ref_texts": ""
      },
      "IncepFormer: efficient inception transformer with pyramid pooling for semantic segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2212.03035",
        "ref_texts": "[38] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017. 2, 8",
        "ref_ids": [
          "38"
        ]
      },
      "Pyramid convolutional RNN for MRI image reconstruction": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1912.00543",
        "ref_texts": "[120] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "120"
        ]
      },
      "Semi-supervised multi-task learning for semantics and depth": {
        "authors": [
          "Yufeng Wang",
          "Hsuan Tsai",
          "Chih Hung",
          "Wenrui Ding",
          "Shuo Liu",
          "Hsuan Yang"
        ],
        "url": "https://openaccess.thecvf.com/content/WACV2022/papers/Wang_Semi-Supervised_Multi-Task_Learning_for_Semantics_and_Depth_WACV_2022_paper.pdf",
        "ref_texts": "[69] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017. 2, 5",
        "ref_ids": [
          "69"
        ]
      },
      "Robustfusion: Robust volumetric performance reconstruction under human-object interactions from monocular rgbd stream": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2104.14837",
        "ref_texts": "[70] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in CVPR , 2017.",
        "ref_ids": [
          "70"
        ]
      },
      "Application of multi-modal fusion attention mechanism in semantic segmentation": {
        "authors": [
          "Yunlong Liu",
          "Osamu Yoshie",
          "Hiroshi Watanabe"
        ],
        "url": "https://openaccess.thecvf.com/content/ACCV2022/papers/Liu_Application_of_Multi-modal_Fusion_Attention_Mechanism_in_Semantic_Segmentation_ACCV_2022_paper.pdf",
        "ref_texts": "34. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: 2017 IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2017, Honolulu, HI, USA, July 21-26, 2017. pp. 6230\u20136239. IEEE Computer Society (2017)",
        "ref_ids": [
          "34"
        ]
      },
      "Edge-aware graph matching network for part-based semantic segmentation": {
        "authors": [
          "Umberto Michieli"
        ],
        "url": "https://link.springer.com/content/pdf/10.1007/s11263-022-01671-z.pdf",
        "ref_texts": "3102. Xia, F., Zhu, J., Wang, P ., & Y uille, A.(2015). Pose-guided human parsing with deep learned features. arXiv preprint arXiv:1508.03881 . Xia, F., Wang, P ., Chen, L. C., & Y uille, A. L. (2016). Zoom better to see clearer: Human and object parsing with hierarchical auto-zoom net. In Proceedings of European conference on computer vision (ECCV) (pp. 648\u2013663). Springer. Xia, F., Wang, P ., Chen, X., & Y uille, A. L. (2017). Joint multi-person pose estimation and semantic part segmentation. In Proceedings of IEEE conference on computer vision and pattern recognition(CVPR) (pp. 6769\u20136778). Xie, E., Wang, W., Y u, Z., Anandkumar, A., Alvarez, J. M., & Luo, P . (2021). Segformer: Simple and efficient design for semanticsegmentation with transformers. In Neural information processing systems (NeurIPS) . Yamaguchi, K., Kiapour, M. H., Ortiz, L. E., & Berg, T. L. (2012). Parsing clothing in fashion photographs. In Proceedings of IEEE conference on computer vision and pattern recognition (CVPR)(pp. 3570\u20133577). Yang, Y ., & Ramanan, D. (2011). Articulated pose estimation with flexible mixtures-of-parts. In Proceedings of IEEE conference on computer vision and pattern recognition (CVPR) (pp. 1385\u20131392). Yin, J., Liu, W., Xing, W., & Xiao, Y . (2021). Class-level aware network for human parsing. In International conference on computing, networks and internet of things (pp. 1\u20136). Y u, C., Wang, J., Peng, C., Gao, C., Y u, G., & Sang, N. (2018). Bisenet: Bilateral segmentation network for real-time semantic segmenta123 International Journal of Computer Vision (2022) 130:2797\u20132821 2821 tion. In Proceedings of European conference on computer vision (ECCV) (pp. 325\u2013341). Y u, C., Gao, C., Wang, J., Y u, G., Shen, C., & Sang, N. (2021). Bisenet v2: Bilateral network with guided aggregation for real-time semantic segmentation. International Journal of Computer Vision (IJCV), 129 (11), 3051\u20133068. Y u, F., Koltun, V ., & Funkhouser, T. (2017). Dilated residual networks. InProceedings of IEEE conference on computer vision and pattern recognition (CVPR) . Y uan, Y ., Huang, L., Guo, J., Zhang, C., Chen, X., & Wang, J. (2018). Ocnet: Object context network for scene parsing. arXiv preprintarXiv:1809.00916 . Zhang, N., Donahue, J., Girshick, R., & Darrell, T. (2014). Part-based r-cnns for fine-grained category detection. In Proceedings of European Conference on Computer Vision (ECCV) (pp. 834\u2013849). Springer. Zhang, W., Huang, Z., Luo, G., Chen, T., Wang, X., Liu, W., Y u, G., & Shen, C. (2022) Topformer: Token pyramid transformer formobile semantic segmentation. In Proceedings of IEEE conference on computer vision and pattern recognition (CVPR) . Zhang, Z., & Pang, Y . (2020). Cgnet: Cross-guidance network for semantic segmentation. Science China Information Sciences, 63(2), 1\u201316. Zhang, Z., Fu, H., Dai, H., Shen, J., Pang, Y ., & Shao, L. (2019). Et-net: A generic edge-attention guidance network for medi-cal image segmentation. In International conference on medical image computing and computer-assisted intervention (pp. 442\u2013",
        "ref_ids": [
          "3102"
        ]
      },
      "Birds of a feather flock together: Category-divergence guidance for domain adaptive segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2204.02111",
        "ref_texts": "[43] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , pp. 6230\u20136239, 2017. 2",
        "ref_ids": [
          "43"
        ]
      },
      "Weak-shot semantic segmentation via dual similarity transfer": {
        "authors": [],
        "url": "https://proceedings.neurips.cc/paper_files/paper/2022/file/d148494b18160a30b14851655208c9c1-Paper-Conference.pdf",
        "ref_texts": "[47] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017.",
        "ref_ids": [
          "47"
        ]
      },
      "Side-scan sonar image segmentation based on multi-channel CNN for AUV navigation": {
        "authors": [
          "Feihu Zhang"
        ],
        "url": "https://www.frontiersin.org/articles/10.3389/fnbot.2022.928206/pdf",
        "ref_texts": ""
      },
      "Semi-supervised video semantic segmentation with inter-frame feature reconstruction": {
        "authors": [
          "Jiafan Zhuang",
          "Zilei Wang",
          "Yuan Gao"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2022/papers/Zhuang_Semi-Supervised_Video_Semantic_Segmentation_With_Inter-Frame_Feature_Reconstruction_CVPR_2022_paper.pdf",
        "ref_texts": "[28] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. InCVPR , 2017. 2,3,6",
        "ref_ids": [
          "28"
        ]
      },
      "N-Net: a novel dense fully convolutional neural network for thyroid nodule segmentation": {
        "authors": [
          "Tong Tong",
          "Shun Chen"
        ],
        "url": "https://www.frontiersin.org/journals/neuroscience/articles/10.3389/fnins.2022.872601/pdf",
        "ref_texts": ""
      },
      "Unsupervised vision-language grammar induction with shared structure modeling": {
        "authors": [],
        "url": "https://lirias.kuleuven.be/retrieve/716450",
        "ref_texts": "5744, 2018. Daniel H Younger. Recognition and parsing of context-free languages in time n3. Information and control , 10(2):189\u2013208, 1967. Songyang Zhang, Linfeng Song, Lifeng Jin, Kun Xu, Dong Yu, and Jiebo Luo. Video-aided unsupervised grammar induction. In Proceedings of the Annual Conference of the North American Chapter of the Association for Computational Linguistics (NAACL) , pp. 1513\u20131524, 2021. Xingxing Zhang, Liang Lu, and Mirella Lapata. Top-down tree long short-term memory networks. InProceedings of the Annual Conference of the North American Chapter of the Association for Computational Linguistics (NAACL) , pp. 310\u2013320, 2016. Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , pp. 2881\u20132890, 2017. Yanpeng Zhao and Ivan Titov. Visually grounded compound PCFGs. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP) , pp."
      },
      "Dmsanet: Dual multi scale attention network": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2106.08382",
        "ref_texts": "9 J. Hu, L. Shen, S. Albanie, G. Sun, and A. Vedaldi. Gather-excite: Exploiting feature context in convolutional neural networks. arXiv preprint arXiv:1810.12348 , 2018a. J. Hu, L. Shen, and G. Sun. Squeeze-and-excitation networks. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 7132\u20137141, 2018b. X. Li, W. Wang, X. Hu, and J. Yang. Selective kernel networks. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 510\u2013519, 2019. T.-Y . Lin, M. Maire, S. Belongie, J. Hays, P. Perona, D. Ramanan, P. Doll\u00e1r, and C. L. Zitnick. Microsoft coco: Common objects in context. In European conference on computer vision , pages 740\u2013755. Springer, 2014. T.-Y . Lin, P. Doll\u00e1r, R. Girshick, K. He, B. Hariharan, and S. Belongie. Feature pyramid networks for object detection. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2117\u20132125, 2017a. T.-Y . Lin, P. Goyal, R. Girshick, K. He, and P. Doll\u00e1r. Focal loss for dense object detection. In Proceedings of the IEEE international conference on computer vision , pages 2980\u20132988, 2017b. S. Ren, K. He, R. Girshick, and J. Sun. Faster r-cnn: Towards real-time object detection with region proposal networks. arXiv preprint arXiv:1506.01497 , 2015. A. Sagar. Aa3dnet: Attention augmented real time 3d object detection. arXiv preprint arXiv:2107.12137 , 2021. A. Sagar and R. Soundrapandiyan. Semantic segmentation with multi scale spatial attention for self driving cars. arXiv preprint arXiv:2007.12685 , 2020. H. Sang, Q. Zhou, and Y . Zhao. Pcanet: Pyramid convolutional attention network for semantic segmentation. Image and Vision Computing , 103:103997, 2020. C. Szegedy, V . Vanhoucke, S. Ioffe, J. Shlens, and Z. Wojna. Rethinking the inception architecture for computer vision. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2818\u20132826, 2016. F. Wang, M. Jiang, C. Qian, S. Yang, C. Li, H. Zhang, X. Wang, and X. Tang. Residual attention network for image classification. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 3156\u20133164, 2017. Q. Wang, B. Wu, P. Zhu, P. Li, W. Zuo, and Q. Hu. Eca-net: Efficient channel attention for deep convolutional neural networks, 2020. X. Wang, R. Girshick, A. Gupta, and K. He. Non-local neural networks. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 7794\u20137803, 2018. S. Woo, J. Park, J.-Y . Lee, and I. S. Kweon. Cbam: Convolutional block attention module. In Proceedings of the European conference on computer vision (ECCV) , pages 3\u201319, 2018. Y . Wu and K. He. Group normalization. In Proceedings of the European conference on computer vision (ECCV) , pages 3\u201319, 2018. H. Zhang, C. Wu, Z. Zhang, Y . Zhu, H. Lin, Z. Zhang, Y . Sun, T. He, J. Mueller, R. Manmatha, et al. Resnest: Split-attention networks. arXiv preprint arXiv:2004.08955 , 2020. H. Zhang, K. Zu, J. Lu, Y . Zou, and D. Meng. Epsanet: An efficient pyramid split attention block on convolutional neural network. arXiv preprint arXiv:2105.14447 , 2021. Q.-L. Zhang and Y .-B. Yang. Sa-net: Shuffle attention for deep convolutional neural networks. In ICASSP 2021-2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) , pages 2235\u20132239. IEEE, 2021. H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017. Z. Zhong, Z. Q. Lin, R. Bidart, X. Hu, I. B. Daya, Z. Li, W.-S. Zheng, J. Li, and A. Wong. Squeezeand-attention networks for semantic segmentation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 13065\u201313074, 2020."
      },
      "Ground-based remote sensing cloud detection using dual pyramid network and encoder\u2013decoder constraint": {
        "authors": [],
        "url": "https://strathprints.strath.ac.uk/81196/1/Zhang_etal_IEEE_TGRS_2022_Ground_based_remote_sensing_cloud_detection_using_dual.pdf",
        "ref_texts": "[28] H. Zhao, J. Shi, and X. Qi, \u201cPyramid scene parsing network,\u201d in Proceedings of IEEE Conference on Computer Vision and Pattern Recognition, 2017, pp. 2881-2890.",
        "ref_ids": [
          "28"
        ]
      },
      "Graspe: Graph based multimodal fusion for robot navigation in unstructured outdoor environments": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2209.05722",
        "ref_texts": "[53] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2017, pp. 6230\u20136239.",
        "ref_ids": [
          "53"
        ]
      },
      "Towards robust semantic segmentation of accident scenes via multi-source mixed sampling and meta-learning": {
        "authors": [
          "Xinyu Luo",
          "Jiaming Zhang",
          "Kailun Yang",
          "Alina Roitberg",
          "Kunyu Peng",
          "Rainer Stiefelhagen"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2022W/WAD/papers/Luo_Towards_Robust_Semantic_Segmentation_of_Accident_Scenes_via_Multi-Source_Mixed_CVPRW_2022_paper.pdf",
        "ref_texts": "[70] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017. 2, 6",
        "ref_ids": [
          "70"
        ]
      },
      "Pedestrian detection for autonomous cars: inference fusion of deep neural networks": {
        "authors": [
          "Muhammad Mobaidul"
        ],
        "url": "https://par.nsf.gov/servlets/purl/10454201",
        "ref_texts": "[49] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR) , Jul. 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "49"
        ]
      },
      ": Dynamic Density-Aware Active Domain Adaptation for Semantic Segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2202.06484",
        "ref_texts": "57. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: Proceedings of the IEEE conference on computer vision and pattern recognition. pp. 2881\u20132890 (2017) 1 Dynamic Density-aware Active Domain Adaptation 19",
        "ref_ids": [
          "57"
        ]
      },
      "Augmentation invariance and adaptive sampling in semantic segmentation of agricultural aerial images": {
        "authors": [
          "Antonio Tavera",
          "Edoardo Arnaudo",
          "Carlo Masone",
          "Barbara Caputo"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2022W/AgriVision/papers/Tavera_Augmentation_Invariance_and_Adaptive_Sampling_in_Semantic_Segmentation_of_Agricultural_CVPRW_2022_paper.pdf",
        "ref_texts": "[40] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , pages 6230\u20136239, 2017. 2, 5",
        "ref_ids": [
          "40"
        ]
      },
      "RankSeg: Adaptive Pixel Classification with Image Category Ranking for Segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2203.04187",
        "ref_texts": "89. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: CVPR (2017)",
        "ref_ids": [
          "89"
        ]
      },
      "Discriminability-transferability trade-off: An information-theoretic perspective": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2203.03871",
        "ref_texts": "60.Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: CVPR (2017)",
        "ref_ids": [
          "60"
        ]
      },
      "Semantic visual simultaneous localization and mapping: A survey": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2209.06428",
        "ref_texts": "[32] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "32"
        ]
      },
      "Distilling inter-class distance for semantic segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2205.03650",
        "ref_texts": "[Zhao et al. , 2017 ]Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u2013",
        "ref_ids": [
          "Zhao et al\\. , 2017 "
        ]
      },
      "BiSeNet-oriented context attention model for image semantic segmentation": {
        "authors": [],
        "url": "https://doiserbia.nb.rs/ft.aspx?id=1820-02142200040T",
        "ref_texts": "38. H. Zhao, J. Shi, X. Qi, X. Wang and J. Jia. \u201dPyramid Scene Parsing Network,\u201d 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2017, pp. 6230-6239, doi: 10.1109/CVPR.2017.660.",
        "ref_ids": [
          "38"
        ]
      },
      "A segmentation-guided deep learning framework for leaf counting": {
        "authors": [
          "Xijian Fan"
        ],
        "url": "https://www.frontiersin.org/articles/10.3389/fpls.2022.844522/pdf",
        "ref_texts": "1016/j.molp.2020.01.008 Zhao, H., Shi, J., Qi, X., Wang, X., and Jia, J. (2017). \u201cPyramid scene parsing network, \u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , San Juan, PR, 2881\u20132890. Zhou, Z., Siddiquee, M. M. R., Tajbakhsh, N., and Liang, J. (2018). \u201cUnet++: a nested u-net architecture for medical image segmentation, \u201d in Deep Learning in Medical Image Analysis and Multimodal Learning for Clinical Decision Support , eds L. Maier-Hein, T. Syeda-Mahmood, Z. Taylor, Z. Lu, D. Stoyanov, A. Madabhushi, et al. (Cham: Springer), 3\u201311. doi: 10.1007/978-3-030-00889-5_1 Zhu, Y., Aoun, M., Krijn, M., Vanschoren, J., and Campus, H. T. (2018)."
      },
      "Float: Factorized learning of object attributes for improved multi-object multi-part scene parsing": {
        "authors": [
          "Rishubh Singh",
          "Pranav Gupta",
          "Pradeep Shenoy",
          "Ravikiran Sarvadevabhatla"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2022/papers/Singh_FLOAT_Factorized_Learning_of_Object_Attributes_for_Improved_Multi-Object_Multi-Part_CVPR_2022_paper.pdf",
        "ref_texts": "[56] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017. 2",
        "ref_ids": [
          "56"
        ]
      },
      "Stereo dense scene reconstruction and accurate localization for learning-based navigation of laparoscope in minimally invasive surgery": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2110.03912",
        "ref_texts": "[22] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proc. IEEE Conf. Comput. Vis. Pattern Recog. , 2017, pp.",
        "ref_ids": [
          "22"
        ]
      },
      "Efficient large-scale localization by global instance recognition": {
        "authors": [
          "Fei Xue",
          "Ignas Budvytis",
          "Daniel Olmeda",
          "Roberto Cipolla"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2022/papers/Xue_Efficient_Large-Scale_Localization_by_Global_Instance_Recognition_CVPR_2022_paper.pdf",
        "ref_texts": "[66] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017. 3, 5",
        "ref_ids": [
          "66"
        ]
      },
      "Towards unsupervised open world semantic segmentation": {
        "authors": [],
        "url": "https://proceedings.mlr.press/v180/uhlemeyer22a/uhlemeyer22a.pdf",
        "ref_texts": "1434171. Fisher Yu, Haofeng Chen, Xin Wang, Wenqi Xian, Yingying Chen, Fangchen Liu, Vashisht Madhavan, and Trevor Darrell. Bdd100k: A diverse driving dataset for heterogeneous multitask learning. 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) , pages 2633\u20132642, 2020. Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network.2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , pages 6230\u20136239, 2017.",
        "ref_ids": [
          "1434171"
        ]
      },
      "Video shadow detection via spatio-temporal interpolation consistency training": {
        "authors": [
          "Xiao Lu",
          "Yihong Cao",
          "Sheng Liu",
          "Chengjiang Long",
          "Zipei Chen",
          "Xuanyu Zhou",
          "Yimin Yang",
          "Chunxia Xiao"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2022/papers/Lu_Video_Shadow_Detection_via_Spatio-Temporal_Interpolation_Consistency_Training_CVPR_2022_paper.pdf",
        "ref_texts": "[42] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2017. 7",
        "ref_ids": [
          "42"
        ]
      },
      "Sommelier: Curating DNN models for the masses": {
        "authors": [],
        "url": "https://dl.acm.org/doi/pdf/10.1145/3514221.3526173",
        "ref_texts": "[81] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. 2017.Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition. 2881\u20132890.",
        "ref_ids": [
          "81"
        ]
      },
      "Appearance quality classification method of Huangguan pear under complex background based on instance segmentation and semantic segmentation": {
        "authors": [
          "Yuhang Zhang"
        ],
        "url": "https://www.frontiersin.org/journals/plant-science/articles/10.3389/fpls.2022.914829/pdf",
        "ref_texts": "161, 1 \u20136. doi: 10.1016/j.postharvbio.2019.111090 Zhao, H., Shi, J., Qi, X., Wang, X., and Jia, J. (2016)Pyramid scene parsing network. doi: 10.48550/arXiv.1612.01105 .Zhang et al. 10.3389/fpls.2022.914829 Frontiers in Plant Science frontiersin.org 16"
      },
      "Fully convolutional network-based self-supervised learning for semantic segmentation": {
        "authors": [
          "Zhengeng Yang",
          "Hongshan Yu",
          "Yong He",
          "Wei Sun",
          "Hong Mao",
          "Ajmal Mian"
        ],
        "url": "https://openreview.net/pdf?id=1cCmCBKsuby",
        "ref_texts": ""
      },
      "Full-scale selective transformer for semantic segmentation": {
        "authors": [
          "Fangjian Lin",
          "Sitong Wu",
          "Yizhe Ma",
          "Shengwei Tian"
        ],
        "url": "https://openaccess.thecvf.com/content/ACCV2022/papers/Lin_Full-scale_Selective_Transformer_for_Semantic_Segmentation_ACCV_2022_paper.pdf",
        "ref_texts": "42. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: Proceedings of the IEEE conference on computer vision and pattern recognition. pp. 2881\u20132890 (2017)",
        "ref_ids": [
          "42"
        ]
      },
      "Inferring the class conditional response map for weakly supervised semantic segmentation": {
        "authors": [
          "Weixuan Sun",
          "Jing Zhang",
          "Nick Barnes"
        ],
        "url": "https://openaccess.thecvf.com/content/WACV2022/papers/Sun_Inferring_the_Class_Conditional_Response_Map_for_Weakly_Supervised_Semantic_WACV_2022_paper.pdf",
        "ref_texts": "[51] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In IEEE Conf. Comput. Vis. Pattern Recog. , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "51"
        ]
      },
      "Dam reservoir extraction from remote sensing imagery using tailored metric learning strategies": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2207.05807",
        "ref_texts": "[48] C. Yu, J. Wang, C. Peng, C. Gao, G. Yu, and N. Sang, \u201cBisenet: Bilateral segmentation network for real-time semantic segmentation,\u201d in ECCV , 2018.[49] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in CVPR , 2017.",
        "ref_ids": [
          "48",
          "49"
        ]
      },
      "Mv6d: Multi-view 6d pose estimation on rgb-d frames using a deep point-wise voting network": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2208.01172",
        "ref_texts": "[55] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in CVPR , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "55"
        ]
      },
      "Automatic prostate gleason grading using pyramid semantic parsing network in digital histopathology": {
        "authors": [
          "Yali Qiu"
        ],
        "url": "https://www.frontiersin.org/articles/10.3389/fonc.2022.772403/pdf",
        "ref_texts": "36. Zhao H, Shi J, Qi X, Wang X, Jia J. Pyramid Scene Parsing Network. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition . Honolulu, HI, USA: IEEE (2017). p. 2881 \u201390.",
        "ref_ids": [
          "36"
        ]
      },
      "Large-batch optimization for dense visual predictions": {
        "authors": [],
        "url": "https://proceedings.neurips.cc/paper_files/paper/2022/file/76bea0a1cf7bf9b78f842009f6de15a1-Supplemental-Conference.pdf",
        "ref_texts": "[21] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "21"
        ]
      },
      "Counting and locating high-density objects using convolutional neural network": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2102.04366",
        "ref_texts": "14 arXiv Arruda et al. (2021) A P REPRINT Yuan, J., Xiong, H.-C., Xiao, Y ., Guan, W., Wang, M., Hong, R., & Li, Z.-Y . (2019). Gated cnn: Integrating multi-scale feature layers for object detection. Pattern Recognition , (p. 107131). doi:doi:https://doi.org/10.1016/j.patcog.2019.107131. Zhang, S., Li, H., Kong, W., Wang, L., & Niu, X. (2019). An object counting network based on hierarchical context and feature fusion. Journal of Visual Communication and Image Representation ,62, 166 \u2013 173. doi:doi:https://doi.org/10.1016/j.jvcir.2019.05.003. Zhang, Y ., Bai, Y ., Ding, M., Li, Y ., & Ghanem, B. (2018). Weakly-supervised object detection via mining pseudo ground truth bounding-boxes. Pattern Recognition ,84, 68 \u2013 81. doi:doi:https://doi.org/10.1016/j.patcog.2018.07.005. Zhao, H., Shi, J., Qi, X., Wang, X., & Jia, J. (2017). Pyramid scene parsing network. In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) .arXiv:1612.01105 ."
      },
      "Multi-level domain adaptation for lane detection": {
        "authors": [
          "Chenguang Li",
          "Boheng Zhang",
          "Jia Shi",
          "Guangliang Cheng"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2022W/WAD/papers/Li_Multi-Level_Domain_Adaptation_for_Lane_Detection_CVPRW_2022_paper.pdf",
        "ref_texts": "[53] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017. 2",
        "ref_ids": [
          "53"
        ]
      },
      "Robust segmentation of underwater fish based on multi-level feature accumulation": {
        "authors": [
          "Adnan Haider"
        ],
        "url": "https://www.frontiersin.org/articles/10.3389/fmars.2022.1010565/pdf",
        "ref_texts": "(2017). \u201cGrad-CAM: Visual explanations from deep networks viagradient-based localization, \u201dinProceedings of the International Conference on Computer Vision , Venice, Italy, 2017 October 22-29. (New York, U.S: IEEE) 618 \u2013626. Sultan, H., Owais, M., Park, C., Mahmood, T., Haider, A., and Park, K. R. (2021). Artificial intelligence-based recognition of different types of shoulder implants in X-ray scans based on dense residual ensemble-network for personalized medicine.J. Pers. Med. 11, 482. doi: 10.3390/jpm11060482 Zhang, L., Li, X., Arnab, A., Yang, K., Tong, Y., and Torr, P. H. S. (2020). Dual graph convolutional network for semantic segmentation. arXiv . New York, U.S: IEEE. doi: 10.48550/arXiv.1909.06121 Zhang, P., Liu, W., Wang, H., Lei, Y., and Lu, H. (2019). Deep gated attention networks for Large-scale Street-level scene segmentation. Pattern Recognit. 88, 702 \u2013714. doi: 10.1016/j.patcog.2018.12.021 Zhang, W., Wu, C., and Bao, Z. (2022). DPANet: Dual pooling-aggregated attention network for fish segmentation. IET Comput. Vis. 16, 67 \u201382:1 \u201318. doi:10.1049/cvi2.12065 Zhang, Q.-L., and Yang, Y.-B. (2021). \u201cSA-Net: Shuf fle attention for deep convolutional neural networks, \u201dinIEEE International Conference on Acoustics, Speech and Signal Processing , Toronto, Canada. Japan, 2021 June 6-11. New York, U.S: IEEE 2235 \u20132239. Zhao, H., Shi, J., Qi, X., Wang, X., and Jia, J. (2017). \u201cPyramid scene parsing network, \u201dinProceedings of the Computer Vision and Pattern Recognition , Honolulu, USA, 2017 July 22-25. (New York, U.S: IEEE) 2881 \u20132890.Haider et al. 10.3389/fmars.2022.1010565 Frontiers in Marine Science frontiersin.org 17"
      },
      "Region rebalance for long-tailed semantic segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2204.01969",
        "ref_texts": "[62] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017. 1, 2, 3, 6",
        "ref_ids": [
          "62"
        ]
      },
      "Looking from a higher-level perspective: Attention and recognition enhanced multi-scale scene text segmentation": {
        "authors": [
          "Yujin Ren",
          "Jiaxin Zhang",
          "Bangdong Chen",
          "Xiaoyi Zhang",
          "Lianwen Jin"
        ],
        "url": "https://openaccess.thecvf.com/content/ACCV2022/papers/Ren_Looking_from_a_Higher-level_Perspective_Attention_and_Recognition_Enhanced_Multi-scale_ACCV_2022_paper.pdf",
        "ref_texts": "45. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: Proceedingsof the IEEE Conference on Computer Vision and Pattern Recognition. pp. 2881\u20132890 (2017)",
        "ref_ids": [
          "45"
        ]
      },
      "MTP: multi-task pruning for efficient semantic segmentation networks": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2007.08386",
        "ref_texts": "[21] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia, \u201cPyramid scene parsing network,\u201d in CVPR , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "21"
        ]
      },
      "Unsupervised contrastive domain adaptation for semantic segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2204.08399",
        "ref_texts": "[65] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017. 6",
        "ref_ids": [
          "65"
        ]
      },
      "Deep-learning approach for automated thickness measurement of epithelial tissue and scab using optical coherence tomography": {
        "authors": [],
        "url": "https://www.spiedigitallibrary.org/journals/journal-of-biomedical-optics/volume-27/issue-1/015002/Deep-learning-approach-for-automated-thickness-measurement-of-epithelial-tissue/10.1117/1.JBO.27.1.015002.pdf",
        "ref_texts": "37. H. Zhao et al., \u201cPyramid scene parsing network, \u201dinProc. IEEE Conf. Comput. Vision and Pattern Recognit. , pp. 2881 \u20132890 (2017).",
        "ref_ids": [
          "37"
        ]
      },
      "CCAT-NET: A novel transformer based semi-supervised framework for COVID-19 lung lesion segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2204.02839",
        "ref_texts": "[14] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia, \u201cPyramid scene parsing network,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition, 2017, pp. 2881\u20132890. ",
        "ref_ids": [
          "14"
        ]
      },
      "DPCCN: Densely-connected pyramid complex convolutional network for robust speech separation and extraction": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2112.13520",
        "ref_texts": "[22] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proc. CVPR , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "22"
        ]
      },
      "Data efficient 3d learner via knowledge transferred from 2d model": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2203.08479",
        "ref_texts": "46.Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: CVPR. pp. 6230\u20136239 (2017) 7",
        "ref_ids": [
          "46"
        ]
      },
      "Cell image segmentation by using feedback and convolutional LSTM": {
        "authors": [
          "Eisuke Shibuya"
        ],
        "url": "https://link.springer.com/content/pdf/10.1007/s00371-021-02221-3.pdf",
        "ref_texts": "33. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: Proceedings of the IEEE Conference on ComputerVision and Pattern Recognition, pp. 2881\u20132890 (2017)",
        "ref_ids": [
          "33"
        ]
      },
      "From pixel to patch: Synthesize context-aware features for zero-shot semantic segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2009.12232",
        "ref_texts": "[14] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , Honolulu, HI, Jul. 2017.[15] L.-C. Chen, G. Papandreou, I. Kokkinos, K. Murphy, and A. L. Yuille, \u201cDeeplab: Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected crfs,\u201d IEEE Transactions on Pattern Analysis and Machine Intelligence , vol. 40, no. 4, pp. 834\u2013848, 2018.",
        "ref_ids": [
          "14",
          "15"
        ]
      },
      "Deep learning image segmentation reveals patterns of UV reflectance evolution in passerine birds": {
        "authors": [
          "Yichen He"
        ],
        "url": "https://www.nature.com/articles/s41467-022-32586-5.pdf",
        "ref_texts": "60. Zhao, H., Shi, J., Qi, X., Wang, X. & Jia, J. Pyramid scene parsing network. arXiv 01105 ,2 0 1 7(1612).",
        "ref_ids": [
          "60"
        ]
      },
      "Real-time guava tree-part segmentation using fully convolutional network with channel and spatial attention": {
        "authors": [
          "Chenglin Wang",
          "Lixue Zhu"
        ],
        "url": "https://www.frontiersin.org/articles/10.3389/fpls.2022.991487/pdf",
        "ref_texts": "192:106609. doi: 10.1016/j.compag.2021.106609 Woo, S. A. P. J. (2018). CBAM: Convolutional block attention module . Cham: Springer. doi: 10.1007/978-3-030-01234-2_1 Yu, C., Gao, C., Wang, J., Yu, G., Shen, C., and Sang, N. (2021). Bisenet v2: Bilateral network with guided aggregation for real-time semantic segmentation. Int. J. Comput. Vision 129, 3051\u20133068. doi: 10.1007/s11263-021-01515-2 Zhang, J., He, L., Karkee, M., Zhang, Q., Zhang, X., and Gao, Z. (2018). Branch detection for apple trees trained in fruiting wall architecture using depth features and regions-convolutional neural network (r-cnn). Comput. Electron. Agric. 155, 386\u2013393. doi: 10.1016/j.compag.2018.10.029 Zhang, X., Karkee, M., Zhang, Q., and Whiting, M. D. (2021). Computer vision-based tree trunk and branch identification and shaking points detection in dense-foliage canopy for automated harvesting of apples. J. Field Robot. 38, 476\u2013493. doi: 10.1002/rob.21998 Zhao, H., Shi, J., Qi, X., Wang, X., and Jia, J. (2016). Pyramid scene parsing network. arXiv [Preprint]. arXiv:1612.01105. doi: 10.1109/CVPR.2017.660 Frontiers in Plant Science 11 frontiersin.org "
      },
      "Hidden path selection network for semantic segmentation of remote sensing images": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2112.05220",
        "ref_texts": "[27] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proc. IEEE Conf. Comput. Vis. Pattern Recognit. , 2017, pp. 6230\u20136239.",
        "ref_ids": [
          "27"
        ]
      },
      "HM: Hybrid masking for few-shot segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2203.12826",
        "ref_texts": "43. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR). pp.",
        "ref_ids": [
          "43"
        ]
      },
      "Semantic segmentation under adverse conditions: a weather and nighttime-aware synthetic data-based approach": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2210.05626",
        "ref_texts": "[49] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "49"
        ]
      },
      "Robust scatterer number density segmentation of ultrasound images": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2201.06143",
        "ref_texts": "[39] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "39"
        ]
      },
      "Efficient fire segmentation for internet-of-things-assisted intelligent transportation systems": {
        "authors": [],
        "url": "https://riunet.upv.es/bitstream/handle/10251/201896/MuhammadUllahKhan%20-%20Efficient%20Fire%20Segmentation%20for%20Internet-of-Things-Assisted%20Intelligent%20Trans....pdf?sequence=11",
        "ref_texts": ""
      },
      "Image segmentation using deep learning: A survey": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2001.05566",
        "ref_texts": "[56] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "56"
        ]
      },
      "A survey of convolutional neural networks: analysis, applications, and prospects": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2004.02806",
        "ref_texts": "[133] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid Scene Parsing Network.\u201d ",
        "ref_ids": [
          "133"
        ]
      },
      "SegFormer: Simple and efficient design for semantic segmentation with transformers": {
        "authors": [],
        "url": "https://proceedings.neurips.cc/paper/2021/file/64f1f27bf1b4ec22924fd0acb550c235-Paper.pdf",
        "ref_texts": "[15] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017. 3, 7, 8",
        "ref_ids": [
          "15"
        ]
      },
      "Coordinate attention for efficient mobile network design": {
        "authors": [
          "Qibin Hou",
          "Daquan Zhou",
          "Jiashi Feng"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2021/papers/Hou_Coordinate_Attention_for_Efficient_Mobile_Network_Design_CVPR_2021_paper.pdf",
        "ref_texts": "[48] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017.",
        "ref_ids": [
          "48"
        ]
      },
      "Pyramid vision transformer: A versatile backbone for dense prediction without convolutions": {
        "authors": [
          "Wenhai Wang",
          "Enze Xie",
          "Xiang Li",
          "Ping Fan",
          "Kaitao Song",
          "Ding Liang",
          "Tong Lu",
          "Ping Luo",
          "Ling Shao"
        ],
        "url": "https://openaccess.thecvf.com/content/ICCV2021/papers/Wang_Pyramid_Vision_Transformer_A_Versatile_Backbone_for_Dense_Prediction_Without_ICCV_2021_paper.pdf",
        "ref_texts": "[79] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proc. IEEE Conf. Comp. Vis. Patt. Recogn. , 2017. 3",
        "ref_ids": [
          "79"
        ]
      },
      "Per-pixel classification is not all you need for semantic segmentation": {
        "authors": [],
        "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/950a4152c2b4aa3ad78bdd6b366cc179-Paper.pdf",
        "ref_texts": "[46] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017. 1, 2, 6",
        "ref_ids": [
          "46"
        ]
      },
      "Rethinking semantic segmentation from a sequence-to-sequence perspective with transformers": {
        "authors": [
          "Sixiao Zheng",
          "Jiachen Lu",
          "Hengshuang Zhao",
          "Xiatian Zhu",
          "Zekun Luo",
          "Yabiao Wang",
          "Yanwei Fu",
          "Jianfeng Feng",
          "Tao Xiang",
          "Philip H",
          "Li Zhang"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2021/papers/Zheng_Rethinking_Semantic_Segmentation_From_a_Sequence-to-Sequence_Perspective_With_Transformers_CVPR_2021_paper.pdf",
        "ref_texts": "[58] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017. 1,2,5,6,7",
        "ref_ids": [
          "58"
        ]
      },
      "Segmenter: Transformer for semantic segmentation": {
        "authors": [
          "Robin Strudel",
          "Ricardo Garcia",
          "Ivan Laptev",
          "Cordelia Schmid"
        ],
        "url": "https://openaccess.thecvf.com/content/ICCV2021/papers/Strudel_Segmenter_Transformer_for_Semantic_Segmentation_ICCV_2021_paper.pdf",
        "ref_texts": "[65] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid Scene Parsing Network. In CVPR , 2017. 1, 2",
        "ref_ids": [
          "65"
        ]
      },
      "Vision transformers for dense prediction": {
        "authors": [
          "Rene Ranftl",
          "Alexey Bochkovskiy",
          "Vladlen Koltun"
        ],
        "url": "http://openaccess.thecvf.com/content/ICCV2021/papers/Ranftl_Vision_Transformers_for_Dense_Prediction_ICCV_2021_paper.pdf",
        "ref_texts": "[55] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017.",
        "ref_ids": [
          "55"
        ]
      },
      "Repvgg: Making vgg-style convnets great again": {
        "authors": [
          "Xiaohan Ding",
          "Xiangyu Zhang",
          "Ningning Ma",
          "Jungong Han",
          "Guiguang Ding",
          "Jian Sun"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2021/papers/Ding_RepVGG_Making_VGG-Style_ConvNets_Great_Again_CVPR_2021_paper.pdf",
        "ref_texts": "[42] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In 2017 IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2017, Honolulu, HI, USA, July 21-26, 2017 , pages 6230\u20136239. IEEE Computer Society, 2017. 6,8",
        "ref_ids": [
          "42"
        ]
      },
      "Empowering things with intelligence: a survey of the progress, challenges, and opportunities in artificial intelligence of things": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2011.08612",
        "ref_texts": "[78] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "78"
        ]
      },
      "Deep high-resolution representation learning for visual recognition": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1908.07919",
        "ref_texts": "[181] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In CVPR , pages 6230\u20136239, 2017. 1, 2, 6, 7, 11",
        "ref_ids": [
          "181"
        ]
      },
      "Unet 3+: A full-scale connected unet for medical image segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2004.08790",
        "ref_texts": "[1] J. Long, E. Shelhamer and T. Darrell, \u201cFully Convolutional Networks for Semantic Segmentation,\u201d The IEEE Conference on Computer Vision and Pattern Recognition, pp. 3431-3440, 2015. [2] O. Ronneberger, P. Fischer and T. Brox, \u201cU-Net: Convolutional Networks for Biomedical Image Segmentation,\u201d Medical Im-age Computing and Computer-Assisted Intervention, pp.234-241, 2015. [3] H.S. Zhao, J.P. Shi, X.J. Qi, X.G. Wang and J.Y. Jia, \u201cPyramid scene parsing network,\u201d The IEEE Conference on Computer Vi-sion and Pattern Recognition, pp. 2881-2890, 2017. [4] L-C. Chen, G. Papandreou, I. Kokkinos, K. Murphy and A.L. Yuille, \u201cSemantic image segmentation with deep convolutional nets, atrous convolution, and fully connected crfs,\u201d IEEE trans-actions on pattern analysis and machine intelligence, vol.40, no.4, pp: 834-848, 2018. [5] L-C. Chen, G. Papandreou, F. Schroff and H. Adam, \u201cRethink-ing atrous convolution for semantic image segmentation\u201d, arXiv preprint arXiv:1706.05587, 2017. [6] L-C. Chen, Y.K. Zhu, G. Papandreou and H. Adam, \u201cEncoder-decoder with atrous separable convolution for semantic image segmentation,\u201d Proceedings of the European Conference on Computer Vision, 2018. \u2028 [7] Z.W. Zhou, M.M.R. Siddiquee, N. Tajbakhsh and J.M. Liang, \u201cUNet++: A Nested U-Net Architecture for Medical Image Segmentation,\u201d Deep Learning in Medical Image Anylysis and Multimodal Learning for Clinical Decision Support, pp: 3-11, 2018. [8] O.O et al., \u201cAttention u-net: Learning where to look for the pan-creas,\u201d Medical Imaging with Deep Learning, 2018. [9] Z. Wang, E.P. Simoncelli and A.C. Bovik, \u201cMultiscale struc-tural similarity for image quality assessment,\u201d The Thrity-Sev-enth Asilomar Conference on Signals, Systems & Computers, 2003. [10] T.-Y. Lin, P. Goyal, R. Girshick, K.M. He and P. Dollar. \u201cFocal loss for dense object detection,\u201d The IEEE international con-ference on computer vision, pp. 2980-2988, 2017. \u2028 [11] G. Mattyus, W.J. Luo, and R. Urtasun, \u201cDeep-roadmapper: Ex-tracting road topology from aerial images\u201d, The IEEE interna-tional conference on computer vision, 2017. [12] P.-T. Boer et al., \u201cA tutorial on the cross-entropy method,\u201d An-nals of Operations Research, vol.134, no.1, pp. 19\u201367, 2005. \u2028 ",
        "ref_ids": [
          "1",
          "2",
          "3",
          "4",
          "5",
          "6",
          "7",
          "8",
          "9",
          "10",
          "11",
          "12"
        ]
      },
      "U2-Net: Going deeper with nested U-structure for salient object detection": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2005.09007",
        "ref_texts": "[57] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "57"
        ]
      },
      "A survey of deep learning techniques for autonomous driving": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1910.07738",
        "ref_texts": "[157] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid Scene Parsing Network,\u201d in 2017 IEEE Conf. on Computer Vision and Pattern Recognition (CVPR) , 2017, pp. 6230\u20136239.",
        "ref_ids": [
          "157"
        ]
      },
      "Object-contextual representations for semantic segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1909.11065",
        "ref_texts": "80. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: CVPR (2017)",
        "ref_ids": [
          "80"
        ]
      },
      "Self-supervised visual feature learning with deep neural networks: A survey": {
        "authors": [],
        "url": "https://par.nsf.gov/servlets/purl/10340377",
        "ref_texts": "[6] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in CVPR , pp. 2881\u20132890, 2017.",
        "ref_ids": [
          "6"
        ]
      },
      "MultiResUNet: Rethinking the U-Net architecture for multimodal biomedical image segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1902.04049",
        "ref_texts": ""
      },
      "Deep learning for image super-resolution: A survey": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1902.06068",
        "ref_texts": "[115] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in CVPR , 2017.",
        "ref_ids": [
          "115"
        ]
      },
      "Exploring self-attention for image recognition": {
        "authors": [
          "Hengshuang Zhao",
          "Jiaya Jia",
          "Vladlen Koltun"
        ],
        "url": "https://openaccess.thecvf.com/content_CVPR_2020/papers/Zhao_Exploring_Self-Attention_for_Image_Recognition_CVPR_2020_paper.pdf",
        "ref_texts": "[44] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017. 2",
        "ref_ids": [
          "44"
        ]
      },
      "Fda: Fourier domain adaptation for semantic segmentation": {
        "authors": [
          "Yanchao Yang",
          "Stefano Soatto"
        ],
        "url": "https://openaccess.thecvf.com/content_CVPR_2020/papers/Yang_FDA_Fourier_Domain_Adaptation_for_Semantic_Segmentation_CVPR_2020_paper.pdf",
        "ref_texts": "[53] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017. 2",
        "ref_ids": [
          "53"
        ]
      },
      "ResUNet-a: A deep learning framework for semantic segmentation of remotely sensed data": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1904.00592",
        "ref_texts": "1707.03237 ,arXiv:1707.03237 . Taghanaki, S.A., Abhishek, K., Cohen, J.P., Cohen-Adad, J., Hamarneh, G., 2019. Deep semantic segmentation of natural and medical images: A review arXiv:1910.07655 . Vincent, L., Soille, P., 1991. Watersheds in digital spaces: an e flcient algorithm based on immersion simulations. IEEE Transactions on Pattern Analysis & Machine Intelligence , 583\u2013598. V olpi, M., Tuia, D., 2017. Dense semantic labeling of subdecimeter resolution images with convolutional neural networks. IEEE Transactions on Geoscience and Remote Sensing 55, 881\u2013893. Waldner, F., Hansen, M.C., Potapov, P.V ., L \u00a8ow, F., Newby, T., Ferreira, S., Defourny, P., 2017. National-scale cropland mapping based on spectraltemporal features and outdated land cover information. PloS one 12, e0181911. Wen, D., Huang, X., Liu, H., Liao, W., Zhang, L., 2017. Semantic classification of urban trees using very high resolution satellite imagery. IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing 10, 1413\u20131424. Xie, S., Tu, Z., 2015. Holistically-nested edge detection. CoRR abs/1504.06375. URL: http://arxiv.org/abs/1504.06375 , arXiv:1504.06375 . Xie, S.M., Jean, N., Burke, M., Lobell, D.B., Ermon, S., 2015. Trans-fer learning from deep features for remote sensing and poverty mapping. CoRR abs /1510.00098. URL: http://arxiv.org/abs/1510.00098 , arXiv:1510.00098 . Yang, H., Wu, P., Yao, X., Wu, Y ., Wang, B., Xu, Y ., 2018. Building extraction in very high resolution imagery by dense-attention networks. Remote Sensing 10. URL: http://www.mdpi.com/2072-4292/10/11/1768 , doi:10.3390/rs10111768 . Zagoruyko, S., Komodakis, N., 2016. Wide residual networks. CoRR abs /1605.07146. URL: http://arxiv.org/abs/1605.07146 , arXiv:1605.07146 . Zhang, H., Dana, K., Shi, J., Zhang, Z., Wang, X., Tyagi, A., Agrawal, A., 2018. Context encoding for semantic segmentation, in: The IEEE Conference on Computer Vision and Pattern Recognition (CVPR). Zhang, Q., Seto, K.C., 2011. Mapping urbanization dynamics at regional and global scales using multi-temporal dmsp /ols nighttime light data. Remote Sensing of Environment 115, 2320\u20132329. Zhang, Z., Liu, Q., Wang, Y ., 2017. Road extraction by deep residual u-net. CoRR abs /1711.10684. URL: http://arxiv.org/abs/1711.10684 , arXiv:1711.10684 . Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J., 2017a. Pyramid scene parsing network, in: CVPR. Zhao, W., Du, S., Wang, Q., Emery, W.J., 2017b. Contextually guided very-high-resolution imagery classification with semantic segments. ISPRS Journal of Photogrammetry and Remote Sensing 132, 48 \u2013"
      },
      "Multi-scale interactive network for salient object detection": {
        "authors": [
          "Youwei Pang",
          "Xiaoqi Zhao",
          "Lihe Zhang",
          "Huchuan Lu"
        ],
        "url": "https://openaccess.thecvf.com/content_CVPR_2020/papers/Pang_Multi-Scale_Interactive_Network_for_Salient_Object_Detection_CVPR_2020_paper.pdf",
        "ref_texts": "[55] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "55"
        ]
      },
      "Axial-deeplab: Stand-alone axial-attention for panoptic segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2003.07853",
        "ref_texts": "98. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: CVPR (2017) 2",
        "ref_ids": [
          "98"
        ]
      },
      "Semi-supervised semantic segmentation with cross-consistency training": {
        "authors": [
          "Yassine Ouali",
          "Celine Hudelot",
          "Myriam Tami"
        ],
        "url": "https://openaccess.thecvf.com/content_CVPR_2020/papers/Ouali_Semi-Supervised_Semantic_Segmentation_With_Cross-Consistency_Training_CVPR_2020_paper.pdf",
        "ref_texts": "[59] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "59"
        ]
      },
      "A survey on instance segmentation: state of the art": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2007.00047",
        "ref_texts": "128. Zhao H, Shi J, Qi X, Wang X, Jia J Pyramid scene parsing network. In: CVPR, 2017. ",
        "ref_ids": [
          "128"
        ]
      },
      "Self-supervised equivariant attention mechanism for weakly supervised semantic segmentation": {
        "authors": [
          "Yude Wang",
          "Jie Zhang",
          "Meina Kan",
          "Shiguang Shan",
          "Xilin Chen"
        ],
        "url": "https://openaccess.thecvf.com/content_CVPR_2020/papers/Wang_Self-Supervised_Equivariant_Attention_Mechanism_for_Weakly_Supervised_Semantic_Segmentation_CVPR_2020_paper.pdf",
        "ref_texts": "[38] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2017.",
        "ref_ids": [
          "38"
        ]
      },
      "Doubleu-net: A deep convolutional neural network for medical image segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2006.04868",
        "ref_texts": "[14] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition (CVPR) , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "14"
        ]
      },
      "Strip pooling: Rethinking spatial pooling for scene parsing": {
        "authors": [
          "Qibin Hou",
          "Li Zhang",
          "Ming Cheng",
          "Jiashi Feng"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPR_2020/papers/Hou_Strip_Pooling_Rethinking_Spatial_Pooling_for_Scene_Parsing_CVPR_2020_paper.pdf",
        "ref_texts": "[65] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017.",
        "ref_ids": [
          "65"
        ]
      },
      "Hierarchical multi-scale attention for semantic segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2005.10821",
        "ref_texts": "[5]Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "5"
        ]
      },
      "Prototype mixture models for few-shot semantic segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2008.03898",
        "ref_texts": "1. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: IEEE CVPR. (2017) 6230{6239",
        "ref_ids": [
          "1"
        ]
      },
      "Camouflaged object detection": {
        "authors": [
          "Ping Fan",
          "Peng Ji",
          "Guolei Sun",
          "Ming Cheng",
          "Jianbing Shen",
          "Ling Shao"
        ],
        "url": "https://openaccess.thecvf.com/content_CVPR_2020/papers/Fan_Camouflaged_Object_Detection_CVPR_2020_paper.pdf",
        "ref_texts": "[75] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In IEEE CVPR , pages 6230\u20136239, 2017.",
        "ref_ids": [
          "75"
        ]
      },
      "Computer vision for autonomous vehicles: Problems, datasets and state of the art": {
        "authors": [],
        "url": "https://www.nowpublishers.com/article/DownloadSummary/CGV-079",
        "ref_texts": "[791]Zhao, H., J. Shi, X. Qi, X. Wang, and J. Jia (2017). \u201cPyramid scene parsing network\u201d. In: Proc. IEEE Conf. on Computer Vision and Pattern Recognition (CVPR). 6230\u20136239.",
        "ref_ids": [
          "791"
        ]
      },
      "Pvn3d: A deep point-wise 3d keypoints voting network for 6dof pose estimation": {
        "authors": [
          "Yisheng He",
          "Wei Sun",
          "Haibin Huang",
          "Jianran Liu",
          "Haoqiang Fan",
          "Jian Sun"
        ],
        "url": "https://openaccess.thecvf.com/content_CVPR_2020/papers/He_PVN3D_A_Deep_Point-Wise_3D_Keypoints_Voting_Network_for_6DoF_CVPR_2020_paper.pdf",
        "ref_texts": "[54] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017. 4",
        "ref_ids": [
          "54"
        ]
      },
      "Bi-directional cross-modality feature propagation with separation-and-aggregation gate for RGB-D semantic segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2007.09183",
        "ref_texts": "45. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: CVPR (2017)",
        "ref_ids": [
          "45"
        ]
      },
      "A2d2: Audi autonomous driving dataset": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2004.06320",
        "ref_texts": "[31] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017.",
        "ref_ids": [
          "31"
        ]
      },
      "Augfpn: Improving multi-scale feature learning for object detection": {
        "authors": [
          "Chaoxu Guo",
          "Bin Fan",
          "Qian Zhang",
          "Shiming Xiang",
          "Chunhong Pan"
        ],
        "url": "https://openaccess.thecvf.com/content_CVPR_2020/papers/Guo_AugFPN_Improving_Multi-Scale_Feature_Learning_for_Object_Detection_CVPR_2020_paper.pdf",
        "ref_texts": "[41] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017. 2,3,4,7",
        "ref_ids": [
          "41"
        ]
      },
      "CPFNet: Context pyramid fusion network for medical image segmentation": {
        "authors": [],
        "url": "http://www.mipav.net/MIPAV%20Papers/FengSLieee_2020.pdf",
        "ref_texts": "[23] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \"Pyramid scene parsing network,\" in Proceedings of the IEEE conference on computer vision and pattern recognition , 2017, pp. 2881-2890.",
        "ref_ids": [
          "23"
        ]
      },
      "Improving convolutional networks with self-calibrated convolutions": {
        "authors": [
          "Jiang Liu",
          "Qibin Hou",
          "Ming Cheng",
          "Changhu Wang",
          "Jiashi Feng"
        ],
        "url": "https://openaccess.thecvf.com/content_CVPR_2020/papers/Liu_Improving_Convolutional_Networks_With_Self-Calibrated_Convolutions_CVPR_2020_paper.pdf",
        "ref_texts": "[45] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017. 1,2,3",
        "ref_ids": [
          "45"
        ]
      },
      "Unsupervised intra-domain adaptation for semantic segmentation through self-supervision": {
        "authors": [
          "Fei Pan",
          "Inkyu Shin",
          "Francois Rameau",
          "Seokju Lee",
          "In So"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPR_2020/papers/Pan_Unsupervised_Intra-Domain_Adaptation_for_Semantic_Segmentation_Through_Self-Supervision_CVPR_2020_paper.pdf",
        "ref_texts": "[33] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017. 1",
        "ref_ids": [
          "33"
        ]
      },
      "Kimera: an open-source library for real-time metric-semantic localization and mapping": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1910.02490",
        "ref_texts": "[67] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in IEEE Conf. on Computer Vision and Pattern Recognition (CVPR) , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "67"
        ]
      },
      "Feature pyramid transformer": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2007.09451",
        "ref_texts": "15. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: CVPR. (2017)",
        "ref_ids": [
          "15"
        ]
      },
      "Semantic flow for fast and accurate scene parsing": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2002.10120",
        "ref_texts": "67. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: CVPR (2017)",
        "ref_ids": [
          "67"
        ]
      },
      "Gridmask data augmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2001.04086",
        "ref_texts": "[28] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017. 1, 8",
        "ref_ids": [
          "28"
        ]
      },
      "Improving semantic segmentation via decoupled body and edge supervision": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2007.10035",
        "ref_texts": "7. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: CVPR. (2017)",
        "ref_ids": [
          "7"
        ]
      },
      "Multi-scale self-guided attention for medical image segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1906.02849",
        "ref_texts": "[8] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "8"
        ]
      },
      "Disentangled non-local neural networks": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2006.06668",
        "ref_texts": "43. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: Proceedings of the IEEE conference on computer vision and pattern recognition. pp. 2881{2890 (2017)",
        "ref_ids": [
          "43"
        ]
      },
      "In defense of grid features for visual question answering": {
        "authors": [
          "Huaizu Jiang",
          "Ishan Misra",
          "Marcus Rohrbach",
          "Erik Learned",
          "Xinlei Chen"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPR_2020/papers/Jiang_In_Defense_of_Grid_Features_for_Visual_Question_Answering_CVPR_2020_paper.pdf",
        "ref_texts": "[52] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017. 2,8",
        "ref_ids": [
          "52"
        ]
      },
      "Cgnet: A light-weight context guided network for semantic segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1811.08201",
        "ref_texts": "[44] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In CVPR , 2017.",
        "ref_ids": [
          "44"
        ]
      },
      "Deep multimodal fusion by channel exchanging": {
        "authors": [],
        "url": "https://proceedings.neurips.cc/paper_files/paper/2020/file/339a18def9898dd60a634b2ad8fbbd58-Paper.pdf",
        "ref_texts": "[53] Hengshuang Zhao et al. \u201cPyramid Scene Parsing Network\u201d. In: CVPR . 2017.",
        "ref_ids": [
          "53"
        ]
      },
      "Part-aware prototype network for few-shot semantic segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2007.06309",
        "ref_texts": "38. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: the IEEE Conference on Computer Vision and Pattern Recognition(CVPR) (2017) Part-aware Prototype Network for Few-shot Semantic Segmentation Supplementary Material Yongfei Liu1\u22c6, Xiangyi Zhang1\u22c6, Songyang Zhang1, and Xuming He1,2",
        "ref_ids": [
          "38"
        ]
      },
      "Adaptive context selection for polyp segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2301.04799",
        "ref_texts": "20. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: Proceedings of the IEEE Conference on Computer Vision andPa ttern Recognition. pp. 2881\u20132890 (2017)",
        "ref_ids": [
          "20"
        ]
      },
      "Evolution of image segmentation using deep convolutional neural network: A survey": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2001.04074",
        "ref_texts": "[95] H. Zhao, J. Shi, X. Qi, X. Wang, J. Jia, Pyramid scene parsing network, CoRR abs/1612.01105 (2016). arXiv:1612.01105 .",
        "ref_ids": [
          "95"
        ]
      },
      "Self-correction for human parsing": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1910.09777",
        "ref_texts": "[33] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , pages 2881\u20132890, 2017. 3, 6, 7",
        "ref_ids": [
          "33"
        ]
      },
      "Classes matter: A fine-grained adversarial approach to cross-domain semantic segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2007.09222",
        "ref_texts": "36. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: CVPR (2017)",
        "ref_ids": [
          "36"
        ]
      },
      "Uncertainty-aware multi-view co-training for semi-supervised medical image segmentation and domain adaptation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2006.16806",
        "ref_texts": "67.H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In IEEE Conf. on Computer Vision andPattern Recognition (CVPR), pages 2881{2890, 2017.",
        "ref_ids": [
          "67"
        ]
      },
      "LANet: Local attention embedding to improve the semantic segmentation of remote sensing images": {
        "authors": [],
        "url": "https://iris.unitn.it/bitstream/11572/279199/1/LANet_Local%20Attention%20Embedding%20to%20Improve%20the%20Semantic%20Segmentation%20of%20Remote%20Sensing%20Images.pdf",
        "ref_texts": ""
      },
      "Context prior for scene segmentation": {
        "authors": [
          "Changqian Yu",
          "Jingbo Wang",
          "Changxin Gao",
          "Gang Yu",
          "Chunhua Shen",
          "Nong Sang"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPR_2020/papers/Yu_Context_Prior_for_Scene_Segmentation_CVPR_2020_paper.pdf",
        "ref_texts": "[49] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2017. 1,2,3,5,6,7,8",
        "ref_ids": [
          "49"
        ]
      },
      "Squeeze-and-attention networks for semantic segmentation": {
        "authors": [
          "Zilong Zhong",
          "Zhong Qiu",
          "Rene Bidart",
          "Xiaodan Hu",
          "Ibrahim Ben",
          "Zhifeng Li",
          "Shi Zheng",
          "Jonathan Li",
          "Alexander Wong"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPR_2020/papers/Zhong_Squeeze-and-Attention_Networks_for_Semantic_Segmentation_CVPR_2020_paper.pdf",
        "ref_texts": "[41] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In IEEE Conf. on Computer Vision and Pattern Recognition (CVPR) , pages 2881\u20132890, 2017. 1,2, 3,4,5,6,7,8",
        "ref_ids": [
          "41"
        ]
      },
      "A review on deep learning techniques for video prediction": {
        "authors": [
          "Sergiu Oprea"
        ],
        "url": "https://arxiv.org/pdf/2004.05214",
        "ref_texts": "[179] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in CVPR , 2017.",
        "ref_ids": [
          "179"
        ]
      },
      "Modeling the background for incremental learning in semantic segmentation": {
        "authors": [
          "Fabio Cermelli",
          "Massimiliano Mancini",
          "Samuel Rota",
          "Elisa Ricci",
          "Barbara Caputo"
        ],
        "url": "https://openaccess.thecvf.com/content_CVPR_2020/papers/Cermelli_Modeling_the_Background_for_Incremental_Learning_in_Semantic_Segmentation_CVPR_2020_paper.pdf",
        "ref_texts": "[38] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017. 1,2",
        "ref_ids": [
          "38"
        ]
      },
      "Foreground-aware relation network for geospatial object segmentation in high spatial resolution remote sensing imagery": {
        "authors": [
          "Zhuo Zheng",
          "Yanfei Zhong",
          "Junjue Wang",
          "Ailong Ma"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPR_2020/papers/Zheng_Foreground-Aware_Relation_Network_for_Geospatial_Object_Segmentation_in_High_Spatial_CVPR_2020_paper.pdf",
        "ref_texts": "[48] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "48"
        ]
      },
      "A survey on deep learning techniques for stereo-based depth estimation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2006.02535",
        "ref_texts": "[136] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in IEEE CVPR , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "136"
        ]
      },
      "Differential treatment for stuff and things: A simple unsupervised domain adaptation method for semantic segmentation": {
        "authors": [
          "Zhonghao Wang",
          "Mo Yu",
          "Yunchao Wei",
          "Rogerio Feris",
          "Jinjun Xiong",
          "Thomas S. Huang",
          "Honghui Shi"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPR_2020/papers/Wang_Differential_Treatment_for_Stuff_and_Things_A_Simple_Unsupervised_Domain_CVPR_2020_paper.pdf",
        "ref_texts": "[45] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In IEEE CVPR , 2017.",
        "ref_ids": [
          "45"
        ]
      },
      "Eff-unet: A novel architecture for semantic segmentation in unstructured environment": {
        "authors": [
          "Bhakti Baheti",
          "Shubham Innani",
          "Suhas Gajre",
          "Sanjay Talbar"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPRW_2020/papers/w22/Baheti_Eff-UNet_A_Novel_Architecture_for_Semantic_Segmentation_in_Unstructured_Environment_CVPRW_2020_paper.pdf",
        "ref_texts": "[35] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. CoRR , abs/1612.01105, 2016. 3",
        "ref_ids": [
          "35"
        ]
      },
      "Single-stage semantic segmentation from image labels": {
        "authors": [
          "Nikita Araslanov",
          "Stefan Roth"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPR_2020/papers/Araslanov_Single-Stage_Semantic_Segmentation_From_Image_Labels_CVPR_2020_paper.pdf",
        "ref_texts": "[61] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , pages 2881\u20132890, 2017. 5",
        "ref_ids": [
          "61"
        ]
      },
      "Self-supervised monocular trained depth estimation using self-attention and discrete disparity volume": {
        "authors": [
          "Adrian Johnston",
          "Gustavo Carneiro"
        ],
        "url": "https://openaccess.thecvf.com/content_CVPR_2020/papers/Johnston_Self-Supervised_Monocular_Trained_Depth_Estimation_Using_Self-Attention_and_Discrete_Disparity_CVPR_2020_paper.pdf",
        "ref_texts": "[61] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017. 3,6",
        "ref_ids": [
          "61"
        ]
      },
      "Scale match for tiny person detection": {
        "authors": [
          "Xuehui Yu",
          "Yuqi Gong",
          "Nan Jiang",
          "Qixiang Ye"
        ],
        "url": "https://openaccess.thecvf.com/content_WACV_2020/papers/Yu_Scale_Match_for_Tiny_Person_Detection_WACV_2020_paper.pdf",
        "ref_texts": "[30] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "30"
        ]
      },
      "Weakly supervised semantic segmentation with boundary exploration": {
        "authors": [],
        "url": "https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123710341.pdf",
        "ref_texts": "34. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: Proceedings of the IEEE conference on computer vision and pattern recognition. pp. 2881{2890 (2017)",
        "ref_ids": [
          "34"
        ]
      },
      "Shape prior deformation for categorical 6d object pose and size estimation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2007.08454",
        "ref_texts": "43. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: Proceedings of the IEEE conference on computer vision and pattern recognition. pp. 2881{2890 (2017)",
        "ref_ids": [
          "43"
        ]
      },
      "Cascadepsp: Toward class-agnostic and very high-resolution segmentation via global and local refinement": {
        "authors": [
          "Ho Kei",
          "Jihoon Chung",
          "Wing Tai",
          "Keung Tang"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPR_2020/papers/Cheng_CascadePSP_Toward_Class-Agnostic_and_Very_High-Resolution_Segmentation_via_Global_and_CVPR_2020_paper.pdf",
        "ref_texts": "[53] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017.",
        "ref_ids": [
          "53"
        ]
      },
      "Vision-language navigation with self-supervised auxiliary reasoning tasks": {
        "authors": [
          "Fengda Zhu",
          "Yi Zhu",
          "Xiaojun Chang",
          "Xiaodan Liang"
        ],
        "url": "https://openaccess.thecvf.com/content_CVPR_2020/papers/Zhu_Vision-Language_Navigation_With_Self-Supervised_Auxiliary_Reasoning_Tasks_CVPR_2020_paper.pdf",
        "ref_texts": "[45] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , pages 6230\u20136239, 2017. 2",
        "ref_ids": [
          "45"
        ]
      },
      "Content-consistent matching for domain adaptive semantic segmentation": {
        "authors": [],
        "url": "https://opus.lib.uts.edu.au/bitstream/10453/148727/2/ECCV20-camera-ready.pdf",
        "ref_texts": "54. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: IEEE CVPR (2017) 2, 11",
        "ref_ids": [
          "54"
        ]
      },
      "Contextual-relation consistent domain adaptation for semantic segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2007.02424",
        "ref_texts": "57. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: Proceedings of the IEEE conference on computer vision and pattern recognition. pp. 2881{2890 (2017)",
        "ref_ids": [
          "57"
        ]
      },
      "Cars can't fly up in the sky: Improving urban-scene segmentation via height-driven attention networks": {
        "authors": [
          "Sungha Choi",
          "Joanne T. Kim",
          "Jaegul Choo"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPR_2020/papers/Choi_Cars_Cant_Fly_Up_in_the_Sky_Improving_Urban-Scene_Segmentation_CVPR_2020_paper.pdf",
        "ref_texts": "[51] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proc. of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , pages 2881\u20132890, 2017. 1,3",
        "ref_ids": [
          "51"
        ]
      },
      "Cylinder3d: An effective 3d framework for driving-scene lidar semantic segmentation": {
        "authors": [
          "Anonymous Submission"
        ],
        "url": "https://arxiv.org/pdf/2008.01550",
        "ref_texts": "[25] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "25"
        ]
      },
      "Multiscale deep equilibrium models": {
        "authors": [],
        "url": "https://proceedings.neurips.cc/paper_files/paper/2020/file/3812f9a59b634c2a9c574610eaba5bed-Paper.pdf",
        "ref_texts": "[64] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In Computer Vision and Pattern Recognition (CVPR) , 2017.",
        "ref_ids": [
          "64"
        ]
      },
      "Dual super-resolution learning for semantic segmentation": {
        "authors": [
          "Li Wang",
          "Dong Li",
          "Yousong Zhu",
          "Lu Tian",
          "Yi Shan"
        ],
        "url": "https://openaccess.thecvf.com/content_CVPR_2020/papers/Wang_Dual_Super-Resolution_Learning_for_Semantic_Segmentation_CVPR_2020_paper.pdf",
        "ref_texts": "[38] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017. 2,3,5,6",
        "ref_ids": [
          "38"
        ]
      },
      "Temporally distributed networks for fast video semantic segmentation": {
        "authors": [
          "Ping Hu",
          "Fabian Caba",
          "Oliver Wang",
          "Zhe Lin",
          "Stan Sclaroff",
          "Federico Perazzi"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPR_2020/papers/Hu_Temporally_Distributed_Networks_for_Fast_Video_Semantic_Segmentation_CVPR_2020_paper.pdf",
        "ref_texts": "[56] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017. 1,2,3,5,6,7[57] Xizhou Zhu, Dazhi Cheng, Zheng Zhang, Stephen Lin, and Jifeng Dai. An empirical study of spatial attention mechanisms in deep networks. ICCV , 2019. 3",
        "ref_ids": [
          "56",
          "57"
        ]
      },
      "Spatial pyramid based graph reasoning for semantic segmentation": {
        "authors": [
          "Xia Li",
          "Yibo Yang",
          "Qijie Zhao",
          "Tiancheng Shen",
          "Zhouchen Lin",
          "Hong Liu"
        ],
        "url": "https://openaccess.thecvf.com/content_CVPR_2020/papers/Li_Spatial_Pyramid_Based_Graph_Reasoning_for_Semantic_Segmentation_CVPR_2020_paper.pdf",
        "ref_texts": "[56] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "56"
        ]
      },
      "Naive-student: Leveraging semi-supervised learning in video sequences for urban scene segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2005.10266",
        "ref_texts": "92. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: CVPR (2017) 2, 3",
        "ref_ids": [
          "92"
        ]
      },
      "Self-supervised model adaptation for multimodal semantic segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1808.03833",
        "ref_texts": "Abadi M, Agarwal A, Barham P, Brevdo E, Chen Z, Citro C, Corrado GS, Davis A, Dean J, Devin M, Ghemawat S, Goodfellow I, Harp A, Irving G, Isard M, Jia Y , Jozefowicz R, Kaiser L, Kudlur M, Levenberg J, Man \u00b4e D, Monga R, Moore S, Murray D, Olah C, Schuster M, Shlens J, Steiner B, Sutskever I, Talwar K, Tucker P, Vanhoucke V , Vasudevan V , Vi \u00b4egas F, Vinyals O, Warden P, Wattenberg M, Wicke 42 Valada et al. M, Yu Y , Zheng X (2015) TensorFlow: Large-scale machine learning on heterogeneous systems. Software available from tensorflow.org Anwar S, Hwang K, Sung W (2017) Structured pruning of deep convolutional neural networks. ACM Journal on Emerging Technologies in Computing Systems (JETC) 13(3):32 Audebert N, Le Saux B, Lef `evre S (2018) Beyond rgb: Very high resolution urban remote sensing with multimodal deep networks. ISPRS Journal of Photogrammetry and Remote Sensing 140:20\u201332 Badrinarayanan V , Kendall A, Cipolla R (2015) Segnet: A deep convolutional encoder-decoder architecture for image segmentation. arXiv preprint arXiv: 151100561 Boniardi F, Valada A, Mohan R, Caselitz T, Burgard W (2019) Robot localization in floor plans using a room layout edge extraction network. arXiv preprint arXiv:190301804 Brostow GJ, Shotton J, Fauqueur J, Cipolla R (2008) Segmentation and recognition using structure from motion point clouds. In: Forsyth D, Torr P, Zisserman A (eds) Proceedings of the European Conference on Computer Vision Bul`o SR, Porzi L, Kontschieder P (2018) In-place activated batchnorm for memory-optimized training of dnns. In: Proceedings of the Conference on Computer Vision and Pattern Recognition Chattopadhyay A, Sarkar A, Howlader P, Balasubramanian VN (2017) Grad-cam++: Generalized gradient-based visual explanations for deep convolutional networks. arXiv preprint arXiv:171011063 Chen L, Papandreou G, Kokkinos I, Murphy K, Yuille AL (2016) Deeplab: Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected crfs. arxiv preprint arXiv: 160600915 Chen LC, Papandreou G, Schroff F, Adam H (2017) Rethinking atrous convolution for semantic image segmentation. arXiv preprint arXiv:170605587 Chen LC, Collins M, Zhu Y , Papandreou G, Zoph B, Schroff F, Adam H, Shlens J (2018a) Searching for efficient multi-scale architectures for dense image prediction. In: Advances in Neural Information Processing Systems, pp 8713\u20138724 Chen LC, Zhu Y , Papandreou G, Schroff F, Adam H (2018b) Encoderdecoder with atrous separable convolution for semantic image segmentation. arXiv preprint arXiv:180202611 Chollet F (2016) Xception: Deep learning with depthwise separable convolutions. arXiv preprint arXiv:161002357 Cichy RM, Pantazis D, Oliva A (2016) Similarity-based fusion of meg and fmri reveals spatio-temporal dynamics in human cortex during visual object recognition. Cerebral Cortex 26(8):3563\u20133579 Cordts M, Omran M, Ramos S, Rehfeld T, Enzweiler M, Benenson R, Franke U, Roth S, Schiele B (2016) The cityscapes dataset for semantic urban scene understanding. In: Proceedings of the Conference on Computer Vision and Pattern Recognition Couprie C, Farabet C, Najman L, LeCun Y (2013) Indoor semantic segmentation using depth information. arXiv preprint arXiv:13013572 Dai A, Nie\u00dfner M (2018) 3dmv: Joint 3d-multi-view prediction for 3d semantic scene segmentation. arXiv preprint arXiv:180310409 Dai A, Chang AX, Savva M, Halber M, Funkhouser T, Nie\u00dfner M (2017) Scannet: Richly-annotated 3d reconstructions of indoor scenes. In: Proceedings of the Conference on Computer Vision and Pattern Recognition Deng J, Dong W, Socher R, Li LJ, Li K, Fei-Fei L (2009) Imagenet: A large-scale hierarchical image database. In: Proceedings of the Conference on Computer Vision and Pattern Recognition Eitel A, Springenberg JT, Spinello L, Riedmiller MA, Burgard W (2015) Multimodal deep learning for robust rgb-d object recognition. In: Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems Everingham M, Eslami SA, Van Gool L, Williams CK, Winn J, Zisserman A (2015) The pascal visual object classes challenge: A retrospective. International journal of computer vision 111(1):98\u2013136Farabet C, Couprie C, Najman L, LeCun Y (2012) Scene parsing with multiscale feature learning, purity trees, and optimal covers. In: Proceedings of the International Conference on Machine Learning Fei-Fei L, Koch C, Iyer A, Perona P (2004) What do we see when we glance at a scene? Journal of Vision 4(8):863\u2013863 Fulkerson B, Vedaldi A, Soatto S (2009) Class segmentation and object localization with superpixel neighborhoods. In: Proceedings of the International Conference on Computer Vision Ghiasi G, Fowlkes CC (2016) Laplacian pyramid reconstruction and refinement for semantic segmentation. In: European Conference on Computer Vision, pp 519\u2013534 Grangier D, Bottou L, , Collobert R (2009) Deep convolutional networks for scene parsing. In: ICML Workshop on Deep Learning Gupta S, Girshick R, Arbel \u00b4aez P, Malik J (2014) Learning rich features from rgb-d images for object detection and segmentation. In: Proceedings of the European Conference on Computer Vision Hazirbas C, Ma L, Domokos C, Cremers D (2016) Fusenet: incorporating depth into semantic segmentation via fusion-based cnn architecture. In: Proceedings of the Asian Conference on Computer Vision He K, Zhang X, Ren S, Sun J (2015a) Deep residual learning for image recognition. In: Proceedings of the Conference on Computer Vision and Pattern Recognition He K, Zhang X, Ren S, Sun J (2015b) Delving deep into rectifiers: Surpassing human-level performance on imagenet classification. In: Proceedings of the International Conference on Computer Vision He K, Zhang X, Ren S, Sun J (2015c) Spatial pyramid pooling in deep convolutional networks for visual recognition. IEEE transactions on pattern analysis and machine intelligence 37(9):1904\u20131916 He K, Zhang X, Ren S, Sun J (2016) Identity mappings in deep residual networks. In: Proceedings of the European Conference on Computer Vision, pp 630\u2013645 Hermans A, Floros G, Leibe B (2014) Dense 3d semantic mapping of indoor scenes from rgb-d images. In: Proceedings of the IEEE International Conference on Robotics and Automation Hu J, Shen L, Sun G (2017) Squeeze-and-excitation networks. arXiv preprint arXiv:170901507 Hu J, Shen L, Sun G (2018) Squeeze-and-excitation networks. In: Proceedings of the Conference on Computer Vision and Pattern Recognition, pp 7132\u20137141 Huete A, Justice C, Van Leeuwen W (1999) Modis vegetation index (mod13). Algorithm theoretical basis document 3:213 Janoch A, Karayev S, Jia Y , Barron JT, Fritz M, Saenko K, Darrell T"
      },
      "Cross-view semantic segmentation for sensing surroundings": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1906.03560",
        "ref_texts": "[7] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proc. CVPR , 2017.",
        "ref_ids": [
          "7"
        ]
      },
      "MSeg: A composite dataset for multi-domain semantic segmentation": {
        "authors": [
          "John Lambert",
          "Zhuang Liu",
          "Ozan Sener",
          "James Hays",
          "Vladlen Koltun"
        ],
        "url": "https://openaccess.thecvf.com/content_CVPR_2020/papers/Lambert_MSeg_A_Composite_Dataset_for_Multi-Domain_Semantic_Segmentation_CVPR_2020_paper.pdf",
        "ref_texts": "[45] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017. 1",
        "ref_ids": [
          "45"
        ]
      },
      "MAP-Net: Multiple attending path neural network for building footprint extraction from remote sensed imagery": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1910.12060",
        "ref_texts": "[40] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition , pp. 2881\u20132890, 2017.",
        "ref_ids": [
          "40"
        ]
      },
      "Agriculture-vision: A large aerial image database for agricultural pattern analysis": {
        "authors": [
          "Mang Tik",
          "Xingqian Xu",
          "Yunchao Wei",
          "Zilong Huang",
          "Alexander G. Schwing",
          "Robert Brunner",
          "Hrant Khachatrian",
          "Hovnatan Karapetyan",
          "Ivan Dozier",
          "Greg Rose",
          "David Wilson",
          "Adrian Tudor",
          "Naira Hovakimyan",
          "Thomas S. Huang",
          "Honghui Shi"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPR_2020/papers/Chiu_Agriculture-Vision_A_Large_Aerial_Image_Database_for_Agricultural_Pattern_Analysis_CVPR_2020_paper.pdf",
        "ref_texts": "[62] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. InProceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017. 6",
        "ref_ids": [
          "62"
        ]
      },
      "UAVid: A semantic segmentation dataset for UAV imagery": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1810.10438",
        "ref_texts": "[39] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , pages 2881\u20132890, 2017. 9",
        "ref_ids": [
          "39"
        ]
      },
      "Pixel-level cycle association: A new perspective for domain adaptive semantic segmentation": {
        "authors": [],
        "url": "https://proceedings.neurips.cc/paper_files/paper/2020/file/243be2818a23c980ad664f30f48e5d19-Paper.pdf",
        "ref_texts": "[50] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "50"
        ]
      },
      "Deep learning on edge: Extracting field boundaries from satellite images with a convolutional neural network": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1910.12023",
        "ref_texts": "241. Ruder, S., 2017. An overview of multi-task learning in deep neural networks. arXiv preprint arXiv:1706.05098 . Rydberg, A., Borgefors, G., 2001. Integrated method for boundary delineation of agricultural fields in multispectral satellite images. IEEE Transactions on Geoscience and Remote Sensing 39, 2514\u20132520. Salman, N., 2006. Image segmentation based on watershed and edge detection techniques. Int. Arab J. Inf. Technol. 3, 104\u2013110. Shrivakshan, G., Chandrasekar, C., 2012. A comparison of various edge detection techniques used in image processing. International Journal of Computer Science Issues (IJCSI) 9, 269. Soille, P.J., Ansoult, M.M., 1990. Automated basin delineation from digital elevation models using mathematical morphology. Signal Processing 20, 171\u2013182. Turker, M., Kok, E.H., 2013. Field-based sub-boundary extraction from remote sensing imagery using perceptual grouping. ISPRS journal of photogrammetry and remote sensing 79, 106\u2013121. Vuola, A.O., Akram, S.U., Kannala, J., 2019. Mask-rcnn and u-net ensembled for nuclei segmentation. arXiv preprint arXiv:1901.10170 . Waldner, F., Duveiller, G., Defourny, P., 2018. Local adjustments of image spatial resolution to optimize large-area mapping in the era of big data. International journal of applied earth observation and geoinformation 73, 374\u2013385. Waldner, F., Hansen, M.C., Potapov, P.V ., L \u00a8ow, F., Newby, T., Ferreira, S., Defourny, P., 2017. National-scale cropland mapping based on spectraltemporal features and outdated land cover information. PloS one 12, e0181911. Watkins, B., van Niekerk, A., 2019. A comparison of object-based image analysis approaches for field boundary delineation using multi-temporal sentinel2 imagery. Computers and Electronics in Agriculture 158, 294\u2013302. Wilcoxon, F., 1945. Individual comparisons by ranking methods. Biometrics Bulletin 1, 80\u201383. Yan, L., Roy, D., 2014. Automated crop field extraction from multi-temporal web enabled landsat data. Remote Sensing of Environment 144, 42\u201364. Zhan, Q., Molenaar, M., Tempfli, K., Shi, W., 2005. Quality assessment for geo-spatial objects derived from remotely sensed data. International Journal of Remote Sensing 26, 2953\u20132974. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J., 2017. Pyramid scene parsing network, in: Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 2881\u20132890. Zhong, Y ., Giri, C., Thenkabail, P., Teluguntla, P., Congalton, G., R., Yadav, K., Oliphant, J., A., Xiong, J., Poehnelt, J., Smith, C., 2017. Nasa making earth system data records for use in research environments (measures) global food security-support analysis data (gfsad) cropland extent 2015 south america 30 m v001 [data set]. http://dx.doi.org/10.5067/ MEaSUREs/GFSAD/GFSAD30SACE.001 . doi: 10.5067/MEaSUREs/GFSAD/ GFSAD30SACE.001 .",
        "ref_ids": [
          "241"
        ]
      },
      "Learning dynamic routing for semantic segmentation": {
        "authors": [
          "Yanwei Li",
          "Lin Song",
          "Yukang Chen",
          "Zeming Li",
          "Xiangyu Zhang",
          "Xingang Wang",
          "Jian Sun"
        ],
        "url": "https://openaccess.thecvf.com/content_CVPR_2020/papers/Li_Learning_Dynamic_Routing_for_Semantic_Segmentation_CVPR_2020_paper.pdf",
        "ref_texts": "[43] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017. 1,2,8",
        "ref_ids": [
          "43"
        ]
      },
      "Classifying, segmenting, and tracking object instances in video with mask propagation": {
        "authors": [
          "Gedas Bertasius",
          "Lorenzo Torresani"
        ],
        "url": "https://openaccess.thecvf.com/content_CVPR_2020/papers/Bertasius_Classifying_Segmenting_and_Tracking_Object_Instances_in_Video_with_Mask_CVPR_2020_paper.pdf",
        "ref_texts": "[45] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In 2017 IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2017, Honolulu, HI, USA, July 21-26, 2017 , pages 6230\u20136239, 2017. 1",
        "ref_ids": [
          "45"
        ]
      },
      "Intra-class feature variation distillation for semantic segmentation": {
        "authors": [],
        "url": "https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123520341.pdf",
        "ref_texts": "46. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: Proc. of CVPR. pp. 2881{2890 (2017) 1, 4, 9, 11",
        "ref_ids": [
          "46"
        ]
      },
      "Jsenet: Joint semantic segmentation and edge detection network for 3d point clouds": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2007.06888",
        "ref_texts": "13. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: Proceedings of the IEEE conference on computer vision and pattern recognition.",
        "ref_ids": [
          "13"
        ]
      },
      "Defocus deblurring using dual-pixel data": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2005.00305",
        "ref_texts": "37. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: CVPR (2017)",
        "ref_ids": [
          "37"
        ]
      },
      "Referring image segmentation via cross-modal progressive comprehension": {
        "authors": [
          "Shaofei Huang",
          "Tianrui Hui",
          "Si Liu",
          "Guanbin Li",
          "Yunchao Wei",
          "Jizhong Han",
          "Luoqi Liu",
          "Bo Li"
        ],
        "url": "https://openaccess.thecvf.com/content_CVPR_2020/papers/Huang_Referring_Image_Segmentation_via_Cross-Modal_Progressive_Comprehension_CVPR_2020_paper.pdf",
        "ref_texts": "[49] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017.",
        "ref_ids": [
          "49"
        ]
      },
      "Funnel activation for visual recognition": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2007.11824",
        "ref_texts": "48. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: Proceedings of the IEEE conference on computer vision and pattern recognition. pp. 2881{2890 (2017)",
        "ref_ids": [
          "48"
        ]
      },
      "Semantic segmentation of underwater imagery: Dataset and benchmark": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2004.01241",
        "ref_texts": "[35] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid Scene Parsing Network,\u201d in IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "35"
        ]
      },
      "Linguistic structure guided context modeling for referring image segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2010.00515",
        "ref_texts": "43. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: CVPR (2017)",
        "ref_ids": [
          "43"
        ]
      },
      "Vulnerability of Antarctica's ice shelves to meltwater-driven fracture": {
        "authors": [
          "Yao Lai"
        ],
        "url": "https://par.nsf.gov/servlets/purl/10281701",
        "ref_texts": "47. Zhao, H., Shi, J., Qi, X., Wang, X. & Jia, J. Pyramid scene parsing network. In 2017 IEEE Conf. Computer Vision and Pattern Recognition 6230\u20136239 (IEEE, 2017).",
        "ref_ids": [
          "47"
        ]
      },
      "Motionnet: Joint perception and motion prediction for autonomous driving based on bird's eye view maps": {
        "authors": [
          "Pengxiang Wu",
          "Siheng Chen",
          "Dimitris N. Metaxas"
        ],
        "url": "https://openaccess.thecvf.com/content_CVPR_2020/papers/Wu_MotionNet_Joint_Perception_and_Motion_Prediction_for_Autonomous_Driving_Based_CVPR_2020_paper.pdf",
        "ref_texts": "[61] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017. 4",
        "ref_ids": [
          "61"
        ]
      },
      "Viewal: Active learning with viewpoint entropy for semantic segmentation": {
        "authors": [
          "Yawar Siddiqui",
          "Julien Valentin",
          "Matthias Niessner"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPR_2020/papers/Siddiqui_ViewAL_Active_Learning_With_Viewpoint_Entropy_for_Semantic_Segmentation_CVPR_2020_paper.pdf",
        "ref_texts": "[58] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017. 1",
        "ref_ids": [
          "58"
        ]
      },
      "Context-aware feature generation for zero-shot semantic segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2008.06893",
        "ref_texts": "[50] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. 2017. Pyramid Scene Parsing Network. In CVPR .",
        "ref_ids": [
          "50"
        ]
      },
      "FuseSeg: Semantic segmentation of urban scenes based on RGB and thermal data fusion": {
        "authors": [],
        "url": "https://hlwang1124.github.io/data/sun2020fuseseg.pdf",
        "ref_texts": "[37] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR) , Jul. 2017, pp. 6230\u20136239.",
        "ref_ids": [
          "37"
        ]
      },
      "Cascade graph neural networks for RGB-D salient object detection": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2008.03087",
        "ref_texts": "86. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: CVPR (2017)",
        "ref_ids": [
          "86"
        ]
      },
      "Synthesize then compare: Detecting failures and anomalies for semantic segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2003.08440",
        "ref_texts": "50. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, CVPR (2017)",
        "ref_ids": [
          "50"
        ]
      },
      "Guided saliency feature learning for person re-identification in crowded scenes": {
        "authors": [],
        "url": "https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123730358.pdf",
        "ref_texts": "26. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: Proceedings of the IEEE conference on computer vision and pattern recognition (CVPR) (2017)",
        "ref_ids": [
          "26"
        ]
      },
      "Pst900: Rgb-thermal calibration, dataset and segmentation network": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1909.10980",
        "ref_texts": "[24] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "24"
        ]
      },
      "Bi-directional relationship inferring network for referring image segmentation": {
        "authors": [
          "Zhiwei Hu",
          "Guang Feng",
          "Jiayu Sun",
          "Lihe Zhang",
          "Huchuan Lu"
        ],
        "url": "https://openaccess.thecvf.com/content_CVPR_2020/papers/Hu_Bi-Directional_Relationship_Inferring_Network_for_Referring_Image_Segmentation_CVPR_2020_paper.pdf",
        "ref_texts": "[42] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "42"
        ]
      },
      "Inter-image communication for weakly supervised localization": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2008.05096",
        "ref_texts": "45. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: IEEE CVPR. pp. 2881{2890 (2017) 1",
        "ref_ids": [
          "45"
        ]
      },
      "Real-time fusion network for RGB-D semantic segmentation incorporating unexpected obstacle detection for road-driving images": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2002.10570",
        "ref_texts": "[34] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "34"
        ]
      },
      "Attention deeplabv3+: Multi-level context attention mechanism for skin lesion segmentation": {
        "authors": [],
        "url": "https://openreview.net/pdf?id=oMQOHIS1JWy",
        "ref_texts": "34. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: Proceedings of the IEEE conference on computer vision and pattern recognition. pp. 2881\u20132890 (2017)",
        "ref_ids": [
          "34"
        ]
      },
      "Self-supervised scene de-occlusion": {
        "authors": [
          "Xiaohang Zhan",
          "Xingang Pan",
          "Bo Dai",
          "Ziwei Liu",
          "Dahua Lin",
          "Chen Change"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPR_2020/papers/Zhan_Self-Supervised_Scene_De-Occlusion_CVPR_2020_paper.pdf",
        "ref_texts": "[10] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "10"
        ]
      },
      "Rethinking zero-shot video classification: End-to-end training for realistic applications": {
        "authors": [
          "Biagio Brattoli",
          "Joseph Tighe",
          "Fedor Zhdanov",
          "Pietro Perona",
          "Krzysztof Chalupka"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPR_2020/papers/Brattoli_Rethinking_Zero-Shot_Video_Classification_End-to-End_Training_for_Realistic_Applications_CVPR_2020_paper.pdf",
        "ref_texts": "[63] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "63"
        ]
      },
      "Map-guided curriculum domain adaptation and uncertainty-aware evaluation for semantic nighttime image segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2005.14553",
        "ref_texts": "[3] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2017. 1",
        "ref_ids": [
          "3"
        ]
      },
      "Understanding cities with machine eyes: A review of deep computer vision in urban analytics": {
        "authors": [],
        "url": "https://discovery.ucl.ac.uk/id/eprint/10089623/1/Cheng%20understanding%20cities%20with%20machine%20eyes-%20preprint.pdf",
        "ref_texts": "[187] Zhao, H., Shi, J., Qi, X., Wang, X., & Jia, J. (2017). Pyramid scene parsing network. IEEE Conf. on Computer Vision and Pattern Recognition (CVPR) , 2881 \u20132890. ",
        "ref_ids": [
          "187"
        ]
      },
      "Learning fast and robust target models for video object segmentation": {
        "authors": [
          "Andreas Robinson",
          "Felix Jaremo",
          "Martin Danelljan",
          "Fahad Shahbaz",
          "Michael Felsberg"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPR_2020/papers/Robinson_Learning_Fast_and_Robust_Target_Models_for_Video_Object_Segmentation_CVPR_2020_paper.pdf",
        "ref_texts": "[51] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017. 4",
        "ref_ids": [
          "51"
        ]
      },
      "Leafgan: An effective data augmentation method for practical plant disease diagnosis": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2002.10100",
        "ref_texts": "[38] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR) , Jul. 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "38"
        ]
      },
      "Do 2d gans know 3d shape? unsupervised 3d shape reconstruction from 2d image gans": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2011.00844",
        "ref_texts": "11 Published as a conference paper at ICLR 2021 Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , pp. 2881\u20132890, 2017. Hang Zhou, Jihao Liu, Ziwei Liu, Yu Liu, and Xiaogang Wang. Rotate-and-render: Unsupervised photorealistic face rotation from single-view images. In CVPR , 2020. Tinghui Zhou, Matthew Brown, Noah Snavely, and David G Lowe. Unsupervised learning of depth and ego-motion from video. In CVPR , 2017. Jun-Yan Zhu, Philipp Kr \u00a8ahenb \u00a8uhl, Eli Shechtman, and Alexei A Efros. Generative visual manipulation on the natural image manifold. In ECCV , pp. 597\u2013613. Springer, 2016."
      },
      "3d-mininet: Learning a 2d representation from point clouds for fast and efficient 3d lidar semantic segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2002.10893",
        "ref_texts": "[26] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Computer Vision and Pattern Recognition , 2017.",
        "ref_ids": [
          "26"
        ]
      },
      "Joint semantic segmentation and boundary detection using iterative pyramid contexts": {
        "authors": [
          "Mingmin Zhen",
          "Jinglu Wang",
          "Lei Zhou",
          "Shiwei Li",
          "Tianwei Shen",
          "Jiaxiang Shang",
          "Tian Fang",
          "Long Quan"
        ],
        "url": "https://openaccess.thecvf.com/content_CVPR_2020/papers/Zhen_Joint_Semantic_Segmentation_and_Boundary_Detection_Using_Iterative_Pyramid_Contexts_CVPR_2020_paper.pdf",
        "ref_texts": ""
      },
      "Efficient semantic video segmentation with per-frame inference": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2002.11433",
        "ref_texts": "37. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: Proc. IEEE Conf. Comp. Vis. Patt. Recogn. pp. 2881{2890 (2017)",
        "ref_ids": [
          "37"
        ]
      },
      "Segmenting transparent objects in the wild": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2003.13948",
        "ref_texts": "3. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: CVPR. (2017)",
        "ref_ids": [
          "3"
        ]
      },
      "Dynamic feature integration for simultaneous detection of salient object, edge, and skeleton": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2004.08595",
        "ref_texts": "[99] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in CVPR , 2017.",
        "ref_ids": [
          "99"
        ]
      },
      "Psgan: Pose and expression robust spatial-aware gan for customizable makeup transfer": {
        "authors": [
          "Wentao Jiang",
          "Si Liu",
          "Chen Gao",
          "Jie Cao",
          "Ran He",
          "Jiashi Feng",
          "Shuicheng Yan"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPR_2020/papers/Jiang_PSGAN_Pose_and_Expression_Robust_Spatial-Aware_GAN_for_Customizable_Makeup_CVPR_2020_paper.pdf",
        "ref_texts": "[32] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2016. 6",
        "ref_ids": [
          "32"
        ]
      },
      "Multi-path region mining for weakly supervised 3d semantic segmentation on point clouds": {
        "authors": [
          "Jiacheng Wei",
          "Guosheng Lin",
          "Hui Yap",
          "Yi Hung",
          "Lihua Xie"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPR_2020/papers/Wei_Multi-Path_Region_Mining_for_Weakly_Supervised_3D_Semantic_Segmentation_on_CVPR_2020_paper.pdf",
        "ref_texts": "[43] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "43"
        ]
      },
      "Benchmarking the robustness of semantic segmentation models": {
        "authors": [
          "Christoph Kamann",
          "Carsten Rother"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPR_2020/papers/Kamann_Benchmarking_the_Robustness_of_Semantic_Segmentation_Models_CVPR_2020_paper.pdf",
        "ref_texts": "[83] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid Scene Parsing Network. In CVPR , 2017.",
        "ref_ids": [
          "83"
        ]
      },
      "Global context based automatic road segmentation via dilated convolutional neural network": {
        "authors": [
          "Meng Lan"
        ],
        "url": "https://openreview.net/pdf?id=bTUc_EdVY5C",
        "ref_texts": "[41] H. Zhao, J. Shi, X. Qi, X. Wang, J. Jia, Pyramid scene parsing network, in: Proceedings of Conference on Computer Vision and Pattern Recognition, 2 017, pp. 6230\u20136239..",
        "ref_ids": [
          "41"
        ]
      },
      "Semi-supervised segmentation based on error-correcting supervision": {
        "authors": [],
        "url": "https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123740137.pdf",
        "ref_texts": "34. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) (July 2017)",
        "ref_ids": [
          "34"
        ]
      },
      "Inter-slice context residual learning for 3D medical image segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2011.14155",
        "ref_texts": "[14] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "14"
        ]
      },
      "Inter-region affinity distillation for road marking segmentation": {
        "authors": [
          "Yuenan Hou",
          "Zheng Ma",
          "Chunxiao Liu",
          "Wai Hui",
          "Chen Change"
        ],
        "url": "https://openaccess.thecvf.com/content_CVPR_2020/papers/Hou_Inter-Region_Affinity_Distillation_for_Road_Marking_Segmentation_CVPR_2020_paper.pdf",
        "ref_texts": "[30] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In IEEE Conference on Computer Vision and Pattern Recognition, pages 2881\u20132890, 2017. 6",
        "ref_ids": [
          "30"
        ]
      },
      "A multi-task mean teacher for semi-supervised shadow detection": {
        "authors": [
          "Zhihao Chen",
          "Lei Zhu",
          "Liang Wan",
          "Song Wang",
          "Wei Feng",
          "Ann Heng"
        ],
        "url": "https://openaccess.thecvf.com/content_CVPR_2020/papers/Chen_A_Multi-Task_Mean_Teacher_for_Semi-Supervised_Shadow_Detection_CVPR_2020_paper.pdf",
        "ref_texts": "[40] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , pages 2881\u20132890, 2017. 6,7",
        "ref_ids": [
          "40"
        ]
      },
      "Dynamic graph message passing networks": {
        "authors": [
          "Li Zhang",
          "Dan Xu",
          "Anurag Arnab",
          "Philip H"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPR_2020/papers/Zhang_Dynamic_Graph_Message_Passing_Networks_CVPR_2020_paper.pdf",
        "ref_texts": "[41] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017. 8",
        "ref_ids": [
          "41"
        ]
      },
      "World-consistent video-to-video synthesis": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2007.08509",
        "ref_texts": "93. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: IEEE Conference on Computer Vision and Pattern Recognition (CVPR) (2017)",
        "ref_ids": [
          "93"
        ]
      },
      "Triple U-net: Hematoxylin-aware nuclei segmentation with progressive dense feature aggregation": {
        "authors": [
          "Bingchao Zhao"
        ],
        "url": "https://chuhan89.com/publication/zhao-2020-nuclei/zhao-2020-nuclei.pdf",
        "ref_texts": "(8), 1962\u20131971 . Vincent, L. , Soille, P. , 1991. Watersheds in digital spaces: an efficient algorithm based on immersion simulations. IEEE Trans. Pattern Anal. Mach.Intell. (6) 583\u2013598 . Vu, Q.D. , Graham, S. , Kurc, T. , To, M.N.N. , Shaban, M. , Qaiser, T. , Koohbanani, N.A. , Khurram, S.A. , Kalpathy-Cramer, J. , Zhao, T. , et al. , 2019. Methods for segmentation and classification of digital microscopy tissue images. Front. Bioeng. Biotechnol. 7 . Xu, J. , Luo, X. , Wang, G. , Gilmore, H. , Madabhushi, A. , 2016. A deep convolutional neural network for segmenting and classifying epithelial and stromal regions in histopathological images. Neurocomputing 191, 214\u2013223 . Yang, T.-J., Collins, M. D., Zhu, Y., Hwang, J.-J., Liu, T., Zhang, X., Sze, V., Papandreou, G., Chen, L.-C., 2019. DeeperLab: Single-shot image parser. arXiv: 1902.05093 . Yu, K.-H. , Zhang, C. , Berry, G.J. , Altman, R.B. , R\u00e9, C. , Rubin, D.L. , Snyder, M. , 2016. Predicting non-small cell lung cancer prognosis by fully automated microscopic pathology image features. Nat. Commun. 7, 12474 . Zhang, Y. , Yang, L. , Chen, J. , Fredericksen, M. , Hughes, D.P. , Chen, D.Z. , 2017. Deep adversarial networks for biomedical image segmentation utilizing unannotated images. In: International Conference on Medical Image Computing and Computer-Assisted Intervention. Springer, pp. 408\u2013416 . Zhao, H. , Shi, J. , Qi, X. , Wang, X. , Jia, J. , 2017. Pyramid scene parsing network. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2881\u20132890 . Zhou, Y. , Graham, S. , Alemi Koohbanani, N. , Shaban, M. , Heng, P.-A. , Rajpoot, N. , "
      },
      "A multi-scale guided cascade hourglass network for depth completion": {
        "authors": [
          "Ang Li",
          "Zejian Yuan",
          "Yonggen Ling",
          "Wanchao Chi",
          "Chong Zhang"
        ],
        "url": "http://openaccess.thecvf.com/content_WACV_2020/papers/Li_A_Multi-Scale_Guided_Cascade_Hourglass_Network_for_Depth_Completion_WACV_2020_paper.pdf",
        "ref_texts": "[25] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition (CVPR) , 2017.",
        "ref_ids": [
          "25"
        ]
      },
      "Edgestereo: An effective multi-task learning network for stereo matching and edge detection": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1903.01700",
        "ref_texts": "66. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: CVPR, pp. 2881\u20132890 (2017)",
        "ref_ids": [
          "66"
        ]
      },
      "Interactive object segmentation with inside-outside guidance": {
        "authors": [
          "Shiyin Zhang",
          "Jun Hao",
          "Yunchao Wei",
          "Shikui Wei",
          "Yao Zhao"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPR_2020/papers/Zhang_Interactive_Object_Segmentation_With_Inside-Outside_Guidance_CVPR_2020_paper.pdf",
        "ref_texts": "[68] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017.",
        "ref_ids": [
          "68"
        ]
      },
      "'Squeeze & excite'guided few-shot segmentation of volumetric images": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1902.01314",
        "ref_texts": "References. S. J\u0013 egou, M. Drozdzal, D. Vazquez, A. Romero, Y. Bengio, The one hundred layers tiramisu: Fully convolutional densenets for semantic segmentation, in: Computer Vision and Pattern Recognition Workshops (CVPRW), 2017 IEEE Conference on, IEEE, pp. 1175{1183. H. Zhao, J. Shi, X. Qi, X. Wang, J. Jia, Pyramid scene parsing network, in: IEEE Conf. on Computer Vision and Pattern Recognition (CVPR), pp. 2881{2890. J. Long, E. Shelhamer, T. Darrell, Fully convolutional networks for semantic segmentation, in: Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 3431{3440. H. Noh, S. Hong, B. Han, Learning deconvolution network for semantic segmentation, in: Proceedings of the IEEE international conference on computer vision, pp. 1520{1528. O. Ronneberger, P. Fischer, T. Brox, U-net: Convolutional networks for biomedical image segmentation, in: International Conference on Medical image computing and computer-assisted intervention 2015, Springer, pp. 234{241.F. Milletari, N. Navab, S.-A. Ahmadi, V-net: Fully convolutional neural networks for volumetric medical image segmentation, in: 3D Vision (3DV), 2016 Fourth International Conference on, IEEE, pp. 565{571. A. Shaban, S. Bansal, Z. Liu, I. Essa, B. Boots, One-shot learning for semantic segmentation, arXiv preprint arXiv:1709.03410 (2017). K. Rakelly, E. Shelhamer, T. Darrell, A. A. Efros, S. Levine, Fewshot segmentation propagation with guided networks, arXiv preprint arXiv:1806.07373 (2018). L. Fei-Fei, R. Fergus, P. Perona, One-shot learning of object categories, IEEE transactions on pattern analysis and machine intelligence 28 (2006) 594{611. E. G. Miller, N. E. Matsakis, P. A. Viola, Learning from one example through shared densities on transforms, in: Computer Vision and Pattern Recognition, 2000. Proceedings. IEEE Conference on, volume 1, IEEE, pp. 464{471. L. Fei-Fei, Knowledge transfer in learning to recognize visual objects classes, in: Proceedings of the International Conference on Development and Learning (ICDL), p. 11. A. G. Roy, N. Navab, C. Wachinger, Recalibrating fully convolutional networks with spatial and channel squeeze & excitationblocks, IEEE Transactions on Medical Imaging (2018a). A. G. Roy, N. Navab, C. Wachinger, Concurrent spatial and channel squeeze & excitation in fully convolutional networks, arXiv preprint arXiv:1803.02579 (2018b). E. Bart, S. Ullman, Cross-generalization: Learning novel classes from a single example by feature replacement, in: Computer Vision and Pattern Recognition, 2005. CVPR 2005. IEEE Computer Society Conference on, volume 1, IEEE, pp. 672{679. B. Hariharan, R. Girshick, Low-shot visual recognition by shrinking and hallucinating features, in: Proc. of IEEE Int. Conf. on Computer Vision (ICCV), Venice, Italy. L. Bertinetto, J. F. Henriques, J. Valmadre, P. Torr, A. Vedaldi, Learning feed-forward one-shot learners, in: Advances in Neural Information Processing Systems, pp. 523{531. Y.-X. Wang, M. Hebert, Learning to learn: Model regression net14 Table 10: The segmentation performance (per-fold and mean Dice score) on silver corpus (validation set and test set combined), by using difierent volumes (Volume ID indicated in the ffrst column) as the support volume. Left and Right are abbreviated as L. and R. Psoas Muscle is abbreviated as P.M. Support Dice Score on rest of 15 volumes of the Dataset Volume ID Liver Spleen L/R kidney L/R P.M. Mean 10000100 1CTce ThAb 0:748 0:550 0:445 0:454 0:550"
      },
      "Who2com: Collaborative perception via learnable handshake communication": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2003.09575",
        "ref_texts": "[40] Hengshuang Zhao et al. \u201cPyramid Scene Parsing Network\u201d. In: The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) . July 2017.",
        "ref_ids": [
          "40"
        ]
      },
      "Don't hit me! glass detection in real-world scenes": {
        "authors": [
          "Haiyang Mei",
          "Xin Yang",
          "Yang Wang",
          "Yuanyuan Liu",
          "Shengfeng He",
          "Qiang Zhang",
          "Xiaopeng Wei",
          "Rynson W"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPR_2020/papers/Mei_Dont_Hit_Me_Glass_Detection_in_Real-World_Scenes_CVPR_2020_paper.pdf",
        "ref_texts": "[46] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017.",
        "ref_ids": [
          "46"
        ]
      },
      "Deep-learning-based image segmentation integrated with optical microscopy for automatically searching for two-dimensional materials": {
        "authors": [
          "Satoru Masubuchi"
        ],
        "url": "https://www.nature.com/articles/s41699-020-0137-z.pdf",
        "ref_texts": "30. Zhao, H., Shi, J., Qi, X., Wang, X. & Jia, J. Pyramid scene parsing network. Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , 2881 \u20132890 (IEEE, 2017).",
        "ref_ids": [
          "30"
        ]
      },
      "3d semi-supervised learning with uncertainty-aware multi-view co-training": {
        "authors": [
          "Yingda Xia",
          "Fengze Liu",
          "Dong Yang",
          "Jinzheng Cai",
          "Lequan Yu",
          "Zhuotun Zhu",
          "Daguang Xu",
          "Alan Yuille",
          "Holger Roth"
        ],
        "url": "http://openaccess.thecvf.com/content_WACV_2020/papers/Xia_3D_semi-supervised_learning_with_uncertainty-aware_multi-view_co-training_WACV_2020_paper.pdf",
        "ref_texts": "[39] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In IEEE Conf. on Computer Vision and Pattern Recognition (CVPR) , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "39"
        ]
      },
      "Dense dilated convolutions' merging network for land cover classification": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2003.04027",
        "ref_texts": "[4] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "4"
        ]
      },
      "Cross-domain semantic segmentation via domain-invariant interactive relation transfer": {
        "authors": [
          "Fengmao Lv",
          "Tao Liang",
          "Xiang Chen",
          "Guosheng Lin"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPR_2020/papers/Lv_Cross-Domain_Semantic_Segmentation_via_Domain-Invariant_Interactive_Relation_Transfer_CVPR_2020_paper.pdf",
        "ref_texts": "[44] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "44"
        ]
      },
      "BSUV-Net: A fully-convolutional neural network for background subtraction of unseen videos": {
        "authors": [
          "Ozan Tezcan",
          "Prakash Ishwar",
          "Janusz Konrad"
        ],
        "url": "http://openaccess.thecvf.com/content_WACV_2020/papers/Tezcan_BSUV-Net_A_Fully-Convolutional_Neural_Network_for_Background_Subtraction_of_Unseen_WACV_2020_paper.pdf",
        "ref_texts": "[32] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In Proc. IEEE Conf. Computer Vision Pattern Recognition , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "32"
        ]
      },
      "Range conditioned dilated convolutions for scale invariant 3d object detection": {
        "authors": [
          "Anonymous Submission"
        ],
        "url": "https://arxiv.org/pdf/2005.09927",
        "ref_texts": ""
      },
      "Class-wise dynamic graph convolution for semantic segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2007.09690",
        "ref_texts": "42. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: Proceedings of the IEEE conference on computer vision and pattern recognition. pp. 2881{2890 (2017)",
        "ref_ids": [
          "42"
        ]
      },
      "Real-time high-performance semantic image segmentation of urban street scenes": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2003.08736",
        "ref_texts": "[11] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), Jun. 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "11"
        ]
      },
      "Hierarchical human parsing with typed part-relation reasoning": {
        "authors": [
          "Wenguan Wang",
          "Hailong Zhu",
          "Jifeng Dai",
          "Yanwei Pang",
          "Jianbing Shen",
          "Ling Shao"
        ],
        "url": "https://openaccess.thecvf.com/content_CVPR_2020/papers/Wang_Hierarchical_Human_Parsing_With_Typed_Part-Relation_Reasoning_CVPR_2020_paper.pdf",
        "ref_texts": "[70] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017. 6,7",
        "ref_ids": [
          "70"
        ]
      },
      "Beyond the parts: Learning multi-view cross-part correlation for vehicle re-identification": {
        "authors": [],
        "url": "https://xinchenliu.com/papers/2020_ACMMM_PCRNet.pdf",
        "ref_texts": "[39] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. 2017. Pyramid Scene Parsing Network. In IEEE Conference on Computer Vision and Pattern Recognition . 6230\u20136239.",
        "ref_ids": [
          "39"
        ]
      },
      "Affinity space adaptation for semantic segmentation across domains": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2009.12559",
        "ref_texts": "[3] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proc. of IEEE Intl. Conf. on Computer Vision and Pattern Recognition , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "3"
        ]
      },
      "Global context networks": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2012.13375",
        "ref_texts": "[24] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "24"
        ]
      },
      "Revisiting feature fusion for RGB-T salient object detection": {
        "authors": [],
        "url": "https://pure.aber.ac.uk/portal/files/38644132/RGB_T_final.pdf",
        "ref_texts": "[49] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "49"
        ]
      },
      "Problems and opportunities in training deep learning software systems: An analysis of variance": {
        "authors": [
          "Hung Viet",
          "Shangshu Qian",
          "Jiannan Wang",
          "Thibaud Lutellier",
          "Jonathan Rosenthal",
          "Lin Tan",
          "Yaoliang Yu",
          "Nachiappan Nagappan"
        ],
        "url": "https://par.nsf.gov/servlets/purl/10252876",
        "ref_texts": ""
      },
      "Image based virtual try-on network from unpaired data": {
        "authors": [
          "Assaf Neuberger",
          "Eran Borenstein",
          "Bar Hilleli",
          "Eduard Oks",
          "Sharon Alpert"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPR_2020/papers/Neuberger_Image_Based_Virtual_Try-On_Network_From_Unpaired_Data_CVPR_2020_paper.pdf",
        "ref_texts": "[37] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017. 4",
        "ref_ids": [
          "37"
        ]
      },
      "AUNet: attention-guided dense-upsampling networks for breast mass segmentation in whole mammograms": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1810.10151",
        "ref_texts": "[28] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In In IEEE CVPR , pages 2881{2890, 2017.",
        "ref_ids": [
          "28"
        ]
      },
      "Spsequencenet: Semantic segmentation network on 4d point clouds": {
        "authors": [
          "Hanyu Shi",
          "Guosheng Lin",
          "Hao Wang",
          "Yi Hung",
          "Zhenhua Wang"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPR_2020/papers/Shi_SpSequenceNet_Semantic_Segmentation_Network_on_4D_Point_Clouds_CVPR_2020_paper.pdf",
        "ref_texts": "[27] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "27"
        ]
      },
      "Learning from scale-invariant examples for domain adaptation in semantic segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2007.14449",
        "ref_texts": "32. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: Proceedings of the IEEE conference on computer vision and pattern recognition. pp. 2881{2890 (2017)",
        "ref_ids": [
          "32"
        ]
      },
      "Curriculum model adaptation with synthetic and real data for semantic foggy scene understanding": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1901.01415",
        "ref_texts": "75. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: IEEE Conference on Computer Vision and Pattern Recognition (CVPR) (2017)",
        "ref_ids": [
          "75"
        ]
      },
      "Tensor low-rank reconstruction for semantic segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2008.00490",
        "ref_texts": "51.Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: Proc. CVPR. pp. 2881{2890 (2017) 2, 4, 5, 7, 9, 10, 11, 12, 13",
        "ref_ids": [
          "51"
        ]
      },
      "Label-driven reconstruction for domain adaptation in semantic segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2003.04614",
        "ref_texts": "59.Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR). pp. 2881\u20132890 (2017)",
        "ref_ids": [
          "59"
        ]
      },
      "Kprnet: Improving projection-based lidar semantic segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2007.12668",
        "ref_texts": "15. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: CVPR. pp. 2881{2890 (2017)",
        "ref_ids": [
          "15"
        ]
      },
      "An end-to-end shape modeling framework for vectorized building outline generation from aerial images": {
        "authors": [
          "Qi Chen"
        ],
        "url": "https://daoqiqi.github.io/assets/img/achievements/polygonCNN.pdf",
        "ref_texts": "6584\u20136592. http://dx.doi.org/10.1109/CVPR.2017.697. Zhang, C., Hu, Y., Cui, W., 2018. Semiautomatic right-angle building extraction from very high-resolution aerial images using graph cuts with star shape constraint and regularization. J. Appl. Remote Sens. http://dx.doi.org/10.1117/1.jrs.12.026005. Zhao, K., Kang, J., Jung, J., Sohn, G., Street, K., Drive, M., York, N., Mb, O.N., 2018. Building extraction from satellite images using mask R-CNN with building boundary regularization. In: CVPR Workshops. pp. 247\u2013251, URL https://www.topcoder.com/ spacenet. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J., Limited, S.G., 2017. Pyramid scene parsing network. In: Proceedings 30th IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2017. ISBN: 9781538604571, http://dx.doi.org/10.1109/CVPR."
      },
      "VisualEchoes: Spatial Image Representation Learning Through Echolocation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2005.01616",
        "ref_texts": "90. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: CVPR (2017)",
        "ref_ids": [
          "90"
        ]
      },
      "Reparameterizing convolutions for incremental multi-task learning without task interference": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2007.12540",
        "ref_texts": "67. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: Proceedings of the IEEE conference on computer vision and pattern recognition. pp. 2881{2890 (2017)",
        "ref_ids": [
          "67"
        ]
      },
      "Graph-guided architecture search for real-time semantic segmentation": {
        "authors": [
          "Peiwen Lin",
          "Peng Sun",
          "Guangliang Cheng",
          "Sirui Xie",
          "Xi Li",
          "Jianping Shi"
        ],
        "url": "https://openaccess.thecvf.com/content_CVPR_2020/papers/Lin_Graph-Guided_Architecture_Search_for_Real-Time_Semantic_Segmentation_CVPR_2020_paper.pdf",
        "ref_texts": "[51] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "51"
        ]
      },
      "Morefusion: Multi-object reasoning for 6d pose estimation from volumetric fusion": {
        "authors": [
          "Kentaro Wada",
          "Edgar Sucar",
          "Stephen James",
          "Daniel Lenton",
          "Andrew J. Davison"
        ],
        "url": "https://openaccess.thecvf.com/content_CVPR_2020/papers/Wada_MoreFusion_Multi-object_Reasoning_for_6D_Pose_Estimation_from_Volumetric_Fusion_CVPR_2020_paper.pdf",
        "ref_texts": "[32] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2017. 4",
        "ref_ids": [
          "32"
        ]
      },
      "Semantic-aware scene recognition": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1909.02410",
        "ref_texts": "[30] H. Zhao, J. Shi, X. Qi, X. Wang, J. Jia, Pyramid scene parsing network, in: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2017, pp. 2881{2890.",
        "ref_ids": [
          "30"
        ]
      },
      "DeFusionNET: Defocus blur detection via recurrently fusing and refining discriminative multi-scale deep features": {
        "authors": [
          "Chang Tang",
          "Xinwang Liu",
          "Xiao Zheng",
          "Wanqing Li",
          "Jian Xiong",
          "Lizhe Wang",
          "Albert Y. Zomaya",
          "Antonella Longo"
        ],
        "url": "https://xinwangliu.github.io/papers/2_5_ChangTang_TPAMI22.pdf",
        "ref_texts": "[56] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proc. IEEE Conf. Comput. Vis. Pattern Recognit. , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "56"
        ]
      },
      "Joint self-attention and scale-aggregation for self-calibrated deraining network": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2008.02763",
        "ref_texts": "[30] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. 2017. Pyramid Scene Parsing Network. In IEEE Conference on Computer Vision and Pattern Recognition . 6230\u20136239.",
        "ref_ids": [
          "30"
        ]
      },
      "Uncertainty-aware learning for zero-shot semantic segmentation": {
        "authors": [],
        "url": "https://proceedings.neurips.cc/paper/2020/file/f73b76ce8949fe29bf2a537cfa420e8f-Paper.pdf",
        "ref_texts": "[63] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In CVPR , 2017.",
        "ref_ids": [
          "63"
        ]
      },
      "One shot 3d photography": {
        "authors": [],
        "url": "https://dl.acm.org/doi/pdf/10.1145/3386569.3392420",
        "ref_texts": "2018. Monocular Relative Depth Perception With Web Stereo Data Supervision. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR) . Richard Zhang, Phillip Isola, Alexei A. Efros, Eli Shechtman, and Oliver Wang. 2018. The Unreasonable Effectiveness of Deep Features as a Perceptual Metric. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR) . Yinda Zhang, Shuran Song, Ersin Yumer, Manolis Savva, Joon-Young Lee, Hailin Jin, and Thomas Funkhouser. 2017. Physically-Based Rendering for Indoor Scene Understanding Using Convolutional Neural Networks. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR) . Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. 2017. Pyramid scene parsing network. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR) . 2881\u20132890. Tinghui Zhou, Richard Tucker, John Flynn, Graham Fyffe, and Noah Snavely. 2018. Stereo Magnification: Learning View Synthesis Using Multiplane Images. ACM Transactions on Graphics (TOG) 37, 4 (2018), article no. 65. C. Lawrence Zitnick, Sing Bing Kang, Matthew Uyttendaele, Simon Winder, and Richard Szeliski. 2004. High-quality Video View Interpolation Using a Layered Representation. ACM Trans. Graph. 23, 3 (2004), 600\u2013608. ACM Trans. Graph., Vol. 39, No. 4, Article 76. Publication date: July 2020.",
        "ref_ids": [
          "2018"
        ]
      },
      "Semi-supervised semantic segmentation via strong-weak dual-branch network": {
        "authors": [],
        "url": "https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123500766.pdf",
        "ref_texts": "38.Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. CVPR pp. 6230\u20136239 (2016)",
        "ref_ids": [
          "38"
        ]
      },
      "Revisiting multi-task learning in the deep learning era": {
        "authors": [],
        "url": "https://homes.esat.kuleuven.be/~konijn/publications/2020/vandenhende.pdf",
        "ref_texts": "[54] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in CVPR , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "54"
        ]
      },
      "Automatic prostate and prostate zones segmentation of magnetic resonance images using DenseNet-like U-net": {
        "authors": [
          "Nader Aldoj"
        ],
        "url": "https://www.nature.com/articles/s41598-020-71080-0.pdf",
        "ref_texts": ""
      },
      "Hierarchical pyramid diverse attention networks for face recognition": {
        "authors": [
          "Qiangchang Wang",
          "Tianyi Wu",
          "He Zheng",
          "Guodong Guo"
        ],
        "url": "https://openaccess.thecvf.com/content_CVPR_2020/papers/Wang_Hierarchical_Pyramid_Diverse_Attention_Networks_for_Face_Recognition_CVPR_2020_paper.pdf",
        "ref_texts": "[43] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017.[44] Heliang Zheng, Jianlong Fu, Tao Mei, and Jiebo Luo. Learning multi-attention convolutional neural network for finegrained image recognition. In proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 5209\u20135217, 2017.",
        "ref_ids": [
          "43",
          "44"
        ]
      },
      "From depth what can you see? Depth completion via auxiliary image reconstruction": {
        "authors": [
          "Kaiyue Lu",
          "Nick Barnes",
          "Saeed Anwar",
          "Liang Zheng"
        ],
        "url": "https://openaccess.thecvf.com/content_CVPR_2020/papers/Lu_From_Depth_What_Can_You_See_Depth_Completion_via_Auxiliary_CVPR_2020_paper.pdf",
        "ref_texts": "[47] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017. 8",
        "ref_ids": [
          "47"
        ]
      },
      "Offline computer-aided diagnosis for Glaucoma detection using fundus images targeted at mobile devices": {
        "authors": [],
        "url": "https://web.fe.up.pt/~jsc/publications/journals/2020JoseMartinsCMPB.pdf",
        "ref_texts": "[17] H. Zhao, J. Shi, X. Qi, X. Wang, J. Jia, Pyramid scene parsing network, in: Proceedings 30th IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2017, January, 2017, pp. 6230\u20136239, doi: 10.1109/CVPR.2017.660 . arXiv:1612.01105v2 . ",
        "ref_ids": [
          "17"
        ]
      },
      "An objective comparison of detection and segmentation algorithms for artefacts in clinical endoscopy": {
        "authors": [
          "Sharib Ali"
        ],
        "url": "https://www.nature.com/articles/s41598-020-59413-5.pdf",
        "ref_texts": ""
      },
      "Edge-aware graph representation learning and reasoning for face parsing": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2007.11240",
        "ref_texts": "35. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: Proceedings of the IEEE international conference on computer vision. (2017) 2881{",
        "ref_ids": [
          "35"
        ]
      },
      "Weakly-supervised semantic segmentation by iterative affinity learning": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2002.08098",
        "ref_texts": "1, 3, 7, 9 Wei YC, Cheng CK, et al (1989) Towards eflcient hierarchical designs by ratio cut partitioning. In: Weakly-Supervised Semantic Segmentation by Iterative Aflnity Learning 15 IEEE International Conference on Computer-Aided Design, pp 298{301 3 Zhao H, Shi J, Qi X, Wang X, Jia J (2017) Pyramid scene parsing network. In: Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp 2881{2890 1 Zhou B, Khosla A, Lapedriza A, Oliva A, Torralba A"
      },
      "VATLD: A Visual Analytics System to Assess, Understand and Improve Traffic Light Detection": {
        "authors": [
          "Liang Gou",
          "Lincan Zou",
          "Nanxiang Li",
          "Michael Hofmann",
          "Arvind Kumar",
          "Axel Wendt",
          "Liu Ren"
        ],
        "url": "https://arxiv.org/pdf/2009.12975",
        "ref_texts": "[47] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. InProceedings of the IEEE conference on computer vision and pattern recognition , pp. 2881\u20132890, 2017.",
        "ref_ids": [
          "47"
        ]
      },
      "Fishing net: Future inference of semantic heatmaps in grids": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2006.09917",
        "ref_texts": "[19] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. CoRR , abs/1612.01105, 2016. 2",
        "ref_ids": [
          "19"
        ]
      },
      "EfficientFCN: Holistically-guided decoding for semantic segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2008.10487",
        "ref_texts": "28. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: Proceedings of the IEEE conference on computer vision and pattern recognition. pp. 2881{2890 (2017) 4, 11, 13",
        "ref_ids": [
          "28"
        ]
      },
      "Ddd20 end-to-end event camera driving dataset: Fusing frames and events with deep learning for improved steering prediction": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2005.08605",
        "ref_texts": "[11] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2017.",
        "ref_ids": [
          "11"
        ]
      },
      "Semi-supervised semantic image segmentation with self-correcting networks": {
        "authors": [
          "Mostafa S. Ibrahim",
          "Arash Vahdat",
          "Mani Ranjbar",
          "William G. Macready"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPR_2020/papers/Ibrahim_Semi-Supervised_Semantic_Image_Segmentation_With_Self-Correcting_Networks_CVPR_2020_paper.pdf",
        "ref_texts": "[71] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2017. 1,2",
        "ref_ids": [
          "71"
        ]
      },
      "Beyond short-term snippet: Video relation detection with spatio-temporal global context": {
        "authors": [
          "Chenchen Liu",
          "Yang Jin",
          "Kehan Xu",
          "Guoqiang Gong",
          "Yadong Mu"
        ],
        "url": "https://openaccess.thecvf.com/content_CVPR_2020/papers/Liu_Beyond_Short-Term_Snippet_Video_Relation_Detection_With_Spatio-Temporal_Global_Context_CVPR_2020_paper.pdf",
        "ref_texts": "[53] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In CVPR , 2017. 1",
        "ref_ids": [
          "53"
        ]
      },
      "A brief survey of visual saliency detection": {
        "authors": [],
        "url": "https://researchportal.port.ac.uk/files/20884767/A_Brief_Survey_of_Visual_Saliency_Detection_pp.pdf",
        "ref_texts": " 126. Zhao H, Shi J, Qi X, Wang X, Jia J Pyramid scene parsing network. In: IEEE Conf. on Computer Vision and Pattern Recognition (CVPR), 2017. pp 2881 -2890 "
      },
      "Renovating parsing R-CNN for accurate multiple human parsing": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2009.09447",
        "ref_texts": "44. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: CVPR (2017) 7",
        "ref_ids": [
          "44"
        ]
      },
      "Geonet++: Iterative geometric neural network with edge-aware refinement for joint depth and surface normal estimation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2012.06980",
        "ref_texts": "[40] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proc. IEEE Conf. Comput. Vis. Pattern Recog. , 2017, pp.",
        "ref_ids": [
          "40"
        ]
      },
      "HS-ResNet: Hierarchical-split block on convolutional neural network": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2010.07621",
        "ref_texts": "[41] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "41"
        ]
      },
      "Knowledge transfer via dense cross-layer mutual-distillation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2008.07816",
        "ref_texts": "59. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: CVPR (2017)",
        "ref_ids": [
          "59"
        ]
      },
      "Distilled semantics for comprehensive scene understanding from videos": {
        "authors": [
          "Fabio Tosi",
          "Filippo Aleotti",
          "Pierluigi Zama",
          "Matteo Poggi",
          "Samuele Salti",
          "Luigi Di",
          "Stefano Mattoccia"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPR_2020/papers/Tosi_Distilled_Semantics_for_Comprehensive_Scene_Understanding_from_Videos_CVPR_2020_paper.pdf",
        "ref_texts": "[93] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017. 2",
        "ref_ids": [
          "93"
        ]
      },
      ", , Alpha Matting": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2003.07711",
        "ref_texts": "40. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (July 2017)",
        "ref_ids": [
          "40"
        ]
      },
      "Search what you want: Barrier panelty nas for mixed precision quantization": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2007.10026",
        "ref_texts": "26. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: IEEE Conf. on Computer Vision and Pattern Recognition (CVPR). pp. 2881{2890",
        "ref_ids": [
          "26"
        ]
      },
      "Banet: Bidirectional aggregation network with occlusion handling for panoptic segmentation": {
        "authors": [
          "Yifeng Chen",
          "Guangchen Lin",
          "Songyuan Li",
          "Omar Bourahla",
          "Yiming Wu",
          "Fangfang Wang",
          "Junyi Feng",
          "Mingliang Xu",
          "Xi Li"
        ],
        "url": "https://openaccess.thecvf.com/content_CVPR_2020/papers/Chen_BANet_Bidirectional_Aggregation_Network_With_Occlusion_Handling_for_Panoptic_Segmentation_CVPR_2020_paper.pdf",
        "ref_texts": "[41] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In CVPR , pages 6230\u20136239, 2017.",
        "ref_ids": [
          "41"
        ]
      },
      "Knowledge transfer dehazing network for nonhomogeneous dehazing": {
        "authors": [
          "Haiyan Wu",
          "Jing Liu",
          "Yuan Xie",
          "Yanyun Qu",
          "Lizhuang Ma"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPRW_2020/papers/w31/Wu_Knowledge_Transfer_Dehazing_Network_for_NonHomogeneous_Dehazing_CVPRW_2020_paper.pdf",
        "ref_texts": "[25] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "25"
        ]
      },
      "Progressive mirror detection": {
        "authors": [
          "Jiaying Lin",
          "Guodong Wang",
          "Rynson W"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPR_2020/papers/Lin_Progressive_Mirror_Detection_CVPR_2020_paper.pdf",
        "ref_texts": "[32] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017.",
        "ref_ids": [
          "32"
        ]
      },
      "Fast video object segmentation with temporal aggregation network and dynamic template matching": {
        "authors": [
          "Xuhua Huang",
          "Jiarui Xu",
          "Wing Tai",
          "Keung Tang"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPR_2020/papers/Huang_Fast_Video_Object_Segmentation_With_Temporal_Aggregation_Network_and_Dynamic_CVPR_2020_paper.pdf",
        "ref_texts": "[59] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017. 2",
        "ref_ids": [
          "59"
        ]
      },
      "Enhanced generative adversarial network for 3D brain MRI super-resolution": {
        "authors": [
          "Yuhua Chen",
          "Yifan Wu",
          "Jianbo Shi",
          "James Gee"
        ],
        "url": "http://openaccess.thecvf.com/content_WACV_2020/papers/Wang_Enhanced_generative_adversarial_network_for_3D_brain_MRI_super-resolution_WACV_2020_paper.pdf",
        "ref_texts": "[40] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "40"
        ]
      },
      "Learning instance occlusion for panoptic segmentation": {
        "authors": [
          "Justin Lazarow",
          "Kwonjoon Lee",
          "Kunyu Shi",
          "Zhuowen Tu"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPR_2020/papers/Lazarow_Learning_Instance_Occlusion_for_Panoptic_Segmentation_CVPR_2020_paper.pdf",
        "ref_texts": "[40] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017. 1,4",
        "ref_ids": [
          "40"
        ]
      },
      "Dynamic and static context-aware lstm for multi-agent motion prediction": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2008.00777",
        "ref_texts": "34. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: Proceedings of the IEEE conference on computer vision and pattern recognition. pp. 2881{2890 (2017)",
        "ref_ids": [
          "34"
        ]
      },
      "Nas-dip: Learning deep image prior with neural architecture search": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2008.11713",
        "ref_texts": ""
      },
      "Variational context-deformable convnets for indoor scene parsing": {
        "authors": [
          "Zhitong Xiong",
          "Yuan Yuan",
          "Nianhui Guo",
          "Qi Wang"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPR_2020/papers/Xiong_Variational_Context-Deformable_ConvNets_for_Indoor_Scene_Parsing_CVPR_2020_paper.pdf",
        "ref_texts": "[54] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017.",
        "ref_ids": [
          "54"
        ]
      },
      "Scaling wide residual networks for panoptic segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2011.11675",
        "ref_texts": "[107] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017. 2, 6, 8",
        "ref_ids": [
          "107"
        ]
      },
      "Bidirectional graph reasoning network for panoptic segmentation": {
        "authors": [
          "Yangxin Wu",
          "Gengwei Zhang",
          "Yiming Gao",
          "Xiajun Deng",
          "Ke Gong",
          "Xiaodan Liang",
          "Liang Lin"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPR_2020/papers/Wu_Bidirectional_Graph_Reasoning_Network_for_Panoptic_Segmentation_CVPR_2020_paper.pdf",
        "ref_texts": "[36] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , pages 2881\u20132890, 2017. 2",
        "ref_ids": [
          "36"
        ]
      },
      "Real-time semantic stereo matching": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1910.00541",
        "ref_texts": "[47] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in CVPR , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "47"
        ]
      },
      "Microstructure synthesis using style-based generative adversarial networks": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1909.07042",
        "ref_texts": "[24] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, Pyramid scene parsing network, in The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) (2017).",
        "ref_ids": [
          "24"
        ]
      },
      "Structured consistency loss for semi-supervised semantic segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2001.04647",
        "ref_texts": "[28] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "28"
        ]
      },
      "Counting from sky: A large-scale data set for remote sensing object counting and a benchmark method": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2008.12470",
        "ref_texts": "[67] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in CVPR , 2017, pp. 2881\u20132890. 5",
        "ref_ids": [
          "67"
        ]
      },
      "Phraseclick: toward achieving flexible interactive segmentation by phrase and click": {
        "authors": [],
        "url": "https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123480426.pdf",
        "ref_texts": "71. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) (2017)",
        "ref_ids": [
          "71"
        ]
      },
      "On vocabulary reliance in scene text recognition": {
        "authors": [
          "Zhaoyi Wan",
          "Jielei Zhang",
          "Liang Zhang",
          "Jiebo Luo",
          "Cong Yao"
        ],
        "url": "https://openaccess.thecvf.com/content_CVPR_2020/papers/Wan_On_Vocabulary_Reliance_in_Scene_Text_Recognition_CVPR_2020_paper.pdf",
        "ref_texts": "[49] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , pages 6230\u20136239, Honolulu, HI, USA, July 2017. 4",
        "ref_ids": [
          "49"
        ]
      },
      "Brinet: Towards bridging the intra-class and inter-class gaps in one-shot segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2008.06226",
        "ref_texts": "[40] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. 2017 IEEE Conference onComputer Vision andPattern Recognition (CVPR), Jul 2017. doi: 10.1109/cvpr.2017.660. URL http://dx. doi.org/10.1109/CVPR.2017.660 .",
        "ref_ids": [
          "40"
        ]
      },
      "Dasgil: Domain adaptation for semantic and geometric-aware image-based localization": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2010.00573",
        "ref_texts": "[12] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "12"
        ]
      },
      "Predicting sharp and accurate occlusion boundaries in monocular depth estimation using displacement fields": {
        "authors": [
          "Michael Ramamonjisoa",
          "Yuming Du",
          "Vincent Lepetit"
        ],
        "url": "https://openaccess.thecvf.com/content_CVPR_2020/papers/Ramamonjisoa_Predicting_Sharp_and_Accurate_Occlusion_Boundaries_in_Monocular_Depth_Estimation_CVPR_2020_paper.pdf",
        "ref_texts": "[62] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid Scene Parsing Network. In CVPR , 2017. 5",
        "ref_ids": [
          "62"
        ]
      },
      "Simpropnet: Improved similarity propagation for few-shot image segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2004.15014",
        "ref_texts": "[29]Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network.",
        "ref_ids": [
          "29"
        ]
      },
      "Dynamic extension nets for few-shot semantic segmentation": {
        "authors": [
          "Lizhao Liu",
          "Junyi Cao",
          "Minqian Liu",
          "Yong Guo",
          "Qi Chen",
          "Mingkui Tan"
        ],
        "url": "https://tanmingkui.github.io/files/publications/Dynamic.pdf",
        "ref_texts": ""
      },
      "Trainable structure tensors for autonomous baggage threat detection under extreme occlusion": {
        "authors": [
          "Taimur Hassan",
          "Naoufel Werghi"
        ],
        "url": "https://openaccess.thecvf.com/content/ACCV2020/papers/Hassan_Trainable_Structure_Tensors_for_Autonomous_Baggage_Threat_Detection_Under_Extreme_ACCV_2020_paper.pdf",
        "ref_texts": ""
      },
      "Correlating edge, pose with parsing": {
        "authors": [
          "Ziwei Zhang",
          "Chi Su",
          "Liang Zheng",
          "Xiaodong Xie"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPR_2020/papers/Zhang_Correlating_Edge_Pose_With_Parsing_CVPR_2020_paper.pdf",
        "ref_texts": "[41] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. InProceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "41"
        ]
      },
      "VR content creation and exploration with deep learning: A survey": {
        "authors": [],
        "url": "https://link.springer.com/content/pdf/10.1007/s41095-020-0162-z.pdf",
        "ref_texts": "[12] Zhao, H.; Shi, J.; Qi, X.; Wang, X.; Jia, J. Pyramid scene parsing network. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2881\u20132890, 2017.",
        "ref_ids": [
          "12"
        ]
      },
      "Training quantized neural networks with a full-precision auxiliary module": {
        "authors": [
          "Bohan Zhuang",
          "Lingqiao Liu",
          "Mingkui Tan",
          "Chunhua Shen",
          "Ian Reid"
        ],
        "url": "https://openaccess.thecvf.com/content_CVPR_2020/papers/Zhuang_Training_Quantized_Neural_Networks_With_a_Full-Precision_Auxiliary_Module_CVPR_2020_paper.pdf",
        "ref_texts": "[53] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proc. IEEE Conf. Comp. Vis. Patt. Recogn. , pages 2881\u2013",
        "ref_ids": [
          "53"
        ]
      },
      "Self-supervised outdoor scene relighting": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2107.03106",
        "ref_texts": "51.Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: IEEE Conf. on Computer Vision and Pattern Recognition (CVPR). pp. 2881{2890",
        "ref_ids": [
          "51"
        ]
      },
      "FDDWNet: a lightweight convolutional neural network for real-time semantic segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1911.00632",
        "ref_texts": "[2]H. Zhao, J. Shi, X. Qi, X. Wang, and J. Y . Jia, \u201cPyramid scene parsing network,\u201d in CVPR , 2016, pp. 6230\u20136239.",
        "ref_ids": [
          "2"
        ]
      },
      "Adversarial learning and self-teaching techniques for domain adaptation in semantic segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1909.00781",
        "ref_texts": "[10] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proceedings of IEEE Conference on Computer Vision and Pattern Recognition , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "10"
        ]
      },
      "Fast panoptic segmentation network": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1910.03892",
        "ref_texts": "[14] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid Scene Parsing Network,\u201d in 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , July 2017, pp. 6230\u20136239.",
        "ref_ids": [
          "14"
        ]
      },
      "Malleable 2.5 D convolution: Learning receptive fields along the depth-axis for RGB-D scene parsing": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2007.09365",
        "ref_texts": "39. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: CVPR. pp. 6230{6239. IEEE Computer Society (2017)",
        "ref_ids": [
          "39"
        ]
      },
      "Online camera-lidar calibration with sensor semantic information": {
        "authors": [
          "Yufeng Zhu",
          "Chenghui Li",
          "Yubo Zhang"
        ],
        "url": "https://mike323zyf.github.io/report/calibration.pdf",
        "ref_texts": "[27] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pp. 2881\u20132890, 2017.",
        "ref_ids": [
          "27"
        ]
      },
      "Representative graph neural network": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2008.05202",
        "ref_texts": "51. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) (2017) 3, 8, 10, 12, 13, 14",
        "ref_ids": [
          "51"
        ]
      },
      "Pyramid global context network for image dehazing": {
        "authors": [],
        "url": "http://www.cvteam.net/papers/2020_TCSVT_Pyramid%20Global%20Context%20Network%20for%20Image%20Dehazing.pdf",
        "ref_texts": "[36] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "36"
        ]
      },
      "Improving semantic segmentation via self-training": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2004.14960",
        "ref_texts": "76. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid Scene Parsing Network. In: IEEE Conference on Computer Vision and Pattern Recognition (CVPR) (2017)",
        "ref_ids": [
          "76"
        ]
      },
      "We learn better road pothole detection: from attention aggregation to adversarial domain adaptation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2008.06840",
        "ref_texts": "16. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition.",
        "ref_ids": [
          "16"
        ]
      },
      "Weak supervision for generating pixel\u2013level annotations in scene text segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1911.09026",
        "ref_texts": "[18] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d 2017, pp. 6230\u20136239.",
        "ref_ids": [
          "18"
        ]
      },
      "Heatnet: Bridging the day-night domain gap in semantic segmentation with thermal images": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2003.04645",
        "ref_texts": "[36] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "36"
        ]
      },
      "Mininet: An efficient semantic segmentation convnet for real-time robotic applications": {
        "authors": [],
        "url": "https://zaguan.unizar.es/record/99446/files/texto_completo.pdf",
        "ref_texts": "[33] Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 2881\u20132890 (2017) 1, 2",
        "ref_ids": [
          "33"
        ]
      },
      "Adaptive object detection with dual multi-label prediction": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2003.12943",
        "ref_texts": "43. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: CVPR (2017)",
        "ref_ids": [
          "43"
        ]
      },
      "Retargetable AR: Context-aware augmented reality in indoor scenes based on 3D scene graph": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2008.07817",
        "ref_texts": "[55] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In Proc. CVPR , pp. 2881\u20132890, 2017.",
        "ref_ids": [
          "55"
        ]
      },
      "SAC-Net: Spatial attenuation context for salient object detection": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1903.10152",
        "ref_texts": "[85] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in CVPR , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "85"
        ]
      },
      "MMFNet: A multi-modality MRI fusion network for segmentation of nasopharyngeal carcinoma": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1812.10033",
        "ref_texts": "[42] H. Zhao, J. Shi, X. Qi, X. Wang, J. Jia, Pyramid scene parsing network, in: IEEE Conf. on Computer Vision and Pattern Recognition (CVPR), 2017, pp. 2881{2890.",
        "ref_ids": [
          "42"
        ]
      },
      "Road obstacle detection method based on an autoencoder with semantic segmentation": {
        "authors": [
          "Toshiaki Ohgushi",
          "Kenji Horiguchi",
          "Masao Yamanaka"
        ],
        "url": "https://openaccess.thecvf.com/content/ACCV2020/papers/Ohgushi_Road_Obstacle_Detection_Method_Based_on_an_Autoencoder_with_Semantic_ACCV_2020_paper.pdf",
        "ref_texts": ""
      },
      "Alleviating semantic-level shift: A semi-supervised domain adaptation method for semantic segmentation": {
        "authors": [
          "Zhonghao Wang",
          "Yunchao Wei",
          "Rogerio Feris",
          "Jinjun Xiong",
          "Thomas S. Huang",
          "Honghui Shi"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPRW_2020/papers/w54/Wang_Alleviating_Semantic-Level_Shift_A_Semi-Supervised_Domain_Adaptation_Method_for_Semantic_CVPRW_2020_paper.pdf",
        "ref_texts": "[29] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In IEEE CVPR , 2017.",
        "ref_ids": [
          "29"
        ]
      },
      "An artificial intelligence-based system to assess nutrient intake for hospitalised patients": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2003.08273",
        "ref_texts": "[40] H. Zhao et al. , \u201cPyramid scene parsing network,\u201d in Proc. of IEEE conf. Comput. Vis. Pattern Recognit. , USA, 2017.",
        "ref_ids": [
          "40"
        ]
      },
      "A locally-constrained YOLO framework for detecting small and densely-distributed building footprints": {
        "authors": [
          "Yiqun Xie"
        ],
        "url": "https://par.nsf.gov/servlets/purl/10106875",
        "ref_texts": "[Accessed Dec 2018]. NAIP Information Sheet, 2015 .https://www.fsa.usda.gov/Internet/FSA_File/naip_info_sheet_2015. pdf. [Accessed Dec 2018]. National Agriculture Imagery Program. https://www.fsa.usda. gov/programs-and-services/aerialphotography/imagery-programs/naip-imagery/ . [Accessed May 2019]. Nogueira, K., Penatti, O.A., and Dos Santos, J.A., 2017 . Towards better exploiting convolutional neural networks for remote sensing scene classification. Pattern Recognition, 61, 539 \u2013556. doi:10.1016/j.patcog.2016.07.001 Razavian, A.S., et al .(2014 ), Cnn features o ffthe-shelf: an astounding baseline for recognition. In: Computer vision and pattern recognition workshops (CVPRW), 2014 IEEE conference on. Columbus, OH, USA, pp. 512 \u2013519. Redmon, J., et al.(2016 ), You only look once: uni fied, real-time object detection. In: Proceedings of the IEEE conference on computer vision and pattern recognition. Las Vegas, NV, USA, 79 \u2013788. Redmon, J. and Farhadi, A. (2017 ), Yolo9000: better, faster, stronger. In:\u2018Computer vision and pattern recognition (CVPR), 2017 IEEE conference on. Honolulu, HI, USA, 6517 \u20136525. Romero, A., Gatta, C., and Camps-Valls, G., 2016 . Unsupervised deep feature extraction for remote sensing image classification. IEEE Transactions on Geoscience and Remote Sensing , 54 (3), 1349 \u20131362. doi: 10.1109/TGRS.2015.2478379 Rylatt, M., Gadsden, S., and Lomas, K., 2001 . Gis-based decision support for solar energy planning in urban environments. Computers, Environment and Urban Systems , 25 (6), 579 \u2013603. doi:10.1016/S0198-9715(00)00032-6 Shin, H.-C., et al .,2016 .Deep convolutional neural networks for computer-aided detection: cnn architectures, dataset characteristics and transfer learning. IEEE Transactions on Medical Imaging , 35 (5), 1285 \u20131298. doi: 10.1109/TMI.2016.2528162 Sirmacek, B. and Unsalan, C., 2009 . Urban-area and building detection using sift keypoints and graph theory. IEEE Transactions on Geoscience and Remote Sensing , 47 (4), 1156 \u20131167. doi:10.1109/TGRS.2008.2008440 Wu, S.S., Wang, L., and Qiu, X., 2018 . Incorporating gis building data and census housing statistics for sub-block-level population estimation. The Professional Geographer , 60 (1), 121 \u2013135. doi:10.1080/00330120701724251 Xie, Y., et al.(2018 ), An unsupervised augmentation framework for deep learning based geospatial object detection: a summary of results. In: Proceedings of the 26th ACM SIGSPATIAL international conference on advances in geographic information systems. Seattle, WA, USA, 349\u2013 358. Yuan, J., 2018 . Learning building extraction in aerial scenes with convolutional networks. IEEE Transactions on Pattern Analysis and Machine Intelligence , 40 (11), 2793 \u20132798. doi: 10.1109/ TPAMI.2017.2750680 Zhao, H., et al .(2017 ), Pyramid scene parsing network. In: IEEE Conf. on computer vision and pattern recognition (CVPR), Honolulu, HI, USA, 2881 \u20132890.24 Y. XIE ET AL. Appendix A. Regression modeling in YOLO In the YOLO framework, the original input size of each image is convoluted and pooled to a spatiallycoarser grid. Thus, a typical input size of 416 /C2416/C23(r o w /C2column /C2channel) finally becomes 13/C213/C2R(row /C2column /C2number of predicted parameters). In this output layer, the cell that contains the center of an object is responsible for predicting its location and size. To understand the regression modeling, first we need to understand the four parameters representing the locations and sizes of predicted bounding boxes, that is, the center coordinatesc xand cy, width lwand height lh. These parameter values are not directly given in the output layer. Instead, they are further derived afterwards. Center coordinates : Since the cell that contains the object \u2019s center is responsible for detecting it, the center coordinates of an object are modeled as o ffsets to the cell \u2019s top-left corner (minimum x and y). Because the center is contained by the cell, the predicted o ffsets are values in the range \u00bd0;1/C138. Width and height : YOLO models width and height using an anchor box. An anchor box represents a common size (width and height) of objects in the images. For example, one canuse the average width and height of all objects to build a common size. Then, the actual widthand height of any object is modeled as a scaling of the common width and height. Equation (A1) shows the detailed derivation of the four parameters: c x\u00bccell x\u00fe\u03c3\u00f0px\u00de cy\u00bccell y\u00fe\u03c3\u00f0py\u00de lw\u00bcanchor w/C1epw lh\u00bcanchor h/C1eph(A1) where cell xand cell yare the top-left coordinates of a cell; \u03c3\u00f0x\u00de\u00bc1",
        "ref_ids": [
          "Accessed Dec 2018",
          "Accessed Dec 2018",
          "Accessed May 2019"
        ]
      },
      "Hi-UCD: A large-scale dataset for urban semantic change detection in remote sensing imagery": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2011.03247",
        "ref_texts": "[20] H. Zhao, J. Shi, X. Qi, X. Wang, J. Jia, Pyramid scene parsing network, in: The IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2017.",
        "ref_ids": [
          "20"
        ]
      },
      "Multi-organ segmentation via co-training weight-averaged models from few-organ datasets": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2008.07149",
        "ref_texts": "16. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: Proceedings of the IEEE conference on computer vision and pattern recognition. pp. 2881{2890 (2017)",
        "ref_ids": [
          "16"
        ]
      },
      "3-D RoI-aware U-net for accurate and efficient colorectal tumor segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1806.10342",
        "ref_texts": "[14] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia, \\Pyramid scene parsing network,\" in IEEE Conf. on Computer Vision and Pattern Recognition (CVPR) , 2017, pp. 2881{2890.",
        "ref_ids": [
          "14"
        ]
      },
      "Learning deep multimodal feature representation with asymmetric multi-layer fusion": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2108.05009",
        "ref_texts": "[37] Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: CVPR",
        "ref_ids": [
          "37"
        ]
      },
      "GINet: Graph interaction network for scene parsing": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2009.06160",
        "ref_texts": "57. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: CVPR (2017)",
        "ref_ids": [
          "57"
        ]
      },
      "Segmentations-leak: Membership inference attacks and defenses in semantic image segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1912.09685",
        "ref_texts": "37. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: CVPR (2017)",
        "ref_ids": [
          "37"
        ]
      },
      "Part-aware context network for human parsing": {
        "authors": [
          "Xiaomei Zhang",
          "Yingying Chen",
          "Bingke Zhu",
          "Jinqiao Wang",
          "Ming Tang"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPR_2020/papers/Zhang_Part-Aware_Context_Network_for_Human_Parsing_CVPR_2020_paper.pdf",
        "ref_texts": "[46] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017.",
        "ref_ids": [
          "46"
        ]
      },
      "Learning semantic neural tree for human parsing": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1912.09622",
        "ref_texts": "[37] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , pages 6230\u20136239, 2017.",
        "ref_ids": [
          "37"
        ]
      },
      "Detection and localization of ultrasound scatterers using convolutional neural networks": {
        "authors": [],
        "url": "https://orbit.dtu.dk/files/217052523/09130724.pdf",
        "ref_texts": "[14] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in IEEE Conf. Computer Vision and Pattern Recognition, 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "14"
        ]
      },
      "Personal fixations-based object segmentation with object localization and boundary preservation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2101.09014",
        "ref_texts": "[54] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proc. IEEE CVPR , Jul. 2017, pp. 6230\u20136239.",
        "ref_ids": [
          "54"
        ]
      },
      "Focus on semantic consistency for cross-domain crowd understanding": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2002.08623",
        "ref_texts": "[23] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in CVPR , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "23"
        ]
      },
      "Clinically verified hybrid deep learning system for retinal ganglion cells aware grading of glaucomatous progression": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2010.03872",
        "ref_texts": "[44] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid Scene Parsing Network,\u201d IEEE International Conference on Computer Vision and Pattern Recognition, 2017.",
        "ref_ids": [
          "44"
        ]
      },
      "Efficient ladder-style densenets for semantic segmentation of large images": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1905.05661",
        "ref_texts": "[22] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in ICCV , 2017.",
        "ref_ids": [
          "22"
        ]
      },
      "Class-incremental learning for semantic segmentation re-using neither old data nor old labels": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2005.06050",
        "ref_texts": "[3] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid Scene Parsing Network,\u201d in Proc. of CVPR , Honulu, HI, USA, Jul. 2017, pp. 2881\u2013",
        "ref_ids": [
          "3"
        ]
      },
      "Collaborative multi-robot systems for search and rescue: Coordination and perception": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2008.12610",
        "ref_texts": "[185] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in CVPR , 2017.",
        "ref_ids": [
          "185"
        ]
      },
      "Text detection and recognition in the wild: A review": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2006.04305",
        "ref_texts": "155. H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proc. IEEE Conf. on Comp. Vision and Pattern Recognit. , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "155"
        ]
      },
      "Mlsl: Multi-level self-supervised learning for domain adaptation with spatially independent and semantically consistent labeling": {
        "authors": [
          "Javed Iqbal",
          "Mohsen Ali"
        ],
        "url": "https://openaccess.thecvf.com/content_WACV_2020/papers/Iqbal_MLSL_Multi-Level_Self-Supervised_Learning_for_Domain_Adaptation_with_Spatially_Independent_WACV_2020_paper.pdf",
        "ref_texts": ""
      },
      "Robust 6d object pose estimation by learning rgb-d features": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2003.00188",
        "ref_texts": "[36] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "36"
        ]
      },
      "Ds-pass: Detail-sensitive panoramic annular semantic segmentation through swaftnet for surrounding sensing": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1909.07721",
        "ref_texts": "[12] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) . IEEE, 2017, pp. 6230\u20136239.[13] X. Hu, K. Yang, L. Fei, and K. Wang, \u201cAcnet: Attention based network to exploit complementary features for rgbd semantic segmentation,\u201d in2019 IEEE International Conference on Image Processing (ICIP) . IEEE, 2019, pp. 1440\u20131444.",
        "ref_ids": [
          "12",
          "13"
        ]
      },
      "UWSOD: Toward fully-supervised-level capacity weakly supervised object detection": {
        "authors": [],
        "url": "https://proceedings.neurips.cc/paper/2020/file/4e0928de075538c593fbdabb0c5ef2c3-Paper.pdf",
        "ref_texts": "[76] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid Scene Parsing Network. In IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) , 2017.",
        "ref_ids": [
          "76"
        ]
      },
      "Improved noise and attack robustness for semantic segmentation by using multi-task training with self-supervised depth estimation": {
        "authors": [
          "Marvin Klingner",
          "Andreas Bar",
          "Tim Fingscheidt"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPRW_2020/papers/w20/Klingner_Improved_Noise_and_Attack_Robustness_for_Semantic_Segmentation_by_Using_CVPRW_2020_paper.pdf",
        "ref_texts": "[73] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid Scene Parsing Network. In Proc. of CVPR , pages 2881\u20132890, Honulu, HI, USA, July 2017. 2",
        "ref_ids": [
          "73"
        ]
      },
      "TRADI: Tracking deep neural network weight distributions": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1912.11316",
        "ref_texts": "[56]Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: Proceedings of the IEEE conference on computer vision and pattern recognition. pp. 2881{2890 (2017)",
        "ref_ids": [
          "56"
        ]
      },
      "IDDA: A large-scale multi-domain dataset for autonomous driving": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2004.08298",
        "ref_texts": "[18] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in CVPR , 2017.",
        "ref_ids": [
          "18"
        ]
      },
      "Deep sub-region network for salient object detection": {
        "authors": [],
        "url": "https://xmengli.github.io/papers/2020TCSVT-LWang.pdf",
        "ref_texts": ""
      },
      "The Synthinel-1 dataset: A collection of high resolution synthetic overhead imagery for building segmentation": {
        "authors": [
          "Fanjie Kong",
          "Bohao Huang",
          "Kyle Bradbury",
          "Jordan Malof"
        ],
        "url": "https://openaccess.thecvf.com/content_WACV_2020/papers/Kong_The_Synthinel-1_dataset_a_collection_of_high_resolution_synthetic_overhead_WACV_2020_paper.pdf",
        "ref_texts": ""
      },
      "3D instance embedding learning with a structure-aware loss function for point cloud segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1902.05247",
        "ref_texts": ""
      },
      "Defocus blur detection via depth distillation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2007.08113",
        "ref_texts": "42. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: CVPR. pp. 2881{2890 (2017)",
        "ref_ids": [
          "42"
        ]
      },
      "Real-time semantic background subtraction": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2002.04993",
        "ref_texts": "[15] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in IEEE Int. Conf. Comput. Vision and Pattern Recogn. (CVPR) , Honolulu, HI, USA, July 2017, pp. 6230\u20136239.",
        "ref_ids": [
          "15"
        ]
      },
      "Towards stabilizing batch statistics in backward propagation of batch normalization": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2001.06838",
        "ref_texts": "10 Published as a conference paper at ICLR 2020 Chao Peng, Tete Xiao, Zeming Li, Yuning Jiang, Xiangyu Zhang, Kai Jia, Gang Yu, and Jian Sun. Megdet: A large mini-batch object detector. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pp. 6181\u20136189, 2018. Siyuan Qiao, Huiyu Wang, Chenxi Liu, Wei Shen, and Alan Yuille. Weight standardization. arXiv preprint arXiv:1903.10520 , 2019. Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma, Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael Bernstein, et al. Imagenet large scale visual recognition challenge. International journal of computer vision , 115(3):211\u2013252, 2015. Wenqi Shao, Tianjian Meng, Jingyu Li, Ruimao Zhang, Yudian Li, Xiaogang Wang, and Ping Luo. Ssn: Learning sparse switchable normalization via sparsestmax. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pp. 443\u2013451, 2019. Saurabh Singh and Abhinav Shrivastava. Evalnorm: Estimating batch normalization statistics for evaluation. arXiv preprint arXiv:1904.06031 , 2019. Dmitry Ulyanov, Andrea Vedaldi, and Victor Lempitsky. Instance normalization: The missing ingredient for fast stylization. arXiv preprint arXiv:1607.08022 , 2016. Yuxin Wu and Kaiming He. Group normalization. In Proceedings of the European Conference on Computer Vision (ECCV) , pp. 3\u201319, 2018. Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pp."
      },
      "Transferring and regularizing prediction for semantic segmentation": {
        "authors": [
          "Yiheng Zhang",
          "Zhaofan Qiu",
          "Ting Yao",
          "Wah Ngo",
          "Dong Liu",
          "Tao Mei"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPR_2020/papers/Zhang_Transferring_and_Regularizing_Prediction_for_Semantic_Segmentation_CVPR_2020_paper.pdf",
        "ref_texts": "[59] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017.",
        "ref_ids": [
          "59"
        ]
      },
      "Ranet: Region attention network for semantic segmentation": {
        "authors": [],
        "url": "https://proceedings.neurips.cc/paper_files/paper/2020/file/9fe8593a8a330607d76796b35c64c600-Paper.pdf",
        "ref_texts": "[7]Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "7"
        ]
      },
      "Pixel consensus voting for panoptic segmentation": {
        "authors": [
          "Haochen Wang",
          "Ruotian Luo",
          "Michael Maire",
          "Greg Shakhnarovich"
        ],
        "url": "https://openaccess.thecvf.com/content_CVPR_2020/papers/Wang_Pixel_Consensus_Voting_for_Panoptic_Segmentation_CVPR_2020_paper.pdf",
        "ref_texts": "[57] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "57"
        ]
      },
      "Discover, hallucinate, and adapt: Open compound domain adaptation for semantic segmentation": {
        "authors": [],
        "url": "https://proceedings.neurips.cc/paper_files/paper/2020/file/7a9a322cbe0d06a98667fdc5160dc6f8-Paper.pdf",
        "ref_texts": "[43] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proc. of Computer Vision and Pattern Recognition (CVPR) , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "43"
        ]
      },
      "Gmnet: Graph matching network for large scale part semantic segmentation in the wild": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2007.09073",
        "ref_texts": "49. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR). pp. 2881{2890 (2017)",
        "ref_ids": [
          "49"
        ]
      },
      "Label efficient visual abstractions for autonomous driving": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2005.10091",
        "ref_texts": "[35] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In CVPR , 2017. 1, 2",
        "ref_ids": [
          "35"
        ]
      },
      "Psconv: Squeezing feature pyramid into one compact poly-scale convolutional layer": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2007.06191",
        "ref_texts": "46. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: CVPR (2017)",
        "ref_ids": [
          "46"
        ]
      },
      "Prototype-based incremental few-shot semantic segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2012.01415",
        "ref_texts": "[60] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In IEEE Conf. Comput. Vis. Pattern Recog. , 2017.",
        "ref_ids": [
          "60"
        ]
      },
      "Self-supervised cyclegan for object-preserving image-to-image domain adaptation": {
        "authors": [],
        "url": "https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123650494.pdf",
        "ref_texts": "35. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: CVPR (2017)",
        "ref_ids": [
          "35"
        ]
      },
      "Instance segmentation of biological images using harmonic embeddings": {
        "authors": [
          "Victor Kulikov",
          "Victor Lempitsky"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPR_2020/papers/Kulikov_Instance_Segmentation_of_Biological_Images_Using_Harmonic_Embeddings_CVPR_2020_paper.pdf",
        "ref_texts": "[31] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , July 2017. 4",
        "ref_ids": [
          "31"
        ]
      },
      "Index networks": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1908.09895",
        "ref_texts": "[48] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2017, pp. 2881\u20132890. 12",
        "ref_ids": [
          "48"
        ]
      },
      "Probabilistic semantic mapping for urban autonomous driving applications": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2006.04894",
        "ref_texts": "[5] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , Jul 2017.",
        "ref_ids": [
          "5"
        ]
      },
      "Self-learning with rectification strategy for human parsing": {
        "authors": [
          "Tao Li",
          "Zhiyuan Liang",
          "Sanyuan Zhao",
          "Jiahao Gong",
          "Jianbing Shen"
        ],
        "url": "https://openaccess.thecvf.com/content_CVPR_2020/papers/Li_Self-Learning_With_Rectification_Strategy_for_Human_Parsing_CVPR_2020_paper.pdf",
        "ref_texts": "[54] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In IEEE CVPR , pages 2881\u20132890, 2017. 7",
        "ref_ids": [
          "54"
        ]
      },
      "Semantic view synthesis": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2008.10598",
        "ref_texts": "52. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: CVPR (2017) 5, 8",
        "ref_ids": [
          "52"
        ]
      },
      "Learning to predict context-adaptive convolution for semantic segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2004.08222",
        "ref_texts": "37. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: Proceedings of the IEEE conference on computer vision and pattern recognition. pp. 2881{2890 (2017) 1, 3, 8, 9, 12, 13",
        "ref_ids": [
          "37"
        ]
      },
      "Regression of instance boundary by aggregated CNN and GCN": {
        "authors": [],
        "url": "https://researchportal.port.ac.uk/files/43188741/Meng_et_al_2020_AAM.pdf",
        "ref_texts": "50. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. pp. 2881{2890 (2017)",
        "ref_ids": [
          "50"
        ]
      },
      "Video semantic segmentation with distortion-aware feature correction": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2006.10380",
        "ref_texts": "[21] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in CVPR , 2017.",
        "ref_ids": [
          "21"
        ]
      },
      "Linear attention mechanism: An efficient attention for semantic segmentation": {
        "authors": [
          "Tiffany Mc"
        ],
        "url": "https://arxiv.org/pdf/2007.14902",
        "ref_texts": "[20] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \"Pyramid scene parsing network,\" in Proceedings of the IEEE conference on computer vision and pattern recognition , 2017, pp. 2881 -2890. ",
        "ref_ids": [
          "20"
        ]
      },
      "Coupled network for robust pedestrian detection with gated multi-layer feature extraction and deformable occlusion handling": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1912.08661",
        "ref_texts": "[7] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "7"
        ]
      },
      "Getting to 99% accuracy in interactive segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2003.07932",
        "ref_texts": "[33] H. Zhao, J. Shi, X. Qi, X. Wang, J. Jia, Pyramid scene parsing network, in: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2017, pp. 6230\u20136239. doi:doi:10.1109/CVPR.2017.660.",
        "ref_ids": [
          "33"
        ]
      },
      "T-net: Nested encoder\u2013decoder architecture for the main vessel segmentation in coronary angiography": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1905.04197",
        "ref_texts": "[24] H. Zhao, J. Shi, X. Qi, X. Wang, J. Jia, Pyramid scene parsing network, in: Proceedings of the IEEE conference on computer vision and pattern recognition, 2017, pp. 2881{2890.",
        "ref_ids": [
          "24"
        ]
      },
      "Visual navigation based on semantic segmentation using only a monocular camera as an external sensor": {
        "authors": [],
        "url": "https://www.jstage.jst.go.jp/article/jrobomech/32/6/32_1137/_pdf",
        "ref_texts": "[14] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d Proc. IEEE Conf. Comput. Vis. Pattern Recognit., pp. 2881-2890, doi: 10.1109/CVPR.2017.660, 2017.",
        "ref_ids": [
          "14"
        ]
      },
      "Deep structure-revealed network for texture recognition": {
        "authors": [
          "Wei Zhai",
          "Yang Cao",
          "Jun Zha",
          "Yong Xie",
          "Feng Wu"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPR_2020/papers/Zhai_Deep_Structure-Revealed_Network_for_Texture_Recognition_CVPR_2020_paper.pdf",
        "ref_texts": ""
      },
      "Intrinsic relationship reasoning for small object detection": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2009.00833",
        "ref_texts": "[48] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. 2017. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition . 2881\u20132890.",
        "ref_ids": [
          "48"
        ]
      },
      "Sinet: Extreme lightweight portrait segmentation networks with spatial squeeze module and information blocking decoder": {
        "authors": [
          "Hyojin Park",
          "Lars Sjosund",
          "Youngjoon Yoo",
          "Nicolas Monet",
          "Jihwan Bang",
          "Nojun Kwak"
        ],
        "url": "http://openaccess.thecvf.com/content_WACV_2020/papers/Park_SINet_Extreme_Lightweight_Portrait_Segmentation_Networks_with_Spatial_Squeeze_Module_WACV_2020_paper.pdf",
        "ref_texts": "[30] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2017.",
        "ref_ids": [
          "30"
        ]
      },
      "River ice segmentation with deep learning": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1901.04412",
        "ref_texts": ""
      },
      "Importance of self-consistency in active learning for semantic segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2008.01860",
        "ref_texts": "[66] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "66"
        ]
      },
      "Deep clustering for weakly-supervised semantic segmentation in autonomous driving scenes": {
        "authors": [
          "Xiang Wang"
        ],
        "url": "https://wangxiang10.github.io/papers/NC20.pdf",
        "ref_texts": "[18] H. Zhao , J. Shi , X. Qi , X. Wang , J. Jia , Pyramid scene parsing network, in: Proceedings of Conference on Computer Vision and Pattern Recognition, CVPR, ",
        "ref_ids": [
          "18"
        ]
      },
      "Deep atrous guided filter for image restoration in under display cameras": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2008.06229",
        "ref_texts": "73. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) (July 2017)",
        "ref_ids": [
          "73"
        ]
      },
      "Efficient video semantic segmentation with labels propagation and refinement": {
        "authors": [
          "Matthieu Paul",
          "Christoph Mayer",
          "Luc Van",
          "Radu Timofte"
        ],
        "url": "http://openaccess.thecvf.com/content_WACV_2020/papers/Paul_Efficient_Video_Semantic_Segmentation_with_Labels_Propagation_and_Refinement_WACV_2020_paper.pdf",
        "ref_texts": "[43] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , July 2017.",
        "ref_ids": [
          "43"
        ]
      },
      "JointsGait: A model-based gait recognition method based on gait graph convolutional networks and joints relationship pyramid mapping": {
        "authors": [
          "Na Li",
          "Xinbo Zhao",
          "Chong Ma"
        ],
        "url": "https://arxiv.org/pdf/2005.08625",
        "ref_texts": "[31] H. Zhao, J. Shi, X. Qi, X. Wang, J. Jia, Pyramid scene parsing network, in: Proceedings of the IEEE conference on computer vision and pattern recognition, 2017, pp. 2881{2890.",
        "ref_ids": [
          "31"
        ]
      },
      "Mini review: Deep learning for atrial segmentation from late gadolinium-enhanced MRIs": {
        "authors": [
          "Jichao Zhao"
        ],
        "url": "https://www.frontiersin.org/articles/10.3389/fcvm.2020.00086/pdf",
        "ref_texts": "60. Zhao H, Shi J, Qi X, Wang X, Jia J. Pyramid scene parsing network. In:Proceedings of the IEEE Conference on Computer Vision and Pat tern Recognition .(2017).p.2881\u201390.doi:10.1109/CVPR.2017.660",
        "ref_ids": [
          "60"
        ]
      },
      "Physical model guided deep image deraining": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2003.13242",
        "ref_texts": "[21] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia, \u201cPyramid scene parsing network,\u201d in CVPR , 2017, pp. 6230\u20136239.",
        "ref_ids": [
          "21"
        ]
      },
      "Dapas: Denoising autoencoder to prevent adversarial attack in semantic segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1908.05195",
        "ref_texts": "[30] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "30"
        ]
      },
      "Hard pixel mining for depth privileged semantic segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1906.11437",
        "ref_texts": "[37] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition , Honolulu, HI, Jul. 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "37"
        ]
      },
      "Self-supervised tuning for few-shot segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2004.05538",
        "ref_texts": "[Zhao et al. , 2017 ]Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u2013",
        "ref_ids": [
          "Zhao et al\\. , 2017 "
        ]
      },
      "Metabox+: A new region based active learning method for semantic segmentation using priority maps": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2010.01884",
        "ref_texts": "[40] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia, \u2018Pyramid scene parsing network\u2019, in Proceedings of the IEEE conference on computer vision and pattern recognition , pp. 2881\u20132890, (2017).",
        "ref_ids": [
          "40"
        ]
      },
      "Auto seg-loss: Searching metric surrogates for semantic segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2010.07930",
        "ref_texts": "10 Fausto Milletari, Nassir Navab, and Seyed-Ahmad Ahmadi. V-net: Fully convolutional neural networks for volumetric medical image segmentation. In 2016 Fourth International Conference on 3D Vision (3DV) , pp. 565\u2013571. IEEE, 2016. Pritish Mohapatra, Michal Rolinek, CV Jawahar, Vladimir Kolmogorov, and M Pawan Kumar. Efficient optimization for rank-based loss functions. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , pp. 3693\u20133701, 2018. Gattigorla Nagendar, Digvijay Singh, Vineeth N Balasubramanian, and CV Jawahar. Neuro-iou: Learning a surrogate loss for semantic segmentation. In Proceedings of the British Machine Vision Conference (BMVC) , pp. 278, 2018. Yash Patel, Tomas Hodan, and Jiri Matas. Learning surrogates via deep embedding. In Proceedings of the European Conference on Computer Vision (ECCV) , 2020. Hieu Pham, Melody Guan, Barret Zoph, Quoc Le, and Jeff Dean. Efficient neural architecture search via parameters sharing. In Proceedings of the 35th International Conference on Machine Learning (ICML) , pp. 4095\u20134104. PMLR, 2018. Xuebin Qin, Zichen Zhang, Chenyang Huang, Chao Gao, Masood Dehghan, and Martin Jagersand. Basnet: Boundary-aware salient object detection. In Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , pp. 7479\u20137489, 2019. Md Atiqur Rahman and Yang Wang. Optimizing intersection-over-union in deep neural networks for image segmentation. In International Symposium on Visual Computing , pp. 234\u2013244. Springer, 2016. Mani Ranjbar, Tian Lan, Yang Wang, Steven N Robinovitch, Ze-Nian Li, and Greg Mori. Optimizing nondecomposable loss functions in structured prediction. IEEE Transactions on Pattern Analysis and Machine Intelligence , 35(4):911\u2013924, 2012. Olaf Ronneberger, Philipp Fischer, and Thomas Brox. U-net: Convolutional networks for biomedical image segmentation. In International Conference on Medical Image Computing and Computer-Assisted Intervention , pp. 234\u2013241. Springer, 2015. John Schulman, Filip Wolski, Prafulla Dhariwal, Alec Radford, and Oleg Klimov. Proximal policy optimization algorithms. arXiv preprint arXiv:1707.06347 , 2017. Yang Song, Alexander Schwing, Raquel Urtasun, et al. Training deep neural networks via direct loss minimization. In Proceedings of the 33rd International Conference on Machine Learning (ICML) , pp. 2169\u20132177. PMLR, 2016. Ke Sun, Bin Xiao, Dong Liu, and Jingdong Wang. Deep high-resolution representation learning for human pose estimation. In Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , pp. 5693\u20135703, 2019. Xiaobo Wang, Shuo Wang, Cheng Chi, Shifeng Zhang, and Tao Mei. Loss function search for face recognition. In Proceedings of the 37th International Conference on Machine Learning (ICML) . PMLR, 2020. Zifeng Wu, Chunhua Shen, and Anton van den Hengel. Bridging category-level and instance-level semantic image segmentation. arXiv preprint arXiv:1605.06885 , 2016. Yisong Yue, Thomas Finley, Filip Radlinski, and Thorsten Joachims. A support vector method for optimizing average precision. In Proceedings of the 30th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval , pp. 271\u2013278, 2007. Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , pp. 2881\u20132890, 2017. Barret Zoph and Quoc V . Le. Neural architecture search with reinforcement learning. In Proceedings of the 5th International Conference on Learning Representations (ICLR) , 2017."
      },
      "Lc-gan: Image-to-image translation based on generative adversarial network for endoscopic images": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2003.04949",
        "ref_texts": "[33] H. Zhao, J. Shi, X. Qi, et al. , \u201cPyramid scene parsing network,\u201d in Proc. IEEE Conf. Comput. Vis. Pattern Recognit. , pp. 2881\u20132890, 2017.",
        "ref_ids": [
          "33"
        ]
      },
      "A water-obstacle separation and refinement network for unmanned surface vehicles": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2001.01921",
        "ref_texts": "[12] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in IEEE Conf. on Computer Vision and Pattern Recognition (CVPR) , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "12"
        ]
      },
      "Spatialflow: Bridging all tasks for panoptic segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1910.08787",
        "ref_texts": "[5] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition , 2017, pp. 2881\u20132890. JOURNAL OF IEEE TRANSACTIONS ON CIRCUITS AND SYSTEMS FOR VIDEO TECHNOLOGY 11 Image Ground Truth SpatialFlow Fig. 7. An illustration of visualization examples of SpatialFlow on Cityscapes valsplit using a single ResNet-101 network. JOURNAL OF IEEE TRANSACTIONS ON CIRCUITS AND SYSTEMS FOR VIDEO TECHNOLOGY 12",
        "ref_ids": [
          "5"
        ]
      },
      "Encoder\u2013decoder semantic segmentation models for electroluminescence images of thin-film photovoltaic modules": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2010.07556",
        "ref_texts": "[46] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. \u201cPyramid scene parsing network\u201d. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "46"
        ]
      },
      "Multiscale cloud detection in remote sensing images using a dual convolutional neural network": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2006.00836",
        "ref_texts": "[20] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proc. of the IEEE conference on computer vision and pattern recognition , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "20"
        ]
      },
      "Increasing the robustness of semantic segmentation models with painting-by-numbers": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2010.05495",
        "ref_texts": "66. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (2017), http://arxiv.org/abs/1612.01105",
        "ref_ids": [
          "66"
        ]
      },
      "STC-GAN: Spatio-temporally coupled generative adversarial networks for predictive scene parsing": {
        "authors": [],
        "url": "https://jueduilingdu.github.io/data/qi2020stcgan.pdf",
        "ref_texts": "\u2022Extensive experiments on two public benchmarks,i.e., Cityscapes and CamVid , validate the performance of the proposed method over the state-of-the-art. This manuscript is organized as the following. In Section II, we provide a brief overview of the literature related tosemantic segmentation in images and videos, predictive scene parsing, and generative adversarial networks. In Section III, we elaborate details of the proposed STC-GAN architecture.In Section IV, we tabulate the performance of the proposed approach, and end in Section V with a conclusion of this work. II. R ELATED WORK In this section, we briefly review three related aspects, i.e., semantic segmentation, predictive scene parsing, and generative adversarial networks. A. Semantic Segmentation With the emergence of deep learning methods, semantic segmentation has seen large improvements in recent years.Long et al. [8] present an end-to-end Fully Convolutional Network (FCN) for pixel-to-pixel semantic segmentation.SegNet [10] is an FCN-based encoder-decoder network for road and indoor scene understanding. Ronneberger et al. [5] propose a similar encoder-decoder architecture named U-net composed of a contracting path t o capture contextual features and a symmetric expanding path for precise localization. Recently, DeepLab [6] combines fully-connected Conditional Random Field (CRF) and deep convolutional neural net-works, and employs atrous spatial pyramid pooling to encode objects at multiple scales. PSPNet [7] utilizes a multi-scale pyramid module to exploit global contextual information from pyramid layers for scene parsing. Furthermore, a growing number of methods attempt to solve video semanticsegmentation [11]\u2013[20] with deep learning methods. In contrast, our model is proposed to handle the unobserved future scene parsing task. B. Predictive Scene Parsing Limited work strive for this new topic. Jin et al. [1], [2] employ predictive feature learni ng for video scene parsing and optic flow anticipation, where a predictive learning network is integrated to produce structure-preserving parsing results.Luc et al. [3] develop an autoregressive convolutional neural network [9] that can iteratively generate multiple frames for semantic segmentation of future frames. Rochan et al. [21] utilize a convolutional LSTM as encoder to capture the representation of observed frames for future parsing mapprediction. Chen and Han [22] introduce a multi-timescale context encoding approach for scene parsing prediction, which can simultaneously extract both short-term and long-termtemporal relations from the preceding frames, and model semantic interdependencies with an attention mechanism. Zhou et al. [23] design a depth embedded recurrent predictive parsing network to address the same challenge, by leveraging binocular stereo images to mine 3D structure information and a LSTM to capture temporal consistence between observed frames. In this work, we present a novel STC-GAN that can learn spatial and temporal information jointly, andemploy them to generate better future frames and produce the corresponding parsing results. C. GAN Generative Adversarial Networks (GAN) are first introduced to generate images from random noise [24], andhave been widely used in many fields including image synthesis [25]\u2013[27], image editing [28], semantic inpainting [29], future prediction learning [9], [30], [31] and rep-resentation learning [32], [33]. The main idea of GAN is to employ an adversarial loss to f orce the generated images to be indistinguishable from real images. Inspired by CoGAN [34], our proposed STC-GAN model shares the knowledge and representations between a future frame generation model anda predictive scene parsing model with a coupled architecture, by employing a weight-sharing constraint and feature adaptation transform in adversarial training. III. P ROPOSED APPROACH A. Overview The framework of our STC-GAN is illustrated in Fig. 1. Given an input video x,w ed e fi n e xt\u2208Rw\u00d7h\u00d7cas the Authorized licensed use limited to: EPFL LAUSANNE. Downloaded on April 23,2020 at 15:31:31 UTC from IEEE Xplore. Restrictions apply. ",
        "ref_ids": [
          "8",
          "10",
          "5",
          "6",
          "7",
          "11",
          "20",
          "1",
          "2",
          "3",
          "9",
          "21",
          "22",
          "23",
          "24",
          "25",
          "27",
          "28",
          "29",
          "9",
          "30",
          "31",
          "32",
          "33",
          "34"
        ]
      },
      "Image-based place recognition on bucolic environment across seasons from semantic edge description": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1910.12468",
        "ref_texts": "[21] M. Larsson, E. Stenborg, L. Hammarstrand, M. Pollefeys, T. Sattler, and F. Kahl, \u201cA cross-season correspondence dataset for robust semantic segmentation,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , 2019, pp. 9532\u20139542.[22] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "21",
          "22"
        ]
      },
      "Efficienthrnet: Efficient scaling for lightweight high-resolution multi-person pose estimation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2007.08090",
        "ref_texts": ""
      },
      "Determining ground elevations covered by vegetation on construction sites using drone-based orthoimage and convolutional neural network": {
        "authors": [
          "Yuhan Jiang",
          "Yong Bai",
          "Sisi Han"
        ],
        "url": "https://epublications.marquette.edu/cgi/viewcontent.cgi?article=1260&context=civengin_fac",
        "ref_texts": "(MICCAI 2015), 234\u2013 241. Cham, Switzerland: Springer. Sandler, M., A. Howard, M. Zhu, A. Zhmoginov, and L. C. Chen. 2018. \u201cInverted residuals and linear bottlenecks: Mobile networks for classification, detection and segmentation.\u201d Prepint, submitted April 7, 2020. http://arxiv.org/abs/1801.04381. Schneider, S., G. W. Taylor, and S. Kremer. 2018. \u201cDeep learning object detection methods for ecological camera trap data.\u201d In Proc., 2018 15th Conf. on Computer and Robot Vision (CRV), 321\u2013 328. New York: IEEE. Shelhamer, E ., J. Long, and T. Darrell. 2017. \u201cFully convolutional networks for semantic segmentation.\u201d IEEE Trans. Pattern Anal. Mach. Intell. 39 (4): 640 \u2013651. https://0 -doiorg.libus.csd.mu.edu/10.1109/TPAMI.2016.2572683. Siebert, S., and J. Teizer. 2014. \u201cMobile 3D mapping for surveying earthwork projects using an Unmanned Aerial Vehicle (UAV) system.\u201d Autom. Constr. 41 (May): 1 \u201314. https://0 -doiorg.libus.csd.mu.edu/10.1016/j.autcon.2014.01.004. Sung, C., and P. Y. Kim. 2016. \u201c3D terrain reconstruction of construction sites using a stereo camera.\u201d Autom. Constr. 64 (Apr): 65 \u201377. https://0 -doiorg.libus.csd.mu.edu/10.1016/j.autcon.2015.12.022. Theodorus, A., M. Nauta, and C. Seifert. 2020. \u201cEvaluating CNN interpretability on sketch classification.\u201d In Proc., 12th Int. Conf. on Machine Vision (ICMV 2019). Bellingham, WA: Society of Photo -Optical Instrumentation Engineers. https://0 -doiorg.libus.csd.mu.edu/10.1117/12.2559536. Westoby, M. J., J. Brasington, N. F. Glasser, M. J. Hambrey, and J. M. Reynolds. 2012. \u201c\u2018St ructure -from Motion\u2019 photogrammetry: A low -cost, effective tool for geoscience applications.\u201d Geomorphology 179 (Dec): 300 \u2013314. https://0 -doiorg.libus.csd.mu.edu/10.1016/j.geomorph.2012.08.021. Zhao, H., J. Shi, X. Qi, X. Wang, and J. Jia. 2017. \u201cPyramid scene parsing network.\u201d In Proc., 2017 IEEE Conf. on Computer Vision and Pattern Recognition (CVPR), 6230 \u20136239. New York: IEEE. "
      },
      "Coronary artery segmentation in angiographic videos utilizing spatial-temporal information": {
        "authors": [
          "Lu Wang"
        ],
        "url": "https://link.springer.com/content/pdf/10.1186/s12880-020-00509-9.pdf",
        "ref_texts": "12. ZhaoH, ShiJ, QiX, WangX, JiaJ.Pyramidsceneparsingnetwork.In: ProceedingsoftheIEEEConferenceonComputerVisionandPattern Recognition;2017. p.6230\u201339.",
        "ref_ids": [
          "12"
        ]
      },
      "Geolayout: Geometry driven room layout estimation based on depth maps of planes": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2008.06286",
        "ref_texts": "41. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: Proceedings of the IEEE conference on computer vision and pattern recognition. pp. 2881{2890 (2017)",
        "ref_ids": [
          "41"
        ]
      },
      "Dual refinement feature pyramid networks for object detection": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2012.01733",
        "ref_texts": "[48] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In CVPR , 2017. 3, 4, 5, 7, 8",
        "ref_ids": [
          "48"
        ]
      },
      "Deep learning method for comet segmentation and comet assay image analysis": {
        "authors": [
          "Yiyu Hong"
        ],
        "url": "https://www.nature.com/articles/s41598-020-75592-7.pdf",
        "ref_texts": ""
      },
      "Fast soft color segmentation": {
        "authors": [
          "Naofumi Akimoto",
          "Huachun Zhu",
          "Yanghua Jin",
          "Yoshimitsu Aoki"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPR_2020/papers/Akimoto_Fast_Soft_Color_Segmentation_CVPR_2020_paper.pdf",
        "ref_texts": "[35] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "35"
        ]
      },
      "Sgnet: Semantics guided deep stereo matching": {
        "authors": [
          "Shuya Chen",
          "Zhiyu Xiang",
          "Chengyu Qiao",
          "Yiman Chen",
          "Tingming Bai"
        ],
        "url": "https://openaccess.thecvf.com/content/ACCV2020/papers/Chen_SGNet_Semantics_Guided_Deep_Stereo_Matching_ACCV_2020_paper.pdf",
        "ref_texts": ""
      },
      "Depth-adapted CNN for RGB-D cameras": {
        "authors": [
          "Zongwei Wu",
          "Guillaume Allibert",
          "Christophe Stolz",
          "Cedric Demonceaux"
        ],
        "url": "http://openaccess.thecvf.com/content/ACCV2020/papers/Wu_Depth-Adapted_CNN_for_RGB-D_cameras_ACCV_2020_paper.pdf",
        "ref_texts": ""
      },
      "Shape constrained network for eye segmentation in the wild": {
        "authors": [
          "Bingnan Luo",
          "Jie Shen",
          "Shiyang Cheng",
          "Yujiang Wang",
          "Maja Pantic"
        ],
        "url": "http://openaccess.thecvf.com/content_WACV_2020/papers/Luo_Shape_Constrained_Network_for_Eye_Segmentation_in_the_Wild_WACV_2020_paper.pdf",
        "ref_texts": "[42] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "42"
        ]
      },
      "Ore image segmentation method based on u-net and watershed": {
        "authors": [],
        "url": "https://cdn.techscience.cn/uploads/attached/file/20200723/20200723003357_43252.pdf",
        "ref_texts": "578 CMC , vol. 65, no.1, pp. 563-578, 2020 Zhang, W.; Jiang, D. L. (2011): The marker -based watershed segmentation algorithm of ore image. IEEE, International Conference on Communication Software and Networks , pp. 472474. Zhao, H.; Shi, J.; Qi, X.; Wang, X.; Jia, J. (2017): Pyramid scene parsing network. Proceedings of IEEE Conference Computer Vision and Pattern Recognition, pp. 2881 -2890. "
      },
      "Lightweight network architecture for real-time action recognition": {
        "authors": [
          "Alexander Kozlov",
          "Vadim Andronov",
          "Yana Gritsenko"
        ],
        "url": "https://dl.acm.org/doi/pdf/10.1145/3341105.3373906",
        "ref_texts": "[58] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. 2017. Pyramid scene parsing network. In IEEE Conf. on Computer Vision and Pattern Recognition (CVPR). 2881\u20132890.",
        "ref_ids": [
          "58"
        ]
      },
      "Cross domain knowledge learning with dual-branch adversarial network for vehicle re-identification": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1905.00006",
        "ref_texts": "[24] H. Zhao, J. Shi, X. Qi, X. Wang, J. Jia, Pyramid scene parsing network, in: Proceedings of the IEEE conference on computer vision and pattern recognition, 2017, pp. 2881{2890.",
        "ref_ids": [
          "24"
        ]
      },
      "Learning rotation-invariant representations of point clouds using aligned edge convolutional neural networks": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2101.00483",
        "ref_texts": "[33] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "33"
        ]
      },
      "Bidirectional pyramid networks for semantic segmentation": {
        "authors": [
          "Dong Nie",
          "Jia Xue",
          "Xiaofeng Ren"
        ],
        "url": "https://openaccess.thecvf.com/content/ACCV2020/papers/Nie_Bidirectional_Pyramid_Networks_for_Semantic_Segmentation_ACCV_2020_paper.pdf",
        "ref_texts": ""
      },
      "Coupled generative adversarial network for heterogeneous face recognition": {
        "authors": [],
        "url": "https://par.nsf.gov/servlets/purl/10223230",
        "ref_texts": ""
      },
      "MaskedFusion: Mask-based 6D object pose estimation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1911.07771",
        "ref_texts": "32. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: Proceedings of the IEEE conference on computer vision and pattern recognition. pp. 2881{2890 (2017)",
        "ref_ids": [
          "32"
        ]
      },
      "One click lesion RECIST measurement and segmentation on CT scans": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2007.11087",
        "ref_texts": "31. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: CVPR. pp. 2881{2890 (2017)",
        "ref_ids": [
          "31"
        ]
      },
      "Warp to the future: Joint forecasting of features and feature motion": {
        "authors": [
          "Josip Saric",
          "Marin Orsic",
          "Tonci Antunovic",
          "Sacha Vrazic",
          "Sinisa Segvic"
        ],
        "url": "https://openaccess.thecvf.com/content_CVPR_2020/papers/Saric_Warp_to_the_Future_Joint_Forecasting_of_Features_and_Feature_CVPR_2020_paper.pdf",
        "ref_texts": "[38] Yu Yao, Mingze Xu, Chiho Choi, David J. Crandall, Ella M. Atkins, and Behzad Dariush. Egocentric vision-based future vehicle localization for intelligent driving assistance systems. In ICRA , 2019. 1[39] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , July 2017. 4",
        "ref_ids": [
          "38",
          "39"
        ]
      },
      "Beyond fixed grid: Learning geometric image representation with a deformable grid": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2008.09269",
        "ref_texts": "42. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: CVPR (2017)",
        "ref_ids": [
          "42"
        ]
      },
      "MeshCut data augmentation for deep learning in computer vision": {
        "authors": [
          "Wei Jiang",
          "Kai Zhang",
          "Nan Wang",
          "Miao Yu"
        ],
        "url": "https://journals.plos.org/plosone/article/file?id=10.1371/journal.pone.0243613&type=printable",
        "ref_texts": "10. H.S.Zhao, J.P.Shi,X.J.Qi,X.G.Wang, J.Y.Jia.Pyramid Scene Parsing Network. IEEE Conferen ce onComputer Vision AndPatter nRecognition .2017:6230-6 239.",
        "ref_ids": [
          "10"
        ]
      },
      "Multi-scale attention u-net (msaunet): a modified u-net architecture for scene segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2009.06911",
        "ref_texts": "[9] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In IEEE Conference on Computer Vision and Pattern Recognition, pages 62306239, 2017.",
        "ref_ids": [
          "9"
        ]
      },
      "Improving land cover classification using extended multi-attribute profiles (EMAP) enhanced color, near infrared, and LiDAR data": {
        "authors": [],
        "url": "https://www.mdpi.com/2072-4292/12/9/1392/pdf",
        "ref_texts": "29. Zhao, H.; Shi, J.; Qi, X.; Wang, X.; Jia, J. Pyramid Scene Parsing Network. In Proceedings of the 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Honolulu, HI, USA, 21\u201326 July 2017; pp. 6230\u20136239.",
        "ref_ids": [
          "29"
        ]
      },
      "A multispectral and multiangle 3-D convolutional neural network for the classification of ZY-3 satellite images over urban areas": {
        "authors": [
          "Xin Huang",
          "Shuang Li",
          "Jiayi Li",
          "Xiuping Jia",
          "Jun Li",
          "Xiao Xiang",
          "Jon Atli"
        ],
        "url": "https://elib.dlr.de/138665/1/A_Multispectral_and_Multiangle_3-D_Convolutional_Neural_Network_for_the_Classification_of_ZY-3_Satellite_Images_Over_Urban_Areas.pdf",
        "ref_texts": ""
      },
      "A modeling method for automatic extraction of offshore aquaculture zones based on semantic segmentation": {
        "authors": [],
        "url": "https://www.mdpi.com/2220-9964/9/3/145/pdf",
        "ref_texts": "23. Zhao, H.; Shi, J.; Qi, X.; Wang, X.; Jia, J. Pyramid scene parsing network. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Hawaii, HI, USA, 21\u201326 July 2017. [CrossRef]",
        "ref_ids": [
          "23"
        ]
      },
      "Dynamic hierarchical mimicking towards consistent optimization objectives": {
        "authors": [
          "Duo Li",
          "Qifeng Chen"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPR_2020/papers/Li_Dynamic_Hierarchical_Mimicking_Towards_Consistent_Optimization_Objectives_CVPR_2020_paper.pdf",
        "ref_texts": "[51] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In CVPR , 2017.",
        "ref_ids": [
          "51"
        ]
      },
      "Farsee-net: Real-time semantic segmentation by efficient multi-scale context aggregation and feature space super-resolution": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2003.03913",
        "ref_texts": "[40] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In IEEE Conference on Computer Vision and Pattern Recognition , pages 2881\u20132890, 2016.",
        "ref_ids": [
          "40"
        ]
      },
      "Convolutional neural network\u2010based pelvic floor structure segmentation using magnetic resonance imaging in pelvic organ prolapse": {
        "authors": [],
        "url": "https://deepblue.lib.umich.edu/bitstream/handle/2027.42/162690/mp14377_am.pdf?sequence=1",
        "ref_texts": "23H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, Pyramid Scene Parsing Network, in 2017 541 IEEE Conference on Computer Vision and Pattern Recognition (CVPR 2017) , pages 542"
      },
      "Probabilistic graph attention network with conditional kernels for pixel-wise prediction": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2101.02843",
        "ref_texts": "[97] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d arXiv preprint arXiv:1612.01105 , 2016.",
        "ref_ids": [
          "97"
        ]
      },
      "Ehanet: An effective hierarchical aggregation network for face parsing": {
        "authors": [],
        "url": "https://www.mdpi.com/2076-3417/10/9/3135/pdf",
        "ref_texts": "28. Zhao, H.; Shi, J.; Qi, X.; Wang, X.; Jia, J. Pyramid scene parsing network. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Honolulu, HI, USA, 21\u201326 July 2017; pp. 2881\u20132890.",
        "ref_ids": [
          "28"
        ]
      },
      "Multi receptive field network for semantic segmentation": {
        "authors": [
          "Yuan Jianlong",
          "Deng Zelu",
          "Shu Wang",
          "Zhenbo Luo"
        ],
        "url": "http://openaccess.thecvf.com/content_WACV_2020/papers/Jianlong_Multi_Receptive_Field_Network_for_Semantic_Segmentation_WACV_2020_paper.pdf",
        "ref_texts": ""
      },
      "DSNet: An efficient CNN for road scene segmentation": {
        "authors": [],
        "url": "https://www.cambridge.org/core/services/aop-cambridge-core/content/view/7F5F21DD5DA0625F3BB96C9846550904/S2048770320000256a.pdf/dsnet-an-efficient-cnn-for-road-scene-segmentation.pdf",
        "ref_texts": ""
      },
      "Super-BPD: Super boundary-to-pixel direction for fast image segmentation": {
        "authors": [
          "Jianqiang Wan",
          "Yang Liu",
          "Donglai Wei",
          "Xiang Bai",
          "Yongchao Xu"
        ],
        "url": "https://openaccess.thecvf.com/content_CVPR_2020/papers/Wan_Super-BPD_Super_Boundary-to-Pixel_Direction_for_Fast_Image_Segmentation_CVPR_2020_paper.pdf",
        "ref_texts": "[46] Ziming Zhang, Yun Liu, Xi Chen, Yanjun Zhu, Ming-Ming Cheng, Venkatesh Saligrama, and Philip HS Torr. Sequential optimization for efficient high-quality object proposal generation. IEEE Transactions on Pattern Analysis and Machine Intelligence , 40(5):1209\u20131223, 2017. 1[47] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proc. of CVPR , pages 2881\u20132890, 2017. 1",
        "ref_ids": [
          "46",
          "47"
        ]
      },
      "Labelenc: A new intermediate supervision method for object detection": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2007.03282",
        "ref_texts": "45. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: Proceedings of the IEEE conference on computer vision and pattern recognition. pp. 2881{2890 (2017)",
        "ref_ids": [
          "45"
        ]
      },
      "A comparison and strategy of semantic segmentation on remote sensing images": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1905.10231",
        "ref_texts": "12. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In IEEE Conf. on Computer Vision and Pattern Recognition (CVPR), pp. 2881-2 890 (2017).",
        "ref_ids": [
          "12"
        ]
      },
      "Listereo: Generate dense depth maps from lidar and stereo imagery": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1905.02744",
        "ref_texts": "[41] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition , 2017, pp. 2881\u2013",
        "ref_ids": [
          "41"
        ]
      },
      "Learning unbiased zero-shot semantic segmentation networks via transductive transfer": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2007.00515",
        "ref_texts": ""
      },
      "Learning from theodore: A synthetic omnidirectional top-view indoor dataset for deep transfer learning": {
        "authors": [
          "Tobias Scheck",
          "Roman Seidel",
          "Gangolf Hirtz"
        ],
        "url": "http://openaccess.thecvf.com/content_WACV_2020/papers/Scheck_Learning_from_THEODORE_A_Synthetic_Omnidirectional_Top-View_Indoor_Dataset_for_WACV_2020_paper.pdf",
        "ref_texts": "[49] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017. 5",
        "ref_ids": [
          "49"
        ]
      },
      "Leaf to panicle ratio (LPR): a new physiological trait indicative of source and sink relation in japonica rice based on deep learning": {
        "authors": [
          "Zongfeng Yang"
        ],
        "url": "https://link.springer.com/content/pdf/10.1186/s13007-020-00660-y.pdf",
        "ref_texts": ""
      },
      "PointAtrousGraph: Deep hierarchical encoder-decoder with point atrous convolution for unorganized 3D points": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1907.09798",
        "ref_texts": "[3] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "3"
        ]
      },
      "Blended grammar network for human parsing": {
        "authors": [],
        "url": "https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123690188.pdf",
        "ref_texts": "43. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: CVPR (2017)",
        "ref_ids": [
          "43"
        ]
      },
      "TapLab: A fast framework for semantic video segmentation tapping into compressed-domain knowledge": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2003.13260",
        "ref_texts": "[23] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proc. IEEE Conf. Comput. Vis. Pattern Recognit. , July 2017.",
        "ref_ids": [
          "23"
        ]
      },
      "BARNet: Bilinear attention network with adaptive receptive fields for surgical instrument segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2001.07093",
        "ref_texts": "[Zhao et al. , 2017 ]H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In IEEE Conference on Computer Vision and Pattern Recognition , pages 6230\u20136239, July 2017.",
        "ref_ids": [
          "Zhao et al\\. , 2017 "
        ]
      },
      "Dynamic face video segmentation via reinforcement learning": {
        "authors": [
          "Yujiang Wang",
          "Mingzhi Dong",
          "Jie Shen",
          "Yang Wu",
          "Shiyang Cheng",
          "Maja Pantic"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPR_2020/papers/Wang_Dynamic_Face_Video_Segmentation_via_Reinforcement_Learning_CVPR_2020_paper.pdf",
        "ref_texts": "[59] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "59"
        ]
      },
      "Adversarial attacks on monocular depth estimation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2003.10315",
        "ref_texts": "[62] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "62"
        ]
      },
      "Improvement of nerve imaging speed with coherent anti-Stokes Raman scattering rigid endoscope using deep-learning noise reduction": {
        "authors": [
          "Naoki Yamato"
        ],
        "url": "https://www.nature.com/articles/s41598-020-72241-x.pdf",
        "ref_texts": ""
      },
      "Image compression with encoder-decoder matched semantic segmentation": {
        "authors": [
          "Trinh Man",
          "Jinjia Zhou",
          "Yibo Fan"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPRW_2020/papers/w7/Hoang_Image_Compression_With_Encoder-Decoder_Matched_Semantic_Segmentation_CVPRW_2020_paper.pdf",
        "ref_texts": "[16] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017. 1",
        "ref_ids": [
          "16"
        ]
      },
      "Automated processing of remote sensing imagery using deep semantic segmentation: A building footprint extraction case": {
        "authors": [],
        "url": "https://www.mdpi.com/2220-9964/9/8/486/pdf",
        "ref_texts": "35. Zhao, H.; Shi, J.; Qi, X.; Wang, X.; Jia, J. Pyramid Scene Parsing Network. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Honolulu, HI, USA, 21\u201326 July 2017; pp. 2881\u20132890.",
        "ref_ids": [
          "35"
        ]
      },
      "An improved boundary-aware perceptual loss for building extraction from VHR images": {
        "authors": [],
        "url": "https://www.mdpi.com/2072-4292/12/7/1195/pdf",
        "ref_texts": "22. Zhao, H.; Shi, J.; Qi, X.; Wang, X.; Jia, J. Pyramid Scene Parsing Network. In Proceedings of the 30th Ieee Conference on Computer Vision and Pattern Recognition, Honolulu, HI, USA, 21\u201326 July 2017; pp. 6230\u20136239.",
        "ref_ids": [
          "22"
        ]
      },
      "Visual relationship detection using scene graphs: A survey": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2005.08045",
        "ref_texts": "[93] Hengshuang Zhao et al. \u201cPyramid Scene Parsing Network\u201d. In: CVPR . 2017.",
        "ref_ids": [
          "93"
        ]
      },
      "An end-to-end Bayesian segmentation network based on a generative adversarial network for remote sensing images": {
        "authors": [],
        "url": "https://www.mdpi.com/2072-4292/12/2/216/pdf",
        "ref_texts": "18. Zhao, H.; Shi, J.; Qi, X.; Wang, X.; Jia, J. Pyramid scene parsing network. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Honolulu, HI, USA, 21\u201326 July 2017; pp. 2881\u20132890.",
        "ref_ids": [
          "18"
        ]
      },
      "SpikeSEG: Spiking segmentation via STDP saliency mapping": {
        "authors": [],
        "url": "https://strathprints.strath.ac.uk/72071/1/Kirkland_etal_IJCNN_2020_SpikeSEG_spiking_segmentation_via_STDP.pdf",
        "ref_texts": "[5] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid Scene Parsing Network,\u201d in 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) . IEEE, jul 2017, pp. 6230\u20136239. [Online]. Available: http://ieeexplore.ieee.org/document/8100143/",
        "ref_ids": [
          "5",
          "Online"
        ]
      },
      "Spinal cord segmentation in ultrasound medical imagery": {
        "authors": [],
        "url": "https://www.mdpi.com/2076-3417/10/4/1370/pdf",
        "ref_texts": "36. Zhao, H.; Shi, J.; Qi, X.; Wang, X.; Jia, J. Pyramid Scene Parsing Network. In Proceedings of the 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Honolulu, HI, USA, 21\u201326 July 2017; doi:10.1109/cvpr.2017.660. [CrossRef]",
        "ref_ids": [
          "36"
        ]
      },
      "Graphonomy: Universal image parsing via graph reasoning and transfer": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2101.10620",
        "ref_texts": "[44] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in IEEE Conf. Comput. Vis.Pattern Recog., 2017.",
        "ref_ids": [
          "44"
        ]
      },
      "Identification of salt deposits on seismic images using deep learning method for semantic segmentation": {
        "authors": [],
        "url": "https://www.mdpi.com/2220-9964/9/1/24/pdf",
        "ref_texts": "18. Zhao, H.; Shi, J.; Qi, X.; Wang, X.; Jia, J. Pyramid scene parsing network. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Honolulu, HI, USA, 21\u201326 July 2017; IEEE: Piscataway, NJ, USA, 2017; pp. 2881\u20132890.",
        "ref_ids": [
          "18"
        ]
      },
      "Wavelet synthesis net for disparity estimation to synthesize dslr calibre bokeh effect on smartphones": {
        "authors": [
          "Chenchi Luo",
          "Yingmao Li",
          "Kaimo Lin",
          "George Chen",
          "Jun Lee",
          "Jihwan Choi",
          "Youngjun Francis",
          "Michael O. Polley"
        ],
        "url": "https://openaccess.thecvf.com/content_CVPR_2020/papers/Luo_Wavelet_Synthesis_Net_for_Disparity_Estimation_to_Synthesize_DSLR_Calibre_CVPR_2020_paper.pdf",
        "ref_texts": "[15] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition , pp. 2881\u20132890, 2017.",
        "ref_ids": [
          "15"
        ]
      },
      "Domain adaptive transfer attack-based segmentation networks for building extraction from aerial images": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2004.11819",
        "ref_texts": ""
      },
      "Feedback U-Net for cell image segmentation": {
        "authors": [
          "Eisuke Shibuya",
          "Kazuhiro Hotta"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPRW_2020/papers/w57/Shibuya_Feedback_U-Net_for_Cell_Image_Segmentation_CVPRW_2020_paper.pdf",
        "ref_texts": "[4] Zhao, Hengshuang, Shi, J., Qi, X., Wang, X., & Jia, J. Pyramid scene parsing network. In: Proceedings of the IEEE conference on computer vision and pattern recognition . pp. ",
        "ref_ids": [
          "4"
        ]
      },
      "Rethinking learnable tree filter for generic feature transform": {
        "authors": [],
        "url": "https://proceedings.neurips.cc/paper_files/paper/2020/file/2952351097998ac1240cb2ab7333a3d2-Paper.pdf",
        "ref_texts": "[13] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In IEEE Conference on Computer Vision and Pattern Recognition , 2017.",
        "ref_ids": [
          "13"
        ]
      },
      "Robust and efficient object change detection by combining global semantic information and local geometric verification": {
        "authors": [
          "Edith Langer",
          "Timothy Patten",
          "Markus Vincze"
        ],
        "url": "http://ras.papercept.net/images/temp/IROS/files/1295.pdf",
        "ref_texts": "[18] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proc. of IEEE CVPR , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "18"
        ]
      },
      "Seek: A framework of superpixel learning with cnn features for unsupervised segmentation": {
        "authors": [],
        "url": "https://www.mdpi.com/2079-9292/9/3/383/pdf",
        "ref_texts": "64. Zhao, H.; Shi, J.; Qi, X.; Wang, X.; Jia, J. Pyramid Scene Parsing Network. In Proceedings of the 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Honolulu, HI, USA, 21\u201326 July 2017.",
        "ref_ids": [
          "64"
        ]
      },
      "SEMEDA: Enhancing segmentation precision with semantic edge aware loss": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1905.01892",
        "ref_texts": "[47] H. Zhao, J. Shi, X. Qi, and J. Jia. Pyramid scene parsing network. In Conference on Computer Vision and Pattern Recognition , 2017.",
        "ref_ids": [
          "47"
        ]
      },
      "Urban function as a new perspective for adaptive street quality assessment": {
        "authors": [],
        "url": "https://www.mdpi.com/2071-1050/12/4/1296/pdf",
        "ref_texts": "31. Zhao, H.; Shi, J.; Qi, X.; Wang, X.; Jia, J. Pyramid Scene Parsing Network. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Salt Lake City, UT, USA, 21\u201326 July 2017; pp. 2881\u20132890.",
        "ref_ids": [
          "31"
        ]
      },
      "Refined UNet V2: End-to-end patch-wise network for noise-free cloud and shadow segmentation": {
        "authors": [
          "Libin Jiao",
          "Lianzhi Huo",
          "Changmiao Hu",
          "Ping Tang"
        ],
        "url": "https://www.mdpi.com/2072-4292/12/21/3530/pdf",
        "ref_texts": "19. Zhao, H.; Shi, J.; Qi, X.; Wang, X.; Jia, J. Pyramid Scene Parsing Network. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Honolulu, HI, USA, 21\u201326 July 2017. Remote Sens. 2020 ,12, 3530 19 of 21",
        "ref_ids": [
          "19"
        ]
      },
      "Openrooms: An end-to-end open framework for photorealistic indoor scene datasets": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2007.12868",
        "ref_texts": "[62] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proc. CVPR , 2017. 2, 7, 8",
        "ref_ids": [
          "62"
        ]
      },
      "Task decomposition and synchronization for semantic biomedical image segmentation": {
        "authors": [
          "Tiffany Mc"
        ],
        "url": "https://arxiv.org/pdf/1905.08720",
        "ref_texts": " dilated convolution [10] in both encoder and decoder. A context encoding module strengthens deep supervision by incorporating semantic encoding loss. Pyramid scene parsing network (PSPNet ) [2] has the traditional dilated FCN architecture for pixel prediction, while this network extends the pixel -level feature s to the specially designed global pyramid pooling features . The local and global cues together make the final prediction more reliable. However, a sophisticated network in deep learning often needs a massive amount of data to train. Whereas a common yet critical challenge in biomedical image segmentation arises due to the limited size of the dataset \u2013 ROBOT181, REFUGE182 and BRATS18 [11], which are all widely used benchmark datasets in biomedical image segmentation and considered in this paper as well, have only 2 ,235, 400 and 285 subjects for training, respectively. To this end, it is essential to probe how to adapt the network for sma ll medical image datasets. While the datasets used in this paper are highly diverse, they all share the same goal of semantic segmentation. ",
        "ref_ids": [
          "10",
          "2",
          "11"
        ]
      },
      "A survey on sensor technologies for unmanned ground vehicles": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2007.01992",
        "ref_texts": "[82] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \"Pyramid Scene Parsing Network,\" 2016. ",
        "ref_ids": [
          "82"
        ]
      },
      "A two-stage attention aware method for train bearing shed oil inspection based on convolutional neural networks": {
        "authors": [
          "Xiao Fu"
        ],
        "url": "http://www.cs.newpaltz.edu/~lik/publications/Xiao-Fu-NC-2019.pdf",
        "ref_texts": "[47] H. Zhao , J. Shi , X. Qi , X. Wang , J. Jia , Pyramid Scene Parsing Network, in: Proceedings of the IEEE conference on computer vision and pattern recognition, ",
        "ref_ids": [
          "47"
        ]
      },
      "Multi-sequence cardiac MR segmentation with adversarial domain adaptation network": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1910.12514",
        "ref_texts": "14. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. pp. 2881{2890 (2017)",
        "ref_ids": [
          "14"
        ]
      },
      "Understanding road layout from videos as a whole": {
        "authors": [
          "Buyu Liu",
          "Bingbing Zhuang",
          "Samuel Schulter",
          "Pan Ji",
          "Manmohan Chandraker"
        ],
        "url": "https://openaccess.thecvf.com/content_CVPR_2020/papers/Liu_Understanding_Road_Layout_From_Videos_as_a_Whole_CVPR_2020_paper.pdf",
        "ref_texts": "[41] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid Scene Parsing Network. In CVPR , 2017.",
        "ref_ids": [
          "41"
        ]
      },
      "Functional architecture for autonomous driving and its implementation": {
        "authors": [],
        "url": "https://www.edi.lv/wp-content/uploads/2020/09/Functional-architecture-for-autonomous-driving-and-its-implementation-.pdf",
        "ref_texts": "[27] Zhao, H., Shi, J., Qi, X., Wang, X ., & Jia, J. (2017). Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 2881 -2890). ",
        "ref_ids": [
          "27"
        ]
      },
      "Panoptic 3D mapping and object pose estimation using adaptively weighted semantic information": {
        "authors": [],
        "url": "http://iliad-project.eu/wp-content/uploads/papers/hoang-2020-panoptic.pdf",
        "ref_texts": "[22] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proc. IEEE Conf. Comput. Vision P attern Recognit. , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "22"
        ]
      },
      "Single-shot panoptic segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1911.00764",
        "ref_texts": "[2] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid Scene Parsing Network,\u201d in IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , July 2017.",
        "ref_ids": [
          "2"
        ]
      },
      "A one-stage approach for surface anomaly detection with background suppression strategies": {
        "authors": [],
        "url": "https://www.mdpi.com/1424-8220/20/7/1829/pdf",
        "ref_texts": "11. Zhao, H.; Shi, J.; Qi, X.; Wang, X.; Jia, J. Pyramid Scene Parsing Network. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Honolulu, HI, USA, 21\u201326 July 2017; pp. 2881\u20132890.",
        "ref_ids": [
          "11"
        ]
      },
      "Deep-learning assisted high-resolution binocular stereo depth reconstruction": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1912.05012",
        "ref_texts": "[7] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "7"
        ]
      },
      "Pavement crack detection with deep learning based on attention mechanism": {
        "authors": [],
        "url": "https://www.jcad.cn/en/article/pdf/preview/10.3724/SP.J.1089.2020.18059.pdf",
        "ref_texts": "[1 3 ] Z h a o H S , S h i J P , Q i X J , et al . Pyramid scene parsing network[C] //Proceedings of the 30th IEEE Conference on Computer Vision and Pattern Recognition. Los Alamitos: IEEE Computer Society Press, 2017: 6230-6239 ",
        "ref_ids": [
          "1 3 ",
          "C"
        ]
      },
      "Custom dilated edge detection filters": {
        "authors": [],
        "url": "https://otik.uk.zcu.cz/bitstream/11025/38463/1/G83.pdf",
        "ref_texts": "[Zhao et al., 2017] Zhao, H., Shi, J., Qi, X., Wang, X., and Jia, J. (2017). Pyramid scene parsing network. In2017 IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2017, Honolulu, HI, USA, July 21-26, 2017, pages 6230\u20136239. IEEE Computer Society.APPENDIX a) b) c) d) e) f) g) h) i) j) k) l) m) n) o) p) q) r) s) Figure 21: a) Original image, b) 3 \u00023 Sobel, c) 5\u00025 extended Sobel, d) 5 \u00025 dilated Sobel, e) 7 \u00027 extended Sobel, f) 7\u00027 dilated Sobel, g) 3 \u00023 Prewitt, h) 5\u00025 extended Prewitt, i) 5 \u00025 dilated Prewitt, j) 7 \u00027 extended Prewitt, k) 7 \u00027 dilated Prewitt, l) 3 \u00023 Scharr, m) 5\u00025 extended Scharr, n) 5 \u00025 dilated Scharr, o)",
        "ref_ids": [
          "Zhao et al\\., 2017"
        ]
      },
      "Towards deep learning assisted autonomous UAVs for manipulation tasks in GPS-denied environments": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2101.06414",
        "ref_texts": "[10] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2017.",
        "ref_ids": [
          "10"
        ]
      },
      "Data logic structure and key technologies on intelligent high-precision map": {
        "authors": [],
        "url": "http://jggs.chinasmp.com/CN/article/downloadArticleFile.do?attachType=PDF&id=67",
        "ref_texts": ""
      },
      "Pp-linknet: Improving semantic segmentation of high resolution satellite imagery with multi-stage training": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2010.06932",
        "ref_texts": ""
      },
      "Match Feature U-Net: Dynamic receptive field networks for biomedical image segmentation": {
        "authors": [],
        "url": "https://www.mdpi.com/2073-8994/12/8/1230/pdf",
        "ref_texts": "19. Zhao, H.; Shi, J.; Qi, X.; Wang, X.; Jia, J. Pyramid scene parsing network. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Honolulu, HI, USA, 21\u201326 July 2017; pp. 2881\u20132890.",
        "ref_ids": [
          "19"
        ]
      },
      "Background segmentation for vehicle re-identification": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1910.06613",
        "ref_texts": "25. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. pp. 2881{2890 (2017)",
        "ref_ids": [
          "25"
        ]
      },
      "EPSNet: efficient panoptic segmentation network with cross-layer attention fusion": {
        "authors": [
          "Yuan Chang",
          "En Chang",
          "Yung Hsiao",
          "Chen Fu"
        ],
        "url": "https://openaccess.thecvf.com/content/ACCV2020/papers/Chang_EPSNet_Efficient_Panoptic_Segmentation_Network_with_Cross-layer_Attention_Fusion_ACCV_2020_paper.pdf",
        "ref_texts": ""
      },
      "Improving 3-m resolution land cover mapping through efficient learning from an imperfect 10-m resolution map": {
        "authors": [],
        "url": "https://www.mdpi.com/2072-4292/12/9/1418/pdf",
        "ref_texts": "30. Zhao, H.; Shi, J.; Qi, X.; Wang, X.; Jia, J. Pyramid scene parsing network. In Proceedings of the IEEE Conference on CVPR, Honolulu, HI, USA, 21\u201326 July 2017; pp. 2881\u20132890.",
        "ref_ids": [
          "30"
        ]
      },
      "Convolution-weight-distribution assumption: Rethinking the criteria of channel pruning": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2004.11627",
        "ref_texts": "[72] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "72"
        ]
      },
      "Deep ice layer tracking and thickness estimation using fully convolutional networks": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2009.00191",
        "ref_texts": "[30] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , July 2017.",
        "ref_ids": [
          "30"
        ]
      },
      "TESA: Tensor element self-attention via matricization": {
        "authors": [
          "Francesca Babiloni",
          "Ioannis Marras",
          "Gregory Slabaugh",
          "Stefanos Zafeiriou"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPR_2020/papers/Babiloni_TESA_Tensor_Element_Self-Attention_via_Matricization_CVPR_2020_paper.pdf",
        "ref_texts": "[50] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017. 4322",
        "ref_ids": [
          "50"
        ]
      },
      "U2-ONet: A Two-Level Nested Octave U-Structure Network with a Multi-Scale Attention Mechanism for Moving Object Segmentation": {
        "authors": [
          "Chenjie Wang",
          "Chengyuan Li",
          "Jun Liu",
          "Bin Luo",
          "Xin Su",
          "Yajun Wang",
          "Yan Gao"
        ],
        "url": "https://www.mdpi.com/2072-4292/13/1/60/pdf",
        "ref_texts": "63. Zhao, H.; Shi, J.; Qi, X.; Wang, X.; Jia, J. Pyramid scene parsing network. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Honolulu, HI, USA, 21\u201326 June 2017; pp. 2881\u20132890.",
        "ref_ids": [
          "63"
        ]
      },
      "Rgb2lidar: Towards solving large-scale cross-modal visual localization": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2009.05695",
        "ref_texts": ""
      },
      "Real-time semantic scene completion via feature aggregation and conditioned prediction": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2303.10967",
        "ref_texts": "[36] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia, \u201cPyramid scene parsing network,\u201d in CVPR . 2017, pp. 6230\u20136239, IEEE Computer Society.",
        "ref_ids": [
          "36"
        ]
      },
      "Spaceborne SAR data for regional urban mapping using a robust building extractor": {
        "authors": [],
        "url": "https://www.mdpi.com/2072-4292/12/17/2791/pdf",
        "ref_texts": "44. Zhao, H.; Shi, J.; Qi, X.; Wang, X.; Jia, J. Pyramid Scene Parsing Network. In Proceedings of the 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Honolulu, HI, USA, 21\u201326 July 2017.",
        "ref_ids": [
          "44"
        ]
      },
      "Self-supervised representation learning for visual anomaly detection": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2006.09654",
        "ref_texts": "[20] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "20"
        ]
      },
      "MNL-network: A multi-scale non-local network for epilepsy detection from EEG signals": {
        "authors": [
          "Qinyuan Liu"
        ],
        "url": "https://www.frontiersin.org/articles/10.3389/fnins.2020.00870/pdf",
        "ref_texts": ""
      },
      "Architecture search of dynamic cells for semantic video segmentation": {
        "authors": [
          "Vladimir Nekrasov",
          "Hao Chen",
          "Chunhua Shen",
          "Ian Reid"
        ],
        "url": "https://openaccess.thecvf.com/content_WACV_2020/papers/Nekrasov_Architecture_Search_of_Dynamic_Cells_for_Semantic_Video_Segmentation_WACV_2020_paper.pdf",
        "ref_texts": "[32] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In Proc. IEEE Conf. Comp. Vis. Patt. Recogn. , 2017.",
        "ref_ids": [
          "32"
        ]
      },
      "DEDNet: Offshore eddy detection and location with HF radar by deep learning": {
        "authors": [],
        "url": "https://www.mdpi.com/1424-8220/21/1/126/pdf",
        "ref_texts": "34. Zhao, H.; Shi, J.; Qi, X.; Wang, X.; Jia, J. Pyramid Scene Parsing Network. In Proceedings of the 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Honolulu, HI, USA, 21\u201326 July 2017; pp. 1063\u20136919.",
        "ref_ids": [
          "34"
        ]
      },
      "Farm area segmentation in satellite images using deeplabv3+ neural networks": {
        "authors": [
          "Markus Richter"
        ],
        "url": "https://researchportal.tuni.fi/files/22496013/Manuscript_sprv2_1_.pdf",
        "ref_texts": "61. H. Zhao, J. Shi, X. Qi, X. Wang, and J.J.: Pyramid scene parsing network. arXiv:1612.01105. (2016). ",
        "ref_ids": [
          "61"
        ]
      },
      "Self-supervised depth estimation to regularise semantic segmentation in knee arthroscopy": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2007.02361",
        "ref_texts": "22. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: Proceedings of the IEEE conference on computer vision and pattern recognition. pp. 2881{2890 (2017)",
        "ref_ids": [
          "22"
        ]
      },
      "Graph motif entropy for understanding time-evolving networks": {
        "authors": [],
        "url": "https://eprints.whiterose.ac.uk/165963/1/motif_entropy_0727.pdf",
        "ref_texts": "[3] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , July 2017.",
        "ref_ids": [
          "3"
        ]
      },
      "MT-DSSD: Deconvolutional single shot detector using multi task learning for object detection, segmentation, and grasping detection": {
        "authors": [],
        "url": "http://mprg.jp/data/MPRG/C_group/C20200603_araki.pdf",
        "ref_texts": "[30] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid Scene Parsing Network,\u201d in IEEE Conference on Computer Vision and Pattern Recognition , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "30"
        ]
      },
      "Bayesian feature pyramid networks for automatic multi-label segmentation of chest X-rays and assessment of cardio-thoratic ratio": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1908.02924",
        "ref_texts": "[44] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2017. 5, 6",
        "ref_ids": [
          "44"
        ]
      },
      "Robust semantic segmentation by redundant networks with a layer-specific loss contribution and majority vote": {
        "authors": [
          "Andreas Bar",
          "Marvin Klingner",
          "Serin Varghese",
          "Fabian Huger",
          "Peter Schlicht",
          "Tim Fingscheidt"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPRW_2020/papers/w20/Bar_Robust_Semantic_Segmentation_by_Redundant_Networks_With_a_Layer-Specific_Loss_CVPRW_2020_paper.pdf",
        "ref_texts": "[81] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid Scene Parsing Network. In Proc. of CVPR , pages 2881\u20132890, Honulu, HI, USA, July 2017.",
        "ref_ids": [
          "81"
        ]
      },
      "A mixture of views network with applications to multi-view medical imaging": {
        "authors": [
          "Yaniv Shachor"
        ],
        "url": "https://www.eng.biu.ac.il/goldbej/files/2021/11/Yaniv_2000.pdf",
        "ref_texts": "[33] H. Zhao, J. Shi, X. Qi, X. Wang, J. Jia, Pyramid scene parsing network, CoRR ",
        "ref_ids": [
          "33"
        ]
      },
      "Adaptive semantic segmentation for unmanned surface vehicle navigation": {
        "authors": [],
        "url": "https://www.mdpi.com/2079-9292/9/2/213/pdf",
        "ref_texts": "45. Zhao, H.; Shi, J.; Qi, X.; Wang, X.; Jia, J. Pyramid scene parsing network. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Honolulu, HI, USA, 21\u201326 July 2017; pp. 2881\u20132890.",
        "ref_ids": [
          "45"
        ]
      },
      "Windowed bundle adjustment framework for unsupervised learning of monocular depth estimation with u-net extension and clip loss": {
        "authors": [],
        "url": "https://www.cs.cmu.edu/~kaess/pub/Zhou20ral.pdf",
        "ref_texts": "[18] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in CVPR , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "18"
        ]
      },
      "\u56fe\u50cf\u5206\u5272\u65b9\u6cd5\u7efc\u8ff0": {
        "authors": [],
        "url": "https://mool.njfu.edu.cn/file/up_document/2021/03/99QZPCtidJ56xNBi.pdf",
        "ref_texts": "\u5377\u79ef\u7f51\u7edc(fullconvolutionalnetwork ,FCN)\u3001 \u91d1\u5b57\u5854\u573a\u666f\u89e3\u6790\u7f51\u7edc( pyramidsceneparsingnetwork ,PSPNet)\u3001DeepLab \u3001Mask R-CNN; \u6700\u540e\u5728\u56fe\u50cf\u5206\u5272\u7684\u5e38\u7528\u6570\u636e\u96c6\u4e0a\u5bf9\u540c\u7c7b\u65b9\u6cd5\u8fdb\u884c\u4e86\u6027\u80fd\u6bd4\u8f83\u548c\u5206\u6790\u3002"
      },
      "Structured convolutions for efficient neural network design": {
        "authors": [],
        "url": "https://proceedings.neurips.cc/paper/2020/file/3be0214185d6177a9aa6adea5a720b09-Paper.pdf",
        "ref_texts": ""
      },
      "3d guided weakly supervised semantic segmentation": {
        "authors": [
          "Weixuan Sun",
          "Jing Zhang",
          "Nick Barnes"
        ],
        "url": "http://openaccess.thecvf.com/content/ACCV2020/papers/Sun_3D_Guided_Weakly_Supervised_Semantic_Segmentation_ACCV_2020_paper.pdf",
        "ref_texts": ""
      },
      "Dense dual-path network for real-time semantic segmentation": {
        "authors": [
          "Xinneng Yang",
          "Yan Wu",
          "Junqiao Zhao",
          "Feilin Liu"
        ],
        "url": "http://openaccess.thecvf.com/content/ACCV2020/papers/Yang_Dense_Dual-Path_Network_for_Real-time_Semantic_Segmentation_ACCV_2020_paper.pdf",
        "ref_texts": ""
      },
      "A survey on novel estimation approach of motion controllers for self-driving cars": {
        "authors": [],
        "url": "https://scholar.archive.org/work/rz3gqljl5rgljaqh7hf4pyjg3m/access/wayback/https://irojournals.com/iroei/V2/I4/03.pdf",
        "ref_texts": "[6] H. Zhao, J. Shi, X. Qi, X. Wang, J. Jia, Pyramid scene parsing network, Proc. of IEEE Conference o n Computer Vision and Pattern Recognition (2017). ",
        "ref_ids": [
          "6"
        ]
      },
      "Low-bit quantization needs good distribution": {
        "authors": [
          "Haibao Yu",
          "Tuopu Wen",
          "Guangliang Cheng",
          "Jiankai Sun",
          "Qi Han",
          "Jianping Shi"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPRW_2020/papers/w40/Yu_Low-Bit_Quantization_Needs_Good_Distribution_CVPRW_2020_paper.pdf",
        "ref_texts": "[31] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In IEEE Conf. on Computer Vision and Pattern Recognition (CVPR) , pages 2881\u20132890, 2017. 1",
        "ref_ids": [
          "31"
        ]
      },
      "Model-based occlusion disentanglement for image-to-image translation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2004.01071",
        "ref_texts": "53. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: CVPR (2017)",
        "ref_ids": [
          "53"
        ]
      },
      "Distribution of urban blue and green space in beijing and its influence factors": {
        "authors": [],
        "url": "https://www.mdpi.com/2071-1050/12/6/2252/pdf",
        "ref_texts": "33. Zhao, H.; Shi, J.; Qi, X.; Wang, X.; Jia, J. Pyramid scene parsing network. In Proceedings of the 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Honolulu, HI, USA, 21\u201326 July 2017; pp. 6230\u20136239.",
        "ref_ids": [
          "33"
        ]
      },
      "Compact cloud detection with bidirectional self-attention knowledge distillation": {
        "authors": [
          "Firstname Lastname",
          "Firstname Lastname",
          "Firstname Lastname"
        ],
        "url": "https://www.mdpi.com/2072-4292/12/17/2770/pdf",
        "ref_texts": "23. Zhao, H.; Shi, J.; Qi, X.; Wang, X.; Jia, J. Pyramid scene parsing network. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Honolulu, HI, USA, 21\u201326 July 2017; pp. 2881\u20132890.",
        "ref_ids": [
          "23"
        ]
      },
      "Multimodal image outpainting with regularized normalized diversification": {
        "authors": [
          "Lingzhi Zhang",
          "Jianbo Shi"
        ],
        "url": "https://openaccess.thecvf.com/content_WACV_2020/papers/Zhang_Multimodal_Image_Outpainting_With_Regularized_Normalized_Diversification_WACV_2020_paper.pdf",
        "ref_texts": "[53] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "53"
        ]
      },
      "Domain adaptation through task distillation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2008.11911",
        "ref_texts": "58. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: CVPR (2017)",
        "ref_ids": [
          "58"
        ]
      },
      "ORDNet: Capturing omni-range dependencies for scene parsing": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2101.03929",
        "ref_texts": "[1] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in CVPR , 2017. 1, 3, 10 IEEE TRANSACTIONS ON IMAGE PROCESSING 12",
        "ref_ids": [
          "1"
        ]
      },
      "MBNet: A multi-task deep neural network for semantic segmentation and lumbar vertebra inspection on X-ray images": {
        "authors": [
          "Van Luan",
          "Yung Lin",
          "Wei Liu"
        ],
        "url": "https://openaccess.thecvf.com/content/ACCV2020/papers/Van_Luan_Tran_MBNet_A_Multi-Task_Deep_Neural_Network_for_Semantic_Segmentation_and_ACCV_2020_paper.pdf",
        "ref_texts": ""
      },
      "A convolutional neural network with parallel multi-scale spatial pooling to detect temporal changes in SAR images": {
        "authors": [],
        "url": "https://www.mdpi.com/2072-4292/12/10/1619/pdf",
        "ref_texts": "15. Zhao, H.; Shi, J.; Qi, X.; Wang, X.; Jia, J. Pyramid scene parsing network. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Honolulu, HI, USA, 21\u201326 July 2017; pp. 2881\u20132890.",
        "ref_ids": [
          "15"
        ]
      },
      "Scan2plan: Efficient floorplan generation from 3d scans of indoor scenes": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2003.07356",
        "ref_texts": "40. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: Proceedings of the IEEE conference on computer vision and pattern recognition. pp. 2881{2890 (2017)",
        "ref_ids": [
          "40"
        ]
      },
      "Robust brain magnetic resonance image segmentation for hydrocephalus patients: Hard and soft attention": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2001.03857",
        "ref_texts": "[12] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia, \u201cPyramid scene parsing network,\u201d inProceedings of the IEEE conference on computer vision and pattern recognition , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "12"
        ]
      },
      "Impact of ground truth annotation quality on performance of semantic image segmentation of traffic conditions": {
        "authors": [
          "Windows User"
        ],
        "url": "https://arxiv.org/pdf/1901.00001",
        "ref_texts": "11. Zhao, H., Shi, J., Qi, X., Wang, X., and Jia, J. : Pyramid scene parsing network. In : IEEE Conf. on Computer Vision and Patte rn Recognition (CVPR) , 2881 -2890 (2017 ). ",
        "ref_ids": [
          "11"
        ]
      },
      "Human attribute recognition\u2014a comprehensive survey": {
        "authors": [],
        "url": "https://www.mdpi.com/2076-3417/10/16/5608/pdf",
        "ref_texts": ""
      },
      "SceneAdapt: Scene-based domain adaptation for semantic segmentation using adversarial learning": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2006.10386",
        "ref_texts": "(2017b). Pyramid scene parsing network. In IEEE Conf. on Computer Vision and Pattern Recognition (CVPR) , pages 2881{2890. Zhu, J.-Y., Park, T., Isola, P., and Efros, A. A."
      },
      "A generalized multi-task learning approach to stereo DSM filtering in urban areas": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2004.02493",
        "ref_texts": "[24] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. \u201cPyramid Scene Parsing Network\u201d. In: Conference on Computer Vision and Pattern Recognition . 2017, pp. 6230\u20136239.",
        "ref_ids": [
          "24"
        ]
      },
      "Boosting connectivity in retinal vessel segmentation via a recursive semantics-guided network": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2004.12776",
        "ref_texts": "17. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: Conference on Computer Vision and Pattern Recognition (CVPR) (2017)",
        "ref_ids": [
          "17"
        ]
      },
      "Learning to learn parameterized classification networks for scalable input images": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2007.06181",
        "ref_texts": "38. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: CVPR (2017)",
        "ref_ids": [
          "38"
        ]
      },
      "Meticulous object segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2012.07181",
        "ref_texts": "[47] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017. 3, 8, 13",
        "ref_ids": [
          "47"
        ]
      },
      "Deep multiphase level set for scene parsing": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1910.03166",
        "ref_texts": "[8] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in CVPR , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "8"
        ]
      },
      "Robust semantic segmentation in adverse weather conditions by means of fast video-sequence segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2007.00290",
        "ref_texts": "[15] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. CoRR , abs/1612.01105, 2016.",
        "ref_ids": [
          "15"
        ]
      },
      "Exploiting the transferability of deep learning systems across multi-modal retinal scans for extracting retinopathy lesions": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2006.02662",
        "ref_texts": "[22] H. Zhao et al. , \u201cPyramid scene parsing network,\u201d in IEEE CVPR . 2017.",
        "ref_ids": [
          "22"
        ]
      },
      "HRCenterNet: An anchorless approach to Chinese character segmentation in historical documents": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2012.05739",
        "ref_texts": "[26] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid Scene Parsing Network,\u201d arXiv:1612.01105 [cs] , Apr. 2017, Accessed: Sep. 15, 2020. ",
        "ref_ids": [
          "26",
          "cs"
        ]
      },
      "Quadtree generating networks: Efficient hierarchical scene parsing with sparse convolutions": {
        "authors": [
          "Kashyap Chitta",
          "Jose M. Alvarez",
          "Martial Hebert"
        ],
        "url": "http://openaccess.thecvf.com/content_WACV_2020/papers/Chitta_Quadtree_Generating_Networks_Efficient_Hierarchical_Scene_Parsing_with_Sparse_Convolutions_WACV_2020_paper.pdf",
        "ref_texts": "[46] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In CVPR , 2017. 1,2,7",
        "ref_ids": [
          "46"
        ]
      },
      "Segmentation of the distal femur in ultrasound images": {
        "authors": [],
        "url": "https://www.degruyter.com/document/doi/10.1515/cdbme-2020-0034/pdf",
        "ref_texts": "18. Wang J, Sun K, Cheng T, Jiang B, Deng C, Zhao Y, et al. TPAMI: deep high-resolution representation learning for visual recognition. In: IEEE transactions on pattern analysis andmachine intelligence; 2020.4 Hohlmann et al.: Distal femur in ultrasound images 19. Zhao H, Shi J, Qi X, Wang X, Jia J. Pyramid scene parsing network. In: The IEEE Conference on Computer Vision and Pattern Recognition (CVPR); 2017. https://doi.org/10.1109/CVPR.2017.660.",
        "ref_ids": [
          "18"
        ]
      },
      "Water segmentation with deep learning models for flood detection and monitoring": {
        "authors": [],
        "url": "https://iris.unito.it/bitstream/2318/1832212/1/2208_MirkoZaffaroni%2BClaudioRossi2020.pdf",
        "ref_texts": ". Zhao,H.,Shi,J.,Qi,X.,Wang,X.,andJia,J.(2016).\u201cPyramidSceneParsingNetwork\u201d.In: CoRR abs/1612.01105. arXiv: 1612.01105"
      },
      "Attention-guided multi-scale segmentation neural network for interactive extraction of region objects from high-resolution satellite imagery": {
        "authors": [],
        "url": "https://www.mdpi.com/2072-4292/12/5/789/pdf",
        "ref_texts": "19. Zhao, H.; Shi, J.; Qi, X.; Wang, X.; Jia, J. Pyramid Scene Parsing Network. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Honolulu, HI, USA, 21\u201326 July 2017; pp. 2881\u20132890.",
        "ref_ids": [
          "19"
        ]
      },
      "Learning affordance segmentation: An investigative study": {
        "authors": [],
        "url": "https://www.conferences.com.au/wp-content/uploads/2020/09/59_CameraReady-1.pdf",
        "ref_texts": "[13] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "13"
        ]
      },
      "Assessment of mixed sward using context sensitive convolutional neural networks": {
        "authors": [
          "Christopher J. Bateman"
        ],
        "url": "https://www.frontiersin.org/articles/10.3389/fpls.2020.00159/pdf",
        "ref_texts": "(2017). Estimation of the botanical composition of clover-grass leys from RGB images using data simulation and fully convolutional neural networks. Sensors (Switzerland) 17. doi: 10.3390/s17122930 Smith, K., and Spangenberg, G. (2014). Forage breeding for changing environments and production systems: an overview. Crop Pasture Sci. 65, i\u2013 ii. doi: 10.1071/CPv65n11_FO Tensor flow (2016). http://download.tensor flow.org/models/vgg_16_2016_08_28.tar.gz. Walter, A., Studer, B., and K\u00f6lliker, R. (2012). Advanced phenotyping offers opportunities for improved breeding of forage and turf species. Ann. Bot. 110, 1271\u20131279. doi: 10.1093/aob/mcs026 Zhang, H., Dana, K., Shi, J., Zhang, Z., Wang, X., Tyagi, A., et al. (2018). Context Encoding for Semantic Segmentation 7151 \u20137160. doi: 10.1109/CVPR.2018.00747 Zhao, H., Shi, J., Qi, X., Wang, X., and Jia, J. (2017). Pyramid scene parsing network 6230 \u20136239. doi: 10.1109/CVPR.2017.660 Conflict of Interest: The authors declare that this study received funding from Pastoral Genomics \u2014a joint venture co-funded by DairyNZ, Beef+Lamb New Zealand, Dairy Australia, AgResearch Ltd, New Zealand Agriseeds Ltd, Grasslands Innovation Ltd, and the Ministry of Business, Innovation and Employment (New Zealand). Pastoral Genomics has interests in developing technology that has potential to be commercialised for adding value to the forage breeding industry, and have involvement in setting the overall goals and vision of the Pastoral Genomics research programme. This relationship did not in fluence study design, data collection and analysis, decision to publish, or preparation of the manuscript. Lincoln Agritech Ltd. and Red Fern S olutions are independent research organisations that were subcontract ed to conduct part of this research. Development of the LC-Net architecture was internally funded by Lincoln Agritech Limited. All other authors declare no competing interests. The handling editor is currently organizing a Research Topic with one of the authors KG and con firms the absence of any other collaboration. Copyright \u00a9 2020 Bateman, Fourie, Hsiao, Irie, Heslop, Hilditch, Hagedorn, Jessep, Gebbie and Ghamkhar. This is an open-access article distributed under the terms of the Creative Commons Attribution License (CC BY). The use, distribution or reproduction in other forums is permitted, provided the original author(s) and the copyright owner(s) are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. No use, distribution orreproduction is permitted which does not comply with these terms.Bateman et al. Assessment of Mixed Sward Using CNNs Frontiers in Plant Science | www.frontiersin.org February 2020 | Volume 11 | Article 159 12"
      },
      "An efficient lens structures segmentation method on as-oct images": {
        "authors": [],
        "url": "https://ufoym.com/pdf/paper-2020-EMBC-B.pdf",
        "ref_texts": "[11] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "11"
        ]
      },
      "Suw-learn: Joint supervised, unsupervised, weakly supervised deep learning for monocular depth estimation": {
        "authors": [
          "Haoyu Ren",
          "Aman Raj",
          "Mostafa El",
          "Jungwon Lee"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPRW_2020/papers/w45/Ren_SUW-Learn_Joint_Supervised_Unsupervised_Weakly_Supervised_Deep_Learning_for_Monocular_CVPRW_2020_paper.pdf",
        "ref_texts": "[28] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "28"
        ]
      },
      "Context-integrated and feature-refined network for lightweight object parsing": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1907.11474",
        "ref_texts": "[7] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid Scene Parsing Network,\u201d in Proc. the 30th IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2017, pp. 6230-6239.",
        "ref_ids": [
          "7"
        ]
      },
      "Less is more: Sample selection and label conditioning improve skin lesion segmentation": {
        "authors": [
          "Vinicius Ribeiro",
          "Sandra Avila",
          "Eduardo Valle"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPRW_2020/papers/w42/Ribeiro_Less_Is_More_Sample_Selection_and_Label_Conditioning_Improve_Skin_CVPRW_2020_paper.pdf",
        "ref_texts": "[46] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In IEEE Conf. on Computer Vision and Pattern Recognition (CVPR) , pages 2881\u20132890, 2017. 2",
        "ref_ids": [
          "46"
        ]
      },
      "X-ray image segmentation using multi-task learning": {
        "authors": [],
        "url": "https://koreascience.kr/article/JAKO202011161035865.pdf",
        "ref_texts": "[34] H. Zhao, J. Shi, X. Qi, X. Wang, J. Jia, \u201cPyramid scene parsing network ,\u201d in Proc. of the IEEE Conference on Computer Vision and Pattern Recognition , pp. 2881 -2890 , 2017 . Article (CrossRefLink) ",
        "ref_ids": [
          "34"
        ]
      },
      "Attribute-guided feature extraction and augmentation robust learning for vehicle re-identification": {
        "authors": [
          "Chaoran Zhuge",
          "Yujie Peng",
          "Yadong Li",
          "Jiangbo Ai",
          "Junru Chen"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPRW_2020/papers/w35/Zhuge_Attribute-Guided_Feature_Extraction_and_Augmentation_Robust_Learning_for_Vehicle_Re-Identification_CVPRW_2020_paper.pdf",
        "ref_texts": "[28] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings oftheIEEE conference oncomputer vision and pattern recognition, pages 2881\u20132890, 2017.",
        "ref_ids": [
          "28"
        ]
      },
      "Impairing land registry: Social, demographic, and economic determinants of forest classification errors": {
        "authors": [],
        "url": "https://www.mdpi.com/2072-4292/12/16/2628/pdf",
        "ref_texts": "103. Zhao, H.; Shi, J.; Qi, X.; Wang, X.; Jia, J. Pyramid Scene Parsing Network. IEEE CVPR 2017 . [CrossRef]",
        "ref_ids": [
          "103"
        ]
      },
      "Semantic foreground inpainting from weak supervision": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1909.04564",
        "ref_texts": "[5] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid Scene Parsing Network,\u201d in CVPR , 2017, pp. 6230\u20136239.",
        "ref_ids": [
          "5"
        ]
      },
      "Deep grouping model for unified perceptual parsing": {
        "authors": [
          "Zhiheng Li",
          "Wenxuan Bao",
          "Jiayang Zheng",
          "Chenliang Xu"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPR_2020/papers/Li_Deep_Grouping_Model_for_Unified_Perceptual_Parsing_CVPR_2020_paper.pdf",
        "ref_texts": "[59] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , July 2017. 1,2",
        "ref_ids": [
          "59"
        ]
      },
      "Exploration for object mapping guided by environmental semantics using uavs": {
        "authors": [],
        "url": "https://www.mdpi.com/2072-4292/12/5/891/pdf",
        "ref_texts": "28. Zhao, H.; Shi, J.; Qi, X.; Wang, X.; Jia, J. Pyramid scene parsing network. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Honolulu, HI, USA, 21\u201326 July 2017; pp. 2881\u20132890.",
        "ref_ids": [
          "28"
        ]
      },
      "Video Frame Interpolation via Generalized Deformable Convolution": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2008.10680",
        "ref_texts": "[29] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "29"
        ]
      },
      "PanoNet: Real-time panoptic segmentation through position-sensitive feature embedding": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2008.00192",
        "ref_texts": "[28] J. Long, E. Shelhamer, and T. Darrell, \u201cFully convolutional networks for semantic segmentation,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition , 2015, pp. 3431\u20133440.[29] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in IEEE Conf. on Computer Vision and Pattern Recognition (CVPR) , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "28",
          "29"
        ]
      },
      "The semantic mutex watershed for efficient bottom-up semantic instance segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1912.12717",
        "ref_texts": "[46] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In IEEE Conf. on Computer Vision and Pattern Recognition (CVPR) , pages 2881\u20132890, 2017. 2, 5A. Symmetric Multiway Cut in Related Literature We will now relate the Symmetric Multiway Cut definition in eqs. (1) to (6) with the the objective given in [24]. In contrast to this work Kroeger et al. [24] do not split the set of edges in to attractive and repulsive edges. Instead they model repulsion with negative weights and formulate the SMWC as the following constrained energy minimization/integer linear program (ILP): min y2f0;1gjE0j X e2ESwe(1\u0000ye) +X e2Eweye! s.t.y2SMWC G0",
        "ref_ids": [
          "46",
          "24",
          "24"
        ]
      },
      "The direction-aware, learnable, additive kernels and the adversarial network for deep floor plan recognition": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2001.11194",
        "ref_texts": "[27] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "27"
        ]
      },
      "A novel post-processing method based on a weighted composite filter for enhancing semantic segmentation results": {
        "authors": [],
        "url": "https://www.mdpi.com/1424-8220/20/19/5500/pdf",
        "ref_texts": "40. Zhao, H.; Shi, J.; Qi, X.; Wang, X.; Jia, J. Pyramid scene parsing network. In Proceedings of the 30th IEEE Conference on Computer Vision and Pattern Recognition (CVPR 2017), Honolulu, HI, USA, 21\u201326 July 2017; pp. 6230\u20136239.",
        "ref_ids": [
          "40"
        ]
      },
      "Tone mapping operators: Progressing towards semantic-awareness": {
        "authors": [],
        "url": "https://hal.science/hal-02543939/document",
        "ref_texts": "[14] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d CoRR , vol. abs/1612.01105, 2016.",
        "ref_ids": [
          "14"
        ]
      },
      "PADENet: An efficient and robust panoramic monocular depth estimation network for outdoor scenes": {
        "authors": [],
        "url": "http://115.159.107.214/file/publications/itsc2020_keyang.pdf",
        "ref_texts": "[17] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "17"
        ]
      },
      "Towards embodied scene description": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2004.14638",
        "ref_texts": "[34] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "34"
        ]
      },
      "Visual localization using semantic segmentation and depth prediction": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2005.11922",
        "ref_texts": "[21] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "21"
        ]
      },
      "Uvirt\u2014Unsupervised virtual try-on using disentangled clothing and person features": {
        "authors": [
          "Hideki Tsunashima",
          "Kosuke Arase",
          "Antony Lam",
          "Hirokatsu Kataoka"
        ],
        "url": "https://www.mdpi.com/1424-8220/20/19/5647/pdf",
        "ref_texts": "32. Zhao, H.; Shi, J.; Qi, X.; Wang, X.; Jia, J. Pyramid Scene Parsing Network. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Honolulu, HI, USA, 21\u201326 July 2017.",
        "ref_ids": [
          "32"
        ]
      },
      "Real-time and embedded compact deep neural networks for seagrass monitoring": {
        "authors": [],
        "url": "https://repository.lboro.ac.uk/articles/conference_contribution/Real-time_and_embedded_compact_deep_neural_networks_for_seagrass_monitoring/12964874/1/files/24697124.pdf",
        "ref_texts": "[22] H. Zhao, J. Shi, X. Qi, X. Wang and J. Jia, \u201cPyramid Scene Parsing Network,\u201d in IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , Honolulu , HI, 2017, pp. 6230 -6239. ",
        "ref_ids": [
          "22"
        ]
      },
      "Towards infield, live plant phenotyping using a reduced-parameter CNN": {
        "authors": [
          "John Atanbori"
        ],
        "url": "https://link.springer.com/content/pdf/10.1007/s00138-019-01051-7.pdf",
        "ref_texts": "42. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: IEEE Conf. on Computer Vision and Pattern Recognition (CVPR), pp. 2881\u20132890 (2017) Publisher\u2019s Note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations. Dr John Atanbori is a Computer Science Lecturer at the University of Hull. He completed his PhD in Computer Science from the Universityof Lincoln. His research focuses on the application of computer vision,machine learning, and deep learning to plant phenotyping, agri-techand animal behaviour. Before his lecturing career, he worked in thecomputing industry, developing computer vision algorithms for agricultural systems that use hyperspectral and depth cameras. He has also worked as a research fellow at the University of Nottingham\u2019s Com-puter Vision Laboratory.Dr Andrew P. French is an Associate Professor at the University of Nottingham, UK. He has a PhD in Computer Science, and his research isin the field of bioimage analysis, developing novel AI and computa-tional methods to extract data from biological images. He has expertisein both computer vision and deep learning approaches to image anal-ysis. He has developed algorithms for a wide variety of microscopyimages (light, confocal, light sheet, etc.) and is developing approachesfor whole organism imaging. In particular, analysing 2D, 3D and 4Dimages for plant phenotyping is a current focus of his research. Professor Tony P. Pridmore is a Professor of Computer Science at the University of Nottingham, where he leads the Computer VisionLaboratory. He holds a BSc in Computer Science from the Univer-sity of Warwick and a PhD in Computer Vision from the Universityof Sheffield. Before returning to Computer Science in 1999, he heldacademic posts in both information and manufacturing engineering.",
        "ref_ids": [
          "42"
        ]
      },
      "FANet: Feature aggregation network for semantic segmentation": {
        "authors": [],
        "url": "https://espace.curtin.edu.au/bitstream/handle/20.500.11937/93644/Singha%20T%202023%20Public.pdf?sequence=1&isAllowed=y#page=153",
        "ref_texts": "[20] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proc. CVPR, 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "20"
        ]
      },
      "Densely dilated spatial pooling convolutional network using benign loss functions for imbalanced volumetric prostate segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1801.10517",
        "ref_texts": "[Martin Arjovsky et al, 2017] Arjovsky, Martin, So umith Chintala, and L \u00e9on Bottou. \"Wasserstein gan.\" arXiv preprint arXiv:1701.07875 (2017). [H. Zhao et al, 2017] H. Zhao, J. Shi, X. Qi, X. Wang and J. Jia, \"Pyramid Scene Parsing Network,\" 2017 IEEE Conference on Computer Vision and Pattern Recognition ",
        "ref_ids": [
          "Martin Arjovsky et al, 2017",
          "H\\. Zhao et al, 2017"
        ]
      },
      "SCG-Net: Self-constructing graph neural networks for semantic segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2009.01599",
        "ref_texts": "[10] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d arXiv preprint arXiv:1612.01105 , 2016.",
        "ref_ids": [
          "10"
        ]
      },
      "Self-supervised simultaneous alignment and change detection": {
        "authors": [
          "Yukuko Furukawa",
          "Kumiko Suzuki",
          "Ryuhei Hamaguchi",
          "Masaki Onishi",
          "Ken Sakurada"
        ],
        "url": "http://ras.papercept.net/images/temp/IROS/files/1888.pdf",
        "ref_texts": "[32] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia, \u201cPyramid scene parsing network,\u201d CVPR , 2017.",
        "ref_ids": [
          "32"
        ]
      },
      "Literature review of deep learning models for liver vessels reconstruction": {
        "authors": [],
        "url": "https://uca.hal.science/hal-03145758/document",
        "ref_texts": "[31] H Zhao, J Shi, X Qi, X Wang, J Jia, \u201cPyramid Scene Parsing Network\u201d in IEEE C ONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION \u201d (CVPR), 2017. ",
        "ref_ids": [
          "31"
        ]
      },
      "DCGSA: A global self-attention network with dilated convolution for crowd density map generating": {
        "authors": [
          "Liping Zhu"
        ],
        "url": "https://www.cup.edu.cn/ai/docs/2021-03/3a90f6b5a476413eaa35592db0c8c80b.pdf",
        "ref_texts": "[36] H. Zhao , J. Shi , X. Qi , X. Wang , J. Jia , Pyramid scene parsing network, in: Proceedings of the IEEE Conference on Computer Vision And Pattern Recognition, ",
        "ref_ids": [
          "36"
        ]
      },
      "W-Net: Dual supervised medical image segmentation model with multi-dimensional attention and cascade multi-scale convolution": {
        "authors": [
          "Bo Wang",
          "Lei Wang",
          "Junyang Chen"
        ],
        "url": "https://arxiv.org/pdf/2012.03674",
        "ref_texts": "[27] Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J., 2017. Pyramid Scene Parsing Network, in: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2881\u20132890.",
        "ref_ids": [
          "27"
        ]
      },
      "Computer Vision\u2013ECCV 2020: 16th European Conference, Glasgow, UK, August 23\u201328, 2020, Proceedings, Part II": {
        "authors": [],
        "url": "https://biblio.cerist.dz/hrbdonf5214/ouvrages/000000000621911000001_2.pdf",
        "ref_texts": ""
      },
      "Semantic segmentation of endangered tree species in Brazilian savanna using deeplabv3+ variants": {
        "authors": [],
        "url": "https://isprs-archives.copernicus.org/articles/XLII-3-W12-2020/355/2020/isprs-archives-XLII-3-W12-2020-355-2020.pdf",
        "ref_texts": "359 Dechesne, C., Mallet, C., Le Bris, A., Gouet-Brunet, V ., 2017. Semantic segmentation of forest stands of pure species combining airborne lidar data and very high resolution multispectral imagery. ISPRS Journal of Photogrammetry and Remote Sensing, 126, 129\u2013145. Everingham, M., Eslami, S. M. A., Gool, L. V ., Williams, C. K. I., Winn, J., Zisserman, A., 2015. The Pascal Visual Object Classes Challenge: A Retrospective. International Journal of Computer Vision, 111(1), 98\u2013136. Farabet, C., Couprie, C., Najman, L., LeCun, Y ., 2012. Learning hierarchical features for scene labeling. IEEE transactions on pattern analysis and machine intelligence, 35(8), 1915\u20131929. Fassnacht, F., Latifi, H., Stere \u00b4nczak, K., Modzelewska, A., Lefsky, M., Waser, L., Straub, C., Ghosh, A., 2016. Review of studies on tree species classification from remotely sensed data. Remote Sensing of Environment, 186, 64\u201387. Grzn \u00b4arov\u00b4a, A., Mokros, M., Surovy, P., Slav \u00b4\u0131k, M., Pondel \u00b4\u0131k, M., Mergani \u02c7c, J., 2019. The Crown Diameter Estimation from Fixed Wing Type of UA V Imagery. ISPRS International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences, XLII-2/W13, 337\u2013341. Guan, H., Yu, Y ., Ji, Z., Li, J., Zhang, Q., 2015. Deep learningbased tree classification using mobile LiDAR data. Remote Sensing Letters, 6(11), 864\u2013873. Hartling, S., Sagan, V ., Sidike, P., Maimaitijiang, M., Carron, J., 2019. Urban tree species classification using a WorldView-2/3 and LiDAR data fusion approach and deep learning. Sensors, 19(6), 1284. Honkavaara, E., Saari, H., Kaivosoja, J., P \u00a8ol\u00a8onen, I., Hakala, T., Litkey, P., M \u00a8akynen, J., Pesonen, L., 2013. Processing and assessment of spectrometric, stereoscopic imagery collected using a lightweight UA V spectral camera for precision agriculture. Remote Sensing, 5(10), 5006\u20135039. Howard, A. G., Zhu, M., Chen, B., Kalenichenko, D., Wang, W., Weyand, T., Andreetto, M., Adam, H., 2017. MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications. ArXiv, abs/1704.04861. Jeronimo, S. M., Kane, V . R., Churchill, D. J., McGaughey, R. J., Franklin, J. F., 2018. Applying LiDAR individual tree detection to management of structurally diverse forest landscapes. Journal of Forestry, 116(4), 336\u2013346. Krizhevsky, A., Sutskever, I., Hinton, G. E., 2017. ImageNet Classification with Deep Convolutional Neural Networks. Commun. ACM, 60(6), 84\u201390. Laurin, G. V ., Liesenberg, V ., Chen, Q., Guerriero, L., Del Frate, F., Bartolini, A., Coomes, D., Wilebore, B., Lindsell, J., Valentini, R., 2013. Optical and SAR sensor synergies for forest and land cover mapping in a tropical site in West Africa. International Journal of Applied Earth Observation and Geoinformation, 21, 7\u201316. Li, Y ., Zhang, X., Chen, D., 2018. CSRNet: Dilated Convolutional Neural Networks for Understanding the Highly Congested Scenes. CoRR, abs/1802.10062.Lim, Y ., La, H., Park, J., Lee, M., Pyeon, M., Kim, J.-I., 2015. Calculation of Tree Height and Canopy Crown from Drone Images Using Segmentation. Journal of the Korean Society of Surveying, Geodesy, Photogrammetry and Cartography, 33(6), 605-613. Lizarazo, I., Angulo, V ., Rodr \u00b4\u0131guez, J., 2017. Automatic mapping of land surface elevation changes from UA V-based imagery. International journal of remote sensing , 38(8-10), 2603\u20132622. Long, J., Shelhamer, E., Darrell, T., 2014. Fully Convolutional Networks for Semantic Segmentation. CoRR, abs/1411.4038. Maschler, J., Atzberger, C., Immitzer, M., 2018. Individual tree crown segmentation and classification of 13 tree species using airborne hyperspectral data. Remote Sensing, 10(8), 1218. Mizoguchi, T., Ishii, A., Nakamura, H., Inoue, T., Takamatsu, H., 2017. Lidar-based individual tree species classification using convolutional neural network. Videometrics, Range Imaging, and Applications XIV, 10332, 193\u2013199. Mohan, M., Silva, C. A., Klauberg, C., Jat, P., Catts, G., Cardil, A., Hudak, A. T., Dia, M., 2017. Individual tree detection from unmanned aerial vehicle (UA V) derived canopy height model in an open canopy mixed conifer forest. Forests, 8(9), 340. Rauhala, A., Tuomela, A., Davids, C., Rossi, P. M., 2017. UA V remote sensing surveillance of a mine tailings impoundment in Sub-Arctic conditions. Remote sensing, 9(12), 1318. Sandler, M., Howard, A. G., Zhu, M., Zhmoginov, A., Chen, L., 2018. Inverted Residuals and Linear Bottlenecks: Mobile Networks for Classification, Detection and Segmentation. CoRR, abs/1801.04381. Santos, A. A. d., Marcato Junior, J., Ara \u00b4ujo, M. S., Di Martini, D. R., Tetila, E. C., Siqueira, H. L., Aoki, C., Eltner, A., Matsubara, E. T., Pistori, H. et al., 2019. Assessment of CNN-Based Methods for Individual Tree Detection on Images Captured by RGB Cameras Attached to UA Vs. Sensors, 19(16), 3595. Szegedy, C., Liu, W., Jia, Y ., Sermanet, P., Reed, S. E., Anguelov, D., Erhan, D., Vanhoucke, V ., Rabinovich, A., 2014. Going Deeper with Convolutions. CoRR, abs/1409.4842. Tang, L., Shao, G., 2015. Drone remote sensing for forestry research and practices. Journal of Forestry Research, 26(4), 791\u2013797. Vigueras-Guill \u00b4en, J. P., Sari, B., Goes, S. F., Lemij, H. G., van Rooij, J., Vermeer, K. A., van Vliet, L. J., 2019. Fully convolutional architecture vs sliding-window CNN for corneal endothelium cell segmentation. BMC Biomedical Engineering, 1(1), 4. Wang, B., Ma, Y ., Chen, G., Li, C., Dao, Z., Sun, W., 2016. Rescuing Magnolia sinica (Magnoliaceae), a critically endangered species endemic to Yunnan, China. Oryx, 50(3), 446\u2013449. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J., 2016. Pyramid Scene Parsing Network. CoRR, abs/1612.01105. The International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences, Volume XLII-3/W12-2020, 2020 "
      },
      "Casting geometric constraints in semantic segmentation as semi-supervised learning": {
        "authors": [
          "Sinisa Stekovic",
          "Friedrich Fraundorfer",
          "Vincent Lepetit"
        ],
        "url": "https://openaccess.thecvf.com/content_WACV_2020/papers/Stekovic_Casting_Geometric_Constraints_in_Semantic_Segmentation_as_Semi-Supervised_Learning_WACV_2020_paper.pdf",
        "ref_texts": "[45] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In CVPR , 2017. 1,2,5",
        "ref_ids": [
          "45"
        ]
      },
      "An'All Terrain'Crack Detector Obtained by Deep Learning on Available Databases": {
        "authors": [],
        "url": "https://www.ipol.im/pub/art/2020/282/article_lr.pdf",
        "ref_texts": ""
      },
      "Unsupervised domain adaptation for semantic segmentation of NIR images through generative latent search": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2006.08696",
        "ref_texts": "53. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: Proceedings of the IEEE conference on computer vision and pattern recognition. pp. 2881{2890 (2017) Unsupervised Domain Adaptation for Semantic Segmentation of NIR Images through Generative Latent Search \u0000Supplementary \u0000 Prashant Pandey?[0000\u00000002\u00006594\u00009685], Aayush Kumar Tyagi?[0000\u00000002\u00003615\u00007283], Sameer Ambekar[0000\u00000002\u00008650\u00003180], and Prathosh AP[0000\u00000002\u00008699\u00005760] Indian Institute of Technology Delhi getprashant57@gmail.com, aayush16081@iiitd.ac.in, ambekarsameer@gmail.com, prathoshap@iitd.ac.in 1 Datasets a) b) c) Fig. 1: a) shows samples of COMPAQ dataset [22] images with only Red-channel present b) contains samples from SNV dataset c) contains samples from Hand Gesture dataset. Each row of Fig. 1 shows few images with the corresponding skin-mask pairs from COMPAQ, SNV and Hand Gesture datasets respectively.",
        "ref_ids": [
          "53"
        ]
      },
      "Semantic labeling in remote sensing corpora using feature fusion-based enhanced global convolutional network with high-resolution representations and depthwise \u2026": {
        "authors": [],
        "url": "https://www.mdpi.com/2072-4292/12/8/1233/pdf",
        "ref_texts": "5. Zhao, H.; Shi, J.; Qi, X.; Wang, X.; Jia, J. Pyramid scene parsing network. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Honolulu, HI, USA, 21\u201326 July 2017; pp.",
        "ref_ids": [
          "5"
        ]
      },
      "Extraction method of offshore mariculture area under weak signal based on multisource feature fusion": {
        "authors": [],
        "url": "https://www.mdpi.com/2077-1312/8/2/99/pdf",
        "ref_texts": "18. Zhao, H.; Shi, J.; Qi, X. Pyramid Scene Parsing Network. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Honolulu, HI, USA, 21\u201326 July 2017.",
        "ref_ids": [
          "18"
        ]
      },
      "Multimodal transfer learning-based approaches for retinal vascular segmentation": {
        "authors": [],
        "url": "https://ebooks.iospress.nl/pdf/doi/10.3233/FAIA200303",
        "ref_texts": "[40] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u2018Pyramid scene parsing network\u2019, in 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 6230\u20136239, (2017).J.Moranoetal./Multimodal Transfer Learning-Based ApproachesforRetinal Vascular Segmentation 1873",
        "ref_ids": [
          "40"
        ]
      },
      "Classification of high resolution satellite images using improved U-Net": {
        "authors": [],
        "url": "https://intapi.sciendo.com/pdf/10.34768/amcs-2020-0030",
        "ref_texts": "(2018). Comparing fully convolutional networks, randomforest, support vector machine, and patch-based deep convolutional neural networks for object-based wetland mapping using images from small unmanned aircraftsystem, GIScience & Remote Sensing 55(2): 243\u2013264. Vemulapalli, R., Tuzel, O., Liu, M.Y . and Chellappa, R. (2016). Gaussian conditional random field network for semantic segmentation, Computer Vision & Pattern Recognition, Las Vegas, NV , USA, pp. 3224\u20133233. V olpi, M. and Tuia, D. (2017). Dense semantic labeling of subdecimeter resolution images with convolutional neural networks, IEEE Transactions on Geoscience and Remote Sensing 55(2): 881\u2013893. Yang, H., Yu, B., Luo, J. and Chen, F. (2019). Semantic segmentation of high spatial resolution images with deep neural networks, GIScience & Remote Sensing 56(5): 1\u201320. Zhang, C., Xin, P., Li, H., Gardiner, A. and Atkinson, P.M. (2018a). A hybrid MLP-CNN classifier for very fine resolution remotely sensed image classification, ISPRS Journal of Photogrammetry & Remote Sensing 140(7): 133\u2013144. Zhang, P., Ke, Y ., Zhang, Z., Wang, M., Li, P. and Zhang, S. (2018b). Urban land use and land cover classification using novel deep learning models based on high spatialresolution satellite imagery, IEEE Transactions on Geoscience & Remote Sensing 18(11): 3717. Zhao, H., Shi, J., Qi, X., Wang, X. and Jia, J. (2017). Pyramid scene parsing network, 2017 IEEE Conference on Computer Vision and Pattern R ecognition (C VPR), H onolulu, HI, USA , pp. 6230\u20136239. Zhao, W. and Du, S. (2016). L earning multiscale and deep representations for classifying remotely sensed imagery,ISPRS Journal of Photogrammetry & Remote Sensing 113(3): 155\u2013165.Zhou, B., Hang, Z., Puig, X., Fidler, S., Barriuso, A. and Torralba, A. (2017). Scene parsing through ADE20K dataset, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Honolulu, HI, USA, pp."
      },
      "River state classification combining patch-based processing and CNN": {
        "authors": [
          "Takahiro Oga",
          "Ryosuke Harakawa",
          "Sayaka Minewaki",
          "Yo Umeki",
          "Yoko Matsuda",
          "Masahiro Iwahashi"
        ],
        "url": "https://journals.plos.org/plosone/article/file?id=10.1371/journal.pone.0243073&type=printable",
        "ref_texts": "21. Zhao H,ShiJ,QiX,Wang X,JiaJ.Pyramid scene parsing network. In:Proc. IEEE Conf. Comput. Vis. Patt. Recogn it.;2017. p.2881\u20132 890.",
        "ref_ids": [
          "21"
        ]
      },
      "Semantic segmentation of drone imagery using deep learning for seagrass habitat monitoring": {
        "authors": [],
        "url": "https://koreascience.kr/article/JAKO202013363975488.pdf",
        "ref_texts": "1708.03888 . Zhang, Z., Q. Liu, and Y . Wang, 2018. Road extraction by deep residual u-net, IEEE Geoscience and Remote Sensing Letters , 15(5): 749-753. Zhao, H., J. Shi, X. Qi, X. Wang, and J. Jia, 2017. Pyramid scene parsing network, Proc. of the IEEE Conference on Computer Vision and Pattern Recognition , Honolulu, Hawaii, USA, Jul. 21-26, pp. 2881-2890. \uc798\ud53c \uc11c\uc2dd\uc9c0 \ubaa8\ub2c8\ud130\ub9c1\uc744 \uc704\ud55c \ub525\ub7ec\ub2dd \uae30\ubc18\uc758 \ub4dc\ub860 \uc601\uc0c1 \uc758\ubbf8\ub860\uc801 \ubd84\ud560 "
      },
      "Interactive deep refinement network for medical image segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2006.15320",
        "ref_texts": "24. Zhao, H., Shi, J., et al.: Pyramid scene parsing network. CVPR (2017)",
        "ref_ids": [
          "24"
        ]
      },
      "Lightweight adversarial network for salient object detection": {
        "authors": [
          "Lili Huang"
        ],
        "url": "https://www.sysu-hcp.net/userfiles/files/2022/02/16/c85a0c1c2bfe2ce0.pdf",
        "ref_texts": "[66] H. Zhao , J. Shi , X. Qi , X. Wang , J. Jia , Pyramid scene parsing network, in: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition ",
        "ref_ids": [
          "66"
        ]
      },
      "Scalenas: One-shot learning of scale-aware representations for visual recognition": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2011.14584",
        "ref_texts": "[35] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017. 6",
        "ref_ids": [
          "35"
        ]
      },
      "First-Person View Hand Segmentation of Multi-Modal Hand Activity Video Dataset.": {
        "authors": [],
        "url": "https://par.nsf.gov/servlets/purl/10297591",
        "ref_texts": "[61] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 2881\u20132890, 2017.",
        "ref_ids": [
          "61"
        ]
      },
      "Claw u-net: A unet-based network with deep feature concatenation for scleral blood vessel segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2010.10163",
        "ref_texts": "[9] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia, \u201cPyramid scene parsing network,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "9"
        ]
      },
      "A review of silhouette extraction algorithms for use within visual hull pipelines": {
        "authors": [],
        "url": "https://e-space.mmu.ac.uk/626941/1/Review_Paper___Computer_Methods_in_Biomechanics_and_Biomedical_Engineering.pdf",
        "ref_texts": "[101] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \\Pyramid scene parsing network,\" in IEEE Conf. on Computer Vision and Pattern Recognition (CVPR) , 2017, pp. 2881{2890.",
        "ref_ids": [
          "101"
        ]
      },
      "Coastal land cover classification of high-resolution remote sensing images using attention-driven context encoding network": {
        "authors": [
          "Jifa Chen",
          "Gang Chen",
          "Lizhe Wang",
          "Bo Fang",
          "Ping Zhou",
          "Mingjie Zhu"
        ],
        "url": "https://www.mdpi.com/1424-8220/20/24/7032/pdf",
        "ref_texts": "12. Zhao, H.; Shi, J.; Qi, X.; Wang, X.; Jia, J. Pyramid scene parsing network. In Proceedings of the 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Honolulu, HI, USA, 21\u201326 July 2017; pp. 2881\u20132890.",
        "ref_ids": [
          "12"
        ]
      },
      "Objectness-aware few-shot semantic segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2004.02945",
        "ref_texts": "[57] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "57"
        ]
      },
      "A novel multi-focus image fusion network with U-Shape structure": {
        "authors": [],
        "url": "https://www.mdpi.com/1424-8220/20/14/3901/pdf",
        "ref_texts": "31. Zhao, H.; Shi, J.; Qi, X.; Wang, X.; Jia, J. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition, Honolulu, HI, USA, 21\u201326 July 2017; pp. 2881\u20132890.",
        "ref_ids": [
          "31"
        ]
      },
      "Mcnet: Multi-scale feature extraction and content-aware reassembly cloud detection model for remote sensing images": {
        "authors": [],
        "url": "https://www.mdpi.com/2073-8994/13/1/28/pdf",
        "ref_texts": "26. Zhao, H.; Shi, J.; Qi, X.; Wang, X.; Jia, J. Pyramid scene parsing network. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Honolulu, HI, USA, 21\u201326 July 2017; pp. 2881\u20132890.",
        "ref_ids": [
          "26"
        ]
      },
      "Feature binding with category-dependant mixup for semantic segmentation and adversarial robustness": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2008.05667",
        "ref_texts": "[40] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017.",
        "ref_ids": [
          "40"
        ]
      },
      "Local context attention for salient object segmentation": {
        "authors": [
          "Jing Tan",
          "Pengfei Xiong",
          "Zhengyi Lv",
          "Kuntao Xiao",
          "Yuwen He"
        ],
        "url": "https://openaccess.thecvf.com/content/ACCV2020/papers/Tan_Local_Context_Attention_for_Salient_Object_Segmentation_ACCV_2020_paper.pdf",
        "ref_texts": ""
      },
      "High-resolution neural network for driver visual attention prediction": {
        "authors": [],
        "url": "https://www.mdpi.com/1424-8220/20/7/2030/pdf",
        "ref_texts": "32. Zhao, H.; Shi, J.; Qi, X.; Wang, X.; Jia, J. Pyramid Scene Parsing Network. In Proceedings of the 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Honolulu, HI, USA, 21\u201326 July 2017; pp.",
        "ref_ids": [
          "32"
        ]
      },
      "Defective samples simulation through neural style transfer for automatic surface defect segment": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1910.03334",
        "ref_texts": "[14] Zhao, H., Shi, J., Qi, X., Wang, X., and Jia, J., \u201cPyramid Scene Parsing Network, \u201d in 2017 IEEE Conf. Comput. Vis. Pattern Recognit. CVPR, 6230 \u20136239 (2017). ",
        "ref_ids": [
          "14"
        ]
      },
      "\u6df1\u5c64\u5b66\u7fd2\u306b\u3088\u308b\u30bb\u30b0\u30e1\u30f3\u30c6\u30fc\u30b7\u30e7\u30f3\u624b\u6cd5\u3092\u7528\u3044\u305f\u30b3\u30f3\u30af\u30ea\u30fc\u30c8\u8868\u9762\u306e\u5909\u72b6\u9818\u57df\u306e\u691c\u51fa": {
        "authors": [],
        "url": "https://www.jstage.jst.go.jp/article/jsceiii/1/J1/1_481/_pdf",
        "ref_texts": "16) Zhao, H.,Shi, J.,Qi, X.,Wang, X. and Jia, J. :Pyramid Scene Parsing Network, IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , pp. 6230-6239, 2017. "
      },
      "Pdanet: Pyramid density-aware attention net for accurate crowd counting": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2001.05643",
        "ref_texts": "[29] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in CVPR , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "29"
        ]
      },
      "DenseAttentionSeg: Segment hands from interacted objects using depth input": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1903.12368",
        "ref_texts": "[17] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In IEEE Conf. on Computer Vision and Pattern Recognition (CVPR) , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "17"
        ]
      },
      "Template-based automatic search of compact semantic segmentation architectures": {
        "authors": [
          "Vladimir Nekrasov",
          "Chunhua Shen",
          "Ian Reid"
        ],
        "url": "http://openaccess.thecvf.com/content_WACV_2020/papers/Nekrasov_Template-Based_Automatic_Search_of_Compact_Semantic_Segmentation_Architectures_WACV_2020_paper.pdf",
        "ref_texts": "[31] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In Proc. IEEE Conf. Comp. Vis. Patt. Recogn. , 2017.",
        "ref_ids": [
          "31"
        ]
      },
      "Predicting terrain mechanical properties in sight for planetary rovers with semantic clues": {
        "authors": [
          "Tiffany Mc"
        ],
        "url": "https://arxiv.org/pdf/2011.01872",
        "ref_texts": "[50] H. Zhao et al., \u201c Pyramid scene parsing network ,\u201d in Proc. IEEE Conf. Comput. Vis. Pattern Recognit. , Honolulu, HI, USA, 2017, pp. 2881 2890. ",
        "ref_ids": [
          "50"
        ]
      },
      "Ascnet: Adaptive-scale convolutional neural networks for multi-scale feature learning": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1907.03241",
        "ref_texts": ""
      },
      "HistoNet: Predicting size histograms of object instances": {
        "authors": [
          "Kishan Sharma",
          "Moritz Gold",
          "Laura Leal",
          "Jan Dirk"
        ],
        "url": "https://openaccess.thecvf.com/content_WACV_2020/papers/Sharma_HistoNet_Predicting_size_histograms_of_object_instances_WACV_2020_paper.pdf",
        "ref_texts": "[29] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In IEEE Conference on Computer Vision and Pattern Recognition , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "29"
        ]
      },
      "\u0421\u0435\u043c\u0430\u043d\u0442\u0438\u0447\u0435\u0441\u043a\u0430\u044f \u0441\u0435\u0433\u043c\u0435\u043d\u0442\u0430\u0446\u0438\u044f \u0441\u043f\u0443\u0442\u043d\u0438\u043a\u043e\u0432\u044b\u0445 \u0441\u043d\u0438\u043c\u043a\u043e\u0432 \u0430\u044d\u0440\u043e\u043f\u043e\u0440\u0442\u043e\u0432 \u0441 \u043f\u043e\u043c\u043e\u0449\u044c\u044e \u0441\u0432\u0451\u0440\u0442\u043e\u0447\u043d\u044b\u0445 \u043d\u0435\u0439\u0440\u043e\u043d\u043d\u044b\u0445 \u0441\u0435\u0442\u0435\u0439": {
        "authors": [
          "Tin Hunter"
        ],
        "url": "https://cyberleninka.ru/article/n/semanticheskaya-segmentatsiya-sputnikovyh-snimkov-aeroportov-s-pomoschyu-svyortochnyh-neyronnyh-setey.pdf",
        "ref_texts": "[10] Hengshuang Z, Jianping S, Xiaoju an Q, Xiaogang W, Jiaya J. Pyramid scene parsing network. IEEE CVPR 2017: ",
        "ref_ids": [
          "10"
        ]
      },
      "\u6539\u8fdb\u7684\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u5728\u80ba\u90e8\u56fe\u50cf\u4e0a\u7684\u5206\u5272\u5e94\u7528.": {
        "authors": [],
        "url": "https://scholar.archive.org/work/rscm3akqs5fvxl3thknbng7mlq/access/wayback/http://fcst.ceaj.org/CN/article/downloadArticleFile.do?attachType=PDF&id=2331",
        "ref_texts": ""
      },
      "\u57fa\u4e8e\u81a8\u80c0\u5377\u79ef\u5e73\u6ed1\u53ca\u8f7b\u578b\u4e0a\u91c7\u6837\u7684\u5b9e\u65f6\u8bed\u4e49\u5206\u5272": {
        "authors": [],
        "url": "https://www.researching.cn/ArticlePdf/m00002/2020/57/2/021017.pdf",
        "ref_texts": " 2  ZhaoHS ShiJP QiXJ etal\u656dPyramidscene parsingnetwork C \u22252017IEEEConferenceon ComputerVisionandPatternRecognition CVPR July21G26 2017 Honolulu HI USA\u656dNewYork IEEE 2017 6230G6239\u656d"
      },
      "\u57fa\u4e8e\u6ce8\u610f\u529b\u673a\u5236\u7684\u9065\u611f\u56fe\u50cf\u5206\u5272\u6a21\u578b": {
        "authors": [],
        "url": "https://www.researching.cn/ArticlePdf/m00002/2020/57/4/041015.pdf",
        "ref_texts": " 8  ZhaoHS ShiJP QiXJ etal\u656dPyramidscene parsingnetwork C \u22252017IEEEConferenceon ComputerVisionandPatternRecognition CVPR July21G26 2017 Honolulu HI USA\u656dNewYork IEEE 2017 6230G6239\u656d"
      },
      "\u57fa\u4e8e\u7279\u5f81\u878d\u5408\u7684\u5b9e\u65f6\u8bed\u4e49\u5206\u5272\u7b97\u6cd5": {
        "authors": [],
        "url": "https://www.researching.cn/ArticlePdf/m00002/2020/57/2/021011.pdf",
        "ref_texts": " 14  ZhaoHS ShiJP QiXJ etal\u656dPyramidscene parsingnetwork C 2017IEEEConferenceon ComputerVisionandPatternRecognition CVPR July21G26 2017 Honolulu HI USA\u656dNewYork IEEE 2017 6230G6239\u656d"
      },
      "Searching for mobilenetv3": {
        "authors": [
          "Andrew Howard",
          "Mark Sandler",
          "Grace Chu",
          "Chieh Chen",
          "Bo Chen",
          "Mingxing Tan",
          "Weijun Wang",
          "Yukun Zhu",
          "Ruoming Pang",
          "Vijay Vasudevan",
          "Quoc V. Le",
          "Hartwig Adam"
        ],
        "url": "http://openaccess.thecvf.com/content_ICCV_2019/papers/Howard_Searching_for_MobileNetV3_ICCV_2019_paper.pdf",
        "ref_texts": "[50] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017. 7",
        "ref_ids": [
          "50"
        ]
      },
      "Deep high-resolution representation learning for human pose estimation": {
        "authors": [
          "Ke Sun",
          "Bin Xiao",
          "Dong Liu",
          "Jingdong Wang"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPR_2019/papers/Sun_Deep_High-Resolution_Representation_Learning_for_Human_Pose_Estimation_CVPR_2019_paper.pdf",
        "ref_texts": "[78] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , pages 6230\u20136239, 2017. 3",
        "ref_ids": [
          "78"
        ]
      },
      "Dual attention network for scene segmentation": {
        "authors": [
          "Jun Fu",
          "Jing Liu",
          "Haijie Tian",
          "Yong Li",
          "Yongjun Bao",
          "Zhiwei Fang",
          "Hanqing Lu"
        ],
        "url": "https://openaccess.thecvf.com/content_CVPR_2019/papers/Fu_Dual_Attention_Network_for_Scene_Segmentation_CVPR_2019_paper.pdf",
        "ref_texts": "[29] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In IEEE Conference on Computer Vision and Pattern Recognition, pages 6230\u20136239, 2017.",
        "ref_ids": [
          "29"
        ]
      },
      "Res2net: A new multi-scale backbone architecture": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1904.01169",
        "ref_texts": "[77] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In IEEE Conf. Comput. Vis. Pattern Recog. , 2017.",
        "ref_ids": [
          "77"
        ]
      },
      "Ccnet: Criss-cross attention for semantic segmentation": {
        "authors": [
          "Zilong Huang",
          "Xinggang Wang",
          "Lichao Huang",
          "Chang Huang",
          "Yunchao Wei",
          "Wenyu Liu"
        ],
        "url": "http://openaccess.thecvf.com/content_ICCV_2019/papers/Huang_CCNet_Criss-Cross_Attention_for_Semantic_Segmentation_ICCV_2019_paper.pdf",
        "ref_texts": "[41] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In IEEE Conf. on Computer Vision and Pattern Recognition (CVPR) , pages 2881\u20132890, 2017. 2,3,6,7,8",
        "ref_ids": [
          "41"
        ]
      },
      "Bag of tricks for image classification with convolutional neural networks": {
        "authors": [
          "Tong He",
          "Zhi Zhang",
          "Hang Zhang",
          "Zhongyue Zhang",
          "Junyuan Xie",
          "Mu Li"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPR_2019/papers/He_Bag_of_Tricks_for_Image_Classification_with_Convolutional_Neural_Networks_CVPR_2019_paper.pdf",
        "ref_texts": "[32] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In Computer Vision and Pattern Recognition (CVPR), 2017 IEEE Conference on , pages 6230\u20136239. IEEE, 2017. 5,8",
        "ref_ids": [
          "32"
        ]
      },
      "Deepgcns: Can gcns go as deep as cnns?": {
        "authors": [
          "Guohao Li",
          "Matthias Muller",
          "Ali Thabet",
          "Bernard Ghanem"
        ],
        "url": "https://openaccess.thecvf.com/content_ICCV_2019/papers/Li_DeepGCNs_Can_GCNs_Go_As_Deep_As_CNNs_ICCV_2019_paper.pdf",
        "ref_texts": "[51] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "51"
        ]
      },
      "Panet: Few-shot image semantic segmentation with prototype alignment": {
        "authors": [
          "Kaixin Wang",
          "Jun Hao",
          "Yingtian Zou",
          "Daquan Zhou",
          "Jiashi Feng"
        ],
        "url": "http://openaccess.thecvf.com/content_ICCV_2019/papers/Wang_PANet_Few-Shot_Image_Semantic_Segmentation_With_Prototype_Alignment_ICCV_2019_paper.pdf",
        "ref_texts": "[29] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "29"
        ]
      },
      "Advent: Adversarial entropy minimization for domain adaptation in semantic segmentation": {
        "authors": [
          "Hung Vu",
          "Himalaya Jain",
          "Maxime Bucher",
          "Matthieu Cord",
          "Patrick Perez"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPR_2019/papers/Vu_ADVENT_Adversarial_Entropy_Minimization_for_Domain_Adaptation_in_Semantic_Segmentation_CVPR_2019_paper.pdf",
        "ref_texts": "[47] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In CVPR , 2017. 1",
        "ref_ids": [
          "47"
        ]
      },
      "Panoptic feature pyramid networks": {
        "authors": [
          "Alexander Kirillov",
          "Ross Girshick",
          "Kaiming He",
          "Piotr Dollar"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPR_2019/papers/Kirillov_Panoptic_Feature_Pyramid_Networks_CVPR_2019_paper.pdf",
        "ref_texts": "[58] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017. 3",
        "ref_ids": [
          "58"
        ]
      },
      "Ce-net: Context encoder network for 2d medical image segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1903.02740.pdf?fbclid=IwAR3nXtcpWHlZJRzJTebvs7WYgKZ9bhjJk5O2WdEtEvm4TNK5-McLYd_MnSQ",
        "ref_texts": "[52] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in IEEE Conf. on Computer Vision and Pattern Recognition (CVPR) , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "52"
        ]
      },
      "Rangenet++: Fast and accurate lidar semantic segmentation": {
        "authors": [],
        "url": "https://www.ipb.uni-bonn.de/wp-content/papercite-data/pdf/milioto2019iros.pdf",
        "ref_texts": "[23] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. arXiv preprint , abs/1612.01105, 2016.",
        "ref_ids": [
          "23"
        ]
      },
      "Panoptic segmentation": {
        "authors": [
          "Alexander Kirillov",
          "Kaiming He",
          "Ross Girshick",
          "Carsten Rother",
          "Piotr Dollar"
        ],
        "url": "https://openaccess.thecvf.com/content_CVPR_2019/papers/Kirillov_Panoptic_Segmentation_CVPR_2019_paper.pdf",
        "ref_texts": "[53] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017. 7",
        "ref_ids": [
          "53"
        ]
      },
      "Auto-deeplab: Hierarchical neural architecture search for semantic image segmentation": {
        "authors": [
          "Chenxi Liu",
          "Chieh Chen",
          "Florian Schroff",
          "Hartwig Adam",
          "Wei Hua",
          "Alan L. Yuille",
          "Li Fei"
        ],
        "url": "https://openaccess.thecvf.com/content_CVPR_2019/papers/Liu_Auto-DeepLab_Hierarchical_Neural_Architecture_Search_for_Semantic_Image_Segmentation_CVPR_2019_paper.pdf",
        "ref_texts": "[88] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In CVPR , 2017. 2,7,8",
        "ref_ids": [
          "88"
        ]
      },
      "Mask scoring r-cnn": {
        "authors": [
          "Zhaojin Huang",
          "Lichao Huang",
          "Yongchao Gong",
          "Chang Huang",
          "Xinggang Wang"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPR_2019/papers/Huang_Mask_Scoring_R-CNN_CVPR_2019_paper.pdf",
        "ref_texts": "[37] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In IEEE Conference on Computer Vision and Pattern Recognition , pages 2881\u20132890, 2017. 1",
        "ref_ids": [
          "37"
        ]
      },
      "A simple pooling-based design for real-time salient object detection": {
        "authors": [
          "Jiang Liu",
          "Qibin Hou",
          "Ming Cheng",
          "Jiashi Feng",
          "Jianmin Jiang"
        ],
        "url": "https://openaccess.thecvf.com/content_CVPR_2019/papers/Liu_A_Simple_Pooling-Based_Design_for_Real-Time_Salient_Object_Detection_CVPR_2019_paper.pdf",
        "ref_texts": "[47] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017. 1,3",
        "ref_ids": [
          "47"
        ]
      },
      "Scale-aware trident networks for object detection": {
        "authors": [
          "Yanghao Li",
          "Yuntao Chen",
          "Naiyan Wang",
          "Zhaoxiang Zhang"
        ],
        "url": "http://openaccess.thecvf.com/content_ICCV_2019/papers/Li_Scale-Aware_Trident_Networks_for_Object_Detection_ICCV_2019_paper.pdf",
        "ref_texts": "[43] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017. 3",
        "ref_ids": [
          "43"
        ]
      },
      "Std: Sparse-to-dense 3d object detector for point cloud": {
        "authors": [
          "Zetong Yang",
          "Yanan Sun",
          "Shu Liu",
          "Xiaoyong Shen",
          "Jiaya Jia"
        ],
        "url": "https://openaccess.thecvf.com/content_ICCV_2019/papers/Yang_STD_Sparse-to-Dense_3D_Object_Detector_for_Point_Cloud_ICCV_2019_paper.pdf",
        "ref_texts": "[36] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017.",
        "ref_ids": [
          "36"
        ]
      },
      "High-resolution representations for labeling pixels and regions": {
        "authors": [],
        "url": "https://i.cs.hku.hk/fyp/2019/fyp19013/Reference/reference5.pdf",
        "ref_texts": "[125] Z. Zhang, X. Zhang, C. Peng, X. Xue, and J. Sun. Exfuse: Enhancing feature fusion for semantic segmentation. InECCV , pages 273\u2013288, 2018. 2[126] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In CVPR , pages 6230\u20136239, 2017. 1, 2, 4, 5",
        "ref_ids": [
          "125",
          "126"
        ]
      },
      "Gated-scnn: Gated shape cnns for semantic segmentation": {
        "authors": [
          "Towaki Takikawa",
          "David Acuna",
          "Varun Jampani",
          "Sanja Fidler"
        ],
        "url": "http://openaccess.thecvf.com/content_ICCV_2019/papers/Takikawa_Gated-SCNN_Gated_Shape_CNNs_for_Semantic_Segmentation_ICCV_2019_paper.pdf",
        "ref_texts": "[59] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017. 1,2,5,7",
        "ref_ids": [
          "59"
        ]
      },
      "Asymmetric non-local neural networks for semantic segmentation": {
        "authors": [
          "Zhen Zhu",
          "Mengde Xu",
          "Song Bai",
          "Tengteng Huang",
          "Xiang Bai"
        ],
        "url": "http://openaccess.thecvf.com/content_ICCV_2019/papers/Zhu_Asymmetric_Non-Local_Neural_Networks_for_Semantic_Segmentation_ICCV_2019_paper.pdf",
        "ref_texts": "[46] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proc. CVPR , pages 6230\u20136239, 2017. 1,2,3,4,5,6,7,8",
        "ref_ids": [
          "46"
        ]
      },
      "Pointweb: Enhancing local neighborhood features for point cloud processing": {
        "authors": [
          "Hengshuang Zhao",
          "Li Jiang",
          "Wing Fu",
          "Jiaya Jia"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPR_2019/papers/Zhao_PointWeb_Enhancing_Local_Neighborhood_Features_for_Point_Cloud_Processing_CVPR_2019_paper.pdf",
        "ref_texts": "[35] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017.",
        "ref_ids": [
          "35"
        ]
      },
      "Expectation-maximization attention networks for semantic segmentation": {
        "authors": [
          "Xia Li",
          "Zhisheng Zhong",
          "Jianlong Wu",
          "Yibo Yang",
          "Zhouchen Lin",
          "Hong Liu"
        ],
        "url": "https://openaccess.thecvf.com/content_ICCV_2019/papers/Li_Expectation-Maximization_Attention_Networks_for_Semantic_Segmentation_ICCV_2019_paper.pdf",
        "ref_texts": "[37] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "37"
        ]
      },
      "Objects365: A large-scale, high-quality dataset for object detection": {
        "authors": [
          "Shuai Shao",
          "Zeming Li",
          "Tianyuan Zhang",
          "Chao Peng",
          "Gang Yu",
          "Xiangyu Zhang",
          "Jing Li",
          "Jian Sun"
        ],
        "url": "https://openaccess.thecvf.com/content_ICCV_2019/papers/Shao_Objects365_A_Large-Scale_High-Quality_Dataset_for_Object_Detection_ICCV_2019_paper.pdf",
        "ref_texts": "[37] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "37"
        ]
      },
      "Structured knowledge distillation for semantic segmentation": {
        "authors": [
          "Yifan Liu",
          "Ke Chen",
          "Chris Liu",
          "Zengchang Qin",
          "Zhenbo Luo",
          "Jingdong Wang"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPR_2019/papers/Liu_Structured_Knowledge_Distillation_for_Semantic_Segmentation_CVPR_2019_paper.pdf",
        "ref_texts": "[56] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proc. IEEE Conf. Comp. Vis. Patt. Recogn. , pages 2881\u2013",
        "ref_ids": [
          "56"
        ]
      },
      "Dfanet: Deep feature aggregation for real-time semantic segmentation": {
        "authors": [
          "Hanchao Li",
          "Pengfei Xiong",
          "Haoqiang Fan",
          "Jian Sun"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPR_2019/papers/Li_DFANet_Deep_Feature_Aggregation_for_Real-Time_Semantic_Segmentation_CVPR_2019_paper.pdf",
        "ref_texts": "[34] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In IEEE Conf. on Computer Vision and Pattern Recognition (CVPR) , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "34"
        ]
      },
      "Enhanced pix2pix dehazing network": {
        "authors": [
          "Yanyun Qu",
          "Yizi Chen",
          "Jingying Huang",
          "Yuan Xie"
        ],
        "url": "https://openaccess.thecvf.com/content_CVPR_2019/papers/Qu_Enhanced_Pix2pix_Dehazing_Network_CVPR_2019_paper.pdf",
        "ref_texts": "[22] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , pages 6230\u20136239, 2017.",
        "ref_ids": [
          "22"
        ]
      },
      "Efficient and accurate arbitrary-shaped text detection with pixel aggregation network": {
        "authors": [
          "Wenhai Wang",
          "Enze Xie",
          "Xiaoge Song",
          "Yuhang Zang",
          "Wenjia Wang",
          "Tong Lu",
          "Gang Yu",
          "Chunhua Shen"
        ],
        "url": "http://openaccess.thecvf.com/content_ICCV_2019/papers/Wang_Efficient_and_Accurate_Arbitrary-Shaped_Text_Detection_With_Pixel_Aggregation_Network_ICCV_2019_paper.pdf",
        "ref_texts": "[55] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proc. IEEE Conf. Comp. Vis. Patt. Recogn. , 2017.",
        "ref_ids": [
          "55"
        ]
      },
      "Context-aware crowd counting": {
        "authors": [
          "Weizhe Liu",
          "Mathieu Salzmann",
          "Pascal Fua"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPR_2019/papers/Liu_Context-Aware_Crowd_Counting_CVPR_2019_paper.pdf",
        "ref_texts": "[43] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid Scene Parsing Network. In Conference on Computer Vision and Pattern Recognition , 2017. 3",
        "ref_ids": [
          "43"
        ]
      },
      "Unsupervised label noise modeling and loss correction": {
        "authors": [],
        "url": "http://proceedings.mlr.press/v97/arazo19a/arazo19a.pdf",
        "ref_texts": "(11):2884\u20132896, 2018. 1 Xiao, T., Xia, T., Yang, Y ., Huang, C., and Wang, X. Learning from massive noisy labeled data for image classification. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2015. 2, 4.1, 4.6 Zhang, C., Bengio, S., Hardt, M., Recht, B., and Vinyals, O. Understanding deep learning requires re-thinking generalization. In International Conference on Learning Representations (ICLR) , 2017. 1, 2, 3.2, 4.1 Zhang, H., Cisse, M., Dauphin, Y ., and Lopez-Paz, D. mixup: Beyond Empirical Risk Minimization. In International Conference on Learning Representations (ICLR) , 2018. 1, 3, 2, 3.3, 4.1, 4.2, 4.3, 3, 4.4, 4.5, 4.6 Zhao, H., Shi, J., Qi, X., Wang, X., and Jia, J. Pyramid Scene Parsing Network. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2017. 1 Zlateski, A., Jaroensri, R., Sharma, P., and Durand, F. On the Importance of Label Quality for Semantic Segmentation. InIEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2018. 1"
      },
      "Drop an octave: Reducing spatial redundancy in convolutional neural networks with octave convolution": {
        "authors": [
          "Yunpeng Chen",
          "Haoqi Fan",
          "Bing Xu",
          "Zhicheng Yan",
          "Yannis Kalantidis",
          "Marcus Rohrbach",
          "Shuicheng Yan",
          "Jiashi Feng"
        ],
        "url": "http://openaccess.thecvf.com/content_ICCV_2019/papers/Chen_Drop_an_Octave_Reducing_Spatial_Redundancy_in_Convolutional_Neural_Networks_ICCV_2019_paper.pdf",
        "ref_texts": "[50] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017. 2",
        "ref_ids": [
          "50"
        ]
      },
      "Sliced wasserstein discrepancy for unsupervised domain adaptation": {
        "authors": [
          "Yu Lee",
          "Tanmay Batra",
          "Mohammad Haris",
          "Daniel Ulbricht"
        ],
        "url": "https://openaccess.thecvf.com/content_CVPR_2019/papers/Lee_Sliced_Wasserstein_Discrepancy_for_Unsupervised_Domain_Adaptation_CVPR_2019_paper.pdf",
        "ref_texts": "[77] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017. 6",
        "ref_ids": [
          "77"
        ]
      },
      "Semantic understanding of scenes through the ade20k dataset": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1608.05442",
        "ref_texts": "36. Yu F, Koltun V (2016) Multi-scale context aggregation by dilated convolutions 37. Zhao H, Shi J, Qi X, Wang X, Jia J (2017) Pyramid scene parsing network. In: Proc. CVPR",
        "ref_ids": [
          "36"
        ]
      },
      "Canet: Class-agnostic segmentation networks with iterative refinement and attentive few-shot learning": {
        "authors": [
          "Chi Zhang",
          "Guosheng Lin",
          "Fayao Liu",
          "Rui Yao",
          "Chunhua Shen"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPR_2019/papers/Zhang_CANet_Class-Agnostic_Segmentation_Networks_With_Iterative_Refinement_and_Attentive_Few-Shot_CVPR_2019_paper.pdf",
        "ref_texts": "[40] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In CVPR , pages 2881\u20132890, 2017. 4",
        "ref_ids": [
          "40"
        ]
      },
      "Fast-scnn: Fast semantic segmentation network": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1902.04502/pdf",
        "ref_texts": "[37] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid Scene Parsing Network. In CVPR , 2017. 2, 3, 4, 5, 6",
        "ref_ids": [
          "37"
        ]
      },
      "Shape robust text detection with progressive scale expansion network": {
        "authors": [
          "Wenhai Wang",
          "Enze Xie",
          "Xiang Li",
          "Wenbo Hou",
          "Tong Lu",
          "Gang Yu",
          "Shuai Shao"
        ],
        "url": "https://openaccess.thecvf.com/content_CVPR_2019/papers/Wang_Shape_Robust_Text_Detection_With_Progressive_Scale_Expansion_Network_CVPR_2019_paper.pdf",
        "ref_texts": ""
      },
      "Attentive feedback network for boundary-aware salient object detection": {
        "authors": [
          "Mengyang Feng",
          "Huchuan Lu",
          "Errui Ding"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPR_2019/papers/Feng_Attentive_Feedback_Network_for_Boundary-Aware_Salient_Object_Detection_CVPR_2019_paper.pdf",
        "ref_texts": "[34] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In Proceedings of IEEE Conference on Computer Vision and Pattern Recognition , 2017.",
        "ref_ids": [
          "34"
        ]
      },
      "Carafe: Content-aware reassembly of features": {
        "authors": [
          "Jiaqi Wang",
          "Kai Chen",
          "Rui Xu",
          "Ziwei Liu",
          "Chen Change",
          "Dahua Lin"
        ],
        "url": "http://openaccess.thecvf.com/content_ICCV_2019/papers/Wang_CARAFE_Content-Aware_ReAssembly_of_FEatures_ICCV_2019_paper.pdf",
        "ref_texts": "[39] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In IEEE Conference on Computer Vision and Pattern Recognition, 2017.",
        "ref_ids": [
          "39"
        ]
      },
      "Recent progress in semantic image segmentation": {
        "authors": [
          "Xiaolong Liu"
        ],
        "url": "https://link.springer.com/content/pdf/10.1007/s10462-018-9641-3.pdf",
        "ref_texts": "1106 X. Liu et al. Viola P , Jones M (2001) Rapid object detection using a boosted cascade of simple features. In: Proceedings of the 2001 IEEE computer society conference on computer vision and pattern recognition, CVPR 2001,vol 1. IEEE, pp I\u2013I Wei GQ, Arbter K, Hirzinger G (1997) Automatic tracking of laparoscopic instruments by color coding. In: CVRMed-MRCAS\u201997. Springer, Berlin, pp 357\u2013366 Wu Z, Shen C, Hengel A (2016a) High-performance semantic segmentation using very deep fully convolutional networks. arXiv preprint arXiv:1604.04339 Wu Z, Shen C, Hengel A (2016b) Wider or deeper: revisiting the resnet model for visual recognition. arXiv preprint arXiv:1611.10080 Xia W, Domokos C, Dong J, Cheong LF, Yan S (2013) Semantic segmentation without annotating segments. In: Proceedings of the IEEE international conference on computer vision, pp 2176\u20132183 Xiao J, Hays J, Ehinger KA, Oliva A, Torralba A (2010) Sun database: large-scale scene recognition from abbey to zoo. In: 2010 IEEE conference on computer vision and pattern recognition (CVPR). IEEE, pp3485\u20133492 Xie S, Girshick R, Dollr P , Tu Z, He K (2016) Aggregated residual transformations for deep neural networks. arXiv preprint arXiv:1611.05431 Xu A, Wang L, Feng S, Qu Y (2010) Threshold-based level set method of image segmentation. In: 2010 3rd international conference on intelligent networks and intelligent systems (ICINIS). IEEE, pp 703\u2013706 Xu J, Schwing AG, Urtasun R (2015) Learning to segment under various forms of weak supervision. In: Proceedings of the IEEE conference on computer vision and pattern recognition, pp 3781\u20133790 Y u F, Koltun V (2015) Multi-scale context aggregation by dilated convolutions. arXiv preprint arXiv:1511.07122 Y u F, Koltun V , Funkhouser T (2017) Dilated residual networks. arXiv preprint arXiv:1705.09914 Zhao H, Shi J, Qi X, Wang X, Jia J (2016) Pyramid scene parsing network. arXiv preprint arXiv:1612.01105 Zheng L, Li G, Bao Y (2010) Improvement of grayscale image 2D maximum entropy threshold segmentation method. In: 2010 international conference on logistics systems and intelligent management, vol 1. IEEE,pp 324\u2013328 Zhou B, Zhao H, Puig X, Fidler S, Barriuso A, Torralba A (2017) Scene parsing through ade20k dataset. In: Proceedings of the IEEE conference on computer vision and pattern recognition Zhu SC, Guo CE, Wang Y , Xu Z (2005) What are textons? Int J Comput Vis 62(1):121\u2013143Zhu J, Mao J, Y uille AL (2014) Learning from weakly supervised data by the expectation loss svm (e-svm) algorithm. In: Advances in neural information processing systems, pp 1125\u20131133"
      },
      "Graph-based global reasoning networks": {
        "authors": [
          "Yunpeng Chen",
          "Marcus Rohrbach",
          "Zhicheng Yan",
          "Yan Shuicheng",
          "Jiashi Feng",
          "Yannis Kalantidis"
        ],
        "url": "https://openaccess.thecvf.com/content_CVPR_2019/papers/Chen_Graph-Based_Global_Reasoning_Networks_CVPR_2019_paper.pdf",
        "ref_texts": "[37] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In Computer Vision and Pattern Recognition (CVPR), 2017 IEEE Conference on , pages 6230\u20136239. IEEE, 2017. 1,2,7",
        "ref_ids": [
          "37"
        ]
      },
      "Understanding deep learning techniques for image segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1907.06119",
        "ref_texts": "[220] Zhao, H., Shi, J., Qi, X., Wang, X., and Jia, J. Pyramid scene parsing network. In IEEE Conf. on Computer Vision and Pattern Recognition (CVPR) (2017), pp. 2881{2890.",
        "ref_ids": [
          "220"
        ]
      },
      "Ficklenet: Weakly and semi-supervised semantic image segmentation using stochastic inference": {
        "authors": [
          "Jungbeom Lee",
          "Eunji Kim",
          "Sungmin Lee",
          "Jangho Lee",
          "Sungroh Yoon"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPR_2019/papers/Lee_FickleNet_Weakly_and_Semi-Supervised_Semantic_Image_Segmentation_Using_Stochastic_Inference_CVPR_2019_paper.pdf",
        "ref_texts": "[36] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In IEEE Conf. on Computer Vision and Pattern Recognition (CVPR) , pages 2881\u20132890, 2017. 1",
        "ref_ids": [
          "36"
        ]
      },
      "Espnetv2: A light-weight, power efficient, and general purpose convolutional neural network": {
        "authors": [
          "Sachin Mehta",
          "Mohammad Rastegari",
          "Linda Shapiro",
          "Hannaneh Hajishirzi"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPR_2019/papers/Mehta_ESPNetv2_A_Light-Weight_Power_Efficient_and_General_Purpose_Convolutional_Neural_CVPR_2019_paper.pdf",
        "ref_texts": "[62] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017. 1",
        "ref_ids": [
          "62"
        ]
      },
      "Domain randomization and pyramid consistency: Simulation-to-real generalization without accessing target domain data": {
        "authors": [
          "Xiangyu Yue",
          "Yang Zhang",
          "Sicheng Zhao",
          "Alberto Sangiovanni",
          "Kurt Keutzer",
          "Boqing Gong"
        ],
        "url": "http://openaccess.thecvf.com/content_ICCV_2019/papers/Yue_Domain_Randomization_and_Pyramid_Consistency_Simulation-to-Real_Generalization_Without_Accessing_Target_ICCV_2019_paper.pdf",
        "ref_texts": "[59] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In IEEE Conference on Computer Vision and Pattern Recognition, pages 2881\u20132890, 2017.",
        "ref_ids": [
          "59"
        ]
      },
      "Cross-modal self-attention network for referring image segmentation": {
        "authors": [
          "Linwei Ye",
          "Mrigank Rochan",
          "Zhi Liu",
          "Yang Wang"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPR_2019/papers/Ye_Cross-Modal_Self-Attention_Network_for_Referring_Image_Segmentation_CVPR_2019_paper.pdf",
        "ref_texts": "[30] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In IEEE Conference on Computer Vision and Pattern Recognition, 2017. 2,6",
        "ref_ids": [
          "30"
        ]
      },
      "PGA-Net: Pyramid feature fusion and global context attention network for automated surface defect detection": {
        "authors": [],
        "url": "https://repository.lboro.ac.uk/articles/PGA-Net_pyramid_feature_fusion_and_global_context_attention_network_for_automated_surface_defect_detection/12249758/files/22535003.pdf",
        "ref_texts": "[21] H. Zhao, J. Shi, X. Qi, X. Wang and J. Jia, \u201cPyramid Scene Parsing Network, \u201d 2017 IEEE Conf . on Comput . Vis. and Pattern Recognit . ",
        "ref_ids": [
          "21"
        ]
      },
      "Generative adversarial networks for extreme learned image compression": {
        "authors": [
          "Eirikur Agustsson",
          "Michael Tschannen",
          "Fabian Mentzer",
          "Radu Timofte",
          "Luc Van"
        ],
        "url": "https://openaccess.thecvf.com/content_ICCV_2019/papers/Agustsson_Generative_Adversarial_Networks_for_Extreme_Learned_Image_Compression_ICCV_2019_paper.pdf",
        "ref_texts": "[48] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid Scene Parsing Network. ArXiv e-prints , Dec. 2016. 6",
        "ref_ids": [
          "48"
        ]
      },
      "Upsnet: A unified panoptic segmentation network": {
        "authors": [
          "Yuwen Xiong",
          "Renjie Liao",
          "Hengshuang Zhao",
          "Rui Hu",
          "Min Bai",
          "Ersin Yumer",
          "Raquel Urtasun"
        ],
        "url": "https://openaccess.thecvf.com/content_CVPR_2019/papers/Xiong_UPSNet_A_Unified_Panoptic_Segmentation_Network_CVPR_2019_paper.pdf",
        "ref_texts": "[40] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017.",
        "ref_ids": [
          "40"
        ]
      },
      "Scaling and benchmarking self-supervised visual representation learning": {
        "authors": [
          "Priya Goyal",
          "Dhruv Mahajan",
          "Abhinav Gupta",
          "Ishan Misra"
        ],
        "url": "http://openaccess.thecvf.com/content_ICCV_2019/papers/Goyal_Scaling_and_Benchmarking_Self-Supervised_Visual_Representation_Learning_ICCV_2019_paper.pdf",
        "ref_texts": "[76] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017. 7",
        "ref_ids": [
          "76"
        ]
      },
      "Scaling out-of-distribution detection for real-world settings": {
        "authors": [
          "Anonymous Submission"
        ],
        "url": "https://arxiv.org/pdf/1911.11132",
        "ref_texts": "582\u2013588, Cambridge, MA, USA, 1999. MIT Press. Tolstikhin, I., Houlsby, N., Kolesnikov, A., Beyer, L., Zhai, X., Unterthiner, T., Yung, J., Keysers, D., Uszkoreit, J., Lucic, M., et al. Mlp-mixer: An all-mlp architecture for vision. arXiv preprint arXiv:2105.01601 , 2021. Yu, F., Zhang, Y ., Song, S., Seff, A., and Xiao, J. LSUN: construction of a large-scale image dataset using deep learning with humans in the loop. CoRR , 2015. Yu, F., Xian, W., Chen, Y ., Liu, F., Liao, M., Madhavan, V ., and Darrell, T. BDD100K: A diverse driving video database with scalable annotation tooling. CoRR , abs/1805.04687, 2018. Zendel, O., Honauer, K., Murschitz, M., Steininger, D., and Fernandez Dominguez, G. Wilddash-creating hazardaware benchmarks. In Proceedings of the European Conference on Computer Vision (ECCV) , pp. 402\u2013416, 2018. Zhao, H., Shi, J., Qi, X., Wang, X., and Jia, J. Pyramid scene parsing network. 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , pp. 6230\u20136239, 2017. Zhou, B., Lapedriza, A., Khosla, A., Oliva, A., and Torralba, A. Places: A 10 million image database for scene recognition. PAMI , 2017. Zhou, P., Han, X., Morariu, V . I., and Davis, L. S. Learning rich features for image manipulation detection. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pp. 1053\u20131061, 2018. Scaling Out-of-Distribution Detection for Real-World Settings FPR95# AUROC\" AUPR\" DinDtest out B M D K B M D K B M D KImageNetGaussian 2 0 5 4 100 100 97 98 93 98 55 79 Rademacher 21 4 4 15 89 98 98 93 29 70 62 54 Blobs 26 32 72 8 80 79 37 99 25 17 7 93 Textures 68 56 74 59 80 87 76 85 25 36 16 48 LSUN 66 63 59 60 75 77 76 79 21 22 19 38 Places365 64 59 63 72 79 83 79 79 27 32 24 46 Mean 41.3 35.8 46 36.1 85.2 87.2 76.9 88.7 37 45.8 30.5 59.7Places365Gaussian 10 6 71 12 93 96 35 93 16 24 2 16 Rademacher 20 10 91 1 89 93 10 100 11 15.9 1.6 88 Blobs 59 6 88 27 72 98 15 93 5 41 2 31 Textures 86 72 87 74 65 79 43 79 4 11 1 12 Places69 88 89 92 91 61 64 52 65 5 6 3 6 Mean 53 36.6 85.8 40.9 76 85.8 31.1 85.8 8 19.2 2 30.5 Table 5: B is for the maximum softmax probability baseline, M is for maximum logit, D is for the method in (DeVries & Taylor, 2018), and K is our own KL method described below. Both M and K are ours. Results are on ImageNet and Places365. All values are percentages and are rounded so that 99:95rounds to 100. A. Full Multiclass OOD Detection Results Datasets. To evaluate the MSP baseline out-ofdistribution detector and the MaxLogit detector, we use the ImageNet-1K object recognition dataset and Places365 scene recognition dataset as in-distribution datasetsDin. We use several out-of-distribution test datasets Dout, all of which are unseen during training. The first out-of-distribution dataset is Gaussian noise, where each example\u2019s pixels are i.i.d. sampled from N(0;0:5)and clipped to be contained within [\u00001;1]. Another type of test-time noise is Rademacher noise, in which each pixel is i.i.d. sampled from 2\u0001Bernoulli (0:5)\u00001, i.e. each pixel is1or\u00001with equal probability. Blob examples are more structured than noise; they are algorithmically generated blob images. Meanwhile, Textures is a dataset consisting in images of describable textures (Cimpoi et al., 2014). When evaluating the ImageNet-1K detector, we use LSUN images, a scene recognition dataset (Yu et al., 2015). Our finalDoutisPlaces69 , a scene classification dataset that does not share classes with Places365. In all, we evaluate against out-of-distribution examples spanning synthetic and realistic images. KL Matching Method. To verify our intuitions that led us to develop the MaxLogit detector, we developed a less convenient but similarly powerful technique applicable for the multiclass setting. Recall that some classes tend to be predicted with low confidence and others high confidence. The shape of predicted posterior distributions is often class dependent. We capture the typical shape of each class\u2019s posterior distribution and form posterior distribution templates for each class. During test time, the network\u2019s softmax pos-terior distribution is compared to these templates and an anomaly score is generated. More concretely, we compute kdifferent distributions dk, one for each class. We write dk=Ex0\u0018X val[p(yjx0)]wherek=argmaxkp(y=kjx0). Then for a new test input x, we calculate the anomaly score minkKL[p(yjx)kdk]rather than the MSP baseline \u0000max kp(y=kjx). Note that we utilize the validation dataset, but our KL matching method does not require the validation dataset\u2019s labels. That said, our KL matching method is less convenient than our MaxLogit technique, and the two perform similarly. Since this technique requires more data than MaxLogit, we opt to simply use the MaxLogit in the main paper. Results. Observe that the proposed MaxLogit method outperforms the maximum softmax probability baseline for all three metrics on both ImageNet and Places365. These results were computed using a ResNet-50 trained on either ImageNet-1K or Places365. In the case of Places365, the AUROC improvement is over 10%. We note that the utility of the maximum logit could not be appreciated as easily in previous work\u2019s small-scale settings. For example, using the small-scale CIFAR-10 setup of Hendrycks et al."
      },
      "Improving semantic segmentation via video propagation and label relaxation": {
        "authors": [
          "Yi Zhu",
          "Karan Sapra",
          "Fitsum A. Reda",
          "Kevin J. Shih",
          "Shawn Newsam",
          "Andrew Tao",
          "Bryan Catanzaro"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPR_2019/papers/Zhu_Improving_Semantic_Segmentation_via_Video_Propagation_and_Label_Relaxation_CVPR_2019_paper.pdf",
        "ref_texts": "[44] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid Scene Parsing Network. In Conference on Computer Vision and Pattern Recognition (CVPR) , 2017.",
        "ref_ids": [
          "44"
        ]
      },
      "Bi-directional cascade network for perceptual edge detection": {
        "authors": [
          "Jianzhong He",
          "Shiliang Zhang",
          "Ming Yang",
          "Yanhu Shan",
          "Tiejun Huang"
        ],
        "url": "https://openaccess.thecvf.com/content_CVPR_2019/papers/He_Bi-Directional_Cascade_Network_for_Perceptual_Edge_Detection_CVPR_2019_paper.pdf",
        "ref_texts": "[55] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In CVPR , pages 2881\u20132890, 2017. 2",
        "ref_ids": [
          "55"
        ]
      },
      "Feature weighting and boosting for few-shot segmentation": {
        "authors": [
          "Khoi Nguyen",
          "Sinisa Todorovic"
        ],
        "url": "https://openaccess.thecvf.com/content_ICCV_2019/papers/Nguyen_Feature_Weighting_and_Boosting_for_Few-Shot_Segmentation_ICCV_2019_paper.pdf",
        "ref_texts": "[33] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , July 2017.",
        "ref_ids": [
          "33"
        ]
      },
      "Certified data removal from machine learning models": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1911.03030",
        "ref_texts": "(2017). Deep learning with dynamic computation graphs. In5th International Conference on Learning Representations, ICLR 2017, Toulon, France, April 24-26, 2017, Conference Track Proceedings . Mahajan, D., Girshick, R. B., Ramanathan, V ., He, K., Paluri, M., Li, Y ., Bharambe, A., and van der Maaten, L. (2018). Exploring the limits of weakly supervised pretraining. In Computer Vision ECCV 2018 15th European Conference, Munich, Germany, September 8-14, 2018, Proceedings, Part II , pages 185\u2013201. Ren, S., He, K., Girshick, R. B., and Sun, J. (2015). Faster R-CNN: towards real-time object detection with region proposal networks. In Advances in Neural Information Processing Systems 28: Annual Conference on Neural Information Processing Systems 2015, December 7-12, 2015, Montreal, Quebec, Canada , pages 91\u201399. Tai, K. S., Socher, R., and Manning, C. D. (2015). Improved semantic representations from tree-structured long short-term memory networks. In Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing of the Asian Federation of Natural Language Processing, ACL 2015, July 26-31, 2015, Beijing, China, Volume 1: Long Papers , pages 1556\u20131566. Thomee, B., Shamma, D. A., Friedland, G., Elizalde, B., Ni, K., Poland, D., Borth, D., and Li, L.-J. (2016). Yfcc100m: The new data in multimedia research. Communications of the ACM , 59(2):64\u201373. Tsai, C., Lin, C., and Lin, C. (2014). Incremental and decremental training for linear classification. In The 20th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD \u201914, New York, NY, USA August 24 27, 2014 , pages 343\u2013352. Wang, A., Singh, A., Michael, J., Hill, F., Levy, O., and Bowman, S. R. (2019). GLUE: A multi-task benchmark and analysis platform for natural language understanding. In7th International Conference on Learning Representations, ICLR 2019, New Orleans, LA, USA, May 6-9, 2019 . Wieting, J., Bansal, M., Gimpel, K., and Livescu, K. (2016). Towards universal paraphrastic sentence embeddings. In 4th International Conference on Learning Representations, ICLR 2016, San Juan, Puerto Rico, May 2-4, 2016, Conference Track Proceedings . Xie, S., Girshick, R. B., Doll \u00b4ar, P., Tu, Z., and He, K. (2017). Aggregated residual transformations for deep neural networks. In 2017 IEEE Conference on Computer Vision Certified Data Removal from Machine Learning Models and Pattern Recognition, CVPR 2017, Honolulu, HI, USA, July 21-26, 2017 , pages 5987\u20135995. Yang, Z., Dai, Z., Yang, Y ., Carbonell, J. G., Salakhutdinov, R., and Le, Q. V . (2019). Xlnet: Generalized autoregressive pretraining for language understanding. CoRR , abs/1906.08237. Yeom, S., Giacomelli, I., Fredrikson, M., and Jha, S. (2018). Privacy risk in machine learning: Analyzing the connection to overfitting. In CSF. Zhao, H., Shi, J., Qi, X., Wang, X., and Jia, J. (2017). Pyramid scene parsing network. In 2017 IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2017, Honolulu, HI, USA, July 21-26, 2017 , pages 6230\u20136239. Certified Data Removal from Machine Learning Models A. Appendix We present proofs for theorems stated in the main paper. Theorem 1. Suppose that \u2200(xi, yi)\u2208 D,w\u2208Rd:\u2225\u2207\u2113(w\u22a4xi, yi)\u22252\u2264C. Suppose also that \u2113\u2032\u2032is\u03b3-Lipschitz and \u2225xi\u22252\u22641for all (xi, yi)\u2208 D. Then: \u2225\u2207L(w\u2212;D\u2032)\u22252=\u2225(Hw\u03b7\u2212Hw\u2217)H\u22121 w\u2217\u2206\u22252"
      },
      "End-to-end interpretable neural motion planner": {
        "authors": [
          "Wenyuan Zeng",
          "Wenjie Luo",
          "Simon Suo",
          "Abbas Sadat",
          "Bin Yang",
          "Sergio Casas",
          "Raquel Urtasun"
        ],
        "url": "https://openaccess.thecvf.com/content_CVPR_2019/papers/Zeng_End-To-End_Interpretable_Neural_Motion_Planner_CVPR_2019_paper.pdf",
        "ref_texts": "[34] H Zhao, J Shi, X Qi, X Wang, and J Jia. Pyramid scene parsing network. corrabs/1612.01105, 2016. 4",
        "ref_ids": [
          "34"
        ]
      },
      "In defense of pre-trained imagenet architectures for real-time semantic segmentation of road-driving images": {
        "authors": [
          "Marin Orsic",
          "Ivan Kreso",
          "Petra Bevandic",
          "Sinisa Segvic"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPR_2019/papers/Orsic_In_Defense_of_Pre-Trained_ImageNet_Architectures_for_Real-Time_Semantic_Segmentation_CVPR_2019_paper.pdf",
        "ref_texts": "[41] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In ICCV , 2017.",
        "ref_ids": [
          "41"
        ]
      },
      "Domain adaptation for semantic segmentation with maximum squares loss": {
        "authors": [
          "Minghao Chen",
          "Hongyang Xue",
          "Deng Cai"
        ],
        "url": "http://openaccess.thecvf.com/content_ICCV_2019/papers/Chen_Domain_Adaptation_for_Semantic_Segmentation_With_Maximum_Squares_Loss_ICCV_2019_paper.pdf",
        "ref_texts": "[35] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017.",
        "ref_ids": [
          "35"
        ]
      },
      "Adaptive pyramid context network for semantic segmentation": {
        "authors": [
          "Junjun He",
          "Zhongying Deng",
          "Lei Zhou",
          "Yali Wang",
          "Yu Qiao"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPR_2019/papers/He_Adaptive_Pyramid_Context_Network_for_Semantic_Segmentation_CVPR_2019_paper.pdf",
        "ref_texts": "[40] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In IEEE Conf. on Computer Vision and Pattern Recognition (CVPR) , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "40"
        ]
      },
      "Deep self-learning from noisy labels": {
        "authors": [
          "Jiangfan Han",
          "Ping Luo",
          "Xiaogang Wang"
        ],
        "url": "http://openaccess.thecvf.com/content_ICCV_2019/papers/Han_Deep_Self-Learning_From_Noisy_Labels_ICCV_2019_paper.pdf",
        "ref_texts": "[40] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "40"
        ]
      },
      "Multi-channel attention selection gan with cascaded semantic guidance for cross-view image translation": {
        "authors": [
          "Hao Tang",
          "Dan Xu",
          "Nicu Sebe",
          "Yanzhi Wang",
          "Jason J. Corso",
          "Yan Yan"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPR_2019/papers/Tang_Multi-Channel_Attention_Selection_GAN_With_Cascaded_Semantic_Guidance_for_Cross-View_CVPR_2019_paper.pdf",
        "ref_texts": "[50] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017. 4",
        "ref_ids": [
          "50"
        ]
      },
      "Semi-supervised semantic segmentation needs strong, varied perturbations": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1906.01916",
        "ref_texts": "[47] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017. SUPPLEMENTAL MATERIAL A Pascal VOC 2012 performance across network architectures We demonstrate the effectiveness of our approach using a variety of architectures on the PASCAL dataset in Table 4. Using an ImageNet pre-trained DeepLab v3+ our baseline and semi-supervised results are stronger than those of [28]. FRENCH ET AL.: SEMI-SUPERVISED SEMANTIC SEGMENTATION 15 Prop. Labels 1/100 1/50 1/20 1/8 Full (10582) Results from [18, 28] with ImageNet pretrained DeepLab v2 Baseline \u2013 48.3% 56.8% 62.0% 70.7% Adversarial [18] \u2013 49.2% 59.1% 64.3% 71.4% s4GAN+MLMT [28] \u2013 60.4% 62.9% 67.3% 73.2% Our results: Same ImageNet pretrained DeepLab v2 network Baseline 33.09% 43.15% 52.05% 60.56% 72.59% CutMix 53.79% 64.81% 66.48% 67.60% 72.54% Results from [28] with ImageNet pretrained DeepLab v3+ Baseline \u2013 unstable unstable 63.5% 74.6% s4GAN+MLMT [28] \u2013 62.6% 66.6% 70.4% 74.7% Our results: ImageNet pretrained DeepLab v3+ network Baseline 37.95% 48.35% 59.19% 66.58% 76.70% CutMix 59.52% 67.05% 69.57% 72.45% 76.73% Our results: ImageNet pretrained DenseNet-161 based Dense U-net Baseline 29.22% 39.92% 50.31% 60.65% 72.30% CutMix 54.19% 63.81% 66.57% 66.78% 72.02% Our results: ImageNet pretrained ResNet-101 based PSPNet Baseline 36.69% 46.96% 59.02% 66.67% 77.59% CutMix 67.20% 68.80% 73.33% 74.11% 77.42% Table 4: Performance (mIoU) on augmented P ASCAL VOC validation set across a variety of architectures, using same splits as Mittal et al. [28]. The results for [18] and [28] are taken from [28]. B Smoothly varying sample density in semantic segmentation B.1 Derivation of signal processing explanation In this section we explain the derivation of our signal-processing based explanation of the lack of low-density regions in semantic segmentation problems. To analyse the smoothness of the distribution of patches over an image we need to compute the L2pixel content distance between patches centred on neighbouring pixels. Let us start with two patches AandB\u2013 see Figure 4(a,b) \u2013 extracted from an image I, centred on horizontally neighbouring pixels, with Aone pixel to the left of B. The L2distance isjB\u0000Aj. Given that each pixel in B\u0000Ais the difference between horizontally neighbouring pixels, B\u0000Ais therefore a patch extracted from the horizontal gradient image DxI(see Figure 4(c)). The squared distance is the sum of the element-wise squares of B\u0000A; it is the sum of the elements in a patch extracted from (DxI)fl2. Computing the sums of all patches of size H\u0002W in a sliding window fashion across (DxI)fl2is equivalent to convolving it with a box kernel 1H\u0002W, thus the distance between all horizontally neighbouring patches can be computed usingp (DxI)fl2\u00031H\u0002W. A box filter \u2013 or closely related uniform filter \u2013 is a low-pass filter that will suppress high-frequency details, resulting in a smooth output. This is implemented in a Jupyter notebook [22] that is distributed with our code.",
        "ref_ids": [
          "47",
          "28",
          "18, 28",
          "18",
          "28",
          "28",
          "28",
          "28",
          "18",
          "28",
          "28",
          "22"
        ]
      },
      "Lednet: A lightweight encoder-decoder network for real-time semantic segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1905.02423",
        "ref_texts": "[8] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Y . Jia, \u201cPyramid scene parsing network,\u201d in CVPR , 2016, pp. 6230\u20136239.",
        "ref_ids": [
          "8"
        ]
      },
      "Acfnet: Attentional class feature network for semantic segmentation": {
        "authors": [
          "Fan Zhang",
          "Yanqin Chen",
          "Zhihang Li",
          "Zhibin Hong",
          "Jingtuo Liu",
          "Feifei Ma",
          "Junyu Han",
          "Errui Ding"
        ],
        "url": "http://openaccess.thecvf.com/content_ICCV_2019/papers/Zhang_ACFNet_Attentional_Class_Feature_Network_for_Semantic_Segmentation_ICCV_2019_paper.pdf",
        "ref_texts": "[46] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In IEEE Conf. on Computer Vision and Pattern Recognition (CVPR) , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "46"
        ]
      },
      "Adapting object detectors via selective cross-domain alignment": {
        "authors": [
          "Xinge Zhu",
          "Jiangmiao Pang",
          "Ceyuan Yang",
          "Jianping Shi",
          "Dahua Lin"
        ],
        "url": "https://openaccess.thecvf.com/content_CVPR_2019/papers/Zhu_Adapting_Object_Detectors_via_Selective_Cross-Domain_Alignment_CVPR_2019_paper.pdf",
        "ref_texts": "[47] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "47"
        ]
      },
      "Crowd counting and density estimation by trellis encoder-decoder networks": {
        "authors": [
          "Xiaolong Jiang",
          "Zehao Xiao",
          "Baochang Zhang",
          "Xiantong Zhen",
          "Xianbin Cao",
          "David Doermann",
          "Ling Shao"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPR_2019/papers/Jiang_Crowd_Counting_and_Density_Estimation_by_Trellis_Encoder-Decoder_Networks_CVPR_2019_paper.pdf",
        "ref_texts": "[54] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In IEEE Conf. on Computer Vision and Pattern Recognition (CVPR) , pages 2881\u20132890, 2017. 2,4",
        "ref_ids": [
          "54"
        ]
      },
      "Neural transfer learning for natural language processing": {
        "authors": [],
        "url": "https://aran.library.nuigalway.ie/bitstream/handle/10379/15463/neural_transfer_learning_for_nlp.pdf?sequence=1",
        "ref_texts": "(March). Jiang, J. (2009). Multi-task transfer learning for weakly-supervised relation extraction. Proceedings of the 47th Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP , (August):1012{1020. Jiang, J. and Zhai, C. (2007). Instance Weighting for Domain Adaptation in NLP. Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics , (October):264{271. Jindal, N. and Liu, B. (2007). Review spam detection. In Proceedings of the 16th international conference on World Wide Web , pages 1189{1190. ACM. Johnson, M., Schuster, M., Le, Q. V., Krikun, M., Wu, Y., Chen, Z., Thorat, N., Vi\u0013 egas, F., Wattenberg, M., Corrado, G., Hughes, M., and Dean, J. (2016). Google's Multilingual Neural Machine Translation System: Enabling Zero-Shot Translation. Johnson, R. and Zhang, T. (2016). Supervised and semi-supervised text categorization using lstm for region embeddings. In International Conference on Machine Learning , pages 526{534. Johnson, R. and Zhang, T. (2017). Deep pyramid convolutional neural networks for text categorization. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) , volume 1, pages 562{570. Jonker, R. and Volgenant, A. (1987). A shortest augmenting path algorithm for dense and sparse linear assignment problems. Computing , 38(4):325{340. Joshi, V., Peters, M., and Hopkins, M. (2018). Extending a Parser to Distant Domains Using a Few Dozen Partially Annotated Examples. In Proceedings of ACL 2018 . Kaiser, L., Nachum, O., Roy, A., and Bengio, S. (2017). Learning to Remember Rare Events. In ICLR 2017 . Kalchbrenner, N., Grefenstette, E., and Blunsom, P. (2014). A Convolutional Neural Network for Modelling Sentences. In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics , pages 655{665. Kang, Z., Grauman, K., and Sha, F. (2011). Learning with whom to share in multitask feature learning. Proceedings of the 28th International Conference on Machine Learning , (4):4{5. Bibliography. 281 Katiyar, A. and Cardie, C. (2017). Going out on a limb : Joint Extraction of Entity Mentions and Relations without Dependency Trees. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics , pages 917{928. Kementchedjhieva, Y., Ruder, S., Cotterell, R., and S\u001cgaard, A. (2018). Generalizing Procrustes Analysis for Better Bilingual Dictionary Induction. In Proceedings of CoNLL 2018 . Kendall, A., Gal, Y., and Cipolla, R. (2018). Multi-Task Learning Using Uncertainty to Weigh Losses for Scene Geometry and Semantics. In Proceedings of CVPR 2018 . Kiela, D. and Clark, S. (2015). Multiand cross-modal semantics beyond vision: Grounding in auditory perception. In Proceedings of EMNLP , pages 2461{2470. Kiela, D., Conneau, A., Jabri, A., and Nickel, M. (2018a). Learning Visually Grounded Sentence Representations. In Proceedings of NAACL-HLT 2018 . Kiela, D., Vuli\u0013 c, I., and Clark, S. (2015). Visual bilingual lexicon induction with transferred ConvNet features. In Proceedings of EMNLP , pages 148{158. Kiela, D., Wang, C., and Cho, K. (2018b). Dynamic Meta-Embeddings for Improved Sentence Representations. In Proceedings of EMNLP 2018 . Kifer, D., Ben-David, S., and Gehrke, J. (2004). Detecting change in data streams. In Proceedings of the Thirtieth international conference on Very large data bases-Volume 30, pages 180{191. VLDB Endowment. Kim, J.-D., Ohta, T., Tsuruoka, Y., Tateisi, Y., and Collier, N. (2004). Introduction to the bio-entity recognition task at jnlpba. In Proceedings of the international joint workshop on natural language processing in biomedicine and its applications , pages 70{75. Association for Computational Linguistics. Kim, S. and Xing, E. P. (2010). Tree-Guided Group Lasso for Multi-Task Regression with Structured Sparsity. 27th International Conference on Machine Learning , pages 1{14. Kim, Y. (2014). Convolutional Neural Networks for Sentence Classiffcation. Proceedings of the Conference on Empirical Methods in Natural Language Processing , pages 1746{1751. Kim, Y.-B., Stratos, K., and Kim, D. (2017a). Adversarial adaptation of synthetic or stale data. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) , pages 1297{1307, Vancouver, Canada. Association for Computational Linguistics. Bibliography. 282 Kim, Y.-b., Stratos, K., and Kim, D. (2017b). Domain Attention with an Ensemble of Experts. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics , pages 643{653. Kim, Y.-b., Stratos, K., and Sarikaya, R. (2016). Frustratingly Easy Neural Domain Adaptation. In Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: Technical Papers , pages 387{396. Kim, Y.-B., Stratos, K., Sarikaya, R., and Jeong, M. (2015). New Transfer Learning Techniques for Disparate Label Sets. In Proceedings of ACL . Kingma, D. P. and Ba, J. L. (2015). Adam: a Method for Stochastic Optimization. Proceedings of ICLR . Kingsbury, P. and Palmer, M. (2002). From treebank to propbank. In LREC , pages 1989{1993. Citeseer. Kiperwasser, E. and Ballesteros, M. (2018). Scheduled Multi-Task Learning : From Syntax to Translation. Transactions of the Association for Computational Linguistics , 6:225{240. Kiperwasser, E. and Goldberg, Y. (2016). Simple and Accurate Dependency Parsing Using Bidirectional LSTM Feature Representations. Transactions of the Association for Computational Linguistics , 4:313{327. Kirkpatrick, J., Pascanu, R., Rabinowitz, N., Veness, J., Desjardins, G., Rusu, A. A., Milan, K., Quan, J., Ramalho, T., Grabska-Barwinska, A., Hassabis, D., Clopath, C., Kumaran, D., and Hadsell, R. (2017). Overcoming catastrophic forgetting in neural networks. PNAS . Kiros, J. R. and Chan, W. (2018). InferLite: Simple Universal Sentence Representations from Natural Language Inference Data. In Proceedings of EMNLP 2018 , pages 4868{"
      },
      "Category anchor-guided unsupervised domain adaptation for semantic segmentation": {
        "authors": [
          "Qiming Z",
          "Jing Zhang",
          "Wei Liu",
          "Dacheng Tao"
        ],
        "url": "https://proceedings.neurips.cc/paper_files/paper/2019/file/6da9003b743b65f4c0ccd295cc484e57-Paper.pdf",
        "ref_texts": "[46] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "46"
        ]
      },
      "Dynamic multi-scale filters for semantic segmentation": {
        "authors": [
          "Junjun He",
          "Zhongying Deng",
          "Yu Qiao"
        ],
        "url": "http://openaccess.thecvf.com/content_ICCV_2019/papers/He_Dynamic_Multi-Scale_Filters_for_Semantic_Segmentation_ICCV_2019_paper.pdf",
        "ref_texts": "[51] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017. 1,2,3,4,5,6, 7,8",
        "ref_ids": [
          "51"
        ]
      },
      "Deeppruner: Learning efficient stereo matching via differentiable patchmatch": {
        "authors": [
          "Shivam Duggal",
          "Shenlong Wang",
          "Chiu Ma",
          "Rui Hu",
          "Raquel Urtasun"
        ],
        "url": "https://openaccess.thecvf.com/content_ICCV_2019/papers/Duggal_DeepPruner_Learning_Efficient_Stereo_Matching_via_Differentiable_PatchMatch_ICCV_2019_paper.pdf",
        "ref_texts": "[42] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017.",
        "ref_ids": [
          "42"
        ]
      },
      "Revisiting single image depth estimation: Toward higher resolution maps with accurate object boundaries": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1803.08673",
        "ref_texts": ""
      },
      "Ssap: Single-shot instance segmentation with affinity pyramid": {
        "authors": [
          "Naiyu Gao",
          "Yanhu Shan",
          "Yupei Wang",
          "Xin Zhao",
          "Yinan Yu",
          "Ming Yang",
          "Kaiqi Huang"
        ],
        "url": "https://openaccess.thecvf.com/content_ICCV_2019/papers/Gao_SSAP_Single-Shot_Instance_Segmentation_With_Affinity_Pyramid_ICCV_2019_paper.pdf",
        "ref_texts": "[49] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017. 1,2",
        "ref_ids": [
          "49"
        ]
      },
      "Dabnet: Depth-wise asymmetric bottleneck for real-time semantic segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1907.11357",
        "ref_texts": "[33] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang W ang, and Jiaya Jia. Pyramid scene parsing network. 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , pages 6230\u20136239, 2017.",
        "ref_ids": [
          "33"
        ]
      },
      "RTFNet: RGB-thermal fusion network for semantic segmentation of urban scenes": {
        "authors": [],
        "url": "https://labsun.org/pub/RAL2019_rtfnet.pdf",
        "ref_texts": "[10] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proc. IEEE Conf. Comput. Vision P attern Recognit. , Jul. 2017, pp. 6230\u20136239.",
        "ref_ids": [
          "10"
        ]
      },
      "Co-occurrent features in semantic segmentation": {
        "authors": [
          "Hang Zhang",
          "Han Zhang",
          "Chenguang Wang",
          "Junyuan Xie"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPR_2019/papers/Zhang_Co-Occurrent_Features_in_Semantic_Segmentation_CVPR_2019_paper.pdf",
        "ref_texts": "[53] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2017. 1, 2,4,5,6,7,8",
        "ref_ids": [
          "53"
        ]
      },
      "Boundary-aware feature propagation for scene segmentation": {
        "authors": [
          "Henghui Ding",
          "Xudong Jiang",
          "Ai Qun",
          "Nadia Magnenat",
          "Gang Wang"
        ],
        "url": "https://openaccess.thecvf.com/content_ICCV_2019/papers/Ding_Boundary-Aware_Feature_Propagation_for_Scene_Segmentation_ICCV_2019_paper.pdf",
        "ref_texts": "[86] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2017.",
        "ref_ids": [
          "86"
        ]
      },
      "IDD: A dataset for exploring problems of autonomous navigation in unconstrained environments": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1811.10200",
        "ref_texts": "[27] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In CVPR , 2017.",
        "ref_ids": [
          "27"
        ]
      },
      "Attention-guided unified network for panoptic segmentation": {
        "authors": [
          "Yanwei Li",
          "Xinze Chen",
          "Zheng Zhu",
          "Lingxi Xie",
          "Guan Huang",
          "Dalong Du",
          "Xingang Wang"
        ],
        "url": "https://openaccess.thecvf.com/content_CVPR_2019/papers/Li_Attention-Guided_Unified_Network_for_Panoptic_Segmentation_CVPR_2019_paper.pdf",
        "ref_texts": "[45] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017. 1,2,3",
        "ref_ids": [
          "45"
        ]
      },
      "Learning depth with convolutional spatial propagation network": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1810.02695",
        "ref_texts": "[89] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in IEEE Conf. on Computer Vision and Pattern Recognition (CVPR) , 2017, pp. 2881\u20132890. 3, 5, 8",
        "ref_ids": [
          "89"
        ]
      },
      "Ai benchmark: All about deep learning on smartphones in 2019": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1910.06663",
        "ref_texts": "[91] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017. 11",
        "ref_ids": [
          "91"
        ]
      },
      "Zero-shot semantic segmentation": {
        "authors": [],
        "url": "https://proceedings.neurips.cc/paper/2019/file/0266e33d3f546cb5436a10798e657d97-Paper.pdf",
        "ref_texts": "[50] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017.",
        "ref_ids": [
          "50"
        ]
      },
      "Global-local temporal representations for video person re-identification": {
        "authors": [
          "Jianing Li",
          "Jingdong Wang",
          "Qi Tian",
          "Wen Gao",
          "Shiliang Zhang"
        ],
        "url": "http://openaccess.thecvf.com/content_ICCV_2019/papers/Li_Global-Local_Temporal_Representations_for_Video_Person_Re-Identification_ICCV_2019_paper.pdf",
        "ref_texts": "[54] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017.",
        "ref_ids": [
          "54"
        ]
      },
      "Fast interactive object annotation with curve-gcn": {
        "authors": [
          "Huan Ling",
          "Jun Gao",
          "Amlan Kar",
          "Wenzheng Chen",
          "Sanja Fidler"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPR_2019/papers/Ling_Fast_Interactive_Object_Annotation_With_Curve-GCN_CVPR_2019_paper.pdf",
        "ref_texts": "[37] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In CVPR , 2017.",
        "ref_ids": [
          "37"
        ]
      },
      "All about structure: Adapting structural information across domains for boosting semantic segmentation": {
        "authors": [
          "Lun Chang",
          "Po Wang",
          "Hsiao Peng",
          "Chen Chiu"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPR_2019/papers/Chang_All_About_Structure_Adapting_Structural_Information_Across_Domains_for_Boosting_CVPR_2019_paper.pdf",
        "ref_texts": "[28] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2017. 1, 7",
        "ref_ids": [
          "28"
        ]
      },
      "Integral object mining via online attention accumulation": {
        "authors": [
          "Tao Jiang",
          "Qibin Hou",
          "Yang Cao",
          "Ming Cheng",
          "Yunchao Wei",
          "Kai Xiong"
        ],
        "url": "https://openaccess.thecvf.com/content_ICCV_2019/papers/Jiang_Integral_Object_Mining_via_Online_Attention_Accumulation_ICCV_2019_paper.pdf",
        "ref_texts": "[42] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017. 1",
        "ref_ids": [
          "42"
        ]
      },
      "Constructing self-motivated pyramid curriculums for cross-domain semantic segmentation: A non-adversarial approach": {
        "authors": [
          "Qing Lian",
          "Fengmao Lv",
          "Lixin Duan",
          "Boqing Gong"
        ],
        "url": "http://openaccess.thecvf.com/content_ICCV_2019/papers/Lian_Constructing_Self-Motivated_Pyramid_Curriculums_for_Cross-Domain_Semantic_Segmentation_A_Non-Adversarial_ICCV_2019_paper.pdf",
        "ref_texts": "[41] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017. 1,2,6",
        "ref_ids": [
          "41"
        ]
      },
      "Hierarchical deep stereo matching on high-resolution images": {
        "authors": [
          "Gengshan Yang",
          "Joshua Manela",
          "Michael Happold",
          "Deva Ramanan"
        ],
        "url": "https://openaccess.thecvf.com/content_CVPR_2019/papers/Yang_Hierarchical_Deep_Stereo_Matching_on_High-Resolution_Images_CVPR_2019_paper.pdf",
        "ref_texts": "[41] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017. 3",
        "ref_ids": [
          "41"
        ]
      },
      "CS-Net: Channel and spatial attention network for curvilinear structure segmentation": {
        "authors": [],
        "url": "https://eprints.whiterose.ac.uk/160601/1/",
        "ref_texts": "18. Zhao, H., et al.: Pyramid scene parsing network. In: CVPR. pp . 2281\u20132890 (2017)",
        "ref_ids": [
          "18"
        ]
      },
      "Decoders matter for semantic segmentation: Data-dependent decoding enables flexible feature aggregation": {
        "authors": [
          "Zhi Tian",
          "Tong He",
          "Chunhua Shen",
          "Youliang Yan"
        ],
        "url": "https://openaccess.thecvf.com/content_CVPR_2019/papers/Tian_Decoders_Matter_for_Semantic_Segmentation_Data-Dependent_Decoding_Enables_Flexible_Feature_CVPR_2019_paper.pdf",
        "ref_texts": "[35] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proc. IEEE Conf. Comp. Vis. Patt. Recogn. , pages 2881\u2013",
        "ref_ids": [
          "35"
        ]
      },
      "Dual graph convolutional network for semantic segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1909.06121",
        "ref_texts": "[55] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In IEEE Conference on Computer Vision and Pattern Recognition , 2017.",
        "ref_ids": [
          "55"
        ]
      },
      "Learning semantic segmentation from synthetic data: A geometrically guided input-output adaptation approach": {
        "authors": [
          "Yuhua Chen",
          "Wen Li",
          "Xiaoran Chen",
          "Luc Van"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPR_2019/papers/Chen_Learning_Semantic_Segmentation_From_Synthetic_Data_A_Geometrically_Guided_Input-Output_CVPR_2019_paper.pdf",
        "ref_texts": "[59] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. CVPR , 2017. 2",
        "ref_ids": [
          "59"
        ]
      },
      "Knowledge adaptation for efficient semantic segmentation": {
        "authors": [
          "Tong He",
          "Chunhua Shen",
          "Zhi Tian",
          "Dong Gong",
          "Changming Sun",
          "Youliang Yan"
        ],
        "url": "https://openaccess.thecvf.com/content_CVPR_2019/papers/He_Knowledge_Adaptation_for_Efficient_Semantic_Segmentation_CVPR_2019_paper.pdf",
        "ref_texts": "[33] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid Scene Parsing Network. In Proc. IEEE Conf. Comp. Vis. Patt. Recogn. , 2017.",
        "ref_ids": [
          "33"
        ]
      },
      "-CNN: Fast Tiny Object Detection in Large-Scale Remote Sensing Images": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1902.06042",
        "ref_texts": "[28] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in IEEE Conf. on Computer Vision and Pattern Recognition (CVPR) , 2017, pp. 2881\u20132890. 3",
        "ref_ids": [
          "28"
        ]
      },
      "Weakly supervised instance segmentation using the bounding box tightness prior": {
        "authors": [
          "Chun Hsu",
          "Jui Hsu",
          "Chi Tsai",
          "Yu Lin",
          "Yu Chuang"
        ],
        "url": "https://proceedings.neurips.cc/paper_files/paper/2019/file/e6e713296627dff6475085cc6a224464-Paper.pdf",
        "ref_texts": "[30] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In CVPR , 2017.",
        "ref_ids": [
          "30"
        ]
      },
      "Ssf-dan: Separated semantic feature based domain adaptation network for semantic segmentation": {
        "authors": [
          "Liang Du",
          "Jingang Tan",
          "Hongye Yang",
          "Jianfeng Feng",
          "Xiangyang Xue",
          "Qibao Zheng",
          "Xiaoqing Ye",
          "Xiaolin Zhang"
        ],
        "url": "https://openaccess.thecvf.com/content_ICCV_2019/papers/Du_SSF-DAN_Separated_Semantic_Feature_Based_Domain_Adaptation_Network_for_Semantic_ICCV_2019_paper.pdf",
        "ref_texts": "[44] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "44"
        ]
      },
      "Adaptis: Adaptive instance selection network": {
        "authors": [
          "Konstantin Sofiiuk",
          "Olga Barinova",
          "Anton Konushin"
        ],
        "url": "https://openaccess.thecvf.com/content_ICCV_2019/papers/Sofiiuk_AdaptIS_Adaptive_Instance_Selection_Network_ICCV_2019_paper.pdf",
        "ref_texts": "[30] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017. 3",
        "ref_ids": [
          "30"
        ]
      },
      "Guided curriculum model adaptation and uncertainty-aware evaluation for semantic nighttime image segmentation": {
        "authors": [
          "Christos Sakaridis",
          "Dengxin Dai",
          "Luc Van"
        ],
        "url": "https://openaccess.thecvf.com/content_ICCV_2019/papers/Sakaridis_Guided_Curriculum_Model_Adaptation_and_Uncertainty-Aware_Evaluation_for_Semantic_Nighttime_ICCV_2019_paper.pdf",
        "ref_texts": "[44] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2017. 1",
        "ref_ids": [
          "44"
        ]
      },
      "Learning linear transformations for fast image and video style transfer": {
        "authors": [
          "Xueting Li",
          "Sifei Liu",
          "Jan Kautz",
          "Hsuan Yang"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPR_2019/papers/Li_Learning_Linear_Transformations_for_Fast_Image_and_Video_Style_Transfer_CVPR_2019_paper.pdf",
        "ref_texts": "[35] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In CVPR , 2017. 10,12",
        "ref_ids": [
          "35"
        ]
      },
      "Seamless scene segmentation": {
        "authors": [
          "Lorenzo Porzi",
          "Samuel Rota",
          "Aleksander Colovic",
          "Peter Kontschieder"
        ],
        "url": "https://openaccess.thecvf.com/content_CVPR_2019/papers/Porzi_Seamless_Scene_Segmentation_CVPR_2019_paper.pdf",
        "ref_texts": "[59] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. CoRR , abs/1612.01105, 2016. 2",
        "ref_ids": [
          "59"
        ]
      },
      "Dpsnet: End-to-end deep plane sweep stereo": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1905.00538",
        "ref_texts": "11 Published as a conference paper at ICLR 2019 Reza Mahjourian, Martin Wicke, and Anelia Angelova. Unsupervised learning of depth and egomotion from monocular video using 3d geometric constraints. In CVPR , 2018. Nikolaus Mayer, Eddy Ilg, Philip Hausser, Philipp Fischer, Daniel Cremers, Alexey Dosovitskiy, and Thomas Brox. A large dataset to train convolutional networks for disparity, optical flow, and scene flow estimation. In CVPR , 2016. Xing Mei, Xun Sun, Weiming Dong, Haitao Wang, and Xiaopeng Zhang. Segment-tree based cost aggregation for stereo matching. In CVPR , 2013. Christoph Rhemann, Asmaa Hosni, Michael Bleyer, Carsten Rother, and Margrit Gelautz. Fast cost-volume filtering for visual correspondence and beyond. In CVPR , 2011. Johannes L Sch \u00a8onberger, Enliang Zheng, Jan-Michael Frahm, and Marc Pollefeys. Pixelwise view selection for unstructured multi-view stereo. In ECCV , 2016. Johannes Lutz Sch \u00a8onberger and Jan-Michael Frahm. Structure-from-motion revisited. In CVPR , 2016. Jamie Shotton, Andrew Fitzgibbon, Mat Cook, Toby Sharp, Mark Finocchio, Richard Moore, Alex Kipman, and Andrew Blake. Real-time human pose recognition in parts from single depth images. InCVPR , 2011. Stepan Tulyakov, Anton Ivanov, and Francois Fleuret. Practical deep stereo (pds): Toward applications-friendly deep stereo matching. In NIPS , 2018. Benjamin Ummenhofer, Huizhong Zhou, Jonas Uhrig, Nikolaus Mayer, Eddy Ilg, Alexey Dosovitskiy, and Thomas Brox. Demon: Depth and motion network for learning monocular stereo. In CVPR , 2017. Chaoyang Wang, Jose Miguel Buenaposada, Rui Zhu, and Simon Lucey. Learning depth from monocular videos using direct methods. In CVPR , 2018. Pichao Wang, Wanqing Li, Zhimin Gao, Jing Zhang, Chang Tang, and Philip O Ogunbona. Action recognition from depth maps using deep convolutional neural networks. IEEE Trans. on Hum.Mac. Sys. , 2016. Ruigang Yang and Marc Pollefeys. Multi-resolution real-time stereo on commodity graphics hardware. In CVPR , 2003. Yao Yao, Zixin Luo, Shiwei Li, Tian Fang, and Long Quan. Mvsnet: Depth inference for unstructured multi-view stereo. ECCV , 2018. Zhichao Yin and Jianping Shi. Geonet: Unsupervised learning of dense depth, optical flow and camera pose. In CVPR , 2018. Fisher Yu and Vladlen Koltun. Multi-scale context aggregation by dilated convolutions. ICLR , 2016. Jure Zbontar and Yann LeCun. Stereo matching by training a convolutional neural network to compare image patches. J. of Machine Learning Research , 2016. Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017. Tinghui Zhou, Matthew Brown, Noah Snavely, and David G Lowe. Unsupervised learning of depth and ego-motion from video. In CVPR , 2017."
      },
      "Multi-task learning for segmentation of building footprints with deep neural networks": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1709.05932",
        "ref_texts": "[10] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d arXiv preprint arXiv:1612.01105 , 2016.",
        "ref_ids": [
          "10"
        ]
      },
      "Planercnn: 3d plane detection and reconstruction from a single image": {
        "authors": [
          "Chen Liu",
          "Kihwan Kim",
          "Jinwei Gu",
          "Yasutaka Furukawa",
          "Jan Kautz"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPR_2019/papers/Liu_PlaneRCNN_3D_Plane_Detection_and_Reconstruction_From_a_Single_Image_CVPR_2019_paper.pdf",
        "ref_texts": "[54] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In IEEE Conf. on Computer Vision and Pattern Recognition (CVPR) , pages 2881\u20132890, 2017. 2",
        "ref_ids": [
          "54"
        ]
      },
      "D-UNet: a dimension-fusion U shape network for chronic stroke lesion segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1908.05104",
        "ref_texts": "[39] Zhao H, Shi J, Qi X, et al. Pyramid scene parsing network[C]. Proceedings of the IEEE conference on computer vision and pattern recognition. 2017: 2881-2890.",
        "ref_ids": [
          "39",
          "C"
        ]
      },
      "Multi-source domain adaptation for semantic segmentation": {
        "authors": [
          "Sicheng Zhao",
          "Bo Li",
          "Xiangyu Yue",
          "Yang Gu",
          "Pengfei Xu",
          "Runbo Hu",
          "Hua Chai",
          "Kurt Keutzer"
        ],
        "url": "https://proceedings.neurips.cc/paper_files/paper/2019/file/db9ad56c71619aeed9723314d1456037-Paper.pdf",
        "ref_texts": "[11] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In IEEE Conference on Computer Vision and Pattern Recognition , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "11"
        ]
      },
      "Multi-view pointnet for 3d scene understanding": {
        "authors": [
          "Maximilian Jaritz",
          "Jiayuan Gu",
          "Hao Su"
        ],
        "url": "http://openaccess.thecvf.com/content_ICCVW_2019/papers/GMDL/Jaritz_Multi-View_PointNet_for_3D_Scene_Understanding_ICCVW_2019_paper.pdf",
        "ref_texts": "[29] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017. 3",
        "ref_ids": [
          "29"
        ]
      },
      "Self-guided network for fast image denoising": {
        "authors": [
          "Shuhang Gu",
          "Yawei Li",
          "Luc Van",
          "Radu Timofte"
        ],
        "url": "http://openaccess.thecvf.com/content_ICCV_2019/papers/Gu_Self-Guided_Network_for_Fast_Image_Denoising_ICCV_2019_paper.pdf",
        "ref_texts": "[48] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In IEEE Conf. on Computer Vision and Pattern Recognition (CVPR) , pages 2881\u20132890, 2017. 2,3",
        "ref_ids": [
          "48"
        ]
      },
      "Why can't i dance in the mall? learning to mitigate scene bias in action recognition": {
        "authors": [
          "Jinwoo Choi",
          "Chen Gao",
          "Joseph C. E",
          "Bin Huang"
        ],
        "url": "https://proceedings.neurips.cc/paper_files/paper/2019/file/ab817c9349cf9c4f6877e1894a1faa00-Paper.pdf",
        "ref_texts": "[69] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017. 3",
        "ref_ids": [
          "69"
        ]
      },
      "Interlaced sparse self-attention for semantic segmentation": {
        "authors": [],
        "url": "http://180.76.120.163/media/pdf/1907.12273.pdf",
        "ref_texts": "[60] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In CVPR , 2017. 5, 6, 8, 9",
        "ref_ids": [
          "60"
        ]
      },
      "Better to follow, follow to be better: Towards precise supervision of feature super-resolution for small object detection": {
        "authors": [
          "Junhyug Noh",
          "Wonho Bae",
          "Wonhee Lee",
          "Jinhwan Seo",
          "Gunhee Kim"
        ],
        "url": "http://openaccess.thecvf.com/content_ICCV_2019/papers/Noh_Better_to_Follow_Follow_to_Be_Better_Towards_Precise_Supervision_ICCV_2019_paper.pdf",
        "ref_texts": "[37] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid Scene Parsing Network. InCVPR , 2017.",
        "ref_ids": [
          "37"
        ]
      },
      "Prior-aware neural network for partially-supervised multi-organ segmentation": {
        "authors": [
          "Yuyin Zhou",
          "Zhe Li",
          "Song Bai",
          "Chong Wang",
          "Xinlei Chen",
          "Mei Han",
          "Elliot Fishman",
          "Alan L. Yuille"
        ],
        "url": "http://openaccess.thecvf.com/content_ICCV_2019/papers/Zhou_Prior-Aware_Neural_Network_for_Partially-Supervised_Multi-Organ_Segmentation_ICCV_2019_paper.pdf",
        "ref_texts": "[43] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017. 2",
        "ref_ids": [
          "43"
        ]
      },
      "Efficient dense modules of asymmetric convolution for real-time semantic segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1809.06323",
        "ref_texts": "[33] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. I n CVPR , 2017. ",
        "ref_ids": [
          "33"
        ]
      },
      "Weakly supervised adversarial domain adaptation for semantic segmentation in urban scenes": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1904.09092",
        "ref_texts": "[24] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in 2017 IEEE Conference on Computer Vision and Pattern Recognition , 2017, pp. 6230\u20136239.",
        "ref_ids": [
          "24"
        ]
      },
      "Deeperlab: Single-shot image parser": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1902.05093",
        "ref_texts": "[36] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in CVPR , 2017. 2, 6",
        "ref_ids": [
          "36"
        ]
      },
      "Drivingstereo: A large-scale dataset for stereo matching in autonomous driving scenarios": {
        "authors": [
          "Guorun Yang",
          "Xiao Song",
          "Chaoqin Huang",
          "Zhidong Deng",
          "Jianping Shi",
          "Bolei Zhou"
        ],
        "url": "https://openaccess.thecvf.com/content_CVPR_2019/papers/Yang_DrivingStereo_A_Large-Scale_Dataset_for_Stereo_Matching_in_Autonomous_Driving_CVPR_2019_paper.pdf",
        "ref_texts": "[35] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017. 3,5",
        "ref_ids": [
          "35"
        ]
      },
      "Semantic correlation promoted shape-variant context for segmentation": {
        "authors": [
          "Henghui Ding",
          "Xudong Jiang",
          "Bing Shuai",
          "Ai Qun",
          "Gang Wang"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPR_2019/papers/Ding_Semantic_Correlation_Promoted_Shape-Variant_Context_for_Segmentation_CVPR_2019_paper.pdf",
        "ref_texts": "[75] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017.",
        "ref_ids": [
          "75"
        ]
      },
      "Adaptive context network for scene parsing": {
        "authors": [
          "Jun Fu",
          "Jing Liu",
          "Yuhang Wang",
          "Yong Li",
          "Yongjun Bao",
          "Jinhui Tang",
          "Hanqing Lu"
        ],
        "url": "http://openaccess.thecvf.com/content_ICCV_2019/papers/Fu_Adaptive_Context_Network_for_Scene_Parsing_ICCV_2019_paper.pdf",
        "ref_texts": "[40] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In IEEE Conference on Computer Vision and Pattern Recognition, pages 6230\u20136239, 2017.",
        "ref_ids": [
          "40"
        ]
      },
      "Horizonnet: Learning room layout with 1d representation and pano stretch data augmentation": {
        "authors": [
          "Cheng Sun",
          "Wei Hsiao",
          "Min Sun",
          "Tzong Chen"
        ],
        "url": "https://openaccess.thecvf.com/content_CVPR_2019/papers/Sun_HorizonNet_Learning_Room_Layout_With_1D_Representation_and_Pano_Stretch_CVPR_2019_paper.pdf",
        "ref_texts": ""
      },
      "A relation-augmented fully convolutional network for semantic segmentation in aerial scenes": {
        "authors": [
          "Lichao Mou",
          "Yuansheng Hua",
          "Xiao Xiang"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPR_2019/papers/Mou_A_Relation-Augmented_Fully_Convolutional_Network_for_Semantic_Segmentation_in_Aerial_CVPR_2019_paper.pdf",
        "ref_texts": "[40] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In IEEE International Conference on Computer Vision and Pattern Recognition (CVPR) , 2017.",
        "ref_ids": [
          "40"
        ]
      },
      "Stacked deconvolutional network for semantic segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1708.04943",
        "ref_texts": "[15] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d CVPR , 2017.",
        "ref_ids": [
          "15"
        ]
      },
      "Panopticfusion: Online volumetric semantic mapping at the level of stuff and things": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1903.01177",
        "ref_texts": "[36] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In IEEE Conf. on Computer Vision and Pattern Recognition (CVPR) , 2017.",
        "ref_ids": [
          "36"
        ]
      },
      "Amodal instance segmentation with kins dataset": {
        "authors": [
          "Lu Qi",
          "Li Jiang",
          "Shu Liu",
          "Xiaoyong Shen",
          "Jiaya Jia"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPR_2019/papers/Qi_Amodal_Instance_Segmentation_With_KINS_Dataset_CVPR_2019_paper.pdf",
        "ref_texts": "[41] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017. 1",
        "ref_ids": [
          "41"
        ]
      },
      "Progressive lidar adaptation for road detection": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1904.01206",
        "ref_texts": "[42] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in IEEE Conf. on Computer Vision and Pattern Recognition (CVPR) , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "42"
        ]
      },
      "Cloud and cloud shadow detection in Landsat imagery based on deep convolutional neural networks": {
        "authors": [
          "Dengfeng Chai"
        ],
        "url": "http://faculty.ucmerced.edu/snewsam/papers/Chai_RSE19_CloudAndCloudShadow.pdf",
        "ref_texts": "Achanta, R., Shaji, A., Smith, K., Lucchi, A., Fua, P., S\u00fcsstrunk, S., et al., 2012. Slic superpixels compared to state-of-the-art superpixel methods. IEEE Trans. Pattern Anal. Mach. Intell. 34 (11), 2274 \u20132282 . Amato, U., Antoniadis, A., Cuomo, V., Cutillo, L., Franzese, M., Murino, L., Serio, C., 2008. Statistical cloud detection from seviri multispectral images. Remote Sens. Environ. 112 (3), 750 \u2013766. Badrinarayanan, V., Kendall, A., Cipolla, R., 2017. Segnet: a deep convolutional encoderdecoder architecture for image segmentation. IEEE Trans. Pattern Anal. Mach. Intell.39 (12), 2481 \u20132495 . Chen, L.-C., Papandreou, G., Kokkinos, I., Murphy, K., Yuille, A.L., 2018. Deeplab: semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected CRFs. IEEE Trans. Pattern Anal. Mach. Intell. 40 (4), 834 \u2013848. Drusch, M., Del Bello, U., Carlier, S., Colin, O., Fernandez, V., Gascon, F., Hoersch, B., Isola, C., Laberinti, P., Martimort, P., et al., 2012. Sentinel-2: ESA's optical high-resolution mission for GMES operational services. Remote Sens. Environ. 120, 25 \u201336. Foga, S., Scaramuzza, P.L., Guo, S., Zhu, Z., Dilley, R.D., Beckmann, T., Schmidt, G.L., Dwyer, J.L., Hughes, M.J., Laue, B., 2017. Cloud detection algorithm comparison and validation for operational Landsat data products. Remote Sens. Environ. 194, 379\u2013390. Frantz, D., R\u00f6der, A., Udelhoven, T., Schmidt, M., 2015. Enhancing the detectability of clouds and their shadows in multitemporal dryland Landsat imagery: extendingFmask. IEEE Geosci. Remote Sens. Lett. 12 (6), 1242 \u20131246 . Girshick, R., Donahue, J., Darrell, T., Malik, J., 2014. Rich feature hierarchies for accurate object detection and semantic segmentation. In: Proceedings of the IEEE Conferenceon Computer Vision and Pattern Recognition, pp. 580 \u2013587. Goodfellow, I., Bengio, Y., Courville, A., 2016. Deep Learning. MIT Press . Hagolle, O., Huc, M., Pascual, D.V., Dedieu, G., 2010. A multi-temporal method for cloud detection, applied to Formosat-2, Ven \u03bcs, Landsat and Sentinel-2 images. Remote Sens. Environ. 114 (8), 1747 \u20131755 . Hollingsworth, B.V., Chen, L., Reichenbach, S.E., Irish, R.R., 1996. Automated cloud cover assessment for Landsat TM images. In: Imaging Spectrometry II. vol. 2819. pp.170\u2013180. Hughes, M.J., Hayes, D.J., 2014. Automated detection of cloud and cloud shadow in single-date Landsat imagery using neural networks and spatial post-processing. Remote Sens. 6 (6), 4907 \u20134926 .Irish, R.R., Barker, J.L., Goward, S.N., Arvidson, T., 2006. Characterization of the Landsat-7 ETM+ automated cloud-cover assessment (ACCA) algorithm. Photogramm. Eng. Remote Sens. 72 (10), 1179 \u20131188 . Jin, S., Homer, C., Yang, L., Xian, G., Fry, J., Danielson, P., Townsend, P.A., 2013. Automated cloud and shadow detection and filling using two-date Landsat imagery in the USA. Int. J. Remote Sens. 34 (5), 1540 \u20131560 . Ju, J., Roy, D.P., 2008. The availability of cloud-free Landsat ETM+ data over the conterminous United States and globally. Remote Sens. Environ. 112 (3), 1196 \u20131211 . Kovalskyy, V., Roy, D.P., 2015. A one year Landsat 8 conterminous United States study of cirrus and non-cirrus clouds. Remote Sens. 7 (1), 564 \u2013578. LeCun, Y., Bottou, L., Bengio, Y., Ha ffner, P., 1998a. Gradient-based learning applied to document recognition. Proc. IEEE 86 (11), 2278 \u20132324 . LeCun, Y., Bottou, L., Orr, G.B., M\u00fcller, K.-R., 1998b. E fficient backprop. In: Neural Networks: Tricks of the Trade. Springer, pp. 9 \u201350. Lee, J., Weger, R.C., Sengupta, S.K., Welch, R.M., 1990. A neural network approach to cloud classi fication. IEEE Trans. Geosci. Remote Sens. 28 (5), 846 \u2013855. Lee, Y., Wahba, G., Ackerman, S.A., 2004. Cloud classi fication of satellite radiance data by multicategory support vector machines. J. Atmos. Ocean. Technol. 21 (2),159\u2013169. Long, J., Shelhamer, E., Darrell, T., 2015. Fully convolutional networks for semantic segmentation. In: Proceedings of the IEEE Conference on Computer Vision andPattern Recognition, pp. 3431 \u20133440 . Molnar, G., Coakley Jr, J., 1985. Retrieval of cloud cover from satellite imagery data: a statistical approach. J. Geophys. Res. Atmos. 90 (D7), 12960 \u201312970 . Qiu, S., He, B., Zhu, Z., Liao, Z., Quan, X., 2017. Improving Fmask cloud and cloud shadow detection in mountainous area for Landsats 4 \u20138 images. Remote Sens. Environ. 199, 107 \u2013119. Ren, S., He, K., Girshick, R., Sun, J., 2015. Faster R-CNN: towards real-time object detection with region proposal networks. In: Advances in Neural Information Processing Systems, pp. 91 \u201399. Ricciardelli, E., Romano, F., Cuomo, V., 2008. Physical and statistical approaches for cloud identi fication using meteosat second generation-spinning enhanced visible and infrared imager data. Remote Sens. Environ. 112 (6), 2741 \u20132760 . Roy, D.P., Ju, J., Kline, K., Scaramuzza, P.L., Kovalskyy, V., Hansen, M., Loveland, T.R., Vermote, E., Zhang, C., 2010. Web-enabled Landsat data (WELD): Landsat ETM+ composited mosaics of the conterminous United States. Remote Sens. Environ. 114(1), 35 \u201349. Roy, D.P., Wulder, M., Loveland, T.R., Woodcock, C., Allen, R., Anderson, M., Helder, D., Irons, J., Johnson, D., Kennedy, R., et al., 2014. Landsat-8: science and product vision for terrestrial global change research. Remote Sens. Environ. 145, 154 \u2013172. Scaramuzza, P.L., Bouchard, M.A., Dwyer, J.L., 2012. Development of the Landsat data continuity mission cloud-cover assessment algorithms. IEEE Trans. Geosci. RemoteSens. 50 (4), 1140 \u20131154 . Simonyan, K., Zisserman, A., 2014. Very Deep Convolutional Networks for Large-scale Image Recognition. arXiv preprint. https://arXiv:1409.1556 . Srivastava, N., Hinton, G., Krizhevsky, A., Sutskever, I., Salakhutdinov, R., 2014. Dropout: a simple way to prevent neural networks from over fitting. J. Mach. Learn. Res. 15 (1), 1929\u20131958 . Sun, L., Liu, X., Yang, Y., Chen, T., Wang, Q., Zhou, X., 2018. A cloud shadow detection method combined with cloud height iteration and spectral analysis for Landsat 8 OLI data. ISPRS J. Photogramm. Remote Sens. 138, 193 \u2013207. Tian, B., Shaikh, M.A., Azimi-Sadjadi, M.R., Haar, T.H.V., Reinke, D.L., 1999. A study of cloud classi fication with neural networks using spectral and textural features. IEEE Trans. Neural Netw. 10 (1), 138 \u2013151. Tieleman, T., Hinton, G., 2012. Lecture 6.5-rmsprop: divide the gradient by a running average of its recent magnitude. COURSERA Neural Netw. Mach. Learn. 4 (2), 26 \u201331. Vermote, E., Justice, C., Claverie, M., Franch, B., 2016. Preliminary analysis of the performance of the Landsat 8/OLI land surface re flectance product. Remote Sens. Environ. 185, 46 \u201356. Wang, B., Ono, A., Muramatsu, K., Fujiwara, N., 1999. Automated detection and removal of clouds and their shadows from Landsat TM images. IEICE Trans. Inf. Syst. 82 (2), 453\u2013460. Wulder, M.A., White, J.C., Loveland, T.R., Woodcock, C.E., Belward, A.S., Cohen, W.B., Fosnight, E.A., Shaw, J., Masek, J.G., Roy, D.P., 2016. The global Landsat archive: status, consolidation, and direction. Remote Sens. Environ. 185, 271 \u2013283. Xie, F., Shi, M., Shi, Z., Yin, J., Zhao, D., 2017. Multilevel cloud detection in remote sensing images based on deep learning. IEEE J. Sel. Top. Appl. Earth Obs. RemoteSens. 10 (8), 3631 \u20133640 . Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J., 2017. Pyramid scene parsing network. In: IEEE Conf. on Computer Vision and Pattern Recognition (CVPR), pp. 2881 \u20132890 . Zhu, X., Helmer, E.H., 2018. An automatic method for screening clouds and cloud shadows in optical satellite image time series in cloudy regions. Remote Sens. Environ.214, 135 \u2013153. Zhu, Z., Woodcock, C.E., 2012. Object-based cloud and cloud shadow detection in Landsat imagery. Remote Sens. Environ. 118, 83 \u201394. Zhu, Z., Woodcock, C.E., 2014. Automated cloud, cloud shadow, and snow detection in multitemporal Landsat data: an algorithm designed speci fically for monitoring land cover change. Remote Sens. Environ. 152, 217 \u2013234. Zi, Y., Xie, F., Jiang, Z., 2018. A cloud detection method for Landsat 8 images based on PCANet. Remote Sens. 10 (6), 877 .D. Chai, et al. Remote Sensing of Environment 225 (2019) 307\u2013316"
      },
      "Chainer: A deep learning framework for accelerating the research cycle": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1908.00213",
        "ref_texts": "[22] Xiaojuan Qi Xiaogang Wang Jiaya Jia Hengshuang Zhao, Jianping Shi. 2017. Pyramid Scene Parsing Network. CVPR (2017).",
        "ref_ids": [
          "22"
        ]
      },
      "Unsupervised scene adaptation with memory regularization in vivo": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1912.11164",
        "ref_texts": "[Zhao et al. , 2017 ]Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. InCVPR , 2017.",
        "ref_ids": [
          "Zhao et al\\. , 2017 "
        ]
      },
      "Partial order pruning: for best speed/accuracy trade-off in neural architecture search": {
        "authors": [
          "Xin Li",
          "Yiming Zhou",
          "Zheng Pan",
          "Jiashi Feng"
        ],
        "url": "https://openaccess.thecvf.com/content_CVPR_2019/papers/Li_Partial_Order_Pruning_For_Best_SpeedAccuracy_Trade-Off_in_Neural_Architecture_CVPR_2019_paper.pdf",
        "ref_texts": "[34] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. CVPR , 2017. 1,2,5",
        "ref_ids": [
          "34"
        ]
      },
      "An end-to-end network for panoptic segmentation": {
        "authors": [
          "Huanyu Liu",
          "Chao Peng",
          "Changqian Yu",
          "Jingbo Wang",
          "Xu Liu",
          "Gang Yu",
          "Wei Jiang"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPR_2019/papers/Liu_An_End-To-End_Network_for_Panoptic_Segmentation_CVPR_2019_paper.pdf",
        "ref_texts": "[48] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In CVPR , 2017.",
        "ref_ids": [
          "48"
        ]
      },
      "Deep learning with microfluidics for biotechnology": {
        "authors": [
          "Mariya Maistrovskaya"
        ],
        "url": "https://tspace.library.utoronto.ca/bitstream/1807/90805/1/Deep%20Learning%20with_TSpace.pdf",
        "ref_texts": "81 Zhao, H. et al. (2017) , Pyramid Scene Parsing Network. , in 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , pp. 6230 \u20136239 "
      },
      "X-net: Brain stroke lesion segmentation based on depthwise separable convolution and long-range dependencies": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1907.07000",
        "ref_texts": "8. Zhao H., Shi J., Qi X., et al.: Pyramid scene parsing network. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. pp. 2881{2890",
        "ref_ids": [
          "8"
        ]
      },
      "The h3d dataset for full-surround 3d multi-object detection and tracking in crowded urban scenes": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1903.01568",
        "ref_texts": "[4] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in CVPR , 2017.",
        "ref_ids": [
          "4"
        ]
      },
      "Single image reflection removal exploiting misaligned training data and network enhancements": {
        "authors": [
          "Kaixuan Wei",
          "Jiaolong Yang",
          "Ying Fu",
          "David Wipf",
          "Hua Huang"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPR_2019/papers/Wei_Single_Image_Reflection_Removal_Exploiting_Misaligned_Training_Data_and_Network_CVPR_2019_paper.pdf",
        "ref_texts": "[47] X. Zhang, R. Ng, and Q. Chen. Single image reflection separation with perceptual losses. In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , June 2018.[48] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , July 2017.",
        "ref_ids": [
          "47",
          "48"
        ]
      },
      "Semantic projection network for zero-and few-label semantic segmentation": {
        "authors": [
          "Yongqin Xian",
          "Subhabrata Choudhury",
          "Yang He",
          "Bernt Schiele",
          "Zeynep Akata"
        ],
        "url": "https://openaccess.thecvf.com/content_CVPR_2019/papers/Xian_Semantic_Projection_Network_for_Zero-_and_Few-Label_Semantic_Segmentation_CVPR_2019_paper.pdf",
        "ref_texts": "[59] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In CVPR , 2017. 2",
        "ref_ids": [
          "59"
        ]
      },
      "Direction-aware spatial context features for shadow detection and removal": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1805.04635",
        "ref_texts": "[60] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in IEEE Conference on Computer Vision and Pattern Recognition , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "60"
        ]
      },
      "Temporal and spatial deep learning network for infrared thermal defect detection": {
        "authors": [],
        "url": "https://nrl.northumbria.ac.uk/id/eprint/41092/1/Temporal%20Spatial%20Deep%20Learning%20Infrared%20Thermal%20Detection_author%20version.pdf",
        "ref_texts": "[37] Zhao H, Shi J, Qi X, et al. Pyramid scene parsing network[C]//IEEE Conf. on Computer Vision and Pattern Recognition (CVPR). 2017: 2881 -2890. ",
        "ref_ids": [
          "37",
          "C"
        ]
      },
      "Fast neural architecture search of compact semantic segmentation models via auxiliary cells": {
        "authors": [
          "Vladimir Nekrasov",
          "Hao Chen",
          "Chunhua Shen",
          "Ian Reid"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPR_2019/papers/Nekrasov_Fast_Neural_Architecture_Search_of_Compact_Semantic_Segmentation_Models_via_CVPR_2019_paper.pdf",
        "ref_texts": "[46] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In Proc. IEEE Conf. Comp. Vis. Patt. Recogn. , 2017.",
        "ref_ids": [
          "46"
        ]
      },
      "Segsort: Segmentation by discriminative sorting of segments": {
        "authors": [
          "Jing Hwang",
          "Stella X. Yu",
          "Jianbo Shi",
          "Maxwell D. Collins",
          "Ju Yang",
          "Xiao Zhang",
          "Chieh Chen"
        ],
        "url": "http://openaccess.thecvf.com/content_ICCV_2019/papers/Hwang_SegSort_Segmentation_by_Discriminative_Sorting_of_Segments_ICCV_2019_paper.pdf",
        "ref_texts": "[80] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017.",
        "ref_ids": [
          "80"
        ]
      },
      "Lip: Local importance-based pooling": {
        "authors": [
          "Ziteng Gao",
          "Limin Wang",
          "Gangshan Wu"
        ],
        "url": "http://openaccess.thecvf.com/content_ICCV_2019/papers/Gao_LIP_Local_Importance-Based_Pooling_ICCV_2019_paper.pdf",
        "ref_texts": ""
      },
      "Dense dilated network with probability regularized walk for vessel detection": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1910.12010",
        "ref_texts": "[41] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2017, pp. 6230\u20136239.",
        "ref_ids": [
          "41"
        ]
      },
      "Collaborative global-local networks for memory-efficient segmentation of ultra-high resolution images": {
        "authors": [
          "Wuyang Chen",
          "Ziyu Jiang",
          "Zhangyang Wang",
          "Kexin Cui",
          "Xiaoning Qian"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPR_2019/papers/Chen_Collaborative_Global-Local_Networks_for_Memory-Efficient_Segmentation_of_Ultra-High_Resolution_Images_CVPR_2019_paper.pdf",
        "ref_texts": "[7] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In IEEE Conf. on Computer Vision and Pattern Recognition (CVPR) , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "7"
        ]
      },
      "Deep learning segmentation of major vessels in X-ray coronary angiography": {
        "authors": [],
        "url": "https://www.nature.com/articles/s41598-019-53254-7.pdf",
        "ref_texts": ""
      },
      "Customizable architecture search for semantic segmentation": {
        "authors": [
          "Yiheng Zhang",
          "Zhaofan Qiu",
          "Jingen Liu",
          "Ting Yao",
          "Dong Liu",
          "Tao Mei"
        ],
        "url": "https://openaccess.thecvf.com/content_CVPR_2019/papers/Zhang_Customizable_Architecture_Search_for_Semantic_Segmentation_CVPR_2019_paper.pdf",
        "ref_texts": "[37] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017.",
        "ref_ids": [
          "37"
        ]
      },
      "Detecting the unexpected via image resynthesis": {
        "authors": [
          "Krzysztof Lis",
          "Krishna Nakka",
          "Pascal Fua",
          "Mathieu Salzmann"
        ],
        "url": "https://openaccess.thecvf.com/content_ICCV_2019/papers/Lis_Detecting_the_Unexpected_via_Image_Resynthesis_ICCV_2019_paper.pdf",
        "ref_texts": "[43] Fisher Yu, Wenqi Xian, Yingying Chen, Fangchen Liu, Mike Liao, Vashisht Madhavan, and Trevor Darrell. BDD100K: A Diverse Driving Video Database with Scalable Annotation Tooling. arXiv Preprint , 2018.[44] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid Scene Parsing Network. In Conference on Computer Vision and Pattern Recognition , 2017.",
        "ref_ids": [
          "43",
          "44"
        ]
      },
      "Edgestereo: A context integrated residual pyramid network for stereo matching": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1803.05196",
        "ref_texts": "28. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: CVPR. (2017) 2881{2890",
        "ref_ids": [
          "28"
        ]
      },
      "Learning compositional neural information fusion for human parsing": {
        "authors": [
          "Wenguan Wang",
          "Zhijie Zhang",
          "Siyuan Qi",
          "Jianbing Shen",
          "Yanwei Pang",
          "Ling Shao"
        ],
        "url": "https://openaccess.thecvf.com/content_ICCV_2019/papers/Wang_Learning_Compositional_Neural_Information_Fusion_for_Human_Parsing_ICCV_2019_paper.pdf",
        "ref_texts": "[76] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017. 6,7",
        "ref_ids": [
          "76"
        ]
      },
      "Adversarially robust generalization just requires more unlabeled data": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1906.00555",
        "ref_texts": "9781108627771. Limin Wang, Yuanjun Xiong, Zhe Wang, Yu Qiao, Dahua Lin, Xiao ou Tang, and Luc Van Gool. Temporal segment networks: Towards good practices for deep action recognition. In European Conference on Computer Vision , pp. 20\u201336. Springer, 2016. Xiaolong Wang, Ross Girshick, Abhinav Gupta, and Kaiming He . Non-local neural networks. In The IEEE Conference on Computer Vision and Pattern Recognit ion (CVPR) , volume 1(3), pp. 4, 2018. Yisen Wang, Xingjun Ma, James Bailey, Jinfeng Yi, Bowen Zhou , and Quanquan Gu. On the convergence and robustness of adversarial training. In Kam alika Chaudhuri and Ruslan Salakhutdinov (eds.), Proceedings of the 36th International Conference on Machin e Learning , volume 97 ofProceedings of Machine Learning Research , pp. 6586\u20136595, Long Beach, California, USA, 09\u201315 Jun 2019. PMLR. Bing Zhang and Mingguang Shi. Semi-supervised learning imp roves gene expression-based prediction of cancer recurrence. Bioinformatics , 27(21):3017\u20133023, 09 2011. ISSN 1367-4803. doi: 10.1093/bioinformatics/btr502. Dinghuai Zhang, Tianyuan Zhang, Yiping Lu, Zhanxing Zhu, an d Bin Dong. You only propagate once: Painless adversarial training using maximal princip le.arXiv preprint arXiv:1905.00877 , 2019a. Hongyang Zhang, Yaodong Yu, Jiantao Jiao, Eric Xing, Lauren t El Ghaoui, and Michael Jordan. Theoretically principled trade-off between robustness an d accuracy. In Kamalika Chaudhuri and Ruslan Salakhutdinov (eds.), Proceedings of the 36th International Conference on Machin e Learning , volume 97 of Proceedings of Machine Learning Research , pp. 7472\u20137482, Long Beach, California, USA, 09\u201315 Jun 2019b. PMLR. Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In IEEE Conf. on Computer Vision and Pattern Recognition (CVPR ), pp. 2881\u20132890, 2017.",
        "ref_ids": [
          "9781108627771"
        ]
      },
      "Region mutual information loss for semantic segmentation": {
        "authors": [
          "Shuai Zhao",
          "Yang Wang",
          "Zheng Yang",
          "Deng Cai"
        ],
        "url": "https://proceedings.neurips.cc/paper/2019/file/a67c8c9a961b4182688768dd9ba015fe-Paper.pdf",
        "ref_texts": "[40] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017.",
        "ref_ids": [
          "40"
        ]
      },
      "Hms-net: Hierarchical multi-scale sparsity-invariant network for sparse depth completion": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1808.08685",
        "ref_texts": "[43] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d IEEE Conference on Computer Vision and Pattern Recognition , pp. 2881\u20132890, 2017.",
        "ref_ids": [
          "43"
        ]
      },
      "Spgnet: Semantic prediction guidance for scene parsing": {
        "authors": [
          "Bowen Cheng",
          "Chieh Chen",
          "Yunchao Wei",
          "Yukun Zhu",
          "Zilong Huang",
          "Jinjun Xiong",
          "Thomas S. Huang",
          "Mei Hwu",
          "Honghui Shi"
        ],
        "url": "https://openaccess.thecvf.com/content_ICCV_2019/papers/Cheng_SPGNet_Semantic_Prediction_Guidance_for_Scene_Parsing_ICCV_2019_paper.pdf",
        "ref_texts": "[73] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017.",
        "ref_ids": [
          "73"
        ]
      },
      "Towards bridging semantic gap to improve semantic segmentation": {
        "authors": [
          "Yanwei Pang",
          "Yazhao Li",
          "Jianbing Shen",
          "Ling Shao"
        ],
        "url": "http://openaccess.thecvf.com/content_ICCV_2019/papers/Pang_Towards_Bridging_Semantic_Gap_to_Improve_Semantic_Segmentation_ICCV_2019_paper.pdf",
        "ref_texts": "[60] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017. 2,6,7",
        "ref_ids": [
          "60"
        ]
      },
      "Representation similarity analysis for efficient task taxonomy & transfer learning": {
        "authors": [
          "Kshitij Dwivedi",
          "Gemma Roig"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPR_2019/papers/Dwivedi_Representation_Similarity_Analysis_for_Efficient_Task_Taxonomy__Transfer_Learning_CVPR_2019_paper.pdf",
        "ref_texts": "[35] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2017.",
        "ref_ids": [
          "35"
        ]
      },
      "Exploiting sparse semantic HD maps for self-driving vehicle localization": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1908.03274.pdf?utm_medium=referral&utm_medium=referral&utm_source=contentstudio.io&utm_source=contentstudio.io",
        "ref_texts": "[43] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In CVPR , 2017.",
        "ref_ids": [
          "43"
        ]
      },
      "Physics-based rendering for improving robustness to rain": {
        "authors": [
          "Shirsendu Sukanta",
          "Francois Lalonde"
        ],
        "url": "http://openaccess.thecvf.com/content_ICCV_2019/papers/Halder_Physics-Based_Rendering_for_Improving_Robustness_to_Rain_ICCV_2019_paper.pdf",
        "ref_texts": "[58] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In IEEE Conference on Computer Vision and Pattern Recognition, 2017. 6,7,8",
        "ref_ids": [
          "58"
        ]
      },
      "Semantic stereo matching with pyramid cost volumes": {
        "authors": [
          "Zhenyao Wu",
          "Xinyi Wu",
          "Xiaoping Zhang",
          "Song Wang",
          "Lili Ju"
        ],
        "url": "https://openaccess.thecvf.com/content_ICCV_2019/papers/Wu_Semantic_Stereo_Matching_With_Pyramid_Cost_Volumes_ICCV_2019_paper.pdf",
        "ref_texts": "[44] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , July 2017.",
        "ref_ids": [
          "44"
        ]
      },
      "Semantic stereo for incidental satellite images": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1811.08739",
        "ref_texts": "[45] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid Scene Parsing Network . In CVPR, 2017. ",
        "ref_ids": [
          "45"
        ]
      },
      "Unsupervised object segmentation by redrawing": {
        "authors": [],
        "url": "https://proceedings.neurips.cc/paper/2019/file/32bbf7b2bc4ed14eb1e9c2580056a989-Paper.pdf",
        "ref_texts": "[58] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "58"
        ]
      },
      "Accel: A corrective fusion network for efficient semantic segmentation on video": {
        "authors": [
          "Samvit Jain",
          "Xin Wang",
          "Joseph E. Gonzalez"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPR_2019/papers/Jain_Accel_A_Corrective_Fusion_Network_for_Efficient_Semantic_Segmentation_on_CVPR_2019_paper.pdf",
        "ref_texts": "[43] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In CVPR , 2017. 6",
        "ref_ids": [
          "43"
        ]
      },
      "Uncovering ecological patterns with convolutional neural networks": {
        "authors": [],
        "url": "https://calslab.snu.ac.kr/treephys/download/313/menu/1412/49/1/PIIS0169534719300862.pdf",
        "ref_texts": "68. Zhao, H. et al. (2017) Pyramid scene parsing network. In IEEE Conference on Computer Vision and Pattern Recognition , pp. 2881 \u20132890, IEEE",
        "ref_ids": [
          "68"
        ]
      },
      "Inverserendernet: Learning single image inverse rendering": {
        "authors": [
          "Ye Yu",
          "William A. P"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPR_2019/papers/Yu_InverseRenderNet_Learning_Single_Image_Inverse_Rendering_CVPR_2019_paper.pdf",
        "ref_texts": "[52] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In IEEE Conf. on Computer Vision and Pattern Recognition (CVPR) , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "52"
        ]
      },
      "Deep floor plan recognition using a multi-task network with room-boundary-guided attention": {
        "authors": [
          "Zhiliang Zeng",
          "Xianzhi Li",
          "Ying Kin",
          "Wing Fu"
        ],
        "url": "http://openaccess.thecvf.com/content_ICCV_2019/papers/Zeng_Deep_Floor_Plan_Recognition_Using_a_Multi-Task_Network_With_Room-Boundary-Guided_ICCV_2019_paper.pdf",
        "ref_texts": "[23] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2017. 6,7",
        "ref_ids": [
          "23"
        ]
      },
      "Fully convolutional network for rice seedling and weed image segmentation at the seedling stage in paddy fields": {
        "authors": [
          "Xu Ma",
          "Xiangwu Deng",
          "Long Qi",
          "Yu Jiang",
          "Hongwei Li",
          "Yuwei Wang",
          "Xupo Xing"
        ],
        "url": "https://journals.plos.org/plosone/article/file?id=10.1371/journal.pone.0215676&type=printable",
        "ref_texts": ""
      },
      "Deep rigid instance scene flow": {
        "authors": [
          "Chiu Ma",
          "Shenlong Wang",
          "Rui Hu",
          "Yuwen Xiong",
          "Raquel Urtasun"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPR_2019/papers/Ma_Deep_Rigid_Instance_Scene_Flow_CVPR_2019_paper.pdf",
        "ref_texts": "[48] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017. 2,3",
        "ref_ids": [
          "48"
        ]
      },
      "Adaptive weighting multi-field-of-view CNN for semantic segmentation in pathology": {
        "authors": [
          "Hiroki Tokunaga",
          "Yuki Teramoto",
          "Akihiko Yoshizawa",
          "Ryoma Bise"
        ],
        "url": "https://openaccess.thecvf.com/content_CVPR_2019/papers/Tokunaga_Adaptive_Weighting_Multi-Field-Of-View_CNN_for_Semantic_Segmentation_in_Pathology_CVPR_2019_paper.pdf",
        "ref_texts": "[47] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In CVPR , 2017. 2",
        "ref_ids": [
          "47"
        ]
      },
      "Switchable whitening for deep representation learning": {
        "authors": [
          "Xingang Pan",
          "Xiaohang Zhan",
          "Jianping Shi",
          "Xiaoou Tang",
          "Ping Luo"
        ],
        "url": "https://openaccess.thecvf.com/content_ICCV_2019/papers/Pan_Switchable_Whitening_for_Deep_Representation_Learning_ICCV_2019_paper.pdf",
        "ref_texts": "[33] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. CVPR , 2017. 6",
        "ref_ids": [
          "33"
        ]
      },
      "Shelfnet for fast semantic segmentation": {
        "authors": [
          "Juntang Zhuang",
          "Junlin Yang",
          "Lin Gu",
          "Nicha Dvornek"
        ],
        "url": "http://openaccess.thecvf.com/content_ICCVW_2019/papers/CVRSUAD/Zhuang_ShelfNet_for_Fast_Semantic_Segmentation_ICCVW_2019_paper.pdf",
        "ref_texts": "[44] H. Zhao et al. Pyramid scene parsing network. In (CVPR) , 2017. 1,2,6,7,8",
        "ref_ids": [
          "44"
        ]
      },
      "EV-SegNet: Semantic segmentation for event-based cameras": {
        "authors": [
          "Inigo Alonso",
          "Ana C. Murillo"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPRW_2019/papers/EventVision/Alonso_EV-SegNet_Semantic_Segmentation_for_Event-Based_Cameras_CVPRW_2019_paper.pdf",
        "ref_texts": "[33] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In IEEE Conf. on Computer Vision and Pattern Recognition (CVPR) , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "33"
        ]
      },
      "Deep learning for light field saliency detection": {
        "authors": [
          "Tiantian Wang",
          "Yongri Piao",
          "Xiao Li",
          "Lihe Zhang",
          "Huchuan Lu"
        ],
        "url": "https://openaccess.thecvf.com/content_ICCV_2019/papers/Wang_Deep_Learning_for_Light_Field_Saliency_Detection_ICCV_2019_paper.pdf",
        "ref_texts": "[75] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , pages 2881\u20132890, 2017. 2",
        "ref_ids": [
          "75"
        ]
      },
      "Deep smoke segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1809.00774",
        "ref_texts": ""
      },
      "Where is my mirror?": {
        "authors": [
          "Xin Yang",
          "Haiyang Mei",
          "Ke Xu",
          "Xiaopeng Wei",
          "Baocai Yin",
          "Rynson W"
        ],
        "url": "http://openaccess.thecvf.com/content_ICCV_2019/papers/Yang_Where_Is_My_Mirror_ICCV_2019_paper.pdf",
        "ref_texts": "[48] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017.",
        "ref_ids": [
          "48"
        ]
      },
      "Darnet: Deep active ray network for building segmentation": {
        "authors": [
          "Dominic Cheng",
          "Renjie Liao",
          "Sanja Fidler",
          "Raquel Urtasun"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPR_2019/papers/Cheng_DARNet_Deep_Active_Ray_Network_for_Building_Segmentation_CVPR_2019_paper.pdf",
        "ref_texts": "[25] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In CVPR , pages 2881\u20132890, 2017. 1",
        "ref_ids": [
          "25"
        ]
      },
      "Towards corner case detection for autonomous driving": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1902.09184",
        "ref_texts": "[30] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid Scene Parsing Network,\u201d in Proc. of CVPR , Honulu, HI, USA, July 2017, pp. 2881\u2013",
        "ref_ids": [
          "30"
        ]
      },
      "Light-Weight Hybrid Convolutional Network for Liver Tumor Segmentation.": {
        "authors": [
          "Jianpeng Zhang",
          "Yutong Xie",
          "Pingping Zhang",
          "Hao Chen",
          "Yong Xia",
          "Chunhua Shen"
        ],
        "url": "https://www.ijcai.org/Proceedings/2019/0593.pdf",
        "ref_texts": "[Zhao et al., 2017 ]Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR, pages 2881\u20132890, 2017.Proceedings of the Twenty-Eighth International Joint Conference on Artificial Intelligence (IJCAI-19)",
        "ref_ids": [
          "Zhao et al\\., 2017 "
        ]
      },
      "V-NAS: Neural architecture search for volumetric medical image segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1906.02817",
        "ref_texts": "[30] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In CVPR , 2017. 3",
        "ref_ids": [
          "30"
        ]
      },
      "A review on deep learning approaches to image classification and object segmentation": {
        "authors": [],
        "url": "https://napier-repository.worktribe.com/preview/2039827/A%20Review%20on%20Deep%20Learning%20Approaches%20VoR.pdf",
        "ref_texts": " A Review on Deep Learning Approaches to Im age Classification 597 Szegedy, C .; Vanhoucke, V .; Ioffe, S .; Shlens, J .; Wojna, Z. (2016) : Rethi nking the inception architectur e for computer vision . IEEE Conference on Computer Vision and Pattern Recognition , pp. 2818 -2826. Tsung, P. K .; Tsai, S. F .; Pai, A .; Lai, S. J .; Lu, C. (2016) : High performance deep neural network on low cost mobile GPU. IEEE International Conference on C onsumer Electronics , pp. 69-70. Van Den Oord, A .; Dieleman, S .; Zen, H .; Simonyan, K .; Vinyals, O . et al . (2016) : Wavenet: a generative model for raw audio . Sound . Wu, Y .; Schuster, M .; Chen, Z .; Le, Q. V .; Norouzi, M . et al. (2016): Google \u2019s neural machin e translation system: bridging the gap between human and machine translation . Computation and Language . Yu, F .; Koltun, V. (2015) : Multi -scale context aggregation by dilated convolutions. OALib Journa l. Zhao, H .; Shi, J .; Qi, X.; Wang, X .; Jia, J. (2017) : Pyramid scene parsing network . IEEE Conf erence on Computer Vision and Pattern Recognition , pp. 2881 -2890. Zhu, Q .; Yeh, M. C .; Cheng, K. T .; Avidan, S. (2006) : Fast human detection using a cascade of histograms of oriented gr adients. IEEE Computer Vision & Pattern Recognition , vol. 2, pp. 1491 -1498. "
      },
      "Coarse-to-fine semantic segmentation from image-level labels": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1812.10885",
        "ref_texts": "[3] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in IEEE Conf. on Computer Vision and Pattern Recognition (CVPR) , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "3"
        ]
      },
      "Recurrent U-Net for resource-constrained segmentation": {
        "authors": [
          "Wei Wang",
          "Kaicheng Yu",
          "Joachim Hugonot",
          "Pascal Fua",
          "Mathieu Salzmann"
        ],
        "url": "https://openaccess.thecvf.com/content_ICCV_2019/papers/Wang_Recurrent_U-Net_for_Resource-Constrained_Segmentation_ICCV_2019_paper.pdf",
        "ref_texts": "[46] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid Scene Parsing Network. In Conference on Computer Vision and Pattern Recognition , 2017. 1,2",
        "ref_ids": [
          "46"
        ]
      },
      "Hierarchical shot detector": {
        "authors": [
          "Jiale Cao",
          "Yanwei Pang",
          "Jungong Han",
          "Xuelong Li"
        ],
        "url": "https://openaccess.thecvf.com/content_ICCV_2019/papers/Cao_Hierarchical_Shot_Detector_ICCV_2019_paper.pdf",
        "ref_texts": "[56] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. Proc. IEEE Conf. Computer Vision and Pattern Recognition , 2017.",
        "ref_ids": [
          "56"
        ]
      },
      "Towards instance-level image-to-image translation": {
        "authors": [
          "Zhiqiang Shen",
          "Mingyang Huang",
          "Jianping Shi",
          "Xiangyang Xue",
          "Thomas S. Huang"
        ],
        "url": "https://openaccess.thecvf.com/content_CVPR_2019/papers/Shen_Towards_Instance-Level_Image-To-Image_Translation_CVPR_2019_paper.pdf",
        "ref_texts": "[41] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017. 7,8",
        "ref_ids": [
          "41"
        ]
      },
      "Restricted deformable convolution-based road scene semantic segmentation using surround view cameras": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1801.00708",
        "ref_texts": "[11] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in IEEE Conf. Comput. Vis. Pattern Recog. , July 2017, pp.",
        "ref_ids": [
          "11"
        ]
      },
      "Online PCB defect detector on a new PCB defect dataset": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1902.06197",
        "ref_texts": "[25] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia, \u201cPyramid scene parsing network,\u201d in IEEE Conference on Computer Vision and Pattern Recognition, 2017, pp. 6230\u20136239.",
        "ref_ids": [
          "25"
        ]
      },
      "See clearer at night: towards robust nighttime semantic segmentation through day-night image conversion": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1908.05868",
        "ref_texts": "[7] Zhao, H., Shi, J., Qi, X., Wang, X., and Jia, J., \\Pyramid scene parsing network,\" in [2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) ], 6230{6239, IEEE (2017).",
        "ref_ids": [
          "7"
        ]
      },
      "Monocular semantic occupancy grid mapping with convolutional variational encoder\u2013decoder networks": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1804.02176",
        "ref_texts": "[3] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid Scene Parsing Network,\u201d in CVPR , 2017, pp. 6230\u20136239.",
        "ref_ids": [
          "3"
        ]
      },
      "How much real data do we actually need: Analyzing object detection performance using synthetic and real data": {
        "authors": [
          "Farzan Erlik",
          "Prince Kapoor",
          "Dhanvin Kolhatkar",
          "Fahed Al",
          "Robert Laganiere",
          "Julien Rebut"
        ],
        "url": "https://arxiv.org/pdf/1907.07061",
        "ref_texts": "1804.08286 . Zhao, H., Shi, J., Qi, X., Wang, X., and Jia, J. Pyramid scene parsing network. 2016. URL http://arxiv. org/abs/1612.01105 ."
      },
      "Feature pyramid encoding network for real-time semantic segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1909.08599",
        "ref_texts": "[27] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 2881\u20132890, 2017. LIU AND YIN: FPENET FOR REAL-TIME SEMANTIC SEGMENTATION 13",
        "ref_ids": [
          "27"
        ]
      },
      "Geometry meets semantics for semi-supervised monocular depth estimation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1810.04093",
        "ref_texts": "33. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: CVPR. (2017) 2881{2890",
        "ref_ids": [
          "33"
        ]
      },
      "Efficient segmentation: Learning downsampling near semantic boundaries": {
        "authors": [
          "Dmitrii Marin",
          "Zijian He",
          "Peter Vajda",
          "Priyam Chatterjee",
          "Sam Tsai",
          "Fei Yang",
          "Yuri Boykov"
        ],
        "url": "http://openaccess.thecvf.com/content_ICCV_2019/papers/Marin_Efficient_Segmentation_Learning_Downsampling_Near_Semantic_Boundaries_ICCV_2019_paper.pdf",
        "ref_texts": "[57] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In IEEE Conf. on Computer Vision and Pattern Recognition (CVPR) , pages 2881\u20132890, 2017. 2,4,5,6",
        "ref_ids": [
          "57"
        ]
      },
      "Putting humans in a scene: Learning affordance in 3d indoor environments": {
        "authors": [
          "Xueting Li",
          "Sifei Liu",
          "Kihwan Kim",
          "Xiaolong Wang",
          "Hsuan Yang",
          "Jan Kautz"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPR_2019/papers/Li_Putting_Humans_in_a_Scene_Learning_Affordance_in_3D_Indoor_CVPR_2019_paper.pdf",
        "ref_texts": "[31] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In CVPR , 2017. 2",
        "ref_ids": [
          "31"
        ]
      },
      "Spatiotemporal cnn for video object segmentation": {
        "authors": [
          "Kai Xu",
          "Longyin Wen",
          "Guorong Li",
          "Liefeng Bo",
          "Qingming Huang"
        ],
        "url": "https://openaccess.thecvf.com/content_CVPR_2019/papers/Xu_Spatiotemporal_CNN_for_Video_Object_Segmentation_CVPR_2019_paper.pdf",
        "ref_texts": "[54] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , pages 6230\u20136239, 2017. 4",
        "ref_ids": [
          "54"
        ]
      },
      "Real-time semantic segmentation via multiply spatial fusion network": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1911.07217",
        "ref_texts": "[28] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "28"
        ]
      },
      "Deep salient object detection with contextual information guidance": {
        "authors": [],
        "url": "https://wrap.warwick.ac.uk/123588/1/WRAP-deep-salient-object-detection-contextual-guidance-Han-2019.pdf",
        "ref_texts": "[72] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , 2017, pp. 6230\u20136239.",
        "ref_ids": [
          "72"
        ]
      },
      "Lucid data dreaming for video object segmentation": {
        "authors": [
          "Anna Khoreva"
        ],
        "url": "https://link.springer.com/content/pdf/10.1007/s11263-019-01164-6.pdf",
        "ref_texts": ". Wu, Z., Shen, C., & van den Hengel, A. (2016). Wider or deeper: Revisiting the ResNet model for visual recognition. arXiv:1611.10080 . Xiao, F., & Lee, Y . J. (2016). Track and segment: An iterative unsupervised approach for video object proposals. In CVPR . Yu, J. J., Harley, A. W., & Derpanis, K. G. (2016). Back to basics: Unsupervised learning of optical flow via brightness constancyand motion smoothness. arXiv:1608.05842 . Zhao, H. (2017). Some promising ideas about multi-instance video segmentation. In CVPR workshops . Zhao, H., Shi, J., Qi, X., Wang, X., & Jia, J. (2017). Pyramid scene parsing network. In CVPR . Zhu, Y ., Lan, Z., Newsam, S., & Hauptmann, A. G. (2017). Guided optical flow learning. arXiv:1702.02295 . Publisher\u2019s Note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations."
      },
      "Simultaneous semantic segmentation and outlier detection in presence of domain shift": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1908.01098",
        "ref_texts": "49. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: CVPR (2017) Appendix A Supplementary material We use this supplement to further discuss the experiments from Section 4 of the main paper. We clarify the losses used for training the models and expand on the quantitative results described in the main paper by ofiering qualitative analysis of model outputs. Furthermore, we ofier experiments with two additional outlier detection approaches applied to dense prediction: MC-dropout and trainable conffdence. In the ffrst section we provide a detailed overview of the training losses. The results of the additional experiments can be seen at the beginning of the second section. The rest of the second and all of the third section are dedicated to illustrating validation experiments on WD-Pascal dataset. WD-Pascal is a set of images which we create by pasting instances of animals from PASCAL VOC",
        "ref_ids": [
          "49"
        ]
      },
      "Batch-shaping for learning conditional channel gated networks": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1907.06627",
        "ref_texts": "2015.2502579 . Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pp."
      },
      "A fully convolutional two-stream fusion network for interactive image segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1807.02480",
        "ref_texts": "[27] H. Zhao, J. Shi, X. Qi, X. Wang, J. Jia, Pyramid scene parsing network, in: IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2017.",
        "ref_ids": [
          "27"
        ]
      },
      "Synthesis of high-quality visible faces from polarimetric thermal faces using generative adversarial networks": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1812.05155",
        "ref_texts": "79. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: Proceedings of the IEEE International Conference on Computer Vision, pp. 1\u20138 (2017)",
        "ref_ids": [
          "79"
        ]
      },
      "Multi-scale deep context convolutional neural networks for semantic segmentation": {
        "authors": [
          "Quan Zhou"
        ],
        "url": "https://cis.temple.edu/~latecki/Papers/QuanZhou_World_Wide_Web2018.pdf",
        "ref_texts": "49. Zhao, H.H., Shi, J.P., Qi, X.J., Wang, X.G., Jia, J.Y .: Pyramid scene parsing network. arXiv: 1612.01105",
        "ref_ids": [
          "49"
        ]
      },
      "Do street-level scene perceptions affect housing prices in Chinese megacities? An analysis using open access datasets and deep learning": {
        "authors": [
          "Xiao Fu",
          "Tianxia Jia",
          "Xueqi Zhang",
          "Shanlin Li",
          "Yonglin Zhang"
        ],
        "url": "https://journals.plos.org/plosone/article/file?id=10.1371/journal.pone.0217505&type=printable",
        "ref_texts": "54. Zhao H,ShiJ,QiX,Wang X,JiaJ.Pyramid scene parsing network. In:IEEE Conferen ceoncomputer vision andpattern recognition. Hawaii, USA: IEEE; 2017. pp.6230\u20136239.",
        "ref_ids": [
          "54"
        ]
      },
      "Switchable normalization for learning-to-normalize deep representation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1907.10473",
        "ref_texts": "[54] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in CVPR , 2017.",
        "ref_ids": [
          "54"
        ]
      },
      "Sense: A shared encoder network for scene-flow estimation": {
        "authors": [
          "Huaizu Jiang",
          "Deqing Sun",
          "Varun Jampani",
          "Zhaoyang Lv",
          "Erik Learned",
          "Jan Kautz"
        ],
        "url": "https://openaccess.thecvf.com/content_ICCV_2019/papers/Jiang_SENSE_A_Shared_Encoder_Network_for_Scene-Flow_Estimation_ICCV_2019_paper.pdf",
        "ref_texts": "[64] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proc. CVPR , 2017. 4",
        "ref_ids": [
          "64"
        ]
      },
      "CLCI-Net: Cross-level fusion and context inference networks for lesion segmentation of chronic stroke": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1907.07008",
        "ref_texts": ""
      },
      "A cross-season correspondence dataset for robust semantic segmentation": {
        "authors": [
          "Mans Larsson",
          "Erik Stenborg",
          "Lars Hammarstrand",
          "Marc Pollefeys",
          "Torsten Sattler",
          "Fredrik Kahl"
        ],
        "url": "https://openaccess.thecvf.com/content_CVPR_2019/papers/Larsson_A_Cross-Season_Correspondence_Dataset_for_Robust_Semantic_Segmentation_CVPR_2019_paper.pdf",
        "ref_texts": "[76] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proc. CVPR , 2017. 2,5",
        "ref_ids": [
          "76"
        ]
      },
      "ESNet: An efficient symmetric network for real-time semantic segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1906.09826",
        "ref_texts": "6. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.Y.: Pyramid scene parsing network. In: CVPR. (2016) 6230{6239",
        "ref_ids": [
          "6"
        ]
      },
      "Fine-grained segmentation networks: Self-supervised segmentation for improved long-term visual localization": {
        "authors": [
          "Mans Larsson",
          "Erik Stenborg",
          "Carl Toft",
          "Lars Hammarstrand",
          "Torsten Sattler",
          "Fredrik Kahl"
        ],
        "url": "https://openaccess.thecvf.com/content_ICCV_2019/papers/Larsson_Fine-Grained_Segmentation_Networks_Self-Supervised_Segmentation_for_Improved_Long-Term_Visual_Localization_ICCV_2019_paper.pdf",
        "ref_texts": "[99] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017. 2,4",
        "ref_ids": [
          "99"
        ]
      },
      "RFBNet: deep multimodal networks with residual fusion blocks for RGB-D semantic segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1907.00135",
        "ref_texts": "[9] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in IEEE Conf. Comput. Vis. Pattern Recog. , July 2017, pp.",
        "ref_ids": [
          "9"
        ]
      },
      "Orientation-aware semantic segmentation on icosahedron spheres": {
        "authors": [
          "Chao Zhang",
          "Stephan Liwicki",
          "William Smith",
          "Roberto Cipolla"
        ],
        "url": "https://openaccess.thecvf.com/content_ICCV_2019/papers/Zhang_Orientation-Aware_Semantic_Segmentation_on_Icosahedron_Spheres_ICCV_2019_paper.pdf",
        "ref_texts": "[30] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "30"
        ]
      },
      "Precipitation nowcasting with satellite imagery": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1905.09932",
        "ref_texts": "[40] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. 2017. Pyramid scene parsing network. In IEEE Conf. on Computer Vision and Pattern Recognition (CVPR) . 2881\u20132890.",
        "ref_ids": [
          "40"
        ]
      },
      "Liteseg: A novel lightweight convnet for semantic segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1912.06683",
        "ref_texts": "[3] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in CVPR , 2017.",
        "ref_ids": [
          "3"
        ]
      },
      "Global aggregation then local distribution in fully convolutional networks": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1909.07229",
        "ref_texts": "[42] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017.",
        "ref_ids": [
          "42"
        ]
      },
      "Real-time instrument segmentation in robotic surgery using auxiliary supervised deep adversarial learning": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2007.11319",
        "ref_texts": "[44] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in IEEE Conf. on Computer Vision and Pattern Recognition (CVPR) , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "44"
        ]
      },
      "Fsnet: An identity-aware generative model for image-based face swapping": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1811.12666",
        "ref_texts": "31. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid Scene Parsing Network. arXiv preprint arXiv:1612.01105 (2016)",
        "ref_ids": [
          "31"
        ]
      },
      "CloudSegNet: A deep network for nychthemeron cloud image segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1904.07979",
        "ref_texts": "[19] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proc. IEEE Conf. on Computer Vision and Pattern Recognition (CVPR) , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "19"
        ]
      },
      "Fast and practical neural architecture search": {
        "authors": [
          "Jiequan Cui",
          "Pengguang Chen",
          "Ruiyu Li",
          "Shu Liu",
          "Xiaoyong Shen",
          "Jiaya Jia"
        ],
        "url": "http://openaccess.thecvf.com/content_ICCV_2019/papers/Cui_Fast_and_Practical_Neural_Architecture_Search_ICCV_2019_paper.pdf",
        "ref_texts": "[35] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017. 2",
        "ref_ids": [
          "35"
        ]
      },
      "Not Using the Car to See the Sidewalk--Quantifying and Controlling the Effects of Context in Classification and Segmentation": {
        "authors": [
          "Rakshith Shetty",
          "Bernt Schiele",
          "Mario Fritz"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPR_2019/papers/Shetty_Not_Using_the_Car_to_See_the_Sidewalk_--_Quantifying_CVPR_2019_paper.pdf",
        "ref_texts": "[26] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2017. 2",
        "ref_ids": [
          "26"
        ]
      },
      "Automated evaluation of semantic segmentation robustness for autonomous driving": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1810.10193",
        "ref_texts": "[2] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d arXiv preprint arXiv:1612.01105 , 2016.",
        "ref_ids": [
          "2"
        ]
      },
      "Deeply-supervised knowledge synergy": {
        "authors": [
          "Dawei Sun",
          "Anbang Yao",
          "Aojun Zhou",
          "Hao Zhao"
        ],
        "url": "https://openaccess.thecvf.com/content_CVPR_2019/papers/Sun_Deeply-Supervised_Knowledge_Synergy_CVPR_2019_paper.pdf",
        "ref_texts": "[54] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In CVPR , 2017. 2",
        "ref_ids": [
          "54"
        ]
      },
      "Cascaded context pyramid for full-resolution 3d semantic scene completion": {
        "authors": [
          "Pingping Zhang",
          "Wei Liu",
          "Yinjie Lei",
          "Huchuan Lu",
          "Xiaoyun Yang"
        ],
        "url": "https://openaccess.thecvf.com/content_ICCV_2019/papers/Zhang_Cascaded_Context_Pyramid_for_Full-Resolution_3D_Semantic_Scene_Completion_ICCV_2019_paper.pdf",
        "ref_texts": "[40] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "40"
        ]
      },
      "Interactive full image segmentation by considering all regions jointly": {
        "authors": [
          "Eirikur Agustsson",
          "Jasper R. R",
          "Vittorio Ferrari"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPR_2019/papers/Agustsson_Interactive_Full_Image_Segmentation_by_Considering_All_Regions_Jointly_CVPR_2019_paper.pdf",
        "ref_texts": "[61] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In CVPR , 2017. 6",
        "ref_ids": [
          "61"
        ]
      },
      "A unified point-based framework for 3d segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1908.00478",
        "ref_texts": "[22] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In CVPR , 2017. 4321",
        "ref_ids": [
          "22"
        ]
      },
      "DSSLIC: Deep semantic segmentation-based layered image compression": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1806.03348",
        "ref_texts": "[23] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In IEEE Conf. on Computer Vision and Pattern Recognition (CVPR) , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "23"
        ]
      },
      "Spatiotemporal patterns of street-level solar radiation estimated using Google Street View in a high-density urban environment": {
        "authors": [
          "Ying Gong"
        ],
        "url": "https://dspace.mit.edu/bitstream/handle/1721.1/122017/Gong_2018b_GSV-based_Street_Solar_Radiation_Method.pdf?sequence=2&isAllowed=y",
        "ref_texts": "[37] H. Zhao, J. Shi, X. Qi, X. Wang, J. Jia, Pyramid Scene Parsing Network, (Dec. 2016)ArXiv161201105 Cs.",
        "ref_ids": [
          "37"
        ]
      },
      "Squeezenas: Fast neural architecture search for faster semantic segmentation": {
        "authors": [
          "Albert Shaw",
          "Daniel Hunter",
          "Forrest Landola",
          "Sammy Sidhu"
        ],
        "url": "http://openaccess.thecvf.com/content_ICCVW_2019/papers/NeurArch/Shaw_SqueezeNAS_Fast_Neural_Architecture_Search_for_Faster_Semantic_Segmentation_ICCVW_2019_paper.pdf",
        "ref_texts": "[48] S. Reitsma, \u201cCost comparison of deep learning hardware: Google TPUv2 vs Nvidia Tesla V100,\u201d 2019. [Online]. Available: https://medium .com/bigdatarepublic/costcomparison-of-deep-learning-hardware-googletpuv2-vs-nvidia-tesla-v100-3c63fe56c20f [49] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "48",
          "Online",
          "49"
        ]
      },
      "Unsupervised high-resolution depth learning from videos with dual networks": {
        "authors": [
          "Junsheng Zhou",
          "Yuwang Wang",
          "Kaihuai Qin",
          "Wenjun Zeng"
        ],
        "url": "http://openaccess.thecvf.com/content_ICCV_2019/papers/Zhou_Unsupervised_High-Resolution_Depth_Learning_From_Videos_With_Dual_Networks_ICCV_2019_paper.pdf",
        "ref_texts": "[53] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017.[54] Tinghui Zhou, Matthew Brown, Noah Snavely, and David G Lowe. Unsupervised learning of depth and ego-motion from video. In CVPR , 2017.",
        "ref_ids": [
          "53",
          "54"
        ]
      },
      "Bonnet: An open-source training and deployment framework for semantic segmentation in robotics using cnns": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1802.08960",
        "ref_texts": "[36] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. arXiv preprint , abs/1612.01105, 2016.",
        "ref_ids": [
          "36"
        ]
      },
      "Defusionnet: Defocus blur detection via recurrently fusing and refining multi-scale deep features": {
        "authors": [
          "Chang Tang",
          "Xinzhong Zhu",
          "Xinwang Liu",
          "Lizhe Wang",
          "Albert Zomaya"
        ],
        "url": "https://openaccess.thecvf.com/content_CVPR_2019/papers/Tang_DeFusionNET_Defocus_Blur_Detection_via_Recurrently_Fusing_and_Refining_Multi-Scale_CVPR_2019_paper.pdf",
        "ref_texts": ""
      },
      "Sem-GAN: Semantically-consistent image-to-image translation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1807.04409",
        "ref_texts": "[53] Z. Yi, H. Zhang, P. Tan, and M. Gong. Dualgan: Unsupervised dual learning for image-to-image translation. In CVPR , 2017.[54] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In CVPR , 2017.",
        "ref_ids": [
          "53",
          "54"
        ]
      },
      "Not all areas are equal: Transfer learning for semantic segmentation via hierarchical region selection": {
        "authors": [
          "Ruoqi Sun",
          "Xinge Zhu",
          "Chongruo Wu",
          "Chen Huang",
          "Jianping Shi",
          "Lizhuang Ma"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPR_2019/papers/Sun_Not_All_Areas_Are_Equal_Transfer_Learning_for_Semantic_Segmentation_CVPR_2019_paper.pdf",
        "ref_texts": "[32] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In IEEE Conference on Computer Vision and Pattern Recognition(CVPR) , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "32"
        ]
      },
      "Semantic understanding of foggy scenes with purely synthetic data": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1910.03997",
        "ref_texts": "[16] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2017.",
        "ref_ids": [
          "16"
        ]
      },
      "S4net: Single stage salient-instance segmentation": {
        "authors": [
          "Ruochen Fan",
          "Ming Cheng",
          "Qibin Hou",
          "Jiang Mu",
          "Jingdong Wang",
          "Min Hu"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPR_2019/papers/Fan_S4Net_Single_Stage_Salient-Instance_Segmentation_CVPR_2019_paper.pdf",
        "ref_texts": "[61] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In CVPR , 2017. 6",
        "ref_ids": [
          "61"
        ]
      },
      "Decoupled spatial neural attention for weakly supervised semantic segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1803.02563",
        "ref_texts": "[14] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in CVPR , 2017.",
        "ref_ids": [
          "14"
        ]
      },
      "Object instance annotation with deep extreme level set evolution": {
        "authors": [
          "Zian Wang",
          "David Acuna",
          "Huan Ling",
          "Amlan Kar",
          "Sanja Fidler"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPR_2019/papers/Wang_Object_Instance_Annotation_With_Deep_Extreme_Level_Set_Evolution_CVPR_2019_paper.pdf",
        "ref_texts": "[40] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. CoRR , abs/1612.01105, 2016.",
        "ref_ids": [
          "40"
        ]
      },
      "Zigzagnet: Fusing top-down and bottom-up context for object segmentation": {
        "authors": [
          "Di Lin",
          "Dingguo Shen",
          "Siting Shen",
          "Yuanfeng Ji",
          "Dani Lischinski",
          "Daniel Cohen",
          "Hui Huang"
        ],
        "url": "https://openaccess.thecvf.com/content_CVPR_2019/papers/Lin_ZigZagNet_Fusing_Top-Down_and_Bottom-Up_Context_for_Object_Segmentation_CVPR_2019_paper.pdf",
        "ref_texts": "[43] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. arXiv , 2016.",
        "ref_ids": [
          "43"
        ]
      },
      "Embedmask: Embedding coupling for one-stage instance segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1912.01954",
        "ref_texts": "[34] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017.",
        "ref_ids": [
          "34"
        ]
      },
      "Automatic segmentation of the mandible from computed tomography scans for 3D virtual surgical planning using the convolutional neural network": {
        "authors": [],
        "url": "https://research.rug.nl/files/88761403/Automatic_segmentation_of_the_mandible_from_computed_tomography_scans_for_3D_virtual_surgical_planning_using_the_convolutional_neural_network.pdf",
        "ref_texts": "& Maal, T. J. (2016). Accuracy of virtually 3d planned resection templates in mandibular reconstruction, Journal of Cranio-Maxillofacial Surgery 44(11): 1828{1832. Wu, J., Tha, K. K., Xing, L. & Li, R. (2018). Radiomics and radiogenomics for precision radiotherapy, Journal of radiation research 59(suppl 1): i25{i31. Yu, F. & Koltun, V. (2015). Multi-scale context aggregation by dilated convolutions, arXiv preprint arXiv:1511.07122 . Yu, L., Yang, X., Chen, H., Qin, J. & Heng, P.-A. (2017). Volumetric convnets with mixed residual connections for automated prostate segmentation from 3d mr images., AAAI, pp. 66{72. Yuheng, S. & Hao, Y. (2017). Image segmentation algorithms overview, arXiv preprint arXiv:1707.02051 . Zhao, H., Shi, J., Qi, X., Wang, X. & Jia, J. (2017). Pyramid scene parsing network, IEEE Conf. on Computer Vision and Pattern Recognition (CVPR) , pp. 2881{2890. Zhu, W., Huang, Y., Tang, H., Qian, Z., Du, N., Fan, W. & Xie, X. (2018). Anatomynet: Deep 3d squeeze-and-excitation u-nets for fast and fully automated whole-volume anatomical segmentation, arXiv preprint arXiv:1808.05238 .Page 20 of 20 AUTHOR SUBMITTED MANUSCRIPT PMB-108319.R2"
      },
      "Reverse and boundary attention network for road segmentation": {
        "authors": [
          "Young Sun",
          "Wook Kim",
          "Won Lee",
          "Won Kim",
          "Jea Ko"
        ],
        "url": "http://openaccess.thecvf.com/content_ICCVW_2019/papers/CVRSUAD/Sun_Reverse_and_Boundary_Attention_Network_for_Road_Segmentation_ICCVW_2019_paper.pdf",
        "ref_texts": "[45] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017. 1,3[46] F. Zohourian, B. Antic, J. Siegemund, M. Meuter, and J. Pauli. Superpixel-based road segmentation for real-time systems using cnn. In VISIGRAPP (5: VISAPP) , pages 257\u2013",
        "ref_ids": [
          "45",
          "46"
        ]
      },
      "Learning implicitly recurrent CNNs through parameter sharing": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1902.09701",
        "ref_texts": "11 Published as a conference paper at ICLR 2019 Yibo Yang, Zhisheng Zhong, Tiancheng Shen, and Zhouchen Lin. Convolutional neural networks with alternately updated clique. CVPR , 2018. Sergey Zagoruyko and Nikos Komodakis. Wide residual networks. BMVC , 2016. Amir Roshan Zamir, Te-Lin Wu, Lin Sun, William B. Shen, Jitendra Malik, and Silvio Savarese. Feedback networks. CVPR , 2017. Wojciech Zaremba, Tomas Mikolov, Armand Joulin, and Rob Fergus. Learning simple algorithms from examples. ICML , 2016. Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. CVPR , 2017. Ligeng Zhu, Ruizhi Deng, Zhiwei Deng, Greg Mori, and Ping Tan. Sparsely aggregated convolutional networks. ECCV , 2018. Barret Zoph and Quoc V . Le. Neural architecture search with reinforcement learning. ICLR , 2017."
      },
      "Deep depth from focus": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1704.01085",
        "ref_texts": "47. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: CVPR (2017) Deep Depth From Focus Supplementary Material Caner Hazirbas, Sebastian Georg Soyer, Maximilian Christian Staab, Laura Leal-Taix\u0013 e, and Daniel Cremers Technical University of Munich, Germany fhazirbas, soyers, staab, leal.taixe, cremers g@cs.tum.edu Abstract. In this supplementary material we include additional information for the reader. We ffrst detail the formulation of the light-ffeld calibration and provide the values for all parameters. We then present the characteristics of the new DDFF 12-Scene dataset, such as disparity histograms per sequence and disparity sampling. Moreover, we show more qualitative results including the failure cases and also visualizations of the activation heat maps for our best performing model, i.e.DDFFNetCC3. Finally, we provide the results on the 4D light-ffeld dataset and also on our mobile DFF (mDFF) dataset.",
        "ref_ids": [
          "47"
        ]
      },
      "Skyscapes fine-grained semantic understanding of aerial scenes": {
        "authors": [
          "Seyed Majid",
          "Corentin Henry",
          "Lars Sommer",
          "Arne Schumann",
          "Eleonora Vig"
        ],
        "url": "http://openaccess.thecvf.com/content_ICCV_2019/papers/Azimi_SkyScapes__Fine-Grained_Semantic_Understanding_of_Aerial_Scenes_ICCV_2019_paper.pdf",
        "ref_texts": "[50] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid Scene Parsing Network. In CVPR , Honolulu, 2017. 4,6,7",
        "ref_ids": [
          "50"
        ]
      },
      "Embodied amodal recognition: Learning to move to perceive objects": {
        "authors": [
          "Jianwei Yang",
          "Zhile Ren",
          "Mingze Xu",
          "Xinlei Chen",
          "David J. Crandall",
          "Devi Parikh",
          "Dhruv Batra"
        ],
        "url": "https://openaccess.thecvf.com/content_ICCV_2019/papers/Yang_Embodied_Amodal_Recognition_Learning_to_Move_to_Perceive_Objects_ICCV_2019_paper.pdf",
        "ref_texts": "[67] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , 2017. 1,3",
        "ref_ids": [
          "67"
        ]
      },
      "Ace: Adapting to changing environments for semantic segmentation": {
        "authors": [
          "Zuxuan Wu",
          "Xin Wang",
          "Joseph E. Gonzalez",
          "Tom Goldstein",
          "Larry S. Davis"
        ],
        "url": "https://openaccess.thecvf.com/content_ICCV_2019/papers/Wu_ACE_Adapting_to_Changing_Environments_for_Semantic_Segmentation_ICCV_2019_paper.pdf",
        "ref_texts": "[70] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017. 6,7",
        "ref_ids": [
          "70"
        ]
      },
      "Ischemic stroke lesion segmentation in CT perfusion scans using pyramid pooling and focal loss": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1811.01085",
        "ref_texts": "27. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: IEEE Conf. on Computer Vision and Pattern Recognition (CVPR). pp. 2881{2890",
        "ref_ids": [
          "27"
        ]
      },
      "Interpretability beyond classification output: Semantic bottleneck networks": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1907.10882",
        "ref_texts": "[30] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017.",
        "ref_ids": [
          "30"
        ]
      },
      "CNN-based semantic segmentation using level set loss": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1910.00950",
        "ref_texts": "[35] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In CVPR . 2017.",
        "ref_ids": [
          "35"
        ]
      },
      "Ssn: Learning sparse switchable normalization via sparsestmax": {
        "authors": [
          "Wenqi Shao",
          "Tianjian Meng",
          "Jingyu Li",
          "Ruimao Zhang",
          "Yudian Li",
          "Xiaogang Wang",
          "Ping Luo"
        ],
        "url": "https://openaccess.thecvf.com/content_CVPR_2019/papers/Shao_SSN_Learning_Sparse_Switchable_Normalization_via_SparsestMax_CVPR_2019_paper.pdf",
        "ref_texts": "[29] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2017.",
        "ref_ids": [
          "29"
        ]
      },
      "Real-time progressive 3D semantic segmentation for indoor scenes": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1804.00257",
        "ref_texts": "[55] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , pages 2881\u20132890, 2017. 6",
        "ref_ids": [
          "55"
        ]
      },
      "Learning multi-class segmentations from single-class datasets": {
        "authors": [
          "Konstantin Dmitriev",
          "Arie E. Kaufman"
        ],
        "url": "https://openaccess.thecvf.com/content_CVPR_2019/papers/Dmitriev_Learning_Multi-Class_Segmentations_From_Single-Class_Datasets_CVPR_2019_paper.pdf",
        "ref_texts": "[47] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. Proc. of IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "47"
        ]
      },
      "Triply supervised decoder networks for joint detection and segmentation": {
        "authors": [
          "Jiale Cao",
          "Yanwei Pang",
          "Xuelong Li"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPR_2019/papers/Cao_Triply_Supervised_Decoder_Networks_for_Joint_Detection_and_Segmentation_CVPR_2019_paper.pdf",
        "ref_texts": "[54] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. Proc. IEEE Conference on Computer Vision and Pattern Recognition , 2017.",
        "ref_ids": [
          "54"
        ]
      },
      "Geo-supervised visual depth prediction": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1807.11130",
        "ref_texts": "[36] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d inCVPR , 2017.",
        "ref_ids": [
          "36"
        ]
      },
      "Global localization with object-level semantics and topology": {
        "authors": [
          "Yu Liu",
          "Yvan R. Petillot",
          "David Lane",
          "Sen Wang"
        ],
        "url": "https://researchportal.hw.ac.uk/files/24248043/ICRA19_1309_FI.pdf",
        "ref_texts": "[18] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in CVPR , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "18"
        ]
      },
      "Learnable tree filter for structure-preserving feature transform": {
        "authors": [
          "Lin Song",
          "Yanwei Li",
          "Zeming Li",
          "Gang Yu",
          "Hongbin Sun",
          "Jian Sun",
          "Nanning Zheng"
        ],
        "url": "https://proceedings.neurips.cc/paper/2019/file/8065d07da4a77621450aa84fee5656d9-Paper.pdf",
        "ref_texts": "[3]Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In IEEE Conference on Computer Vision and Pattern Recognition , 2017.",
        "ref_ids": [
          "3"
        ]
      },
      "Dispsegnet: Leveraging semantics for end-to-end learning of disparity estimation from stereo imagery": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1809.04734",
        "ref_texts": "[28] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , 2017, pp. 2881\u2013",
        "ref_ids": [
          "28"
        ]
      },
      "Multi-stage pathological image classification using semantic segmentation": {
        "authors": [
          "Shusuke Takahama",
          "Yusuke Kurose",
          "Yusuke Mukuta",
          "Hiroyuki Abe",
          "Masashi Fukayama",
          "Akihiko Yoshizawa",
          "Masanobu Kitagawa",
          "Tatsuya Harada"
        ],
        "url": "http://openaccess.thecvf.com/content_ICCV_2019/papers/Takahama_Multi-Stage_Pathological_Image_Classification_Using_Semantic_Segmentation_ICCV_2019_paper.pdf",
        "ref_texts": "[35] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017.",
        "ref_ids": [
          "35"
        ]
      },
      "Context-reinforced semantic segmentation": {
        "authors": [
          "Yizhou Zhou",
          "Xiaoyan Sun",
          "Jun Zha",
          "Wenjun Zeng"
        ],
        "url": "https://openaccess.thecvf.com/content_CVPR_2019/papers/Zhou_Context-Reinforced_Semantic_Segmentation_CVPR_2019_paper.pdf",
        "ref_texts": "[37] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In IEEE Conf. on Computer Vision and Pattern Recognition (CVPR) , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "37"
        ]
      },
      "Is this the right place? geometric-semantic pose verification for indoor visual localization": {
        "authors": [
          "Hajime Taira",
          "Ignacio Rocco",
          "Jiri Sedlar",
          "Masatoshi Okutomi",
          "Josef Sivic",
          "Tomas Pajdla",
          "Torsten Sattler",
          "Akihiko Torii"
        ],
        "url": "http://openaccess.thecvf.com/content_ICCV_2019/papers/Taira_Is_This_the_Right_Place_Geometric-Semantic_Pose_Verification_for_Indoor_ICCV_2019_paper.pdf",
        "ref_texts": "[86] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proc. CVPR , 2017. 5[87] Bolei Zhou, Hang Zhao, Xavier Puig, Sanja Fidler, Adela Barriuso, and Antonio Torralba. Scene parsing through ADE20K dataset. In Proc. CVPR , 2017. 5",
        "ref_ids": [
          "86",
          "87"
        ]
      },
      "M2kd: Multi-model and multi-level knowledge distillation for incremental learning": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1904.01769",
        "ref_texts": "[37] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017.",
        "ref_ids": [
          "37"
        ]
      },
      "2D-CTC for scene text recognition": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1907.09705",
        "ref_texts": "[42] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , pages 6230\u20136239, Honolulu, HI, USA, July 2017.",
        "ref_ids": [
          "42"
        ]
      },
      "Student becoming the master: Knowledge amalgamation for joint scene parsing, depth estimation, and more": {
        "authors": [
          "Jingwen Ye",
          "Yixin Ji",
          "Xinchao Wang",
          "Kairi Ou",
          "Dapeng Tao",
          "Mingli Song"
        ],
        "url": "https://openaccess.thecvf.com/content_CVPR_2019/papers/Ye_Student_Becoming_the_Master_Knowledge_Amalgamation_for_Joint_Scene_Parsing_CVPR_2019_paper.pdf",
        "ref_texts": "[40] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. InComputer Vision and Pattern Recognition , pages 2881\u2013",
        "ref_ids": [
          "40"
        ]
      },
      "Grid saliency for context explanations of semantic segmentation": {
        "authors": [
          "Lukas Hoyer",
          "Mauricio Munoz",
          "Prateek Katiyar",
          "Anna Khoreva",
          "Volker Fischer"
        ],
        "url": "https://proceedings.neurips.cc/paper/2019/file/6950aa02ae8613af620668146dd11840-Paper.pdf",
        "ref_texts": "[30] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , pages 6230\u20136239, 2017.",
        "ref_ids": [
          "30"
        ]
      },
      "Natural language guided visual relationship detection": {
        "authors": [
          "Wentong Liao",
          "Bodo Rosenhahn",
          "Ling Shuai",
          "Michael Ying"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPRW_2019/papers/MULA/Liao_Natural_Language_Guided_Visual_Relationship_Detection_CVPRW_2019_paper.pdf",
        "ref_texts": "[45] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In CVPR , 2017.",
        "ref_ids": [
          "45"
        ]
      },
      "Domain adaptive person re-identification via camera style generation and label propagation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1905.05382",
        "ref_texts": "[37] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Computer Vision and Pattern Recognition, 2017, pp. 2881\u20132890. 4",
        "ref_ids": [
          "37"
        ]
      },
      "Frame-to-frame aggregation of active regions in web videos for weakly supervised semantic segmentation": {
        "authors": [
          "Jungbeom Lee",
          "Eunji Kim",
          "Sungmin Lee",
          "Jangho Lee",
          "Sungroh Yoon"
        ],
        "url": "https://openaccess.thecvf.com/content_ICCV_2019/papers/Lee_Frame-to-Frame_Aggregation_of_Active_Regions_in_Web_Videos_for_Weakly_ICCV_2019_paper.pdf",
        "ref_texts": "[52] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 2881\u20132890, 2017.[53] Bolei Zhou, Aditya Khosla, Agata Lapedriza, Aude Oliva, and Antonio Torralba. Learning deep features for discriminative localization. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 2921\u2013",
        "ref_ids": [
          "52",
          "53"
        ]
      },
      "Sketch2code: Generating a website from a paper mockup": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1905.13750",
        "ref_texts": "[62] Hengshuang Zhao et al. \\Pyramid Scene Parsing Network\". In: CoRR abs/1612.01105 (2016). arXiv: 1612.01105 .url:http://arxiv.org/abs/1612.01105 .",
        "ref_ids": [
          "62"
        ]
      },
      "Incorporating luminance, depth and color information by a fusion-based network for semantic segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1809.09077",
        "ref_texts": "[20] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \"Pyramid scene parsing network,\" in IEEE Conference on Computer Vision and Pattern Recognition , 2017. ",
        "ref_ids": [
          "20"
        ]
      },
      "Robust semantic segmentation in adverse weather conditions by means of sensor data fusion": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1905.10117",
        "ref_texts": "[27] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. CoRR , abs/1612.01105, 2016.",
        "ref_ids": [
          "27"
        ]
      },
      "Semantic segmentation of video sequences with convolutional lstms": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1905.01058",
        "ref_texts": "[26] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. CoRR , abs/1612.01105, 2016.",
        "ref_ids": [
          "26"
        ]
      },
      "Pixel level data augmentation for semantic image segmentation using generative adversarial networks": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1811.00174",
        "ref_texts": "[20] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia, \u201cPyramid scene parsing network,\u201d inThe IEEE Conference on Computer Vision and Pattern Recognition(CVPR) , 2017.",
        "ref_ids": [
          "20"
        ]
      },
      "Amnet: Deep atrous multiscale stereo disparity estimation networks": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1904.09099",
        "ref_texts": "[28] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2017.",
        "ref_ids": [
          "28"
        ]
      },
      "Weakly supervised semantic segmentation by a class-level multiple group cosegmentation and foreground fusion strategy": {
        "authors": [],
        "url": "https://coolbeam.github.io/collections/2019_csvt/2019_csvt.pdf",
        "ref_texts": ""
      },
      "Geometry and uncertainty in deep learning for computer vision": {
        "authors": [],
        "url": "https://sanjeevg15.github.io/media/papers/alex_kendall_phd_thesis_compressed.pdf",
        "ref_texts": "185 References. Yosinski, J., Clune, J., Bengio, Y ., and Lipson, H. (2014). How transferable are features in deep neural networks? In Advances in neural information processing systems , pages 3320\u20133328. Yu, F. and Koltun, V . (2016). Multi-scale context aggregation by dilated convolutions. In ICLR . Zabih, R. and Woodfill, J. (1994). Non-parametric Local Transforms for Computing Visual Correspondence. In Proceedings of European Conference on Computer Vision , pages 151\u2013158. Zagoruyko, S. and Komodakis, N. (2015). Learning to compare image patches via convolutional neural networks. Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition , 07-12-June(i):4353\u20134361. Zamir, A. R., Sax, A., Shen, W., Guibas, L., Malik, J., and Savarese, S. (2018). Taskonomy: Disentangling task transfer learning. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 3712\u20133722. Zbontar, J. and LeCun, Y . (2015). Computing the stereo matching cost with a convolutional neural network. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 1592\u20131599. Zbontar, J. and LeCun, Y . (2016). Stereo matching by training a convolutional neural network to compare image patches. Journal of Machine Learning Research , 17:1\u201332. Zeiler, M. D. and Fergus, R. (2014). Visualizing and understanding convolutional networks. InEuropean Conference on Computer Vision , pages 818\u2013833. Springer. Zeisl, B., Sattler, T., and Pollefeys, M. (2015). Camera pose voting for large-scale imagebased localization. In International Conference on Computer Vision (ICCV) . Zhang, C., Wang, L., and Yang, R. (2010). Semantic segmentation of urban scenes using dense depth maps. In European Conference on Computer Vision , pages 708\u2013721. Springer. Zhang, L. and Seitz, S. M. (2007). Estimating optimal parameters for MRF stereo from a single image pair. IEEE Transactions on Pattern Analysis and Machine Intelligence , 29(2):331\u2013342. Zhao, H., Shi, J., Qi, X., Wang, X., and Jia, J. (2017). Pyramid scene parsing network. In Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR) . Zheng, S., Jayasumana, S., Romera-Paredes, B., Vineet, V ., Su, Z., Du, D., Huang, C., and Torr, P. H. (2015). Conditional random fields as recurrent neural networks. In Proceedings of the IEEE International Conference on Computer Vision , pages 1529\u20131537. Zhou, B., Khosla, A., Lapedriza, A., Oliva, A., and Torralba, A. (2014a). Object detectors emerge in deep scene cnns. arXiv preprint arXiv:1412.6856 . Zhou, B., Lapedriza, A., Xiao, J., Torralba, A., and Oliva, A. (2014b). Learning deep features for scene recognition using places database. In Advances in Neural Information Processing Systems , pages 487\u2013495."
      },
      "Recurrent flow-guided semantic forecasting": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1809.08318",
        "ref_texts": "[50] F. Yu and V . Koltun. Multi-scale context aggregation by dilated convolutions. In International Conference on Learning Representations (ICLR) , 2016.[51] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In Computer Vision and Pattern Recognition (CVPR) , 2017.",
        "ref_ids": [
          "50",
          "51"
        ]
      },
      "Pyramid scene parsing network in 3D: Improving semantic segmentation of point clouds with multi-scale contextual information": {
        "authors": [],
        "url": "https://inria.hal.science/hal-02159279/file/elsarticle-template.pdf",
        "ref_texts": "3dmatch: Learning local geometric descriptors from rgb-d reconstructions, in: Proc. of Computer Vision and Pattern Recognition (CVPR). Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J., 2017. Pyramid scene parsing network, 620 in: Proc. of Computer Vision and Pattern Recognition (CVPR). Zhao, Y ., Birdal, T., Deng, H., Tombari, F., 2018. 3d point-capsule networks. arXiv preprint arXiv:1812.10775 . Zheng, S., Jayasumana, S., Romera-Paredes, B., Vineet, V ., Su, Z., Du, D., Huang, C., Torr, P.H., 2015. Conditional random fields as recurrent neural networks, 625 in: Proc. of International Conference on Computer Vision (ICCV)."
      },
      "ARTHuS: Adaptive real-time human segmentation in sports through online distillation": {
        "authors": [
          "Anthony Cioppa",
          "Adrien Deliege",
          "Maxime Istasse",
          "Christophe De",
          "Marc Van"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPRW_2019/papers/CVSports/Cioppa_ARTHuS_Adaptive_Real-Time_Human_Segmentation_in_Sports_Through_Online_Distillation_CVPRW_2019_paper.pdf",
        "ref_texts": "[32] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In IEEE Int. Conf. Comput. Vision and Pattern Recogn. (CVPR) , pages 6230\u20136239, Honolulu, HI, USA, July 2017.",
        "ref_ids": [
          "32"
        ]
      },
      "Multi-task deep relative attribute learning for visual urban perception": {
        "authors": [],
        "url": "http://123.57.42.89/foodcomputing/weiqingmin/Papers/Multi-Task%20Deep%20Relative%20Attribute%20Learning%20for%20Visual%20Urban%20Perception.pdf",
        "ref_texts": ""
      },
      "KE-GAN: Knowledge embedded generative adversarial networks for semi-supervised scene parsing": {
        "authors": [
          "Mengshi Qi",
          "Yunhong Wang",
          "Jie Qin",
          "Annan Li"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPR_2019/papers/Qi_KE-GAN_Knowledge_Embedded_Generative_Adversarial_Networks_for_Semi-Supervised_Scene_Parsing_CVPR_2019_paper.pdf",
        "ref_texts": "[46] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR . IEEE, 2017.",
        "ref_ids": [
          "46"
        ]
      },
      "Pyramid real image denoising network": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1908.00273",
        "ref_texts": "[10] H.-S Zhao, J.-P Shi, X.-J Qi, X.-G Wang, and J.-Y Jia, \u201cPyramid scene parsing network,\u201d in CVPR , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "10"
        ]
      },
      "Unsupervised domain adaptation for semantic segmentation of urban scenes": {
        "authors": [
          "Matteo Biasetton",
          "Umberto Michieli",
          "Gianluca Agresti",
          "Pietro Zanuttigh"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPRW_2019/papers/WAD/Biasetton_Unsupervised_Domain_Adaptation_for_Semantic_Segmentation_of_Urban_Scenes_CVPRW_2019_paper.pdf",
        "ref_texts": "[43] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. pages 2881\u20132890, 2017. 2",
        "ref_ids": [
          "43"
        ]
      },
      "A graph theoretic framework of recomputation algorithms for memory-efficient backpropagation": {
        "authors": [
          "Mitsuru Kusumoto",
          "Takuya Inoue",
          "Gentaro Watanabe",
          "Takuya Akiba",
          "Masanori Koyama"
        ],
        "url": "https://proceedings.neurips.cc/paper/2019/file/e555ebe0ce426f7f9b2bef0706315e0c-Paper.pdf",
        "ref_texts": "[20] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , pages 6230\u20136239, 2017.",
        "ref_ids": [
          "20"
        ]
      },
      "Budgeted training: Rethinking deep neural network training under resource constraints": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1905.04753",
        "ref_texts": "12 Published as a conference paper at ICLR 2020 Yu-Xiong Wang, Deva Ramanan, and Martial Hebert. Growing a brain: Fine-tuning by increasing model capacity. In CVPR , pp. 2471\u20132480, 2017. Ashia C Wilson, Rebecca Roelofs, Mitchell Stern, Nati Srebro, and Benjamin Recht. The marginal value of adaptive gradient methods in machine learning. In NIPS , pp. 4148\u20134158. 2017. Saining Xie and Zhuowen Tu. Holistically-nested edge detection. In ICCV , 2015. Zhichao Yin, Trevor Darrell, and Fisher Yu. Hierarchical discrete distribution decomposition for match density estimation. CVPR , 2019. Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. CVPR , pp. 6230\u20136239, 2017. Martin Zinkevich. Online convex programming and generalized infinitesimal gradient ascent. In ICML , pp. 928\u2013936, 2003. Barret Zoph and Quoc V . Le. Neural architecture search with reinforcement learning. ICLR , 2017."
      },
      "Preserving semantic and temporal consistency for unpaired video-to-video translation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1908.07683",
        "ref_texts": "[38] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. 2017. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition . 2881\u20132890.",
        "ref_ids": [
          "38"
        ]
      },
      "Tree-structured kronecker convolutional network for semantic segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1812.04945",
        "ref_texts": "[24] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017.",
        "ref_ids": [
          "24"
        ]
      },
      "Distance transform regression for spatially-aware deep semantic segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1909.01671",
        "ref_texts": "8078510. 2 S. Song, S. P. Lichtenberg, and J. Xiao. SUN RGB-D: A RGB-D scene understanding benchmark suite. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 567\u2013576, June 2015. doi: 10.1109/CVPR.2015.7298655. 7 Vladim\u00edr Ulman, Martin Maska, Klas E. G. Magnusson, Olaf Ronneberger, Carsten Haubold, Nathalie Harder, Pavel Matula, Petr Matula, 18 David Svoboda, Miroslav Radojevic, Ihor Smal, Karl Rohr, Joakim Jald\u00e9n, Helen M. Blau, Oleh Dzyubachyk, Boudewijn Lelieveldt, Pengdong Xiao, Yuexiang Li, Siu-Yeung Cho, Alexandre C. Dufour, Jean-Christophe Olivo-Marin, Constantino C. Reyes-Aldasoro, Jose A. Solis-Lemus, Robert Bensch, Thomas Brox, Johannes Stegmaier, Ralf Mikut, Steffen Wolf, Fred A. Hamprecht, Tiago Esteves, Pedro Quelhas, \u00d6mer Demirel, Lars Malmstr\u00f6m, Florian Jug, Pavel Tomancak, Erik Meijering, Arrate Mu\u00f1oz-Barrutia, Michal Kozubek, and Carlos Ortiz-de-Solorzano. An objective comparison of cell-tracking algorithms. Nature Methods , advance online publication, October 2017. ISSN 1548-7091. doi: 10.1038/nmeth.4473. 1, 2 J. Yang, B. Price, S. Cohen, H. Lee, and M. Yang. Object Contour Detection with a Fully Convolutional Encoder-Decoder Network. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , pages 193\u2013202, June 2016. doi: 10.1109/ CVPR.2016.28. 3 Q. Z. Ye. The signed Euclidean distance transform and its applications. In [1988 Proceedings] 9th International Conference on Pattern Recognition , pages 495\u2013499 vol.1, November 1988. doi: 10.1109/ICPR.1988.28276. 5 Fisher Yu and Vladlen Koltun. Multi-Scale Context Aggregation by Dilated Convolutions. In Proceedings of the International Conference on Learning Representations (ICLR) , November 2015. 2 Zhiding Yu, Chen Feng, Ming-Yu Liu, and Srikumar Ramalingam. CASENet: Deep Category-Aware Semantic Edge Detection. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 5964\u20135973, 2017. 3 F. d A. Zampirolli and L. Filipe. A Fast CUDA-Based Implementation for the Euclidean Distance Transform. In International Conference on High Performance Computing Simulation , pages 815\u2013818, July 2017. doi: 10.1109/HPCS.2017.123. 8 Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid Scene Parsing Network. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , pages 2881\u20132890, Honolulu, United States, July 2017. doi: 10.1109/CVPR.2017.660. 2, 7, 8, 12 Shuai Zheng, Sadeep Jayasumana, Bernardino Romera-Paredes, Vibhav Vineet, Zhizhong Su, Dalong Du, Chang Huang, and Philip H. S. Torr. Conditional Random Fields as Recurrent Neural Networks. In Proceedings of the IEEE International Conference on Computer Vision, pages 1529\u20131537, December 2015. doi: 10.1109/ICCV.2015.179. 1, 2, 3",
        "ref_ids": [
          "8078510"
        ]
      },
      "Real photographs denoising with noise domain adaptation and attentive generative adversarial network": {
        "authors": [
          "Kai Lin",
          "Thomas H. Li",
          "Shan Liu",
          "Ge Li"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPRW_2019/papers/NTIRE/Lin_Real_Photographs_Denoising_With_Noise_Domain_Adaptation_and_Attentive_Generative_CVPRW_2019_paper.pdf",
        "ref_texts": "[17] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. pages 6230\u20136239, 2016.",
        "ref_ids": [
          "17"
        ]
      },
      "An analysis of pre-training on object detection": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1904.05871",
        "ref_texts": "[59] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017. 2",
        "ref_ids": [
          "59"
        ]
      },
      "Visual-based semantic SLAM with landmarks for large-scale outdoor environment": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2001.01028",
        "ref_texts": "[3] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "3"
        ]
      },
      "Semantic segmentation of panoramic images using a synthetic dataset": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1909.00532",
        "ref_texts": "[15] Zhao, H., Shi, J., Qi, X., Wang, X., and Jia, J., \\Pyramid scene parsing network,\" in [The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) ], (July 2017).",
        "ref_ids": [
          "15"
        ]
      },
      "A parametric top-view representation of complex road scenes": {
        "authors": [
          "Ziyan Wang",
          "Buyu Liu",
          "Samuel Schulter",
          "Manmohan Chandraker"
        ],
        "url": "https://openaccess.thecvf.com/content_CVPR_2019/papers/Wang_A_Parametric_Top-View_Representation_of_Complex_Road_Scenes_CVPR_2019_paper.pdf",
        "ref_texts": "[33] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid Scene Parsing Network. In CVPR , 2017.",
        "ref_ids": [
          "33"
        ]
      },
      "An efficient 3D CNN for action/object segmentation in video": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1907.08895",
        "ref_texts": "[48] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "48"
        ]
      },
      "Disentangled makeup transfer with generative adversarial network": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1907.01144",
        "ref_texts": "[Zhao et al. , 2017 ]Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , pages 6230\u20136239, 2017.[Zhuet al. , 2017 ]Jun-Yan Zhu, Taesung Park, Phillip Isola, and Alexei A. Efros. Unpaired image-to-image translation using cycle-consistent adversarial networks. CoRR , abs/1703.10593, 2017.",
        "ref_ids": [
          "Zhao et al\\. , 2017 ",
          "Zhuet al\\. , 2017 "
        ]
      },
      "Urban semantic 3D reconstruction from multiview satellite imagery": {
        "authors": [
          "Matthew J. Leotta",
          "Chengjiang Long",
          "Bastien Jacquet",
          "Matthieu Zins",
          "Dan Lipsa",
          "Jie Shan",
          "Bo Xu",
          "Zhixin Li",
          "Xu Zhang",
          "Fu Chang",
          "Matthew Purri",
          "Jia Xue",
          "Kristin Dana"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPRW_2019/papers/EarthVision/Leotta_Urban_Semantic_3D_Reconstruction_From_Multiview_Satellite_Imagery_CVPRW_2019_paper.pdf",
        "ref_texts": "[46] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "46"
        ]
      },
      "Corse-to-fine road extraction based on local Dirichlet mixture models and multiscale-high-order deep learning": {
        "authors": [],
        "url": "https://www.uwaterloo.ca/geospatial-intelligence/sites/default/files/uploads/files/2019-chen-fan-zhong-li-du-wang-tits.pdf",
        "ref_texts": ""
      },
      "Context aware 3D CNNs for brain tumor segmentation": {
        "authors": [],
        "url": "https://inria.hal.science/hal-01959610/document",
        "ref_texts": "32. H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. CoRR , abs/1612.01105, 2016.",
        "ref_ids": [
          "32"
        ]
      },
      "You reap what you sow: Using videos to generate high precision object proposals for weakly-supervised object detection": {
        "authors": [
          "Krishna Kumar",
          "Yong Jae"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPR_2019/papers/Singh_You_Reap_What_You_Sow_Using_Videos_to_Generate_High_CVPR_2019_paper.pdf",
        "ref_texts": "[35] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017.",
        "ref_ids": [
          "35"
        ]
      },
      "Small obstacle avoidance based on RGB-D semantic segmentation": {
        "authors": [
          "Minjie Hua",
          "Yibing Nan",
          "Shiguo Lian"
        ],
        "url": "http://openaccess.thecvf.com/content_ICCVW_2019/papers/CVRSUAD/Hua_Small_Obstacle_Avoidance_Based_on_RGB-D_Semantic_Segmentation_ICCVW_2019_paper.pdf",
        "ref_texts": "[29] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "29"
        ]
      },
      "Semantic segmentation via highly fused convolutional network with multiple soft cost functions": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1801.01317",
        "ref_texts": "[34]. Zhao, Hengshuang., Jianping, Shi., Xiaojuan, Qi., Xiaogang, Wang., Jiaya, Jia.: Pyramid scene parsing network. arXiv preprint arXiv:1612.01105 (2016). ",
        "ref_ids": [
          "34"
        ]
      },
      "Veritatem dies aperit-temporally consistent depth prediction enabled by a multi-task geometric and semantic scene understanding approach": {
        "authors": [
          "Amir Atapour",
          "Toby P. Breckon"
        ],
        "url": "https://openaccess.thecvf.com/content_CVPR_2019/papers/Atapour-Abarghouei_Veritatem_Dies_Aperit_-_Temporally_Consistent_Depth_Prediction_Enabled_by_CVPR_2019_paper.pdf",
        "ref_texts": "[85] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In IEEE Conf. Computer Vision and Pattern Recognition , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "85"
        ]
      },
      "VIAN: A visual annotation tool for film analysis": {
        "authors": [],
        "url": "https://www.zora.uzh.ch/id/eprint/173590/1/vian_paper_final.pdf",
        "ref_texts": "[ZSQ\u221716] Z HAO H., S HIJ., Q IX., W ANG X., J IAJ.: Pyramid Scene Parsing Network. arXiv:1612.01105 [cs] (Dec. 2016). arXiv: 1612.01105. 6 c/circlecopyrt2019 The Author(s) Computer Graphics Forum c/circlecopyrt2019 The Eurographics Association and John Wiley & Sons Ltd.",
        "ref_ids": [
          "ZSQ\u221716",
          "cs"
        ]
      },
      "Deep convolutional encoder-decoders with aggregated multi-resolution skip connections for skin lesion segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1901.09197",
        "ref_texts": "[9] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia, \u201cPyramid scene parsing network,\u201d Proceedings 30th IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2017 , vol. 2017Janua, pp. 6230\u20136239, 2017.",
        "ref_ids": [
          "9"
        ]
      },
      "ThunderNet: A turbo unified network for real-time semantic segmentation": {
        "authors": [],
        "url": "https://crystal.uta.edu/~athitsos/publications/xiang_wacv2019.pdf",
        "ref_texts": "[30] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In IEEE Conf. on Computer Vision and Pattern Recognition (CVPR) , pages 2881\u20132890, 2017. 1, 2, 3, 5",
        "ref_ids": [
          "30"
        ]
      },
      "Semantic segmentation of fashion images using feature pyramid networks": {
        "authors": [
          "John Martinsson",
          "Olof Mogren"
        ],
        "url": "http://openaccess.thecvf.com/content_ICCVW_2019/papers/CVFAD/Martinsson_Semantic_Segmentation_of_Fashion_Images_Using_Feature_Pyramid_Networks_ICCVW_2019_paper.pdf",
        "ref_texts": "[14] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2881\u20132890, 2017. 2",
        "ref_ids": [
          "14"
        ]
      },
      "Multidepth: Single-image depth estimation via multi-task regression and classification": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1907.11111",
        "ref_texts": "[51] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. \u201cPyramid Scene Parsing Network\u201d. In: CVPR .",
        "ref_ids": [
          "51"
        ]
      },
      "A unified framework for mutual improvement of SLAM and semantic segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1812.10016",
        "ref_texts": "[18] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in IEEE Conf. on Computer Vision and Pattern Recognition (CVPR) , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "18"
        ]
      },
      "Single network panoptic segmentation for street scene understanding": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1902.02678",
        "ref_texts": "[7] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid Scene Parsing Network,\u201d in 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , July 2017, pp. 6230\u20136239.",
        "ref_ids": [
          "7"
        ]
      },
      "A spatial-aware joint optic disc and cup segmentation method": {
        "authors": [
          "Qing Liu"
        ],
        "url": "https://oulurepo.oulu.fi/bitstream/handle/10024/25351/nbnfi-fe2019091828627.pdf?sequence=1",
        "ref_texts": "[47] H. Zhao, J. Shi, X. Qi, X. Wang, J. Jia, Pyramid scene parsing network (2017) 2881\u20132890.",
        "ref_ids": [
          "47"
        ]
      },
      "A survey on deep learning techniques for image and video semantic segmentation": {
        "authors": [
          "Alberto Garcia"
        ],
        "url": "https://rua.ua.es/dspace/bitstream/10045/75753/3/2018_Garcia-Garcia_etal_ApplSoftComp_accepted.pdf",
        "ref_texts": "[82] H.Zhao, J.Shi, X.Qi, X.Wang, J.Jia, Pyramidsceneparsingnetwork, CoRR abs/1612.01105. URL http://arxiv.org/abs/1612.01105",
        "ref_ids": [
          "82"
        ]
      },
      "Planning and decision-making for autonomous vehicles": {
        "authors": [],
        "url": "https://autonomousrobots.nl/assets/files/publications/18-schwarting-AR.pdf",
        "ref_texts": "(57) and PSPNet (Pyramid Scene Parsing Network) (58), achieve more than 80% mIoU (mean intersection over union) in the Cityscapes data set (43) but take multiple seconds to propagateon high-resolution images, since they require a large number of floating-point operations. More recently, ENet (Efficient Neural Network) (59) achieved a 13-ms runtime on 1,024 \u00d72,048\u2013pixel images with 58% mIoU on the Cityscapes data set (43), while ICNet (Image Cascade Network) (60) achieved 70% mIoU at 33 ms. ICNet incorporates multiresolution branches under proper label guidance to combine low-resolution layers (from which it learns the representation and extracts themost semantic information) and higher-resolution layers while simultaneously preserving details."
      },
      "Encoder-decoder with atrous separable convolution for semantic image segmentation": {
        "authors": [
          "Chieh Chen",
          "Yukun Zhu",
          "George Papandreou",
          "Florian Schroff",
          "Hartwig Adam"
        ],
        "url": "http://openaccess.thecvf.com/content_ECCV_2018/papers/Liang-Chieh_Chen_Encoder-Decoder_with_Atrous_ECCV_2018_paper.pdf",
        "ref_texts": ""
      },
      "Path aggregation network for instance segmentation": {
        "authors": [
          "Shu Liu",
          "Lu Qi",
          "Haifang Qin",
          "Jianping Shi",
          "Jiaya Jia"
        ],
        "url": "https://openaccess.thecvf.com/content_cvpr_2018/papers/Liu_Path_Aggregation_Network_CVPR_2018_paper.pdf"
      },
      "High-resolution image synthesis and semantic manipulation with conditional gans": {
        "authors": [
          "Chun Wang",
          "Yu Liu",
          "Yan Zhu",
          "Andrew Tao",
          "Jan Kautz",
          "Bryan Catanzaro"
        ],
        "url": "https://openaccess.thecvf.com/content_cvpr_2018/papers/Wang_High-Resolution_Image_Synthesis_CVPR_2018_paper.pdf",
        "ref_texts": "[59] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2017. 6",
        "ref_ids": [
          "59"
        ]
      },
      "Bisenet: Bilateral segmentation network for real-time semantic segmentation": {
        "authors": [
          "Changqian Yu",
          "Jingbo Wang",
          "Chao Peng",
          "Changxin Gao",
          "Gang Yu",
          "Nong Sang"
        ],
        "url": "https://openaccess.thecvf.com/content_ECCV_2018/papers/Changqian_Yu_BiSeNet_Bilateral_Segmentation_ECCV_2018_paper.pdf",
        "ref_texts": ""
      },
      "Multi-task learning using uncertainty to weigh losses for scene geometry and semantics": {
        "authors": [
          "Alex Kendall",
          "Yarin Gal",
          "Roberto Cipolla"
        ],
        "url": "http://openaccess.thecvf.com/content_cvpr_2018/papers/Kendall_Multi-Task_Learning_Using_CVPR_2018_paper.pdf",
        "ref_texts": "[44] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. arXiv preprint arXiv:1612.01105 , 2016. 8",
        "ref_ids": [
          "44"
        ]
      },
      "Deep ordinal regression network for monocular depth estimation": {
        "authors": [
          "Huan Fu",
          "Mingming Gong",
          "Chaohui Wang",
          "Kayhan Batmanghelich",
          "Dacheng Tao"
        ],
        "url": "https://openaccess.thecvf.com/content_cvpr_2018/papers/Fu_Deep_Ordinal_Regression_CVPR_2018_paper.pdf",
        "ref_texts": "[61] Z. Zhang, A. G. Schwing, S. Fidler, and R. Urtasun. Monocular object instance segmentation and depth ordering with cnns. In ICCV , 2015. 2[62] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In CVPR , 2017. 2,3",
        "ref_ids": [
          "61",
          "62"
        ]
      },
      "Unified perceptual parsing for scene understanding": {
        "authors": [
          "Tete Xiao",
          "Yingcheng Liu",
          "Yuning Jiang",
          "Bolei Zhou",
          "Jian Sun"
        ],
        "url": "http://openaccess.thecvf.com/content_ECCV_2018/papers/Tete_Xiao_Unified_Perceptual_Parsing_ECCV_2018_paper.pdf",
        "ref_texts": ""
      },
      "Person transfer gan to bridge domain gap for person re-identification": {
        "authors": [
          "Longhui Wei",
          "Shiliang Zhang",
          "Wen Gao",
          "Qi Tian"
        ],
        "url": "https://openaccess.thecvf.com/content_cvpr_2018/papers/Wei_Person_Transfer_GAN_CVPR_2018_paper.pdf",
        "ref_texts": "[37] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In CVPR , 2017.",
        "ref_ids": [
          "37"
        ]
      },
      "Pyramid stereo matching network": {
        "authors": [
          "Ren Chang",
          "Sheng Chen"
        ],
        "url": "http://openaccess.thecvf.com/content_cvpr_2018/papers/Chang_Pyramid_Stereo_Matching_CVPR_2018_paper.pdf",
        "ref_texts": "[32] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , July 2017. 1,2,3, 4",
        "ref_ids": [
          "32"
        ]
      },
      "Unsupervised domain adaptation for semantic segmentation via class-balanced self-training": {
        "authors": [
          "Yang Zou",
          "Zhiding Yu",
          "Vijaya Kumar",
          "Jinsong Wang"
        ],
        "url": "http://openaccess.thecvf.com/content_ECCV_2018/papers/Yang_Zou_Unsupervised_Domain_Adaptation_ECCV_2018_paper.pdf",
        "ref_texts": ""
      },
      "Learning to adapt structured output space for semantic segmentation": {
        "authors": [
          "Hsuan Tsai",
          "Chih Hung",
          "Samuel Schulter",
          "Kihyuk Sohn",
          "Hsuan Yang",
          "Manmohan Chandraker"
        ],
        "url": "https://openaccess.thecvf.com/content_cvpr_2018/papers/Tsai_Learning_to_Adapt_CVPR_2018_paper.pdf",
        "ref_texts": "[40] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In CVPR , 2017. 1,2,4",
        "ref_ids": [
          "40"
        ]
      },
      "Exploring the limits of weakly supervised pretraining": {
        "authors": [
          "Dhruv Mahajan",
          "Ross Girshick",
          "Vignesh Ramanathan",
          "Kaiming He",
          "Manohar Paluri",
          "Yixuan Li",
          "Ashwin Bharambe"
        ],
        "url": "http://openaccess.thecvf.com/content_ECCV_2018/papers/Dhruv_Mahajan_Exploring_the_Limits_ECCV_2018_paper.pdf",
        "ref_texts": ""
      },
      "Denseaspp for semantic segmentation in street scenes": {
        "authors": [
          "Maoke Yang",
          "Kun Yu",
          "Chi Zhang",
          "Zhiwei Li",
          "Kuiyuan Yang"
        ],
        "url": "http://openaccess.thecvf.com/content_cvpr_2018/papers/Yang_DenseASPP_for_Semantic_CVPR_2018_paper.pdf",
        "ref_texts": "[24] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. arXiv preprint arXiv:1612.01105 , 2016.",
        "ref_ids": [
          "24"
        ]
      },
      "Context encoding for semantic segmentation": {
        "authors": [
          "Hang Zhang",
          "Kristin Dana",
          "Jianping Shi",
          "Zhongyue Zhang",
          "Xiaogang Wang",
          "Ambrish Tyagi",
          "Amit Agrawal"
        ],
        "url": "http://openaccess.thecvf.com/content_cvpr_2018/papers/Zhang_Context_Encoding_for_CVPR_2018_paper.pdf",
        "ref_texts": "[57] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2017. 2, 4,5,7",
        "ref_ids": [
          "57"
        ]
      },
      "Densepose: Dense human pose estimation in the wild": {
        "authors": [
          "Riza Alp",
          "Natalia Neverova",
          "Iasonas Kokkinos"
        ],
        "url": "https://openaccess.thecvf.com/content_cvpr_2018/papers/Guler_DensePose_Dense_Human_CVPR_2018_paper.pdf",
        "ref_texts": "[49] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2017. 7",
        "ref_ids": [
          "49"
        ]
      },
      "Icnet for real-time semantic segmentation on high-resolution images": {
        "authors": [
          "Hengshuang Zhao",
          "Xiaojuan Qi",
          "Xiaoyong Shen",
          "Jianping Shi",
          "Jia Jiaya"
        ],
        "url": "https://openaccess.thecvf.com/content_ECCV_2018/papers/Hengshuang_Zhao_ICNet_for_Real-Time_ECCV_2018_paper.pdf",
        "ref_texts": ""
      },
      "Multi-task learning as multi-objective optimization": {
        "authors": [
          "Ozan Sener",
          "Vladlen Koltun"
        ],
        "url": "https://proceedings.neurips.cc/paper_files/paper/2018/file/432aca3a1e345e339f35a30c8f65edce-Paper.pdf",
        "ref_texts": "11 Y. Yang and T. M. Hospedales. Trace norm regularised deep multi-task learning. arXiv:1606.04038 , 2016. A. R. Zamir, A. Sax, W. B. Shen, L. J. Guibas, J. Malik, and S. Savarese. Taskonomy: Disentangling task transfer learning. In CVPR , 2018. Y. Zhang and D. Yeung. A convex formulation for learning task relationships in multi-task learning. In UAI, 2010. H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In CVPR , 2017. B. Zhou, H. Zhao, X. Puig, S. Fidler, A. Barriuso, and A. Torralba. Scene parsing through ADE20K dataset. In CVPR , 2017a. D. Zhou, J. Wang, B. Jiang, H. Guo, and Y. Li. Multi-task multi-view learning based on cooperative multiobjective optimization. IEEE Access , 2017b. J. Zhou, J. Chen, and J. Ye. Clustered multi-task learning via alternating structure optimization. In NIPS , 2011a. J. Zhou, J. Chen, and J. Ye. MALSAR: Multi-task learning via structural regularization. Arizona State University , 2011b."
      },
      "Psanet: Point-wise spatial attention network for scene parsing": {
        "authors": [
          "Hengshuang Zhao",
          "Yi Z",
          "Shu Liu",
          "Jianping Shi",
          "Chen Change",
          "Dahua Lin",
          "Jia Jiaya"
        ],
        "url": "http://openaccess.thecvf.com/content_ECCV_2018/papers/Hengshuang_Zhao_PSANet_Point-wise_Spatial_ECCV_2018_paper.pdf",
        "ref_texts": ""
      },
      "Deep layer aggregation": {
        "authors": [
          "Fisher Yu",
          "Dequan Wang",
          "Evan Shelhamer",
          "Trevor Darrell"
        ],
        "url": "https://openaccess.thecvf.com/content_cvpr_2018/papers/Yu_Deep_Layer_Aggregation_CVPR_2018_paper.pdf",
        "ref_texts": "[48] M. D. Zeiler and R. Fergus. Visualizing and understanding convolutional networks. In ECCV , 2014. 1, 2[49] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. arXiv preprint arXiv:1612.01105 , 2016. 7",
        "ref_ids": [
          "48",
          "49"
        ]
      },
      "The apolloscape dataset for autonomous driving": {
        "authors": [
          "Xinyu Huang",
          "Xinjing Cheng",
          "Qichuan Geng",
          "Binbin Cao",
          "Dingfu Zhou",
          "Peng Wang",
          "Yuanqing Lin",
          "Ruigang Yang"
        ],
        "url": "http://openaccess.thecvf.com/content_cvpr_2018_workshops/papers/w14/Huang_The_ApolloScape_Dataset_CVPR_2018_paper.pdf",
        "ref_texts": ""
      },
      "Densely connected pyramid dehazing network": {
        "authors": [
          "He Zhang",
          "Vishal M. Patel"
        ],
        "url": "https://openaccess.thecvf.com/content_cvpr_2018/papers/Zhang_Densely_Connected_Pyramid_CVPR_2018_paper.pdf",
        "ref_texts": "[57] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. arXiv preprint arXiv:1612.01105 , 2016.",
        "ref_ids": [
          "57"
        ]
      },
      "Megadepth: Learning single-view depth prediction from internet photos": {
        "authors": [
          "Zhengqi Li",
          "Noah Snavely"
        ],
        "url": "https://openaccess.thecvf.com/content_cvpr_2018/papers/Li_MegaDepth_Learning_Single-View_CVPR_2018_paper.pdf",
        "ref_texts": "[41] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. Proc. Computer Vision and Pattern Recognition (CVPR) , 2017.",
        "ref_ids": [
          "41"
        ]
      },
      "Density-aware single image de-raining using a multi-stream dense network": {
        "authors": [
          "He Zhang",
          "Vishal M. Patel"
        ],
        "url": "http://openaccess.thecvf.com/content_cvpr_2018/papers/Zhang_Density-Aware_Single_Image_CVPR_2018_paper.pdf",
        "ref_texts": "[45] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In Proceedings of the IEEE International Conference on Computer Vision , pages 1\u20138, 2017.",
        "ref_ids": [
          "45"
        ]
      },
      "Espnet: Efficient spatial pyramid of dilated convolutions for semantic segmentation": {
        "authors": [
          "Sachin Mehta",
          "Mohammad Rastegari",
          "Anat Caspi",
          "Linda Shapiro",
          "Hannaneh Hajishirzi"
        ],
        "url": "http://openaccess.thecvf.com/content_ECCV_2018/papers/Sachin_Mehta_ESPNet_Efficient_Spatial_ECCV_2018_paper.pdf",
        "ref_texts": "1. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: CVPR. (2017)",
        "ref_ids": [
          "1"
        ]
      },
      "Semantic foggy scene understanding with synthetic data": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1708.07819",
        "ref_texts": "75. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: IEEE Conference on Computer Vision and Pattern Recognition (CVPR) (2017)",
        "ref_ids": [
          "75"
        ]
      },
      "Learning a discriminative feature network for semantic segmentation": {
        "authors": [
          "Changqian Yu",
          "Jingbo Wang",
          "Chao Peng",
          "Changxin Gao",
          "Gang Yu",
          "Nong Sang"
        ],
        "url": "https://openaccess.thecvf.com/content_cvpr_2018/papers/Yu_Learning_a_Discriminative_CVPR_2018_paper.pdf",
        "ref_texts": "[40] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In IEEE Conference on Computer Vision and Pattern Recognition , 2017. 1,2,3,8",
        "ref_ids": [
          "40"
        ]
      },
      "D-LinkNet: LinkNet with pretrained encoder and dilated convolution for high resolution satellite imagery road extraction": {
        "authors": [
          "Lichen Zhou",
          "Chuang Zhang",
          "Ming Wu"
        ],
        "url": "http://openaccess.thecvf.com/content_cvpr_2018_workshops/papers/w4/Zhou_D-LinkNet_LinkNet_With_CVPR_2018_paper.pdf",
        "ref_texts": "[25] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In IEEE Conf. on Computer Vision and Pattern Recognition (CVPR) , pages 2881\u20132890, 2017. 2",
        "ref_ids": [
          "25"
        ]
      },
      "Ocnet: Object context network for scene parsing": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1809.00916",
        "ref_texts": "Badrinarayanan V , Kendall A, Cipolla R (2017) Segnet: A deep convolutional encoder-decoder architecture for image segmentation. PAMI Caesar H, Uijlings J, Ferrari V (2018) Coco-stuff: Thing and stuff classes in context. In: CVPR Chen LC, Papandreou G, Schroff F, Adam H (2017) Rethinking atrous convolution for semantic image segmentation. arXiv:170605587 Chen LC, Papandreou G, Kokkinos I, Murphy K, Yuille AL (2018) Deeplab: Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected crfs. PAMI Cheng B, Chen LC, Wei Y , Zhu Y , Huang Z, Xiong J, Huang TS, Hwu WM, Shi H (2019) Spgnet: Semantic prediction guidance for scene parsing. In: Proceedings of the IEEE International Conference on Computer Vision, pp 5218\u20135228 Child R, Gray S, Radford A, Sutskever I (2019) Generating long sequences with sparse transformers. arXiv:190410509 Cordts M, Omran M, Ramos S, Rehfeld T, Enzweiler M, Benenson R, Franke U, Roth S, Schiele B (2016) The cityscapes dataset for semantic urban scene understanding. In: CVPR Ding H, Jiang X, Shuai B, Liu AQ, Wang G (2018) Context contrasted feature and gated multi-scale aggregation for scene segmentation. In: CVPR Ding H, Jiang X, Liu AQ, Thalmann NM, Wang G (2019a) Boundaryaware feature propagation for scene segmentation. In: Proceedings of the IEEE International Conference on Computer Vision, pp 6819\u20136829 Ding H, Jiang X, Shuai B, Liu AQ, Wang G (2019b) Semantic correlation promoted shape-variant context for segmentation. In: CVPR Divvala SK, Hoiem D, Hays JH, Efros AA, Hebert M (2009) An empirical study of context in object detection. In: CVPR Fu J, Liu J, Tian H, Fang Z, Lu H (2019a) Dual attention network for scene segmentation. In: CVPR Fu J, Liu J, Wang Y , Li Y , Bao Y , Tang J, Lu H (2019b) Adaptive context network for scene parsing. In: Proceedings of the IEEE international conference on computer vision, pp 6748\u20136757 Gong K, Liang X, Zhang D, Shen X, Lin L (2017) Look into person: Self-supervised structure-sensitive learning and a new benchmark for human parsing. In: CVPR Gonzalez-Garcia A, Modolo D, Ferrari V (2018) Objects as context for detecting their semantic parts. In: CVPR Greenspun P (1999) Philip and Alex\u2019s guide to Web publishing. Morgan Kaufmann He J, Deng Z, Zhou L, Wang Y , Qiao Y (2019) Adaptive pyramid context network for semantic segmentation. In: CVPR He K, Zhang X, Ren S, Sun J (2016) Deep residual learning for image recognition. In: CVPR He K, Gkioxari G, Doll \u00b4ar P, Girshick RB (2017) Mask R-CNN. In: ICCV Hoyer L, Munoz M, Katiyar P, Khoreva A, Fischer V (2019) Grid saliency for context explanations of semantic segmentation. In: NIPS Huang Z, Wang X, Huang L, Huang C, Wei Y , Liu W (2019) Ccnet: Criss-cross attention for semantic segmentation. In: ICCV Ioffe S, Szegedy C (2015) Batch normalization: Accelerating deep network training by reducing internal covariate shift. arXiv:150203167 Ke TW, Hwang JJ, Liu Z, Yu SX (2018) Adaptive affinity fields for semantic segmentation. In: ECCV Kong S, Fowlkes CC (2018) Recurrent scene parsing with perspective understanding in the loop. In: CVPR Krishna R, Zhu Y , Groth O, Johnson J, Hata K, Kravitz J, Chen S, Kalantidis Y , Li LJ, Shamma DA, et al. (2017) Visual genome: Connecting language and vision using crowdsourced dense image annotations. IJCVKuo W, Angelova A, Malik J, Lin TY (2019) Shapemask: Learning to segment novel objects by refining shape priors. In: ICCV Li X, Zhong Z, Wu J, Yang Y , Lin Z, Liu H (2019) Expectationmaximization attention networks for semantic segmentation. In: Proceedings of the IEEE International Conference on Computer Vision, pp 9167\u20139176 Li Y , Gupta A (2018) Beyond grids: Learning graph representations for visual recognition. In: NIPS Liang X, Gong K, Shen X, Lin L (2018a) Look into person: Joint body parsing & pose estimation network and a new benchmark. PAMI Liang X, Hu Z, Zhang H, Lin L, Xing EP (2018b) Symbolic graph reasoning meets convolutions. In: NIPS Liang X, Zhou H, Xing E (2018c) Dynamic-structured semantic propagation network. In: CVPR Lin G, Milan A, Shen C, Reid ID (2017a) Refinenet: Multi-path refinement networks for high-resolution semantic segmentation. In: CVPR Lin T, Doll \u00b4ar P, Girshick RB, He K, Hariharan B, Belongie SJ (2017b) Feature pyramid networks for object detection. In: CVPR Lin TY , Maire M, Belongie S, Hays J, Perona P, Ramanan D, Doll \u00b4ar P, Zitnick CL (2014) Microsoft coco: Common objects in context. In: ECCV Liu T, Ruan T, Huang Z, Wei Y , Wei S, Zhao Y , Huang T (2018) Devil in the details: Towards accurate single and multiple human parsing. arXiv:180905996 Liu W, Rabinovich A, Berg AC (2015) Parsenet: Looking wider to see better. arXiv:150604579 Long J, Shelhamer E, Darrell T (2015) Fully convolutional networks for semantic segmentation. In: CVPR Luo Y , Zheng Z, Zheng L, Tao G, Junqing Y , Yang Y (2018) Macromicro adversarial network for human parsing. In: ECCV Ma N, Zhang X, Zheng HT, Sun J (2018) Shufflenet v2: Practical guidelines for efficient cnn architecture design. In: ECCV Massa F, Girshick R (2018) maskrcnn-benchmark: Fast, modular reference implementation of Instance Segmentation and Object Detection algorithms in PyTorch. https://github.com/ facebookresearch/maskrcnn-benchmark Mottaghi R, Chen X, Liu X, Cho NG, Lee SW, Fidler S, Urtasun R, Yuille A (2014) The role of context for object detection and semantic segmentation in the wild. In: CVPR Nie X, Feng J, Yan S (2018) Mutual learning to adapt for joint human parsing and pose estimation. In: ECCV Pang Y , Li Y , Shen J, Shao L (2019) Towards bridging semantic gap to improve semantic segmentation. In: Proceedings of the IEEE International Conference on Computer Vision, pp 4230\u20134239 Roelofs G, Koman R (1999) PNG: the definitive guide. O\u2019Reilly & Associates, Inc. Ronneberger O, Fischer P, Brox T (2015) U-net: Convolutional networks for biomedical image segmentation. In: MICCAI Rota Bul `o S, Porzi L, Kontschieder P (2018) In-place activated batchnorm for memory-optimized training of dnns. In: CVPR Shen Z, Zhang M, Zhao H, Yi S, Li H (2018) Efficient attention: Attention with linear complexities. arXiv:181201243 Shetty R, Schiele B, Fritz M (2019) Not using the car to see the sidewalk\u2013quantifying and controlling the effects of context in classification and segmentation. In: CVPR Shuai B, Zuo Z, Wang B, Wang G (2017) Scene segmentation with dag-recurrent neural networks. PAMI Sun K, Xiao B, Liu D, Wang J (2019a) Deep high-resolution representation learning for human pose estimation. In: CVPR Sun K, Zhao Y , Jiang B, Cheng T, Xiao B, Liu D, Mu Y , Wang X, Liu W, Wang J (2019b) High-resolution representations for labeling pixels and regions. arXiv:190404514 Tian Z, He T, Shen C, Yan Y (2019) Decoders matter for semantic segmentation: Data-dependent decoding enables flexible feature aggregation. In: Proceedings of the IEEE Conference on Computer Vision OCNet: Object Context for Semantic Segmentation 19 and Pattern Recognition, pp 3126\u20133135 Vaswani A, Shazeer N, Parmar N, Uszkoreit J, Jones L, Gomez AN, Kaiser \u0141, Polosukhin I (2017) Attention is all you need. In: NIPS Wang P, Chen P, Yuan Y , Liu D, Huang Z, Hou X, Cottrell G (2018a) Understanding convolution for semantic segmentation. In: WACV Wang W, Zhang Z, Qi S, Shen J, Pang Y , Shao L (2019) Learning compositional neural information fusion for human parsing. In: Proceedings of the IEEE International Conference on Computer Vision, pp 5703\u20135713 Wang X, Girshick R, Gupta A, He K (2018b) Non-local neural networks. In: CVPR Wu T, Tang S, Zhang R, Cao J, Li J (2018) Tree-structured kronecker convolutional network for semantic segmentation. arXiv:181204945 Xiao T, Liu Y , Zhou B, Jiang Y , Sun J (2018) Unified perceptual parsing for scene understanding. In: ECCV Xie G, Wang J, Zhang T, Lai J, Hong R, Qi GJ (2018) Igcv 2: Interleaved structured sparse convolutional neural networks. arXiv:180406202 Yang M, Yu K, Zhang C, Li Z, Yang K (2018) Denseaspp for semantic segmentation in street scenes. In: CVPR Yu C, Wang J, Peng C, Gao C, Yu G, Sang N (2018a) Bisenet: Bilateral segmentation network for real-time semantic segmentation. In: ECCV Yu C, Wang J, Peng C, Gao C, Yu G, Sang N (2018b) Learning a discriminative feature network for semantic segmentation. In: CVPR Yu F, Koltun V (2016) Multi-scale context aggregation by dilated convolutions. In: ICLR Yuan Y , Chen X, Wang J (2019) Object-contextual representations for semantic segmentation. arXiv preprint arXiv:190911065 Yue K, Sun M, Yuan Y , Zhou F, Ding E, Xu F (2018) Compact generalized non-local network. In: NIPS Zhang F, Chen Y , Li Z, Hong Z, Liu J, Ma F, Han J, Ding E (2019a) Acfnet: Attentional class feature network for semantic segmentation. In: Proceedings of the IEEE International Conference on Computer Vision, pp 6798\u20136807 Zhang H, Dana K, Shi J, Zhang Z, Wang X, Tyagi A, Agrawal A (2018) Context encoding for semantic segmentation. In: CVPR Zhang H, Zhang H, Wang C, Xie J (2019b) Co-occurrent features in semantic segmentation. In: CVPR Zhang R, Tang S, Zhang Y , Li J, Yan S (2017a) Scale-adaptive convolutions for scene parsing. In: ICCV Zhang T, Qi GJ, Xiao B, Wang J (2017b) Interleaved group convolutions. In: ICCV Zhao H, Shi J, Qi X, Wang X, Jia J (2017) Pyramid scene parsing network. In: CVPR Zhao H, Yi Z, Shu L, Jianping S, Loy CC, Dahua L, Jia J (2018) Psanet: Point-wise spatial attention network for scene parsing. In: ECCV Zhou B, Zhao H, Puig X, Fidler S, Barriuso A, Torralba A (2017) Scene parsing through ade20k dataset. In: CVPR Zhou Z, Siddiquee MMR, Tajbakhsh N, Liang J (2018) Unet++: A nested u-net architecture for medical image segmentation. In: MICCAI Zhu Z, Xu M, Bai S, Huang T, Bai X (2019) Asymmetric non-local neural networks for semantic segmentation. In: ICCV Appendix A. More discussions on the benefits of object context . We give a further explanation on why we believe OC is superior to the previous two representation methods includingPPM (Zhao et al., 2017) and ASPP (Chen et al., 2017) as following: \u2013In theory, enhancing the object information in the context can decrease the variance of the context information, in other words, the context of PPM and ASPP suffers from larger variance than the OC context. Because the OC context only contains the variance of the fobject informationgwhile the context of PPM/ASPP further contains the variance of fobject information, useful background information, irrelevant background information g. The recent study (Hoyer et al., 2019; Shetty et al., 2019) has verified that the overuse of the noisy context information based on PPM suffers from poor generalization ability. For example, the \u201ccow\u201d pixels might be mis-classified as \u201chorse\u201d pixels when the \u201ccow\u201d appears on the road. We directly use the Fig. 10 from Hoyer et al."
      },
      "Mask textspotter: An end-to-end trainable neural network for spotting text with arbitrary shapes": {
        "authors": [
          "Pengyuan Lyu",
          "Minghui Liao",
          "Cong Yao",
          "Wenhao Wu",
          "Xiang Bai"
        ],
        "url": "https://openaccess.thecvf.com/content_ECCV_2018/papers/Pengyuan_Lyu_Mask_TextSpotter_An_ECCV_2018_paper.pdf",
        "ref_texts": ""
      },
      "A review of semantic segmentation using deep neural networks": {
        "authors": [
          "Yanming Guo"
        ],
        "url": "https://link.springer.com/content/pdf/10.1007/s13735-017-0141-z.pdf",
        "ref_texts": "47. Liu W, Rabinovich A, Berg AC (2016) Parsenet: Looking wider to see better. In: ICLR Workshop 48. Zhao H, Shi J, Qi X, Wang X, Jia J (2017) Pyramid scene parsing network. In: CVPR",
        "ref_ids": [
          "47"
        ]
      },
      "Sniper: Efficient multi-scale training": {
        "authors": [
          "Bharat Singh",
          "Mahyar Najibi",
          "Larry S. Davis"
        ],
        "url": "https://proceedings.neurips.cc/paper/2018/file/166cee72e93a992007a89b39eb29628b-Paper.pdf",
        "ref_texts": "[41] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In IEEE Conf. on Computer Vision and Pattern Recognition (CVPR) , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "41"
        ]
      },
      "Adversarial learning for semi-supervised semantic segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1802.07934",
        "ref_texts": ""
      },
      "A bi-directional message passing model for salient object detection": {
        "authors": [
          "Lu Zhang",
          "Ju Dai",
          "Huchuan Lu",
          "You He",
          "Gang Wang"
        ],
        "url": "https://openaccess.thecvf.com/content_cvpr_2018/papers/Zhang_A_Bi-Directional_Message_CVPR_2018_paper.pdf"
      },
      "Searching for efficient multi-scale architectures for dense image prediction": {
        "authors": [
          "Chieh Chen",
          "Maxwell Collins",
          "Yukun Zhu",
          "George Papandreou",
          "Barret Zoph",
          "Florian Schroff",
          "Hartwig Adam",
          "Jon Shlens"
        ],
        "url": "https://proceedings.neurips.cc/paper_files/paper/2018/file/c90070e1f03e982448983975a0f52d57-Paper.pdf",
        "ref_texts": "[97] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In CVPR , 2017.",
        "ref_ids": [
          "97"
        ]
      },
      "Measuring human perceptions of a large-scale urban region using machine learning": {
        "authors": [
          "Fan Zhang"
        ],
        "url": "http://bzhou.ie.cuhk.edu.hk/publication/landscape_urbanplanning.pdf",
        "ref_texts": "159 Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., ... Bernstein, M. (2015). Imagenet large scale visual recognition challenge. International Journal of Computer Vision, 115 (3), 211 \u2013252. Salesses, P., Schechtner, K., & Hidalgo, C. A. (2013). The collaborative image of the city: mapping the inequality of urban perception. PLoS ONE, 8 (7), e68400 . Schroeder, H. W., & Anderson, L. M. (1984). Perception of personal safety in urban recreation sites. Journal of Leisure Research, 16 (2), 178 . Short, J. R. (1984). An introduction to urban geography. London: Routledge & Kegan Paul . Skogan, W. G., & Max field, M. G. (1981). Coping with crime: Individual and neighborhood reactions. Sutskever, I., Vinyals, O., & Le, Q. V. (2014). Sequence to sequence learning with neural networks. Advances in Neural Information Processing Systems, 3104 \u20133112 . Taylor, R. B., Gottfredson, S. D., & Brower, S. (1984). Block crime and fear: Defensible space, local social ties, and territorial functioning. Journal of Research in Crime and Delinquency, 21 (4), 303 \u2013331. Tuan, Y.-F. (1977). Space and place: The perspective of experience. University of Minnesota Press . Ulrich, R. S. (1983). Aesthetic and a ffective response to natural environment. In Behavior and the natural environment. Springer pp. 85 \u2013125.Ulrich, R. S. (1984). View through a window may in fluence recovery from surgery. Science, 224 (4647), 420 \u2013421. Valtchanov, D., & Ellard, C. G. (2015). Cognitive and a ffective responses to natural scenes: e ffects of low level visual properties on preference, cognitive load and eyemovements. Journal of Environmental Psychology, 43 , 184 \u2013195. Wilson, J. Q., & Kelling, G. L. (1982). Broken windows. Atlantic Monthly, 249 (3), 29 \u201338. Wong, M. S., Nichol, J., & Ng, E. (2011). A study of the wall e ffect caused by proliferation of high-rise buildings using gis techniques. Landscape and Urban Planning, 102 (4), 245\u2013253. Zhang, F., Zhang, D., Liu, Y., & Lin, H. (2018). Representing place locales using scene elements. Computers, Environment and Urban Systems, 71 , 153 \u2013164. Zhao, H., Shi, J., Qi, X., Wang, X., & Jia, J. (2017). Pyramid scene parsing network. Proceedings of IEEE conference on computer vision and pattern recognition, 2881 \u20132890 . Zhou, B., Lapedriza, A., Khosla, A., Oliva, A., & Torralba, A. (2017). Places: A 10 million image database for scene recognition. IEEE Transactions on Pattern Analysis and Machine Intelligence . Zhou, B., Zhao, H., Puig, X., Fidler, S., Barriuso, A., & Torralba, A. (2017). Scene parsing through ADE20K dataset. Proceedings of the IEEE conference on computer vision and pattern recognition .F. Zhang et al. Landscape and Urban Planning 180 (2018) 148\u2013160"
      },
      "Pad-net: Multi-tasks guided prediction-and-distillation network for simultaneous depth estimation and scene parsing": {
        "authors": [
          "Dan Xu",
          "Wanli Ouyang",
          "Xiaogang Wang",
          "Nicu Sebe"
        ],
        "url": "https://openaccess.thecvf.com/content_cvpr_2018/papers/Xu_PAD-Net_Multi-Tasks_Guided_CVPR_2018_paper.pdf",
        "ref_texts": "[59] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. arXiv preprint arXiv:1612.01105 , 2016. 7",
        "ref_ids": [
          "59"
        ]
      },
      "Beyond RGB: Very high resolution urban remote sensing with multimodal deep networks": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1711.08681",
        "ref_texts": "[17] H. Zhao, J. Shi, X. Qi, X. Wang, J. Jia, Pyramid scene parsing network, in: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) Workshops, Honolulu, USA, 2017.",
        "ref_ids": [
          "17"
        ]
      },
      "Evaluating the robustness of neural networks: An extreme value theory approach": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1801.10578",
        "ref_texts": ""
      },
      "Stochastic adversarial video prediction": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1804.01523",
        "ref_texts": "54. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: Computer Vision and Pattern Recognition (CVPR). (2017)",
        "ref_ids": [
          "54"
        ]
      },
      "Efficient interactive annotation of segmentation datasets with polygon-rnn++": {
        "authors": [
          "David Acuna",
          "Huan Ling",
          "Amlan Kar",
          "Sanja Fidler"
        ],
        "url": "http://openaccess.thecvf.com/content_cvpr_2018/papers/Acuna_Efficient_Interactive_Annotation_CVPR_2018_paper.pdf",
        "ref_texts": "[40] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In CVPR , 2017.",
        "ref_ids": [
          "40"
        ]
      },
      "Deep extreme cut: From extreme points to object segmentation": {
        "authors": [
          "Kokitsi Maninis",
          "Sergi Caelles",
          "Jordi Pont",
          "Luc Van"
        ],
        "url": "http://openaccess.thecvf.com/content_cvpr_2018/papers/Maninis_Deep_Extreme_Cut_CVPR_2018_paper.pdf",
        "ref_texts": "[43] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In CVPR , 2017. 1,3,5,6,7",
        "ref_ids": [
          "43"
        ]
      },
      "Segstereo: Exploiting semantic information for disparity estimation": {
        "authors": [
          "Guorun Yang",
          "Hengshuang Zhao",
          "Jianping Shi",
          "Jia Jiaya"
        ],
        "url": "http://openaccess.thecvf.com/content_ECCV_2018/papers/Guorun_Yang_SegStereo_Exploiting_Semantic_ECCV_2018_paper.pdf",
        "ref_texts": ""
      },
      "Masklab: Instance segmentation by refining object detection with semantic and direction features": {
        "authors": [
          "Chieh Chen",
          "Alexander Hermans",
          "George Papandreou",
          "Florian Schroff",
          "Peng Wang",
          "Hartwig Adam"
        ],
        "url": "http://openaccess.thecvf.com/content_cvpr_2018/papers/Chen_MaskLab_Instance_Segmentation_CVPR_2018_paper.pdf",
        "ref_texts": "[79] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In CVPR , 2017.",
        "ref_ids": [
          "79"
        ]
      },
      "Context contrasted feature and gated multi-scale aggregation for scene segmentation": {
        "authors": [
          "Henghui Ding",
          "Xudong Jiang",
          "Bing Shuai",
          "Ai Qun",
          "Gang Wang"
        ],
        "url": "https://openaccess.thecvf.com/content_cvpr_2018/papers/Ding_Context_Contrasted_Feature_CVPR_2018_paper.pdf",
        "ref_texts": "[63] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , July 2017.",
        "ref_ids": [
          "63"
        ]
      },
      "Spacenet: A remote sensing dataset and challenge series": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1807.01232",
        "ref_texts": "[35] Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. CoRR abs/1612.01105 (2016)",
        "ref_ids": [
          "35"
        ]
      },
      "Instance-level human parsing via part grouping network": {
        "authors": [
          "Ke Gong",
          "Xiaodan Liang",
          "Yicheng Li",
          "Yimin Chen",
          "Liang Lin"
        ],
        "url": "https://openaccess.thecvf.com/content_ECCV_2018/papers/Ke_Gong_Instance-level_Human_Parsing_ECCV_2018_paper.pdf",
        "ref_texts": ""
      },
      "Fully convolutional adaptation networks for semantic segmentation": {
        "authors": [
          "Yiheng Zhang",
          "Zhaofan Qiu",
          "Ting Yao",
          "Dong Liu",
          "Tao Mei"
        ],
        "url": "http://openaccess.thecvf.com/content_cvpr_2018/papers/Zhang_Fully_Convolutional_Adaptation_CVPR_2018_paper.pdf",
        "ref_texts": "[37] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In CVPR , 2017.",
        "ref_ids": [
          "37"
        ]
      },
      "Generative adversarial perturbations": {
        "authors": [
          "Omid Poursaeed",
          "Isay Katsman",
          "Bicheng Gao",
          "Serge Belongie"
        ],
        "url": "https://openaccess.thecvf.com/content_cvpr_2018/papers/Poursaeed_Generative_Adversarial_Perturbations_CVPR_2018_paper.pdf",
        "ref_texts": "[60] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. arXiv preprint arXiv:1612.01105 , 2016. 1",
        "ref_ids": [
          "60"
        ]
      },
      "Pyramid dilated deeper convlstm for video salient object detection": {
        "authors": [
          "Hongmei Song",
          "Sanyuan Zhao",
          "Jianbing Shen",
          "Man Lam"
        ],
        "url": "http://openaccess.thecvf.com/content_ECCV_2018/papers/Hongmei_Song_Pseudo_Pyramid_Deeper_ECCV_2018_paper.pdf"
      },
      "Self-erasing network for integral object attention": {
        "authors": [
          "Qibin Hou",
          "Tao Jiang",
          "Yunchao Wei",
          "Ming Cheng"
        ],
        "url": "https://proceedings.neurips.cc/paper/2018/file/c042f4db68f23406c6cecf84a7ebb0fe-Paper.pdf",
        "ref_texts": "[40] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017.",
        "ref_ids": [
          "40"
        ]
      },
      "Parallel feature pyramid network for object detection": {
        "authors": [
          "Wook Kim",
          "Keun Kook",
          "Young Sun",
          "Cheon Kang",
          "Jea Ko"
        ],
        "url": "https://openaccess.thecvf.com/content_ECCV_2018/papers/Seung-Wook_Kim_Parallel_Feature_Pyramid_ECCV_2018_paper.pdf",
        "ref_texts": ""
      },
      "3d recurrent neural networks with context fusion for point cloud semantic segmentation": {
        "authors": [
          "Xiaoqing Ye",
          "Jiamao Li",
          "Hexiao Huang",
          "Xiaolin Zhang"
        ],
        "url": "http://openaccess.thecvf.com/content_ECCV_2018/papers/Xiaoqing_Ye_3D_Recurrent_Neural_ECCV_2018_paper.pdf",
        "ref_texts": ""
      },
      "Photographic text-to-image synthesis with a hierarchically-nested adversarial network": {
        "authors": [
          "Zizhao Zhang",
          "Yuanpu Xie",
          "Lin Yang"
        ],
        "url": "http://openaccess.thecvf.com/content_cvpr_2018/papers/Zhang_Photographic_Text-to-Image_Synthesis_CVPR_2018_paper.pdf",
        "ref_texts": "[50] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In CVPR , 2017. 2",
        "ref_ids": [
          "50"
        ]
      },
      "In-place activated batchnorm for memory-optimized training of dnns": {
        "authors": [
          "Samuel Rota",
          "Lorenzo Porzi",
          "Peter Kontschieder"
        ],
        "url": "https://openaccess.thecvf.com/content_cvpr_2018/papers/Bulo_In-Place_Activated_BatchNorm_CVPR_2018_paper.pdf",
        "ref_texts": "[33] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. CoRR , abs/1612.01105, 2016. 7",
        "ref_ids": [
          "33"
        ]
      },
      "Conditional generative adversarial network for structured domain adaptation": {
        "authors": [
          "Weixiang Hong",
          "Zhenzhen Wang",
          "Ming Yang",
          "Junsong Yuan"
        ],
        "url": "http://openaccess.thecvf.com/content_cvpr_2018/papers/Hong_Conditional_Generative_Adversarial_CVPR_2018_paper.pdf",
        "ref_texts": "[46] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , July 2017. 3",
        "ref_ids": [
          "46"
        ]
      },
      "Capsules for object segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1804.04241.pdf?fbclid=IwAR0-3o43guVH_yLCLbJpFj5KBGE-vNi8WUHgOmVOx3qU6rWx4NnURKofixM",
        "ref_texts": "2017. IEEE Computer Society Conference on , pages 4353\u20134361, 2017. Dzung L Pham, Chenyang Xu, and Jerry L Prince. Current methods in medical image segmentation. Annual review of biomedical engineering , 2(1):315\u2013337, 2000. Olaf Ronneberger, Philipp Fischer, and Thomas Brox. U-net: Convolutional networks for biomedical image segmentation. In International Conference on Medical image computing and computer-assisted intervention , pages 234\u2013241. Springer, 2015. Sara Sabour, Nicholas Frosst, and Geoffrey E Hinton. Dynamic routing between capsules. In Advances in Neural Information Processing Systems , pages 3859\u20133869, 2017. Jayaram K Udupa and Supun Samarasekera. Fuzzy connectedness and object definition: theory, algorithms, and applications in image segmentation. Graphical models and image processing , 58(3):246\u2013261, 1996. Eva M van Rikxoort, Bartjan de Hoop, Max A Viergever, Mathias Prokop, and Bram van Ginneken. Automatic lung segmentation from thoracic computed tomography scans using a hybrid approach with error detection. Medical physics , 36(7):2934\u20132947, 2009. Luminita A Vese and Tony F Chan. A multiphase level set framework for image segmentation using the mumford and shah model. International journal of computer vision , 50(3):271\u2013293, 2002. Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. InComputer Vision and Pattern Recognition, 2017. CVPR 2017. IEEE Computer Society Conference on , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "2017"
        ]
      },
      "Sparse and dense data with cnns: Depth completion and semantic segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1808.00769",
        "ref_texts": "[25] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "25"
        ]
      },
      "Explicit inductive bias for transfer learning with convolutional networks": {
        "authors": [
          "Xuhong L",
          "Yves G",
          "Franck D"
        ],
        "url": "http://proceedings.mlr.press/v80/li18a/li18a.pdf",
        "ref_texts": "(2):303\u2013338, 2010. Fei-Fei, L., Fergus, R., and Perona, P. One-shot learning of object categories. IEEE Trans. Pattern Anal. Mach. Intell. , 28(4):594\u2013611, 2006. Ge, W. and Yu, Y . Borrowing treasures from the wealthy: Deep transfer learning through selective joint fine-tuning. InCVPR , 2017. Girshick, R., Donahue, J., Darrell, T., and Malik, J. Rich feature hierarchies for accurate object detection and semantic segmentation. In CVPR , 2014.Grachten, M. and Chac \u00b4on, C. E. C. Strategies for conceptual change in convolutional neural networks. arXiv preprint arXiv:1711.01634 , 2017. Griffin, G., Holub, A., and Perona, P. Caltech-256 object category dataset. Technical report, California Institute of Technology, 2007. He, K., Zhang, X., Ren, S., and Sun, J. Deep residual learning for image recognition. In CVPR , 2016. Khosla, A., Jayadevaprakash, N., Yao, B., and Li, F.-F. Novel dataset for fine-grained image categorization: Stanford dogs. In Proc. CVPR Workshop on Fine-Grained Visual Categorization (FGVC) , 2011. Kirkpatrick, J., Pascanu, R., Rabinowitz, N., Veness, J., Desjardins, G., Rusu, A. A., Milan, K., Quan, J., Ramalho, T., Grabska-Barwinska, A., et al. Overcoming catastrophic forgetting in neural networks. Proc. Natl. Acad. Sci. U.S.A. , 2017. Krizhevsky, A., Sutskever, I., and Hinton, G. E. Imagenet classification with deep convolutional neural networks. InNIPS , 2012. Lehmann, E. L. and Casella, G. Theory of point estimation . Springer, 2 edition, 1998. Li, Z. and Hoiem, D. Learning without forgetting. IEEE Trans. Pattern Anal. Mach. Intell. , 2017. doi: 10.1109/ TPAMI.2017.2773081. Liao, H. Speaker adaptation of context dependent deep neural networks. In ICASSP , 2013. Long, J., Shelhamer, E., and Darrell, T. Fully convolutional networks for semantic segmentation. In CVPR , 2015a. Long, M., Cao, Y ., Wang, J., and Jordan, M. Learning transferable features with deep adaptation networks. In ICML , 2015b. Ochiai, T., Matsuda, S., Lu, X., Hori, C., and Katagiri, S. Speaker adaptive training using deep neural networks. In ICASSP , 2014. Pan, S. J. and Yang, Q. A survey on transfer learning. IEEE T. Knowl. Data En. , 22(10):1345\u20131359, 2010. Pentina, A. and Lampert, C. H. Lifelong learning with non-iid tasks. In NIPS , 2015. Quattoni, A. and Torralba, A. Recognizing indoor scenes. InCVPR , 2009. Redmon, J., Divvala, S., Girshick, R., and Farhadi, A. You only look once: Unified, real-time object detection. In CVPR , 2016. Explicit Inductive Bias for Transfer Learning with Convolutional Networks Ren, S., He, K., Girshick, R., and Sun, J. Faster r-cnn: Towards real-time object detection with region proposal networks. In NIPS , 2015. Rozantsev, A., Salzmann, M., and Fua, P. Beyond sharing weights for deep domain adaptation. arXiv preprint arXiv:1603.06432 , 2016. Simonyan, K. and Zisserman, A. Very deep convolutional networks for large-scale image recognition. In ICLR , 2015. Szegedy, C., Vanhoucke, V ., Ioffe, S., Shlens, J., and Wojna, Z. Rethinking the inception architecture for computer vision. In CVPR , 2016. Thrun, S. and Mitchell, T. M. Lifelong robot learning. Robot. Auton. Syst. , 15(1-2):25\u201346, 1995. Tommasi, T., Orabona, F., and Caputo, B. Learning categories from few examples with multi model knowledge transfer. IEEE Trans. Pattern Anal. Mach. Intell. , 2014. Yang, J., Yan, R., and Hauptmann, A. G. Adapting svm classifiers to data with shifted distributions. In ICDM Workshops , 2007. Yosinski, J., Clune, J., Bengio, Y ., and Lipson, H. How transferable are features in deep neural networks? In NIPS , 2014. Zeiler, M. D. and Fergus, R. Visualizing and understanding convolutional networks. In ECCV , 2014. Zhao, H., Shi, J., Qi, X., Wang, X., and Jia, J. Pyramid scene parsing network. In CVPR , 2017. Zhou, B., Lapedriza, A., Khosla, A., Oliva, A., and Torralba, A. Places: A 10 million image database for scene recognition. IEEE Trans. Pattern Anal. Mach. Intell. , 2017."
      },
      "Toward driving scene understanding: A dataset for learning driver behavior and causal reasoning": {
        "authors": [
          "Vasili Ramanishka",
          "Ting Chen",
          "Teruhisa Misu",
          "Kate Saenko"
        ],
        "url": "https://openaccess.thecvf.com/content_cvpr_2018/papers/Ramanishka_Toward_Driving_Scene_CVPR_2018_paper.pdf",
        "ref_texts": "[35] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid Scene Parsing Network. In CVPR , 2017. 1,2",
        "ref_ids": [
          "35"
        ]
      },
      "On the robustness of semantic segmentation models to adversarial attacks": {
        "authors": [
          "Anurag Arnab",
          "Ondrej Miksik",
          "Philip H"
        ],
        "url": "http://openaccess.thecvf.com/content_cvpr_2018/papers/Arnab_On_the_Robustness_CVPR_2018_paper.pdf",
        "ref_texts": "[67] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In CVPR , 2017. 1,2,4,5,6",
        "ref_ids": [
          "67"
        ]
      },
      "Road: Reality oriented adaptation for semantic segmentation of urban scenes": {
        "authors": [
          "Yuhua Chen",
          "Wen Li",
          "Luc Van"
        ],
        "url": "https://openaccess.thecvf.com/content_cvpr_2018/papers/Chen_ROAD_Reality_Oriented_CVPR_2018_paper.pdf",
        "ref_texts": "[50] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. arXiv:1612.01105 , 2016. 2,3,5",
        "ref_ids": [
          "50"
        ]
      },
      "Dcan: Dual channel-wise alignment networks for unsupervised scene adaptation": {
        "authors": [
          "Zuxuan Wu",
          "Xintong Han",
          "Liang Lin",
          "Gokhan Uzunbas",
          "Tom Goldstein",
          "Nam Lim",
          "Larry Davis"
        ],
        "url": "https://openaccess.thecvf.com/content_ECCV_2018/papers/Zuxuan_Wu_DCAN_Dual_Channel-wise_ECCV_2018_paper.pdf",
        "ref_texts": ""
      },
      "In defense of classical image processing: Fast depth completion on the cpu": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1802.00036",
        "ref_texts": "[3] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. arXiv preprint arXiv:1612.01105 , 2016. 1",
        "ref_ids": [
          "3"
        ]
      },
      "Fully convolutional networks for semantic segmentation of very high resolution remotely sensed images combined with DSM": {
        "authors": [],
        "url": "https://prism.ucalgary.ca/bitstreams/4ea81049-7181-40b0-95e8-32abc92dfd26/download",
        "ref_texts": "[83] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In IEEE Conf. on Computer Vision and Pattern Recognition (CVPR) , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "83"
        ]
      },
      "Bidirectional feature pyramid network with recurrent attention residual modules for shadow detection": {
        "authors": [
          "Lei Zhu",
          "Zijun Deng",
          "Xiaowei Hu",
          "Wing Fu",
          "Xuemiao Xu",
          "Jing Qin",
          "Ann Heng"
        ],
        "url": "http://openaccess.thecvf.com/content_ECCV_2018/papers/Lei_Zhu_Bi-directional_Feature_Pyramid_ECCV_2018_paper.pdf"
      },
      "Evaluating bayesian deep learning methods for semantic segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1811.12709",
        "ref_texts": "[68] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In IEEE Conf. on Computer Vision and Pattern Recognition (CVPR) , pages 2881\u20132890, 2017. 1, 3 Appendices A. Bayesian DeepLab Network Architecture In Figure 7, we present the network architecture of Bayesian DeepLab using MC dropout inference. We use Xception as the base network. However, there are certain differences between the original Xception [14] architecture and the one which we use. The differences are as follows: 1. There are no pooling layers in our network. We use separable convolution filters with a stride of 2 instead of max pooling layers. This helps in dense predictions. Furthermore, following the FCN [47] philosophy, our network is fully convolutional and hence can segment images of arbitrary sizes.",
        "ref_ids": [
          "68",
          "14",
          "47"
        ]
      },
      "Contextnet: Exploring context and detail for semantic segmentation in real-time": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1805.04554",
        "ref_texts": "7. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid Scene Parsing Network. In: CVPR. (2017)",
        "ref_ids": [
          "7"
        ]
      },
      "Model adaptation with synthetic and real data for semantic dense foggy scene understanding": {
        "authors": [
          "Christos Sakaridis",
          "Luc Van"
        ],
        "url": "http://openaccess.thecvf.com/content_ECCV_2018/papers/Christos_Sakaridis_Semantic_Scene_Understanding_ECCV_2018_paper.pdf",
        "ref_texts": ""
      },
      "Effective use of dilated convolutions for segmenting small object instances in remote sensing imagery": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1709.00179",
        "ref_texts": "[7] H. Zhao, J. Sh i, X. Qi, X. Wang, and J. Jia . Pyramid Scene Parsing Network . arXiv preprint arXiv:1612.01105 . 2016. ",
        "ref_ids": [
          "7"
        ]
      },
      "Differentiable learning-to-normalize via switchable normalization": {
        "authors": [],
        "url": "https://openreview.net/pdf?id=ryggIs0cYQ",
        "ref_texts": "9 Published as a conference paper at ICLR 2019 Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton. Imagenet classification with deep convolutional neural networks. In NIPS , 2012. Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva Ramanan, Piotr Doll \u00b4ar, and C Lawrence Zitnick. Microsoft coco: Common objects in context. In European conference on computer vision , pp. 740\u2013755. Springer, 2014. Tsung-Yi Lin, Piotr Dollra, Ross Girshick, Kaiming He, Bharath Hariharan, and Serge Belongie. Feature pyramid networks for object detection. arXiv:1612.03144 , 2016. Hanxiao Liu, Karen Simonyan, and Yiming Yang. Darts: Differentiable architecture search. arXiv:1806.09055 , 2018. Ping Luo. Eigennet: Towards fast and structural learning of deep neural networks. IJCAI , 2017a. Ping Luo. Learning deep architectures via generalized whitened neural networks. ICML , 2017b. Ping Luo, Zhanglin Peng, Jiamin Ren, and Ruimao Zhang. Do normalization layers in a deep convnet really need to be distinct? arXiv:1811.07727 , 2018. Ping Luo, Xinjiang Wang, Wenqi Shao, and Zhanglin Peng. Towards understanding regularization in batch normalization. ICLR , 2019. Xingang Pan, Xiaohang Zhan, Jianping Shi, Xiaoou Tang, and Ping Luo. Switchable whitening for deep representation learning. In arXiv:1904.09739 , 2019. Chao Peng, Tete Xiao, Zeming Li, Yuning Jiang, Xiangyu Zhang, Kai Jia, Gang Yu, and Jian Sun. Megdet: A large mini-batch object detector. arXiv:1711.07240 , 2017. Ethan Perez, Harm de Vries, and Florian Strub. Learning visual reasoning without strong priors. In arXiv:1707.03017 , 2017. Hieu Pham, Melody Y . Guan, Barret Zoph, Quoc V . Le, and Jeff Dean. Efficient neural architecture search via parameter sharing. arXiv:1802.03268 , 2018. Mengye Ren, Renjie Liao, Raquel Urtasun, Fabian H. Sinz, and Richard S. Zemel. Normalizing the normalizers: Comparing and extending network normalization schemes. In ICLR , 2016. Shaoqing Ren, Kaiming He, Ross Girshick, and Jian Sun. Faster r-cnn: Towards real-time object detection with region proposal networks. arXiv:1506.01497 , 2015. Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma, Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael Bernstein, et al. Imagenet large scale visual recognition challenge. International Journal of Computer Vision , 115(3):211\u2013252, 2015. Tim Salimans and Diederik P. Kingma. Weight normalization: A simple reparameterization to accelerate training of deep neural networks. arXiv:1602.07868 , 2016. Wenqi Shao, Tianjian Meng, Jingyu Li, Ruimao Zhang, Yudian Li, Xiaogang Wang, and Ping Luo. Ssn: Learning sparse switchable normalization via sparsestmax. In CVPR , 2019. Karen Simonyan and Andrew Zisserman. Very deep convolutional networks for large-scale image recognition. arXiv:1409.1556 , 2014. Dmitry Ulyanov, Andrea Vedaldi, and Victor Lempitsky. Instance normalization: The missing ingredient for fast stylization. arXiv:1607.08022 , 2016. Guangrun Wang, Jiefeng Peng, Ping Luo, Xinjiang Wang, and Liang Lin. Batch kalman normalization: Towards training deep neural networks with micro-batches. NIPS , 2018. Ronald J. Williams. Simple statistical gradient-following algorithms for connectionist reinforcement learning. Machine Learning , 1992. Yuxin Wu and Kaiming He. Group normalization. arXiv:1803.08494 , 2018. Jianwei Yang, Jiasen Lu, Dhruv Batra, and Devi Parikh. A faster pytorch implementation of faster r-cnn. https://github.com/jwyang/faster-rcnn.pytorch , 2017. Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. InCVPR , 2017. Bolei Zhou, Hang Zhao, Xavier Puig, Sanja Fidler, Adela Barriuso, and Antonio Torralba. Scene parsing through ADE20K dataset. In CVPR , 2017."
      },
      "Mapping sky, tree, and building view factors of street canyons in a high-density urban environment": {
        "authors": [
          "Ying Gong"
        ],
        "url": "https://xiaojianggis.github.io/li/pdf/built_environment.pdf",
        "ref_texts": "[49] H. Zhao, J. Shi, X. Qi, X. Wang, J. Jia, Pyramid scene parsing network, ArXiv161201105 Cs (Dec. 2016) .",
        "ref_ids": [
          "49"
        ]
      },
      "Single-image svbrdf capture with a rendering-aware deep network": {
        "authors": [],
        "url": "https://dl.acm.org/doi/pdf/10.1145/3197517.3201378",
        "ref_texts": "2016. Minimal BRDF Sampling for Two-shot Near-field Reflectance Acquisition. ACM Transactions on Graphics (Proc. SIGGRAPH Asia) 35, 6 (2016). Richard Zhang, Jun-Yan Zhu, Phillip Isola, Xinyang Geng, Angela S Lin, Tianhe Yu, and Alexei A Efros. 2017b. Real-Time User-Guided Image Colorization with Learned Deep Priors. ACM Transactions on Graphics (Proc. SIGGRAPH) 9, 4 (2017). Yinda Zhang, Shuran Song, Ersin Yumer, Manolis Savva, Joon-Young Lee, Hailin Jin, and Thomas A. Funkhouser. 2017a. Physically-Based Rendering for Indoor Scene ACM Transactions on Graphics, Vol. 37, No. 4, Article 128. Publication date: August 2018. Single-Image SVBRDF Capture with a Rendering-Aware Deep Network \u2022128:15 Understanding Using Convolutional Neural Networks. In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) . Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. 2017. Pyramid Scene Parsing Network. In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) . T. Zickler, R. Ramamoorthi, S. Enrique, and P. N. Belhumeur. 2006. Reflectance sharing: predicting appearance from a sparse set of images of a known shape. IEEE Transactions on Pattern Analysis and Machine Intelligence 28, 8 (2006). ACM Transactions on Graphics, Vol. 37, No. 4, Article 128. Publication date: August 2018.",
        "ref_ids": [
          "2016"
        ]
      },
      "Semantic labeling in very high resolution images via a self-cascaded convolutional neural network": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1807.11236",
        "ref_texts": "23 Silberman, N., Hoiem, D., Kohli, P., Fergus, R., 2012. Indoor segmentation and support inference from rgbd images. In: European Conference on Computer Vision. pp. 746\u2013760. Simonyan, K., Zisserman, A., 2015. Very deep convolutional networks for large-scale image recognition. In: International Conference on Learning Representations. pp. 1\u201314. Srivastava, N., Hinton, G. E., Krizhevsky, A., Sutskever, I., Salakhutdinov, R., 2014. Dropout: a simple way to prevent neural networks from overfitting. Journal of Machine Learning Research. 15 (1), 1929\u20131958. V olpi, M., Tuia, D., 2017. Dense semantic labeling of subdecimeter resolution images with convolutional neural networks. IEEE Transactions on Geoscience and Remote Sensing. 55 (2), 881\u2013893. Wen, D., Huang, X., Liu, H., Liao, W., Zhang, L., 2017. Semantic classification of urban trees using very high resolution satellite imagery. IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing. 10 (4), 1413\u20131424. Xie, M., Jean, N., Burke, M., Lobell, D., Ermon, S., 2015. Transfer learning from deep features for remote sensing and poverty mapping. arXiv preprint arXiv:1510.00098. Xu, X., Li, J., Huang, X., Mura, M. D., Plaza, A., 2016. Multiple morphological component analysis based decomposition for remote sensing image classification. IEEE Transactions on Geoscience and Remote Sensing. 54 (5), 3083\u20133102. Xue, Z., Li, J., Cheng, L., Du, P., 2015. Spectralspatial classification of hyperspectral data via morphological component analysis-based image separation. IEEE Transactions on Geoscience and Remote Sensing. 53 (1), 70\u201384. Yosinski, J., Clune, J., Bengio, Y ., Lipson, H., 2014. How transferable are features in deep neural networks. In: Neural Information Processing Systems. pp. 3320\u20133328. Yu, F., Koltun, V ., 2016. Multi-scale context aggregation by dilated convolutions. In: International Conference on Learning Representations. Yuan, Y ., Mou, L., Lu, X., 2015. Scene recognition by manifold regularized deep learning architecture. IEEE Transactions on Neural Networks and Learning Systems. 26 (10), 2222\u20132233. Zeiler, M. D., Fergus, R., 2014. Visualizing and understanding convolutional networks. In: European Conference on Computer Vision. pp. 818\u2013833. Zeiler, M. D., Krishnan, D., Taylor, G. W., Fergus, R., 2010. Deconvolutional networks. In: IEEE Conference on Computer Vision and Pattern Recognition. pp. 2528\u20132535. Zhang, C., Pan, X., Li, H., Gardiner, A., Sargent, I., Hare, J., Atkinson, P. M., 2017. A hybrid mlp-cnn classifier for very fine resolution remotely sensed image classification. ISPRS Journal of Photogrammetry and Remote Sensing. pp, 1\u201312. Zhang, L., Zhang, L., Tao, D., Huang, X., 2012. On combining multiple features for hyperspectral remote sensing image classification. IEEE Transactions on Geoscience and Remote Sensing. 50 (3), 879\u2013893. Zhang, P., Gong, M., Su, L., Liu, J., Li, Z., 2016. Change detection based on deep feature representation and mapping transformation for multi-spatial-resolution remote sensing images. ISPRS Journal of Photogrammetry and Remote Sensing. 116, 24\u201341. Zhang, Q., Seto, K. C., 2011. Mapping urbanization dynamics at regional and global scales using multi-temporal dmsp/ols nighttime light data. Remote Sensing of Environment 115 (9), 2320\u20132329. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J., 2016. Pyramid scene parsing network. arXiv preprint arXiv:1612.01105. Zhao, W., Du, S., 2016. Learning multiscale and deep representations for classifying remotely sensed imagery. ISPRS Journal of Photogrammetry and Remote Sensing. 113, 155\u2013165. Zhou, B., Khosla, A., Lapedriza, A., Oliva, A., , Torralba, A., 2015. Object detectors emerge in deep scene cnns. In: International Conference on Learning Representations."
      },
      "Where are the blobs: Counting by localization with point supervision": {
        "authors": [
          "Issam Hadj",
          "Negar Rostamzadeh",
          "Pedro Pinheiro",
          "David Vazquez",
          "Mark Schmidt"
        ],
        "url": "http://openaccess.thecvf.com/content_ECCV_2018/papers/Issam_Hadj_Laradji_Where_are_the_ECCV_2018_paper.pdf",
        "ref_texts": ""
      },
      "Beyond grids: Learning graph representations for visual recognition": {
        "authors": [
          "Yin Li",
          "Abhinav Gupta"
        ],
        "url": "https://proceedings.neurips.cc/paper_files/paper/2018/file/4efb80f630ccecb2d3b9b2087b0f9c89-Paper.pdf",
        "ref_texts": "[13] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017.",
        "ref_ids": [
          "13"
        ]
      },
      "Sbnet: Sparse blocks network for fast inference": {
        "authors": [
          "Mengye Ren",
          "Andrei Pokrovsky",
          "Bin Yang",
          "Raquel Urtasun"
        ],
        "url": "https://openaccess.thecvf.com/content_cvpr_2018/papers/Ren_SBNet_Sparse_Blocks_CVPR_2018_paper.pdf",
        "ref_texts": "[38] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2017.",
        "ref_ids": [
          "38"
        ]
      },
      "Direction-aware spatial context features for shadow detection": {
        "authors": [
          "Xiaowei Hu",
          "Lei Zhu",
          "Wing Fu",
          "Jing Qin",
          "Ann Heng"
        ],
        "url": "http://openaccess.thecvf.com/content_cvpr_2018/papers/Hu_Direction-Aware_Spatial_Context_CVPR_2018_paper.pdf"
      },
      "Y-Net: joint segmentation and classification for diagnosis of breast biopsy images": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1806.01313",
        "ref_texts": "12. Zhao et al.: Pyramid scene parsing network. In: CVPR (2017)",
        "ref_ids": [
          "12"
        ]
      },
      "Planenet: Piece-wise planar reconstruction from a single rgb image": {
        "authors": [
          "Chen Liu",
          "Jimei Yang",
          "Duygu Ceylan",
          "Ersin Yumer",
          "Yasutaka Furukawa"
        ],
        "url": "https://openaccess.thecvf.com/content_cvpr_2018/papers/Liu_PlaneNet_Piece-Wise_Planar_CVPR_2018_paper.pdf",
        "ref_texts": "[43] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. arXiv preprint arXiv:1612.01105 , 2016. 3",
        "ref_ids": [
          "43"
        ]
      },
      "Video object segmentation with joint re-identification and attention-aware mask propagation": {
        "authors": [
          "Xiaoxiao Li",
          "Chen Change"
        ],
        "url": "http://openaccess.thecvf.com/content_ECCV_2018/papers/Xiaoxiao_Li_Video_Object_Segmentation_ECCV_2018_paper.pdf",
        "ref_texts": "40. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: CVPR (2017)",
        "ref_ids": [
          "40"
        ]
      },
      "Hsa-rnn: Hierarchical structure-adaptive rnn for video summarization": {
        "authors": [
          "Bin Zhao",
          "Xuelong Li",
          "Xiaoqiang Lu"
        ],
        "url": "http://openaccess.thecvf.com/content_cvpr_2018/papers/Zhao_HSA-RNN_Hierarchical_Structure-Adaptive_CVPR_2018_paper.pdf",
        "ref_texts": ""
      },
      "Adaptive affinity fields for semantic segmentation": {
        "authors": [
          "Jing Hwang",
          "Wei Ke",
          "Ziwei Liu",
          "Stella Yu"
        ],
        "url": "http://openaccess.thecvf.com/content_ECCV_2018/papers/Jyh-Jing_Hwang_Adaptive_Affinity_Field_ECCV_2018_paper.pdf",
        "ref_texts": "36. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: CVPR (2017)",
        "ref_ids": [
          "36"
        ]
      },
      "Smoothed dilated convolutions for improved dense prediction": {
        "authors": [
          "Zhengyang Wang",
          "Shuiwang Ji"
        ],
        "url": "https://dl.acm.org/doi/pdf/10.1145/3219819.3219944",
        "ref_texts": "[31] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. 2016. Pyramid scene parsing network. arXiv preprint arXiv:1612.01105 (2016). Research Track Paper KDD 2018, August 19\u201223, 2018, London, United Kingdom 2495 ",
        "ref_ids": [
          "31"
        ]
      },
      "Ipod: Intensive point-based object detector for point cloud": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1812.05276",
        "ref_texts": "[34] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In CVPR , 2017.",
        "ref_ids": [
          "34"
        ]
      },
      "Monocular relative depth perception with web stereo data supervision": {
        "authors": [
          "Ke Xian",
          "Chunhua Shen",
          "Zhiguo Cao",
          "Hao Lu",
          "Yang Xiao",
          "Ruibo Li",
          "Zhenbo Luo"
        ],
        "url": "https://openaccess.thecvf.com/content_cvpr_2018/papers/Xian_Monocular_Relative_Depth_CVPR_2018_paper.pdf",
        "ref_texts": "[45] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proc. IEEE Conf. Comp. Vis. Patt. Recogn. , 2017. 4",
        "ref_ids": [
          "45"
        ]
      },
      "Distortion-aware convolutional filters for dense prediction in panoramic images": {
        "authors": [
          "Keisuke Tateno",
          "Nassir Navab",
          "Federico Tombari"
        ],
        "url": "http://openaccess.thecvf.com/content_ECCV_2018/papers/Keisuke_Tateno_Distortion-Aware_Convolutional_Filters_ECCV_2018_paper.pdf",
        "ref_texts": "30. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: In Proc. Int. Conf. Computer Vision and Pattern Recognition (CVPR) (2017)",
        "ref_ids": [
          "30"
        ]
      },
      "Referring image segmentation via recurrent refinement networks": {
        "authors": [
          "Ruiyu Li",
          "Kaican Li",
          "Chun Kuo",
          "Michelle Shu",
          "Xiaojuan Qi",
          "Xiaoyong Shen",
          "Jiaya Jia"
        ],
        "url": "https://openaccess.thecvf.com/content_cvpr_2018/papers/Li_Referring_Image_Segmentation_CVPR_2018_paper.pdf",
        "ref_texts": "[35] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In CVPR , 2017. 1,2",
        "ref_ids": [
          "35"
        ]
      },
      "Semantic video segmentation by gated recurrent flow propagation": {
        "authors": [
          "David Nilsson",
          "Cristian Sminchisescu"
        ],
        "url": "https://openaccess.thecvf.com/content_cvpr_2018/papers/Nilsson_Semantic_Video_Segmentation_CVPR_2018_paper.pdf"
      },
      "Weakly-and semi-supervised panoptic segmentation": {
        "authors": [
          "Anurag Arnab",
          "Philip Torr",
          "Qizhu Li"
        ],
        "url": "https://openaccess.thecvf.com/content_ECCV_2018/papers/Anurag_Arnab_Weakly-_and_Semi-Supervised_ECCV_2018_paper.pdf",
        "ref_texts": "59. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: CVPR. (2017)",
        "ref_ids": [
          "59"
        ]
      },
      "Symbolic graph reasoning meets convolutions": {
        "authors": [
          "Xiaodan Liang",
          "Zhiting Hu",
          "Hao Zhang",
          "Liang Lin",
          "Eric P. Xing"
        ],
        "url": "https://proceedings.neurips.cc/paper_files/paper/2018/file/cbb6a3b884f4f88b3a8e3d44c636cbd8-Paper.pdf",
        "ref_texts": "[50] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In CVPR , 2017. 7",
        "ref_ids": [
          "50"
        ]
      },
      "Key-word-aware network for referring expression image segmentation": {
        "authors": [
          "Hengcan Shi",
          "Hongliang Li",
          "Fanman Meng",
          "Qingbo Wu"
        ],
        "url": "https://openaccess.thecvf.com/content_ECCV_2018/papers/Hengcan_Shi_Key-Word-Aware_Network_for_ECCV_2018_paper.pdf",
        "ref_texts": ""
      },
      "Effective use of synthetic data for urban scene semantic segmentation": {
        "authors": [
          "Fatemeh Sadat",
          "Mohammad Sadegh",
          "Mathieu Salzmann",
          "Lars Petersson",
          "Jose Manuel"
        ],
        "url": "http://openaccess.thecvf.com/content_ECCV_2018/papers/Fatemeh_Sadat_Saleh_Effective_Use_of_ECCV_2018_paper.pdf",
        "ref_texts": ""
      },
      "Lego: Learning edge with geometry all at once by watching videos": {
        "authors": [
          "Zhenheng Yang",
          "Peng Wang",
          "Yang Wang",
          "Wei Xu",
          "Ram Nevatia"
        ],
        "url": "http://openaccess.thecvf.com/content_cvpr_2018/papers/Yang_LEGO_Learning_Edge_CVPR_2018_paper.pdf"
      },
      "Light-weight refinenet for real-time semantic segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1810.03272",
        "ref_texts": "[77] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017.",
        "ref_ids": [
          "77"
        ]
      },
      "Semantic human matting": {
        "authors": [
          "Quan Chen",
          "Tiezheng Ge",
          "Yanyu Xu",
          "Zhiqiang Zhang",
          "Xinxin Yang",
          "Kun Gai"
        ],
        "url": "https://arxiv.org/pdf/1809.01354",
        "ref_texts": ""
      },
      "Low-latency video semantic segmentation": {
        "authors": [
          "Yule Li",
          "Jianping Shi",
          "Dahua Lin"
        ],
        "url": "https://openaccess.thecvf.com/content_cvpr_2018/papers/Li_Low-Latency_Video_Semantic_CVPR_2018_paper.pdf"
      },
      "Linknet: Relational embedding for scene graph": {
        "authors": [
          "Sanghyun Woo",
          "Dahun Kim",
          "Donghyeon Cho",
          "In So"
        ],
        "url": "https://proceedings.neurips.cc/paper_files/paper/2018/file/58238e9ae2dd305d79c2ebc8c1883422-Paper.pdf",
        "ref_texts": "[39] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proc. of Computer Vision and Pattern Recognition (CVPR) , 2017.",
        "ref_ids": [
          "39"
        ]
      },
      "ISLES 2016 and 2017-benchmarking ischemic stroke lesion outcome prediction based on multispectral MRI": {
        "authors": [
          "Stefan Winzeck",
          "Mauricio Reyes"
        ],
        "url": "https://www.frontiersin.org/articles/10.3389/fneur.2018.00679/pdf",
        "ref_texts": "19. Zhao H, Shi J, Qi X, Wang X, Jia J. Pyramid scene parsing network. In :IEEE Conference on Computer Vision and Pattern Recognition (CVPR ). Honolulu (2017)p.2881\u201390.",
        "ref_ids": [
          "19"
        ]
      },
      "ChangeNet: A deep learning architecture for visual change detection": {
        "authors": [
          "Ashley Varghese",
          "Jayavardhana Gubbi",
          "Akshaya Ramaswamy"
        ],
        "url": "http://openaccess.thecvf.com/content_ECCVW_2018/papers/11130/Varghese_ChangeNet_A_Deep_Learning_Architecture_for_Visual_Change_Detection_ECCVW_2018_paper.pdf",
        "ref_texts": "28. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. arXiv preprint arXiv:1612.01105 (2016)",
        "ref_ids": [
          "28"
        ]
      },
      "A comparative study of real-time semantic segmentation for autonomous driving": {
        "authors": [
          "Mennatullah Siam",
          "Mostafa Gamal",
          "Moemen Abdel",
          "Senthil Yogamani",
          "Martin Jagersand",
          "Hong Zhang"
        ],
        "url": "http://openaccess.thecvf.com/content_cvpr_2018_workshops/papers/w12/Siam_A_Comparative_Study_CVPR_2018_paper.pdf",
        "ref_texts": "[64] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In IEEE Conf. on Computer Vision and Pattern Recognition (CVPR) , pages 2881\u2013",
        "ref_ids": [
          "64"
        ]
      },
      "Semi-parametric image synthesis": {
        "authors": [
          "Xiaojuan Qi",
          "Qifeng Chen",
          "Jiaya Jia",
          "Vladlen Koltun"
        ],
        "url": "https://openaccess.thecvf.com/content_cvpr_2018/papers/Qi_Semi-Parametric_Image_Synthesis_CVPR_2018_paper.pdf",
        "ref_texts": "[38] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In CVPR , 2017. 6,7",
        "ref_ids": [
          "38"
        ]
      },
      "Rsgan: face swapping and editing using face and hair representation in latent spaces": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1804.03447",
        "ref_texts": "37. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid Scene Parsing Network. arXiv preprint arXiv:1612.01105 (2016)",
        "ref_ids": [
          "37"
        ]
      },
      "Multi-scale single image dehazing using perceptual pyramid deep network": {
        "authors": [
          "He Zhang",
          "Vishwanath Sindagi",
          "Vishal M. Patel"
        ],
        "url": "http://openaccess.thecvf.com/content_cvpr_2018_workshops/papers/w13/Zhang_Multi-Scale_Single_Image_CVPR_2018_paper.pdf",
        "ref_texts": "[58] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In IEEE Conf. on Computer Vision and Pattern Recognition (CVPR) , pages 2881\u20132890, 2017. 2,4",
        "ref_ids": [
          "58"
        ]
      },
      "Recurrent pixel embedding for instance grouping": {
        "authors": [
          "Shu Kong",
          "Charless C. Fowlkes"
        ],
        "url": "http://openaccess.thecvf.com/content_cvpr_2018/papers/Kong_Recurrent_Pixel_Embedding_CVPR_2018_paper.pdf",
        "ref_texts": "[91] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on Computer Vision and Pattern Recognition (CVPR) , 2016.",
        "ref_ids": [
          "91"
        ]
      },
      "Modanet: A large-scale street fashion dataset with polygon annotations": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1807.01394.pdf?fbclid=IwAR0mPKOx0DThGV49lZQcgBUbjClg0QoVB1tQyV2d4UfKw6P0NPMLWXbM-FE",
        "ref_texts": ""
      },
      "Semantic match consistency for long-term visual localization": {
        "authors": [
          "Carl Toft",
          "Erik Stenborg",
          "Lars Hammarstrand",
          "Lucas Brynte",
          "Marc Pollefeys",
          "Torsten Sattler",
          "Fredrik Kahl"
        ],
        "url": "http://openaccess.thecvf.com/content_ECCV_2018/papers/Carl_Toft_Semantic_Match_Consistency_ECCV_2018_paper.pdf",
        "ref_texts": ""
      },
      "Pointseg: Real-time semantic segmentation based on 3d lidar point cloud": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1807.06288",
        "ref_texts": "[5] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in IEEE Conf. on Computer Vision and Pattern Recognition (CVPR) , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "5"
        ]
      },
      "Learning intrinsic image decomposition from watching the world": {
        "authors": [
          "Zhengqi Li",
          "Noah Snavely"
        ],
        "url": "https://openaccess.thecvf.com/content_cvpr_2018/papers/Li_Learning_Intrinsic_Image_CVPR_2018_paper.pdf",
        "ref_texts": "[38] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. Proc. Computer Vision and Pattern Recognition (CVPR) , 2017.",
        "ref_ids": [
          "38"
        ]
      },
      "Unsupervised video object segmentation with motion-based bilateral networks": {
        "authors": [
          "Siyang Li",
          "Bryan Seybold",
          "Alexey Vorobyov",
          "Xuejing Lei",
          "Jay Kuo"
        ],
        "url": "https://openaccess.thecvf.com/content_ECCV_2018/papers/Siyang_Li_Unsupervised_Video_Object_ECCV_2018_paper.pdf",
        "ref_texts": ""
      },
      "3d anisotropic hybrid network: Transferring convolutional features from 2d images to 3d anisotropic volumes": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1711.08580",
        "ref_texts": "[23] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid Scene Parsing Network. 12 2016. A. Visual Cases of the DBT dataset We selected some example slices from the DBT dataset to demonstrate the advantage of our proposed AH-Net for the Breast cancer screening. From Fig. 8 to Fig. 12, we show slices from five test DBT volumes that both the MCGCN and the proposed 3D AH-Net could successfully detect the suspected breast lesion. The original DBT slice is 9 shown on the left with the lesion annotated by our radiologist. Please note the original annotation is a 3D box. The figures in the middle and on the right are response maps from MC-GCN and 3D AH-Net overlaid on the original image, respectively. The detection locations obtained with non-maximal suppression are displayed with cross markers. As shown in the images, the proposed network can detect breast lesions varying in sizes and appearances. The confidence of the 3D AH-Net is usually higher than that of MC-GCN. From Fig. 13 to Fig. 17, we show five volumes that MC-GCN failed to detect the lesions since the lesions were not distinguishable from other breast tissues using the information within the slice. In contrast, 3D AH-Net was able to detect the lesions from such volumes using the 3D context between slices. As shown in Fig. 18 to Fig. 22, there are also volumes with lesions that both network failed to detect. Such lesions normally reside in the dense breast tissues. The boundary between these lesions and the normal breast tissues usually have low contrast. The networks sometimes also confuse them with other roundish structures in the breast such as lymph nodes or skin moles. Figure 8. Example DBT slice 1 with a lesion that can be detected by both MC-GCN and 3D AH-Net. Though the lesion is blended in the dense breast tissues, our network is able to detect it according to the speculations around the lesion boundary. B. Liver Tumor Segmentation Challenge We show 9 example sagittal slices from the LITS challenge test set in Fig. 23 to demonstrate the variation of both livers and liver lesions. The images are cropped to the region with liver centered. The sizes and shapes of the livers vary a lot between individuals. The variation of liver lesion in sizes and intensities is even higher. The lesions are highly sparse in the abdominal CT images. Thus it is challenging for the networks to segment the lesions with small sizes. Please note that we do not have the ground truth of the test volumes. Three example volumes are selected from the test image set to demonstrate the effectiveness of our proposed netFigure 9. Example DBT slice 2 with a lesion that can be detected by both MC-GCN and 3D AH-Net. The lesion is small and can also be identified with the architectural distortion in the surrounding tissues. Figure 10. Example DBT slice 3 with a lesion that can be detected by both MC-GCN and 3D AH-Net. The lesion is blended in the dense breast tissues. work in Fig. 24, Fig. 25 and Fig. 26. Although we do not have the groundtruth label maps for the testing images, the liver boundaries and the presence of lesions can be visually inspected. The liver lesions normally appear as a dark region within the liver. Without sufficient 3D context, MCGCN tends to generate false positive regions at the structure boundaries, especially under low image contrast. From the sagittal and coronal views, it is visible that MC-GCN could not generate the correct boundaries close to the top or the bottom of the lesion. By considering the consistency between slices, 3D AH-Net can segment the structures in 3D correctly, although the feature extraction network is transferred from a 2D network. The jagged boundary in the sagittal and coronal view is due to the low resolution in the z direction.",
        "ref_ids": [
          "23"
        ]
      },
      "SLSDeep: Skin lesion segmentation based on dilated residual and pyramid pooling networks": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1805.10241",
        "ref_texts": "27. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: IEEE Conf. CVPR. pp. 2881{2890 (2017)",
        "ref_ids": [
          "27"
        ]
      },
      "Holistic 3d scene parsing and reconstruction from a single rgb image": {
        "authors": [
          "Siyuan Huang",
          "Siyuan Qi",
          "Yixin Zhu",
          "Yinxue Xiao",
          "Yuanlu Xu",
          "Chun Zhu"
        ],
        "url": "http://openaccess.thecvf.com/content_ECCV_2018/papers/Siyuan_Huang_Monocular_Scene_Parsing_ECCV_2018_paper.pdf",
        "ref_texts": ""
      },
      "Visual feature attribution using wasserstein gans": {
        "authors": [
          "Christian F. Baumgartner",
          "Lisa M. Koch",
          "Kerem Can",
          "Jia Xi",
          "Ender Konukoglu"
        ],
        "url": "http://openaccess.thecvf.com/content_cvpr_2018/papers/Baumgartner_Visual_Feature_Attribution_CVPR_2018_paper.pdf",
        "ref_texts": ""
      },
      "Semantic soft segmentation": {
        "authors": [],
        "url": "https://dl.acm.org/doi/pdf/10.1145/3197517.3201275",
        "ref_texts": "(2017), 19:1\u201319:19. Xiaobo An and Fabio Pellacini. 2008. AppProp: All-pairs Appearance-space Edit Propagation. ACM Trans. Graph. 27, 3 (2008), 40:1\u201340:9. R. Barrett, M. Berry, T. Chan, J. Demmel, J. Donato, J. Dongarra, V. Eijkhout, R. Pozo, C. Romine, and H. van der Vorst. 1994. Templates for the Solution of Linear Systems: Building Blocks for Iterative Methods . SIAM. Gedas Bertasius, Jianbo Shi, and Lorenzo Torresani. 2015. High-for-low and low-forhigh: Efficient boundary detection from deep object features and its applications to high-level vision. In Proc. ICCV . Gedas Bertasius, Jianbo Shi, and Lorenzo Torresani. 2016. Semantic Segmentation with Boundary Neural Fields. In Proc. CVPR . V. Bychkovsky, S. Paris, E. Chan, and F. Durand. 2011. Learning Photographic Global Tonal Adjustment with a Database of Input/Output Image Pairs. In Proc. CVPR . Holger Caesar, Jasper Uijlings, and Vittorio Ferrari. 2016. COCO-Stuff: Thing and Stuff Classes in Context. arXiv:1612.03716 [cs.CV] (2016).Liang-Chieh Chen, George Papandreou, Iasonas Kokkinos, Kevin Murphy, and Alan L Yuille. 2017. DeepLab: Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Connected CRFs. IEEE Trans. Pattern Anal. Mach. Intell. (2017). Qifeng Chen, Dingzeyu Li, and Chi-Keung Tang. 2013. KNN Matting. IEEE Trans. Pattern Anal. Mach. Intell. 35, 9 (2013), 2175\u20132188. Xiaowu Chen, Dongqing Zou, Qinping Zhao, and Ping Tan. 2012. Manifold Preserving Edit Propagation. ACM Trans. Graph. 31, 6 (2012), 132:1\u2013132:7. Yuki Endo, Satoshi Iizuka, Yoshihiro Kanamori, and Jun Mitani. 2016. DeepProp: Extracting Deep Features from a Single Image for Edit Propagation. Comput. Graph. Forum 35, 2 (2016), 189\u2013201. D. Eynard, A. Kovnatsky, and M. M. Bronstein. 2014. Laplacian colormaps: a framework for structure-preserving color transformations. Comput. Graph. Forum 33, 2 (2014), 215\u2013224. H. Farid and E. P. Simoncelli. 2004. Differentiation of discrete multidimensional signals. IEEE Trans. Image Process. 13, 4 (2004), 496\u2013508. Alireza Fathi, Zbigniew Wojna, Vivek Rathod, Peng Wang, Hyun Oh Song, Sergio Guadarrama, and Kevin P. Murphy. 2017. Semantic Instance Segmentation via Deep Metric Learning. arXiv:1703.10277 [cs.CV] (2017). Bharath Hariharan, Pablo Arbel\u00e1ez, Ross Girshick, and Jitendra Malik. 2015. Hypercolumns for object segmentation and fine-grained localization. In Proc. CVPR . Kaiming He, Georgia Gkioxari, Piotr Dollar, and Ross Girshick. 2017. Mask R-CNN. In Proc. ICCV . Kaiming He, Jian Sun, and Xiaoou Tang. 2013. Guided Image Filtering. IEEE Trans. Pattern Anal. Mach. Intell. 35, 6 (2013), 1397\u20131409. Elad Hoffer and Nir Ailon. 2015. Deep metric learning using triplet network. In International Workshop on Similarity-Based Pattern Recognition . Anat Levin, Dani Lischinski, and Yair Weiss. 2008a. A Closed-Form Solution to Natural Image Matting. IEEE Trans. Pattern Anal. Mach. Intell. 30, 2 (2008), 228\u2013242. Anat Levin, Alex Rav-Acha, and Dani Lischinski. 2008b. Spectral Matting. IEEE Trans. Pattern Anal. Mach. Intell. 30, 10 (2008), 1699\u20131712. Y. Li, E. Adelson, and A. Agarwala. 2008. ScribbleBoost: Adding Classification to EdgeAware Interpolation of Local Image and Video Adjustments. Comput. Graph. Forum 27, 4 (2008), 1255\u20131264. Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva Ramanan, Piotr Doll\u00e1r, and C Lawrence Zitnick. 2014. Microsoft COCO: Common objects in context. In Proc. ECCV . Tae-Hyun Oh, Kyungdon Joo, Neel Joshi, Baoyuan Wang, In So Kweon, and Sing Bing Kang. 2017. Personalized Cinemagraphs Using Semantic Understanding and Collaborative Learning. In Proc. ICCV . S. Qin, S. Kim, and R. Manduchi. 2017. Automatic skin and hair masking using fully convolutional networks. In Proc. ICME . Wenqi Ren, Jinshan Pan, Xiaochun Cao, and Ming-Hsuan Yang. 2017. Video Deblurring via Semantic Segmentation and Pixel-Wise Non-Linear Kernel. In Proc. ICCV . Christoph Rhemann, Carsten Rother, Jue Wang, Margrit Gelautz, Pushmeet Kohli, and Pamela Rott. 2009. A Perceptually Motivated Online Benchmark for Image Matting. InProc. CVPR . Xiaoyong Shen, Xin Tao, Hongyun Gao, Chao Zhou, and Jiaya Jia. 2016. Deep Automatic Portrait Matting. In Proc. ECCV . D. Singaraju and R. Vidal. 2011. Estimation of Alpha Mattes for Multiple Image Layers. IEEE Trans. Pattern Anal. Mach. Intell. 33, 7 (2011), 1295\u20131309. Kihyuk Sohn. 2016. Improved deep metric learning with multi-class N-pair loss objective. InProc. NIPS . Yu-Wing Tai, Jiaya Jia, and Chi-Keung Tang. 2007. Soft Color Segmentation and Its Applications. IEEE Trans. Pattern Anal. Mach. Intell. 29, 9 (2007), 1520\u20131537. Jianchao Tan, Jyh-Ming Lien, and Yotam Gingold. 2016. Decomposing Images into Layers via RGB-space Geometry. ACM Trans. Graph. 36, 1 (2016), 7:1\u20137:14. Ning Xu, Brian Price, Scott Cohen, and Thomas Huang. 2017. Deep Image Matting. In Proc. CVPR . Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. 2017. Pyramid Scene Parsing Network. In Proc. CVPR . Received January 2018; final version May 2018; accepted May 2018 ACM Trans. Graph., Vol. 37, No. 4, Article 72. Publication date: August 2018."
      },
      "Dynamic-structured semantic propagation network": {
        "authors": [
          "Xiaodan Liang",
          "Hongfei Zhou",
          "Eric Xing"
        ],
        "url": "http://openaccess.thecvf.com/content_cvpr_2018/papers/Liang_Dynamic-Structured_Semantic_Propagation_CVPR_2018_paper.pdf"
      },
      "Vision-based real estate price estimation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1707.05489",
        "ref_texts": "[31] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In IEEE Conf. on Computer Vision and Pattern Recognition (CVPR) , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "31"
        ]
      },
      "Semantic aware attention based deep object co-segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1804.06423",
        "ref_texts": "46. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: CVPR (2017)",
        "ref_ids": [
          "46"
        ]
      },
      "Dense decoder shortcut connections for single-pass semantic segmentation": {
        "authors": [
          "Piotr Bilinski",
          "Victor Prisacariu"
        ],
        "url": "https://openaccess.thecvf.com/content_cvpr_2018/papers/Bilinski_Dense_Decoder_Shortcut_CVPR_2018_paper.pdf",
        "ref_texts": "[54] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid Scene Parsing Network. In CVPR , 2017.",
        "ref_ids": [
          "54"
        ]
      },
      "Dynamic video segmentation network": {
        "authors": [
          "Syuan Xu",
          "Jui Fu",
          "Kung Yang",
          "Yi Lee"
        ],
        "url": "http://openaccess.thecvf.com/content_cvpr_2018/papers/Xu_Dynamic_Video_Segmentation_CVPR_2018_paper.pdf",
        "ref_texts": "[8] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proc. IEEE Conf. Computer Vision and Pattern Recognition (CVPR) , pp. 6230-6239, Jul. 2017. 1,2, 3,6",
        "ref_ids": [
          "8"
        ]
      },
      "Efficient uncertainty estimation for semantic segmentation in videos": {
        "authors": [
          "Yu Huang",
          "Ting Hsu",
          "Yueh Chiu",
          "Tingfan Wu",
          "Min Sun"
        ],
        "url": "http://openaccess.thecvf.com/content_ECCV_2018/papers/Po-Yu_Huang_Efficient_Uncertainty_Estimation_ECCV_2018_paper.pdf"
      },
      "Penalizing top performers: Conservative loss for semantic segmentation adaptation": {
        "authors": [
          "Xinge Zhu",
          "Hui Zhou",
          "Ceyuan Yang",
          "Jianping Shi",
          "Dahua Lin"
        ],
        "url": "http://openaccess.thecvf.com/content_ECCV_2018/papers/Xinge_Zhu_Penalizing_Top_Performers_ECCV_2018_paper.pdf",
        "ref_texts": ""
      },
      "Learning to fuse things and stuff": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1812.01192",
        "ref_texts": "[43] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In IEEE Conf. on Computer Vision and Pattern Recognition (CVPR) , pages 2881\u2013",
        "ref_ids": [
          "43"
        ]
      },
      "Convolutional CRFs for semantic segmentation": {
        "authors": [],
        "url": "https://www.repository.cam.ac.uk/bitstreams/bee52147-f7d5-4fd5-80fc-670fccc2076b/download",
        "ref_texts": "[42] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In IEEE Conf. on Computer Vision and Pattern Recognition (CVPR) , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "42"
        ]
      },
      "Affinity derivation and graph merge for instance segmentation": {
        "authors": [
          "Yiding Liu",
          "Siyu Yang",
          "Bin Li",
          "Zeng Xu",
          "Houqiang Li",
          "Yan Lu"
        ],
        "url": "https://openaccess.thecvf.com/content_ECCV_2018/papers/Yiding_Liu_Affinity_Derivation_and_ECCV_2018_paper.pdf",
        "ref_texts": ""
      },
      "Learning linear transformations for fast arbitrary style transfer": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1808.04537",
        "ref_texts": "[41] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In CVPR , 2017.",
        "ref_ids": [
          "41"
        ]
      },
      "Characterizing adversarial examples based on spatial consistency information for semantic segmentation": {
        "authors": [
          "I X",
          "Ruizhi Deng",
          "Bo Li",
          "Fisher Yu",
          "Dawn Song"
        ],
        "url": "http://openaccess.thecvf.com/content_ECCV_2018/papers/CHAOWEI_XIAO_Characterize_Adversarial_Examples_ECCV_2018_paper.pdf",
        "ref_texts": "55. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: IEEE Conf. on Computer Vision and Pattern Recognition (CVPR). pp. 2881\u20132890",
        "ref_ids": [
          "55"
        ]
      },
      "Associating inter-image salient instances for weakly supervised semantic segmentation": {
        "authors": [
          "Ruochen Fan",
          "Qibin Hou",
          "Ming Cheng",
          "Gang Yu",
          "Ralph Martin",
          "Shimin Hu"
        ],
        "url": "http://openaccess.thecvf.com/content_ECCV_2018/papers/Ruochen_Fan_Associating_Inter-Image_Salient_ECCV_2018_paper.pdf",
        "ref_texts": "46. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: CVPR (2017)",
        "ref_ids": [
          "46"
        ]
      },
      "Partial convolution based padding": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1811.11718",
        "ref_texts": "[35] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In IEEE Conf. on Computer Vision and Pattern Recognition (CVPR) , pages 2881\u20132890, 2017. 7, 8",
        "ref_ids": [
          "35"
        ]
      },
      "Grab, pay, and eat: Semantic food detection for smart restaurants": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1711.05128",
        "ref_texts": ""
      },
      "One-shot instance segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1811.11507",
        "ref_texts": "[68] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017.",
        "ref_ids": [
          "68"
        ]
      },
      "End-to-end video-level representation learning for action recognition": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1711.04161",
        "ref_texts": ""
      },
      "Aerial LaneNet: Lane-marking semantic segmentation in aerial imagery using wavelet-enhanced cost-sensitive symmetric fully convolutional neural networks": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1803.06904",
        "ref_texts": "[52] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in CVPR , 2017.",
        "ref_ids": [
          "52"
        ]
      },
      "PSNet: prostate segmentation on MRI based on a convolutional neural network": {
        "authors": [],
        "url": "https://www.spiedigitallibrary.org/journalArticle/Download?fullDOI=10.1117/1.JMI.5.2.021208",
        "ref_texts": "38. H. Zhao et al., \u201cPyramid scene parsing network, \u201dinIEEE Conf. on Computer Vision and Pattern Recognition (CVPR) (2017).",
        "ref_ids": [
          "38"
        ]
      },
      "Improving fast segmentation with teacher-student learning": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1810.08476",
        "ref_texts": "[39] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang W ang, and Jiaya Jia. Pyramid scene parsing network. In IEEE Conf. on Computer Vision and Pattern Recognition (CVPR) , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "39"
        ]
      },
      "Analysis of hand segmentation in the wild": {
        "authors": [
          "Aisha Urooj",
          "Ali Borji"
        ],
        "url": "http://openaccess.thecvf.com/content_cvpr_2018/papers/Urooj_Analysis_of_Hand_CVPR_2018_paper.pdf",
        "ref_texts": "[38] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. arXiv preprint arXiv:1612.01105 , 2016. 4",
        "ref_ids": [
          "38"
        ]
      },
      "Efficient convolutions for real-time semantic segmentation of 3d point clouds": {
        "authors": [],
        "url": "http://www.cs.toronto.edu/~wenjie/papers/3dv18.pdf",
        "ref_texts": "[38] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. arXiv preprint arXiv:1612.01105 , 2016. 1",
        "ref_ids": [
          "38"
        ]
      },
      "Recurrent scene parsing with perspective understanding in the loop": {
        "authors": [
          "Shu Kong",
          "Charless C. Fowlkes"
        ],
        "url": "http://openaccess.thecvf.com/content_cvpr_2018/papers/Kong_Recurrent_Scene_Parsing_CVPR_2018_paper.pdf",
        "ref_texts": "[38] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2017. 2,6",
        "ref_ids": [
          "38"
        ]
      },
      "Deep multi-sensor lane detection": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1905.01555.pdf?utm_campaign=affiliate-ir-FlexOffers.com%2C%20LLC_1_-99_national_D_all_ACQ_cpa_en&utm_content=&utm_source=affiliate-ir&utm_term=1tXUHjRSkVGnRB5zE2xe1zb9UkmUrBT8CTTXRg0",
        "ref_texts": "[23] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d 2017.",
        "ref_ids": [
          "23"
        ]
      },
      "Detecting traffic lights by single shot detection": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1805.02523",
        "ref_texts": "[32] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid Scene Parsing Network. 2016.",
        "ref_ids": [
          "32"
        ]
      },
      "See and think: Disentangling semantic scene completion": {
        "authors": [
          "Shice Liu",
          "U H",
          "Yiming Zeng",
          "Qiankun Tang",
          "Beibei Jin",
          "Yinhe Han",
          "Xiaowei Li"
        ],
        "url": "https://proceedings.neurips.cc/paper/2018/file/9872ed9fc22fc182d371c3e9ed316094-Paper.pdf",
        "ref_texts": "[12] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid Scene Parsing Network. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "12"
        ]
      },
      "Automatic mitochondria segmentation for EM data using a 3D supervised convolutional network": {
        "authors": [
          "Qiwei Xie",
          "Hua Han"
        ],
        "url": "https://www.frontiersin.org/articles/10.3389/fnana.2018.00092/pdf",
        "ref_texts": ""
      },
      "FReLU: Flexible rectified linear units for improving convolutional neural networks": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1706.08098",
        "ref_texts": ""
      },
      "Attention-based pyramid aggregation network for visual place recognition": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1808.00288",
        "ref_texts": "[50] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. 2017. Pyramid scene parsing network. In CVPR . 2881\u20132890.",
        "ref_ids": [
          "50"
        ]
      },
      "Panoptic segmentation with a joint semantic and instance segmentation network": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1809.02110",
        "ref_texts": "[14] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid Scene Parsing Network. In 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , pages 6230\u20136239, July 2017.",
        "ref_ids": [
          "14"
        ]
      },
      "RiFCN: Recurrent network in fully convolutional network for semantic segmentation of high resolution remote sensing images": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1805.02091",
        "ref_texts": "[33] H. Zhao, J. Shi, X. Qi, X. Wang, J. Jia, Pyramid scene parsing network, in: IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2017.",
        "ref_ids": [
          "33"
        ]
      },
      "Automatic segmentation of kidney and renal tumor in ct images based on 3d fully convolutional neural network with pyramid pooling module": {
        "authors": [],
        "url": "https://univ-rennes.hal.science/hal-02036719/file/yang%20ICPR.pdf",
        "ref_texts": "[8]H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsingnetwork,\u201d IEEE Conference on Computer Vision and PatternRecognition. IEEE Computer Society, 2017, pp.6230-6239.",
        "ref_ids": [
          "8"
        ]
      },
      "Ensemble knowledge transfer for semantic segmentation": {
        "authors": [
          "Ishan Nigam",
          "Chen Huang",
          "Deva Ramanan"
        ],
        "url": "https://www.cs.cmu.edu/~deva/papers/aeroscapes.pdf",
        "ref_texts": "[50] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , 2017. 1,2,6",
        "ref_ids": [
          "50"
        ]
      },
      "Learning to look around objects for top-view representations of outdoor scenes": {
        "authors": [
          "Samuel Schulter",
          "Menghua Zhai",
          "Nathan Jacobs",
          "Manmohan Chandraker"
        ],
        "url": "https://openaccess.thecvf.com/content_ECCV_2018/papers/Samuel_Schulter_Learning_to_Look_ECCV_2018_paper.pdf",
        "ref_texts": ""
      },
      "On the importance of label quality for semantic segmentation": {
        "authors": [
          "Aleksandar Zlateski",
          "Ronnachai Jaroensri",
          "Prafull Sharma",
          "Fredo Durand"
        ],
        "url": "http://openaccess.thecvf.com/content_cvpr_2018/papers/Zlateski_On_the_Importance_CVPR_2018_paper.pdf",
        "ref_texts": ""
      },
      "Stacked U-Nets for ground material segmentation in remote sensing imagery": {
        "authors": [
          "Arthita Ghosh",
          "Max Ehrlich",
          "Sohil Shah",
          "Larry S. Davis",
          "Rama Chellappa"
        ],
        "url": "http://openaccess.thecvf.com/content_cvpr_2018_workshops/papers/w4/Ghosh_Stacked_U-Nets_for_CVPR_2018_paper.pdf",
        "ref_texts": "[29] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In CVPR , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "29"
        ]
      },
      "Deep spatio-temporal random fields for efficient video segmentation": {
        "authors": [
          "Siddhartha Chandra",
          "Camille Couprie",
          "Iasonas Kokkinos"
        ],
        "url": "https://openaccess.thecvf.com/content_cvpr_2018/papers/Chandra_Deep_Spatio-Temporal_Random_CVPR_2018_paper.pdf",
        "ref_texts": "[40] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. CoRR , abs/1612.01105, 2016. 2,7",
        "ref_ids": [
          "40"
        ]
      },
      "Guided upsampling network for real-time semantic segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1807.07466",
        "ref_texts": "[25] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In IEEE Conf. on Computer Vision and Pattern Recognition (CVPR) , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "25"
        ]
      },
      "Virtual-to-real: Learning to control in visual semantic segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1802.00285",
        "ref_texts": "[Zhao et al. , 2017b ]Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proc. IEEE Conf. Computer Vision and Pattern Recognition (CVPR) , pages 2881-2890, Jul.",
        "ref_ids": [
          "Zhao et al\\. , 2017b "
        ]
      },
      "Bootstrapping the performance of webly supervised semantic segmentation": {
        "authors": [
          "Tong Shen",
          "Guosheng Lin",
          "Chunhua Shen",
          "Ian Reid"
        ],
        "url": "http://openaccess.thecvf.com/content_cvpr_2018/papers/Shen_Bootstrapping_the_Performance_CVPR_2018_paper.pdf",
        "ref_texts": "[33] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid Scene Parsing Network. In CVPR , 2017. 1,3",
        "ref_ids": [
          "33"
        ]
      },
      "A survey on deep learning methods for robot vision": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1803.10862",
        "ref_texts": ""
      },
      "Efficient dense labelling of human activity sequences from wearables using fully convolutional networks": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1702.06212",
        "ref_texts": ""
      },
      "Hairnet: Single-view hair reconstruction using convolutional neural networks": {
        "authors": [
          "Yi Zhou",
          "Jun Xing",
          "Liwen Hu",
          "Weikai Chen",
          "Hao Li",
          "Wei Kung"
        ],
        "url": "http://openaccess.thecvf.com/content_ECCV_2018/papers/Yi_Zhou_Single-view_Hair_Reconstruction_ECCV_2018_paper.pdf",
        "ref_texts": ""
      },
      "Ongoing evolution of visual SLAM from geometry to deep learning: Challenges and opportunities": {
        "authors": [],
        "url": "https://researchportal.hw.ac.uk/files/23073574/ongoing_evolution_visual.pdf",
        "ref_texts": "[89] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d arXiv preprint arXiv:1612.01105 , 2016.",
        "ref_ids": [
          "89"
        ]
      },
      "Deeplens: Shallow depth of field from a single image": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1810.08100",
        "ref_texts": "2018. Aperture Supervision for Monocular Depth Estimation. In Proceedings of IEEE Conference on Computer Vision and Pattern Recognition . Pratul P. Srinivasan, Tongzhou Wang, Ashwin Sreelal, Ravi Ramamoorthi, and Ren Ng. 2017. Learning to Synthesize a 4D RGBD Light Field from a Single Image. In Proceedings of IEEE International Conference on Computer Vision . 2262\u20132270. Supasorn Suwajanakorn, Carlos Hernandez, and Steven M Seitz. 2015. Depth from focus with your mobile phone. In Proceedings of IEEE Conference on Computer Vision and Pattern Recognition . 3497\u20133506. Lijun Wang, Huchuan Lu, Yifan Wang, Mengyang Feng, Dong Wang, Baocai Yin, and Xiang Ruan. 2017. Learning to Detect Salient Objects with Image-Level Supervision. InProceedings of IEEE Conference on Computer Vision and Pattern Recognition . IEEE, 3796\u20133805. Ning Xu, Brian Price, Scott Cohen, and Thomas Huang. 2017. Deep image matting. In Proceedings of IEEE Conference on Computer Vision and Pattern Recognition . Yang Yang, Haiting Lin, Zhan Yu, Sylvain Paris, and Jingyi Yu. 2016. Virtual DSLR: High Quality Dynamic Depth-of-Field Synthesis on Mobile Platforms. Electronic Imaging 2016, 18 (2016), 1\u20139. Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. 2017. Pyramid scene parsing network. In Proceedings of IEEE Conference on Computer Vision and Pattern Recognition . 2881\u20132890. ACM Trans. Graph., Vol. 37, No. 6, Article 245. Publication date: November 2018.",
        "ref_ids": [
          "2018"
        ]
      },
      "Focus, segment and erase: an efficient network for multi-label brain tumor segmentation": {
        "authors": [
          "Xuan Chen",
          "Jun Hao",
          "Wei Xiong",
          "Kong Chui",
          "Heng Ong"
        ],
        "url": "http://openaccess.thecvf.com/content_ECCV_2018/papers/Xuan_Chen_Focus_Segment_and_ECCV_2018_paper.pdf",
        "ref_texts": ""
      },
      "Treepedia 2.0: applying deep learning for large-scale quantification of urban tree cover": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1808.04754",
        "ref_texts": "[16] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in IEEE Conf. on Computer Vision and Pattern Recognition (CVPR) , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "16"
        ]
      },
      "Learning to cluster for proposal-free instance segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1803.06459",
        "ref_texts": "[30] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2017.",
        "ref_ids": [
          "30"
        ]
      },
      "Sparsely aggregated convolutional networks": {
        "authors": [
          "Ligeng Zhu",
          "Ruizhi Deng",
          "Michael Maire",
          "Zhiwei Deng",
          "Greg Mori",
          "Ping Tan"
        ],
        "url": "http://openaccess.thecvf.com/content_ECCV_2018/papers/Ligeng_Zhu_Sparsely_Aggregated_Convolutional_ECCV_2018_paper.pdf",
        "ref_texts": ""
      },
      "Learning strict identity mappings in deep residual networks": {
        "authors": [
          "Xin Yu",
          "Zhiding Yu",
          "Srikumar Ramalingam"
        ],
        "url": "https://openaccess.thecvf.com/content_cvpr_2018/papers/Yu_Learning_Strict_Identity_CVPR_2018_paper.pdf",
        "ref_texts": "[52] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In CVPR , 2017. 1",
        "ref_ids": [
          "52"
        ]
      },
      "Deep fundamental matrix estimation without correspondences": {
        "authors": [
          "Omid Poursaeed",
          "Guandao Yang",
          "Aditya Prakash",
          "Qiuren Fang",
          "Hanqing Jiang",
          "Bharath Hariharan",
          "Serge Belongie"
        ],
        "url": "http://openaccess.thecvf.com/content_ECCVW_2018/papers/11131/Poursaeed_Deep_Fundamental_Matrix_Estimation_without_Correspondences_ECCVW_2018_paper.pdf",
        "ref_texts": "47.Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: IEEE Conf. on Computer Vision and Pattern Recognition (CVPR). pp. 2881\u20132890 (2017)",
        "ref_ids": [
          "47"
        ]
      },
      "Stacked U-Nets: a no-frills approach to natural image segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1804.10343",
        "ref_texts": "14. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: IEEE Conf. on Computer Vision and Pattern Recognition (CVPR). (2017) 2881{",
        "ref_ids": [
          "14"
        ]
      },
      "Semantic segmentation from limited training data": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1709.07665",
        "ref_texts": "[23] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in CVPR , 2017.",
        "ref_ids": [
          "23"
        ]
      },
      "Bayesian prediction of future street scenes using synthetic likelihoods": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1810.00746",
        "ref_texts": "(7310):1102, 2010. Shi Xingjian, Zhourong Chen, Hao Wang, Dit-Yan Yeung, Wai-Kin Wong, and Wang-chun Woo. Convolutional lstm network: A machine learning approach for precipitation nowcasting. NIPS , 2015. Tianfan Xue, Jiajun Wu, Katherine Bouman, and Bill Freeman. Visual dynamics: Probabilistic future frame synthesis via cross convolutional networks. In NIPS , pp. 91\u201399, 2016. Fisher Yu and Vladlen Koltun. Multi-scale context aggregation by dilated convolutions. In ICLR , 2016. Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017."
      },
      "Dels-3d: Deep localization and segmentation with a 3d semantic map": {
        "authors": [
          "Peng Wang",
          "Ruigang Yang",
          "Binbin Cao",
          "Wei Xu",
          "Yuanqing Lin"
        ],
        "url": "https://openaccess.thecvf.com/content_cvpr_2018/papers/Wang_DeLS-3D_Deep_Localization_CVPR_2018_paper.pdf",
        "ref_texts": "[48] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. CVPR , 2017. 1,3",
        "ref_ids": [
          "48"
        ]
      },
      "GraphNet: Learning image pseudo annotations for weakly-supervised semantic segmentation": {
        "authors": [
          "Mengyang Pu",
          "Yaping Huang",
          "Qingji Guan",
          "Qi Zou"
        ],
        "url": "https://openreview.net/pdf?id=2YQ-Gp0zcr",
        "ref_texts": "[47] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. 2017. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition . 2881\u20132890.",
        "ref_ids": [
          "47"
        ]
      },
      "Driving scene perception network: Real-time joint detection, depth estimation and semantic segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1803.03778",
        "ref_texts": "[26] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. arXiv preprint arXiv:1612.01105 , 2016.",
        "ref_ids": [
          "26"
        ]
      },
      "Deep aggregation net for land cover classification": {
        "authors": [
          "Sheng Kuo",
          "Sen Tseng",
          "Wei Yan",
          "Cheng Liu",
          "Chiang Frank"
        ],
        "url": "http://openaccess.thecvf.com/content_cvpr_2018_workshops/papers/w4/Kuo_Deep_Aggregation_Net_CVPR_2018_paper.pdf",
        "ref_texts": "[14] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2017. 1",
        "ref_ids": [
          "14"
        ]
      },
      "Small object sensitive segmentation of urban street scene with spatial adjacency between object classes": {
        "authors": [],
        "url": "https://cse.sc.edu/~songwang/document/tip19b.pdf",
        "ref_texts": "(INPERCENTAGE ). F OREACH OBJECT CLASS ,THE NUMBERS WITHBETTER AND THE BESTPERFORMANCE AREHIGHLIGHTED IN BLUE AND RED,RESPECTIVEL Y of overall training iterations is 20k for both CamVid and CityScapes datasets. C. Experimental Results and Discussion 1) Comparisons to Baselines and Existing Methods: To demonstrate the effectiveness of the proposed method, we evaluate the proposed method using the baseline segmentation networks with spatial pyramid pooling-based architecture (e.g., FCN-8s [14], SegNet [15], GCN [16], PSPNet [18], and DeepLabV3 [12]), and the baseline segmentation network withfeature pyramid network-based architecture (e.g., DLA [42]). For CamVid dataset, three baseline segmentation networks \u2013 FCN-8s, SegNet, and DLA \u2013 are trained and evaluated.For CityScapes dataset, five baseline segmentation networks \u2013 FCN-8s, GCN, PSPNet, DeepLabV3, and DLA are trained and evaluated. The proposed pipeline is also compared with several existing segmentation methods: ALE [43], SuperParsing [44], Liu & He [45], Deeplab-LFOV [17], and FoveaNet [13]. Using CamVid dataset for evaluation, the quantitative results are shown in Table II. We observe that by employing the proposed ISBEncoder to the baseline segmentation network,the IoU scores of the small objects classes can be significantly improved when comparing to the settings without the ISBEncoder. Combining the ISBEncoder to the SegNet, FCN-8s, and DLA baseline segmentation networks, it shows 3.6%, 5.5% and 1 .7% improvements for small-object classes (mIoU S), respectively. It also shows 1 .2%, 2 .0% and 0 .2% improvements for large-object classes (mIoU L)u s i n gt h e SegNet, FCN-8s, and DLA respectively. The overall mIoUimprovements are 2 .0% for SegNet, 3 .3% for FCN-8s, and 0.7% for DLA. Using CityScapes dataset for evaluation, the quantitative results are shown in Table III. We also observe significant improvements on segmenting small object classes after employing the ISBEncoder. It shows 3 .2%, 3.0%, 2.8%, 1.7%, and 2 .2% improvements for small-object classes (mIoU S) using FCN-8s, GCN, PSPNet, DeepLab V3, and DLA,respectively. It shows 1 .6%, 0.3%, 0.3%, 0.03%, and 0 .04% improvements for large-object classes (mIoU L) using FCN-8s, GCN, PSPNet, DeepLab V3, and DLA, respectively. Theoverall mIoU improvements by including ISBEncoder are 2.2% for FCN-8s, 1 .3% for GCN, 1 .3% for PSPNet, 0 .7% for DeepLab V3, and 0 .8% for DLA. To demonstrate the effectiveness of the proposed ISBMetric, we conduct an additional experime nt using the weighted loss function whose weights are based on the ISBMetric. The conventional weighted loss func tion used in semantic segmentation, e.g., weighted sigmoid cross-entropy loss, requires asingle value as the weight for each object class. However, the weight for each object class in ISBMetric is a row vector, which makes it difficult to be directly applied to the weighted loss function. Alternatively, as each row in the ISBMetric is associated with an object class, we calculate the row-wiseMSE between the ISBMetric of the segmentation prediction and the ISBMetric ground-truth, and use the calculated rowwise Mean Square Error (row-wise MSE) to weigh each objectclass in the segmentation loss function (weighted sigmoid cross-entropy loss). In the experiment, we first calculate the ISBMetric using the segmentation predictions. Then, we calculate the row-wise MSE based on m pred isbandmgt isb, and use the calculated row-wise MSE as the weight of the objectclass to train the segmentation network. Experimental results are shown in Tables II and III, in which \u201cISBMetric-w\u201d denotes the method uses the ISBMetric based weightedloss function. Using CamVid testing dataset for evaluation, the experimental results demonstrate that weighing the object classes using the row-wise MSE of the ISBMetric shows 2 .5%, 5.1%, and 1 .3% mIoU Simprovements, and 1 .0%, 2.3%, and 0.4% mIoU improvements for the SegNet, FCN-8s, and DLA, respectively. Using CityScapes te sting dataset for evaluation, it shows shows 2 .5%, 2 .2%, 2 .2%, 1 .3%, and 1 .6% mIoU S improvements, and 1 .6%, 0.8%, 0.9%, 0.3%, and 0 .4% mIoU improvements for the FCN-8s, GCN, PSPNet, DeepLab v3, and DLA, respectively. In comparison to the proposed method, the segmentation performance of small object classes when using the ISBMetric based weighted loss function is better than the baselines but is slightly worse than the proposed method. To visually demonstrate the effectiveness of the proposed ISBEncoder, we provide representative segmentation results of FCN-8s and PSPNet with or without ISBEncoder on CamVid GUO et al. : SMALL OBJECT SENSITIVE SEGMENTATION OF URBAN STREET SCENE 2649 TABLE III THECOMPARISON RESULTS OF SMALL OBJECT CLASSES (TOP)AND LARGE OBJECT CLASSES (BOTTOM )ONCITYSCAPES TESTING DATAS ET (INPERCENTAGE ). F OREACH OBJECT CLASS ,THE NUMBERS WITHBETTER AND THE BEST PERFORMANCE AREHIGHLIGHTED IN BLUE AND RED,RESPECTIVELY and CityScapes datasets in Fig. 5. For small-object classes, we find that the regions segmented using ISBEncoder are more accurate, e.g., the poles, sign symbols and person,indicated by dashed rectangles, which are insufficiently segmented or totally missing when using the baseline method. By employing proposed ISBEncoder to the baseline segmen-tation network, it can better capture the missing components and render more accurate segmentation results.",
        "ref_ids": [
          "14",
          "15",
          "16",
          "18",
          "12",
          "42",
          "43",
          "44",
          "45",
          "17",
          "13"
        ]
      },
      "Unifying terrain awareness through real-time semantic segmentation": {
        "authors": [
          "Kailun Yang",
          "Luis M. Bergasa",
          "Eduardo Romera",
          "Ruiqi Cheng",
          "Tianxue Chen",
          "I W"
        ],
        "url": "http://115.159.107.214/file/publications/iv2018_kailun.pdf",
        "ref_texts": "[21] H. Zhao, J. Shi, X. Qi, X. Wang and J. Jia, \u201cPyramid scene parsing network,\u201d in IEEE Conf. on Computer Vision and Pattern Recognition (CVPR) , 2017, pp. 2881-2890.",
        "ref_ids": [
          "21"
        ]
      },
      "The best of both worlds: Combining cnns and geometric constraints for hierarchical motion segmentation": {
        "authors": [
          "Pia Bideau",
          "Aruni Roy",
          "Rakesh R. Menon",
          "Erik Learned"
        ],
        "url": "https://openaccess.thecvf.com/content_cvpr_2018/papers/Bideau_The_Best_of_CVPR_2018_paper.pdf",
        "ref_texts": "[49] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. arXiv preprint arXiv:1612.01105 , 2016. 1",
        "ref_ids": [
          "49"
        ]
      },
      "VH-HFCN based parking slot and lane markings segmentation on panoramic surround view": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1804.07027",
        "ref_texts": "[20] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d arXiv preprint arXiv:1612.01105 , 2016.",
        "ref_ids": [
          "20"
        ]
      },
      "In defense of single-column networks for crowd counting": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1808.06133",
        "ref_texts": "[33] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In IEEE Conf. on Computer Vision and Pattern Recognition (CVPR) , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "33"
        ]
      },
      "Pyramid network with online hard example mining for accurate left atrium segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1812.05802",
        "ref_texts": "15. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: CVPR. pp. 2881{2890 (2017)",
        "ref_ids": [
          "15"
        ]
      },
      "Single image water hazard detection using fcn with reflection attention units": {
        "authors": [
          "Xiaofeng Han",
          "Chuong Nguyen",
          "Shaodi You",
          "Jianfeng Lu"
        ],
        "url": "https://openaccess.thecvf.com/content_ECCV_2018/papers/Xiaofeng_Han_Single_Image_Water_ECCV_2018_paper.pdf",
        "ref_texts": ""
      },
      "CNN-based fisheye image real-time semantic segmentation": {
        "authors": [],
        "url": "http://www.robesafe.es/personal/bergasa/papers/iv2018_cnn-fisheye.pdf",
        "ref_texts": "[22] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d arXiv preprint arXiv:1612.01105 , 2016.",
        "ref_ids": [
          "22"
        ]
      },
      "Sharing Residual Units Through Collective Tensor Factorization To Improve Deep Neural Networks.": {
        "authors": [
          "Yunpeng Chen",
          "Xiaojie Jin",
          "Bingyi Kang",
          "Jiashi Feng",
          "Shuicheng Yan"
        ],
        "url": "https://www.ijcai.org/Proceedings/2018/0088.pdf",
        "ref_texts": "[Zhao et al., 2016 ]Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. arXiv preprint arXiv:1612.01105, 2016.",
        "ref_ids": [
          "Zhao et al\\., 2016 "
        ]
      },
      "Reading between the lanes: Road layout reconstruction from partially segmented scenes": {
        "authors": [
          "Lars Kunze",
          "Tom Bruls",
          "Tarlan Suleymanov",
          "Paul Newman"
        ],
        "url": "https://ora.ox.ac.uk/objects/uuid:e9392e86-116c-4acd-a414-b14cbcecc641/download_file?file_format=pdf&safe_filename=Reading%2Bbetween%2Bthe%2BLanes-%2BRoad%2BLayout%2BReconstruction%2Bfrom%2BPartially%2BSegmented%2BScenes.pdf&type_of_work=Conference+item",
        "ref_texts": "[2] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in IEEE Conf. on Computer Vision and Pattern Recognition (CVPR) , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "2"
        ]
      },
      "Toward achieving robust low-level and high-level scene parsing": {
        "authors": [],
        "url": "https://dr.ntu.edu.sg/bitstream/10356/142866/2/Toward%20Achieving%20Robust%20Low-Level%20and%20High-Level%20Scene%20Parsing.pdf",
        "ref_texts": "[40] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , July 2017.",
        "ref_ids": [
          "40"
        ]
      },
      "Scan: Semantic context aware network for accurate small object detection": {
        "authors": [],
        "url": "https://link.springer.com/content/pdf/10.2991/ijcis.11.1.72.pdf",
        "ref_texts": "34. H. Zhao, J. Shi, X. Qi, X. Wang and J. Jia. Pyramid scene parsing network. arXiv preprint arXiv:1612.01105, (2016).",
        "ref_ids": [
          "34"
        ]
      },
      "Tiling and stitching segmentation output for remote sensing: Basic challenges and recommendations": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1805.12219",
        "ref_texts": ""
      },
      "Monocular vehicle self-localization method based on compact semantic map": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1805.06155",
        "ref_texts": "[13] Zhao, Hengshuang , et al. \"Pyramid Scene Parsing Network.\" IEEE Conference on Computer Vision and Pattern Recognition IEEE Computer Society, 2017:6230 -6239. ",
        "ref_ids": [
          "13"
        ]
      },
      "Dense fusion classmate network for land cover classification": {
        "authors": [
          "Chao Tian",
          "Cong Li",
          "Jianping Shi"
        ],
        "url": "http://openaccess.thecvf.com/content_cvpr_2018_workshops/papers/w4/Tian_Dense_Fusion_Classmate_CVPR_2018_paper.pdf",
        "ref_texts": "[21] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In IEEE Conference on Computer Vision and Pattern Recognition , pages 6230\u20136239, 2017.",
        "ref_ids": [
          "21"
        ]
      },
      "Drive video analysis for the detection of traffic near-miss incidents": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1804.02555",
        "ref_texts": "[11] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network.\u201d IEEE Conference on Computer Vision and Pa ttern Recognition (CVPR), 2017.",
        "ref_ids": [
          "11"
        ]
      },
      "Vortex pooling: Improving context representation in semantic segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1804.06242",
        "ref_texts": "3203, 2016. Wei Liu, Andrew Rabinovich, and Alexander Berg. Parsenet: Looking wider to see better. arXiv:1506.04579 , 2015. Jonathan Long, Evan Shelhamer, and Trevor Darrell. Fully convolutional networks for semantic segmentation. In CVPR , pages 3431\u20133440, 2015. Ping Luo, Guangrun Wang, Liang Lin, and Xiaogang Wang. Deep dual learning for semantic image segmentation. In ICCV , pages 2718\u20132726, 2017. Hyeonwoo Noh, Seunghoon Hong, and Bohyung Han. Learning deconvolution network for semantic segmentation. In ICCV , pages 1520\u20131528, 2015. Chao Peng, Xiangyu Zhang, Gang Yu, Guiming Luo, and Jian Sun. Large Kernel Matters Improve semantic segmentation by global convolutional network. In CVPR , pages 4353\u20134361, 2017. Pedro Pinheiro, Ronan Collobert, and Piotr Doll \u00b4ar. Learning to segment object candidates. In NIPS , pages 1990\u20131998, 2015. Shaoqing Ren, Kaiming He, Ross Girshick, and Jian Sun. Faster R-CNN: Towards real-time object detection with region proposal networks. In NIPS , pages 91\u201399, 2015. Falong Shen, Rui Rui, Shuicheng Yan, and Gang Zeng. Semantic segmentation via structured patch prediction, context crf and guidance crf. In CVPR , pages 1953\u20131961, 2017.Tong Shen, Guosheng Lin, Chunhua Shen, and Ian Reid. Learning multi-level region consistency with dense multilabel networks for semantic segmentation. In IJCAI , pages 2708\u20132714, 2017. Karen Simonyan and Andrew Zisserman. Very deep convolutional networks for large-scale image recognition. In ICLR , 2015. Haiming Sun, Di Xie, and Shiliang Pu. Mixed context networks for semantic segmentation. arXiv:1610.05854 , 2016. Guangrun Wang, Ping Luo, Liang Lin, and Xiaogang Wang. Learning object interactions and descriptions for semantic image segmentation. In CVPR , pages 5859\u20135867, 2017. Panqu Wang, Pengfei Chen, Ye Yuan, Ding Liu, Zehua Huang, Xiaodi Hou, and Garrison Cottrell. Understanding convolution for semantic segmentation. arXiv:1702.08502 , 2017. Zifeng Wu, Chunhua Shen, and Anton van den Hengel. Wider or deeper: Revisiting the resnet model for visual recognition. arXiv:1611.10080 , 2016. Fisher Yu and Vladlen Koltun. Multi-scale context aggregation by dilated convolutions. In ICLR , 2016. Fisher Yu, Vladlen Koltun, and Thomas Funkhouser. Dilated residual networks. In CVPR , pages 472\u2013480, 2017. Hang Zhang, Jia Xue, and Kristin Dana. Deep TEN: Texture encoding network. In CVPR , pages 708\u2013717, 2017. Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , pages 6230\u20136239, 2017. Bolei Zhou, Aditya Khosla, Agata Lapedriza, Aude Oliva, and Antonio Torralba. Object detectors emerge in deep scene cnns. In ICLR , 2014."
      },
      "Learning to understand image blur": {
        "authors": [
          "Shanghang Zhang",
          "Xiaohui Shen",
          "Zhe Lin",
          "Radomir Mech",
          "Joao P. Costeira",
          "Jose M. F"
        ],
        "url": "https://openaccess.thecvf.com/content_cvpr_2018/papers/Zhang_Learning_to_Understand_CVPR_2018_paper.pdf",
        "ref_texts": "[36] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. arXiv preprint arXiv:1612.01105 , 2016. 4",
        "ref_ids": [
          "36"
        ]
      },
      "Instance segmentation by deep coloring": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1807.10007",
        "ref_texts": "[12] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , July 2017.",
        "ref_ids": [
          "12"
        ]
      },
      "A bottom-up approach based on semantics for the interpretation of the main camera stream in soccer games": {
        "authors": [
          "Anthony Cioppa",
          "Adrien Deliege",
          "Marc Van"
        ],
        "url": "http://openaccess.thecvf.com/content_cvpr_2018_workshops/papers/w34/Cioppa_A_Bottom-Up_Approach_CVPR_2018_paper.pdf",
        "ref_texts": "[44] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In IEEE Int. Conf. Comput. Vision and Pattern Recogn. (CVPR) , pages 6230\u20136239, Honolulu, USA, July 2017.",
        "ref_ids": [
          "44"
        ]
      },
      "Semantic binary segmentation using convolutional networks without decoders": {
        "authors": [
          "Shubhra Aich",
          "Ian Stavness"
        ],
        "url": "http://openaccess.thecvf.com/content_cvpr_2018_workshops/papers/w4/Aich_Semantic_Binary_Segmentation_CVPR_2018_paper.pdf",
        "ref_texts": "[29] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , pages 6230\u20136239, July 2017.",
        "ref_ids": [
          "29"
        ]
      },
      "A memory model based on the Siamese network for long-term tracking": {
        "authors": [
          "Hankyeol Lee",
          "Seokeon Choi",
          "Changick Kim"
        ],
        "url": "http://openaccess.thecvf.com/content_ECCVW_2018/papers/11129/Lee_A_Memory_Model_based_on_the_Siamese_Network_for_Long-term_ECCVW_2018_paper.pdf",
        "ref_texts": ""
      },
      "Joint person segmentation and identification in synchronized first-and third-person videos": {
        "authors": [
          "Mingze Xu",
          "Chenyou Fan",
          "Yuchen Wang",
          "Michael Ryoo",
          "David Crandall"
        ],
        "url": "http://openaccess.thecvf.com/content_ECCV_2018/papers/Mingze_Xu_Joint_Person_Segmentation_ECCV_2018_paper.pdf",
        "ref_texts": ""
      },
      "Semantically-aware attentive neural embeddings for image-based visual localization": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1812.03402",
        "ref_texts": "[63] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "63"
        ]
      },
      "Densely Cascaded Shadow Detection Network via Deeply Supervised Parallel Fusion.": {
        "authors": [
          "Yupei Wang",
          "Xin Zhao",
          "Yin Li",
          "Xuecai Hu",
          "Kaiqi Huang"
        ],
        "url": "https://www.ijcai.org/proceedings/2018/0140.pdf",
        "ref_texts": "[Zhao et al., 2017 ]Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR, 2017.",
        "ref_ids": [
          "Zhao et al\\., 2017 "
        ]
      },
      "Pixel-wise attentional gating for parsimonious pixel labeling": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1805.01556",
        "ref_texts": "[58] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2017. Pixel-wise Attentional Gating for Scene Parsing (Appendix) Abstract In the supplementary material, we first present in detail how to transform the (unpredictable) global surface normals into (predictable) local normals in panoramic images. We then show more ablation studies on the loss functions introduced in the main paper and MultiPool module with/without PAG unit. Finally, we provide more qualitative visualization of the results for various pixel-labeling tasks, as well as the attentional ponder maps and MultiPool maps.",
        "ref_ids": [
          "58"
        ]
      },
      "A detection and segmentation architecture for skin lesion segmentation on dermoscopy images": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1809.03917",
        "ref_texts": "[5]Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. CoRR , abs/1612.01105, 2016.",
        "ref_ids": [
          "5"
        ]
      },
      "Real-time hair rendering using sequential adversarial networks": {
        "authors": [
          "Lingyu Wei",
          "Liwen Hu",
          "Vladimir Kim",
          "Ersin Yumer",
          "Hao Li"
        ],
        "url": "https://openaccess.thecvf.com/content_ECCV_2018/papers/Lingyu_Wei_Real-Time_Hair_Rendering_ECCV_2018_paper.pdf",
        "ref_texts": ""
      },
      "Difnet: Semantic segmentation by diffusion networks": {
        "authors": [
          "Peng Jiang",
          "Fanglin Gu",
          "Yunhai Wang",
          "Changhe Tu",
          "Baoquan Chen"
        ],
        "url": "https://proceedings.neurips.cc/paper/2018/file/c2626d850c80ea07e7511bbae4c76f4b-Paper.pdf",
        "ref_texts": "[5] Zhao, H., J. Shi, X. Qi, et al. Pyramid scene parsing network. In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) . 2017.",
        "ref_ids": [
          "5"
        ]
      },
      "Three birds one stone: A general architecture for salient object segmentation, edge detection and skeleton extraction": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1803.09860",
        "ref_texts": "[2] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in IEEE Conference on Computer Vision and Pattern Recognition , 2017.",
        "ref_ids": [
          "2"
        ]
      },
      "Intersection perception through real-time semantic segmentation to assist navigation of visually impaired pedestrians": {
        "authors": [],
        "url": "http://www.robesafe.uah.es/personal/bergasa/papers/ROBIO2018_intersection_open.pdf",
        "ref_texts": "[20] H. Zhao, J. Shi, X. Qi, X. Wang and J. Jia, Pyramid scene parsing network, In IEEE Conf. on Computer Vision and Pattern Recognition (CVPR), 2017, pp. 2881-2890.",
        "ref_ids": [
          "20"
        ]
      },
      "Craft: Complementary recommendation by adversarial feature transform": {
        "authors": [
          "Cong Phuoc",
          "Arridhana Ciptadi",
          "Ambrish Tyagi",
          "Amit Agrawal"
        ],
        "url": "http://openaccess.thecvf.com/content_ECCVW_2018/papers/11131/Huynh_CRAFT_Complementary_Recommendation_by_Adversarial_Feature_Transform_ECCVW_2018_paper.pdf"
      },
      "Overcoming missing and incomplete modalities with generative adversarial networks for building footprint segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1808.03195",
        "ref_texts": "[29] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia, \u201cPyramid Scene Parsing Network,\u201d arXiv preprint arXiv:1612.01105 , 2016.",
        "ref_ids": [
          "29"
        ]
      },
      "Regularizing deep networks by modeling and predicting label structure": {
        "authors": [
          "Mohammadreza Mostajabi",
          "Michael Maire",
          "Gregory Shakhnarovich"
        ],
        "url": "http://openaccess.thecvf.com/content_cvpr_2018/papers/Mostajabi_Regularizing_Deep_Networks_CVPR_2018_paper.pdf",
        "ref_texts": "[46] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. CVPR , 2017.",
        "ref_ids": [
          "46"
        ]
      },
      "Neuro-IoU: Learning a Surrogate Loss for Semantic Segmentation.": {
        "authors": [],
        "url": "https://bmva-archive.org.uk/bmvc/2018/contents/papers/1055.pdf",
        "ref_texts": "[20] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2016.",
        "ref_ids": [
          "20"
        ]
      },
      "Surfconv: Bridging 3d and 2d convolution for rgbd images": {
        "authors": [
          "Hang Chu",
          "Chiu Ma",
          "Kaustav Kundu",
          "Raquel Urtasun",
          "Sanja Fidler"
        ],
        "url": "http://openaccess.thecvf.com/content_cvpr_2018/papers/Chu_SurfConv_Bridging_3D_CVPR_2018_paper.pdf",
        "ref_texts": "[56] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In CVPR , 2017. 3",
        "ref_ids": [
          "56"
        ]
      },
      "Efficient module based single image super resolution for multiple problems": {
        "authors": [
          "Dongwon Park",
          "Kwanyoung Kim",
          "Se Young"
        ],
        "url": "http://openaccess.thecvf.com/content_cvpr_2018_workshops/papers/w13/Park_Efficient_Module_Based_CVPR_2018_paper.pdf",
        "ref_texts": "[22] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "22"
        ]
      },
      "Exploiting semantics in adversarial training for image-level domain adaptation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1810.05852",
        "ref_texts": "[20] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in IEEE Conf. on Computer Vision and Pattern Recognition (CVPR) , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "20"
        ]
      },
      "Agile amulet: Real-time salient object detection with contextual attention": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1802.06960",
        "ref_texts": "[62] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In CVPR , 2017. 3",
        "ref_ids": [
          "62"
        ]
      },
      "Future semantic segmentation with convolutional lstm": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1807.07946",
        "ref_texts": "[28] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017.",
        "ref_ids": [
          "28"
        ]
      },
      "Monocular depth estimation by learning from heterogeneous datasets": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1803.08018",
        "ref_texts": "[5] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in CVPR , 2017.",
        "ref_ids": [
          "5"
        ]
      },
      "Coarse-to-fine annotation enrichment for semantic segmentation learning": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1808.07209",
        "ref_texts": "[36] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. 2017. Pyramid Scene Parsing Network. In 2017 IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2017, Honolulu, HI, USA, July 21-26, 2017 . 6230\u20136239.",
        "ref_ids": [
          "36"
        ]
      },
      "High-resolution image dehazing with respect to training losses and receptive field sizes": {
        "authors": [
          "Hyeonjun Sim",
          "Sehwan Ki",
          "Seok Choi",
          "Soomin Seo",
          "Saehun Kim",
          "Munchurl Kim"
        ],
        "url": "http://openaccess.thecvf.com/content_cvpr_2018_workshops/papers/w13/Sim_High-Resolution_Image_Dehazing_CVPR_2018_paper.pdf",
        "ref_texts": "[8] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. IEEE Conf. on Computer Vision and Pattern Recognition (CVPR), 2017 [9] S. Iizuka, E. Simo-Serra, and H. Ishikawa. Globally and locally consistent image completion. ACM Transactions on Graphics (TOG), 2017 ",
        "ref_ids": [
          "8",
          "9"
        ]
      },
      "Pfdet: 2nd place solution to open images challenge 2018 object detection track": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1809.00778",
        "ref_texts": "[15] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In CVPR , 2017.",
        "ref_ids": [
          "15"
        ]
      },
      "Minimizing supervision for free-space segmentation": {
        "authors": [
          "Satoshi Tsutsui",
          "Tommi Kerola",
          "Shunta Saito",
          "David J. Crandall"
        ],
        "url": "http://openaccess.thecvf.com/content_cvpr_2018_workshops/papers/w14/Tsutsui_Minimizing_Supervision_for_CVPR_2018_paper.pdf",
        "ref_texts": "[48] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid Scene Parsing Network. In CVPR , 2017. 2,7",
        "ref_ids": [
          "48"
        ]
      },
      "Recurrent segmentation for variable computational budgets": {
        "authors": [
          "Lane Mc",
          "Niru Maheswaranathan",
          "David Sussillo",
          "Jonathon Shlens"
        ],
        "url": "http://openaccess.thecvf.com/content_cvpr_2018_workshops/papers/w33/McIntosh_Recurrent_Segmentation_for_CVPR_2018_paper.pdf",
        "ref_texts": "[72] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. arXiv preprint arXiv:1612.01105 , 2016. 1, 5,6,12",
        "ref_ids": [
          "72"
        ]
      },
      "Large-scale tissue histopathology image segmentation based on feature pyramid": {
        "authors": [
          "Pinle Qin"
        ],
        "url": "https://link.springer.com/content/pdf/10.1186/s13640-018-0320-8.pdf",
        "ref_texts": "22. Zhao H, Shi J, Qi X, et al. Pyramid Scene Parsing Network[J]. arXiv:1612.",
        "ref_ids": [
          "22"
        ]
      },
      "Autonomous driving in reality with reinforcement learning and image translation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1801.05299",
        "ref_texts": "[24] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. CoRR , abs/1612.01105, 2016.",
        "ref_ids": [
          "24"
        ]
      },
      "On the iterative refinement of densely connected representation levels for semantic segmentation": {
        "authors": [
          "Arantxa Casanova",
          "Guillem Cucurull",
          "Michal Drozdzal",
          "Adriana Romero",
          "Yoshua Bengio"
        ],
        "url": "http://openaccess.thecvf.com/content_cvpr_2018_workshops/papers/w14/Casanova_On_the_Iterative_CVPR_2018_paper.pdf",
        "ref_texts": "[48] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. CVPR , 2017.",
        "ref_ids": [
          "48"
        ]
      },
      "Historical handwritten document segmentation by using a weighted loss": {
        "authors": [],
        "url": "https://flore.unifi.it/bitstream/2158/1146014/1/capobiancoscommegna.pdf",
        "ref_texts": "15. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: 2017 IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2017, Honolulu, HI, USA, July 21-26, 2017. pp. 6230{6239 (2017)",
        "ref_ids": [
          "15"
        ]
      },
      "Attention to refine through multi scales for semantic segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1807.02917",
        "ref_texts": "21. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. pp. 2881{2890 (2017)",
        "ref_ids": [
          "21"
        ]
      },
      "Recognizing challenging handwritten annotations with fully convolutional networks": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1804.00236",
        "ref_texts": "[38] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in IEEE Conf. on Computer Vision and Pattern Recognition (CVPR) , 2017, pp. 2881\u20132890. 4",
        "ref_ids": [
          "38"
        ]
      },
      "Fast semantic segmentation on video using block motion-based feature interpolation": {
        "authors": [
          "Samvit Jain",
          "Joseph E. Gonzalez"
        ],
        "url": "http://openaccess.thecvf.com/content_ECCVW_2018/papers/11132/Jain_Fast_Semantic_Segmentation_on_Video_Using_Block_Motion-Based_Feature_Interpolation_ECCVW_2018_paper.pdf",
        "ref_texts": ""
      },
      "Cell image segmentation by integrating multiple CNNs": {
        "authors": [
          "Yuki Hiramatsu",
          "Kazuhiro Hotta",
          "Ayako Imanishi",
          "Michiyuki Matsuda",
          "Kenta Terai"
        ],
        "url": "http://openaccess.thecvf.com/content_cvpr_2018_workshops/papers/w44/Hiramatsu_Cell_Image_Segmentation_CVPR_2018_paper.pdf",
        "ref_texts": "[3] H. Zhao, J. Shi, X. Qi, Z. Wang and J. Jia, \u201cPyramid Scene Parsing Network\u201d, Proceeding of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2881-2890, ",
        "ref_ids": [
          "3"
        ]
      },
      "Concept mask: Large-scale segmentation from semantic concepts": {
        "authors": [
          "Yufei Wang",
          "Zhe Lin",
          "Xiaohui Shen",
          "Scott Cohen",
          "Jianming Zhang"
        ],
        "url": "http://openaccess.thecvf.com/content_ECCV_2018/papers/Yufei_Wang_ConceptMask_Large-Scale_Segmentation_ECCV_2018_paper.pdf",
        "ref_texts": ""
      },
      "Semantic segmentation of human thigh quadriceps muscle in magnetic resonance images": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1801.00415",
        "ref_texts": "[40] H. Zhao, J. Shi, X. Qi, X. Wang, J. Jia, Pyramid scene parsing network, arXiv preprint arXiv:1612.01105.",
        "ref_ids": [
          "40"
        ]
      },
      "Eng: End-to-end neural geometry for robust depth and pose estimation using cnns": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1807.05705",
        "ref_texts": "41. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: IEEE Computer Vision and Pattern Recognition (CVPR) (2017)",
        "ref_ids": [
          "41"
        ]
      },
      "Predicting polarization beyond semantics for wearable robotics": {
        "authors": [
          "Kailun Yang",
          "Luis Miguel",
          "Eduardo Romera",
          "Xiao Huang",
          "I W"
        ],
        "url": "http://www.robesafe.uah.es/personal/bergasa/papers/Humanoids2018.pdf",
        "ref_texts": "[29] H. Zhao, J. Shi, X. Qi, X. Wang and J. Jia, Pyramid scene parsing network, In 2017 IEEE Conference on Computer Vision and Patter Recognition (CVPR) , 2017, pp. 6230-6339.",
        "ref_ids": [
          "29"
        ]
      },
      "Semantic segmentation of aerial imagery via multi-scale shuffling convolutional neural networks with deep supervision": {
        "authors": [],
        "url": "https://isprs-annals.copernicus.org/articles/IV-1/29/2018/isprs-annals-IV-1-29-2018.pdf",
        "ref_texts": "3rd Earth Resources Technology Satellite-1 Symposium (ERTS), Washington, D.C., USA, V ol. I, pp. 309\u2013317. Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z., Karpathy, A., Khosla, A., Bernstein, M., Berg, A. C. and Fei-Fei, L., 2015. ImageNet large scale visual recognition challenge. International Journal of Computer Vision 115(3), pp. 211\u2013252. Sherrah, J., 2016. Fully convolutional networks for dense semantic labelling of high-resolution aerial imagery. arXiv preprint arXiv:1606.02585. Shi, W., Caballero, J., Husz \u00b4ar, F., Totz, J., Aitken, A. P., Bishop, R., Rueckert, D. and Wang, Z., 2016. Real-time single image and video super-resolution using an efficient sub-pixel convolutional neural network. In: Proc. 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Las Vegas, NV , USA, pp. 1874\u20131883. Simonyan, K. and Zisserman, A., 2014. Very deep convolutional networks for large-scale image recognition. arXiv preprint arXiv:1409.1556. Szegedy, C., Liu, W., Jia, Y ., Sermanet, P., Reed, S., Anguelov, D., Erhan, D., Vanhoucke, V . and Rabinovich, A., 2015. Going deeper with convolutions. In: Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Boston, MA, USA, pp. 1\u20139. V olpi, M. and Tuia, D., 2017. Dense semantic labeling of subdecimeter resolution images with convolutional neural networks. IEEE Transactions on Geoscience and Remote Sensing 55(2), pp. 881\u2013893. Weinmann, M., 2016. Reconstruction and analysis of 3D scenes \u2013 From irregularly distributed 3D points to object classes. Springer, Cham, Switzerland. Weinmann, M. and Weinmann, M., 2018. Geospatial computer vision based on multi-modal data \u2013 How valuable is shape information for the extraction of semantic information? Remote Sensing 10(1), pp. 2:1\u20132:20. West, K. F., Webb, B. N., Lersch, J. R., Pothier, S., Triscari, J. M. and Iverson, A. E., 2004. Context-driven automated target detection in 3-D data. Proceedings of SPIE 5426, pp. 133\u2013143. Zhao, H., Shi, J., Qi, X., Wang, X. and Jia, J., 2016. Pyramid scene parsing network. arXiv preprint arXiv:1612.01105. ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial Information Sciences, Volume IV-1, 2018 ISPRS TC I Mid-term Symposium \u201cInnovative Sensing \u2013 From Sensors to Methods and Applications\u201d, 10\u201312 October 2018, Karlsruhe, Germany This contribution has been peer-reviewed. The double-blind peer-review was conducted on the basis of the full paper. https://doi.org/10.5194/isprs-annals-IV-1-29-2018 | \u00a9 Authors 2018. CC BY 4.0 License."
      },
      "Stripnet: Towards topology consistent strip structure segmentation": {
        "authors": [],
        "url": "https://zhangwenwei.cn/publications/papers/StripNet.pdf",
        "ref_texts": "[44] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. 2017. Pyramid scene parsing network. In IEEE Conf. on Computer Vision and Pattern Recognition (CVPR) . 2881\u20132890.",
        "ref_ids": [
          "44"
        ]
      },
      "Deep neural networks with box convolutions": {
        "authors": [
          "Egor Burkov",
          "Victor Lempitsky"
        ],
        "url": "https://proceedings.neurips.cc/paper_files/paper/2018/file/8e489b4966fe8f703b5be647f1cbae63-Paper.pdf",
        "ref_texts": "[34] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. Proc. CVPR , pp.",
        "ref_ids": [
          "34"
        ]
      },
      "Towards low-cost image-based plant phenotyping using reduced-parameter CNN": {
        "authors": [],
        "url": "https://eprints.nottingham.ac.uk/54696/1/CNN%200023.pdf",
        "ref_texts": "[1]Shubhra Aich and Ian Stavness. Leaf counting with deep convolutional and deconvo-lutional networks.arXiv preprint arXiv:1708.07570, 2017.[2]Shubhra Aich, Imran Ahmed, Ilya Obsyannikov, Ian Stavness, Anique Josuttes, KeeganStrueby, Hema Sudhakar Duddu, Curtis Pozniak, and Steve Shirtliffe. Deepwheat:Estimating phenotypic traits from images of crops using deep learning.arXiv preprintarXiv:1710.00241, 2017.[3]Nikos Alexandratos, Jelle Bruinsma, et al. World agriculture towards 2030/2050: the2012 revision. Technical report, ESA Working paper FAO, Rome, 2012.[4]Vijay Badrinarayanan, Alex Kendall, and Roberto Cipolla. Segnet: A deep convo-lutional encoder-decoder architecture for image segmentation.IEEE transactions onpattern analysis and machine intelligence, 39(12):2481\u20132495, 2017.[5]Fran\u00e7ois Chollet. Xception: Deep learning with depthwise separable convolutions.arXiv preprint, pages 1610\u20132357, 2017.[6]Emily L Denton, Wojciech Zaremba, Joan Bruna, Yann LeCun, and Rob Fergus. Ex-ploiting linear structure within convolutional networks for efficient evaluation. InAd-vances in neural information processing systems, pages 1269\u20131277, 2014.[7]Mario Valerio Giuffrida, Massimo Minervini, and Sotirios Tsaftaris. Learning to countleaves in rosette plants. In H. Scharr S. A. Tsaftaris and T. Pridmore, editors,Proceed-ings of the Computer Vision Problems in Plant Phenotyping (CVPPP), pages 1.1\u20131.13.BMV A Press, September 2015. ISBN 1-901725-55-3. doi: 10.5244/C.29.CVPPP.1.URLhttps://dx.doi.org/10.5244/C.29.CVPPP.1.[8]Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learningfor image recognition. InProceedings of the IEEE conference on computer vision andpattern recognition, pages 770\u2013778, 2016.[9]Forrest N Iandola, Song Han, Matthew W Moskewicz, Khalid Ashraf, William J Dally,and Kurt Keutzer. Squeezenet: Alexnet-level accuracy with 50x fewer parameters and<0.5 mb model size.arXiv preprint arXiv:1602.07360, 2016.[10]Jonghoon Jin, Aysegul Dundar, and Eugenio Culurciello. Flattened convolutional neu-ral networks for feedforward acceleration.arXiv preprint arXiv:1412.5474, 2014.[11]Jonathan Long, Evan Shelhamer, and Trevor Darrell. Fully convolutional networks forsemantic segmentation. InProceedings of the IEEE conference on computer vision andpattern recognition, pages 3431\u20133440, 2015.[12]Massimo Minervini, Andreas Fischbach, Hanno Scharr, and Sotirios A Tsaftaris.Finely-grained annotated datasets for image-based plant phenotyping.Pattern recog-nition letters, 81:80\u201389, 2016. ATANBORI, ET. AL.: TOWARDS LOW-COST IMAGE-BASED PLANT PHENOTYPING.11[13]Maria-Elena Nilsback and Andrew Zisserman. Delving deeper into the whorl of flowersegmentation.Image and Vision Computing, 28(6):1049\u20131062, 2010.[14]Michael P Pound, Jonathan A Atkinson, Alexandra J Townsend, Michael H Wilson,Marcus Griffiths, Aaron S Jackson, Adrian Bulat, Georgios Tzimiropoulos, Darren MWells, Erik H Murchie, et al. Deep machine learning provides state-of-the-art perfor-mance in image-based plant phenotyping.GigaScience, 2017.[15]Michael P Pound, Jonathan A Atkinson, Darren M Wells, Tony P Pridmore, and An-drew P French. Deep learning for multi-task plant phenotyping. InProceedings ofthe IEEE Conference on Computer Vision and Pattern Recognition, pages 2055\u20132063,2017.[16]Yifan Sun, Liang Zheng, Weijian Deng, and Shengjin Wang. Svdnet for pedestrianretrieval.arXiv preprint, 2017.[17]Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott Reed, DragomirAnguelov, Dumitru Erhan, Vincent Vanhoucke, and Andrew Rabinovich. Going deeperwith convolutions. InProceedings of the IEEE conference on computer vision and pat-tern recognition, pages 1\u20139, 2015.[18]Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jon Shlens, and Zbigniew Wojna.Rethinking the inception architecture for computer vision. InProceedings of the IEEEConference on Computer Vision and Pattern Recognition, pages 2818\u20132826, 2016.[19]Martin Thoma. A survey of semantic segmentation.arXiv preprint arXiv:1602.06541,2016.[20]Min Wang, Baoyuan Liu, and Hassan Foroosh. Factorized convolutional neural net-works.IEEE International Conference on Computer Vision Workshops, pages 545\u2013553, 2017.[21]Jiaxiang Wu, Cong Leng, Yuhang Wang, Qinghao Hu, and Jian Cheng. Quantized con-volutional neural networks for mobile devices. InProceedings of the IEEE Conferenceon Computer Vision and Pattern Recognition, pages 4820\u20134828, 2016.[22]Fisher Yu and Vladlen Koltun. Multi-scale context aggregation by dilated convolutions.arXiv preprint arXiv:1511.07122, 2015.[23]Xiangyu Zhang, Xinyu Zhou, Mengxiao Lin, and Jian Sun. Shufflenet: An ex-tremely efficient convolutional neural network for mobile devices.arXiv preprintarXiv:1707.01083, 2017.[24]Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramidscene parsing network. InIEEE Conf. on Computer Vision and Pattern Recognition(CVPR), pages 2881\u20132890, 2017.",
        "ref_ids": [
          "1",
          "2",
          "3",
          "4",
          "5",
          "6",
          "7",
          "8",
          "9",
          "10",
          "11",
          "12",
          "13",
          "14",
          "15",
          "16",
          "17",
          "18",
          "19",
          "20",
          "21",
          "22",
          "23",
          "24"
        ]
      },
      "Dermoscopic image analysis for ISIC challenge 2018": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1807.08948",
        "ref_texts": "[1] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wa ng & Jiaya Jia (2017) Pyramid Scene Parsing Network. CVPR , pp. 6230-6239",
        "ref_ids": [
          "1"
        ]
      },
      "Performance evaluation of deep learning networks for semantic segmentation of traffic stereo-pair images": {
        "authors": [
          "Devendra Kumar"
        ],
        "url": "https://arxiv.org/pdf/1806.01896",
        "ref_texts": "[8] Zhao, H., Shi, J., Qi, X., Wang, X., and Jia, J. 2017. Pyramid scene parsing network. In IEEE Conf. on Computer Vision and Pattern Recognition (CVPR) 2881 -2890. ",
        "ref_ids": [
          "8"
        ]
      },
      "Evidential grid mapping, from asynchronous LIDAR scans and RGB images, for autonomous driving": {
        "authors": [],
        "url": "https://hal.science/hal-01867699/document",
        "ref_texts": "[8] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d arXiv preprint arXiv:1612.01105 , 2016.",
        "ref_ids": [
          "8"
        ]
      },
      "Deep online video stabilization": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1802.08091",
        "ref_texts": "[20] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d arXiv preprint arXiv:1612.01105 , 2016.",
        "ref_ids": [
          "20"
        ]
      },
      "Robust semantic segmentation with ladder-densenet models": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1806.03465",
        "ref_texts": "[13] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In ICCV , 2017. 2",
        "ref_ids": [
          "13"
        ]
      },
      "Adaptive semantic segmentation with a strategic curriculum of proxy labels": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1811.03542",
        "ref_texts": "[48] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In CVPR , 2017. 5",
        "ref_ids": [
          "48"
        ]
      },
      "The uavid dataset for video semantic segmentation": {
        "authors": [],
        "url": "https://research.utwente.nl/files/151373232/1810.10438v1.pdf",
        "ref_texts": "[31] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in CVPR , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "31"
        ]
      },
      "Learning deep representations for semantic image parsing: a comprehensive overview": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1810.04377",
        "ref_texts": "[1] Zhao H, Shi J, Qi X, Wang X, Jia J. Pyramid scene parsing network. ArXiv Preprint ArXiv:161201105, 2016",
        "ref_ids": [
          "1"
        ]
      },
      "Priming neural networks": {
        "authors": [
          "Amir Rosenfeld",
          "Mahdi Biparva",
          "John K. Tsotsos"
        ],
        "url": "http://openaccess.thecvf.com/content_cvpr_2018_workshops/papers/w39/Rosenfeld_Priming_Neural_Networks_CVPR_2018_paper.pdf",
        "ref_texts": "[42] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. arXiv preprint arXiv:1612.01105 , 2016. 4.2.1",
        "ref_ids": [
          "42"
        ]
      },
      "Do normalization layers in a deep ConvNet really need to be distinct?": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1811.07727",
        "ref_texts": "[34] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In CVPR , 2017. 10",
        "ref_ids": [
          "34"
        ]
      },
      "Fusion scheme for semantic and instance-level segmentation": {
        "authors": [],
        "url": "https://cv.utcluj.ro/Publications/Fusion%20Scheme%20for%20Semantic%20and%20Instance-level%20Segmentation.pdf",
        "ref_texts": "[44] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In CVPR , 2017.3475",
        "ref_ids": [
          "44"
        ]
      },
      "A comparison of deep learning architectures for semantic mapping of very high resolution images": {
        "authors": [],
        "url": "https://publ.nr.no/1549971883/liu2018-igarss_paper.pdf",
        "ref_texts": "[12] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d arXiv preprint arXiv:1612.01105 , 2016.",
        "ref_ids": [
          "12"
        ]
      },
      "River water quality estimation based on convolutional neural network": {
        "authors": [],
        "url": "http://www.apsipa.org/proceedings/2018/pdfs/0001305.pdf",
        "ref_texts": "[20] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proc. IEEE Conf. Comput. Vis. Patt. Recognit. , 2017, pp.",
        "ref_ids": [
          "20"
        ]
      },
      "Multiple workspaces in visual analytics": {
        "authors": [],
        "url": "https://vvise.iat.sfu.ca/user/data/papers/dynspace.pdf",
        "ref_texts": ""
      },
      "Cnns fusion for building detection in aerial images for the building detection challenge": {
        "authors": [
          "Remi Delassus",
          "Romain Giot"
        ],
        "url": "http://openaccess.thecvf.com/content_cvpr_2018_workshops/papers/w4/Delassus_CNNs_Fusion_for_CVPR_2018_paper.pdf",
        "ref_texts": "[24] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. arXiv preprint arXiv:1612.01105 , 2016.",
        "ref_ids": [
          "24"
        ]
      },
      "High Resolution Feature Recovering for Accelerating Urban Scene Parsing.": {
        "authors": [
          "Rui Zhang",
          "Sheng Tang",
          "Luoqi Liu",
          "Yongdong Zhang",
          "Jintao Li",
          "Shuicheng Yan"
        ],
        "url": "https://www.ijcai.org/proceedings/2018/0161.pdf",
        "ref_texts": "[Zhao et al., 2017 ]Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. InCVPR, 2017.Proceedings of the Twenty-Seventh International Joint Conference on Artificial Intelligence (IJCAI-18)",
        "ref_ids": [
          "Zhao et al\\., 2017 "
        ]
      },
      "In pixels we trust: from pixel labeling to object localization and scene categorization": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1807.07284",
        "ref_texts": "[10] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in CVPR , 2017.",
        "ref_ids": [
          "10"
        ]
      },
      "Efficient semantic segmentation using gradual grouping": {
        "authors": [
          "Nikitha Vallurupalli",
          "Sriharsha Annamaneni",
          "Girish Varma",
          "Manu Mathew",
          "Soyeb Nagori"
        ],
        "url": "http://openaccess.thecvf.com/content_cvpr_2018_workshops/papers/w12/Vallurupalli_Efficient_Semantic_Segmentation_CVPR_2018_paper.pdf",
        "ref_texts": "[24] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In IEEE Conf. on Computer Vision and Pattern Recognition (CVPR) , pages 2881\u2013",
        "ref_ids": [
          "24"
        ]
      },
      "Combining ElasticFusion with PSPNet for RGB-D based indoor semantic mapping": {
        "authors": [],
        "url": "https://kartobit.github.io/doc/wang&yang_cac18.pdf",
        "ref_texts": "[6] Zhao H , Shi J, Qi X, et al. Pyramid Scene Parsing Network[J]. CVPR, ",
        "ref_ids": [
          "6",
          "J"
        ]
      },
      "Classifying obstacles and exploiting knowledge about classes for efficient humanoid navigation": {
        "authors": [
          "Peter Regier",
          "Andres Milioto",
          "Philipp Karkowski",
          "Cyrill Stachniss",
          "Maren Bennewitz"
        ],
        "url": "http://crlab.cs.columbia.edu/humanoids_2018_proceedings/media/files/0019.pdf",
        "ref_texts": "[15] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d arXiv preprint , vol. abs/1612.01105, 2016.",
        "ref_ids": [
          "15"
        ]
      },
      "Uncertainty gated network for land cover segmentation": {
        "authors": [
          "Guillem Pascual",
          "Santi Segui",
          "Jordi Vitria"
        ],
        "url": "http://openaccess.thecvf.com/content_cvpr_2018_workshops/papers/w4/Pascual_Uncertainty_Gated_Network_CVPR_2018_paper.pdf",
        "ref_texts": "[12] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2017. 1",
        "ref_ids": [
          "12"
        ]
      },
      "Sobel heuristic kernel for aerial semantic segmentation": {
        "authors": [],
        "url": "https://www.perceptualui.org/publications/hu18_icip.pdf",
        "ref_texts": "[3] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia, \u201cPyramid scene parsing network,\u201d arXiv preprint arXiv:1612.01105 , 2016.",
        "ref_ids": [
          "3"
        ]
      },
      "Progressive refinement: A method of coarse-to-fine image parsing using stacked network": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1804.08256",
        "ref_texts": "[7] H. Zhao, J. Shi, X. Qi, and et al., \u201cPyramid Scene Parsing Network,\u201d in CVPR . 2017, pp. 6230\u20136239, IEEE.",
        "ref_ids": [
          "7"
        ]
      },
      "Three for one and one for three: Flow, Segmentation, and Surface Normals": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1807.07473",
        "ref_texts": "[40] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid Scene Parsing Network. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , pages 310\u2013313, 2017.",
        "ref_ids": [
          "40"
        ]
      },
      "MULTI-X, a state-of-the-art cloud-based ecosystem for biomedical research": {
        "authors": [],
        "url": "https://eprints.whiterose.ac.uk/143253/1/IEEE-BIBM-2018_MULTI-X.pdf",
        "ref_texts": ""
      },
      "3D segmentation of mandible from multisectional CT scans by convolutional neural networks": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1809.06752",
        "ref_texts": "2017), 2017 IEEE 14th International Symposium on , IEEE, pp. 1209{1212. Yu, F. & Koltun, V. (2015). Multi-scale context aggregation by dilated convolutions, arXiv preprint arXiv:1511.07122 . Zhao, H., Shi, J., Qi, X., Wang, X. & Jia, J. (2017). Pyramid scene parsing network, IEEE Conf. on Computer Vision and Pattern Recognition (CVPR) , pp. 2881{2890."
      },
      "A general, fault tolerant, adaptive, deadlock-free routing protocol for network-on-chip": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1811.11262",
        "ref_texts": ""
      },
      "Deep dual pyramid network for barcode segmentation using barcode-30k database": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1807.11886",
        "ref_texts": "31. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: CVPR. pp. 6230{6239 (2017)",
        "ref_ids": [
          "31"
        ]
      },
      "Automatic semantic content removal by learning to neglect": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1807.07696",
        "ref_texts": "[33] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In IEEE Conf. on Computer Vision and Pattern Recognition (CVPR) , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "33"
        ]
      },
      "Exploring multi-branch and high-level semantic networks for improving pedestrian detection": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1804.00872",
        "ref_texts": "[64] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proc. IEEE Conf. Computer Vis. Pattern Recognition , 2017.",
        "ref_ids": [
          "64"
        ]
      },
      "Interactive medical image segmentation via point-based interaction and sequential patch learning": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1804.10481",
        "ref_texts": "31. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: IEEE Conf. on Computer Vision and Pattern Recognition (CVPR). pp. 2881{2890",
        "ref_ids": [
          "31"
        ]
      },
      "Parallel grid pooling for data augmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1803.11370",
        "ref_texts": "8. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: CVPR. (2017)",
        "ref_ids": [
          "8"
        ]
      },
      "Aerial image semantic segmentation using neural search network architecture": {
        "authors": [],
        "url": "https://eprints.uet.vnu.edu.vn/eprints/id/eprint/3264/1/Thinh_miwai_0703_paper.pdf",
        "ref_texts": "23. H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \\Pyramid scene parsing network,\" in IEEE Conf. on Computer Vision and Pattern Recognition (CVPR) , pp. 2881{2890, 2017.",
        "ref_ids": [
          "23"
        ]
      },
      "A pytorch semantic segmentation toolbox": {
        "authors": [],
        "url": "https://xwcv.github.io/pubs/toolbox.pdf",
        "ref_texts": "[9] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In CVPR , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "9"
        ]
      },
      "Large kernel refine fusion net for neuron membrane segmentation": {
        "authors": [
          "Dongnan Liu",
          "Donghao Zhang",
          "Yang Song",
          "Chaoyi Zhang",
          "Heng Huang",
          "Mei Chen",
          "Weidong Cai"
        ],
        "url": "http://openaccess.thecvf.com/content_cvpr_2018_workshops/papers/w44/Liu_Large_Kernel_Refine_CVPR_2018_paper.pdf",
        "ref_texts": "[33] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In CVPR , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "33"
        ]
      },
      "Mask propagation network for video object segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1810.10289",
        "ref_texts": "[13] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In IEEE Conf. on Computer Vision and Pattern Recognition (CVPR) , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "13"
        ]
      },
      "Not all pixels are born equal: An analysis of evasion attacks under locality constraints": {
        "authors": [
          "Vikash Sehwag",
          "Not All",
          "Born Equal",
          "An Analysis",
          "Evasion Attacks",
          "Locality Constraintscl",
          "Chawin Sitawarin",
          "Arjun Nitin",
          "Arsalan Mosenia",
          "Mung Chiang",
          "Prateek Mittal",
          "Princeton University",
          "Purdue University"
        ],
        "url": "https://dl.acm.org/doi/pdf/10.1145/3243734.3278515",
        "ref_texts": "[13] Hengshuang Zhao, et al. 2016. Pyramid Scene Parsing Network. arXiv:1612.01105",
        "ref_ids": [
          "13"
        ]
      },
      "Semantic perception of curbs beyond traversability for real-world navigation assistance systems": {
        "authors": [],
        "url": "http://www.robesafe.uah.es/personal/bergasa/papers/icves2018.pdf",
        "ref_texts": "[26] H. Zhao, J. Shi, X. Qi, X. Wang and J. Jia, Pyramid scene parsing network, In IEEE Conf. on Computer Vision and Pattern Recognition (CVPR), 2017, pp. 2881-2890.",
        "ref_ids": [
          "26"
        ]
      },
      "Rapid computer vision-aided disaster response via fusion of multiresolution, multisensor, and multitemporal satellite imagery": {
        "authors": [],
        "url": "https://www-live.dfki.de/fileadmin/user_upload/import/10215_NeurIPS_ai_for_social_good.pdf",
        "ref_texts": "5 Yamazaki, F. 2001. Applications of remote sensing and gis for damage assessment. Structural Safety and Reliability 1\u201312. Yu, F.; Koltun, V.; and Funkhouser, T. A. 2017. Dilated residual networks. In CVPR. Zhang, L.; Zhang, L.; and Du, B. 2016. Deep learning for remote sensing data: A technical tutorial on the state of the art. IEEE Geoscience and Remote Sensing Magazine 4:22\u201340. Zhao, H.; Shi, J.; Qi, X.; Wang, X.; and Jia, J. 2017. Pyramid scene parsing network. In CVPR. Zhu, X. X.; Tuia, D.; Mou, L.; Xia, G.-S.; Zhang, L.; Xu, F.; and Fraundorfer, F. 2017. Deep learning in remote sensing: A comprehensive review and list of resources. IEEE Geoscience and Remote Sensing Magazine 5(4):8\u201336."
      },
      "Dense deconvolutional network for semantic segmentation": {
        "authors": [],
        "url": "https://cis.temple.edu/~latecki/Papers/Quan-ICIP2018.pdf",
        "ref_texts": "[3] Zhao H., Shi J., Qi X., Wang X., and Jia J., Y ., \u201cPyramid scene parsing network,\u201d in CVPR , 2016, pp. 6230\u20136239.",
        "ref_ids": [
          "3"
        ]
      },
      "Webseg: Learning semantic segmentation from web searches": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1803.09859",
        "ref_texts": "3. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: CVPR. (2017)",
        "ref_ids": [
          "3"
        ]
      },
      "Error correction for dense semantic image labeling": {
        "authors": [
          "Hui Huang",
          "Xu Jia",
          "Stamatios Georgoulis",
          "Tinne Tuytelaars",
          "Luc Van"
        ],
        "url": "http://openaccess.thecvf.com/content_cvpr_2018_workshops/papers/w14/Huang_Error_Correction_for_CVPR_2018_paper.pdf",
        "ref_texts": "[42] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In Proceedings of IEEE Conference on Computer Vision and Pattern Recognition , 2017. 2",
        "ref_ids": [
          "42"
        ]
      },
      "Semantic labeling of structural elements in buildings by fusing RGB and depth images in an encoder-decoder CNN framework": {
        "authors": [],
        "url": "https://isprs-archives.copernicus.org/articles/XLII-1/225/2018/isprs-archives-XLII-1-225-2018.pdf",
        "ref_texts": "231 Channels GlobalAcc MeanAcc Mean IoU RGB 71.8% 62.9% 48.7% HSD 69.4% 59.4% 45.7% RdGdBd 72.8% 67.8% 55.0% RGBD 74.7% 70.7% 56.9% Table 8. Results on semantic labeling of structural elements of buildings in test T2 (10% of the dataset for training and 90% for testing). Becker, S., Peter, M. and Fritsch, D., 2015. Grammar-supported 3d indoor reconstruction from point clouds for\u201d as-built\u201d bim. ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial Information Sciences 2(3), pp. 17. Chen, K., Lai, Y .-K. and Hu, S.-M., 2015. 3d indoor scene modeling from rgb-d data: a survey. Computational Visual Media 1(4), pp. 267\u2013278. Chen, L.-C., Papandreou, G., Kokkinos, I., Murphy, K. and Yuille, A. L., 2018. Deeplab: Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected crfs. IEEE transactions on pattern analysis and machine intelligence 40(4), pp. 834\u2013848. Del Pero, L., Bowdish, J., Fried, D., Kermgard, B., Hartley, E. and Barnard, K., 2012. Bayesian geometric modeling of indoor scenes. In: Computer Vision and Pattern Recognition (CVPR), 2012 IEEE Conference on, IEEE, pp. 2719\u20132726. F\u00a8orstner, W. and Kor \u02c7c, F., 2009. etrims image database for interpreting images of man-made scenes. Technical report, Department of Photogrammetry, University of Bonn. (TR-IGG-P-200901). Garcia, D., 2010. Robust smoothing of gridded data in one and higher dimensions with missing values. Computational statistics & data analysis 54(4), pp. 1167\u20131178. Girshick, R. B., Donahue, J., Darrell, T. and Malik, J., 2013. Rich feature hierarchies for accurate object detection and semantic segmentation. CoRR. Gupta, S., Girshick, R., Arbel \u00b4aez, P. and Malik, J., 2014. Learning rich features from rgb-d images for object detection and segmentation. In: European Conference on Computer Vision, Springer, pp. 345\u2013360. Hazirbas, C., Ma, L., Domokos, C. and Cremers, D., 2016. Fusenet: Incorporating depth into semantic segmentation via fusion-based cnn architecture. In: Asian Conference on Computer Vision, Springer, pp. 213\u2013228. Karpathy, A., 2014. What i learned from competing against a convnet on imagenet. Web: http://karpathy.github.io/2014/09/02/what-i-learned-fromcompeting-against-a-convnet-on-imagenet, Last Access: Apr. 1, 2018. Kontschieder, P., Bulo, S. R., Bischof, H. and Pelillo, M., 2011. Structured class-labels in random forests for semantic image labelling. In: Computer Vision (ICCV), 2011 IEEE International Conference on, IEEE, pp. 2190\u20132197. Liu, Z., Zhang, Y ., Wu, W., Liu, K. and Sun, Z., 2015. Modeldriven indoor scenes modeling from a single image. In: Proceedings of the 41st Graphics Interface Conference, Canadian Information Processing Society, pp. 25\u201332. Long, J., Shelhamer, E. and Darrell, T., 2015. Fully convolutional networks for semantic segmentation. In: Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 3431\u20133440.Ripperda, N., 2008. Grammar based fac \u00b8ade reconstruction using rjmcmc. PFG Photogrammetrie Fernerkundung Geoinformation 2008(2), pp. 83\u201392. Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z., Karpathy, A., Khosla, A., Bernstein, M., Berg, A. C. and Fei-Fei, L., 2015. ImageNet Large Scale Visual Recognition Challenge. International Journal of Computer Vision (IJCV) 115(3), pp. 211\u2013252. Schneider, L., Jasch, M., Fr \u00a8ohlich, B., Weber, T., Franke, U., Pollefeys, M. and R \u00a8atsch, M., 2017. Multimodal neural networks: Rgb-d for semantic segmentation and object detection. In: P. Sharma and F. M. Bianchi (eds), Image Analysis, Springer International Publishing, Cham, pp. 98\u2013109. Sherrah, J., 2016. Fully convolutional networks for dense semantic labelling of high-resolution aerial imagery. Shotton, J., Johnson, M. and Cipolla, R., 2008. Semantic texton forests for image categorization and segmentation. In: Computer vision and pattern recognition, 2008. CVPR 2008. IEEE Conference on, IEEE, pp. 1\u20138. Simonyan, K. and Zisserman, A., 2014. Very deep convolutional networks for large-scale image recognition. arXiv preprint arXiv:1409.1556. Toth, C. K. and Koppanyi, Z., 2017. Localization using regionbased convolution neural network: A comparison study. In: Proceedings of the 10th International Conference on Mobile Mapping Technology, Cairo, Eqypt. Tuttas, S. and Stilla, U., 2011. Window detection in sparse point clouds using indoor points. In: ISPRS International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences, V ol. 38-3/W22, pp. 131\u2013136. Proceedings of PIA11 Photogrammetric Image Analysis. Vadivel, A., Sural, S. and Majumdar, A., 2005. Human color perception in the hsv space and its application in histogram generation for image retrieval. Wang, G., Garcia, D., Liu, Y ., De Jeu, R. and Dolman, A. J., 2012. A three-dimensional gap filling method for large geophysical datasets: Application to global satellite soil moisture observations. Environmental Modelling & Software 30, pp. 139\u2013142. Yu, F. and Koltun, V ., 2015. Multi-scale context aggregation by dilated convolutions. arXiv preprint arXiv:1511.07122. Zeng, A., Yu, K.-T., Song, S., Suo, D., Walker, E., Rodriguez, A. and Xiao, J., 2017. Multi-view self-supervised deep learning for 6d pose estimation in the amazon picking challenge. In: Robotics and Automation (ICRA), 2017 IEEE International Conference on, IEEE, pp. 1386\u20131383. Zhao, H., Shi, J., Qi, X., Wang, X. and Jia, J., 2017. Pyramid scene parsing network. In: IEEE Conf. on Computer Vision and Pattern Recognition (CVPR). The International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences, Volume XLII-1, 2018 ISPRS TC I Mid-term Symposium \u201cInnovative Sensing \u2013 From Sensors to Methods and Applications\u201d, 10\u201312 October 2018, Karlsruhe, Germany This contribution has been peer-reviewed. https://doi.org/10.5194/isprs-archives-XLII-1-225-2018 | \u00a9 Authors 2018. CC BY 4.0 License."
      },
      "Boosting up scene text detectors with guided cnn": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1805.04132",
        "ref_texts": "[63] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017.",
        "ref_ids": [
          "63"
        ]
      },
      "Spatiotemporal modeling for efficient registration of dynamic 3D faces": {
        "authors": [],
        "url": "https://inria.hal.science/hal-01855955/file/3DV18-registration-dynamic-faces.pdf",
        "ref_texts": ""
      },
      "Development of movable binocular high-resolution eye-camera unit for humanoid and the evaluation of looking around fixation control and object recognition": {
        "authors": [
          "Tasuku Makabe",
          "Kento Kawaharazuka",
          "Kei Tsuzuki",
          "Kentaro Wada",
          "Shogo Makino",
          "Masaya Kawamura",
          "Ayaka Fujii",
          "Moritaka Onitsuka",
          "Yuki Asano",
          "Kei Okada",
          "Koji Kawasaki",
          "Masayuki Inaba"
        ],
        "url": "http://crlab.cs.columbia.edu/humanoids_2018_proceedings/media/files/0080.pdf",
        "ref_texts": "[8] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in IEEE Conf. on Computer Vision and Pattern Recognition (CVPR) , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "8"
        ]
      },
      "Multi-view inpainting for rgb-d sequence": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1811.09012",
        "ref_texts": "[36] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in IEEE Conf. on Computer Vision and Pattern Recognition (CVPR) , pp. 2881\u20132890, 2017.",
        "ref_ids": [
          "36"
        ]
      },
      "Pixel offset regression (por) for single-shot instance segmentation": {
        "authors": [],
        "url": "https://cse.buffalo.edu/~siweilyu/papers/avss18.pdf",
        "ref_texts": "[27] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In CVPR , 2017.",
        "ref_ids": [
          "27"
        ]
      },
      "Detailed dense inference with convolutional neural networks via discrete wavelet transform": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1808.01834",
        "ref_texts": "[2] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2017.",
        "ref_ids": [
          "2"
        ]
      },
      "Image-level to Pixel-wise Labeling: From Theory to Practice.": {
        "authors": [
          "Tiezhu Sun",
          "Wei Zhang",
          "Zhijie Wang",
          "Lin Ma",
          "Zequn Jie"
        ],
        "url": "https://forestlinma.com/welcome_files/Tiezhu_Sun_Image-leve_to_Pixel-wise_Labeling_via_IJCAI_2018.pdf",
        "ref_texts": "[Zhao et al., 2016 ]Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. arXiv:1612.01105, 2016.",
        "ref_ids": [
          "Zhao et al\\., 2016 "
        ]
      },
      "Perception framework of water hazards beyond traversability for real-world navigation assistance systems": {
        "authors": [],
        "url": "http://www.robesafe.com/personal/bergasa/papers/ROBIO2018_perception_open.pdf",
        "ref_texts": "[21] H. Zhao, J. Shi, X. Qi, X. Wang and J. Jia, Pyramid scene parsing network, In IEEE Conf. on Computer Vision and Pattern Recognition (CVPR), 2017, pp. 2881-2890.",
        "ref_ids": [
          "21"
        ]
      },
      "Risk-based service selection in federated clouds": {
        "authors": [],
        "url": "https://orca.cardiff.ac.uk/id/eprint/118328/1/cloudAM18.pdf",
        "ref_texts": ""
      },
      "Lucss: Language-based user-customized colourization of scene sketches": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1808.10544",
        "ref_texts": "2017. Sketch-a-Net: A Deep Neural Network that Beats Humans. International Journal of Computer Vision 122, 3 (2017), 411\u2013425. Han Zhang, Tao Xu, and Hongsheng Li. 2017. StackGAN: Text to Photo-Realistic Image Synthesis with Stacked Generative Adversarial Networks. In ICCV . 5908\u20135916. Jianhui Zhang, Yilan Chen, Lei Li, Hongbo Fu, and Chiew-Lan Tai. 2018. Context-based Sketch Classification. In Expressive 2018 . Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. 2016. Pyramid Scene Parsing Network. CoRR abs/1612.01105 (2016). Luowei Zhou, Chenliang Xu, Parker Koch, and Jason J Corso. 2016. Image Caption Generation with Text-Conditional Semantic Attention. arXiv preprint arXiv:1606.04621",
        "ref_ids": [
          "2017"
        ]
      },
      "Semantics meet saliency: Exploring domain affinity and models for dual-task prediction": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1807.09430",
        "ref_texts": "[33] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017.",
        "ref_ids": [
          "33"
        ]
      },
      "Anytime neural network: a versatile trade-off between computation and accuracy": {
        "authors": [],
        "url": "https://openreview.net/pdf?id=H1PRwFkDG",
        "ref_texts": "9 Under review as a conference paper at ICLR 2018 Lefakis, Leonidas and Fleuret, Francois. Joint Cascade Optimization Using a Product of Boosted Classifiers. In Advances in Neural Information Processing Systems (NIPS) , 2010. Li, H., Kadav, A., Durdanovic, I., Samet, H., and Graf, H. P. Pruning filters for efficient convnets. InICLR , 2017. Littlestone, N. and Warmuth, M.K. The weighted majority algorithm. Information and Computation , 1994. Liu, Z., Li, J., Shen, Z., Huang, G., Yan, S., and Zhang, C. Learning efficient convolutional networks through network slimming. In arxiv preprint:1708.06519 , 2017. Mai, Son T., Assent, Ira, and Storgaard, Martin. Anydbc: An efficient anytime density-based clustering algorithm for very large complex datasets. In KDD , 2016. Nan, Feng and Saligrama, Venkatesh. Dynamic model selection for prediction under a budget. In NIPS , 2017. Netzer, Yuval, Wang, Tao, Coates, Adam, Bissacco, Alessandro, Wu, Bo, and Ng, Andrew Y . Reading digits in natural images with unsupervised feature learning. In NIPS Workshop on Deep Learning and Unsupervised Feature Learning 2011 , 2011. Odena, A., Lawson, D., and Olah, C. Changing model behavior at test-time using reinforcement. In Arxive preprint: 1702.07780 , 2017. Rastegari, M., Ordonez, V ., Redmon, J., and Farhadi, A. Xnor-net: Imagenet classification using binary convolutional neural networks. In ECCV , 2016. Reyzin, Lev. Boosting on a budget: Sampling for feature-efficient prediction. In the 28th International Conference on Machine Learning (ICML) , 2011. Russakovsky, Olga, Deng, Jia, Su, Hao, Krause, Jonathan, Satheesh, Sanjeev, Ma, Sean, Huang, Zhiheng, Karpathy, Andrej, Khosla, Aditya, Bernstein, Michael, Berg, Alexander C., and Fei-Fei, Li. ImageNet Large Scale Visual Recognition Challenge. IJCV , 2015. Shalev-Shwartz, Shai and Wexler, Yonatan. Minimizing the maximal loss: How and why. In International Conference on Machine Learning (ICML) , 2016. Szegedy, Christian, Ioffe, Sergey, Vanhoucke, Vincent, and Alemi, Alex. Inception-v4, inceptionresnet and the impact of residual connections on learning. In AAAI , 2017. Viola, Paul A. and Jones, Michael J. Rapid Object Detection using a Boosted Cascade of Simple Features. In Computer Vision and Pattern Recognition (CVPR) , 2001. Weinberger, K.Q., Dasgupta, A., Langford, J., Smola, A., and Attenberg, J. Feature Hashing for Large Scale Multitask Learning. In ICML , 2009. Xie, Saining and Tu, Zhuowen. Holistically-nested edge detection. In ICCV , 2015. Xu, Z., Kusner, M. J., Weinberger, K. Q., Chen, M., and Chapelle, O. Classifier cascades and trees for minimizing feature evaluation cost. Journal of Machine Learning Research . Xu, Z., Weinberger, K., and Chapelle, O. The Greedy Miser: Learning under Test-time Budgets. In Proceedings of the 28th International Conference on Machine Learning (ICML) , 2012. Xu, Z., Kusner, M., Huang, G., and Weinberger, K. Q. Anytime Representation Learning. In Proceedings of the 30th International Conference on Machine Learning (ICML) , 2013. Yang, Y ., Webb, G., Korb, K., and Ting, K. Classifying under computational resource constraints: Anytime classification using probabilistic estimators. Mach. Learn. , 2007. Zagoruyko, Sergey and Komodakis, Nikos. Wide residual networks. In British Machine Vision Conference (BMVC) , 2016. Zamir, Amir R., Wu, Te-Lin, Sun, Lin, Shen, William, Malik, Jitendra, and Savarese, Silvio. Feedback networks. In Computer Vision and Pattern Recognition (CVPR) , 2017. Zhao, Hengshuang, Shi, Jianping, Qi, Xiaojuan, Wang, Xiaogang, and Jia, Jiaya. Pyramid scene parsing network. In Computer Vision and Pattern Recognition (CVPR) , 2017."
      },
      "Diagnostics in semantic segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1809.10328",
        "ref_texts": "27. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: CVPR (2017)",
        "ref_ids": [
          "27"
        ]
      },
      "Deep learning algorithm to identify cancer pictures": {
        "authors": [],
        "url": "https://koreascience.kr/article/JAKO201831960579946.pdf",
        "ref_texts": "[17] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, Jiaya Jia, \u201cPyramid Scene Parsing Network\u201d, IEEE Confernce on Computer Vision and Pattern Recognition (CVPR), pp. 6230 6239, July 2017. ",
        "ref_ids": [
          "17"
        ]
      },
      "A simple non-iid Sampling approach for efficient training and better generalization": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1811.09347",
        "ref_texts": "[56] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017. 1, 6, 7",
        "ref_ids": [
          "56"
        ]
      },
      "Stacked encoder-decoders for accurate semantic segmentation of very high resolution satellite datasets": {
        "authors": [],
        "url": "https://hal.science/hal-01870857/document",
        "ref_texts": "[5] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia, \u201cPyramid scene parsing network,\u201d in Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2017.",
        "ref_ids": [
          "5"
        ]
      },
      "Segment-and-count: Vehicle counting in aerial imagery using atrous convolutional neural networks": {
        "authors": [],
        "url": "https://isprs-archives.copernicus.org/articles/XLII-1/19/2018/isprs-archives-XLII-1-19-2018.pdf",
        "ref_texts": "3466. Redmon, J. and Farhadi, A., 2017. Yolo9000: better, faster, stronger. arXiv preprint arXiv:1612.08242. Ren, S., He, K., Girshick, R. and Sun, J., 2015. Faster r-cnn: Towards real-time object detection with region proposal networks. In: Advances in neural information processing systems , pp. 91\u201399. Sherrah, J., 2016. Fully convolutional networks for dense semantic labelling of high-resolution aerial imagery. arXiv preprint arXiv:1606.02585. Simonyan, K. and Zisserman, A., 2014. Very deep convolutional networks for large-scale image recognition. arXiv preprint arXiv:1409.1556. Tang, T., Zhou, S., Deng, Z., Zou, H. and Lei, L., 2017. Vehicle detection in aerial images based on region convolutional neural networks and hard negative example mining. In: Sensors, V ol. 17number 2, Multidisciplinary Digital Publishing Institute, p. 336. Yang, M., Yu, K., Zhang, C., Li, Z. and Yang, K., 2018. DenseASPP for semantic segmentation in street scenes. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 3684\u20133692. Yu, F. and Koltun, V ., 2015. Multi-scale context aggregation by dilated convolutions. arXiv preprint arXiv:1511.07122. Yuan, J., 2016. Automatic building extraction in aerial scenes using convolutional networks. arXiv preprint arXiv:1602.06564. Zhao, H., Shi, J., Qi, X., Wang, X. and Jia, J., 2017. Pyramid scene parsing network. In: IEEE Conf. on Computer Vision and Pattern Recognition (CVPR), pp. 2881\u20132890. The International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences, Volume XLII-1, 2018 ISPRS TC I Mid-term Symposium \u201cInnovative Sensing \u2013 From Sensors to Methods and Applications\u201d, 10\u201312 October 2018, Karlsruhe, Germany This contribution has been peer-reviewed. https://doi.org/10.5194/isprs-archives-XLII-1-19-2018 | \u00a9 Authors 2018. CC BY 4.0 License.",
        "ref_ids": [
          "3466"
        ]
      },
      "Cidpro: Custom instructions for dynamic program diversification": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1809.01221",
        "ref_texts": ""
      },
      "Task-specific vision models explain task-specific areas of visual cortex": {
        "authors": [],
        "url": "https://www.biorxiv.org/content/biorxiv/early/2018/08/28/402735.full.pdf",
        "ref_texts": "27. Zhao H, Shi J, Qi X, Wang X, Jia J. Pyramid Scene Parsing Network. In: Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR); 2017. August 21, 2018 16/17. CC-BY 4.0 International licenseacertified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made available under The copyright holder for this preprint (which was not this version posted August 28, 2018. ; https://doi.org/10.1101/402735doi: bioRxiv preprint ",
        "ref_ids": [
          "27"
        ]
      },
      "Cross-connected networks for multi-task learning of detection and segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1805.05569",
        "ref_texts": "27. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: Proceedings of Computer Vision and Pattern Recognition (CVPR). (2017)",
        "ref_ids": [
          "27"
        ]
      },
      "CuisineNet: food attributes classification using multi-scale convolution network": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1805.12081",
        "ref_texts": "[16] H. Zhao, J. Shi, X. Qi, X. Wang and J. Jia, Pyramid scene parsing network, in: IEEE Conf. on Computer Vision and Pattern Recognition (CVPR) , 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "16"
        ]
      },
      "Improvement in accuracy and speed of image semantic segmentation via convolution neural network encoder-decoder": {
        "authors": [],
        "url": "http://jist.ir/WebUsers/jist/UploadFiles/OK/13970703164554-F.pdf",
        "ref_texts": "[22] H. Zhao , J. Shi, X. Qi, X. Wang, and J. Jia, \u2015Pyramid Scene Parsing Network,\u2016 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 6230 -6239, 2017. ",
        "ref_ids": [
          "22"
        ]
      },
      "Understanding popularity growth of packages in JavaScript package ecosystem": {
        "authors": [],
        "url": "http://sel.ist.osaka-u.ac.jp/lab-db/betuzuri/archive/1116/1116.pdf",
        "ref_texts": ""
      },
      "Using sgx-based virtual clones for iot security": {
        "authors": [],
        "url": "https://razaaliraza.github.io/papers/iotSGX.pdf",
        "ref_texts": ""
      },
      "Mason: A model agnostic objectness framework": {
        "authors": [
          "K J",
          "Rajiv Chunilal",
          "Amit Srivastava",
          "Uma Gupta",
          "Vineeth N"
        ],
        "url": "http://openaccess.thecvf.com/content_ECCVW_2018/papers/11133/Joseph_MASON_A_Model_AgnoStic_ObjectNess_Framework_ECCVW_2018_paper.pdf",
        "ref_texts": ""
      },
      "ScaleNet: Scale Invariant Network for Semantic Segmentation in Urban Driving Scenes.": {
        "authors": [],
        "url": "https://www.scitepress.org/papers/2018/67230/67230.pdf",
        "ref_texts": "(2013). Learning hierarchical features for scene labeling. Pattern Analysis and Machine Intelligence (PAMI) , 35(8):1915\u20131929. Grauman, K. and Darrell, T. (2005). The pyramid match kernel: Discriminative classification with sets of image features. In International Conference on Computer Vision (ICCV) , volume 2, pages 1458\u20131465. IEEE. Holschneider, M., Kronland-Martinet, R., Morlet, J., and Tchamitchian, P. (1990). A real-time algorithm for signal analysis with the help of the wavelet transform. InWavelets , pages 286\u2013297. Springer. Kong, S. and Fowlkes, C. (2017). Recurrent scene parsing with perspective understanding in the loop. arXiv preprint arXiv:1705.07238 . Lazebnik, S., Schmid, C., and Ponce, J. (2006). Beyond bags of features: Spatial pyramid matching for recognizing natural scene categories. In Computer Vision and Pattern Recognition (CVPR) , volume 2, pages 2169\u20132178. IEEE. Li, Y ., Qi, H., Dai, J., Ji, X., and Wei, Y . (2016). Fully convolutional instance-aware semantic segmentation. arXiv preprint arXiv:1611.07709 . Lin, G., Milan, A., Shen, C., and Reid, I. (2016a). Refinenet: Multi-path refinement networks with identity mappings for high-resolution semantic segmentation. arXiv preprint arXiv:1611.06612 . Lin, G., Shen, C., van den Hengel, A., and Reid, I. (2016b). Efficient piecewise training of deep structured models for semantic segmentation. In Computer Vision and Pattern Recognition (CVPR) , pages 3194\u20133203.Lin, T.-Y ., Maire, M., Belongie, S., Hays, J., Perona, P., Ramanan, D., Doll \u00b4ar, P., and Zitnick, C. L. (2014). Microsoft coco: Common objects in context. In European conference on computer vision (ECCV) , pages 740\u2013755. Springer. Long, J., Shelhamer, E., and Darrell, T. (2015a). Fully convolutional networks for semantic segmentation. In Computer Vision and Pattern Recognition (CVPR) . Long, J., Shelhamer, E., and Darrell, T. (2015b). Fully convolutional networks for semantic segmentation. In Computer Vision and Pattern Recognition (CVPR) , pages 3431\u20133440. Noh, H., Hong, S., and Han, B. (2015). Learning deconvolution network for semantic segmentation. In International Conference on Computer Vision (ICCV) , pages 1520\u20131528. Ronneberger, O., Fischer, P., and Brox, T. (2015). Unet: Convolutional networks for biomedical image segmentation. In International Conference on Medical Image Computing and Computer-Assisted Intervention , pages 234\u2013241. Springer. Schuster, R., Wasenm \u00a8uller, O., Kuschk, G., Bailer, C., and Stricker, D. (2018). Sceneflowfields: Dense interpolation of sparse scene flow correspondences. In IEEE Winter Conference on Computer Vision (WACV) . Vedaldi, A. and Lenc, K. (2015). Matconvnet \u2013 convolutional neural networks for matlab. In Proceeding of the ACM Int. Conf. on Multimedia . Wasenm \u00a8uller, O., Ansari, M. D., and Stricker, D. (2016). Dna-slam: Dense noise aware slam for tof rgb-d cameras. In Asian Conference on Computer Vision Workshop (ACCV workshop) . Springer. Wasenm \u00a8uller, O., Bleser, G., and Stricker, D. (2015). Combined bilateral filter for enhanced real-time upsampling of depth images. In International Conference on Computer Vision Theory and Applications (VISAPP) , pages 5\u201312. Wu, Z., Shen, C., and Hengel, A. v. d. (2016). Bridging category-level and instance-level semantic image segmentation. arXiv preprint arXiv:1605.06885 . Yoshida, T., Wasenm \u00a8uller, O., and Stricker, D. (2017). Time-of-flight sensor depth enhancement for automotive exhaust gas. In IEEE International Conference on Image Processing (ICIP) . Zhao, H., Shi, J., Qi, X., Wang, X., and Jia, J. (2016). Pyramid scene parsing network. arXiv preprint arXiv:1612.01105 .VISAPP 2018 International Conference on Computer Vision Theory and Applications 404"
      },
      "Domain adaptive semantic segmentation through structure enhancement": {
        "authors": [
          "Fengmao Lv",
          "Qing Lian",
          "Guowu Yang",
          "Guosheng Lin",
          "Sinno Jialin",
          "Lixin Duan"
        ],
        "url": "http://openaccess.thecvf.com/content_ECCVW_2018/papers/11130/Lv_Domain_Adaptive_Semantic_Segmentation_through_Structure_Enhancement_ECCVW_2018_paper.pdf",
        "ref_texts": ""
      },
      "Inter-bmv: Interpolation with block motion vectors for fast semantic segmentation on video": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1810.04047",
        "ref_texts": "9 Evan Shelhamer, Kate Rakelly, Judy Hoffman, and Trevor Darrell. Clockwork convnets for video semantic segmentation. In Video Semantic Segmentation Workshop at ECCV , 2016. Jamie Shotton, John Winn, Carsten Rother, and Antonio Criminisi. Textonboost for image understanding: Multi-class object recognition and segmentation by jointly modeling texture, layout, and context. IJCV , 81(1):2\u201323, 2009. Karen Simonyan and Andrew Zisserman. Two-stream convolutional networks for action recognition in videos. In NIPS , 2014. Paul Sturgess, Karteek Alahari, L\u2019ubor Ladick \u00b4y, and Phillip H. S. Torr. Combining appearance and structure from motion features for road scene understanding. In BMVC , 2009. Chao-Yuan Wu, Manzil Zaheer, Hexiang Hu, R. Manmatha, Alexander J Smola, and Philipp Krhenbhl. Compressed video action recognition. In CVPR , 2018. Yu-Syuan Xu, Tsu-Jui Fu, Hsuan-Kung Yang, and Chun-Yi Lee. Dynamic video segmentation network. In CVPR , 2018. Fisher Yu and Vladlen Koltun. Multi-scale context aggregation by dilated convolutions. In ICLR , 2016. Fisher Yu, Vladlen Koltun, and Thomas Funkhouser. Dilated residual networks. In CVPR , 2017. Bowen Zhang, Limin Wang, Zhe Wang, Yu Qiao, and Hanli Wang. Real-time action recognition with enhanced motion vector cnns. In CVPR , 2016. Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR , 2017. Xizhou Zhu, Yuwen Xiong, Jifeng Dai, Lu Yuan, and Yichen Wei. Deep feature flow for video recognition. In CVPR , 2017. Xizhou Zhu, Jifeng Dai, Lu Yuan, and Yichen Wei. Toward high performance video object detection. InCVPR , 2018."
      },
      "\uac00\ub85c\uacf5\uac04 \ubcf4\ud589\ub9cc\uc871\ub3c4 \uc608\uce21\uc744 \uc704\ud55c \ub525\ub7ec\ub2dd \ubaa8\ud615\uc758 \uc801\uc6a9\uacfc \uac80\uc99d": {
        "authors": [],
        "url": "https://repository.hanyang.ac.kr/bitstream/20.500.11754/120821/1/%EA%B0%80%EB%A1%9C%EA%B3%B5%EA%B0%84%20%EB%B3%B4%ED%96%89%EB%A7%8C%EC%A1%B1%EB%8F%84%20%EC%98%88%EC%B8%A1%EC%9D%84%20%EC%9C%84%ED%95%9C%20%EB%94%A5%EB%9F%AC%EB%8B%9D%20%EB%AA%A8%ED%98%95%EC%9D%98%EC%A0%81%EC%9A%A9%EA%B3%BC%20%EA%B2%80%EC%A6%9D.pdf",
        "ref_texts": "26.Zhao,\u0000 H\u0000et\u0000al.\u00002017,\u0000 \u2018Pyramid\u0000 scene\u0000 parsing\u0000 network\u2019,\u0000 proceedings\u0000 of\u0000the\u0000 IEEE\u0000 on\u0000computer\u0000 vision\u0000 and\u0000pattern\u0000 recognition ,\u0000Hawaii\u0000 Convention\u0000 Center,\u0000 Honolulu,\u0000 pp.2881-2890.\u0000",
        "ref_ids": [
          "26"
        ]
      },
      "Real-time Image Semantic Segmentation Networks with Residual Depth-wise Separable Blocks": {
        "authors": [],
        "url": "http://eprints.uet.vnu.edu.vn/eprints/3263/1/review_2.pdf",
        "ref_texts": "[24] Zhao, Hengshuang et al. \u201cPyramid scene parsing network\u201d. In: IEEE Conf. on Computer Vision and Pattern Recognition (CVPR) . 2017, pp. 2881\u20132890.",
        "ref_ids": [
          "24"
        ]
      },
      "Towards closing the gap in weakly supervised semantic segmentation with dcnns: Combining local and global models": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1808.01625",
        "ref_texts": "[39] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , July 2017. 7, 10",
        "ref_ids": [
          "39"
        ]
      },
      "Neural cell segmentation in large-scale 3D color fluorescence microscopy images for developemental neuroscience": {
        "authors": [],
        "url": "https://polytechnique.hal.science/hal-01910114/file/Nourbakhsh_et_al_final_manuscript.pdf",
        "ref_texts": "[13] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d CoRR , vol. abs/1612.01105, 2016.",
        "ref_ids": [
          "13"
        ]
      },
      "Functionally modular and interpretable temporal filtering for robust segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1810.03867",
        "ref_texts": "[27] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In IEEE Conf. on Computer Vision and Pattern Recognition (CVPR) , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "27"
        ]
      },
      "Person segmentation using convolutional neural networks with dilated convolutions": {
        "authors": [
          "David Joon",
          "Qian Lin"
        ],
        "url": "https://library.imaging.org/admin/apis/public/api/ist/website/downloadArticle/ei/30/10/art00016",
        "ref_texts": ""
      },
      "Real Time Incremental Foveal Texture Mapping for Autonomous Vehicles": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2101.06393",
        "ref_texts": "[7] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2017.",
        "ref_ids": [
          "7"
        ]
      },
      "Viewpoint quality evaluation for augmented virtual environment": {
        "authors": [
          "Ming Meng"
        ],
        "url": "http://nave.vr3i.com/attached/file/20181017/20181017161824_432.pdf",
        "ref_texts": "30. Zhao, H.S., Shi, J.P., Qi, X.J.: Pyramid scene parsing network. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2881 \u20132890 (2017)",
        "ref_ids": [
          "30"
        ]
      },
      "Captain: Comprehensive composition assistance for photo taking": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1811.04184",
        "ref_texts": "1186 Xue SF, Tang H, Tretter D, Lin Q, Allebach J (2013) Feature design for aesthetic inference on photos with faces. In: IEEE conference on image processing, pp 2689\u20132693 Yan J, Lin S, Kang S, Tang X (2013) Learning the change for automatic image cropping. In: IEEE conference on computer vision and pattern recognition, pp 971\u2013978 Yao L, Suryanarayan P, Qiao M, Wang JZ, Li J (2012) Oscar: On-site composition and aesthetics feedback through exemplars for photographers. International Journal of Computer Vision 96(3):353\u2013383 Zhang M, Zhang L, Sun Y, Feng L, Ma Wy (2005) Auto croppingfordigitalphotographs.In:IEEEconference on multimedia and expo Zhao H, Shi J, Qi X, Wang X, Jia J (2017) Pyramid scene parsing network. In: IEEE conference on computer vision and pattern recognition, pp 2881\u20132890 Zhou B, Zhao H, Puig X, Fidler S, Barriuso A, Torralba A (2017a) Scene parsing through ade20k dataset. In: IEEE conference on computer vision and pattern recognition Zhou Z, Farhat F, Wang JZ (2016) Detecting dominant vanishing points in natural scenes with application to composition-sensitive image retrieval. arXiv preprint arXiv:160804267 Zhou Z, Farhat F, Wang JZ (2017b) Detecting dominant vanishing points in natural scenes with application to composition-sensitive image retrieval. IEEE Transactions on Multimedia 19(12):2651\u20132665"
      },
      "Adversarial learning for image forensics deep matching with atrous convolution": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1809.02791",
        "ref_texts": "[38] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proc. IEEE Conf. Comput. Vis. Pattern Recognit. , Jul. 2017, pp. 6230\u20136239.",
        "ref_ids": [
          "38"
        ]
      },
      "Fast, Better Training Trick--Random Gradient": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1808.04293",
        "ref_texts": "15 Wei OlgaRussakovsky, JiaDeng, HaoSu, JonathanKrause, SanjeevSatheesh, SeanMa, Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael Bernstein, Alexander C. Berg, and LiFei-Fei. Imagenetlargescalevisualrecognitionchallenge, 2015. InIJCV,pages10.1007/ s11263\u00e2\u0102\u015e015\u00e2\u0102\u015e0816\u00e2\u0102\u015ey. Tim Salimans, Ian Goodfellow, Wojciech Zaremba, Vicki Cheung, Alec Radford, and Xi Chen. Improved techniques for training gans. 2016. Mark Sandler, Andrew Howard, Menglong Zhu, Andrey Zhmoginov, and Liang Chieh Chen. Mobilenetv2: Inverted residuals and linear bottlenecks. 2018. LeslieN.Smith. Cyclicallearningratesfortrainingneuralnetworks, 2015. arXiv:1506.01186. Leslie N. Smith and Nicholay Topin. Super-convergence: very fast training of residual networks using large learning rates., 2017. Samuel L. Smith and Quoc V. Le. A bayesian perspective on generalization and stochastic gradient descent, 2017. arXiv:1710.06451. Samuel L. Smith, Pieter-Jan Kindermans, Chris Ying, and Quoc V. Le. Don\u2019t decay the learning rate, increase the batch size, 2017. arXiv:1711.00489. Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdinov. Dropout: a simple way to prevent neural networks from overfitting. Journal of Machine Learning Research , 15(1):1929\u20131958, 2014. Panqu Wang, Pengfei Chen, Ye Yuan, Ding Liu, Zehua Huang, Xiaodi Hou, and Garrison Cottrell. Understanding convolution for semantic segmentation. pages 1451\u20131460, 2017. Saining Xie, Ross Girshick, Piotr Dollar, Zhuowen Tu, and Kaiming He. Aggregated residual transformations for deep neural networks. pages 5987\u20135995, 2016. YangYou, IgorGitman, andBorisGinsburg. Largebatchtrainingofconvolutionalnetworks, 2017. arXiv:1708.03888. Sergey Zagoruyko and Nikos Komodakis. Wide residual networks. 2016. H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In CVPR , 2017. Junbo Zhao, Michael Mathieu, and Yann Lecun. Energy-based generative adversarial network. 2016. Jun Yan Zhu, Taesung Park, Phillip Isola, and Alexei A Efros. Unpaired image-to-image translation using cycle-consistent adversarial networks. pages 2242\u20132251, 2017."
      },
      "A network structure to explicitly reduce confusion errors in semantic segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1808.00313",
        "ref_texts": "46. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: IEEE Conf. on Computer Vision and Pattern Recognition (CVPR). pp. 2881\u20132890 (2017)",
        "ref_ids": [
          "46"
        ]
      },
      "Bayesian prediction of future street scenes through importance sampling based optimization": {
        "authors": [],
        "url": "https://pure.mpg.de/rest/items/item_2609268/component/file_2609267/content",
        "ref_texts": "[27] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In CVPR , 2017.",
        "ref_ids": [
          "27"
        ]
      },
      "SIVO: Semantically Informed Visual Odometry and Mapping": {
        "authors": [
          "Pranav Ganti"
        ],
        "url": "https://uwspace.uwaterloo.ca/bitstream/handle/10012/14111/Ganti_Pranav.pdf?sequence=1&isAllowed=y",
        "ref_texts": "[54] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \\Pyramid scene parsing network,\" in IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2017, pp.",
        "ref_ids": [
          "54"
        ]
      },
      "Segmentation s\u00e9mantique profonde par r\u00e9gression sur cartes de distances sign\u00e9es": {
        "authors": [],
        "url": "https://hal.science/hal-01809991/document",
        "ref_texts": "[41] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid Scene Parsing Network. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "41"
        ]
      },
      "Automatic lesion boundary detection in dermoscopy": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1812.00877",
        "ref_texts": "[5] Xiaojuan Qi Xiaogang Wang Hengshuang Zhao, Jianping Shi and Jiaya Jia. Pyramid scene parsing network. Arxiv , 2016.",
        "ref_ids": [
          "5"
        ]
      },
      "Automatic Segmentation of Ships in Digital Images": {
        "authors": [],
        "url": "https://repository.tudelft.nl/file/File_2367354b-1d96-4775-97f3-dd2e153c1c0b?preview=1",
        "ref_texts": "[29] H. Zhao et al. Pyramid Scene Parsing Network . 2016. arXiv: 1612.01105 .",
        "ref_ids": [
          "29"
        ]
      },
      "Robotic surgical instrument segmentation using dual global attention upsample": {
        "authors": [],
        "url": "https://www.doc.ic.ac.uk/~bglocker/public/mednips2018/med-nips_2018_paper_106.pdf",
        "ref_texts": "[10] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In IEEE Conf. on Computer Vision and Pattern Recognition (CVPR) , pages 2881\u20132890, 2017.",
        "ref_ids": [
          "10"
        ]
      },
      "Semantic Segmentation, Urban Navigation, and Research Directions": {
        "authors": [],
        "url": "https://www.cs.princeton.edu/courses/archive/spring18/cos598B/public/projects/LiteratureReview/COS598B_spr2018_SemanticSegmentationNavigation.pdf",
        "ref_texts": "[41] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2017.",
        "ref_ids": [
          "41"
        ]
      },
      "Text Spotting in the Wild": {
        "authors": [],
        "url": "https://escholarship.org/content/qt89p4j73z/qt89p4j73z.pdf",
        "ref_texts": "[101] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In IEEE Conf. on Computer Vision and Pattern Recognition (CVPR) , pages 2881{2890, 2017.",
        "ref_ids": [
          "101"
        ]
      },
      "Exploiting test time evidence to improve predictions of deep neural networks": {
        "authors": [],
        "url": "https://www.cse.iitd.ac.in/~parags/papers/workshop/2019/etteipdnn-lire_nips19.pdf",
        "ref_texts": ""
      },
      "Identifying potholes under challenging weather conditions": {
        "authors": [],
        "url": "https://cerv.aut.ac.nz/wp-content/uploads/2018/09/CeRV-TR-110.pdf",
        "ref_texts": "[31] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network\u201d, CoRR , 1612.01105, 2016.",
        "ref_ids": [
          "31"
        ]
      },
      "Combining pyramid pooling and attention mechanism for pelvic MR image semantic segmentaion": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1806.00264",
        "ref_texts": "22. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. CVPR (2017)",
        "ref_ids": [
          "22"
        ]
      },
      "How machine perception relates to human perception: visual saliency and distance in a frame-by-frame semantic segmentation task for highly/fully automated driving": {
        "authors": [],
        "url": "https://www.dfki.de/fileadmin/user_upload/import/9824_machine-perception-relates_SEFAIAS.pdf",
        "ref_texts": "[11] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. 2016. Pyramid Scene Parsing Network. CoRR abs/1612.01105 (2016). arXiv:1612.01105 http://arxiv.org/abs/1612.01105",
        "ref_ids": [
          "11"
        ]
      },
      "Learning reliable and scalable representations using multimodal multitask deep learning": {
        "authors": [],
        "url": "http://ais.informatik.uni-freiburg.de/publications/papers/valada18rsspi.pdf",
        "ref_texts": "[7]H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proceedings of the Conference on Computer Vision and Pattern Recognition , 2017.",
        "ref_ids": [
          "7"
        ]
      },
      "Sensing, perception and decision for deep learning based autonomous driving": {
        "authors": [],
        "url": "http://mprg.jp/data/MPRG/C_group/C20180720_yamashita.pdf",
        "ref_texts": "23. H. Zhao, J. Shi, X. Qi, X. Wang and J. Jia, \\Pyramid Scene Parsing Network\", arXiv preprint arXiv:1612.01105,2016.",
        "ref_ids": [
          "23"
        ]
      },
      "Apprentissage automatique pour la d\u00e9tection d'anomalies dans les donn\u00e9es ouvertes: application \u00e0 la cartographie": {
        "authors": [],
        "url": "https://theses.hal.science/tel-02100741/file/DELASSUS_REMI_2018.pdf",
        "ref_texts": "148 R\u00e9mi Delassus BIBLIOGRAPHIE Yakimovsky etFeldman ,2009. Asemantics-baseddecisiontheoryregionanalyser. IJCAI, 73 :580\u2013588. Yang, Lin,Wu, Xiaqing, Praun, Emil et Ma, Xiaoxu, 2009. Tree detection from aerial imagery. Dans Proceedings of the 17th ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems ,pages131\u2013137.ACM. Yu, Fisher et Koltun, Vladlen, 2015. Multi-scale context aggregation by dilated convolutions. arXiv preprint arXiv :1511.07122 . Yu, Zhiding et Zhang, Cha, 2015. Image based static facial expression recognition with multiple deep network learning. Dans Proceedings of the 2015 ACM on International Conference on Multimodal Interaction , pages 435\u2013442. ACM. Yuan, Jiangye, 2016. Automatic building extraction in aerial scenes using convolutional networks. arXiv preprint arXiv :1602.06564 . Yuan,Jiangye,2017. Learningbuildingextractioninaerialsceneswithconvolutional networks. IEEE transactions on pattern analysis and machine intelligence . Yuille, Alan L, Hallinan , Peter W et Cohen, David S, 1992. Feature extraction from faces using deformable templates. International journal of computer vision , 8(2) :99\u2013111. Zaharia ,Matei,Chowdhury ,Mosharaf, Franklin ,MichaelJ, Shenker ,Scottet Stoica, Ion, 2010. Spark : Cluster computing with working sets. Dans HotCLoud , tome 10, pages 10\u201310. Zeng, Nianyin, Zhang, Hong,Song, Baoye,Liu, Weibo,Li, Yurong et Dobaie, Abdullah M, 2018. Facial expression recognition via learning deep sparse autoencoders.Neurocomputing , 273 :643\u2013649. Zhao, Hengshuang, Shi, Jianping, Qi, Xiaojuan, Wang, Xiaogang et Jia, Jiaya, 2016. Pyramid scene parsing network. arXiv preprint arXiv :1612.01105 . Zhao, Kang,Kang, Jungwon, Jung, Jaewook et Sohn, Gunho, 2018. Building extraction from satellite images using mask r-cnn with building boundary regularization. Dans Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops , pages 247\u2013251. Ziegler , Julius, Bender , Philipp, Schreiber , Markus, Lategahn , Henning, Strauss ,Tobias,Stiller,Christoph, Dang,Thao,Franke ,Uwe,Appenrodt , Nils,Keller, Christoph G et al., 2014. Making bertha drive\u2014an autonomous journey on a historic route. IEEE Intelligent Transportation Systems Magazine , 6(2) :8\u201320. Zojaji, Zahra,Atani, Reza Ebrahimi, Monadjemi , Amir Hassan et al., 2016. A survey of credit card fraud detection techniques : data and technique oriented perspective. arXiv preprint arXiv :1611.06439 . D\u00e9tection d\u2019anomalies dans les donn\u00e9es ouvertes 149"
      },
      "ICNet for Real-Time Semantic Segmentation on High-Resolution Images\u2014Supplementary Material": {
        "authors": [],
        "url": "https://i.cs.hku.hk/~hszhao/paper/eccv18_icnet_supp.pdf",
        "ref_texts": "6. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: CVPR. (2017)",
        "ref_ids": [
          "6"
        ]
      },
      "USING STREET-LEVEL IMAGES AND DEEP LEARNING FOR URBAN LANDSCAPE STUDIES": {
        "authors": [],
        "url": "https://scholar.archive.org/work/r7q6psembvevzjhn7vcarsnzny/access/wayback/https://hep-journal.oss-cn-beijing.aliyuncs.com/hep-wk/fileup/2095-5405/PDF/2095-5405-2018-2-20.pdf?Expires=1581517498&OSSAccessKeyId=LTAIuKHpoKLDbF9n&Signature=sUXvSczvGT92NbfRBEEn6X%2Fx7og%3D",
        "ref_texts": "[15] Zhao, H., Shi, J., Qi, X., Wang, X., & Jia, J. (2017, July). Pyramid scene parsing network. In Ieee Conference on Computer vision and Pattern Recognition (pp. 6230-6239). Ieee Computer Society, Honolulu.",
        "ref_ids": [
          "15"
        ]
      },
      "\u81ea\u52d5\u904b\u8ee2\u30b7\u30b9\u30c6\u30e0\u306b\u304a\u3051\u308b AI \u6280\u8853": {
        "authors": [],
        "url": "https://www.jstage.jst.go.jp/article/sicejl/57/7/57_493/_pdf",
        "ref_texts": "1\u02a3H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia: Pyramid Scene Parsing Network, CVPR\u201917 , 2881/2890 (2017)"
      },
      "CT-To-MR Conditional Generative Adversarial Networks for Improved Stroke Lesion Segmentation": {
        "authors": [],
        "url": "https://openreview.net/pdf?id=HyemZQzExE",
        "ref_texts": "10 CT-To-MR Conditional Generative Adversarial Networks Jelmer M Wolterink, Tim Leiner, and Ivana Isgum. Blood vessel geometry synthesis using generative adversarial networks. arXiv preprint arXiv:1804.04381 , 2018. Fisher Yu and Vladlen Koltun. Multi-scale context aggregation by dilated convolutions. arXiv preprint arXiv:1511.07122 , 2015. Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In IEEE Conf. on Computer Vision and Pattern Recognition (CVPR) , pages 2881{2890, 2017. Jun-Yan Zhu, Taesung Park, Phillip Isola, and Alexei A Efros. Unpaired image-to-image translation using cycle-consistent adversarial networks. In Computer Vision (ICCV), 2017 IEEE International Conference on , 2017."
      },
      "A Residual encoder-decoder network for semantic segmentation in autonomous driving scenarios": {
        "authors": [],
        "url": "https://doras.dcu.ie/22505/1/A%20Residual%20Encoder-Decoder%20Network%20for%20Semantic%20Segmentation%20in%20Autonomous%20Driving%20Scenarios_Camera%20ready_Paper%20_ID_%23905%20(1570439315).pdf",
        "ref_texts": "[6] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d arXiv preprint arXiv:1612.01105 , 2016.",
        "ref_ids": [
          "6"
        ]
      },
      "Measurements of retinal microvasculature in mice and humans with deep learning": {
        "authors": [],
        "url": "https://iro.uiowa.edu/view/pdfCoverPage?instCode=01IOWA_INST&filePid=13730832760002771&download=true",
        "ref_texts": "[106] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \\Pyramid scene parsing network,\" inIEEE Conf. on Computer Vision and Pattern Recognition (CVPR), 2017, pp. 2881{2890.",
        "ref_ids": [
          "106"
        ]
      },
      "Exploiting visual context and consistency for semantic segmentation": {
        "authors": [],
        "url": "https://dr.ntu.edu.sg/bitstream/10356/80532/1/RunAll_softcopy.pdf",
        "ref_texts": "2.1.3.1 Visual Context Cues Visual context cues are most frequently encoded as a new type of computational layers, which are trained together end-to-end with a pretrained classiffcation network to perform semantic segmentation. For example, to encode global scene context, in the ParseNet work [59], feature maps average pooled from the entire image are concatenated with the local feature maps before the ffnal classiffcation layer. Zhao et al. [15] propose a pyramid scene parsing network to integrate global context information pooled from feature maps at difierent levels of a spatial pyramid. To encode region context, Holger et al. [26] propose an end-to-end image semantic segmentation system. In their approach, each region mask is ffrst classiffed using a free-form ROI pooling layer, then the mask classiffcation scores are converted into pixel classiffcation scores with a difierentiable region-to-pixel layer. Their region-to-pixel layer is also adopted in Chapter 5 of this thesis, where we exploit region context to develop an actor-action semantic segmentation system. Context cues can also be modeled with a new type of network operator. For example, dilated convolution operator [2, 3] is proposed to rapidly increase the fflter receptive ffeld size (i.e., to incorporate long-range context information) while preserving the same feature map resolution. It is one of key elements in many Nanyang Technological University 15 Singapore Chapter 2. Literature Review state-of-the-art semantic segmentation networks [2, 3, 15, 60] and has been successfully applied to other dense prediction tasks [61] as well. By adjusting the dilation rate, dilation convolution operator can also be used to model the multi-scale context information as was done in the DeepLab approach [3]. We adopt the DeepLab network [3] as the basis for developing our approach in Chapter 5 due to its good performance.",
        "ref_ids": [
          "59",
          "15",
          "26",
          "61",
          "3",
          "3"
        ]
      },
      "Using CNN for Ellipse Estimation in An Infant Length Measurement Application": {
        "authors": [],
        "url": "http://www.apsipa.org/proceedings/2018/pdfs/0001383.pdf",
        "ref_texts": "[11] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid Scene Parsing Network,\u201d in IEEE Conf erence on Computer Vision and Pattern Recognition (CVPR) , 2017. ",
        "ref_ids": [
          "11"
        ]
      },
      "Automatic segmentation of the human thigh muscles in magnetic resonance imaging": {
        "authors": [],
        "url": "https://e-space.mmu.ac.uk/621007/1/1_PhDThesis_EzakAhmad_12105717.pdf",
        "ref_texts": "7.2.3 PSPNet In 2016, Zhou et al. proposed a network architecture called Pyramid Scene Parsing Network (PSPNet )[3]. In this work, the research team from Chinese University of Hong Chapter 7. Semantic Segmentation of MR Images of Human Thigh Muscle 124 Kong and SenseTime Group Limited used the global context information proficiency by aggregation of a di\u21b5erent-region-based context. The global spatial context is important since it provides suggestions on the distribution of the segmentation classes. This procedure is done by the combination of a pyramid pooling module (applying large kernel pooling layers) and the proposed PSPNet, and proved to have an e\u21b5ective global prior representation capable to produce good results in the scene parsing tasks and pixel-level predictions. Other key features of this architecture include: integrating dilated convolutions as a means of modifying the base architecture of Residual Network ResNet [252], a 152-layer network architecture proposed by Microsoft Research Asia in late 2015. The proposed method achieved the first place in ImageNet scene parsing challenge 2016, PASCAL VOC 2012 benchmark and Cityscapes benchmark. The paper also reported that PSPNet model yields accuracy of 85.4% (by mean intersection over union (mIoU)) on PASCAL VOC 2012 and accuracy of 80.2% on Cityscapes. Figure 7.4shows the PSPNet architecture. Figure 7.4: The network architecture of PSPNet [3]. Spatial pyramid pooling module is added after the encoder network mainly to concatenates the feature maps from modified ResNet with upsampled output of parallel pooling layers with ascending sizes of kernels (hence the name pyramid). An auxiliary loss is introduced as an input to pyramid pooling module to optimize overall learning process. PSPNet is proposed by the motivation of tackling issues related to mismatched relationship, confusion categories and inconspicuous classes. The pyramid pooling module combines features based on four di\u21b5erent pyramid scales. The first pyramid level in the red coloured box (as in Figure 7.4) is a global pooling layer that produces a single bin output. The feature map is separated into di\u21b5erent sub-regions and di\u21b5erent locations of pool representation are formed in the next pyramid level. Each pyramid pooling module holds di\u21b5erent sizes of feature map and a 1 x 1 convolutional layer is applied after each Chapter 7. Semantic Segmentation of MR Images of Human Thigh Muscle 125 level to preserve the weight of the global feature and this results in a reduced depth of context representation to 1/N of the original input, where N is equal to the level of pyramid. To get the identical original size of feature map, the low-dimension feature maps are directly upsampled via bilinear interpolation. The final pyramid pooling layer depicts global features that are concatenated from di\u21b5erent levels of features. To train the final classifier, the main branch used softmax loss and another classifier (the res4b22 residue block)[3] is employed after the fourth stage. To assist in optimizing the learning process, the auxiliary loss (with additional weight to balance it) is used and this yields the master branch loss to take the most responsibility. For testing, the auxiliary branch is abandoned and instead only the optimized master branch is used for the final model prediction.",
        "ref_ids": [
          "3",
          "252",
          "3",
          "3"
        ]
      },
      "Deep Convolutional Neural Networks for Semantic Segmentation of Multi-Band Satellite Images": {
        "authors": [],
        "url": "https://uia.brage.unit.no/uia-xmlui/bitstream/handle/11250/2563316/Bore,%20Fredrik%20Klinkenberg%20og%20Taraldsen,%20Andreas%20Nyland.pdf?sequence=1",
        "ref_texts": "3.2.4 PSPNet Scene parsing is based on semantic segmentation and is a fundamental topic in computer vision. The goal of scene parsing is to provide a complete understanding of the scene by predicting the label, location and shape of the objects. The previous state-of-the-art scene parsing frameworks are in most times based on the FCN. The usage of CNNs comes with some challenges, it having a hard time to consider diverse scenes and unrestricted vocabulary. To overcome the challenges, a paper called Pyramid Scene Parsing Network (PSPNet) was released[22][26]. PSPNet are based on FCN for pixel prediction. On top of that they have extended the pixel-level feature to a designed global pyramid pooling, where the local and global values combined makes the ffnal prediction more reliable. In addition to that they have included an optimization strategy with deeply supervised loss[26]. Figure 3.8: PSPNet Structure[26] To address the challenge of reducing context information loss between different sub-regions they introduce Pyramid Pooling Module for global scene prior construction upon the ffnal-layer-feature-map of the neural network. This module has operations under four difierent pyramid stages. Figure 3.8 shows the structure of the pyramid pooling module. The pooling highlighted with red is global pooling to generate a single bin output. The next pyramid level, labeled with orange, separates the feature map to difierent regions and forms pooled representation for difierent locations. The output of these four levels contains a feature map with varied sizes. The four levels in the pyramid pooling module has bin size of 1x1, 2x2, 3x3 and 6x6, from to to bottom illustrated in the ffgure above[26].",
        "ref_ids": [
          "22",
          "26",
          "26",
          "26",
          "26"
        ]
      },
      "Indoor Semantic Segmentation from Rgb-D Images by Integrating Fully Convolutional Network with Higher-Order Markov Random Field": {
        "authors": [],
        "url": "https://isprs-archives.copernicus.org/articles/XLII-4/717/2018/isprs-archives-XLII-4-717-2018.pdf",
        "ref_texts": "6, pp. 583 -598. Wolf, D., Prankl, J., and Vincze, M., 2015. Fast semantic segmentation of 3D point clouds using a dense CRF with learned parameters. IEEE International Conference on Robotics and Automation . IEEE, pp. 4867 -4873. Woodford, O., Torr, P., Reid, I., and Fitzgibbon, A., 2009. Global stereo reconstruction under second -order smoothness priors. IEEE transactions on pattern analysis and machine intelligence , vol. 31, no. 12, pp. 2115 -2128 . Xu, S., Liu, H., and Song, E., 2011. Marker -controlled watershed for lesion segmentation in mammograms. Journal of digital imaging , vol. 24, no. 5, pp. 754 -763. Yang, J., Jiang, Z., Hao, S., and Zhang, H., 2018. Higher Order Support Vector Random Fields for Hyperspectral Image Classification. ISPRS International Journal of Geo -Information , vol. 7, no. 1, pp. 19. Zhao, H., Shi, J., Qi, X., Wang, X., and Jia, J., 2017. Pyramid scene parsing network. IEEE Conf. on Computer Vision and Pattern Recognition (CVP R). pp. 2881 -2890. "
      },
      "Fully Convolutional Architectures for Multi-Part Body Segmentation": {
        "authors": [],
        "url": "https://sergioescalera.com/wp-content/uploads/2018/09/TFM_convolutions_body_JuanBC.pdf",
        "ref_texts": "4659.url:http://arxiv.org/abs/1312.4659 . Tripathi, Subarna et al. (2017). \u201cPose2Instance: Harnessing Keypoints for Person Instance Segmentation\u201d. In: CoRRabs/1704.01152. arXiv: 1704.01152 . url:http://arxiv.org/abs/1704.01152 . Varol,G\u00fcletal.(2017).\u201cLearningfromSyntheticHumans\u201d.In: CoRRabs/1701.01370. arXiv: 1701.01370 .url:http://arxiv.org/abs/1701.01370 . Yu, Fisher and Vladlen Koltun (2015). \u201cMulti-Scale Context Aggregation by Dilated Convolutions\u201d. In: CoRRabs/1511.07122. arXiv: 1511.07122 .url: http://arxiv.org/abs/1511.07122 . Zhao, Hengshuang et al. (2016). \u201cPyramid Scene Parsing Network\u201d. In: CoRR abs/1612.01105. arXiv: 1612.01105 .url:http://arxiv.org/abs/1612.",
        "ref_ids": [
          "4659"
        ]
      },
      "Fully convolutional architectures for multi-part body segmentation": {
        "authors": [],
        "url": "https://diposit.ub.edu/dspace/bitstream/2445/133458/2/memoria.pdf",
        "ref_texts": "4659.url:http://arxiv.org/abs/1312.4659 . Tripathi, Subarna et al. (2017). \u201cPose2Instance: Harnessing Keypoints for Person Instance Segmentation\u201d. In: CoRRabs/1704.01152. arXiv: 1704.01152 . url:http://arxiv.org/abs/1704.01152 . Varol,G\u00fcletal.(2017).\u201cLearningfromSyntheticHumans\u201d.In: CoRRabs/1701.01370. arXiv: 1701.01370 .url:http://arxiv.org/abs/1701.01370 . Yu, Fisher and Vladlen Koltun (2015). \u201cMulti-Scale Context Aggregation by Dilated Convolutions\u201d. In: CoRRabs/1511.07122. arXiv: 1511.07122 .url: http://arxiv.org/abs/1511.07122 . Zhao, Hengshuang et al. (2016). \u201cPyramid Scene Parsing Network\u201d. In: CoRR abs/1612.01105. arXiv: 1612.01105 .url:http://arxiv.org/abs/1612.",
        "ref_ids": [
          "4659"
        ]
      },
      "A Residual Encoder-Decoder Network for Semantic Segmentation in Autonomous Driving Scenarios": {
        "authors": [
          "Naresh Yarlapati",
          "Suzanne Little",
          "Noel E"
        ],
        "url": "https://eurasip.org/Proceedings/Eusipco/Eusipco2018/papers/1570439315.pdf",
        "ref_texts": "[6] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d arXiv preprint arXiv:1612.01105, 2016.",
        "ref_ids": [
          "6"
        ]
      },
      "PET Tumor Segmentation Using a Deep Residual CNN with Dilated Convolutions": {
        "authors": [],
        "url": "https://fse.studenttheses.ub.rug.nl/18148/1/Bachelors_Thesis_Werner_Final.pdf",
        "ref_texts": "[9] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In IEEE Conf. on Computer Vision and Pattern Recognition (CVPR) , pages 2881{2890, 2017.",
        "ref_ids": [
          "9"
        ]
      },
      "Using deep learning and Open Street Maps to find features in aerial images": {
        "authors": [],
        "url": "https://diposit.ub.edu/dspace/bitstream/2445/133457/3/memoria.pdf",
        "ref_texts": "[39] Hengshuang Zhao et al. \u201cPyramid Scene Parsing Network\u201d. In: CoRR abs/1612.01105",
        "ref_ids": [
          "39"
        ]
      },
      "Semantic Segmentation with Scarce Data": {
        "authors": [
          "Isay Katsman",
          "Rohun Tripathi",
          "Andreas Veit",
          "Serge Belongie"
        ],
        "url": "https://arxiv.org/pdf/1807.00911",
        "ref_texts": "Badrinarayanan, Vijay, Kendall, Alex, and Cipolla, Roberto. Segnet: A deep convolutional encoder-decoder architecture for image segmentation. IEEE Transactions on Pattern Analysis and Machine Intelligence , 39:2481\u20132495, 2017. Chen, Liang-Chieh, Papandreou, George, Kokkinos, Iasonas, Murphy, Kevin, and Yuille, Alan L. Deeplab: Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected crfs. IEEE Transactions on Pattern Analysis and Machine Intelligence , 40:834\u2013848, 2018. Cordts, Marius, Omran, Mohamed, Ramos, Sebastian, Rehfeld, Timo, Enzweiler, Markus, Benenson, Rodrigo, Franke, Uwe, Roth, Stefan, and Schiele, Bernt. The cityscapes dataset for semantic urban scene understanding. 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , pp. 3213\u20133223, 2016. Everingham, Mark, Gool, Luc Van, Williams, Christopher K. I., Winn, John M., and Zisserman, Andrew. The pascal visual object classes (voc) challenge. International Journal of Computer Vision , 88:303\u2013338, 2009. Garcia-Garcia, Alberto, Orts, Sergio, Oprea, Sergiu, VillenaMartinez, Victor, and Rodr \u00b4\u0131guez, Jos \u00b4e Garc \u00b4\u0131a. A review on deep learning techniques applied to semantic segmentation. CoRR , abs/1704.06857, 2017. He, Kaiming, Zhang, Xiangyu, Ren, Shaoqing, and Sun, Jian. Deep residual learning for image recognition. 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , pp. 770\u2013778, 2016. Papandreou, George, Chen, Liang-Chieh, Murphy, Kevin P., and Yuille, Alan L. Weakly-and semi-supervised learning of a deep convolutional network for semantic image segmentation. 2015 IEEE International Conference on Computer Vision (ICCV) , pp. 1742\u20131750, 2015. Perez, Ethan, de Vries, Harm, Strub, Florian, Dumoulin, Vincent, and Courville, Aaron C. Learning visual reasoning without strong priors. CoRR , abs/1707.03017, 2017. Pinheiro, Pedro H. O., Lin, Tsung-Yi, Collobert, Ronan, and Dollar, Piotr. Learning to refine object segments. In ECCV , 2016. Ronneberger, Olaf, Fischer, Philipp, and Brox, Thomas. U-net: Convolutional networks for biomedical image segmentation. In MICCAI , 2015. Shelhamer, Evan, Long, Jonathan, and Darrell, Trevor. Fully convolutional networks for semantic segmentation. 2015IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , pp. 3431\u20133440, 2015. Szegedy, Christian, Vanhoucke, Vincent, Ioffe, Sergey, Shlens, Jonathon, and Wojna, Zbigniew. Rethinking the inception architecture for computer vision. 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , pp. 2818\u20132826, 2016. Veit, Andreas, Alldrin, Neil, Chechik, Gal, Krasin, Ivan, Gupta, Abhinav, and Belongie, Serge J. Learning from noisy large-scale datasets with minimal supervision. 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , pp. 6575\u20136583, 2017. Zhao, Hengshuang, Shi, Jianping, Qi, Xiaojuan, Wang, Xiaogang, and Jia, Jiaya. Pyramid scene parsing network."
      },
      "A Simple Weight Recall for Semantic Segmentation: Application to Urban Scenes": {
        "authors": [],
        "url": "https://hal.science/hal-01838445/file/v3_submission_0430.pdf",
        "ref_texts": "[3] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proc. of CVPR , Hawaii, USA, 2017.",
        "ref_ids": [
          "3"
        ]
      },
      "Continual Learning for Deep Dense Prediction": {
        "authors": [],
        "url": "https://vtechworks.lib.vt.edu/bitstreams/feaf2f28-5a62-4a00-a7f6-b642ae82cc55/download",
        "ref_texts": "[38] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. arXiv preprint arXiv:1612.01105 , 2016.",
        "ref_ids": [
          "38"
        ]
      },
      "Video Object Segmentation by Tracking One Point": {
        "authors": [],
        "url": "https://www.research-collection.ethz.ch/bitstream/handle/20.500.11850/268001/1/MontesGomez_Alberto.pdf",
        "ref_texts": "[ZSQ\u00c517] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia, Pyramid scene parsing network , IEEE Conf. on Computer Vision and Pattern Recognition (CVPR), 2017, pp. 2881\u20132890. 8, 16",
        "ref_ids": [
          "ZSQ\u00c517"
        ]
      },
      "Supplementary Material: Efficient Interactive Annotation of Segmentation Datasets with Polygon-RNN+": {
        "authors": [],
        "url": "http://openaccess.thecvf.com/content_cvpr_2018/Supplemental/3409-supp.pdf",
        "ref_texts": "[9]H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In CVPR , 2017.",
        "ref_ids": [
          "9"
        ]
      },
      "Semantic Soft Segmentation Supplementary Material": {
        "authors": [],
        "url": "https://www2.cs.sfu.ca/~yagiz/papers/TOG18-sss-supp.pdf",
        "ref_texts": "72-Supp.:6 \u2022Aksoy, Oh, Paris, Pollefeys and Matusik Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. 2015b. Delving deep into rectifiers: Surpassing human-level performance on imagenet classification. In Proc. ICCV . Elad Hoffer and Nir Ailon. 2015. Deep metric learning using triplet network. In International Workshop on Similarity-Based Pattern Recognition . Anat Levin, Alex Rav-Acha, and Dani Lischinski. 2008. Spectral Matting. IEEE Trans. Pattern Anal. Mach. Intell. 30, 10 (2008), 1699\u20131712. Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva Ramanan, Piotr Doll\u00e1r, and C Lawrence Zitnick. 2014. Microsoft coco: Common objects in context. In Proc. ECCV . Kihyuk Sohn. 2016. Improved deep metric learning with multi-class n-pair loss objective. InProc. NIPS . Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. 2017. Pyramid Scene Parsing Network. In Proc. CVPR . ACM Transactions on Graphics, Vol. 37, No. 4, Article 72-Supp.. Publication date: August 2018."
      },
      "Exploring Multi-Modal and Structured Representation Learning for Visual Image and Video Understanding": {
        "authors": [],
        "url": "http://eprints-phd.biblio.unitn.it/2918/2/phd_thesis.pdf",
        "ref_texts": "[186]Zhao, H., Shi, J., Qi, X., Wang, X., and Jia, J. (2016). Pyramid scene parsing network. arXiv preprint arXiv:1612.01105 .",
        "ref_ids": [
          "186"
        ]
      },
      "\u7b4b\u9aa8\u683c\u30d2\u30e5\u30fc\u30de\u30ce\u30a4\u30c9\u306b\u304a\u3051\u308b\u53ef\u52d5\u773c\u7403\u306e\u958b\u767a\u3068\u8eca\u4e21\u898b\u56de\u3057\u767a\u9032\u52d5\u4f5c\u306e\u5b9f\u73fe": {
        "authors": [],
        "url": "https://www.jstage.jst.go.jp/article/jsmermd/2018/0/2018_2A2-G11/_pdf"
      },
      "Semantic Soft Segmentation": {
        "authors": [],
        "url": "https://cdfg.mit.edu/assets/images/semantic-soft-segmentation.pdf",
        "ref_texts": "(2017), 19:1\u201319:19. Xiaobo An and Fabio Pellacini. 2008. AppProp: All-pairs Appearance-space Edit Propagation. ACM Trans. Graph. 27, 3 (2008), 40:1\u201340:9. R. Barrett, M. Berry, T. Chan, J. Demmel, J. Donato, J. Dongarra, V. Eijkhout, R. Pozo, C. Romine, and H. van der Vorst. 1994. Templates for the Solution of Linear Systems: Building Blocks for Iterative Methods . SIAM. Gedas Bertasius, Jianbo Shi, and Lorenzo Torresani. 2015. High-for-low and low-forhigh: Efficient boundary detection from deep object features and its applications to high-level vision. In Proc. ICCV .Gedas Bertasius, Jianbo Shi, and Lorenzo Torresani. 2016. Semantic Segmentation with Boundary Neural Fields. In Proc. CVPR . V. Bychkovsky, S. Paris, E. Chan, and F. Durand. 2011. Learning Photographic Global Tonal Adjustment with a Database of Input/Output Image Pairs. In Proc. CVPR . Holger Caesar, Jasper Uijlings, and Vittorio Ferrari. 2016. COCO-Stuff: Thing and Stuff Classes in Context. arXiv:1612.03716 [cs.CV] (2016). Liang-Chieh Chen, George Papandreou, Iasonas Kokkinos, Kevin Murphy, and Alan L Yuille. 2017. DeepLab: Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Connected CRFs. IEEE Trans. Pattern Anal. Mach. Intell. (2017). Qifeng Chen, Dingzeyu Li, and Chi-Keung Tang. 2013. KNN Matting. IEEE Trans. Pattern Anal. Mach. Intell. 35, 9 (2013), 2175\u20132188. Xiaowu Chen, Dongqing Zou, Qinping Zhao, and Ping Tan. 2012. Manifold Preserving Edit Propagation. ACM Trans. Graph. 31, 6 (2012), 132:1\u2013132:7. Yuki Endo, Satoshi Iizuka, Yoshihiro Kanamori, and Jun Mitani. 2016. DeepProp: Extracting Deep Features from a Single Image for Edit Propagation. Comput. Graph. Forum 35, 2 (2016), 189\u2013201. D. Eynard, A. Kovnatsky, and M. M. Bronstein. 2014. Laplacian colormaps: a framework for structure-preserving color transformations. Comput. Graph. Forum 33, 2 (2014), 215\u2013224. H. Farid and E. P. Simoncelli. 2004. Differentiation of discrete multidimensional signals. IEEE Trans. Image Process. 13, 4 (2004), 496\u2013508. Alireza Fathi, Zbigniew Wojna, Vivek Rathod, Peng Wang, Hyun Oh Song, Sergio Guadarrama, and Kevin P. Murphy. 2017. Semantic Instance Segmentation via Deep Metric Learning. arXiv:1703.10277 [cs.CV] (2017). Bharath Hariharan, Pablo Arbel\u00e1ez, Ross Girshick, and Jitendra Malik. 2015. Hypercolumns for object segmentation and fine-grained localization. In Proc. CVPR . Kaiming He, Georgia Gkioxari, Piotr Dollar, and Ross Girshick. 2017. Mask R-CNN. In Proc. ICCV . Kaiming He, Jian Sun, and Xiaoou Tang. 2013. Guided Image Filtering. IEEE Trans. Pattern Anal. Mach. Intell. 35, 6 (2013), 1397\u20131409. Elad Hoffer and Nir Ailon. 2015. Deep metric learning using triplet network. In International Workshop on Similarity-Based Pattern Recognition . Anat Levin, Dani Lischinski, and Yair Weiss. 2008a. A Closed-Form Solution to Natural Image Matting. IEEE Trans. Pattern Anal. Mach. Intell. 30, 2 (2008), 228\u2013242. Anat Levin, Alex Rav-Acha, and Dani Lischinski. 2008b. Spectral Matting. IEEE Trans. Pattern Anal. Mach. Intell. 30, 10 (2008), 1699\u20131712. Y. Li, E. Adelson, and A. Agarwala. 2008. ScribbleBoost: Adding Classification to EdgeAware Interpolation of Local Image and Video Adjustments. Comput. Graph. Forum 27, 4 (2008), 1255\u20131264. Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva Ramanan, Piotr Doll\u00e1r, and C Lawrence Zitnick. 2014. Microsoft COCO: Common objects in context. In Proc. ECCV . Tae-Hyun Oh, Kyungdon Joo, Neel Joshi, Baoyuan Wang, In So Kweon, and Sing Bing Kang. 2017. Personalized Cinemagraphs Using Semantic Understanding and Collaborative Learning. In Proc. ICCV . S. Qin, S. Kim, and R. Manduchi. 2017. Automatic skin and hair masking using fully convolutional networks. In Proc. ICME . Wenqi Ren, Jinshan Pan, Xiaochun Cao, and Ming-Hsuan Yang. 2017. Video Deblurring via Semantic Segmentation and Pixel-Wise Non-Linear Kernel. In Proc. ICCV . Christoph Rhemann, Carsten Rother, Jue Wang, Margrit Gelautz, Pushmeet Kohli, and Pamela Rott. 2009. A Perceptually Motivated Online Benchmark for Image Matting. InProc. CVPR . Xiaoyong Shen, Xin Tao, Hongyun Gao, Chao Zhou, and Jiaya Jia. 2016. Deep Automatic Portrait Matting. In Proc. ECCV . D. Singaraju and R. Vidal. 2011. Estimation of Alpha Mattes for Multiple Image Layers. IEEE Trans. Pattern Anal. Mach. Intell. 33, 7 (2011), 1295\u20131309. Kihyuk Sohn. 2016. Improved deep metric learning with multi-class N-pair loss objective. InProc. NIPS . Yu-Wing Tai, Jiaya Jia, and Chi-Keung Tang. 2007. Soft Color Segmentation and Its Applications. IEEE Trans. Pattern Anal. Mach. Intell. 29, 9 (2007), 1520\u20131537. Jianchao Tan, Jyh-Ming Lien, and Yotam Gingold. 2016. Decomposing Images into Layers via RGB-space Geometry. ACM Trans. Graph. 36, 1 (2016), 7:1\u20137:14. Ning Xu, Brian Price, Scott Cohen, and Thomas Huang. 2017. Deep Image Matting. In Proc. CVPR . Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. 2017. Pyramid Scene Parsing Network. In Proc. CVPR . ACM Transactions on Graphics, Vol. 37, No. 4, Article 72. Publication date: August 2018."
      },
      "Labeling Transformation and Introspective Learning with Convolutional Nets": {
        "authors": [],
        "url": "https://escholarship.org/content/qt514796kk/qt514796kk.pdf",
        "ref_texts": "[139] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. CoRR , abs/1612.01105, 2016.",
        "ref_ids": [
          "139"
        ]
      },
      "Semantic See-Through Rendering on Light Fields": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1803.09474",
        "ref_texts": "[46] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. 2017. Pyramid Scene Parsing Network. In2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) .",
        "ref_ids": [
          "46"
        ]
      },
      "Sim-to-Real: Autonomous Robotic Control": {
        "authors": [],
        "url": "https://files.challengerocket.com/files/photo_projects/al/alle/allenchen09581/sim-to-real-autonomous-robotic-control_c08e18/edbac100.pdf",
        "ref_texts": "[22]Zhao, H., Shi, J., Qi, X., Wang, X., and Jia, J., \u201cPyramid scene parsing network,\u201d Proc. IEEE Conf. Computer Vision and Pattern Recognition (CVPR) , 2017, pp. 2881-2890.",
        "ref_ids": [
          "22"
        ]
      },
      "Convolutional Neural Network based Medical Imaging Segmentation: Recent Progress and Challenges": {
        "authors": [],
        "url": "https://pdfs.semanticscholar.org/a19a/d07eaa06546f77d89310bc68d69d31ae4f29.pdf",
        "ref_texts": "31/53 www.gc.cuny.eduLink-Net\u2022Similar\tto\tU-Net\u2022Link\teach\tencoder\twith\tdecoder\u2022Each\tencoder\tblock\tis\ta\tResNetBlock\u2022Reduced\tparameters 32/53 www.gc.cuny.eduPSP-Net\u2022Embed\tdifficult\tscenery\tcontext\tfeatures\tin\tan\tFCN\tbased\tpixel\tprediction\t framework.\u2022First\tuse\ta\tpretrainedResNetmodel\twith\tthe\tdilated\tnetwork\tstrategy\tto\textract\tthe\tfeature\tmap.\t\u2022Then\tfuse\tdifferent\tlevel\tfeatures\tfor\tfurther\tanalysis.33/53 www.gc.cuny.edu\u2022Givenaninputimage(a)\u2022UseCNNtogetthefeaturemapofthelastconvolutionallayer(b)\u2022Apyramidparsingmoduleisappliedtoharvestdifferentsub-regionrepresentations,followedbyup-samplingandconcatenationlayerstoformthefinalfeaturerepresentation,whichcarriesbothlocalandglobalcontextinformationin(c).\u2022Finally,therepresentationisfedintoaconvolutionlayertogetthefinalper-pixelprediction(d)."
      },
      "Structural inference embedded adversarial networks for scene parsing": {
        "authors": [
          "Yu Wang",
          "Xia Wu",
          "Hui Bu",
          "Cheng Han",
          "Yin Zhang"
        ],
        "url": "https://journals.plos.org/plosone/article/file?id=10.1371/journal.pone.0195114&type=printable",
        "ref_texts": "21. Zhao H,ShiJ,QiX,Wang X,JiaJ.Pyramid scene parsing network. IEEE Conf. onComput erVision andPattern Recognition (CVPR). 2017: 2881-2890.",
        "ref_ids": [
          "21"
        ]
      },
      "Learning Robust Features and Metrics for Image Classification and Matching": {
        "authors": [
          "Bailey Kong"
        ],
        "url": "https://escholarship.org/content/qt2rp1k1qj/qt2rp1k1qj.pdf",
        "ref_texts": "72 To generate shape masks, we use a pyramid scene parsing network (PSPNet) [77]. PSPNets capture both local and global contextual information for image segmentation by building a feature pyramid that is used to make pixel-level predictions. The levels of the feature pyramid are computed much like an image pyramid (through a series of ffltering and downsampling operations), but with learned fflters. Levels of the pyramid are combined by upsampling and concatenating each level of the feature pyramid with the original feature map, which is then used to make pixel-level predictions. We use a PSPNet to make a binary prediction of outsole versus non-outsole.",
        "ref_ids": [
          "77"
        ]
      },
      "Deep Learning Based Anatomical Structure Localization and Segmentation in Fetal Ultrasound Images": {
        "authors": [],
        "url": "https://waseda.repo.nii.ac.jp/record/47491/files/Gaiyo-8218.pdf",
        "ref_texts": ""
      },
      "Deep Neural Network Architectures and Learning Methodologies for Classification and Application in 3D Reconstruction": {
        "authors": [],
        "url": "https://spectrum.library.concordia.ca/id/eprint/985222/1/Forbes_MCompSc_S2019.pdf",
        "ref_texts": "[27] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid Scene Parsing Network,\u201d arXiv:1612.01105 [cs] , Dec.",
        "ref_ids": [
          "27",
          "cs"
        ]
      },
      "Automaitc Generation of Fashion Image Dataset by Using Progressive Growing GAN": {
        "authors": [],
        "url": "https://koreascience.kr/article/JAKO201809863361970.pdf",
        "ref_texts": ""
      },
      "Parameters estimation from remote sensing data for the generation of virtual 3D city models": {
        "authors": [],
        "url": "https://upcommons.upc.edu/bitstream/handle/2117/128168/thesis_final.pdf?sequence=1",
        "ref_texts": "[21] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. CoRR, abs/1612.01105, 2016.",
        "ref_ids": [
          "21"
        ]
      },
      "Dynamic Multimodal Object Segmentation based on natural language referring expressions and its applications": {
        "authors": [],
        "url": "https://repositorio.uniandes.edu.co/bitstreams/5f2785bb-dab0-4126-9b8c-b6431f7ec0cb/download",
        "ref_texts": "[3] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2017.",
        "ref_ids": [
          "3"
        ]
      },
      "Self-Supervised Learning of Object Motion Through Adversarial Video Prediction": {
        "authors": [],
        "url": "https://openreview.net/pdf?id=HJrJpzZRZ",
        "ref_texts": "10 Under review as a conference paper at ICLR 2018 Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. InProceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2017. Jun-Yan Zhu, Taesung Park, Phillip Isola, and Alexei A Efros. Unpaired image-to-image translation using cycle-consistent adversarial networks. ICCV , 2017."
      },
      "Sujet de these CIFRE: Apprentissage profond pour la compr\u00e9hension de": {
        "authors": [],
        "url": "http://cedric.cnam.fr/~crucianm/src/theseXXii18.pdf",
        "ref_texts": "[12] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \\Pyramid scene parsing network,\" CoRR , vol. abs/1612.01105, 2016.",
        "ref_ids": [
          "12"
        ]
      },
      "\u8d70\u884c\u74b0\u5883\u8a8d\u8b58\u306e\u305f\u3081\u306e Semantic Segmentation \u306e\u6027\u80fd\u5411\u4e0a\u306b\u95a2\u3059\u308b\u7814\u7a76": {
        "authors": [],
        "url": "https://www.jstage.jst.go.jp/article/jsmermd/2018/0/2018_1P2-B11/_pdf",
        "ref_texts": "\u0ce5\u0370\u0378 Pyramid Scene Parsing Network(PSPNet)[2] \u038dImage Cascade Network(ICNet)[3]\u0b04\u0377\u03c9\u03bf",
        "ref_ids": [
          "2",
          "3"
        ]
      },
      "Exploring Aspects of Image Segmentation: Diversity, Global Reasoning, and Panoptic Formulation": {
        "authors": [],
        "url": "https://archiv.ub.uni-heidelberg.de/volltextserver/25750/1/thesis_kirillov.pdf",
        "ref_texts": "[Zha+17] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. \u201cPyramid Scene Parsing Network\u201d. In:The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) .",
        "ref_ids": [
          "Zha\\+17"
        ]
      },
      "\u0420\u041e\u041b\u042c \u0418 \u0417\u041d\u0410\u0427\u0415\u041d\u0418\u0415 \u0418\u041d\u0424\u041e\u0420\u041c\u0410\u0426\u0418\u041e\u041d\u041d\u041e\u0419 \u0421\u0418\u0421\u0422\u0415\u041c\u042b \u0412 \u0421\u0424\u0415\u0420\u0415 \u041c\u0415\u0414\u0418\u0426\u0418\u041d\u0421\u041a\u0418\u0425 \u0423\u0421\u041b\u0423\u0413": {
        "authors": [],
        "url": "https://www.kaznu.kz/content/files/news/folder24345/%D0%90%D0%BA%D1%82.%D0%BD%D0%B0%D1%83%D1%87.%D0%B8%D1%81%D1%81%D0%BB%D0%B5%D0%B4%D0%BE%D0%B2%D0%B0%D0%BD%D0%B8%D1%8F_169712.pdf#page=65",
        "ref_texts": "10. Zhao, Hengshuang, et al. \"Pyramid scene parsing network.\" IEEE Conf. on Computer Vision and Pattern Recognition (CVPR). 2017. ",
        "ref_ids": [
          "10"
        ]
      },
      "Learning Context For Semantic Segmentation and Applications": {
        "authors": [
          "Vladimir Haltakov"
        ],
        "url": "https://mediatum.ub.tum.de/doc/1435905/document.pdf",
        "ref_texts": "3 Related Work pyramid pooling (ASPP) which is an efficient variant of processing the same image multiple times at different scales and combining the results. The idea behind ASPP is that multiple dilated convolutions with different rates are computed in parallel on the same image, effectively simulating sampling at different scales. The combination of dilated convolutions and processing of the image at different scales gives the DeepLab v2 network a large receptive field and access to large image regions, allowing the network to learn context relations in those regions. Analyzing the results of the paper shows, however, the network still has problems with certain regions that need to be corrected by the smoothing of the CRF. Those problems could in general be solved by using more context information. DilatedNet. The authors of [157] use a similar idea to [23] and replace the last layers (here both pooling and convolution) with dilated convolution layers. Another important extension, is a context module designed specifically to capture context information. It consists of a cascade of dilated convolutional layers with increasing dilation factor that can be plugged to the predictions layer of any segmentation architecture. The authors present this idea as a way to increase the receptive field of the network without reducing resolution and by this capturing global context. The ability of the network to learn context is improved by the consecutive use of dilated convolutions to enlarge the receptive field of the network. Furthermore, the authors show that the proposed context module is efficient and can be plugged after every network and increases the performance. DeepLab v3. An extension of the DeepLab architecture [23] is presented in [24], which includes improved ASPP module and a cascade of dilated convolutions in order to remove the need of using a CRF. An important observation in the paper is that having larger rates of the dilated convolutions helps to capture more long range context relations, but it starts causing problems, when the rate is too high, because most of the pixels are then sampled outside of the image and are therefore not valid. The authors also integrate an additional image level feature as in [94] in the ASPP module to deal with this problem. Furthermore, a cascade of dilated convolutions is introduced inside of the ResNet blocks, which is similar to the context module of [157], but it operated on the feature level and not on the final predictions as in [157]. Similar to [94], the image level features in the ASPP are useful for encoding co-occurrence information, but not for spatial context. Otherwise, the ability of the network to capture context is improved by the usage of a dilated convolutions cascade. PSPNet. The Pyramid Scene Parsing Network (PSPNet) of [159] combines ideas similar to ParseNet [94] and DilatedNet [157] the authors use a ResNet [61] network modified with dilated convolutions in the last layers as in [24]. The idea of the proposed pyramid pooling module can be seen as extension to the global feature vector of [94]. Here, however, pooling is applied not only on the whole image but also on increasingly smaller regions. This allows the network to capture information not only on image level, but also in different regions around the pixel of interest and therefore learn more powerful context 26",
        "ref_ids": [
          "157",
          "23",
          "23",
          "24",
          "94",
          "157",
          "157",
          "94",
          "159",
          "94",
          "157",
          "61",
          "24",
          "94"
        ]
      },
      "\ub525\ub7ec\ub2dd\uc744 \uc774\uc6a9\ud55c Semantic Segmentation \uae30\uc220 \ub3d9\ud5a5 \ubd84\uc11d": {
        "authors": [],
        "url": "https://koreascience.kr/article/JAKO201820765435879.pdf",
        "ref_texts": "3.6. Pyramid Scene Parsing Network (PSPNet) [11]",
        "ref_ids": [
          "11"
        ]
      },
      "\u30bb\u30de\u30f3\u30c6\u30a3\u30c3\u30af\u30de\u30c3\u30d7\u3092\u7528\u3044\u305f\u8996\u5dee\u30de\u30c3\u30d7\u306e\u6539\u5584": {
        "authors": [],
        "url": "https://naist.repo.nii.ac.jp/record/8399/files/R014459.pdf",
        "ref_texts": "2.5 PSPNet: Pyramid Scene Parsing Network [14] . . . . . . . . . . 13",
        "ref_ids": [
          "14"
        ]
      },
      "\u0417\u0430\u0441\u0442\u043e\u0441\u0443\u0432\u0430\u043d\u043d\u044f \u043d\u0435\u0439\u0440\u043e\u043d\u043d\u0438\u0445 \u043c\u0435\u0440\u0435\u0436 \u0430\u0440\u0445\u0456\u0442\u0435\u043a\u0442\u0443\u0440\u0438 UNet, DeepLabV3, PSPNet \u0434\u043b\u044f \u0441\u0435\u043c\u0430\u043d\u0442\u0438\u0447\u043d\u043e\u0457 \u0441\u0435\u0433\u043c\u0435\u043d\u0442\u0430\u0446\u0456\u0457 \u043e\u0431\u043b\u0438\u0447\u0447\u044f \u043d\u0430 \u0444\u043e\u0442\u043e\u0433\u0440\u0430\u0444\u0456\u0457": {
        "authors": [],
        "url": "https://www.kaznu.kz/content/files/news/folder24345/%D0%90%D0%BA%D1%82.%D0%BD%D0%B0%D1%83%D1%87.%D0%B8%D1%81%D1%81%D0%BB%D0%B5%D0%B4%D0%BE%D0%B2%D0%B0%D0%BD%D0%B8%D1%8F_169712.pdf#page=70",
        "ref_texts": "10. Zhao, Hengshuang, et al. \"Pyramid scene parsing network.\" IEEE Conf. on Computer Vision and Pattern Recognition (CVPR). 2017. ",
        "ref_ids": [
          "10"
        ]
      },
      "The mapillary vistas dataset for semantic understanding of street scenes": {
        "authors": [
          "Gerhard Neuhold",
          "Tobias Ollmann",
          "Samuel Rota",
          "Peter Kontschieder"
        ],
        "url": "https://openaccess.thecvf.com/content_ICCV_2017/papers/Neuhold_The_Mapillary_Vistas_ICCV_2017_paper.pdf",
        "ref_texts": "[61] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. CoRR , abs/1612.01105, 2016. 6,7",
        "ref_ids": [
          "61"
        ]
      },
      "Generating high-quality crowd density maps using contextual pyramid cnns": {
        "authors": [
          "Vishwanath A. Sindagi",
          "Vishal M. Patel"
        ],
        "url": "https://openaccess.thecvf.com/content_ICCV_2017/papers/Sindagi_Generating_High-Quality_Crowd_ICCV_2017_paper.pdf",
        "ref_texts": "[51] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , 2017. 1",
        "ref_ids": [
          "51"
        ]
      },
      "Deep watershed transform for instance segmentation": {
        "authors": [
          "Min Bai",
          "Raquel Urtasun"
        ],
        "url": "http://openaccess.thecvf.com/content_cvpr_2017/papers/Bai_Deep_Watershed_Transform_CVPR_2017_paper.pdf",
        "ref_texts": "[34] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid Scene Parsing Network. arXiv preprint arXiv:1612.01105 , 2016. 2, 3,4,6,7,8",
        "ref_ids": [
          "34"
        ]
      },
      "The reversible residual network: Backpropagation without storing activations": {
        "authors": [
          "Aidan N. Gomez",
          "Mengye Ren",
          "Raquel Urtasun",
          "Roger B. Grosse"
        ],
        "url": "https://proceedings.neurips.cc/paper_files/paper/2017/file/f9be311e65d81a9ad8150a60844bb94c-Paper.pdf",
        "ref_texts": "[36] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In CVPR , 2017.",
        "ref_ids": [
          "36"
        ]
      },
      "Curriculum domain adaptation for semantic segmentation of urban scenes": {
        "authors": [
          "Yang Zhang",
          "Philip David",
          "Boqing Gong"
        ],
        "url": "https://openaccess.thecvf.com/content_ICCV_2017/papers/Zhang_Curriculum_Domain_Adaptation_ICCV_2017_paper.pdf",
        "ref_texts": "[69] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid Scene Parsing Network. arXiv preprint arXiv:1612.01105 , 2016. 3",
        "ref_ids": [
          "69"
        ]
      },
      "Playing for benchmarks": {
        "authors": [
          "Stephan R. Richter",
          "Zeeshan Hayder",
          "Vladlen Koltun"
        ],
        "url": "http://openaccess.thecvf.com/content_ICCV_2017/papers/Richter_Playing_for_Benchmarks_ICCV_2017_paper.pdf",
        "ref_texts": "[65] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In CVPR , 2017. 6",
        "ref_ids": [
          "65"
        ]
      },
      "A stagewise refinement model for detecting salient objects in images": {
        "authors": [
          "Tiantian Wang",
          "Ali Borji",
          "Lihe Zhang",
          "Pingping Zhang",
          "Huchuan Lu"
        ],
        "url": "https://openaccess.thecvf.com/content_ICCV_2017/papers/Wang_A_Stagewise_Refinement_ICCV_2017_paper.pdf"
      },
      "A Convolutional Approach for Misinformation Identification.": {
        "authors": [
          "Feng Yu",
          "Qiang Liu",
          "Shu Wu",
          "Liang Wang",
          "Tieniu Tan"
        ],
        "url": "https://www.ijcai.org/proceedings/2017/0545.pdf",
        "ref_texts": "[Zhao et al., 2017 ]Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR, 2017.Proceedings of the Twenty-Sixth International Joint Conference on Artificial Intelligence (IJCAI-17)",
        "ref_ids": [
          "Zhao et al\\., 2017 "
        ]
      },
      "Couplenet: Coupling global structure with local parts for object detection": {
        "authors": [
          "Yousong Zhu",
          "Chaoyang Zhao",
          "Jinqiao Wang",
          "Xu Zhao",
          "Yi Wu",
          "Hanqing Lu"
        ],
        "url": "http://openaccess.thecvf.com/content_ICCV_2017/papers/Zhu_CoupleNet_Coupling_Global_ICCV_2017_paper.pdf",
        "ref_texts": "[27] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. arXiv preprint arXiv:1612.01105 , 2016.",
        "ref_ids": [
          "27"
        ]
      },
      "Sgn: Sequential grouping networks for instance segmentation": {
        "authors": [
          "Shu Liu",
          "Jiaya Jia",
          "Sanja Fidler",
          "Raquel Urtasun"
        ],
        "url": "https://openaccess.thecvf.com/content_ICCV_2017/papers/Liu_SGN_Sequential_Grouping_ICCV_2017_paper.pdf",
        "ref_texts": "[42] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. CoRR , 2016. 5,6,8",
        "ref_ids": [
          "42"
        ]
      },
      "Universal adversarial perturbations against semantic image segmentation": {
        "authors": [
          "Jan Hendrik",
          "Mummadi Chaithanya",
          "Thomas Brox",
          "Volker Fischer"
        ],
        "url": "http://openaccess.thecvf.com/content_ICCV_2017/papers/Metzen_Universal_Adversarial_Perturbations_ICCV_2017_paper.pdf",
        "ref_texts": "[29] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid Scene Parsing Network. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2017. 8",
        "ref_ids": [
          "29"
        ]
      },
      "Detecting unexpected obstacles for self-driving cars: Fusing deep learning and geometric modeling": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1612.06573",
        "ref_texts": ""
      },
      "Residual conv-deconv grid network for semantic segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1707.07958",
        "ref_texts": "[25] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. CoRR , abs/1612.01105, 2016.",
        "ref_ids": [
          "25"
        ]
      },
      "Pixelwise instance segmentation with a dynamically instantiated network": {
        "authors": [
          "Anurag Arnab",
          "Philip H. S"
        ],
        "url": "http://openaccess.thecvf.com/content_cvpr_2017/papers/Arnab_Pixelwise_Instance_Segmentation_CVPR_2017_paper.pdf",
        "ref_texts": "[52] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In arXiv preprint arXiv:1612.01105 , 2017.",
        "ref_ids": [
          "52"
        ]
      },
      "Gated feedback refinement network for dense image labeling": {
        "authors": [
          "Md Amirul",
          "Mrigank Rochan",
          "Neil D. B",
          "Yang Wang"
        ],
        "url": "http://openaccess.thecvf.com/content_cvpr_2017/papers/Islam_Gated_Feedback_Refinement_CVPR_2017_paper.pdf",
        "ref_texts": ""
      },
      "Convolutional oriented boundaries: From image segmentation to high-level tasks": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1701.04658",
        "ref_texts": "[69] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in CVPR , 2017.",
        "ref_ids": [
          "69"
        ]
      },
      "Scale-adaptive convolutions for scene parsing": {
        "authors": [
          "Rui Zhang",
          "Sheng Tang",
          "Yongdong Zhang",
          "Jintao Li",
          "Shuicheng Yan"
        ],
        "url": "https://openaccess.thecvf.com/content_ICCV_2017/papers/Zhang_Scale-Adaptive_Convolutions_for_ICCV_2017_paper.pdf",
        "ref_texts": "[33] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. CoRR , 2016.",
        "ref_ids": [
          "33"
        ]
      },
      "Semantic video cnns through representation warping": {
        "authors": [
          "Raghudeep Gadde",
          "Varun Jampani",
          "Peter V. Gehler"
        ],
        "url": "https://openaccess.thecvf.com/content_ICCV_2017/papers/Gadde_Semantic_Video_CNNs_ICCV_2017_paper.pdf",
        "ref_texts": "[48] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. arXiv preprint arXiv:1612.01105 , 2016. 5, 6,7,8",
        "ref_ids": [
          "48"
        ]
      },
      "Lucid data dreaming for object tracking": {
        "authors": [],
        "url": "https://pure.mpg.de/rest/items/item_2493068/component/file_2493067/content",
        "ref_texts": "[23] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In CVPR , 2017. 3",
        "ref_ids": [
          "23"
        ]
      },
      "Semantic background subtraction": {
        "authors": [],
        "url": "https://orbi.uliege.be/bitstream/2268/213419/1/Braham2017Semantic.pdf",
        "ref_texts": "[13] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in IEEE Int. Conf. Comput. Vision and Pattern Recogn. (CVPR) , July 2017.",
        "ref_ids": [
          "13"
        ]
      },
      "Video scene parsing with predictive feature learning": {
        "authors": [
          "Xiaojie Jin",
          "Xin Li",
          "Huaxin Xiao",
          "Xiaohui Shen",
          "Zhe Lin",
          "Jimei Yang",
          "Yunpeng Chen",
          "Jian Dong",
          "Luoqi Liu",
          "Zequn Jie",
          "Jiashi Feng",
          "Shuicheng Yan"
        ],
        "url": "https://openaccess.thecvf.com/content_ICCV_2017/papers/Jin_Video_Scene_Parsing_ICCV_2017_paper.pdf",
        "ref_texts": "[49] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. CoRR , abs/1612.01105, 2016. 3",
        "ref_ids": [
          "49"
        ]
      },
      "Dense and low-rank gaussian crfs using deep embeddings": {
        "authors": [
          "Siddhartha Chandra",
          "Nicolas Usunier",
          "Iasonas Kokkinos"
        ],
        "url": "https://openaccess.thecvf.com/content_ICCV_2017/papers/Chandra_Dense_and_Low-Rank_ICCV_2017_paper.pdf",
        "ref_texts": "[38] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. CoRR , abs/1612.01105, 2016. 7",
        "ref_ids": [
          "38"
        ]
      },
      "Fast deep matting for portrait animation on mobile phone": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1707.08289",
        "ref_texts": "[36] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. 2017. Pyramid Scene Parsing Network. In Computer Vision and Pattern Recognition (CVPR), 2017 .",
        "ref_ids": [
          "36"
        ]
      },
      "Deep fully convolutional networks with random data augmentation for enhanced generalization in road detection": {
        "authors": [],
        "url": "http://www.invett.es/sotelo/ITSC2017-Jesus.pdf",
        "ref_texts": "[13] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid Scene Parsing Network,\u201d arXiv:1612.01105 [cs] , Dec. 2016, arXiv: 1612.01105.",
        "ref_ids": [
          "13",
          "cs"
        ]
      },
      "Real-time semantic image segmentation via spatial sparsity": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1712.00213",
        "ref_texts": "[23] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. arXiv:1612.01105, 2016.",
        "ref_ids": [
          "23"
        ]
      },
      "Self-supervised neural aggregation networks for human parsing": {
        "authors": [
          "Jian Zhao",
          "Jianshu Li",
          "Xuecheng Nie",
          "Fang Zhao",
          "Yunpeng Chen",
          "Zhecan Wang",
          "Jiashi Feng",
          "Shuicheng Yan"
        ],
        "url": "http://openaccess.thecvf.com/content_cvpr_2017_workshops/w19/papers/Zhao_Self-Supervised_Neural_Aggregation_CVPR_2017_paper.pdf",
        "ref_texts": "[39] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. arXiv preprint arXiv:1612.01105 , 2016.",
        "ref_ids": [
          "39"
        ]
      },
      "Semantic segmentation with reverse attention": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1707.06426",
        "ref_texts": ""
      },
      "Semantic segmentation via structured patch prediction, context crf and guidance crf": {
        "authors": [
          "Falong Shen",
          "Rui Gan",
          "Shuicheng Yan",
          "Gang Zeng"
        ],
        "url": "https://openaccess.thecvf.com/content_cvpr_2017/papers/Shen_Semantic_Segmentation_via_CVPR_2017_paper.pdf",
        "ref_texts": "[34] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. arXiv preprint arXiv:1612.01105 , 2016.",
        "ref_ids": [
          "34"
        ]
      },
      "Scene parsing with global context embedding": {
        "authors": [
          "Chih Hung",
          "Hsuan Tsai",
          "Xiaohui Shen",
          "Zhe Lin",
          "Kalyan Sunkavalli",
          "Xin Lu",
          "Hsuan Yang"
        ],
        "url": "https://openaccess.thecvf.com/content_ICCV_2017/papers/Hung_Scene_Parsing_With_ICCV_2017_paper.pdf",
        "ref_texts": "[33] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. CVPR , 2017. 2",
        "ref_ids": [
          "33"
        ]
      },
      "Large-scale 3d shape reconstruction and segmentation from shapenet core55": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1710.06104",
        "ref_texts": "[20] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2017.",
        "ref_ids": [
          "20"
        ]
      },
      "Ladder-style densenets for semantic segmentation of large natural images": {
        "authors": [
          "Ivan Kreso",
          "Sinisa Segvic",
          "Josip Krapac"
        ],
        "url": "http://openaccess.thecvf.com/content_ICCV_2017_workshops/papers/w3/Kreso_Ladder-Style_DenseNets_for_ICCV_2017_paper.pdf",
        "ref_texts": "[37] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. CoRR , abs/1612.01105, 2016. 2,5,6",
        "ref_ids": [
          "37"
        ]
      },
      "Holistic, instance-level human parsing": {
        "authors": [
          "Qizhu Li",
          "Anurag Arnab",
          "Philip H"
        ],
        "url": "https://arxiv.org/pdf/1709.03612",
        "ref_texts": "[50] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR, 2017.",
        "ref_ids": [
          "50"
        ]
      },
      "Pedestrian detection at night using deep neural networks and saliency maps": {
        "authors": [
          "Duyoung Heo",
          "Ju Lee",
          "Byoung Chul",
          "Keimyung University"
        ],
        "url": "https://library.imaging.org/admin/apis/public/api/ist/website/downloadArticle/ei/30/17/art00015",
        "ref_texts": "31L-C. Chem, Y. Yang, J. Wang, W . Xu, and A. L. Yuille, `` Attention to scale: scale-aware semantic image segmentation, '' Proc. 2016 IEEE Int'l. Conf. on Computer Vision and Pattern Recognition\u0015CVPR 2016 (IEEE, Piscataway, NJ, 2016), pp. 3640\u00153649.32H. Zhao, J. Shi, Z. Qi, X. Wang, and J. Jia, ``Pyramid scene parsing network, '' Proc. 2017 IEEE Int'l. Conf. on Computer Vision and Pattern Recognition\u0015CVPR 2017 (IEEE, Piscataway, NJ, 2017), pp. 1\u001511."
      },
      "Automatic tool landmark detection for stereo vision in robot-assisted retinal surgery": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1709.05665",
        "ref_texts": "[31] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In CVPR , 2017.",
        "ref_ids": [
          "31"
        ]
      },
      "Log-densenet: How to sparsify a densenet": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1711.00002",
        "ref_texts": "9 Published as a conference paper at ICLR 2018 G. Larsson, M. Maire, and G. Shakhnarovich. Fractalnet: Ultra-deep neural networks without residuals. In International Conference on Learning Representations (ICLR) , 2017. Chen-Yu Lee, Saining Xie, Patrick W. Gallagher, Zhengyou Zhang, and Zhuowen Tu. Deeplysupervised nets. In AISTATS , 2015. Tongchen Li. https://github.com/Tongcheng/caffe/blob/master/src/caffe/ layers/DenseBlock_layer.cu , 2016. Zhuang Liu. https://github.com/liuzhuang13/DenseNet/tree/master/ models , 2017. Zhuang Liu, Jianguo Li, Zhiqiang Shen, Gao Huang, Shoumeng Yan, and Changshui Zhang. Learning efficient convolutional networks through network slimming. In arxiv preprint:1708.06519 , 2017. J. Long, E. Shelhamer, and T. Darrell. Fully convolutional networks for semantic segmentation. In CVPR , 2015. Yuval Netzer, Tao Wang, Adam Coates, Alessandro Bissacco, Bo Wu, and Andrew Y . Ng. Reading digits in natural images with unsupervised feature learning. In NIPS Workshop on Deep Learning and Unsupervised Feature Learning , 2011. S. Hussain Raza, Matthias Grundmann, and Irfan Essa. Geometric context from video. In CVPR , 2013. Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma, Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael Bernstein, Alexander C. Berg, and Li Fei-Fei. ImageNet Large Scale Visual Recognition Challenge. IJCV , 2015. Karen Simonyan and Andrew Zisserman. Very deep convolutional networks for large-scale image recognition. arXiv preprint arXiv:1409.1556 , 2014. Rupesh Kumar Srivastava, Klaus Greff, and J \u00a8urgen Schmidhuber. Highway networks. arXiv preprint arXiv:1505.00387 , 2015. Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Computer Vision and Pattern Recognition (CVPR) , 2017."
      },
      "Large scale labelled video data augmentation for semantic segmentation in driving scenarios": {
        "authors": [
          "Ignas Budvytis",
          "Patrick Sauer",
          "Thomas Roddick",
          "Kesar Breen",
          "Roberto Cipolla"
        ],
        "url": "http://openaccess.thecvf.com/content_ICCV_2017_workshops/papers/w3/Budvytis_Large_Scale_Labelled_ICCV_2017_paper.pdf",
        "ref_texts": "[37] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , July 2017.",
        "ref_ids": [
          "37"
        ]
      },
      "Close yet distinctive domain adaptation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1704.04235",
        "ref_texts": "[21] Z HAO, H., S HI, J., Q I, X., W ANG , X., AND JIA, J. Pyramid scene parsing network. CoRR abs/1612.01105 (2016).",
        "ref_ids": [
          "21"
        ]
      },
      "Lucid data dreaming for multiple object tracking": {
        "authors": [],
        "url": "https://pure.mpg.de/rest/items/item_2418086_4/component/file_2493060/content",
        "ref_texts": "78. H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In CVPR , 2017. 2, 4",
        "ref_ids": [
          "78"
        ]
      },
      "Deep edge-aware saliency detection": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1708.04366",
        "ref_texts": "[55] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proc. IEEE Conf. Comp. Vis. Patt. Recogn. , July 2017, pp.",
        "ref_ids": [
          "55"
        ]
      },
      "Sharing residual units through collective tensor factorization in deep neural networks": {
        "authors": [
          "Chen Yunpeng",
          "Jin Xiaojie",
          "Kang Bingyi",
          "Feng Jiashi",
          "Yan Shuicheng"
        ],
        "url": "https://arxiv.org/pdf/1703.02180",
        "ref_texts": "442\u2013450, 2015. Oseledets, Ivan V . Tensor-train decomposition. SIAM Journal on Scientific Computing , 33(5):2295\u20132317, 2011. Russakovsky, Olga, Deng, Jia, Su, Hao, Krause, Jonathan, Satheesh, Sanjeev, Ma, Sean, Huang, Zhiheng, Karpathy, Andrej, Khosla, Aditya, Bernstein, Michael, Berg, Alexander C., and Fei-Fei, Li. ImageNet Large Scale Visual Recognition Challenge. International Journal of Computer Vision (IJCV) , 115(3):211\u2013252, 2015. doi: 10.1007/s11263-015-0816-y. Szegedy, Christian, Ioffe, Sergey, Vanhoucke, Vincent, and Alemi, Alex. Inception-v4, inception-resnet and the impact of residual connections on learning. arXiv preprint arXiv:1602.07261 , 2016. Tucker, Ledyard R. Some mathematical notes on threemode factor analysis. Psychometrika , 31(3):279\u2013311, 1966. Veit, Andreas, Wilber, Michael J, and Belongie, Serge. Residual networks behave like ensembles of relatively shallow networks. In Advances in Neural Information Processing Systems , pp. 550\u2013558, 2016. Wu, Zifeng, Shen, Chunhua, and Hengel, Anton van den. Wider or deeper: Revisiting the resnet model for visual recognition. arXiv preprint arXiv:1611.10080 , 2016. Xie, Saining, Girshick, Ross, Doll \u00b4ar, Piotr, Tu, Zhuowen, and He, Kaiming. Aggregated residual transformations for deep neural networks. arXiv preprint arXiv:1611.05431 , 2016. Sharing Residual Units Through Collective Tensor Factorization in Deep Neural Networks Zagoruyko, Sergey and Komodakis, Nikos. Wide residual networks. arXiv preprint arXiv:1605.07146 , 2016. Zhang, Xingcheng, Li, Zhizhong, Loy, Chen Change, and Lin, Dahua. Polynet: A pursuit of structural diversity in very deep networks. arXiv preprint arXiv:1611.05725 , 2016. Zhao, Hengshuang, Shi, Jianping, Qi, Xiaojuan, Wang, Xiaogang, and Jia, Jiaya. Pyramid scene parsing network. arXiv preprint arXiv:1612.01105 , 2016. Zhou, Bolei, Khosla, Aditya, Lapedriza, Agata, Torralba, Antonio, and Oliva, Aude. Places: An image database for deep scene understanding. arXiv preprint arXiv:1610.02055 , 2016."
      },
      "Distantly supervised road segmentation": {
        "authors": [
          "Satoshi Tsutsui",
          "Tommi Kerola",
          "Shunta Saito"
        ],
        "url": "http://openaccess.thecvf.com/content_ICCV_2017_workshops/papers/w3/Tsutsui_Distantly_Supervised_Road_ICCV_2017_paper.pdf",
        "ref_texts": "[32] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid Scene Parsing Network. In CVPR , 2017. 1,2",
        "ref_ids": [
          "32"
        ]
      },
      "Load balancing memcached traffic using software defined networking": {
        "authors": [
          "Anat Bremler",
          "David Hay",
          "Idan Moyal",
          "Liron Schiff"
        ],
        "url": "http://opendl.ifip-tc6.org/db/conf/networking/networking2017/1570334807.pdf",
        "ref_texts": ""
      },
      "Computationally efficient cardiac views projection using 3D convolutional neural networks": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1711.01345",
        "ref_texts": "10. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. arXiv preprint arXiv:1612.01105 (2016)",
        "ref_ids": [
          "10"
        ]
      },
      "Multi-scale salient object detection with pyramid spatial pooling": {
        "authors": [],
        "url": "http://www.apsipa.org/proceedings/2017/CONTENTS/papers2017/14DecThursday/Poster%204/TP-P4.16.pdf",
        "ref_texts": "[14] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d CoRR, vol. abs/1612.01105, 2016. 1,2,3",
        "ref_ids": [
          "14"
        ]
      },
      "A review of neural network based semantic segmentation for scene understanding in context of the self driving car": {
        "authors": [],
        "url": "https://elib.dlr.de/110862/1/PaperStudierendentagungJoshuaNiemeijer.pdf",
        "ref_texts": "[1] E. Shelhamer, J. Long, and T. Darrell, \u201cFully con-volutional networks for semantic segmentation,\u201dIEEETransactions on Pattern Analysis and Machine Intelli-gence, vol. PP, no. 99, pp. 1\u20131, 2016.[2] M. Cordts, M. Omran, S. Ramos, T. Rehfeld, M. En-zweiler, R. Benenson, U. Franke, S. Roth, andB. Schiele, \u201cThe cityscapes dataset for semantic ur-ban scene understanding,\u201dCoRR, vol. abs/1604.01685,2016.[3] G. Ghiasi and C. C. Fowlkes,Laplacian Pyramid Re-construction and Refinement for Semantic Segmenta-tion, pp. 519\u2013534. Cham: Springer International Pub-lishing, 2016.[4] G. Lin, C. Shen, A. van den Hengel, and I. D. Reid,\u201cExploring context with deep structured models forsemantic segmentation,\u201dCoRR, vol. abs/1603.03183,2016.[5] Z. Wu, C. Shen, and A. van den Hengel, \u201cWider ordeeper: Revisiting the resnet model for visual recog-nition,\u201dCoRR, vol. abs/1611.10080, 2016.[6] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramidScene Parsing Network,\u201dArXiv e-prints, Dec. 2016.[7] K. Simonyan and A. Zisserman, \u201cVery deep convo-lutional networks for large-scale image recognition,\u201dCoRR, vol. abs/1409.1556, 2014.",
        "ref_ids": [
          "1",
          "2",
          "3",
          "4",
          "5",
          "6",
          "7"
        ]
      },
      "Enlarging effective receptive field of convolutional neural networks for better semantic segmentation": {
        "authors": [],
        "url": "http://www.yongxu.org/paper/Enlarging%20Effective%20Receptive%20Field%20of%20Convolutional%20Neural%20Networks%20for%20Better.pdf",
        "ref_texts": "[12] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d arXiv preprint arXiv:1612.01105 , 2016.",
        "ref_ids": [
          "12"
        ]
      },
      "Learning dilation factors for semantic segmentation of street scenes": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1709.01956",
        "ref_texts": "21. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. arXiv preprint arXiv:1612.01105 (2016)",
        "ref_ids": [
          "21"
        ]
      },
      "Magic-wall: Visualizing room decoration": {
        "authors": [
          "Ting Liu",
          "Yunchao Wei",
          "Yao Zhao",
          "Si Liu",
          "Shikui Wei"
        ],
        "url": "http://mepro.bjtu.edu.cn/res/papers/2017/Magic-wall%20%20Visualizing%20Room%20Decoration.pdf",
        "ref_texts": "[40] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. 2016. Pyramid Scene Parsing Network. CoRR abs/1612.01105 (2016).",
        "ref_ids": [
          "40"
        ]
      },
      "Identifying most walkable direction for navigation in an outdoor environment": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1711.08040",
        "ref_texts": "[72] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. CVPR , 2017. 10",
        "ref_ids": [
          "72"
        ]
      },
      "Synthesized semantic views for mobile robot localization": {
        "authors": [],
        "url": "https://www.tu-chemnitz.de/etit/proaut/publications/ecmr2017.pdf",
        "ref_texts": "[12] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d CoRR , vol. abs/1612.01105, 2016.",
        "ref_ids": [
          "12"
        ]
      },
      "Transferring visual knowledge for a robust road environment perception in intelligent vehicles": {
        "authors": [],
        "url": "http://robesafe.com/personal/bergasa/papers/Roberto_ITSC2017.pdf",
        "ref_texts": "[8] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d arXiv preprint arXiv:1612.01105 , 2016.",
        "ref_ids": [
          "8"
        ]
      },
      "Beyond forward shortcuts: Fully convolutional master-slave networks (msnets) with backward skip connections for semantic segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1707.05537",
        "ref_texts": "[41] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. CoRR , abs/1612.01105, 2016.",
        "ref_ids": [
          "41"
        ]
      },
      "Arbitext: Arbitrary-oriented text detection in unconstrained scene": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1711.11249",
        "ref_texts": "[30] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid Scene Parsing Network. arXiv:1612.01105 [cs] , Dec. 2016. arXiv: 1612.01105.",
        "ref_ids": [
          "30",
          "cs"
        ]
      },
      "\u6df1\u5c64\u5b66\u7fd2\u306b\u3088\u308b\u753b\u50cf\u8a8d\u8b58": {
        "authors": [],
        "url": "https://www.jstage.jst.go.jp/article/jrsj/35/3/35_35_180/_pdf",
        "ref_texts": "[24] H. Zhao, J. Shi, X. Qi, X. Wang and J. Jia: \u201cPyramid Scene Parsing Network,\u201d arXiv preprint arXiv:1612.01105, 2016.",
        "ref_ids": [
          "24"
        ]
      },
      "Evidential grammars: A compositional approach for scene understanding. Application to multimodal street data": {
        "authors": [],
        "url": "https://hal.science/hal-01703417/document",
        "ref_texts": "[5] H. Zhao, J. Shi, X. Qi, X. Wang, J. Jia, Pyramid scene parsing network, in: IEEE Conference on Computer Vision and Pattern Recognition, IEEE Computer Society, Honolulu, Hawaii, USA, 2017.",
        "ref_ids": [
          "5"
        ]
      },
      "Using cross-model egosupervision to learn cooperative basketball intention": {
        "authors": [],
        "url": "http://openaccess.thecvf.com/content_ICCV_2017_workshops/papers/w34/attention_gbertaseas.upenn.edu_jshiseas.upenn.edu_ICCV_2017_paper.pdf",
        "ref_texts": "[48] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. CoRR , abs/1612.01105, 2016. 6",
        "ref_ids": [
          "48"
        ]
      },
      "Rethinking convolutional semantic segmentation learning": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1710.07991",
        "ref_texts": "[10] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. arXiv:1612.01105, 2016.",
        "ref_ids": [
          "10"
        ]
      },
      "Traffic scene segmentation based on boosting over multimodal low, intermediate and high order multi-range channel features": {
        "authors": [
          "Arthur Daniel",
          "Sergiu Nedevschi"
        ],
        "url": "https://cv.utcluj.ro/tl_files/cv/publications/Traffic%20Scene%20Segmentation%20based%20on%20Boosting%20over%20Multimodal%20Low,%20Intermediate%20and%20High%20Order%20Multi-range%20Channel%20Features%20.pdf",
        "ref_texts": "[34] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. \u0002Pyramid Scene Parsing Network\u0004. In arXiv , 2016. ",
        "ref_ids": [
          "34"
        ]
      },
      "CYBERH: Cyber-physical systems in health for personalized assistance": {
        "authors": [],
        "url": "http://refbase.cvc.uab.es/files/GHC2017.pdf",
        "ref_texts": ""
      },
      "Semi-supervised hierarchical semantic object parsing": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1709.08019",
        "ref_texts": "[18] H Zh ao, J Shi, X Qi, X Wang, J Jia, \u201c Pyramid scene parsing network,\u201d CVPR, 2017 . ",
        "ref_ids": [
          "18"
        ]
      },
      "Neuron-level selective context aggregation for scene segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1711.08278",
        "ref_texts": "[30] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In Proc. CVPR , 2017. 1, 2, 3",
        "ref_ids": [
          "30"
        ]
      },
      "Cascaded region-based densely connected network for event detection: A seismic application": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1709.07943",
        "ref_texts": "[16] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in CVPR , 2016.",
        "ref_ids": [
          "16"
        ]
      },
      "Image segmentation via foreground and background semantic descriptors": {
        "authors": [],
        "url": "https://www.spiedigitallibrary.org/journals/Journal-of-Electronic-Imaging/volume-26/issue-5/053004/Image-segmentation-via-foreground-and-background-semantic-descriptors/10.1117/1.JEI.26.5.053004.pdf",
        "ref_texts": "19. H. Zhao et al., \u201cPyramid scene parsing network, \u201dinIEEE Conf. on Computer Vision and Pattern Recognition (CVPR) , pp. 2881 \u20132890",
        "ref_ids": [
          "19"
        ]
      },
      "Some promising ideas about multi-instance video segmentation": {
        "authors": [],
        "url": "https://davischallenge.org/challenge2017/papers/DAVIS-Challenge-7th-Team.pdf",
        "ref_texts": "[9] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In CVPR 2017 .1",
        "ref_ids": [
          "9"
        ]
      },
      "Automatic real-time background cut for portrait videos": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1704.08812",
        "ref_texts": "[74] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. CoRR , abs/1612.01105, 2016.",
        "ref_ids": [
          "74"
        ]
      },
      "Multiple skip connections and dilated convolutions for semantic segmentation": {
        "authors": [],
        "url": "http://mprg.jp/data/MPRG/C_group/C087_yamashita2017.pdf",
        "ref_texts": "[21] H. Zhao, J. Shi, X. Qi, X. Wang, J. Jia, \u201dPyramid Scene Parsing Network\u201d, arXiv preprint arXiv:1612.01105, 2016.",
        "ref_ids": [
          "21"
        ]
      },
      "On the diversity of realistic image synthesis": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1712.07329",
        "ref_texts": "[37] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2017.",
        "ref_ids": [
          "37"
        ]
      },
      "Towards interpretable vision systems": {
        "authors": [],
        "url": "https://vtechworks.lib.vt.edu/bitstreams/73fa0a2c-8b78-461a-81be-1656307323ba/download",
        "ref_texts": "[156] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In arXiv:1612.01105 , 2016.",
        "ref_ids": [
          "156"
        ]
      },
      "\u753b\u50cf\u3092\u751f\u6210\u3059\u308b\u6df1\u5c64\u5b66\u7fd2\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u2015\u9818\u57df\u5206\u5272\u3068\u753b\u50cf\u751f\u6210\u30fb\u5909\u63db\u2015": {
        "authors": [],
        "url": "https://www.jstage.jst.go.jp/article/isj/56/2/56_168/_pdf",
        "ref_texts": ""
      },
      "Per-Pixel Feedback for improving Semantic Segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1712.02861",
        "ref_texts": "[50] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. CoRR , abs/1612.01105, 2016.",
        "ref_ids": [
          "50"
        ]
      },
      "Applying Deep Learning in Street View Imagery for Environmental Health Research": {
        "authors": [],
        "url": "https://ir.library.oregonstate.edu/downloads/6682x8885",
        "ref_texts": " Semantic segmentation, as described abo ve, takes as input an image and does classification for every pixel in the image. It assigns each pixel in the input image a category label. After comparing several impressive deep learning models on semantic segmentation, we choose Pyramid Scene Parsing N etwork (PSPNet) [15] as out model to do segmentation on street -view images. And since the PSPNet framework is based on the fully convolutional network (FCN), understanding FCN is necessary for understanding PSPNet. FCN is a famous model that many state -of-the-art segmentation models are based on it. Unlike prior models which labels each pixel with the class of its enclosing region, FCN does pixelwise prediction directly on every pixel and hence leads to efficiency. Two important components of FCN are convolu tional layers that ",
        "ref_ids": [
          "15"
        ]
      },
      "Instance-level Semantic Segmentation by Deep Normalized Cuts": {
        "authors": [],
        "url": "https://lup.lub.lu.se/student-papers/record/8925933/file/8925936.pdf",
        "ref_texts": "2 Another successful method for instance-level semantic segmentation is proposed by Li et al. (2016). It combines the segment proposal system of Dai, He, Li, Ren and Sun (2016) with the object detection system of Dai, Li, He and Sun (2016). The common idea in these systems is to detect instances from position-sensitive feature maps that jointly consider object classes, bounding boxes, and segmentation masks, making their implementations fast. Some methods based on object detectors may assign multiple instances to the same pixel. A conceptually different way of performing instance-level semantic segmentation, that resolves this problem, is to instead begin with a pixel-level semantic segmentation, then attempt to further partition the segments of a given class into individual object instances. The pyramid scene parsing network (PSPNet) of Zhao et al. (2016) demonstrates state-of-the-art performance on several pixel-level segmentation benchmarks. Starting from an image\u2019s pixel-level semantic segmentation, as produced by PSPNet, Bai and Urtasun (2016) combine intuitions from the classical watershed transform and modern deep learning to produce an energy map of the image, where object instances are represented as energy basins. A cut at a single energy level yields connected components that correspond to object instances. Arnab and Torr (2017) use an initial pixel-level semantic segmentation module and cues from an object detector to feed an instance-aware subnetwork that uses an end-to-end conditional random field to predict instances. Both of these methods prove successful at performing instance-level semantic segmentation. The mechanism used by human beings to infer object segments is arguably more similar to the above methods that start off with object detection. Be that as it may, this thesis follows the latter approach and attempts to carve out individual object instances from pixellevel segmentations. (It does, however, not attempt to compete with current state of the art methods.)"
      },
      "Depth based image segmentation": {
        "authors": [],
        "url": "https://upcommons.upc.edu/bitstream/handle/2117/114201/depth_based_image_segmentation.pdf?sequence=1",
        "ref_texts": " \u201cPyramid \u200b \u200b Scene \u200b \u200b Parsing \u200b \u200b Network\u201d. \u200b \u200b In \u200b \u200b\u200b arXiv:1612.01105 \u200b , \u200b \u200b December \u200b \u200b 2016 "
      },
      "Exploring and Exploiting Diversity for Image Segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1709.01625",
        "ref_texts": ""
      },
      "Instance Re-Identification Flow for Video Object Segmentation": {
        "authors": [],
        "url": "https://davischallenge.org/challenge2017/papers/DAVIS-Challenge-3rd-Team.pdf",
        "ref_texts": "[21] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia. Pyramid scene parsing network. In Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2017.",
        "ref_ids": [
          "21"
        ]
      },
      "Masknet: An instance segmentation algorithm-Leveraging object detection and semantic segmentation to tackle instance segmentation": {
        "authors": [],
        "url": "https://odr.chalmers.se/bitstreams/08d433a8-9c07-439b-8699-6dc09e91091e/download",
        "ref_texts": "[31] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. CoRR, abs/1612.01105, 2016.",
        "ref_ids": [
          "31"
        ]
      },
      "Designing Convolutional Neural Networks for Urban Scene Understanding": {
        "authors": [],
        "url": "https://www.ri.cmu.edu/app/uploads/2017/05/YeYuan_Thesis.compressed.pdf",
        "ref_texts": "[37] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. arXiv preprint arXiv:1612.01105 , 2016. 4.1.4",
        "ref_ids": [
          "37"
        ]
      },
      "Recurrent Scene Parsing with Perspective Understanding in the Loop": {
        "authors": [],
        "url": "http://vision.ics.uci.edu/papers/KongF_TR_2017/KongF_TR_2017.pdf",
        "ref_texts": "[30] Zhao, H., Shi, J., Qi, X., Wang, X., and Jia, J. (2017). Pyramid scene parsing network. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition .",
        "ref_ids": [
          "30"
        ]
      },
      "Improving Deep Learning Image Recognition Performance Using Region of Interest Localization Networks": {
        "authors": [
          "Wahab Kabani"
        ],
        "url": "https://ir.lib.uwo.ca/cgi/viewcontent.cgi?article=6236&context=etd",
        "ref_texts": "[90] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. arXiv preprint arXiv:1612.01105 , 2016.",
        "ref_ids": [
          "90"
        ]
      },
      "Improved deep learning techniques for recognition and labeling": {
        "authors": [],
        "url": "https://dr.ntu.edu.sg/bitstream/10356/72748/1/Abrar_Thesis_NTU_2017.pdf",
        "ref_texts": "[236] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \\Pyramid scene parsing network,\" CoRR , vol. abs/1612.01105, 2016.",
        "ref_ids": [
          "236"
        ]
      },
      "Brain inspired Image Understanding": {
        "authors": [],
        "url": "https://webthesis.biblio.polito.it/secure/6436/1/tesi.pdf",
        "ref_texts": ""
      },
      "\u6df1\u5c64\u5b66\u7fd2\u3068\u305d\u306e\u753b\u50cf\u5fdc\u7528\u306b\u95a2\u3059\u308b\u6700\u65b0\u52d5\u5411": {
        "authors": [],
        "url": "https://www.jstage.jst.go.jp/article/isj/56/2/56_157/_pdf",
        "ref_texts": ""
      }
    }
  },
  {
    "title": "robust monocular slam in dynamic environments",
    "id": 7,
    "valid_pdf_number": "15/19",
    "matched_pdf_number": "0/15",
    "matched_rate": 0.0,
    "citations": {
      "Revisiting trends in augmented reality research: A review of the 2nd decade of ISMAR (2008\u20132017)": {
        "authors": [
          "Kangsoo Kim",
          "Student Member",
          "Mark Billinghurst",
          "Senior Member",
          "Gerd Bruder",
          "Henry Been",
          "Lirn Duh",
          "Senior Member",
          "Gregory F. Welch",
          "Senior Member"
        ],
        "url": "https://par.nsf.gov/servlets/purl/10105851",
        "ref_texts": "[137] W. Tan, H. Liu, Z. Dong, G. Zhang, and H. Bao. Robust monocular SLAM in dynamic environments. IEEE International Symposium on Mixed and Augmented Reality, pages 209\u2013218, 2013.",
        "ref_ids": [
          "137"
        ]
      },
      "Visual SLAM and structure from motion in dynamic environments: A survey": {
        "authors": [],
        "url": "https://www.cs.ox.ac.uk/files/9926/Visual%20Slam.pdf",
        "ref_texts": "[152] Wei Tan, Haomin Liu, Zilong Dong, Guofeng Zhang, and Hujun Bao. 2013. Robust monocular SLAM in dynamic environments. In IEEEInt.Symp. Mix. Augment.Real.",
        "ref_ids": [
          "152"
        ]
      },
      "ORB-SLAM: a versatile and accurate monocular SLAM system": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1502.00956",
        "ref_texts": "[24] W. Tan, H. Liu, Z. Dong, G. Zhang, and H. Bao, \u201cRobust monocular SLAM in dynamic environments,\u201d in IEEE International Symposium on Mixed and Augmented Reality (ISMAR) , Adelaide, Australia, October 2013, pp. 209\u2013218.",
        "ref_ids": [
          "24"
        ]
      },
      "DynaSLAM: Tracking, mapping, and inpainting in dynamic scenes": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1806.05620",
        "ref_texts": "[9] W. Tan, H. Liu, Z. Dong, G. Zhang, and H. Bao, \u201cRobust monocular SLAM in dynamic environments,\u201d in ISMAR , pp. 209\u2013218, 2013.",
        "ref_ids": [
          "9"
        ]
      },
      "The revisiting problem in simultaneous localization and mapping: A survey on visual loop closure detection": {
        "authors": [
          "Konstantinos A. Tsintotas",
          "Loukas Bampis",
          "Antonios Gasteratos"
        ],
        "url": "https://arxiv.org/pdf/2204.12831",
        "ref_texts": "19932 IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEM S, VOL. 23, NO. 11, NOVEMBER 2022 a query image as possible, e.g., for 3D-model reconstruction [38]. More specifically, the former has to identify only one reference candidate associated with the previously visited traversal under varied conditions, while the latter can retrievemore matches, corresponding to a broad collection of images. Furthermore, in robotics, visual place recognition involves sequential imagery, significantly affecting the recognizer\u2019s per-formance. Finally, visual place recognition in robotics, apart from performing a topological constraint that indicates the same place in the database, produces geometric information that can be used to correct the trajectory, such as in the case of loop closure detection. In [7], Lowry et al. discuss the problem and provide a comprehensive survey of visual place recognition, while the work of Garg et al. [10] gives a broader discussion about the differences between visual placerecognition in computer visi on and robotics communities. III. S IMULTANEOUS LOCALIZATION AND MAPPING A robot\u2019s capability to build a map (deriving the model of an unknown environment) and loca lizing (estimating its position) within that map is essential f or intelligent autonomous operations and, during the last three decades, one of the most famousresearch topics [39]. This is the classic SLAM problem, which has evolved as a primary paradigm for providing a solution for autonomous systems\u2019 navigation without depending onabsolute positioning measurements, such as the ones given by global navigation satellite systems (GNSS). Nevertheless, given the noise in the sensors\u2019 signal and modeling inaccuracies, drift is presented even if the most accurate state estimators are used. Therefore, the robot\u2019s motion estimationdegenerates as the explored environment size grows, specifically with the traversed cycles\u2019 size therein [40]. A SLAM architecture commonly comprises a front-end and a back-end component. The former handles the unprocessed sensor data modeling that is amenable for estimation, and the latter performs assumptions based on the incoming sensory inputs. Loop closure detection belongs to the front-end, as it is required to create constraints among locations once the robotreturns to an earlier visited area [3], while outlier (i.e., falsepositive loop closures) rejection is assigned to the back-end of SLAM [41]\u2013[43]. In what follows, the role of loop closuredetection and re-localization in the localization and mapping engines of SLAM is analyzed, and its dependence on the utilized sensing devices are examined. A. Localization Localization refers to the robot\u2019s task to establish its pose concerning a known frame of reference [44]. More specifically, \u201cthe wake-up robot problem,\u201d [45] i.e., global localization, addresses the difficulty of recovering the robot\u2019s pose within a previously built map. At the same time, similar to the previous task, the re-localization task into SLAM, which is also known as the \u201ckidnapped-robot problem,\u201d [46] concerns the position recovery based on a beforehand generated map following anarbitrary \u201cblind\u201d displacement, viz., without awareness of the displacement, happening under h eavy occlusions or tracking failures. The above tasks attempt to identify a correspondenceconnecting the robot\u2019s current observation with a stored one in the database. Nevertheless, the robot has no information about its previous pose during that process, and it can be considered lost. Contrariwise, constraints between the currentand the previous pose are known during loop closure detection. More specifically, the system tries to determine whether or not the currently recorded location belongs to an earlier visitedarea and compute an additional constrain to further improve its localization and mapping (see Section III-B) accuracy. However, each of the aforementioned cases is addressed by similar mechanisms using the most recent observation and a place recognizer. If a match is successful, it providescorrespondence and, in many cases, a transformation matrix between the current and the database poses in the map. B. Mapping Trajectory mapping, which is of particular interest in autonomous vehicles, provides the robot with a modeled structure to effectively localize, navigate, and interact with its sur-roundings. Three major mapping models exist within SLAM, viz., metric, topological, and hybrid (metric-topological) maps. Metric maps provide geometri cally accurate representations of the robot\u2019s surroundings, enabling centimeter-level accuracy for localization [47]. However , when the appearance information is not considered, more frequent loop closure detection failures in environments with repetitive geometrical structures are indicated. In addition, this model is also computationallyinfeasible when large distances are dealt with [48]. Relying on a higher representation level than metric ones, topological maps mimic the humans\u2019 and animals\u2019 internal maps[49]\u2013[51]. A coarse, graph-like description of the environment is generated, where each new observation is added as a node, corresponding to a specific location. Furthermore, edges are used to denote neighboring connections, i.e., if a location is accessible from a different one. This flexible model, intro-duced by Kuipers and Byun [52], provides a more compact structure that scales better with the traversed route\u2019s size. Regardless of the robot\u2019s estimated metric position, whichbecomes progressively less accura te, these approaches attempt to detect loops only upon the similarity between sensory measurements [53]\u2013[55]. On the one hand, two nodes become directly connected during re-localization, enabling the robot to continue its mapping process. On the other hand, loopclosure detection forms additional connections between the current and a corresponding node while the current node rectifying this way the accumulated mapping error [56] (seeFig. 4). An extensive review regarding topological mapping is provided by the authors in [5]. Finally, in metric-topological maps, the environment is represented via a graph-based modelwhose nodes are related to local metric maps, i.e.,a topological map is constructed, which is further split into a set of metric sub-maps [57]\u2013[60]. C. Sensing Aiming at overcoming GNSS limitations and detecting loop closures, different sensors have been used over the years, Authorized licensed use limited to: University of Thrace (Democritus University of Thrace). Downloaded on November 09,2022 at 11:14:46 UTC from IEEE Xplore. Restrictions apply. TSINTOTAS et al. : REVISITING PROBLEM IN SLAM: SURVEY ON VISUAL LOOP CLOSURE DETECTION 19933 Fig. 4. A representative example highlighting the differences between topological loop closure detection and re -localization. The query node (shaded observation) searches the database for candidate matches and, subsequently, the most similar is chosen. Two components are connected through a constraint (bottom) when the system re-localizes its pose due to a tracking failure,while an another one edge is created between the two nodes (top) in the caseof loop closure detection. including wheel encoders, sonars, lasers, and cameras. Generally, range finders are chosen because of their capability tomeasure the distance of the robot\u2019s surroundings with high precision [61]\u2013[63]. However, they are also bounded with some limitations. The sonar is fast and inexpensive but frequentlyvery crude, whereas a laser sensor is active and accurate; however, it is slow. Within the last years, since 3D maps [64] became more popular over traditi onal 2D [65], light detection and ranging (LiDAR) is established as the primary sensor for large-scale 3D geometric reconstructions [66]. Yet, theyremain unsuitable for mass installation on mobile robots due to their weight, price, and power consumption. Furthermore, its measurements, i.e., scan readings, cannot be distinguished during loop closure detection from locations with similar shapes but different appearances, such as corridors. Although successful mapping techniques based on range-finders are implemented [67]\u2013[69], these types of sensors tend to be associated with, or replaced by , single cameras [70]\u2013[76] or stereo camera rigs [77]\u2013[82]. This is mainly due to the rich textural information embedded in images, the cameras\u2019 low cost, and their applicability to vari ous mobile robots with limited computational powers, such as the unmanned aerial vehicles (UA Vs) [83]. Yet, even if multi-sensor frameworks [84]\u2013[87] can improve performance, especia lly in changing environmental conditions [88], such a setup requires expensive hardware and additional calibration than camera-only ones [89]. Duringthe second decade of visual-based navigation, autonomous robots\u2019 trajectory mapping of up to 1000 km has been successfully achieved using cameras as the primary sensorymodality [90]. The solution of a monocular camera provides practical advantages concerning size, power, and cost, but also several challenges, such as the unobservability of thescale or state initialization. Nevertheless, these issues could be addressed by adopting more complex setups, such as stereo or RGB-D cameras [91]\u2013[94]. Lastly, even if limited attention has been received regarding the event-based cameras within the vision research community [95], their high dynamic rangeand the lack of motion blur are proved benefitial in challenging lighting conditions and high-speed applications [96].Fig. 5. Schematic structure depicting the essential parts of a visual loop closure detection system. The image is processed to extract the corresponding visual representation, by either using trained data (visual bag of words) or not, and the robot\u2019s internal database is c onstructed incrementally as the newly captured sensory measurement enters the system (visual data). When the query image arrives, its representation is compared against the database, i.e., the environment representation, aiming to decide whether the robot navigates to an already visited area. Since loop closures occur sparsely, the database isupdated accordingly when a match occurs. IV . S TRUCTURE OF A VISUAL LOOP CLOSURE DETECTION SYSTEM A loop closure detection system\u2019s generic block diagram is depicted in Fig. 5. Firstly, a system interpreting the environment\u2019s appearance has to detect previously visited locations by employing only visual sensory information; thus,the perceived images have to be interpreted robustly, aiming for an informatively built map. Then, the system\u2019s internal environment representation of the navigated path needs to beaddressed. In many cases, such representations are driven by the robot\u2019s assigned mission. Aiming to decide whether or not the robot navigates a previously seen area, the decisionextraction module performs data comparisons among the query and the database instances. Confidence is determined via their similarity scores. Lastly, as the system operates on-line, the map is updated accordingly throughout the autonomous mission\u2019s course. Each of the parts mentioned above is detailedin the following sections. V. F EATURE EXTRACTION Aiming at an informative map constructed solely from visual sensing, a suitable representation of the recorded data is needed. It is not surprising that most pipelines use feature vectors extracted from images to describe the traversedroute, given their discriminative capabilities. This characteristic extends to the visual loop closure detection task and renders it essential to select an effective visual feature encoder. The traditional choice for such a mech anism refers to hand-crafted features that are manually designed to extract specific imagecharacteristics. Recently, however, the outstanding achievements in several computer vision tasks through deep learning have turned the scientific focus towards learned featuresextracted from CNN activations. A categorization of these methods is provided in Table I. A. Hand-Crafted Feature-Based Representation It is shown via various experimental studies that humans can rapidly categorize a scene using only the crude global information or \u201cgist\u201d of a scene [177], [178]. Similarly, Authorized licensed use limited to: University of Thrace (Democritus University of Thrace). Downloaded on November 09,2022 at 11:14:46 UTC from IEEE Xplore. Restrictions apply. ",
        "ref_ids": [
          "38",
          "7",
          "10",
          "39",
          "40",
          "3",
          "41",
          "43",
          "44",
          "45",
          "46",
          "47",
          "48",
          "49",
          "51",
          "52",
          "53",
          "55",
          "56",
          "5",
          "57",
          "60",
          "61",
          "63",
          "64",
          "65",
          "66",
          "67",
          "69",
          "70",
          "76",
          "77",
          "82",
          "83",
          "84",
          "87",
          "88",
          "89",
          "90",
          "91",
          "94",
          "95",
          "96",
          "177",
          "178"
        ]
      },
      "PL-SLAM: Real-time monocular visual SLAM with points and lines": {
        "authors": [],
        "url": "https://upcommons.upc.edu/bitstream/handle/2117/110259/1836-PL-SLAM--Real-Time-Monocular-Visual-SLAM-with-Points-and-Lines.pdf?ref=https://githubhelp.com",
        "ref_texts": "[29] W. Tan, H. Liu, Z. Dong, G. Zhang, and H. Bao. Robust monocular SLAM in dynamic environments. In ISMAR , pages 209\u2013218. IEEE, 2013.",
        "ref_ids": [
          "29"
        ]
      },
      "A comprehensive survey of augmented reality assembly research": {
        "authors": [],
        "url": "https://www.aim.shu.edu.cn/CN/article/downloadArticleFile.do?attachType=PDF&id=10845",
        "ref_texts": ""
      },
      "Semantics for robotic mapping, perception and interaction: A survey": {
        "authors": [],
        "url": "https://www.nowpublishers.com/article/DownloadSummary/ROB-059",
        "ref_texts": "[559]W. Tan, H. Liu, Z. Dong, G. Zhang, and H. Bao, \u201cRobust monocular SLAM in dynamic environments,\u201d in 2013 IEEE International Symposium on Mixed and Augmented Reality (ISMAR) , IEEE, pp. 209\u2013218, 2013.",
        "ref_ids": [
          "559"
        ]
      },
      "VDO-SLAM: A visual dynamic object-aware SLAM system": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2005.11052",
        "ref_texts": "[35] W. Tan, H. Liu, Z. Dong, G. Zhang, and H. Bao, \u201cRobust Monocular SLAM in Dynamic Environments,\u201d in International Symposium on Mixed and Augmented Reality (ISMAR) . IEEE, 2013, pp. 209\u2013218.",
        "ref_ids": [
          "35"
        ]
      },
      "Fast relocalisation and loop closing in keyframe-based SLAM": {
        "authors": [
          "Raul Mur",
          "Juan D. Tardos"
        ],
        "url": "https://webdiis.unizar.es/~jdtardos/papers/2014_IEEE_ICRA_Mur.pdf",
        "ref_texts": "[15] W. Tan, H. Liu, Z. Dong, G. Zhang, and H. Bao, \u201cRobust monocular SLAM in dynamic environments,\u201d in IEEE International Symposium on Mixed and Augmented Reality (ISMAR), 2013.",
        "ref_ids": [
          "15"
        ]
      },
      "Motion removal for reliable RGB-D SLAM in dynamic environments": {
        "authors": [],
        "url": "https://labsun.org/pub/RAS2018_motion.pdf",
        "ref_texts": "[20] W.Tan,H.Liu,Z.Dong,G.Zhang,H.Bao,RobustmonocularSLAMindynamic environments,in:MixedandAugmentedReality(ISMAR),2013IEEEInternationalSymposiumon,IEEE,2013,pp.209\u2013218.",
        "ref_ids": [
          "20"
        ]
      },
      "Rgb-d slam in dynamic environments using point correlations": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1811.03217",
        "ref_texts": "[38] W. Tan, H. Liu, Z. Dong, G. Zhang, and H. Bao, \u201cRobust monocular slam in dynamic environments,\u201d in Mixed and Augmented Reality (ISMAR), 2013 IEEE International Symposium on . IEEE, 2013, pp.",
        "ref_ids": [
          "38"
        ]
      },
      "A survey of simultaneous localization and mapping with an envision in 6g wireless networks": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1909.05214",
        "ref_texts": "[224] Wei Tan, Haomin Liu, Zilong Dong, Guofeng Zhang, and Hu jun Bao. Robust monocular slam in dynamic environments. In 2013 IEEE International Symposium on Mixed and Augmented Reality (IS MAR) , pages 209\u2013218. IEEE, 2013.",
        "ref_ids": [
          "224"
        ]
      },
      "Keyframe-based monocular SLAM: design, survey, and future directions": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1607.00470",
        "ref_texts": "[60] W. Tan, H. Liu, Z. Dong, G. Zhang, H. Bao, Robust monocula r SLAM in dynamic environments, 2013 IEEE International Symposium o n Mixed and Augmented Reality (ISMAR) (2013) 209\u2013218.",
        "ref_ids": [
          "60"
        ]
      },
      "The history of mobile augmented reality": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1505.01319",
        "ref_texts": "[68] W. Tan, H. Liu, Z. Dong, G. Zhang, and H. Bao, \\Robust monocular slam in dynamic environments,\" in IEEE International Symposium on Mixed and Augmented Reality (ISMAR) , pp. 209{218, Oct 2013. 28",
        "ref_ids": [
          "68"
        ]
      }
    }
  },
  {
    "title": "path aggregation network for instance segmentation",
    "id": 4,
    "valid_pdf_number": "718/1369",
    "matched_pdf_number": "0/718",
    "matched_rate": 0.0,
    "citations": {
      "Advances in medical image analysis with vision transformers: a comprehensive review": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2301.03505",
        "ref_texts": "[186] S. Liu, L. Qi, H. Qin, J. Shi, J. Jia, Path aggregation network for instance segmentation, in: Proceedings of the IEEE conference on computer vision and pattern recognition, 2018, pp. 8759\u20138768.",
        "ref_ids": [
          "186"
        ]
      },
      "Detrs beat yolos on real-time object detection": {
        "authors": [
          "Yian Zhao",
          "Wenyu Lv",
          "Shangliang Xu",
          "Jinman Wei",
          "Guanzhong Wang",
          "Qingqing Dang",
          "Yi Liu",
          "Jie Chen"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2024/papers/Zhao_DETRs_Beat_YOLOs_on_Real-time_Object_Detection_CVPR_2024_paper.pdf",
        "ref_texts": "[21] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 8759\u20138768, 2018. 4",
        "ref_ids": [
          "21"
        ]
      },
      "Deep learning in breast cancer imaging: A decade of progress and future directions": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2304.06662",
        "ref_texts": "[422] S. Liu et al. , \u201cPath aggregation network for instance segmentation,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition , pp. 8759\u20138768, 2018. V",
        "ref_ids": [
          "422"
        ]
      },
      "Yolo-world: Real-time open-vocabulary object detection": {
        "authors": [
          "Tianheng Cheng",
          "Lin Song",
          "Yixiao Ge",
          "Wenyu Liu",
          "Xinggang Wang",
          "Ying Shan"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Cheng_YOLO-World_Real-Time_Open-Vocabulary_Object_Detection_CVPR_2024_paper.pdf",
        "ref_texts": "[29] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In CVPR , pages 8759\u20138768, 2018. 3, 4",
        "ref_ids": [
          "29"
        ]
      },
      "Yolo-facev2: A scale and occlusion aware face detector": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2208.02019",
        "ref_texts": "[17] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia. Path aggregation network for instance segmentation. In 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2018.",
        "ref_ids": [
          "17"
        ]
      },
      "Regiongpt: Towards region understanding vision language model": {
        "authors": [
          "Qiushan Guo",
          "Shalini De",
          "Hongxu Yin",
          "Wonmin Byeon",
          "Ka Chun",
          "Yizhou Yu",
          "Ping Luo",
          "Sifei Liu"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Guo_RegionGPT_Towards_Region_Understanding_Vision_Language_Model_CVPR_2024_paper.pdf",
        "ref_texts": "[30] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 8759\u20138768, 2018. 4",
        "ref_ids": [
          "30"
        ]
      },
      "Diffusioninst: Diffusion model for instance segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2212.02773",
        "ref_texts": "[Liuet al. , 2018 ]Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In CVPR , pages 8759\u20138768, 2018.",
        "ref_ids": [
          "Liuet al\\. , 2018 "
        ]
      },
      "A yolo-based model for breast cancer detection in mammograms": {
        "authors": [
          "Francesco Prinzi"
        ],
        "url": "https://link.springer.com/content/pdf/10.1007/s12559-023-10189-6.pdf",
        "ref_texts": ""
      },
      "ICAFusion: Iterative cross-attention guided feature fusion for multispectral object detection": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2308.07504",
        "ref_texts": "[38] S. Liu, L. Qi, H. Qin, J. Shi, J. Jia, Path aggregation network for instance segmentation, in: Proceedings of the IEEE conference on computer vision and pattern recognition, 2018, pp. 8759\u20138768.",
        "ref_ids": [
          "38"
        ]
      },
      "Aims: All-inclusive multi-level segmentation for anything": {
        "authors": [],
        "url": "https://proceedings.neurips.cc/paper_files/paper/2023/file/3da292ced54290c19fc55d9dba3da793-Paper-Conference.pdf",
        "ref_texts": "[15] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In CVPR , 2018. 3",
        "ref_ids": [
          "15"
        ]
      },
      "VM-UNET-V2: rethinking vision mamba UNet for medical image segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2403.09157",
        "ref_texts": "12. Liu, S., Qi, L., Qin, H., Shi, J., Jia, J.: Path aggregatio n network for instance segmentation. In: Proceedings of the IEEE conference on com puter vision and pattern recognition. pp. 8759\u20138768 (2018)",
        "ref_ids": [
          "12"
        ]
      },
      "Yolov10: Real-time end-to-end object detection": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2405.14458",
        "ref_texts": "[37] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 8759\u20138768, 2018.",
        "ref_ids": [
          "37"
        ]
      },
      "Bgf-yolo: Enhanced yolov8 with multiscale attentional feature fusion for brain tumor detection": {
        "authors": [
          "Ming Kang"
        ],
        "url": "https://arxiv.org/pdf/2309.12585",
        "ref_texts": "16. Liu, S., Qi, L., Qin, H., Shi, J., Jia, J.: Path aggregation network for instance segmentation. In: 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pp. 8759 \u20138768. IEEE, Piscataway (2018) ",
        "ref_ids": [
          "16"
        ]
      },
      "Unigs: Unified representation for image generation and segmentation": {
        "authors": [
          "Lu Qi",
          "Lehan Yang",
          "Weidong Guo",
          "Yu Xu",
          "Bo Du",
          "Varun Jampani",
          "Hsuan Yang"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Qi_UniGS_Unified_Representation_for_Image_Generation_and_Segmentation_CVPR_2024_paper.pdf",
        "ref_texts": "[32] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In CVPR , 2018. 1, 2",
        "ref_ids": [
          "32"
        ]
      },
      "Efficient multi-scale network with learnable discrete wavelet transform for blind motion deblurring": {
        "authors": [
          "Xin Gao",
          "Tianheng Qiu",
          "Xinyu Zhang",
          "Hanlin Bai",
          "Kang Liu",
          "Xuan Huang",
          "Hu Wei",
          "Guoying Zhang",
          "Huaping Liu"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Gao_Efficient_Multi-scale_Network_with_Learnable_Discrete_Wavelet_Transform_for_Blind_CVPR_2024_paper.pdf",
        "ref_texts": "[17] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 8759\u20138768, 2018. 1",
        "ref_ids": [
          "17"
        ]
      },
      "Learning to aggregate multi-scale context for instance segmentation in remote sensing images": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2111.11057",
        "ref_texts": "[28] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia, \u201cPath aggregation network for instance segmentation,\u201d in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) , 2018, pp. 8759\u2013",
        "ref_ids": [
          "28"
        ]
      },
      "Unihead: unifying multi-perception for detection heads": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2309.13242",
        "ref_texts": "[7] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia, \u201cPath aggregation network for instance segmentation,\u201d in Proc. CVPR , 2018, pp. 8759\u20138768.",
        "ref_ids": [
          "7"
        ]
      },
      "Surface defect detection of hot rolled steel based on multi-scale feature fusion and attention mechanism residual block": {
        "authors": [
          "Hongkai Zhang"
        ],
        "url": "https://www.nature.com/articles/s41598-024-57990-3.pdf",
        "ref_texts": ""
      },
      "A deep learning model for steel surface defect detection": {
        "authors": [
          "Zhaoguo Li"
        ],
        "url": "https://link.springer.com/content/pdf/10.1007/s40747-023-01180-7.pdf",
        "ref_texts": "22. Liu S, Qi L, Qin H, Shi J, Jia J (2018) Path aggregation network for instance segmentation. In: IEEE Conference on computer visionand pattern recognition. pp 8759\u20138768",
        "ref_ids": [
          "22"
        ]
      },
      "Toward the unification of generative and discriminative visual foundation model: a survey": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2312.10163",
        "ref_texts": "[156] Hafiz, A.M., Bhat, G.M.: A survey on instance segmentation: state of the art. International Journal of Multimedia Information Retrieval 9(3), 171\u2013189 (2020) https://doi.org/10.1007/s13735-020-00195-x [157] Liu, S., Qi, L., Qin, H., Shi, J., Jia, J.: Path Aggregation Network for Instance Segmentation (2018)",
        "ref_ids": [
          "156",
          "157"
        ]
      },
      "Real-time pavement damage detection with damage shape adaptation": {
        "authors": [],
        "url": "https://yingchaoao.github.io/files/TITS2024.pdf",
        "ref_texts": "[37] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia, \u201cPath aggregation network for instance segmentation,\u201d in Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit., Jun. 2018, pp. 8759\u20138768.",
        "ref_ids": [
          "37"
        ]
      },
      "YOLOv1 to YOLOv10: The fastest and most accurate real-time object detection systems": {
        "authors": [],
        "url": "https://www.nowpublishers.com/article/OpenAccessDownload/SIP-20240058",
        "ref_texts": "[66]S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia, \u201cPath aggregation network for instance segmentation\u201d, in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) , 2018, 8759\u201368.",
        "ref_ids": [
          "66"
        ]
      },
      "Yolov5, yolov8 and yolov10: The go-to detectors for real-time vision": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2407.02988",
        "ref_texts": "[16] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. InProceedings of the IEEE conference on computer vision and pa ttern recognition , pages 8759\u20138768, 2018.",
        "ref_ids": [
          "16"
        ]
      },
      "Lightweight and efficient tiny-object detection based on improved YOLOv8n for UAV aerial images": {
        "authors": [
          "Min Yue",
          "Liqiang Zhang",
          "Juan Huang",
          "Haifeng Zhang"
        ],
        "url": "https://www.mdpi.com/2504-446X/8/7/276/pdf",
        "ref_texts": "23. Liu, S.; Qi, L.; Qin, H.; Shi, J.; Jia, J. Path Aggregation Network for Instance Segmentation. arXiv 2018 , arXiv:1803.01534. [CrossRef]",
        "ref_ids": [
          "23"
        ]
      },
      "Reference twice: A simple and unified baseline for few-shot instance segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2301.01156",
        "ref_texts": "[8] Z. Fan, J.-G. Yu, Z. Liang, J. Ou, C. Gao, G.-S. Xia, and Y. Li, \u201cFgn: Fully guided network for few-shot instance segmentation,\u201d in 16 TABLE 22: gFSOD and gFSIS results using the scaled-up backbone on COCO with K = {1, 5, 10}. \u201c-\": unavailable corresponding result. Object Detection nAP bAPBackbone Methods 1 5 10 1 5 10 LVC [10] 18.6 29.2Swin-TRefT (Ours) 5.3 16.8 20.0 39.6 37.0 37.9 LVC [10] 19.0 28.7Swin-SRefT (Ours) 5.2 21.0 24.2 40.4 39.8 40.5 Swin-B RefT (Ours) 7.4 20.2 26.4 42.6 40.9 41.0 Instance Segmentation nAP bAPBackbone Methods 1 5 10 1 5 10 Swin-T RefT (Ours) 5.2 15.4 18.5 37.1 35.0 36.2 Swin-S RefT (Ours) 5.0 19.4 22.7 38.3 37.9 38.3 Swin-B RefT (Ours) 7.1 20.7 24.8 40.2 38.7 39.2 CVPR , 2020. 1, 2, 3",
        "ref_ids": [
          "8",
          "10",
          "10"
        ]
      },
      "An enhanced real-time human pose estimation method based on modified YOLOv8 framework": {
        "authors": [
          "Chengang Dong"
        ],
        "url": "https://www.nature.com/articles/s41598-024-58146-z.pdf",
        "ref_texts": ""
      },
      "YOLOv8-CB: Dense Pedestrian Detection Algorithm Based on In-Vehicle Camera": {
        "authors": [
          "Qiuli Liu",
          "Haixiong Ye",
          "Shiming Wang",
          "Zhe Xu"
        ],
        "url": "https://www.mdpi.com/2079-9292/13/1/236/pdf",
        "ref_texts": "30. Liu, S.; Qi, L.; Qin, H.; Shi, J.; Jia, J. Path aggregation network for instance segmentation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Salt Lake City, UT, USA, 18\u201323 June 2018; pp. 8759\u20138768.",
        "ref_ids": [
          "30"
        ]
      },
      "Flexible thermal camera solution for Smart city people detection and counting": {
        "authors": [
          "Enrico Collini"
        ],
        "url": "https://link.springer.com/content/pdf/10.1007/s11042-023-16374-x.pdf",
        "ref_texts": ""
      },
      "Salience DETR: Enhancing Detection Transformer with Hierarchical Salience Filtering Refinement": {
        "authors": [
          "Xiuquan Hou",
          "Meiqin Liu",
          "Senlin Zhang",
          "Ping Wei",
          "Badong Chen"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Hou_Salience_DETR_Enhancing_Detection_Transformer_with_Hierarchical_Salience_Filtering_Refinement_CVPR_2024_paper.pdf",
        "ref_texts": "[18] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 8759\u20138768, 2018. 4",
        "ref_ids": [
          "18"
        ]
      },
      "Sardet-100k: Towards open-source benchmark and toolkit for large-scale sar object detection": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2403.06534",
        "ref_texts": "[40] Liu, S., Qi, L., Qin, H., Shi, J., Jia, J.: Path aggregation network for instance segmentation. In: CVPR (2018)",
        "ref_ids": [
          "40"
        ]
      },
      "Accurate leukocyte detection based on deformable-DETR and multi-level feature fusion for aiding diagnosis of blood diseases": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2401.00926",
        "ref_texts": "[3] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia, \u201cPath aggregation network for instance segmentation,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition , 2018, pp. 8759\u20138768.",
        "ref_ids": [
          "3"
        ]
      },
      "Detection based on semantics and a detail infusion feature pyramid network and a coordinate adaptive spatial feature fusion mechanism remote sensing small object \u2026": {
        "authors": [
          "Shilong Zhou",
          "Haijin Zhou"
        ],
        "url": "https://www.mdpi.com/2072-4292/16/13/2416/pdf",
        "ref_texts": "36. Liu, S.; Qi, L.; Qin, H.; Shi, J.; Jia, J. Path aggregation network for instance segmentation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Salt Lake City, UT, USA, 18\u201323 June 2018; pp. 8759\u20138768. Remote Sens. 2024 ,16, 2416 23 of 23",
        "ref_ids": [
          "36"
        ]
      },
      "MPE-YOLO: enhanced small target detection in aerial imaging": {
        "authors": [
          "Jia Su"
        ],
        "url": "https://www.nature.com/articles/s41598-024-68934-2.pdf",
        "ref_texts": ""
      },
      "Lightweight oriented detector for insulators in drone aerial images": {
        "authors": [
          "Fengrui Qu",
          "Yu Lin",
          "Lianfang Tian",
          "Qiliang Du",
          "Huangyuan Wu",
          "Wenzhi Liao"
        ],
        "url": "https://www.mdpi.com/2504-446X/8/7/294/pdf",
        "ref_texts": "28. Liu, S.; Qi, L.; Qin, H.; Shi, J.; Jia, J. Path Aggregation Network for Instance Segmentation. In Proceedings of the 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), Salt Lake City, UT, USA, 18\u201323 June 2018; pp. 8759\u20138768.",
        "ref_ids": [
          "28"
        ]
      },
      "Extreme Point Supervised Instance Segmentation": {
        "authors": [
          "Hyeonjun Lee",
          "Sehyun Hwang",
          "Suha Kwak"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Lee_Extreme_Point_Supervised_Instance_Segmentation_CVPR_2024_paper.pdf",
        "ref_texts": "[41] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2018. 2",
        "ref_ids": [
          "41"
        ]
      },
      "YOLO-TLA: An Efficient and Lightweight Small Object Detection Model based on YOLOv5": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2402.14309",
        "ref_texts": "[31] S. Liu, L. Qi, H. Qin, J. Shi, J. Jia, Path aggregation network for instance segmentation, in: 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2018, pp. 8759\u20138768.",
        "ref_ids": [
          "31"
        ]
      },
      "SEB-YOLO: An Improved YOLOv5 Model for Remote Sensing Small Target Detection": {
        "authors": [
          "Yan Hui",
          "Shijie You",
          "Xiuhua Hu",
          "Panpan Yang",
          "Jing Zhao"
        ],
        "url": "https://www.mdpi.com/1424-8220/24/7/2193/pdf",
        "ref_texts": "30. Liu, S.; Qi, L.; Qin, H.; Shi, J.; Jia, J. Path Aggregation Network for Instance Segmentation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Salt Lake City, UT, USA, 18\u201323 June 2018; pp. 8759\u20138768.",
        "ref_ids": [
          "30"
        ]
      },
      "Efficient forest fire detection based on an improved YOLO model": {
        "authors": [
          "Lei Cao"
        ],
        "url": "https://link.springer.com/content/pdf/10.1007/s44267-024-00053-y.pdf",
        "ref_texts": "21. Liu,S.,Qi,L.,Qin,H.,Shi,J.,&Jia,J.(2018).Pathaggregationnetworkfor instancesegmentation.In ProceedingsoftheIEEEconferenceoncomputer visionandpatternrecognition (pp.8759\u20138768).Piscataway:IEEE.",
        "ref_ids": [
          "21"
        ]
      },
      "DPNet: Dual-path network for real-time object detection with lightweight attention": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2209.13933",
        "ref_texts": "[51] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia, \u201cPath aggregation network for instance segmentation,\u201d in CVPR , 2018, pp. 8759\u20138768.",
        "ref_ids": [
          "51"
        ]
      },
      "Remote Sensing Micro-Object Detection under Global and Local Attention Mechanism": {
        "authors": [
          "Yuanyuan Li",
          "Zhengguo Zhou",
          "Guanqiu Qi",
          "Gang Hu",
          "Zhiqin Zhu",
          "Xin Huang"
        ],
        "url": "https://www.mdpi.com/2072-4292/16/4/644/pdf",
        "ref_texts": "29. Liu, S.; Qi, L.; Qin, H.; Shi, J.; Jia, J. Path aggregation network for instance segmentation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Salt Lake City, UT, USA, 18\u201322 June 2018; pp. 8759\u20138768.",
        "ref_ids": [
          "29"
        ]
      },
      "HRYNet: a highly robust YOLO network for complex road traffic object detection": {
        "authors": [
          "Lindong Tang",
          "Lijun Yun",
          "Zaiqing Chen",
          "Feiyan Cheng"
        ],
        "url": "https://www.mdpi.com/1424-8220/24/2/642/pdf",
        "ref_texts": "33. Liu, S.; Qi, L.; Qin, H.; Shi, J.; Jia, J. Path aggregation network for instance segmentation. In Proceedings of the 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition, Salt Lake City, UT, USA, 18\u201323 June 2018; pp. 8759\u20138768.",
        "ref_ids": [
          "33"
        ]
      },
      "Lr-fpn: Enhancing remote sensing object detection with location refined feature pyramid network": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2404.01614",
        "ref_texts": "[6] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia, \u201cPath aggregation network for instance segmentation,\u201d in 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition , 2018, pp.",
        "ref_ids": [
          "6"
        ]
      },
      "Enhancing traffic object detection in variable illumination with rgb-event fusion": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2311.00436",
        "ref_texts": "[76] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia, \u201cPath aggregation network for instance segmentation,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition , 2018, pp. 8759\u20138768.",
        "ref_ids": [
          "76"
        ]
      },
      "A Lightweight Forest Pest Image Recognition Model Based on Improved YOLOv8": {
        "authors": [
          "Tingyao Jiang",
          "Shuo Chen"
        ],
        "url": "https://www.mdpi.com/2076-3417/14/5/1941/pdf",
        "ref_texts": "23. Liu, S.; Qi, L.; Qin, H.; Shi, J.; Jia, J. Path Aggregation Network for Instance Segmentation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Salt Lake City, UT, USA, 18\u201323 June 2018; pp. 8759\u20138768.",
        "ref_ids": [
          "23"
        ]
      },
      "Well googled is half done: Multimodal forecasting of new fashion product sales with image\u2010based google trends": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2109.09824",
        "ref_texts": "-Y Lara-Ben \u00b4\u0131tez, P., Carranza-Garc \u00b4\u0131a, M., & Riquelme, J. C. (2021). An experimental review on deep learning architectures for time series forecasting. CoRR , abs/2103.12057 . Retrieved from https://arxiv.org/abs/2103.12057 Liu, S., Qi, L., Qin, H., Shi, J., & Jia, J. (2018, June). Path aggregation network for instance segmentation. In Proceedings of the ieee conference on computer vision and pattern recognition (cvpr). Ma, Y ., Ding, Y ., Yang, X., Liao, L., Wong, W. K., & Chua, T.-S. (2020, June). Knowledge Enhanced Neural Fashion Trend Forecasting. In Proceedings of the 2020 International Conference on Multimedia Retrieval (pp. 82\u201390). Dublin Ireland: ACM. Retrieved 2020-10-25, from https://dl.acm.org/doi/10.1145/"
      },
      "Object Detection in Remote Sensing Images Based on Adaptive Multi-Scale Feature Fusion Method": {
        "authors": [
          "Chun Liu",
          "Sixuan Zhang",
          "Mengjie Hu",
          "Qing Song"
        ],
        "url": "https://www.mdpi.com/2072-4292/16/5/907/pdf",
        "ref_texts": "25. Liu, S.; Qi, L.; Qin, H.; Shi, J.; Jia, J. Path aggregation network for instance segmentation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Salt Lake City, UT, USA, 18\u201322 June 2018; pp. 8759\u20138768.",
        "ref_ids": [
          "25"
        ]
      },
      "Skin Cancer Recognition Using Unified Deep Convolutional Neural Networks": {
        "authors": [
          "Nasser A. Al",
          "Shatha Ali",
          "Mohamed Maher",
          "Ben Ismail",
          "Ouiem Bchir"
        ],
        "url": "https://www.mdpi.com/2072-6694/16/7/1246/pdf",
        "ref_texts": "45. Liu, S.; Qi, L.; Qin, H.; Shi, J.; Jia, J. Path Aggregation Network for Instance Segmentation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, Salt Lake City, UT, USA, 18\u201323 June 2018; pp. 8759\u20138768.",
        "ref_ids": [
          "45"
        ]
      },
      "Lumos: Empowering Multimodal LLMs with Scene Text Recognition": {
        "authors": [
          "Ashish Shenoy"
        ],
        "url": "https://dl.acm.org/doi/pdf/10.1145/3637528.3671633",
        "ref_texts": "[21] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. 2018. Path Aggregation Network for Instance Segmentation. arXiv:1803.01534 [cs.CV]",
        "ref_ids": [
          "21",
          "cs\\.CV"
        ]
      },
      "Segment Any Event Streams via Weighted Adaptation of Pivotal Tokens": {
        "authors": [
          "Zhiwen Chen",
          "Zhiyu Zhu",
          "Yifan Zhang",
          "Junhui Hou",
          "Guangming Shi",
          "Jinjian Wu"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Chen_Segment_Any_Event_Streams_via_Weighted_Adaptation_of_Pivotal_Tokens_CVPR_2024_paper.pdf",
        "ref_texts": ""
      },
      "Siamese-DETR for generic multi-object tracking": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2310.17875",
        "ref_texts": "[58] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia, \u201cPath aggregation network for instance segmentation,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition , 2018, pp. 8759\u20138768.",
        "ref_ids": [
          "58"
        ]
      },
      "High-precision and lightweight small-target detection algorithm for low-cost edge intelligence": {
        "authors": [],
        "url": "https://www.nature.com/articles/s41598-024-75243-1.pdf",
        "ref_texts": ""
      },
      "Lightweight pedestrian detection network for UAV remote sensing images based on strideless pooling": {
        "authors": [
          "Sanzai Liu",
          "Lihua Cao",
          "Yi Li"
        ],
        "url": "https://www.mdpi.com/2072-4292/16/13/2331/pdf",
        "ref_texts": "51. Liu, S.; Qi, L.; Qin, H.; Shi, J.; Jia, J. Path Aggregation Network for Instance Segmentation. arXiv 2018 , arXiv:1803.01534.",
        "ref_ids": [
          "51"
        ]
      },
      "A Convolution with Transformer Attention Module Integrating Local and Global Features for Object Detection in Remote Sensing Based on YOLOv8n": {
        "authors": [
          "Kaiqi Lang",
          "Jie Cui",
          "Mingyu Yang",
          "Hanyu Wang",
          "Zilong Wang",
          "Honghai Shen"
        ],
        "url": "https://www.mdpi.com/2072-4292/16/5/906/pdf",
        "ref_texts": "58. Liu, S.; Qi, L.; Qin, H.; Shi, J.; Jia, J. Path Aggregation Network For Instance Segmentation. In Proceedings of the IEEE Conference On Computer Vision And Pattern Recognition, Salt Lake City, UT, USA, 18\u201322 June 2018; pp. 8759\u20138768.",
        "ref_ids": [
          "58"
        ]
      },
      "You only look at once for real-time and generic multi-task": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2310.01641",
        "ref_texts": "[28] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia, \u201cPath aggregation network for instance segmentation,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition , 2018, pp. 8759\u20138768.",
        "ref_ids": [
          "28"
        ]
      },
      "Fast vehicle detection algorithm based on lightweight YOLO7-tiny": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2304.06002",
        "ref_texts": "[23] Liu S, Qi L, Qin H, et al. Path aggregation network for instance segmentation[C]//Proceedings of the IEEE conference on computer vision and pattern recognition. 2018: 8759 -8768. ",
        "ref_ids": [
          "23",
          "C"
        ]
      },
      "Real-time sign language recognition based on YOLO algorithm": {
        "authors": [
          "Melek Alaftekin"
        ],
        "url": "https://link.springer.com/content/pdf/10.1007/s00521-024-09503-6.pdf",
        "ref_texts": "37. Dosovitskiy A, Beyer L, Kolesnikov A, Weissenborn D, Zhai X, Unterthiner T, Dehghani M, Minderer M (2021) An image isworth 16x16 words: Transformers for image recognition at scale In: 9. International conference on learning representations38. Liu S, Qi L, Qin H, Shi J, Jia J (2018) Path aggregation network for instance segmentation. In: Proceedings of the IEEE conference on computer vision and pattern recognition 39. Elfwing S, Uchibe E, Doya K (2018) Sigmoid-weighted linear units for neural network function approximation in reinforcement learning. Neural Netw 107:3\u201311",
        "ref_ids": [
          "37"
        ]
      },
      "Green pepper fruits counting based on improved DeepSort and optimized Yolov5s": {
        "authors": [
          "Pengcheng Du"
        ],
        "url": "https://www.frontiersin.org/journals/plant-science/articles/10.3389/fpls.2024.1417682/pdf",
        "ref_texts": "(3), 1861-8219. doi: 10.1007/s11554-024-01436-6 Li, X., Pan, J., Xie, F., Zeng, J., Li, Q., Huang, X., et al. (2021). Fast and accurate green pepper detection in complex backgrounds via an improved Yolov4-tiny model.Comput. Electron. Agric. 191, 106503. doi: 10.1016/j.compag.2021.106503 Li, X., Zhao, Z., Wu, J., Huang, Y., Wen, J., Sun, S., et al. (2022). Y-BGD: Broiler counting based on multi-object tracking. Comput. Electron. Agric. 202, 107347. doi:10.1016/j.compag.2022.107347 Lin, T. Y., Dolla \u0301r, P., Girshick, R., He, K., Hariharan, B., and Belongie, S. (2017). Feature Pyramid Networks for Object Detection (arXiv). Available at: http://arxiv.org/ abs/1612.03144 . [2024 \u201305-10]. doi: 10.48550/arXiv.1612.03144Du et al. 10.3389/fpls.2024.1417682 Frontiers in Plant Science frontiersin.org 17 Liu, X., Chen, S. W., Liu, C., Shivakumar, S. S., Das, J., Taylor, C. J., et al. (2019). Monocular camera based fruit counting and mapping with semantic data association.IEEE Robotics Automation Lett. 4, 2296 \u20132303. doi: 10.1109/LSP.2016. Liu, S., Qi, L., Qin, H., Shi, J., and Jia, J. (2018). Path Aggregation Network for Instance Segmentation (arXiv). Available at: http://arxiv.org/abs/1803.01534 .[2 0 2 4 \u201305-10]. doi:10.48550/arXiv.1803.01534 Lu, E., and Hu, X. (2022). Image super-resolution via channel attention and spatial attention. Appl. Intell. 52, 2260 \u20132268. doi: 10.1007/s10489-021-02464-6 Luo, W., Xing, J., Milan, A., Zhang, X., Liu, W., and Kim, T.-K. (2014). Multiple object tracking: a literature review. Artificial Intelligence 293, 103448. doi: 10.1016/j.artint.2020.103448 Malik, Z., Ziauddin, S., Shahid, A., and Sa fi, A. (2016). Detection and counting of ontree citrus fruit for crop yield estimation. Int. J. Advanced Comput. Sci. Appl. 7 (5), 2016. doi:10.14569/IJACSA.2016.070569 Mccool, C., Sa, I., Dayoub, F., Lehnert, C., Perez, T., and Upcroft, B. (2016). \u201cVisual detection of occluded crop: For automated harvesting/, \u201din2016 IEEE International Conference on Robotics and Automation (ICRA) . 2506 \u20132512. Available at: https:// ieeexplore.ieee.org/document/7487405 . doi: 10.1109/ICRA.2016.7487405 Payne, A. B., Walsh, K. B., Subedi, P. P., and Jarvis, D. (2013). Estimation of mango crop yield using image analysis \u2013Segmentation method. Comput. Electron. Agric. 91, 57\u201364. doi: 10.1016/j.compag.2012.11.009 R e d m o n ,J . ,a n dF a r h a d i ,A .(2 0 1 8 ) . YOLOv3: An Incremental Improvement (arXiv). Available at: http://arxiv.org/abs/1804.02767 . [2024 \u201305-10]. doi: 10.48550/arXiv.1804.02767 Ren, D., and Yang, S. X. (2016). Intelligent automation with applications to agriculture. Intelligent Automation Soft Computing 22, 227 \u2013228. doi: 10.1080/"
      },
      "Football referee gesture recognition algorithm based on YOLOv8s": {
        "authors": [],
        "url": "https://www.frontiersin.org/articles/10.3389/fncom.2024.1341234/pdf",
        "ref_texts": "10.1155/2021/9562782 Lin, T., Doll\u00e1r, P ., Girshick, R., He, K., Hariharan, B., and Belongie, S. (2017), \"Feature pyramid networks for object detection\", in Proceedings of the IEEE conference on computer vision and pattern recognition , pp.\u00a02117\u20132125. Liu, S., Qi, L., Qin, H., Shi, J., and Jia, J. (2018), \"Path aggregation network for instance segmentation\", in Proceedings of the IEEE conference on computer vision and pattern recognition , pp.\u00a08759\u20138768. Liu, Y ., Shao, Z., and Hoffmann, N. (2021), \"Global attention mechanism: Retain information to enhance channel-spatial interactions\", arXiv [Preprint]. arXiv:2112.05561. Mesbahi, S. C., Mahraz, M. A., Riffi, J., and Tairi, H. (2023). Hand gesture recognition based on various deep learning YOLO models. Int. J. Adv. Comput. Sci. Appl. 14:435. doi: "
      },
      "A PV cell defect detector combined with transformer and attention mechanism": {
        "authors": [
          "Du Lang"
        ],
        "url": "https://www.nature.com/articles/s41598-024-72019-5.pdf",
        "ref_texts": ""
      },
      "Early gastric cancer detection and lesion segmentation based on deep learning and gastroscopic images": {
        "authors": [
          "Kezhi Zhang"
        ],
        "url": "https://www.nature.com/articles/s41598-024-58361-8.pdf",
        "ref_texts": ""
      },
      "Enhanced YOLO Network for Improving the Efficiency of Traffic Sign Detection": {
        "authors": [
          "Yang Cui",
          "Dong Guo",
          "Hao Yuan",
          "Hengzhi Gu",
          "Hongbo Tang"
        ],
        "url": "https://www.mdpi.com/2076-3417/14/2/555/pdf",
        "ref_texts": "30. Liu, S.; Qi, L.; Qin, H.; Shi, J.; Jia, J. Path aggregation network for instance segmentation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Salt Lake City, UT, USA, 18\u201323 June 2018; pp. 8759\u20138768.",
        "ref_ids": [
          "30"
        ]
      },
      "Kernel-mask knowledge distillation for efficient and accurate arbitrary-shaped text detection": {
        "authors": [
          "Honghui Chen"
        ],
        "url": "https://link.springer.com/content/pdf/10.1007/s40747-023-01134-z.pdf",
        "ref_texts": "8. Liu S, Qi L, Qin H, Shi J, Jia J (2018) Path aggregation network for instance segmentation. In: Proceedings of the IEEE conferenceon computer vision and pattern recognition, IEEE, Salt Lake City, pp 8759\u20138768",
        "ref_ids": [
          "8"
        ]
      },
      "An ensemble approach for robust automated crack detection and segmentation in concrete structures": {
        "authors": [
          "Muhammad Sohaib",
          "Saima Jamil",
          "Myon Kim"
        ],
        "url": "https://www.mdpi.com/1424-8220/24/1/257/pdf",
        "ref_texts": "23. Liu, S.; Qi, L.; Qin, H.; Shi, J.; Jia, J. Path Aggregation Network for Instance Segmentation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Salt Lake City, UT, USA, 18\u201323 June 2018; pp. 8759\u20138768.",
        "ref_ids": [
          "23"
        ]
      },
      "Tfdet: Target-aware fusion for rgb-t pedestrian detection": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2305.16580",
        "ref_texts": "[43] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia, \u201cPath Aggregation Network for Instance Segmentation,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2018. III-C",
        "ref_ids": [
          "43"
        ]
      },
      "Hyper-yolo: When visual object detection meets hypergraph computation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2408.04804",
        "ref_texts": "[16] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia, \u201cPath aggregation network for instance segmentation,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , 2018, pp. 8759\u20138768.",
        "ref_ids": [
          "16"
        ]
      },
      "SAM-CFFNet: SAM-based cross-feature fusion network for intelligent identification of landslides": {
        "authors": [
          "Laidian Xi",
          "Junchuan Yu",
          "Daqing Ge",
          "Yunxuan Pang",
          "Ping Zhou",
          "Changhong Hou",
          "Yichuan Li",
          "Yangyang Chen",
          "Yuanbiao Dong"
        ],
        "url": "https://www.mdpi.com/2072-4292/16/13/2334/pdf",
        "ref_texts": "23. Liu, S.; Qi, L.; Qin, H.; Shi, J.; Jia, J. Path aggregation network for instance segmentation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Salt Lake City, UT, USA, 18\u201323 June 2018; pp. 8759\u20138768.",
        "ref_ids": [
          "23"
        ]
      },
      "GM-DETR: Generalized Muiltispectral DEtection TRansformer with Efficient Fusion Encoder for Visible-Infrared Detection": {
        "authors": [
          "Yiming Xiao",
          "Fanman Meng",
          "Qingbo Wu",
          "Linfeng Xu",
          "Mingzhou He",
          "Hongliang Li"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024W/JRDB/papers/Xiao_GM-DETR_Generalized_Muiltispectral_DEtection_TRansformer_with_Efficient_Fusion_Encoder_for_CVPRW_2024_paper.pdf",
        "ref_texts": "[16] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 8759\u20138768, 2018. 4",
        "ref_ids": [
          "16"
        ]
      },
      "Deep learning-based computer vision methods for complex traffic environments perception: A review": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2211.05120",
        "ref_texts": "[134] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia, \u201cPath aggregation network for instance segmentation,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition , 2018, pp. 8759\u20138768.",
        "ref_ids": [
          "134"
        ]
      },
      "An Efficient and Lightweight Detection Model for Forest Smoke Recognition": {
        "authors": [
          "Xiao Guo",
          "Yichao Cao",
          "Tongxin Hu"
        ],
        "url": "https://www.mdpi.com/1999-4907/15/1/210/pdf",
        "ref_texts": "22. Liu, S.; Qi, L.; Qin, H.; Shi, J.; Jia, J. Path aggregation network for instance segmentation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Salt Lake City, UT, USA, 18\u201322 June 2018; pp. 8759\u20138768.",
        "ref_ids": [
          "22"
        ]
      },
      "Small-Scale Foreign Object Debris Detection Using Deep Learning and Dual Light Modes": {
        "authors": [
          "Yiming Mo",
          "Lei Wang",
          "Wenqing Hong",
          "Congzhen Chu",
          "Peigen Li",
          "Haiting Xia"
        ],
        "url": "https://www.mdpi.com/2076-3417/14/5/2162/pdf",
        "ref_texts": "29. Liu, S.; Qi, L.; Qin, H.; Shi, J.; Jia, J. Path aggregation network for instance segmentation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Salt Lake City, UT, USA, 18\u201323 June 2018; pp. 8759\u20138768.",
        "ref_ids": [
          "29"
        ]
      },
      "Enhanced object detection: A study on vast vocabulary object detection track for v3det challenge 2024": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2406.09201",
        "ref_texts": "[24] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia. Path aggregation network for instance segmentation. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 8759\u20138768, 2018.",
        "ref_ids": [
          "24"
        ]
      },
      "YOLO-DD: Improved YOLOv5 for defect detection": {
        "authors": [],
        "url": "https://cdn.techscience.cn/files/cmc/2024/TSP_CMC-78-1/TSP_CMC_41600/TSP_CMC_41600.pdf",
        "ref_texts": "[44] S. Liu, L. Qi, H. Qin, J. Shi and J. Jia, \u201cPath aggregation network for instance segmentation,\u201d in Proc. of the IEEE Conf. on Computer Vision and Pattern Recognition , Salt Lake City, UT, USA, pp. 8759\u20138768, 2018.",
        "ref_ids": [
          "44"
        ]
      },
      "Research on surface defect detection algorithm of pipeline weld based on YOLOv7": {
        "authors": [
          "Xiangqian Xu"
        ],
        "url": "https://www.nature.com/articles/s41598-024-52451-3.pdf",
        "ref_texts": ""
      },
      "RTMW: Real-Time Multi-Person 2D and 3D Whole-body Pose Estimation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2407.08634?",
        "ref_texts": "[19] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2018. 3",
        "ref_ids": [
          "19"
        ]
      },
      "PNeRV: Enhancing Spatial Consistency via Pyramidal Neural Representation for Videos": {
        "authors": [
          "Qi Zhao",
          "Salman Asif",
          "Zhan Ma"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Zhao_PNeRV_Enhancing_Spatial_Consistency_via_Pyramidal_Neural_Representation_for_Videos_CVPR_2024_paper.pdf",
        "ref_texts": "[28] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation.",
        "ref_ids": [
          "28"
        ]
      },
      "Cross-Modality Proposal-guided Feature Mining for Unregistered RGB-Thermal Pedestrian Detection": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2308.12111",
        "ref_texts": "[44] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia, \u201cPath aggregation network for instance segmentation,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition , 2018, pp. 8759\u20138768.",
        "ref_ids": [
          "44"
        ]
      },
      "Improved YOLOv7 Algorithm for Small Object Detection in Unmanned Aerial Vehicle Image Scenarios": {
        "authors": [
          "Xinmin Li",
          "Yingkun Wei",
          "Jiahui Li",
          "Wenwen Duan",
          "Xiaoqiang Zhang",
          "Yi Huang"
        ],
        "url": "https://www.mdpi.com/2076-3417/14/4/1664/pdf",
        "ref_texts": "35. Liu, S.; Qi, L.; Qin, H.F.; Shi, J.P .; Jia, J.Y. Path aggregation network for instance segmentation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), Salt Lake City, UT, USA, 18\u201322 June 2018.",
        "ref_ids": [
          "35"
        ]
      },
      "S3AD: Semi-Supervised Small Apple Detection in Orchard Environments": {
        "authors": [
          "Robert Johanson",
          "Christian Wilms",
          "Ole Johannsen",
          "Simone Frintrop"
        ],
        "url": "https://openaccess.thecvf.com/content/WACV2024/papers/Johanson_S3AD_Semi-Supervised_Small_Apple_Detection_in_Orchard_Environments_WACV_2024_paper.pdf",
        "ref_texts": "[19] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In Computer Vision and Pattern Recognition , 2018. 1, 2, 5, 6",
        "ref_ids": [
          "19"
        ]
      },
      "Transformer-based stereo-aware 3D object detection from binocular images": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2304.11906",
        "ref_texts": "[46] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia, \u201cPath aggregation network for instance segmentation,\u201d in IEEE Conference on Computer Vision and Pattern Recognition . Salt Lake City, UT, USA: IEEE, Jun. 2018, pp.",
        "ref_ids": [
          "46"
        ]
      },
      "Development and Validation of an Artificial Neural Network for the Recognition of Custom Dataset with YOLOv4": {
        "authors": [
          "Ritish Patnaik"
        ],
        "url": "https://arxiv.org/pdf/2405.02298",
        "ref_texts": "[21] Liu, S.; Qi, L.; Qin, H.; Shi, J.; Jia, J. (Eds.) (2018): Path aggregation network for instance segmentation. Proceedings of the IEEE conference on computer vision and pattern recognition. ",
        "ref_ids": [
          "21"
        ]
      },
      "MTP-YOLO: You only look once based maritime tiny person detector for emergency rescue": {
        "authors": [
          "Yonggang Shi",
          "Shaokun Li",
          "Ziyan Liu",
          "Zhiguo Zhou",
          "Xuehua Zhou"
        ],
        "url": "https://www.mdpi.com/2077-1312/12/4/669/pdf",
        "ref_texts": "9. Liu, S.; Qi, L.; Qin, H.; Shi, J.; Jia, J. Path Aggregation Network for Instance Segmentation. In Proceedings of the 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition, Salt Lake City, UT, USA, 18\u201323 June 2018.",
        "ref_ids": [
          "9"
        ]
      },
      "WiLoR: End-to-end 3D Hand Localization and Reconstruction in-the-wild": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2409.12259",
        "ref_texts": "[45] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 8759\u20138768, 2018. 4",
        "ref_ids": [
          "45"
        ]
      },
      "Segment anything with precise interaction": {
        "authors": [],
        "url": "https://openreview.net/pdf?id=lD9A7SS4BP"
      },
      "Overtaking mechanisms based on augmented intelligence for autonomous driving: Datasets, methods, and challenges": {
        "authors": [],
        "url": "https://napier-repository.worktribe.com/preview/3643801/Overtaking%20Mechanisms%20Based%20on%20Augmented%20Intelligence%20for%20Autonomous%20Driving%20Datasets_%20Methods_%20and%20Challenges_compressed.pdf",
        "ref_texts": "[172] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia, \u201cPath aggregation network for instance segmentation,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition , 2018, pp. 8759\u20138768.",
        "ref_ids": [
          "172"
        ]
      },
      "Automated Pavement Condition Index Assessment with Deep Learning and Image Analysis: An End-to-End Approach": {
        "authors": [
          "Eldor Ibragimov",
          "Yongsoo Kim",
          "Jung Hee",
          "Junsang Cho",
          "Jae Lee"
        ],
        "url": "https://www.mdpi.com/1424-8220/24/7/2333/pdf",
        "ref_texts": "33. Liu, S.; Qi, L.; Qin, H.; Shi, J.; Jia, J. Path Aggregation Network for Instance Segmentation. In Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition, Salt Lake City, UT, USA, 18\u201322 June 2018.",
        "ref_ids": [
          "33"
        ]
      },
      "FEB-YOLOv8: A multi-scale lightweight detection model for underwater object detection": {
        "authors": [
          "Yuyin Zhao",
          "Fengjie Sun",
          "Xuewen Wu"
        ],
        "url": "https://journals.plos.org/plosone/article/file?id=10.1371/journal.pone.0311173&type=printable",
        "ref_texts": "33. LiuS,QiL,QinH,ShiJ,JiaJ,editors. Path aggregation network forinstance segmentat ion.ProceedingsoftheIEEE conferenc eoncomputer vision andpattern recognition; 2018. https:// doi.org/10.48 550/ arXiv.1803. 01534",
        "ref_ids": [
          "33"
        ]
      },
      "Saliency Guided Siamese Attention Network for Infrared Ship Target Tracking": {
        "authors": [
          "Xiang Li"
        ],
        "url": "https://pure.solent.ac.uk/files/54015282/Saliency_Guided_Siamese_Attention_Network_for_Infrared_Ship_Target_Tracking_-_draft_.pdf"
      },
      "Bud-YOLOv8s: A Potato Bud-Eye-Detection Algorithm Based on Improved YOLOv8s": {
        "authors": [
          "Firstname Lastname",
          "Firstname Lastname",
          "Firstname Lastname"
        ],
        "url": "https://www.mdpi.com/2079-9292/13/13/2541/pdf",
        "ref_texts": "36. Liu, S.; Qi, L.; Qin, H.; Shi, J.; Jia, J. Path Aggregation Network for Instance Segmentation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Salt Lake City, UT, USA, 18\u201323 June 2018; pp. 8759\u20138768.",
        "ref_ids": [
          "36"
        ]
      },
      "Superpixel perception graph neural network for intelligent defect detection of aero-engine blade": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2210.07539",
        "ref_texts": "[60] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia, \"Path aggregation network for instance segmentation,\" Proceedings of the IEEE conference on computer vision and pattern recognition, 2018, pp. 87598768. ",
        "ref_ids": [
          "60"
        ]
      },
      "LSDNet: a lightweight ship detection network with improved YOLOv7": {
        "authors": [],
        "url": "https://www.researchsquare.com/article/rs-3572198/latest.pdf",
        "ref_texts": "24. S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia, \u2018\u2018Path aggregation network for instance segmentation,\u2019\u2019 in Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit., Jun. 2018, pp. 8759\u20138768.",
        "ref_ids": [
          "24"
        ]
      },
      "Extraction of Tobacco Planting Information Based on UAV High-Resolution Remote Sensing Images": {
        "authors": [
          "Lei He",
          "Kunwei Liao",
          "Yuxia Li",
          "Bin Li",
          "Jinglin Zhang",
          "Yong Wang",
          "Liming Lu",
          "Sichun Jian",
          "Rui Qin",
          "Xinjun Fu"
        ],
        "url": "https://www.mdpi.com/2072-4292/16/2/359/pdf",
        "ref_texts": "33. Liu, S.; Qi, L.; Qin, H.; Shi, J.; Jia, J. Path Aggregation Network for Instance Segmentation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Salt Lake City, UT, USA, 18\u201323 June 2018; pp. 8759\u20138768.",
        "ref_ids": [
          "33"
        ]
      },
      "Enhancing dense small object detection in UAV images based on hybrid transformer": {
        "authors": [],
        "url": "https://cdn.techscience.cn/files/cmc/2024/TSP_CMC-78-3/TSP_CMC_48351/TSP_CMC_48351.pdf",
        "ref_texts": "[37] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia, \u201cPath aggregation network for instance segmentation,\u201d in 2018 IEEE/CVF Conf. Comput. Vis. Pattern Recognit. , Salt Lake City, UT, USA, Jun. 2018, pp. 8759\u20138768.",
        "ref_ids": [
          "37"
        ]
      },
      "MCH-PAN: gastrointestinal polyp detection model integrating multi-scale feature information": {
        "authors": [],
        "url": "https://www.nature.com/articles/s41598-024-74609-9.pdf",
        "ref_texts": ""
      },
      "Lightweight vehicle detection based on improved YOLOv5s": {
        "authors": [
          "Yuhai Wang",
          "Shuobo Xu",
          "Peng Wang",
          "Kefeng Li",
          "Ze Song",
          "Quanfeng Zheng",
          "Yanshun Li",
          "Qiang He"
        ],
        "url": "https://www.mdpi.com/1424-8220/24/4/1182/pdf",
        "ref_texts": "31. Liu, S.; Qi, L.; Qin, H.; Shi, J.; Jia, J. Path Aggregation Network for Instance Segmentation. In Proceedings of the 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition, Salt Lake City, UT, USA, 18\u201323 June 2018.",
        "ref_ids": [
          "31"
        ]
      },
      "Cross-layer feature pyramid transformer for small object detection in aerial images": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2407.19696",
        "ref_texts": "[12] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia, \u201cPath aggregation network for instance segmentation,\u201d in Proc. IEEE Conf. Comp. Vis. Patt. Recogn. , 2018, pp. 8759\u20138768.",
        "ref_ids": [
          "12"
        ]
      },
      "High-resolution mapping of urban Aedes aegypti immature abundance through breeding site detection based on satellite and street view imagery": {
        "authors": [
          "Steffen Knoblauch"
        ],
        "url": "https://www.nature.com/articles/s41598-024-67914-w.pdf",
        "ref_texts": ""
      },
      "Mask-Pyramid Network: A Novel Panoptic Segmentation Method": {
        "authors": [
          "Fei Xian",
          "Man Po",
          "Jing Xiong",
          "Zhi Zhao",
          "Yin Yu",
          "Wai Cheung"
        ],
        "url": "https://www.mdpi.com/1424-8220/24/5/1411/pdf",
        "ref_texts": "27. Liu, S.; Qi, L.; Qin, H.; Shi, J.; Jia, J. Path aggregation network for instance segmentation. In Proceedings of the IEEE conference on Computer Vision and Pattern Recognition, Salt Lake City, UT, USA, 18\u201323 June 2018; pp. 8759\u20138768.",
        "ref_ids": [
          "27"
        ]
      },
      "YOLO-v1 to YOLO-v8, the rise of YOLO and its complementary nature toward digital manufacturing and industrial defect detection": {
        "authors": [
          "Muhammad Hussain"
        ],
        "url": "https://www.mdpi.com/2075-1702/11/7/677/pdf",
        "ref_texts": "56. Liu, S.; Qi, L.; Qin, H.; Shi, J.; Jia, J. Path aggregation network for instance segmentation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Salt Lake City, UT, USA, 18\u201323 June 2018; pp. 8759\u20138768.",
        "ref_ids": [
          "56"
        ]
      },
      "Universal instance perception as object discovery and retrieval": {
        "authors": [
          "Bin Yan",
          "Yi Jiang",
          "Jiannan Wu",
          "Dong Wang",
          "Ping Luo",
          "Zehuan Yuan",
          "Huchuan Lu"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2023/papers/Yan_Universal_Instance_Perception_As_Object_Discovery_and_Retrieval_CVPR_2023_paper.pdf",
        "ref_texts": "[64] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In CVPR , 2018. 1",
        "ref_ids": [
          "64"
        ]
      },
      "Convolutions die hard: Open-vocabulary segmentation with single frozen convolutional clip": {
        "authors": [],
        "url": "https://proceedings.neurips.cc/paper_files/paper/2023/file/661caac7729aa7d8c6b8ac0d39ccbc6a-Paper-Conference.pdf",
        "ref_texts": "[56] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In CVPR , 2018.",
        "ref_ids": [
          "56"
        ]
      },
      "DC-YOLOv8: small-size object detection algorithm based on camera sensor": {
        "authors": [
          "Haitong Lou",
          "Xuehu Duan",
          "Junmei Guo",
          "Haiying Liu",
          "Jason Gu",
          "Lingyun Bi",
          "Haonan Chen"
        ],
        "url": "https://www.mdpi.com/2079-9292/12/10/2323/pdf",
        "ref_texts": "30. Liu, S.; Qi, L.; Qin, H.; Shi, J.; Jia, J. Path Aggregation Network for Instance Segmentation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Salt Lake City, UT, USA, 18\u201323 June 2018; pp. 8759\u20138768.",
        "ref_ids": [
          "30"
        ]
      },
      "Gpt4roi: Instruction tuning large language model on region-of-interest": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2307.03601",
        "ref_texts": "10 Liunian Harold Li, Mark Yatskar, Da Yin, Cho-Jui Hsieh, and Kai-Wei Chang. 2019b. Visualbert: A simple and performant baseline for vision and language. Liunian Harold Li*, Pengchuan Zhang*, Haotian Zhang*, Jianwei Yang, Chunyuan Li, Yiwu Zhong, Lijuan Wang, Lu Yuan, Lei Zhang, Jenq-Neng Hwang, Kai-Wei Chang, and Jianfeng Gao. 2022. Grounded language-image pre-training. In CVPR . Yikang Li, Wanli Ouyang, Bolei Zhou, Kun Wang, and Xiaogang Wang. 2017. Scene graph generation from objects, phrases and region captions. Tsung-Yi Lin, Piotr Doll\u00e1r, Ross Girshick, Kaiming He, Bharath Hariharan, and Serge Belongie. 2017. Feature pyramid networks for object detection. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 2117\u20132125. Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva Ramanan, Piotr Doll\u00e1r, and C Lawrence Zitnick. 2014. Microsoft coco: Common objects in context. In Computer Vision\u2013 ECCV 2014: 13th European Conference, Zurich, Switzerland, September 6-12, 2014, Proceedings, Part V 13 , pages 740\u2013755. Springer. Haotian Liu, Chunyuan Li, Qingyang Wu, and Yong Jae Lee. 2023a. Visual instruction tuning. arXiv preprint arXiv:2304.08485 . Rosanne Liu, Joel Lehman, Piero Molino, Felipe Petroski Such, Eric Frank, Alex Sergeev, and Jason Yosinski. 2018a. An intriguing failing of convolutional neural networks and the coordconv solution. Shilong Liu, Zhaoyang Zeng, Tianhe Ren, Feng Li, Hao Zhang, Jie Yang, Chunyuan Li, Jianwei Yang, Hang Su, Jun Zhu, and Lei Zhang. 2023b. Grounding dino: Marrying dino with grounded pre-training for openset object detection. Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. 2018b. Path aggregation network for instance segmentation. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 8759\u20138768. Yuan Liu, Haodong Duan, Yuanhan Zhang, Bo Li, Songyang Zhang, Wangbo Zhao, Yike Yuan, Jiaqi Wang, Conghui He, Ziwei Liu, et al. 2023c. Mmbench: Is your multi-modal model an all-around player? arXiv preprint arXiv:2307.06281 . Zhaoyang Liu, Yinan He, Wenhai Wang, Weiyun Wang, Yi Wang, Shoufa Chen, Qinglong Zhang, Yang Yang, Qingyun Li, Jiashuo Yu, et al. 2023d. Internchat: Solving vision-centric tasks by interacting with chatbots beyond language. arXiv preprint arXiv:2305.05662 . Jiasen Lu, Dhruv Batra, Devi Parikh, and Stefan Lee."
      },
      "Yolov6 v3. 0: A full-scale reloading": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2301.05586.pdf?trk=public_post_comment-text",
        "ref_texts": "[10] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 8759\u20138768, 2018. 2",
        "ref_ids": [
          "10"
        ]
      },
      "A modified YOLOv8 detection network for UAV aerial image recognition": {
        "authors": [
          "Yiting Li",
          "Qingsong Fan",
          "Haisong Huang",
          "Zhenggong Han",
          "Qiang Gu"
        ],
        "url": "https://www.mdpi.com/2504-446X/7/5/304/pdf",
        "ref_texts": "30. Liu, S.; Qi, L.; Qin, H.; Shi, J.; Jia, J. Path Aggregation Network for Instance Segmentation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Salt Lake City, UT, USA, 18\u201323 June 2018; pp. 8759\u20138768.",
        "ref_ids": [
          "30"
        ]
      },
      "UAV-YOLOv8: A small-object-detection model based on improved YOLOv8 for UAV aerial photography scenarios": {
        "authors": [
          "Gang Wang",
          "Yanfei Chen",
          "Pei An",
          "Hanyu Hong",
          "Jinghu Hu",
          "Tiange Huang"
        ],
        "url": "https://www.mdpi.com/1424-8220/23/16/7190/pdf",
        "ref_texts": "33. Liu, S.; Qi, L.; Qin, H.; Shi, J.; Jia, J. Path Aggregation Network for Instance Segmentation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Salt Lake City, UT, USA, 18\u201323 June 2018; pp. 8759\u20138768.",
        "ref_ids": [
          "33"
        ]
      },
      "Improved YOLOv5 network for real-time multi-scale traffic sign detection": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2112.08782",
        "ref_texts": "38. Liu S, Qi L, Qin H, Shi J, Jia J. Path Aggregation Network for Instance Segmentation. 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition2018. p. 8759-68. ",
        "ref_ids": [
          "38"
        ]
      },
      "Think twice before driving: Towards scalable decoders for end-to-end autonomous driving": {
        "authors": [
          "Xiaosong Jia",
          "Penghao Wu",
          "Li Chen",
          "Jiangwei Xie",
          "Conghui He",
          "Junchi Yan",
          "Hongyang Li"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Jia_Think_Twice_Before_Driving_Towards_Scalable_Decoders_for_End-to-End_Autonomous_CVPR_2023_paper.pdf",
        "ref_texts": ""
      },
      "AGGN: Attention-based glioma grading network with multi-scale feature extraction and multi-modal information fusion": {
        "authors": [],
        "url": "https://bura.brunel.ac.uk/bitstream/2438/26038/1/FullText.pdf",
        "ref_texts": "[27] S. Liu, L. Qi, H. Qin, J. Shi and J. Jia, \u201cPath aggregation network for instance segmentation\u201d, Procedding of the 31th IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , pp. 8759-8768, 2018.",
        "ref_ids": [
          "27"
        ]
      },
      "PillarNeXt: Rethinking network designs for 3D object detection in LiDAR point clouds": {
        "authors": [
          "Jinyu Li",
          "Chenxu Luo",
          "Xiaodong Yang"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2023/papers/Li_PillarNeXt_Rethinking_Network_Designs_for_3D_Object_Detection_in_LiDAR_CVPR_2023_paper.pdf",
        "ref_texts": "[18] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 8759\u20138768, 2018. 2",
        "ref_ids": [
          "18"
        ]
      },
      "Driveadapter: Breaking the coupling barrier of perception and planning in end-to-end autonomous driving": {
        "authors": [
          "Xiaosong Jia",
          "Yulu Gao",
          "Li Chen",
          "Junchi Yan",
          "Patrick Langechuan",
          "Hongyang Li"
        ],
        "url": "http://openaccess.thecvf.com/content/ICCV2023/papers/Jia_DriveAdapter_Breaking_the_Coupling_Barrier_of_Perception_and_Planning_in_ICCV_2023_paper.pdf",
        "ref_texts": ""
      },
      "Normalization techniques in training dnns: Methodology, analysis and application": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2009.12836",
        "ref_texts": "[133] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia, \u201cPath aggregation network for instance segmentation,\u201d in CVPR , 2018.",
        "ref_ids": [
          "133"
        ]
      },
      "Lite detr: An interleaved multi-scale encoder for efficient detr": {
        "authors": [
          "Feng Li",
          "Ailing Zeng",
          "Shilong Liu",
          "Hao Zhang",
          "Hongyang Li",
          "Lei Zhang",
          "Lionel M. Ni"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Li_Lite_DETR_An_Interleaved_Multi-Scale_Encoder_for_Efficient_DETR_CVPR_2023_paper.pdf",
        "ref_texts": "[19] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 8759\u20138768, 2018. 2, 3",
        "ref_ids": [
          "19"
        ]
      },
      "Centralized feature pyramid for object detection": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2210.02093",
        "ref_texts": "[16] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia, \u201cPath aggregation network for instance segmentation,\u201d in IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2018.",
        "ref_ids": [
          "16"
        ]
      },
      "Polyformer: Referring image segmentation as sequential polygon generation": {
        "authors": [
          "Jiang Liu",
          "Hui Ding",
          "Zhaowei Cai",
          "Yuting Zhang",
          "Ravi Kumar",
          "Vijay Mahadevan"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Liu_PolyFormer_Referring_Image_Segmentation_As_Sequential_Polygon_Generation_CVPR_2023_paper.pdf",
        "ref_texts": "[52] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In CVPR , pages 8759\u20138768, 2018. 1",
        "ref_ids": [
          "52"
        ]
      },
      "Fracture detection in pediatric wrist trauma X-ray images using YOLOv8 algorithm": {
        "authors": [
          "Yang Ju"
        ],
        "url": "https://www.nature.com/articles/s41598-023-47460-7.pdf",
        "ref_texts": ""
      },
      "YOLO-tea: A tea disease detection model improved by YOLOv5": {
        "authors": [
          "Zhenyang Xue",
          "Renjie Xu",
          "Di Bai",
          "Haifeng Lin"
        ],
        "url": "https://www.mdpi.com/1999-4907/14/2/415/pdf",
        "ref_texts": "31. Liu, S.; Qi, L.; Qin, H.; Shi, J.; Jia, J. Path aggregation network for instance segmentation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Salt Lake City, UT, USA, 18\u201323 June 2018.",
        "ref_ids": [
          "31"
        ]
      },
      "Steerer: Resolving scale variations for counting and localization via selective inheritance learning": {
        "authors": [
          "Tao Han",
          "Lei Bai",
          "Lingbo Liu",
          "Wanli Ouyang"
        ],
        "url": "http://openaccess.thecvf.com/content/ICCV2023/papers/Han_STEERER_Resolving_Scale_Variations_for_Counting_and_Localization_via_Selective_ICCV_2023_paper.pdf",
        "ref_texts": "[39] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 8759\u20138768, 2018. 1",
        "ref_ids": [
          "39"
        ]
      },
      "AFPN: Asymptotic feature pyramid network for object detection": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2306.15988",
        "ref_texts": "[9] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia, \u201cPath aggregation network for instance segmentation,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition , 2018, pp. 8759\u20138768.",
        "ref_ids": [
          "9"
        ]
      },
      "Dynamic coarse-to-fine learning for oriented tiny object detection": {
        "authors": [
          "Chang Xu",
          "Jian Ding",
          "Jinwang Wang",
          "Wen Yang",
          "Huai Yu",
          "Lei Yu",
          "Song Xia"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Xu_Dynamic_Coarse-To-Fine_Learning_for_Oriented_Tiny_Object_Detection_CVPR_2023_paper.pdf",
        "ref_texts": "[33] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In IEEE Conference on Computer Vision and Pattern Recognition, pages 8759\u20138768, 2018. 3",
        "ref_ids": [
          "33"
        ]
      },
      "A survey on label-efficient deep image segmentation: Bridging the gap between weak supervision and dense prediction": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2207.01223",
        "ref_texts": "[14] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia, \u201cPath aggregation network for instance segmentation,\u201d in CVPR , 2018.",
        "ref_ids": [
          "14"
        ]
      },
      "Large scale visual food recognition": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2103.16107",
        "ref_texts": "[96] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia, \u201cPath aggregation network for instance segmentation,\u201d in CVPR , 2018, pp. 8759\u20138768.",
        "ref_ids": [
          "96"
        ]
      },
      "Fastinst: A simple query-based model for real-time instance segmentation": {
        "authors": [
          "Junjie He",
          "Pengyu Li",
          "Yifeng Geng",
          "Xuansong Xie"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2023/papers/He_FastInst_A_Simple_Query-Based_Model_for_Real-Time_Instance_Segmentation_CVPR_2023_paper.pdf",
        "ref_texts": "[28] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In CVPR , 2018. 1",
        "ref_ids": [
          "28"
        ]
      },
      "A comprehensive survey on segment anything model for vision and beyond": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2305.08196",
        "ref_texts": "[74] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia, \u201cPath aggregation network for instance segmentation,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition , 2018, pp. 8759\u20138768.",
        "ref_ids": [
          "74"
        ]
      },
      "LXL: LiDAR excluded lean 3D object detection with 4D imaging radar and camera fusion": {
        "authors": [
          "Weiyi Xiong",
          "Jianan Liu",
          "Tao Huang",
          "Long Han",
          "Yuxuan Xia",
          "Bing Zhu"
        ],
        "url": "https://figshare.swinburne.edu.au/articles/journal_contribution/LXL_LiDAR_Excluded_Lean_3D_Object_Detection_With_4D_Imaging_Radar_and_Camera_Fusion/26254550/1/files/47590082.pdf",
        "ref_texts": "[54] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia, \u201cPath aggregation network for instance segmentation,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2018, pp. 8759\u20138768.",
        "ref_ids": [
          "54"
        ]
      },
      "Consistent-teacher: Towards reducing inconsistent pseudo-targets in semi-supervised object detection": {
        "authors": [
          "Xinjiang Wang",
          "Xingyi Yang",
          "Shilong Zhang",
          "Yijiang Li",
          "Litong Feng",
          "Shijie Fang",
          "Chengqi Lyu",
          "Kai Chen",
          "Wayne Zhang"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_Consistent-Teacher_Towards_Reducing_Inconsistent_Pseudo-Targets_in_Semi-Supervised_Object_Detection_CVPR_2023_paper.pdf",
        "ref_texts": "[22] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 8759\u20138768, 2018. 4",
        "ref_ids": [
          "22"
        ]
      },
      "Towards local visual modeling for image captioning": {
        "authors": [
          "Yiwei Ma",
          "Jiayi Ji",
          "Xiaoshuai Sun",
          "Yiyi Zhou",
          "Rongrong Ji"
        ],
        "url": "https://arxiv.org/pdf/2302.06098"
      },
      "Look before you match: Instance understanding matters in video object segmentation": {
        "authors": [
          "Junke Wang",
          "Dongdong Chen",
          "Zuxuan Wu",
          "Chong Luo",
          "Chuanxin Tang",
          "Xiyang Dai",
          "Yucheng Zhao",
          "Yujia Xie",
          "Lu Yuan",
          "Gang Jiang"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2023/papers/Wang_Look_Before_You_Match_Instance_Understanding_Matters_in_Video_Object_CVPR_2023_paper.pdf",
        "ref_texts": "[39] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In CVPR , 2018. 3",
        "ref_ids": [
          "39"
        ]
      },
      "Underwater target detection based on improved YOLOv7": {
        "authors": [
          "Kaiyue Liu",
          "Qi Sun",
          "Daming Sun",
          "Lin Peng",
          "Mengduo Yang",
          "Nizhuan Wang"
        ],
        "url": "https://www.mdpi.com/2077-1312/11/3/677/pdf",
        "ref_texts": ""
      },
      "BuildMapper: A fully learnable framework for vectorized building contour extraction": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2211.03373",
        "ref_texts": "[20] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia, \"Path aggregation network for instance segmentation,\" in Proceedings of the IEEE conference on computer vision and pattern recognition , 2018, pp. ",
        "ref_ids": [
          "20"
        ]
      },
      "Yolo-ms: rethinking multi-scale representation learning for real-time object detection": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2308.05480",
        "ref_texts": "[35] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , June 2018. 3, 5, 7",
        "ref_ids": [
          "35"
        ]
      },
      "YOLO-Drone: an optimized YOLOv8 network for tiny UAV object detection": {
        "authors": [
          "Xianxu Zhai",
          "Zhihua Huang",
          "Tao Li",
          "Hanzheng Liu",
          "Siyuan Wang"
        ],
        "url": "https://www.mdpi.com/2079-9292/12/17/3664/pdf",
        "ref_texts": "31. Liu, S.; Qi, L.; Qin, H.; Shi, J.; Jia, J. Path aggregation network for instance segmentation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Salt Lake City, UT, USA, 18\u201323 June 2018; pp. 8759\u20138768.",
        "ref_ids": [
          "31"
        ]
      },
      "Double branch parallel network for segmentation of buildings and waters in remote sensing images": {
        "authors": [
          "Jing Chen",
          "Min Xia",
          "Dehao Wang",
          "Haifeng Lin"
        ],
        "url": "https://www.mdpi.com/2072-4292/15/6/1536/pdf",
        "ref_texts": "41. Liu, S.; Qi, L.; Qin, H.; Shi, J.; Jia, J. Path aggregation network for instance segmentation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Salt Lake City, UT, USA, 18\u201322 June 2018; pp. 8759\u20138768.",
        "ref_ids": [
          "41"
        ]
      },
      "Real-time vehicle detection algorithm based on a lightweight You-Only-Look-Once (YOLOv5n-L) approach": {
        "authors": [
          "Minglin Bie"
        ],
        "url": "http://ir.ciomp.ac.cn/bitstream/181722/67021/1/Real-time%20vehicle%20detection%20algorithm%20based%20on%20a%20lightweight%20You-Only-Look-Once%20%28YOLOv5n-L%29%20approach.pdf",
        "ref_texts": "(pp. 6274-6278). IEEE. Liu, R. W., Yuan, W., Chen, X., & Lu, Y. (2021). An enhanced CNN-enabled learning method for promoting ship detection in maritime surveillance system. Ocean Engineering, 235, Article 109435 . Liu, S., Qi, L., Qin, H., Shi, J., & Jia, J. (2018). Path aggregation network for instance segmentation. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 8759-8768). Maity, M., Banerjee, S., & Chaudhuri, S. S. (2021, April). Faster r-cnn and yolo based vehicle detection: A survey. In 2021 5th International Conference on Computing Methodologies and Communication (ICCMC) (pp. 1442-1447). IEEE. Mathew, M. P., & Mahesh, T. Y. (2022). Leaf-based disease detection in bell pepper plant using YOLO v5. Signal, Image and Video Processing, 16(3), 841\u2013847. Miao, Y., Liu, F., Hou, T., Liu, L., & Liu, Y. (2020, November). A nighttime vehicle detection method based on YOLO v3. In 2020 Chinese Automation Congress (CAC) "
      },
      "Open-vocabulary panoptic segmentation with embedding modulation": {
        "authors": [
          "Xi Chen",
          "Shuang Li",
          "Nam Lim",
          "Antonio Torralba",
          "Hengshuang Zhao"
        ],
        "url": "https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Open-vocabulary_Panoptic_Segmentation_with_Embedding_Modulation_ICCV_2023_paper.pdf",
        "ref_texts": "[29] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In CVPR , 2018.",
        "ref_ids": [
          "29"
        ]
      },
      "Face mask detection in smart cities using deep and transfer learning: Lessons learned from the COVID-19 pandemic": {
        "authors": [
          "Yassine Himeur",
          "Somaya Al",
          "Iraklis Varlamis",
          "Noor Al",
          "Khalid Abualsaud",
          "Amr Mohamed"
        ],
        "url": "https://www.mdpi.com/2079-8954/11/2/107/pdf",
        "ref_texts": "111. Liu, S.; Qi, L.; Qin, H.; Shi, J.; Jia, J. Path aggregation network for instance segmentation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Salt, Lake City, UT, USA, 18\u201322 June 2018; pp. 8759\u20138768.",
        "ref_ids": [
          "111"
        ]
      },
      "Coco-o: A benchmark for object detectors under natural distribution shifts": {
        "authors": [
          "Xiaofeng Mao",
          "Yuefeng Chen",
          "Yao Zhu",
          "Da Chen",
          "Hang Su",
          "Rong Zhang",
          "Hui Xue"
        ],
        "url": "http://openaccess.thecvf.com/content/ICCV2023/papers/Mao_COCO-O_A_Benchmark_for_Object_Detectors_under_Natural_Distribution_Shifts_ICCV_2023_paper.pdf",
        "ref_texts": "[54] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 8759\u20138768, 2018.",
        "ref_ids": [
          "54"
        ]
      },
      "Task-specific context decoupling for object detection": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2303.01047",
        "ref_texts": "[28] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 8759\u20138768, 2018. 2, 4, 7, 8",
        "ref_ids": [
          "28"
        ]
      },
      "Lightweight aerial image object detection algorithm based on improved YOLOv5s": {
        "authors": [
          "Lixia Deng"
        ],
        "url": "https://www.nature.com/articles/s41598-023-34892-4.pdf",
        "ref_texts": ""
      },
      "Generalized parametric contrastive learning": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2209.12400",
        "ref_texts": "[4] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia, \u201cPath aggregation network for instance segmentation,\u201d in CVPR , 2018.",
        "ref_ids": [
          "4"
        ]
      },
      "Deep learning approaches for wildland fires remote sensing: Classification, detection, and segmentation": {
        "authors": [
          "Rafik Ghali",
          "Moulay A. Akhloufi"
        ],
        "url": "https://www.mdpi.com/2072-4292/15/7/1821/pdf",
        "ref_texts": "109. Liu, S.; Qi, L.; Qin, H.; Shi, J.; Jia, J. Path Aggregation Network for Instance Segmentation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Salt Lake City, UT, USA, 18\u201323 June 2018.",
        "ref_ids": [
          "109"
        ]
      },
      "A survey of modern deep learning based object detection models": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2104.11892",
        "ref_texts": "[46] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia, \u201cPath aggregation network for instance segmentation.\u201d [Online]. Available: http: //arxiv.org/abs/1803.01534",
        "ref_ids": [
          "46",
          "Online"
        ]
      },
      "YOLOv6: A single-stage object detection framework for industrial applications": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2209.02976",
        "ref_texts": "[24] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 8759\u20138768, 2018. 2, 4",
        "ref_ids": [
          "24"
        ]
      },
      "ISNet: Shape matters for infrared small target detection": {
        "authors": [
          "Mingjin Zhang",
          "Rui Zhang",
          "Yuxiang Yang",
          "Haichen Bai",
          "Jing Zhang",
          "Jie Guo"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_ISNet_Shape_Matters_for_Infrared_Small_Target_Detection_CVPR_2022_paper.pdf",
        "ref_texts": "[20] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In Proceedings of the IEEE conference on Computer Vision and Pattern Recognition , pages 8759\u20138768, 2018. 3",
        "ref_ids": [
          "20"
        ]
      },
      "Yolo-pose: Enhancing yolo for multi person pose estimation using object keypoint similarity loss": {
        "authors": [
          "Debapriya Maji",
          "Soyeb Nagori",
          "Manu Mathew",
          "Deepak Poddar"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2022W/ECV/papers/Maji_YOLO-Pose_Enhancing_YOLO_for_Multi_Person_Pose_Estimation_Using_Object_CVPRW_2022_paper.pdf",
        "ref_texts": " Path aggregation network for instance segm entation. In CVPR, 2018. "
      },
      "Clrnet: Cross layer refinement network for lane detection": {
        "authors": [
          "Tu Zheng",
          "Yifei Huang",
          "Yang Liu",
          "Wenjian Tang",
          "Zheng Yang",
          "Deng Cai",
          "Xiaofei He"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2022/papers/Zheng_CLRNet_Cross_Layer_Refinement_Network_for_Lane_Detection_CVPR_2022_paper.pdf",
        "ref_texts": "[14] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In Pro-ceedings of the IEEE conference on computer vision and pattern recognition , pages 8759\u20138768, 2018. 3",
        "ref_ids": [
          "14"
        ]
      },
      "No more strided convolutions or pooling: A new CNN building block for low-resolution images and small objects": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2208.03641",
        "ref_texts": "22. Liu, S., Qi, L., Qin, H., Shi, J., Jia, J.: Path aggregation network for instance segmentation. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. pp. 8759\u20138768 (2018)",
        "ref_ids": [
          "22"
        ]
      },
      "Yolop: You only look once for panoptic driving perception": {
        "authors": [],
        "url": "https://link.springer.com/content/pdf/10.1007/s11633-022-1339-y.pdf",
        "ref_texts": "\u00a0S.\u00a0Liu,\u00a0L.\u00a0Qi,\u00a0H.\u00a0F.\u00a0Qin,\u00a0J.\u00a0P.\u00a0Shi,\u00a0J.\u00a0Y.\u00a0Jia.\u00a0Path\u00a0aggregation\u00a0network\u00a0for\u00a0instance \u00a0segmentation. \u00a0In\u00a0Proceedings of IEEE/CVF Conference on Computer Vision and Pattern Recognition ,\u00a0IEEE,\u00a0Salt\u00a0Lake\u00a0City,\u00a0USA,\u00a0pp.\u00a08759\u2013"
      },
      "A fast accurate fine-grain object detection model based on YOLOv4 deep neural network": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2111.00298",
        "ref_texts": ""
      },
      "Msft-yolo: Improved yolov5 based on transformer for detecting defects of steel surface": {
        "authors": [
          "Zexuan Guo",
          "Chensheng Wang",
          "Guang Yang",
          "Zeyuan Huang",
          "Guo Li"
        ],
        "url": "https://www.mdpi.com/1424-8220/22/9/3467/pdf",
        "ref_texts": "24. Liu, S.; Qi, L.; Qin, H.; Shi, J.; Jia, J. Path Aggregation Network for Instance Segmentation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), Salt Lake City, UT, USA, 28\u201323 June 2018.",
        "ref_ids": [
          "24"
        ]
      },
      "Swin-transformer-enabled YOLOv5 with attention mechanism for small object detection on satellite images": {
        "authors": [
          "Hang Gong",
          "Tingkui Mu",
          "Qiuxia Li",
          "Haishan Dai",
          "Chunlai Li",
          "Zhiping He",
          "Wenjing Wang",
          "Feng Han",
          "Abudusalamu Tuniyazi",
          "Haoyang Li",
          "Xuechan Lang",
          "Zhiyuan Li",
          "Bin Wang"
        ],
        "url": "https://www.mdpi.com/2072-4292/14/12/2861/pdf",
        "ref_texts": "19. Liu, S.; Qi, L.; Qin, H.; Shi, J.; Jia, J. Path aggregation network for instance segmentation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Salt Lake City, UT, USA, 18\u201322 June 2018; pp. 8759\u20138768.",
        "ref_ids": [
          "19"
        ]
      },
      "RFLA: Gaussian receptive field based label assignment for tiny object detection": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2208.08738",
        "ref_texts": "26. Liu, S., Qi, L., Qin, H., Shi, J., Jia, J.: Path aggregation network for instance segmentation. In: IEEE Conference on Computer Vision and Pattern Recognition. pp. 8759\u20138768 (2018)",
        "ref_ids": [
          "26"
        ]
      },
      "Lite-yolov5: A lightweight deep learning detector for on-board ship detection in large-scene sentinel-1 sar images": {
        "authors": [
          "Xiaowo Xu",
          "Xiaoling Zhang",
          "Tianwen Zhang"
        ],
        "url": "https://www.mdpi.com/2072-4292/14/4/1018/pdf",
        "ref_texts": "37. Liu, S.; Qi, L.; Qin, H.; Shi, J.; Jia, J. Path Aggregation Network for Instance Segmentation. In Proceedings of the 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition, Salt Lake City, UT, USA, 18\u201323 June 2018; pp. 8759\u20138768.",
        "ref_ids": [
          "37"
        ]
      },
      "Learning equivariant segmentation with instance-unique querying": {
        "authors": [],
        "url": "https://proceedings.neurips.cc/paper_files/paper/2022/file/53a525a5f8910609263ffd130ef370b8-Paper-Conference.pdf",
        "ref_texts": "[8]Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In CVPR , 2018. 1, 2",
        "ref_ids": [
          "8"
        ]
      },
      "Deformable feature aggregation for dynamic multi-modal 3D object detection": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2207.10316",
        "ref_texts": "[18] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 8759\u20138768, 2018. 2, 5",
        "ref_ids": [
          "18"
        ]
      },
      "Adamixer: A fast-converging query-based object detector": {
        "authors": [
          "Ziteng Gao",
          "Limin Wang",
          "Bing Han",
          "Sheng Guo"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2022/papers/Gao_AdaMixer_A_Fast-Converging_Query-Based_Object_Detector_CVPR_2022_paper.pdf",
        "ref_texts": "[25] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In CVPR , 2018. 7",
        "ref_ids": [
          "25"
        ]
      },
      "YOLO5Face: Why reinventing a face detector": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2105.12931",
        "ref_texts": "[36] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia, \u201cPath aggregation network for instance segmentation,\u201d ArXiv preprint 1803.01534 , 2018. 2, 5",
        "ref_ids": [
          "36"
        ]
      },
      "Cbnet: A composite backbone network architecture for object detection": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2107.00420",
        "ref_texts": "[58] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia, \u201cPath aggregation network for instance segmentation,\u201d in CVPR , 2018. 4",
        "ref_ids": [
          "58"
        ]
      },
      "Freesolo: Learning to segment objects without annotations": {
        "authors": [
          "Xinlong Wang",
          "Zhiding Yu",
          "Shalini De",
          "Jan Kautz",
          "Anima Anandkumar",
          "Chunhua Shen",
          "Jose M. Alvarez"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_FreeSOLO_Learning_To_Segment_Objects_Without_Annotations_CVPR_2022_paper.pdf",
        "ref_texts": "[22] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In IEEE Conf. Comput. Vis. Pattern Recog. , 2018. 2",
        "ref_ids": [
          "22"
        ]
      },
      "Mask transfiner for high-quality instance segmentation": {
        "authors": [
          "Lei Ke",
          "Martin Danelljan",
          "Xia Li",
          "Wing Tai",
          "Keung Tang",
          "Fisher Yu"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2022/papers/Ke_Mask_Transfiner_for_High-Quality_Instance_Segmentation_CVPR_2022_paper.pdf",
        "ref_texts": "[34] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In CVPR , 2018. 1",
        "ref_ids": [
          "34"
        ]
      },
      "Sf-yolov5: A lightweight small object detection algorithm based on improved feature fusion mode": {
        "authors": [
          "Haiying Liu",
          "Fengqian Sun",
          "Jason Gu",
          "Lixia Deng"
        ],
        "url": "https://www.mdpi.com/1424-8220/22/15/5817/pdf",
        "ref_texts": "26. Liu, S.; Qi, L.; Qin, H.; Shi, J.; Jia, J. Path aggregation network for instance segmentation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Salt Lake City, UT, USA, 18\u201323 June 2018; pp. 8759\u20138768.",
        "ref_ids": [
          "26"
        ]
      },
      "E2ec: An end-to-end contour-based method for high-quality high-speed instance segmentation": {
        "authors": [
          "Tao Zhang",
          "Shiqing Wei",
          "Shunping Ji"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_E2EC_An_End-to-End_Contour-Based_Method_for_High-Quality_High-Speed_Instance_Segmentation_CVPR_2022_paper.pdf",
        "ref_texts": "[23] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 8759\u20138768, 2018. 1, 3, 7",
        "ref_ids": [
          "23"
        ]
      },
      "Scrdet++: Detecting small, cluttered and rotated objects via instance-level feature denoising and rotation loss smoothing": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2004.13316",
        "ref_texts": "[76] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia, \u201cPath aggregation network for instance segmentation,\u201d in IEEE Conference on Computer Vision and Pattern Recognition , 2018, pp. 8759\u20138768.",
        "ref_ids": [
          "76"
        ]
      },
      "Deep convolutional neural network for enhancing traffic sign recognition developed on Yolo V4": {
        "authors": [],
        "url": "https://researchportal.port.ac.uk/files/52086128/Deep_CNN_for_Sign_recognition_Multimedia_Tools_pp.pdf",
        "ref_texts": "405\u2013412. https://doi.org/10.1007/978 -3-319-46681 -1_49 Liu, S., Qi, L., Qin, H., Shi, J., & Jia, J. (2018). Path Aggregation Network for Instance Segmentation. Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition , 8759 \u20138768. https://doi.org/10.1109/CVPR.2018.00913 Loshchilov, I., & Hutter, F. (2017). SGDR: Sto chastic gradient descent with warm restarts. 5th International Conference on Learning Representations, ICLR 2017 Conference Track Proceedings . Min, W., Li, X., Wang, Q., Zeng, Q., & Liao, Y . (2019). New approach to vehicle license plate location based on new model YOLO -L and plate pre -identification. IET Image Processing , 13(7), 1041 \u20131049. https://doi.org/10.1049/iet ipr.2018.6449 Misra, D. (2019). 1908.08681V2. Mish: A Self Regularized Non -Monotonic Neural Activation Function , (1). Redmon, J., & Farhadi, A. (2017). YOLO9000: Better, faster, stronger. Proceedings 30th IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2017 , 6517 \u20136525. https://doi.org/10.1109/CVPR.2017.690 Redmon, J., & Farhadi, A. (2018). YOLOv3: An Incremental Improvement. CoRR , abs/1804.0 , 1\u20136. Retrieved from http://arxiv.org/abs/1804.02767 Ren, S., He, K., Girshick, R., & Sun, J. (2017). Faster R -CNN: Towards Real -Time Object Detection with Region Proposal Networks. IEEE Transactions on Pattern Analysis and Machine Intell igence , 39(6), 1137 \u20131149. https://doi.org/10.1109/TPAMI.2016.2577031 Tai, S., Dewi, C., Chen, R., Liu, Y ., Jiang, X., & Yu, H. (2020). Deep Learning for Traffic Sign Recognition Based on Spatial Pyramid Pooling with Scale Analysis. Applied Sciences (Switze rland) , 10(19), 6997. https://doi.org/10.3390/app10196997 Tan, M., Pang, R., & Le, Q. V . (2020). EfficientDet: Scalable and Efficient Object Detection. 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) , 10778 \u201310787. Wang, C., Liao, H. M., Wu, Y ., & Chen, P. (2020). CSPNet: A new backbone that can enhance learning capability of cnn. Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshop (CVPR Workshop) , 2. Yang, T., Long, X., Sangaiah, A. K., Zheng, Z. , & Tong, C. (2018). Deep detection network for real -life traffic sign in vehicular networks. Computer Networks , 136(8), 95 \u2013104. https://doi.org/10.1016/j.comnet.2018.02.026 "
      },
      "Deep learning based detector YOLOv5 for identifying insect pests": {
        "authors": [
          "Iftikhar Ahmad",
          "Yayun Yang",
          "Yi Yue",
          "Chen Ye",
          "Muhammad Hassan",
          "Xi Cheng",
          "Yunzhi Wu",
          "Youhua Zhang"
        ],
        "url": "https://www.mdpi.com/2076-3417/12/19/10167/pdf",
        "ref_texts": "43. Liu, S.; Qi, L.; Qin, H.; Shi, J.; Jia, J. Path Aggregation Network for Instance Segmentation. In Proceedings of the 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), Salt Lake City, UT, USA, 18\u201323 June 2018; Institute of Electrical and Electronics Engineers (IEEE): New York, NY, USA, 2018; pp. 8759\u20138768. [CrossRef]",
        "ref_ids": [
          "43"
        ]
      },
      "Good visual guidance makes a better extractor: Hierarchical visual prefix for multimodal entity and relation extraction": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2205.03521",
        "ref_texts": "2016b. Neural architectures for named entity recognition. In NAACL HLT 2016, The 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, San Diego California, USA, June 1217, 2016 , pages 260\u2013270. The Association for Computational Linguistics. Gen Li, Nan Duan, Yuejian Fang, Ming Gong, and Daxin Jiang. 2020. Unicoder-vl: A universal encoder for vision and language by cross-modal pretraining. In The Thirty-Fourth AAAI Conference on Artificial Intelligence, AAAI 2020, The ThirtySecond Innovative Applications of Artificial Intelligence Conference, IAAI 2020, The Tenth AAAI Symposium on Educational Advances in Artificial Intelligence, EAAI 2020, New York, NY, USA, February 7-12, 2020 , pages 11336\u201311344. AAAI Press. Liunian Harold Li, Mark Yatskar, Da Yin, Cho-Jui Hsieh, and Kai-Wei Chang. 2019. Visualbert: A simple and performant baseline for vision and language. ArXiv preprint , abs/1908.03557. Xiang Lisa Li and Percy Liang. 2021. Prefix-tuning: Optimizing continuous prompts for generation. In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, ACL/IJCNLP 2021, (Volume 1: Long Papers), Virtual Event, August 1-6, 2021 , pages 4582\u20134597. Association for Computational Linguistics. Xiaozhuan Liang, Ningyu Zhang, Siyuan Cheng, Zhen Bi, Zhenru Zhang, Chuanqi Tan, Songfang Huang, Fei Huang, and Huajun Chen. 2022. Contrastive demonstration tuning for pre-trained language models.CoRR , abs/2204.04392. Tsung-Yi Lin, Piotr Doll\u00e1r, Ross B. Girshick, Kaiming He, Bharath Hariharan, and Serge J. Belongie. 2017. Feature pyramid networks for object detection. In 2017 IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2017, Honolulu, HI, USA, July 21-26, 2017 , pages 936\u2013944. IEEE Computer Society. Kun Liu, Yao Fu, Chuanqi Tan, Mosha Chen, Ningyu Zhang, Songfang Huang, and Sheng Gao. 2021. Noisy-labeled NER with confidence estimation. In Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2021, Online, June 6-11, 2021 , pages 3437\u20133445. Association for Computational Linguistics. Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. 2018. Path aggregation network for instance segmentation. In 2018 IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2018, Salt Lake City, UT, USA, June 18-22, 2018 , pages 8759\u2013"
      },
      "Seqformer: Sequential transformer for video instance segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2112.08275.pdf?trk=public_post_comment-text",
        "ref_texts": "22. Liu, S., Qi, L., Qin, H., Shi, J., Jia, J.: Path aggregation network for instance segmentation. In: Proceedings of the IEEE conference on computer vision and pattern recognition. pp. 8759\u20138768 (2018) 3",
        "ref_ids": [
          "22"
        ]
      },
      "A small target forest fire detection model based on YOLOv5 improvement": {
        "authors": [
          "Zhenyang Xue",
          "Haifeng Lin",
          "Fang Wang"
        ],
        "url": "https://www.mdpi.com/1999-4907/13/8/1332/pdf",
        "ref_texts": "19. Liu, S.; Qi, L.; Qin, H.; Shi, J.; Jia, J. Path aggregation network for instance segmentation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Salt Lake City, UT, USA, 18\u201323 June 2018; pp. 8759\u20138768.",
        "ref_ids": [
          "19"
        ]
      },
      "Underwater target detection algorithm based on improved YOLOv5": {
        "authors": [
          "Fei Lei",
          "Feifei Tang",
          "Shuhan Li"
        ],
        "url": "https://www.mdpi.com/2077-1312/10/3/310/pdf",
        "ref_texts": "35. Liu, S.; Qi, L.; Qin, H.; Shi, J.; Jia, J. Path aggregation network for instance segmentation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Salt Lake City, UT, USA, 18\u201322 June 2018; pp. 8759\u20138768.",
        "ref_ids": [
          "35"
        ]
      },
      "RigNet: Repetitive image guided network for depth completion": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2107.13802",
        "ref_texts": "30. Liu, S., Qi, L., Qin, H., Shi, J., Jia, J.: Path aggregation network for instance segmentation. In: CVPR. pp. 8759\u20138768 (2018) 3",
        "ref_ids": [
          "30"
        ]
      },
      "SUNet: Swin transformer UNet for image denoising": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2202.14009",
        "ref_texts": "[34] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia, \u201cPath aggregation network for instance segmentation,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition , 2018, pp. 8759\u20138768.",
        "ref_ids": [
          "34"
        ]
      },
      "YOLO-LOGO: A transformer-based YOLO segmentation model for breast mass detection and segmentation in digital mammograms": {
        "authors": [
          "Yongye Su"
        ],
        "url": "https://www.cse.unr.edu/~bebis/CS791/Fall2023/Papers/DeepLearning/2022%20-%20YOLO-LOGO%20A%20transformer-based%20YOLO%20segmentation%20model%20for%20breast%20mass%20detection%20and%20segmentation%20in%20digital%20mammograms.pdf",
        "ref_texts": "[36] S. Liu, L. Qi, H. Qin, J. Shi, J. Jia, Path aggregation network for instance segmentation, in: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2018, pp. 8759\u20138768 . ",
        "ref_ids": [
          "36"
        ]
      },
      "CE-FPN: enhancing channel information for object detection": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2103.10643",
        "ref_texts": "[13] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia, \u201cPath aggregation network for instance segmentation,\u201d in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , 2018, pp. 8759\u20138768. JOURNAL OF L ATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015 9",
        "ref_ids": [
          "13"
        ]
      },
      "Cross-modality attentive feature fusion for object detection in multispectral remote sensing imagery": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2112.02991",
        "ref_texts": ""
      },
      "Cat: Cross attention in vision transformer": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2106.05786",
        "ref_texts": "[64] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 8759\u20138768, 2018.",
        "ref_ids": [
          "64"
        ]
      },
      "Polyworld: Polygonal building extraction with graph neural networks in satellite images": {
        "authors": [
          "Stefano Zorzi",
          "Shabab Bazrafkan",
          "Stefan Habenschuss",
          "Friedrich Fraundorfer"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2022/papers/Zorzi_PolyWorld_Polygonal_Building_Extraction_With_Graph_Neural_Networks_in_Satellite_CVPR_2022_paper.pdf",
        "ref_texts": "[21] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 8759\u20138768, 2018. 2, 7, 8",
        "ref_ids": [
          "21"
        ]
      },
      "Open-vocabulary instance segmentation via robust cross-modal pseudo-labeling": {
        "authors": [
          "Dat Huynh",
          "Jason Kuen",
          "Zhe Lin",
          "Jiuxiang Gu",
          "Ehsan Elhamifar"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2022/papers/Huynh_Open-Vocabulary_Instance_Segmentation_via_Robust_Cross-Modal_Pseudo-Labeling_CVPR_2022_paper.pdf",
        "ref_texts": "[7] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia, \u201cPath aggregation network for instance segmentation,\u201d IEEE Conference on Computer Vision and Pattern Recognition , 2018. 1",
        "ref_ids": [
          "7"
        ]
      },
      "Osformer: One-stage camouflaged instance segmentation with transformers": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2207.02255",
        "ref_texts": "35. Liu, S., Qi, L., Qin, H., Shi, J., Jia, J.: Path aggregation network for instance segmentation. In: IEEE CVPR (2018)",
        "ref_ids": [
          "35"
        ]
      },
      "Ms-tct: Multi-scale temporal convtransformer for action detection": {
        "authors": [
          "Rui Dai",
          "Srijan Das",
          "Kumara Kahatapitiya",
          "Michael S. Ryoo",
          "Francois Bremond"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2022/papers/Dai_MS-TCT_Multi-Scale_Temporal_ConvTransformer_for_Action_Detection_CVPR_2022_paper.pdf",
        "ref_texts": "[33] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 8759\u20138768, 2018. 5",
        "ref_ids": [
          "33"
        ]
      },
      "A mask attention interaction and scale enhancement network for SAR ship instance segmentation": {
        "authors": [
          "Tiffany Mc"
        ],
        "url": "https://arxiv.org/pdf/2207.03912",
        "ref_texts": "[41]. S. Liu et al. \u201cPath Aggregation Network for Instance Segmentation,\u201d in Proc. IEEE Conf. Comput . Vis. Pattern Recognit. , 2018, pp. 8759 \u20128768. ",
        "ref_ids": [
          "41"
        ]
      },
      "A wildfire smoke detection system using unmanned aerial vehicle images based on the optimized YOLOv5": {
        "authors": [
          "Mukhriddin Mukhiddinov",
          "Akmalbek Bobomirzaevich",
          "Jinsoo Cho"
        ],
        "url": "https://www.mdpi.com/1424-8220/22/23/9384/pdf",
        "ref_texts": "61. Liu, S.; Qi, L.; Qin, H.; Shi, J.; Jia, J. Path aggregation network for instance segmentation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Salt Lake City, UT, USA, 18\u201323 June 2018; pp. 8759\u20138768.",
        "ref_ids": [
          "61"
        ]
      },
      "Reslt: Residual learning for long-tailed recognition": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2101.10633.pdf?amp=1",
        "ref_texts": "[12] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia, \u201cPath aggregation network for instance segmentation,\u201d in CVPR , 2018.",
        "ref_ids": [
          "12"
        ]
      },
      "Improved YOLO v5 wheat ear detection algorithm based on attention mechanism": {
        "authors": [
          "Rui Li",
          "Yanpeng Wu"
        ],
        "url": "https://www.mdpi.com/2079-9292/11/11/1673/pdf",
        "ref_texts": "30. Liu, S.; Qi, L.; Qin, H.; Shi, J.; Jia, J. Path Aggregation Network for Instance Segmentation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Salt Lake City, UT, USA, 18\u201323 June 2018.",
        "ref_ids": [
          "30"
        ]
      },
      "Automated detection, classification and counting of fish in fish passages with deep learning": {
        "authors": [
          "Chris Whidden"
        ],
        "url": "https://www.frontiersin.org/articles/10.3389/fmars.2021.823173/pdf",
        "ref_texts": "\u201cMicrosoft COCO: common objects in context,\u201d in European Conference on ComputerVision (Z\u00fcrich:Springer),740\u2013755. Liu, S., Qi, L., Qin, H., Shi, J., and Jia, J. (2018). \u201cPath aggre gation network for instance segmentation,\u201d in Proceedings of the IEEE Conference on Computer VisionandPatternRecognition (SaltLakeCity,UT),8759\u20138768. Martignac,F.,Daroux,A.,Bagliniere,J.-L.,Ombredane,D.,andG uillard,J.(2015). The use of acoustic cameras in shallow waters: new hydroacoustic t ools for monitoringmigratoryfishpopulation.areviewofdidsontechnology. FishFish."
      },
      "Siamese transformer pyramid networks for real-time UAV tracking": {
        "authors": [
          "Daitao Xing",
          "Nikolaos Evangeliou",
          "Athanasios Tsoukalas",
          "Anthony Tzes"
        ],
        "url": "https://openaccess.thecvf.com/content/WACV2022/papers/Xing_Siamese_Transformer_Pyramid_Networks_for_Real-Time_UAV_Tracking_WACV_2022_paper.pdf",
        "ref_texts": "[32] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 8759\u20138768, 2018.",
        "ref_ids": [
          "32"
        ]
      },
      "Tubeformer-deeplab: Video mask transformer": {
        "authors": [
          "Dahun Kim",
          "Jun Xie",
          "Huiyu Wang",
          "Siyuan Qiao",
          "Qihang Yu",
          "Seok Kim",
          "Hartwig Adam",
          "In So",
          "Chieh Chen"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2022/papers/Kim_TubeFormer-DeepLab_Video_Mask_Transformer_CVPR_2022_paper.pdf",
        "ref_texts": "[53] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In CVPR , 2018. 2",
        "ref_ids": [
          "53"
        ]
      },
      "Detection of transmission line insulator defects based on an improved lightweight YOLOv4 model": {
        "authors": [
          "Zhibin Qiu",
          "Xuan Zhu",
          "Caibo Liao",
          "Dazhai Shi",
          "Wenqian Qu"
        ],
        "url": "https://www.mdpi.com/2076-3417/12/3/1207/pdf",
        "ref_texts": "37. Liu, S.; Qi, L.; Qin, H.; Shi, J.; Jia, J. Path aggregation network for instance segmentation. In Proceedings of the 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition, Salt Lake City, UT, USA, 18\u201323 June 2018. [CrossRef]",
        "ref_ids": [
          "37"
        ]
      },
      "Improvement of lightweight convolutional neural network model based on YOLO algorithm and its research in pavement defect detection": {
        "authors": [
          "Jun Du",
          "Jian Jiao"
        ],
        "url": "https://www.mdpi.com/1424-8220/22/9/3537/pdf",
        "ref_texts": "51. Liu, S.; Qi, L.; Qin, H.; Shi, J.; Jia, J. Path Aggregation Network for Instance Segmentation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Salt Lake City, UT, USA, 18\u201323 June 2018; pp. 8759\u20138768.",
        "ref_ids": [
          "51"
        ]
      },
      "Small object detection method based on adaptive spatial parallel convolution and fast multi-scale fusion": {
        "authors": [
          "Firstname Lastname",
          "Firstname Lastname",
          "Firstname Lastname"
        ],
        "url": "https://www.mdpi.com/2072-4292/14/2/420/pdf",
        "ref_texts": "28. Liu, S.; Qi, L.; Qin, H.; Shi, J.; Jia, J. Path aggregation network for instance segmentation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Salt Lake City, UT, USA, 18\u201322 June 2018; pp. 8759\u20138768.",
        "ref_ids": [
          "28"
        ]
      },
      "k-means Mask Transformer": {
        "authors": [],
        "url": "https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136890286.pdf",
        "ref_texts": "68. Liu, S., Qi, L., Qin, H., Shi, J., Jia, J.: Path aggregation network for instance segmentation. In: CVPR (2018) 13",
        "ref_ids": [
          "68"
        ]
      },
      "Yolopv2: Better, faster, stronger for panoptic driving perception": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2208.11434.pdf?trk=public_post_comment-text",
        "ref_texts": "[12] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 8759\u20138768, 2018.[13] Ilya Loshchilov and Frank Hutter. Sgdr: Stochastic gradient descent with warm restarts. arXiv preprint arXiv:1608.03983 , 2016.",
        "ref_ids": [
          "12",
          "13"
        ]
      },
      "Target detection method of UAV aerial imagery based on improved YOLOv5": {
        "authors": [
          "Xudong Luo",
          "Yiquan Wu",
          "Feiyue Wang"
        ],
        "url": "https://www.mdpi.com/2072-4292/14/19/5063/pdf",
        "ref_texts": "40. Liu, S.; Qi, L.; Qin, H.F.; Shi, J.P .; Jia, J.Y. Path Aggregation Network for Instance Segmentation. In Proceedings of the 31st IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), Salt Lake City, UT, USA, 18\u201323 June 2018; pp. 8759\u20138768.",
        "ref_ids": [
          "40"
        ]
      },
      "Real-time vehicle classification and tracking using a transfer learning-improved deep learning network": {
        "authors": [
          "Bipul Neupane",
          "Teerayut Horanont",
          "Jagannath Aryal"
        ],
        "url": "https://www.mdpi.com/1424-8220/22/10/3813/pdf",
        "ref_texts": "54. Liu, S.; Qi, L.; Qin, H.; Shi, J.; Jia, J. Path aggregation network for instance segmentation. In Proceedings of the 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition, Salt Lake City, UT, USA, 18\u201323 June 2018; pp. 8759\u20138768.",
        "ref_ids": [
          "54"
        ]
      },
      "AI-based object detection latest trends in remote sensing, multimedia and agriculture applications": {
        "authors": [
          "Saqib Ali"
        ],
        "url": "https://www.frontiersin.org/journals/plant-science/articles/10.3389/fpls.2022.1041514/pdf",
        "ref_texts": "\u201cSsd: Single shot multibox detector, \u201dinEuropean Conference on computer vision (Cham: Springer), 21 \u201337. Liu, N., Celik, T., and Li, H. C. (2021). Gated ladder-shaped feature pyramid network for object detection in optical remote sensing images. IEEE Geosci. Remote Sens. Lett. 19, 1 \u20135. doi: 10.1109/lgrs.2020.3046137 Liu, W., Luo, B., and Liu, J. (2021). Synthetic data augmentation using multiscale attention CycleGAN for aircraft detection in remote sensing images. IEEE Geosci. Remote Sens. Lett. 19, 1 \u20135. doi: 10.1109/lgrs.2021.3052017 Liu, S., Qi, L., Qin, H., Shi, J., and Jia, J. (2018). \u201cPath aggregation network for instance segmentation, \u201dinProceedings of the IEEE conference on computer vision and pattern recognition , (Salt Lake City, UT, USA: IEEE) 8759 \u20138768. Li, K., Wan, G., Cheng, G., Meng, L., and Han, J. (2020). Object detection in optical remote sensing images: A survey and a new benchmark. ISPRS. J. Photogrammet. Remote Sens. 159, 296 \u2013307. doi: 10.1016/j.isprsjprs.2019.11.023 Li, J., Wei, Y., Liang, X., Dong, J., Xu, T., Feng, J., et al. (2016). Attentive contexts for object detection. IEEE Trans. Multimedia. 19 (5), 944 \u2013954. doi: 10.1109/ tmm.2016.2642789 Li, M., Zhang, Z., Lei, L., Wang, X., and Guo, X. (2020). Agricultural greenhouses detection in high-resolution satellite images based on convolutional neural networks: Comparison of faster r-CNN, YOLO v3 and SSD. Sensors 20 (17), 4938. doi: 10.3390/s20174938 Li, Z., and Zhou, F. (2017). FSSD: feature fusion single shot multibox detector. arXiv. preprint. arXiv. , 1712.00960. doi: 10.48550/arXiv.1712.00960 L u o ,Y .M . ,H u a n g ,D .T . ,L i u ,P .Z . ,a n dF e n g ,H .M .(2 0 1 6 ) .A nn o v e lr a n d o m forests and its application to the classi fication of mangroves remote sensing image. Multimedia. Tools Appl. 75 (16), 9707 \u20139722. doi: 10.1007/s11042-0152906-9 Mahanti, N. K., Pandiselvam, R., Kothakota, A., Ishwarya, P., Chakraborty, S. K., Kumar, M., et al. (2021). Emerging non-destructive imaging techniques for fruitdamage detection: Image processing and analysis. Trends Food Sci. Technol 120, 418\u2013438. doi: 10.1016/j.tifs.2021.12.021 Marris, H., Deboudt, K., Augustin, P., Flament, P., Blond, F., Fiani, E., et al."
      },
      "End-to-end deep learning framework for printed circuit board manufacturing defect classification": {
        "authors": [
          "Abhiroop Bhattacharya"
        ],
        "url": "https://www.nature.com/articles/s41598-022-16302-3.pdf",
        "ref_texts": ""
      },
      "Solve the puzzle of instance segmentation in videos: A weakly supervised framework with spatio-temporal collaboration": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2212.07592",
        "ref_texts": "[42] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia, \u201cPath aggregation network for instance segmentation,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition , 2018, pp. 8759\u20138768.",
        "ref_ids": [
          "42"
        ]
      },
      "HTC+ for SAR ship instance segmentation": {
        "authors": [
          "Tianwen Zhang",
          "Xiaoling Zhang"
        ],
        "url": "https://www.mdpi.com/2072-4292/14/10/2395/pdf",
        "ref_texts": "34. Liu, S.; Qi, L.; Qin, H.; Shi, J.; Jia, J. Path Aggregation Network for Instance Segmentation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Salt Lake City, UT, USA, 18\u201323 June 2018; pp. 8759\u20138768.",
        "ref_ids": [
          "34"
        ]
      },
      "Multi-scale convolutional neural network for automated AMD classification using retinal OCT images": {
        "authors": [
          "Saman Sotoudeh"
        ],
        "url": "https://arxiv.org/pdf/2110.03002",
        "ref_texts": "[62] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia, \u201cPath Aggregation Network for Instance Segmentation,\u201d Proc. IEEE Conf. Comput. Vis. pattern Recognit. , pp. 8759 \u20138768, 2018. ",
        "ref_ids": [
          "62"
        ]
      },
      "YOLO-LRDD: A lightweight method for road damage detection based on improved YOLOv5s": {
        "authors": [
          "Fang Wan"
        ],
        "url": "https://link.springer.com/content/pdf/10.1186/s13634-022-00931-x.pdf",
        "ref_texts": ""
      },
      "A lightweight YOLOv3 algorithm used for safety helmet detection": {
        "authors": [
          "Lixia Deng"
        ],
        "url": "https://www.nature.com/articles/s41598-022-15272-w.pdf",
        "ref_texts": ""
      },
      "Precise single-stage detector": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2210.04252",
        "ref_texts": "[61]S. Liu, L. Qi, H. Qin, J. Shi, J. Jia, Path aggregation network for instance segmentation, in: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2018, pp. 8759--8768.",
        "ref_ids": [
          "61"
        ]
      },
      "Open world entity segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2107.14228",
        "ref_texts": "[47] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia. Path aggregation network for instance segmentation. In CVPR , 2018.",
        "ref_ids": [
          "47"
        ]
      },
      "Contrastmask: Contrastive learning to segment every thing": {
        "authors": [
          "Xuehui Wang",
          "Kai Zhao",
          "Ruixin Zhang",
          "Shouhong Ding",
          "Yan Wang",
          "Wei Shen"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_ContrastMask_Contrastive_Learning_To_Segment_Every_Thing_CVPR_2022_paper.pdf",
        "ref_texts": "[26] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In Proceedings of the IEEE conference on computer vision and pattern recognition (CVPR) , pages 8759\u20138768, 2018. 1, 2",
        "ref_ids": [
          "26"
        ]
      },
      "A defect detection method based on BC-YOLO for transmission line components in UAV remote sensing images": {
        "authors": [
          "Wenxia Bao",
          "Xiang Du",
          "Nian Wang",
          "Mu Yuan",
          "Xianjun Yang"
        ],
        "url": "https://www.mdpi.com/2072-4292/14/20/5176/pdf",
        "ref_texts": "29. Liu, S.; Qi, L.; Qin, H.; Shi, J.; Jia, J. Path aggregation network for instance segmentation. In Proceedings of the 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), Salt Lake City, UT, USA, 18\u201323 June 2018; pp. 8759\u20138768.",
        "ref_ids": [
          "29"
        ]
      },
      "Small object detection method with shallow feature fusion network for chip surface defect detection": {
        "authors": [
          "Haixin Huang"
        ],
        "url": "https://www.nature.com/articles/s41598-022-07654-x.pdf",
        "ref_texts": ""
      },
      "YOLO-GD: a deep learning-based object detection algorithm for empty-dish recycling robots": {
        "authors": [
          "Xuebin Yue",
          "Hengyi Li",
          "Masao Shimizu",
          "Sadao Kawamura",
          "Lin Meng"
        ],
        "url": "https://www.mdpi.com/2075-1702/10/5/294/pdf",
        "ref_texts": "47. Liu, S.; Qi, L.; Qin, H.; Shi, J.; Jia, J. Path Aggregation Network for Instance Segmentation. arXiv 2018 , arXiv:1803.01534.",
        "ref_ids": [
          "47"
        ]
      },
      "Fast and precise detection of litchi fruits for yield estimation based on the improved YOLOv5 model": {
        "authors": [
          "Yuanhong Li",
          "Yubin Lan"
        ],
        "url": "https://www.frontiersin.org/articles/10.3389/fpls.2022.965425/pdf",
        "ref_texts": "6503 Liang, C., Xiong, J., Zheng, Z., Zhong, Z., Li, Z., Chen, S., et al. (2020). A visual detection method for nighttime litchi fruits and fruiting stems. Comput. Electron. Agric. 169:105192. doi: 10.1016/j.compag.2019.105192 Liu, G., Nouaze, J., Mbouembe, P., and Kim, J. (2020). YOLO-tomato: a robust algorithm for tomato detection based on YOLOv3. Sensors Basel 20:2145. doi: 10.3390/s20072145 Liu, S., Qi, L., Qin, H., Shi, J., and Jia, J. (2018). \u201cPath aggregation network for instance segmentation, \u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Salt Lake City, UT, 8759\u20138768. doi: 10.1109/CVPR.2018."
      },
      "Salient object detection via dynamic scale routing": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2210.13821",
        "ref_texts": "[67] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia, \u201cPath aggregation network for instance segmentation,\u201d in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , 2018, pp. 8759\u20138768.",
        "ref_ids": [
          "67"
        ]
      },
      "Pyramid architecture for multi-scale processing in point cloud segmentation": {
        "authors": [
          "Dong Nie",
          "Rui Lan",
          "Ling Wang",
          "Xiaofeng Ren"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2022/papers/Nie_Pyramid_Architecture_for_Multi-Scale_Processing_in_Point_Cloud_Segmentation_CVPR_2022_paper.pdf",
        "ref_texts": "[26] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 8759\u20138768, 2018. 2",
        "ref_ids": [
          "26"
        ]
      },
      "Fcdm: an improved forest fire classification and detection model based on yolov5": {
        "authors": [
          "Qilin Xue",
          "Haifeng Lin",
          "Fang Wang"
        ],
        "url": "https://www.mdpi.com/1999-4907/13/12/2129/pdf",
        "ref_texts": "28. Liu, S.; Qi, L.; Qin, H.; Shi, J.; Jia, J. Path aggregation network for instance segmentation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Salt Lake City, UT, USA, 18\u201322 June 2018; pp. 8759\u20138768.",
        "ref_ids": [
          "28"
        ]
      },
      "ASFF-YOLOv5: Multielement detection method for road traffic in UAV images based on multiscale feature fusion": {
        "authors": [
          "Mulan Qiu",
          "Liang Huang",
          "Hui Tang"
        ],
        "url": "https://www.mdpi.com/2072-4292/14/14/3498/pdf",
        "ref_texts": "28. Liu, S.; Qi, L.; Qin, H.F.; Shi, J.P .; Jia, J.Y. Path aggregation network for instance segmentation. In Proceedings of the 31st IEEE Conference on Computer Vision and Pattern Recognition, Salt Lake City, UT, USA, 18\u201323 June 2018.",
        "ref_ids": [
          "28"
        ]
      },
      "You should look at all objects": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2207.07889",
        "ref_texts": "24. Liu, S., Qi, L., Qin, H., Shi, J., Jia, J.: Path aggregation network for instance segmentation. In: Proceedings of the IEEE conference on computer vision and pattern recognition. pp. 8759\u20138768 (2018)",
        "ref_ids": [
          "24"
        ]
      },
      "Application of an improved YOLOv5 algorithm in real-time detection of foreign objects by ground penetrating radar": {
        "authors": [
          "Zhi Qiu",
          "Zuoxi Zhao",
          "Shaoji Chen",
          "Junyuan Zeng",
          "Yuan Huang",
          "Borui Xiang"
        ],
        "url": "https://www.mdpi.com/2072-4292/14/8/1895/pdf",
        "ref_texts": "32. Liu, S.; Qi, L.; Qin, H.; Shi, J.; Jia, J. Path Aggregation Network for Instance Segmentation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Salt Lake City, UT, USA, 18\u201323 June 2018; pp. 8759\u20138768.",
        "ref_ids": [
          "32"
        ]
      },
      "Multi-species individual tree segmentation and identification based on improved mask R-CNN and UAV imagery in mixed forests": {
        "authors": [
          "Chong Zhang",
          "Jiawei Zhou",
          "Huiwen Wang",
          "Tianyi Tan",
          "Mengchen Cui",
          "Zilu Huang",
          "Pei Wang",
          "Li Zhang"
        ],
        "url": "https://www.mdpi.com/2072-4292/14/4/874/pdf",
        "ref_texts": "46. Liu, S.; Qi, L.; Qin, H.; Shi, J.; Jia, J. Path Aggregation Network for Instance Segmentation. In Proceedings of the 2018, IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), Salt Lake City, UT, USA, 18\u201323 June 2018; Institute of Electrical and Electronics Engineers (IEEE): New York, NY, USA, 2018; pp. 8759\u20138768. [CrossRef]",
        "ref_ids": [
          "46"
        ]
      },
      "Semantic image segmentation: Two decades of research": {
        "authors": [],
        "url": "https://www.nowpublishers.com/article/DownloadSummary/CGV-095",
        "ref_texts": "2724. Liu, S., L. Qi, H. Qin, J. Shi, and J. Jia. (2018b). \u201cPath Aggregation Network for Instance Segmentation\u201d. In: CVPR. Liu, W., A. Rabinovich, and A. C. Berg. (2016). \u201cParseNet: Looking Wider to See Better\u201d. In: ICLR Workshops. Liu, X., L. Song, S. Liu, and Y. Zhang. (2021a). \u201cA Review of DeepLearning-Based Medical Image Segmentation Methods\u201d. Sustainability. 13(3): 1224. Liu, X., Z. Guo, S. Li, F. Xing, J. You, C. -C. J. Kuo, G. El Fakhri, and J. Woo. (2021b). \u201cAdversarial Unsupervised Domain Adaptation With Conditional and Label Shift: Infer, Align and Iterate\u201d. In: ICCV. Liu, Y., W. Zhang, and J. Wang. (2021c). \u201cSource-Free Domain Adaptation for Semantic Segmentation\u201d. In: CVPR. Liu, Z., Y. Lin, Y. Cao, H. Hu, Y. Wei, Z. Zhang, S. Lin, and B. Guo.",
        "ref_ids": [
          "2724"
        ]
      },
      "Automated bone marrow cytology using deep learning to generate a histogram of cell types": {
        "authors": [
          "Rohollah Moosavi"
        ],
        "url": "https://www.nature.com/articles/s43856-022-00107-6.pdf",
        "ref_texts": "42. Liu, S., Qi, L., Qin, H., Shi, J. & Jia, J. Path aggregation network for instance segmentation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , 8759 \u20138768 (2018).",
        "ref_ids": [
          "42"
        ]
      },
      "Detection and recognition of drones based on a deep convolutional neural network using visible imagery": {
        "authors": [
          "Farhad Samadzadegan",
          "Farzaneh Dadrass",
          "Farnaz Ashtari",
          "Mehrnaz Gholamshahi"
        ],
        "url": "https://www.mdpi.com/2226-4310/9/1/31/pdf",
        "ref_texts": "55. Liu, S.; Qi, L.; Qin, H.; Shi, J.; Jia, J. Path Aggregation Network for Instance Segmentation. In Proceedings of the 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition, Salt Lake City, UT, USA, 18\u201328 June 2018; pp. 8759\u20138768.",
        "ref_ids": [
          "55"
        ]
      },
      "Tracking and counting of tomato at different growth period using an improving YOLO-deepsort network for inspection robot": {
        "authors": [
          "Yuhao Ge",
          "Sen Lin",
          "Yunhe Zhang",
          "Zuolin Li",
          "Hongtai Cheng",
          "Jing Dong",
          "Shanshan Shao",
          "Jin Zhang",
          "Xiangyu Qi",
          "Zedong Wu"
        ],
        "url": "https://www.mdpi.com/2075-1702/10/6/489/pdf",
        "ref_texts": "39. Liu, S.; Qi, L.; Qin, H.; Shi, J.; Jia, J. Path aggregation network for instance segmentation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Salt Lake City, UT, USA, 18\u201322 June 2018; pp. 8759\u20138768.",
        "ref_ids": [
          "39"
        ]
      },
      "Fully convolutional networks for panoptic segmentation with point-based supervision": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2108.07682",
        "ref_texts": "[35] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia, \u201cPath aggregation network for instance segmentation,\u201d in IEEE Conference on Computer Vision and Pattern Recognition , 2018.",
        "ref_ids": [
          "35"
        ]
      },
      "Image coding for machines with omnipotent feature learning": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2207.01932",
        "ref_texts": "54. Liu, S., Qi, L., Qin, H., Shi, J., Jia, J.: Path aggregation network for instance segmentation. In: CVPR. pp. 8759\u20138768 (2018)",
        "ref_ids": [
          "54"
        ]
      },
      "Attention-based multi-level feature fusion for object detection in remote sensing images": {
        "authors": [
          "Xiaohu Dong",
          "Yao Qin",
          "Yinghui Gao",
          "Ruigang Fu",
          "Songlin Liu",
          "Yuanxin Ye"
        ],
        "url": "https://www.mdpi.com/2072-4292/14/15/3735/pdf"
      },
      "Light field salient object detection: A review and benchmark": {
        "authors": [],
        "url": "https://link.springer.com/content/pdf/10.1007/s41095-021-0256-2.pdf",
        "ref_texts": "[97] Liu, S.; Qi, L.; Qin, H. F.; Shi, J. P.; Jia, J. Y. Path aggregation network for instance segmentation. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 8759\u20138768, 2018.",
        "ref_ids": [
          "97"
        ]
      },
      "Review of object instance segmentation based on deep learning": {
        "authors": [],
        "url": "https://www.spiedigitallibrary.org/journals/journal-of-electronic-imaging/volume-31/issue-4/041205/Review-of-object-instance-segmentation-based-on-deep-learning/10.1117/1.JEI.31.4.041205.pdf",
        "ref_texts": "74. S. Liu et al., \u201cPath aggregation network for instance segmentation, \u201dinProc. 31st IEEE/ CVF Conf. Comput. Vision and Pattern Recognit. , Utah (2018).",
        "ref_ids": [
          "74"
        ]
      },
      "MDDI-SCL: predicting multi-type drug-drug interactions via supervised contrastive learning": {
        "authors": [
          "Shenggeng Lin"
        ],
        "url": "https://link.springer.com/content/pdf/10.1186/s13321-022-00659-8.pdf",
        "ref_texts": ""
      },
      "Animal detection and classification from camera trap images using different mainstream object detection architectures": {
        "authors": [
          "Mengyu Tan",
          "Wentao Chao",
          "Ku Cheng",
          "Mo Zhou",
          "Yiwen Ma",
          "Xinyi Jiang",
          "Jianping Ge",
          "Lian Yu",
          "Limin Feng"
        ],
        "url": "https://www.mdpi.com/2076-2615/12/15/1976/pdf",
        "ref_texts": "40. Liu, S.; Qi, L.; Qin, H.; Shi, J.; Jia, J. Path aggregation network for instance segmentation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Salt Lake City, UT, USA, 18\u201323 June 2018; pp. 8759\u20138768.",
        "ref_ids": [
          "40"
        ]
      },
      "Distributed inference with deep learning models across heterogeneous edge devices": {
        "authors": [],
        "url": "https://iqua.ece.toronto.edu/papers/chenghao-infocom22.pdf",
        "ref_texts": "[4] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia, \u201cPath aggregation network for instance segmentation,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition , 2018, pp. 8759\u20138768.",
        "ref_ids": [
          "4"
        ]
      },
      "Vision transformer hashing for image retrieval": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2109.12564",
        "ref_texts": "[27] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 8759\u20138768, 2018. 1",
        "ref_ids": [
          "27"
        ]
      },
      "A new approach for detecting fundus lesions using image processing and deep neural network architecture based on YOLO model": {
        "authors": [
          "Carlos Santos",
          "Marilton Aguiar",
          "Daniel Welfer",
          "Bruno Belloni"
        ],
        "url": "https://www.mdpi.com/1424-8220/22/17/6441/pdf",
        "ref_texts": ""
      },
      "Underwater object detection algorithm based on attention mechanism and cross-stage partial fast spatial pyramidal pooling": {
        "authors": [
          "Jinghui Yan"
        ],
        "url": "https://www.frontiersin.org/articles/10.3389/fmars.2022.1056300/pdf",
        "ref_texts": "\u201cSsd: Single shot multibox detector, \u201dinEuropean Conference on computer vision (Berlin: Springer), 21 \u201337. Liu, T.-Y., and Tie, YL. (2009). Learning to rank for information retrieval. Found. Trends\u00aeInf. Retr. 3, 225 \u2013331. doi: 10.1561/1500000016 Liu, S., Qi, L., Qin, H., Shi, J., and Jia, J. (2018). \u201cPath aggregation network for instance segmentation, \u201dinProceedings of the IEEE conference on computer vision and pattern recognition . (NY: IEEE), 8759 \u20138768. Qiang, W., He, Y., Guo, Y., Li, B., and He, L. (2020). Exploring underwater target detection algorithm based on improved ssd. Xibei Gongye Daxue Xuebao/J. Northwest. Polytech. Univ. 38, 747 \u2013754. doi: 10.1051/jnwpu/20203840747 Qiu, S., Xu, M., Jin, W., Yang, J., and Guo, H. (2019). Radon transform detection method for underwater moving target based on water surface characteristic wave.Acta Optica Sin. 39, 25 \u201337. doi: 10.3788/AOS201939.1001003Redmon, J., Divvala, S., Girshick, R., and Farhadi, A. (2016). \u201cYou only look once: Uni fied, real-time object detection, \u201dinProceedings of the IEEE conference on computer vision and pattern recognition . (NY: IEEE), 779 \u2013788. Redmon, J., and Farhadi, A. (2017). \u201cYolo9000: better, faster, stronger, \u201din Proceedings of the IEEE conference on computer vision and pattern recognition . (NY: IEEE), 7263 \u20137271. Redmon, J., and Farhadi, A. (2018). Yolov3: An incremental improvement. arXiv , 02767. doi: 10.48550/arXiv.1804.02767 Ren, S., He, K., Girshick, R., and Sun, J. (2015). Faster r-cnn: Towards real-time object detection with region proposal networks. Adv. Neural Inf. Process. Syst. 28, 91\u201399. doi: 10.48550/arXiv.1506.01497 Shi, P., Xu, X., Ni, J., Xin, Y., Huang, W., and Han, S. (2021). Underwater biological detection algorithm based on improved faster-rcnn. Water 13, 2420. doi: 10.3390/w13172420 Tan, M., Pang, R., and Le, Q. V. (2020). \u201cEfficientdet: Scalable and ef ficient object detection, \u201dinProceedings of the IEEE/CVF conference on computer vision and pattern recognition . (NY: IEEE), 10781 \u201310790. Tinghui, H., Xinyu, G., Chunde, H., and Yueping, H. (2022). Research on underwater target detection algorithm based on fattention-yolov5. Microelectron. Comput. 39, 60 \u201368. doi: 10.19304/J.ISSN1000-7180.2021.1261 Villon, S., Chaumont, M., Subsol, G., Ville \u0301ger, S., Claverie, T., and Mouillot, D."
      },
      "Small-object detection for UAV-based images using a distance metric method": {
        "authors": [
          "Helu Zhou",
          "Aitong Ma",
          "Yifeng Niu",
          "Zhaowei Ma"
        ],
        "url": "https://www.mdpi.com/2504-446X/6/10/308/pdf",
        "ref_texts": "6. Liu, S.; Qi, L.; Qin, H.; Shi, J.; Jia, J. Path Aggregation Network for Instance Segmentation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Salt Lake City, UT, USA, 18\u201323 June 2018.",
        "ref_ids": [
          "6"
        ]
      },
      "Surface defect detection model for aero-engine components based on improved YOLOv5": {
        "authors": [
          "Xin Li",
          "Cheng Wang",
          "Haijuan Ju",
          "Zhuoyue Li"
        ],
        "url": "https://www.mdpi.com/2076-3417/12/14/7235/pdf",
        "ref_texts": "20. Liu, S.; Qi, L.; Qin, H.; Shi, J.; Jia, J. Path Aggregation Network for Instance Segmentation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Salt Lake City, UT, USA, 18\u201323 June 2018; pp. 8759\u20138768.",
        "ref_ids": [
          "20"
        ]
      },
      "One-stage disease detection method for maize leaf based on multi-scale feature fusion": {
        "authors": [
          "Ying Li",
          "Shiyu Sun",
          "Changshe Zhang",
          "Guangsong Yang",
          "Qiubo Ye"
        ],
        "url": "https://www.mdpi.com/2076-3417/12/16/7960/pdf",
        "ref_texts": "39. Liu, S.; Qi, L.; Qin, H.; Shi, J.; Jia, J. Path Aggregation Network for Instance Segmentation. In Proceedings of the 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), Salt Lake City, UT, USA, 18\u201323 June 2018.",
        "ref_ids": [
          "39"
        ]
      },
      "Teacher\u2013student behavior recognition in classroom teaching based on improved YOLO-v4 and Internet of Things technology": {
        "authors": [
          "Henghuai Chen",
          "Jiansheng Guan"
        ],
        "url": "https://www.mdpi.com/2079-9292/11/23/3998/pdf",
        "ref_texts": "36. Liu, S.; Qi, L.; Qin, H.; Shi, J.; Jia, J. Path aggregation network for instance segmentation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Salt Lake City, UT, USA, 18\u201323 June 2018; pp. 8759\u20138768.",
        "ref_ids": [
          "36"
        ]
      },
      "Research on mask-wearing detection algorithm based on improved YOLOv5": {
        "authors": [
          "Shuyi Guo",
          "Lulu Li",
          "Tianyou Guo",
          "Yunyu Cao",
          "Yinlei Li"
        ],
        "url": "https://www.mdpi.com/1424-8220/22/13/4933/pdf",
        "ref_texts": "31. Liu, S.; Qi, L.; Qin, H.; Shi, J.; Jia, J. Path aggregation network for instance segmentation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Salt Lake City, UT, USA, 18\u201323 June 2018; pp. 8759\u20138768. [CrossRef]",
        "ref_ids": [
          "31"
        ]
      },
      "Application of convolutional neural network-based detection methods in fresh fruit production: a comprehensive review": {
        "authors": [
          "Juntao Xiong",
          "Zhaoguo Zhang"
        ],
        "url": "https://www.frontiersin.org/journals/plant-science/articles/10.3389/fpls.2022.868745/pdf",
        "ref_texts": "673-7 Liu, S., Jia, J., Fidler, S., and Urtasun, R. (2017). \u201cSGN: sequential grouping networks for instance segmentation, \u201d in Proceedings of the 2017 IEEE International Conference on Computer Vision (ICCV) , Venice, 3516\u20133524. Liu, S., Qi, L., Qin, H., Shi, J., and Jia, J. (2018). \u201cPath aggregation network for instance segmentation, \u201d in Proceedings of the 2018 IEEE Conference on Computer Vision and Pattern , Salt Lake City, UT. Liu, S., Qi, X., Shi, J., Zhang, H., and Jia, J. (2016). \u201cMufti-scale Patch aggregation(MPA)for Simultaneous Detection and Segmentation}G], \u201d in Proceedings of the 2016 IEEE Conference on Computer Vision and Pattern Recognition , Las Vegas, NV , 3141\u20133149. Liu, W., Anguelov, D., Erhan, D., Szegedy, C., Reed, S., Fu, C., et al. (2016). \u201cSSD: single shot MultiBox detector, \u201d in Computer Vision \u2013 ECCV 2016. ECCV 2016. Lecture Notes in Computer Science , eds B. Leibe, J. Matas, N. Sebe, and M. Welling (Cham: Springer), 21\u201337. doi: 10.1007/978-3-319-46448-0_2 Liu, Y. P., Y ang, C., Ling, H., Mabu, S., and Kuremoto, T. (2018). \u201cA visual system of citrus picking robot using convolutional neural networks, \u201d in Proceedings of the 2018 5th International Conference on Systems and Informatics (ICSAI) , Nanjing, 344\u2013349. doi: 10.1109/ICSAI.2018.8599325 Liu, Z., Wu, J., Fu, L., Majeed, Y., Feng, Y., Li, R., et al. (2019). Improved kiwifruit detection using pre-trained VGG16 with RGB and NIR information fusion. IEEE Access 8, 2327\u20132336. doi: 10.1109/ACCESS.2019.2962513 Longye, X., Zhuo, W., Haishen, L., Xilong, K., and Changhui, Y. (2019). Overlapping citrus segmentation and reconstruction based on mask R-CNN model and concave region simplification and distance analysis. J. Phys. Conf. Ser.1345:32064. doi: 10.1088/1742-6596/1345/3/032064 Majeed, Y., Zhang, J., Zhang, X., Fu, L., Karkee, M., Zhang, Q., et al. (2020). Deep learning based segmentation for automated training of apple trees on trellis wires. Comput. Electron. Agric. 170:105277. doi: 10.1016/j.compag.2020.105277 Mohsen, Y. N., Dan, T., and Milad, E. (2021). Using hybrid artificial intelligence and evolutionary optimization algorithms for estimating soybean yield and fresh biomass using hyperspectral vegetation indices. Remote Sens. 13:2555. doi: 10.3390/rs13132555 Momeny, M., Jahanbakhshi, A., Jafarnezhad, K., and Zhang, Y. (2020). Accurate classification of cherry fruit using deep CNN based on hybrid pooling approach. Postharvest Biol. Technol. 166:111204. doi: 10.1016/j.postharvbio.2020.1"
      },
      "Detection of unauthorized unmanned aerial vehicles using YOLOv5 and transfer learning": {
        "authors": [
          "Nader Al",
          "Abdulrahman Alenezi",
          "Turki Alanazi",
          "Abdulrahman Senyor",
          "Naif Alanezi",
          "Bandar Alotaibi",
          "Munif Alotaibi",
          "Abdul Razaque",
          "Abdelaziz Abdelhamid",
          "Aziz Alotaibi"
        ],
        "url": "https://www.mdpi.com/2079-9292/11/17/2669/pdf",
        "ref_texts": "37. Liu, S.; Qi, L.; Qin, H.; Shi, J.; Jia, J. Path aggregation network for instance segmentation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Salt Lake City, UT, USA, 18\u201322 June 2018; pp. 8759\u20138768.",
        "ref_ids": [
          "37"
        ]
      },
      "High-precision wheat head detection model based on one-stage network and GAN model": {
        "authors": [],
        "url": "https://www.frontiersin.org/articles/10.3389/fpls.2022.787852/pdf",
        "ref_texts": "(2017).Featurepyramidnetworksforobjectdetection. ProceedingsoftheIEEE conferenceoncomputervisionandpatternrecognition .2117\u20132125. Lin, T.-Y., Maire, M., Belongie, S., Hays, J., Perona, P., Ramana n, D., et al. (2014). \u201cMicrosoft COCO: common objects in context,\u201d in European Conference on Computer Vision (Zurich: Springer), 740\u2013755. doi:10.1007/978-3-319-10602-1_48 Liu, S., Qi, L., Qin, H., Shi, J., and Jia, J. (2018). Path aggreg ation network for instance segmentation,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (Salt Lake City, UT), 8759\u20138768. doi:10.1109/CVPR.2018.00913 Liu,W.,Anguelov,D.,Erhan,D.,Szegedy,C.,Reed,S.,Fu,C. -Y.,etal.(2016).\u201cSSD: single shot multibox detector,\u201d in European Conference on Computer Vision (Springer),21\u201337.doi:10.1007/978-3-319-46448-0_2Liu,Z.,Sun,H.,andHuangJ.(2007).Classificationofemptyandhe althypanicles inriceplantsbyhyperspectralreflectancebasedonlearningvectorqu antization (LVQ)neuralnetwork. Chin.J.RiseSci. 21,664\u2013668.Availableonlineat:http:// www.ricesci.cn/CN/Y2007/V21/I6/664 Redmon, J., Divvala, S., Girshick, R., and Farhadi, A. (2016). \u201cYou only look once:unified,real-timeobjectdetection,\u201din ProceedingsoftheIEEEConference on Computer Vision and Pattern Recognition (Las Vegas, NV), 779\u2013788. doi:10.1109/CVPR.2016.91 Redmon, J., and Farhadi, A. (2017). \u201cYOLO9000: better, faste r, stronger,\u201d in ProceedingsoftheIEEEConferenceonComputerVisionandPat ternRecognition (Honolulu),7263\u20137271.doi:10.1109/CVPR.2017.690 Redmon,J.,andFarhadi,A.(2018).YOLOV3:anincrementalimprove ment.arXiv preprintarXiv:1804.02767 .doi:10.48550/arxiv.1804.02767 Saleh, H., Alharbi, A., and Alsamhi, S. H. (2021). Opcnn-fake: Optimiz ed convolutional neural network for fake news detection. IEEE Access 9, 129471\u2013"
      },
      "Automatic extraction of damaged houses by earthquake based on improved YOLOv5: A case study in Yangbi": {
        "authors": [
          "Yafei Jing",
          "Yuhuan Ren",
          "Yalan Liu",
          "Dacheng Wang",
          "Linjun Yu"
        ],
        "url": "https://www.mdpi.com/2072-4292/14/2/382/pdf",
        "ref_texts": "32. Liu, S.; Qi, L.; Qin, H.; Shi, J.; Jia, J. Path Aggregation Network for Instance Segmentation. In Proceedings of the 2018 IEEE Conference on Computer Vision and Pattern Recognition, Salt Lake City, UT, USA, 18\u201323 June 2018; pp. 8759\u20138768. [CrossRef]",
        "ref_ids": [
          "32"
        ]
      },
      "SharpContour: a contour-based boundary refinement approach for efficient and accurate instance segmentation": {
        "authors": [
          "Chenming Zhu",
          "Xuanye Zhang",
          "Yanran Li",
          "Liangdong Qiu",
          "Kai Han",
          "Xiaoguang Han"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2022/papers/Zhu_SharpContour_A_Contour-Based_Boundary_Refinement_Approach_for_Efficient_and_Accurate_CVPR_2022_paper.pdf",
        "ref_texts": "[24] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 8759\u20138768, 2018. 2",
        "ref_ids": [
          "24"
        ]
      },
      "A two-stage seismic damage assessment method for small, dense, and imbalanced buildings in remote sensing images": {
        "authors": [
          "Yu Wang",
          "Liangyi Cui",
          "Chenzong Zhang",
          "Wenli Chen",
          "Yang Xu",
          "Qiangqiang Zhang"
        ],
        "url": "https://www.mdpi.com/2072-4292/14/4/1012/pdf",
        "ref_texts": "47. Liu, S.; Qi, L.; Qin, H.; Shi, J.; Jia, J. Path aggregation network for instance segmentation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Salt Lake City, UT, USA, 18\u201322 June 2018; pp. 8759\u20138768. [CrossRef]",
        "ref_ids": [
          "47"
        ]
      },
      "Research on steel surface defect detection based on YOLOv5 with attention mechanism": {
        "authors": [
          "Jianting Shi",
          "Jian Yang",
          "Yingtao Zhang"
        ],
        "url": "https://www.mdpi.com/2079-9292/11/22/3735/pdf",
        "ref_texts": "31. Liu, S.; Qi, L.; Qin, H.; Shi, J.; Jia, J. Path aggregation network for instance segmentation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Salt Lake City, UT, USA, 18\u201323 June 2018; pp. 8759\u20138768.",
        "ref_ids": [
          "31"
        ]
      },
      "Consecutive pre-training: A knowledge transfer learning strategy with relevant unlabeled data for remote sensing domain": {
        "authors": [
          "Tong Zhang",
          "Peng Gao",
          "Hao Dong",
          "Yin Zhuang",
          "Guanqun Wang",
          "Wei Zhang",
          "He Chen"
        ],
        "url": "https://www.mdpi.com/2072-4292/14/22/5675/pdf",
        "ref_texts": "90. Liu, S.; Qi, L.; Qin, H.; Shi, J.; Jia, J. Path aggregation network for instance segmentation. In Proceedings of the 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition, Salt Lake City, UT, USA, 18\u201323 June 2018; pp. 8759\u20138768.",
        "ref_ids": [
          "90"
        ]
      },
      "Visolo: Grid-based space-time aggregation for efficient online video instance segmentation": {
        "authors": [
          "Su Ho",
          "Sukjun Hwang",
          "Seoung Wug",
          "Yeonchool Park",
          "Hyunwoo Kim",
          "Jung Kim",
          "Seon Joo"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2022/papers/Han_VISOLO_Grid-Based_Space-Time_Aggregation_for_Efficient_Online_Video_Instance_Segmentation_CVPR_2022_paper.pdf",
        "ref_texts": "[21] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , June 2018. 2",
        "ref_ids": [
          "21"
        ]
      },
      "A survey on object instance segmentation": {
        "authors": [
          "Rabi Sharma"
        ],
        "url": "https://link.springer.com/content/pdf/10.1007/s42979-022-01407-3.pdf",
        "ref_texts": ""
      },
      "Underwater object detection based on improved efficientdet": {
        "authors": [
          "Jiaqi Jia",
          "Min Fu",
          "Xuefeng Liu",
          "Bing Zheng"
        ],
        "url": "https://www.mdpi.com/2072-4292/14/18/4487/pdf",
        "ref_texts": "38. Liu, S.; Qi, L.; Qin, H.; Shi, J.; Jia, J. Path Aggregation Network for Instance Segmentation. In Proceedings of the 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition, Salt Lake City, UT, USA, 18\u201323 June 2018; pp. 8759\u20138768.",
        "ref_ids": [
          "38"
        ]
      },
      "Caa-yolo: Combined-attention-augmented yolo for infrared ocean ships detection": {
        "authors": [
          "Jing Ye",
          "Zhaoyu Yuan",
          "Cheng Qian",
          "Xiaoqiong Li"
        ],
        "url": "https://www.mdpi.com/1424-8220/22/10/3782/pdf",
        "ref_texts": "22. Liu, S.; Qi, L.; Qin, H.; Shi, J.; Jia, J. Path aggregation network for instance segmentation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Salt Lake City, UT, USA, 18\u201323 June 2018; pp. 8759\u20138768.",
        "ref_ids": [
          "22"
        ]
      },
      "Light-YOLOv5: A lightweight algorithm for improved YOLOv5 in complex fire scenarios": {
        "authors": [
          "Hao Xu",
          "Bo Li",
          "Fei Zhong"
        ],
        "url": "https://www.mdpi.com/2076-3417/12/23/12312/pdf",
        "ref_texts": "20. Liu, S.; Qi, L.; Qin, H.; Shi, J.; Jia, J. Path aggregation network for instance segmentation. In Proceedings of the IEEE conference on Computer Vision and Pattern Recognition, Salt Lake City, UT, USA, 18\u201323 June 2018; pp. 8759\u20138768.",
        "ref_ids": [
          "20"
        ]
      },
      "Excavating roi attention for underwater object detection": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2206.12128",
        "ref_texts": "[26] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia, \u201cPath aggregation network for instance segmentation,\u201d inProceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2018.",
        "ref_ids": [
          "26"
        ]
      },
      "A scale-aware pyramid network for multi-scale object detection in SAR images": {
        "authors": [],
        "url": "https://www.mdpi.com/2072-4292/14/4/973/pdf",
        "ref_texts": "30. Liu, S.; Qi, L.; Qin, H.; Shi, J.; Jia, J. Path aggregation network for instance segmentation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Salt Lake City, UT, USA, 18\u201323 June 2018; pp. 8759\u20138768.",
        "ref_ids": [
          "30"
        ]
      },
      "Noisy boundaries: Lemon or lemonade for semi-supervised instance segmentation?": {
        "authors": [
          "Zhenyu Wang",
          "Yali Li",
          "Shengjin Wang"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Noisy_Boundaries_Lemon_or_Lemonade_for_Semi-Supervised_Instance_Segmentation_CVPR_2022_paper.pdf",
        "ref_texts": "[37] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In CVPR , 2018. 2",
        "ref_ids": [
          "37"
        ]
      },
      "Instance and panoptic segmentation using conditional convolutions": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2102.03026",
        "ref_texts": "[21] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia, \u201cPath aggregation network for instance segmentation,\u201d in Proc. IEEE Conf. Comp. Vis. Patt. Recogn. , pp. 8759\u20138768, 2018.",
        "ref_ids": [
          "21"
        ]
      },
      "Attentional feature refinement and alignment network for aircraft detection in SAR imagery": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2201.07124",
        "ref_texts": "[46] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia, \u201cPath aggregation network for instance segmentation,\u201d in IEEE Conference on Computer Vision and Pattern Recognition , 2018, pp. 8759\u20138768. 3",
        "ref_ids": [
          "46"
        ]
      },
      "Fooling the eyes of autonomous vehicles: Robust physical adversarial examples against traffic sign recognition systems": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2201.06192",
        "ref_texts": "[28] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia, \u201cPath aggregation network for instance segmentation,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition , 2018, pp. 8759\u20138768.",
        "ref_ids": [
          "28"
        ]
      },
      "A comprehensive study of real-time object detection networks across multiple domains: A survey": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2208.10895",
        "ref_texts": "35 Published in Transactions on Machine Learning Research (08/2022) Tsung-Yi Lin, Priya Goyal, Ross Girshick, Kaiming He, and Piotr Dollar. Focal loss for dense object detection. In Proceedings of the IEEE International Conference on Computer Vision (ICCV) , Oct 2017b. Li Liu, Wanli Ouyang, Xiaogang Wang, Paul Fieguth, Jie Chen, Xinwang Liu, and Matti Pietik\u00e4inen. Deep learning for generic object detection: A survey. arXiv preprint arXiv:1809.02165 , 2018a. Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. InProceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , June 2018b. Wei Liu, Dragomir Anguelov, Dumitru Erhan, Christian Szegedy, Scott Reed, Cheng-Yang Fu, and Alexander C Berg. Ssd: Single shot multibox detector. In European conference on computer vision , pp. 21\u201337. Springer, 2016. Yang Liu, Peng Sun, Nickolas Wergeles, and Yi Shang. A survey and performance evaluation of deep learning methods for small object detection. Expert Systems with Applications , 172:114602, 2021. ISSN"
      },
      "Human instance matting via mutual guidance and multi-instance refinement": {
        "authors": [
          "Yanan Sun",
          "Keung Tang",
          "Wing Tai"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2022/papers/Sun_Human_Instance_Matting_via_Mutual_Guidance_and_Multi-Instance_Refinement_CVPR_2022_paper.pdf",
        "ref_texts": "[40] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In IEEE Conference on Computer Vision and Pattern Recognition , 2018. 2",
        "ref_ids": [
          "40"
        ]
      },
      "A comprehensive review of modern object segmentation approaches": {
        "authors": [],
        "url": "https://www.nowpublishers.com/article/DownloadSummary/CGV-097",
        "ref_texts": "2104. Liu, S., L. Qi, H. Qin, J. Shi, and J. Jia. (2018). \u201cPath aggregation network for instance segmentation\u201d. In: Proceedings of the IEEE conference on computer vision and pattern recognition . 8759\u20138768. Liu,W.,D.Anguelov,D.Erhan,C.Szegedy,S.Reed,C. -Y.Fu,andA.C. Berg. (2016a). \u201cSsd: Single shot multibox detector\u201d. In: European conference on computer vision . Springer. 21\u201337. Liu, W., A. Rabinovich, and A. Berg. (2016b). \u201cParseNet: Looking Wider to See Better\u201d. In: Liu, X., Z. Han, Y. -S. Liu, and M. Zwicker. (2019b). \u201cPoint2sequence: Learning the shape representation of 3d point clouds with an attention-based sequence to sequence network\u201d. In: Proceedings of the AAAI Conference on Artificial Intelligence . Vol. 33. No. 01.",
        "ref_ids": [
          "2104"
        ]
      },
      "A multi-scale feature pyramid network for detection and instance segmentation of marine ships in SAR images": {
        "authors": [
          "Zequn Sun",
          "Chunning Meng",
          "Jierong Cheng",
          "Zhiqing Zhang",
          "Shengjiang Chang"
        ],
        "url": "https://www.mdpi.com/2072-4292/14/24/6312/pdf",
        "ref_texts": "50. Liu, S.; Qi, L.; Qin, H.; Shi, J.; Jia, J. Path Aggregation Network for Instance Segmentation. In Proceedings of the 31st IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), Salt Lake City, UT, USA, 18\u201323 June 2018; pp. 8759\u20138768.",
        "ref_ids": [
          "50"
        ]
      },
      "R-YOLO: A YOLO-based method for arbitrary-oriented target detection in high-resolution remote sensing images": {
        "authors": [
          "Yongjie Hou",
          "Gang Shi",
          "Yingxiang Zhao",
          "Fan Wang",
          "Xian Jiang",
          "Rujun Zhuang",
          "Yunfei Mei",
          "Xinjiang Ma"
        ],
        "url": "https://www.mdpi.com/1424-8220/22/15/5716/pdf",
        "ref_texts": "21. Liu, S.; Qi, L.; Qin, H.; Shi, J.; Jia, J. Path aggregation network for instance segmentation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Salt Lake, UT, USA, 18\u201323 June 2018; pp. 8759\u20138768.",
        "ref_ids": [
          "21"
        ]
      },
      "Evaluation of deep learning algorithms for semantic segmentation of car parts": {
        "authors": [
          "Kitsuchart Pasupa"
        ],
        "url": "https://link.springer.com/content/pdf/10.1007/s40747-021-00397-8.pdf",
        "ref_texts": "22. Liu S, Qi L, Qin H, Shi J, Jia J (2018) Path aggregation network for instance segmentation. In: Proceedings of the IEEE/CVF con-ference on computer vision and pattern recognition (CVPR), p8759\u20138768",
        "ref_ids": [
          "22"
        ]
      },
      "A water level measurement approach based on YOLOv5s": {
        "authors": [
          "Guangchao Qiao",
          "Mingxiang Yang",
          "Hao Wang"
        ],
        "url": "https://www.mdpi.com/1424-8220/22/10/3714/pdf",
        "ref_texts": "22. Liu, S.; Qi, L.; Qin, H.; Shi, J.; Jia, J. Path Aggregation Network for Instance Segmentation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Salt Lake City, UT, USA, 18\u201323 June 2018; pp. 8759\u20138768. [CrossRef]",
        "ref_ids": [
          "22"
        ]
      },
      "Towards high accuracy pedestrian detection on edge gpus": {
        "authors": [
          "Huaping Zhou",
          "Tao Wu",
          "Kelei Sun",
          "Chunjiong Zhang"
        ],
        "url": "https://www.mdpi.com/1424-8220/22/16/5980/pdf",
        "ref_texts": "12. Liu, S.; Qi, L.; Qin, H.; Shi, J.; Jia, J. Path Aggregation Network for Instance Segmentation. In Proceedings of the IEEE/CVF Conference on Computer Vis-ion and Pattern Recognition, CVPR, Salt Lake City, UT, USA, 18\u201323 June 2018; pp. 3\u201319.",
        "ref_ids": [
          "12"
        ]
      },
      "Application of low-altitude UAV remote sensing image object detection based on improved YOLOv5": {
        "authors": [
          "Ziran Li",
          "Akio Namiki",
          "Satoshi Suzuki",
          "Qi Wang",
          "Tianyi Zhang",
          "Wei Wang"
        ],
        "url": "https://www.mdpi.com/2076-3417/12/16/8314/pdf",
        "ref_texts": "35. Liu, S.; Qi, L.; Qin, H.; Shi, J.; Jia, J. Path Aggregation Network for Instance Segmentation. In Proceedings of the 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), Salt Lake City, UT, USA, 18\u201323 June 2018; pp. 8759\u20138768.",
        "ref_ids": [
          "35"
        ]
      },
      "Semantic-aligned fusion transformer for one-shot object detection": {
        "authors": [
          "Yizhou Zhao",
          "Xun Guo",
          "Yan Lu"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2022/papers/Zhao_Semantic-Aligned_Fusion_Transformer_for_One-Shot_Object_Detection_CVPR_2022_paper.pdf",
        "ref_texts": "[35] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In CVPR , pages 8759\u20138768, 2018. 3",
        "ref_ids": [
          "35"
        ]
      },
      "YOLO-ReT: Towards high accuracy real-time object detection on edge GPUs": {
        "authors": [
          "Prakhar Ganesh",
          "Yao Chen",
          "Yin Yang",
          "Deming Chen",
          "Marianne Winslett"
        ],
        "url": "http://openaccess.thecvf.com/content/WACV2022/papers/Ganesh_YOLO-ReT_Towards_High_Accuracy_Real-Time_Object_Detection_on_Edge_GPUs_WACV_2022_paper.pdf",
        "ref_texts": "[30] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 8759\u20138768, 2018.",
        "ref_ids": [
          "30"
        ]
      },
      "Detecting human actions in drone images using YOLOv5 and stochastic gradient boosting": {
        "authors": [
          "Tasweer Ahmad",
          "Marc Cavazza",
          "Yutaka Matsuo",
          "Helmut Prendinger"
        ],
        "url": "https://www.mdpi.com/1424-8220/22/18/7020/pdf",
        "ref_texts": "55. Liu, S.; Qi, L.; Qin, H.; Shi, J.; Jia, J. Path aggregation network for instance segmentation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Salt Lake City, UT, USA, 18\u201323 June 2018.",
        "ref_ids": [
          "55"
        ]
      },
      "RS-YOLOX: A high-precision detector for object detection in satellite remote sensing images": {
        "authors": [
          "Lei Yang",
          "Guowu Yuan",
          "Hao Zhou",
          "Hongyu Liu",
          "Jian Chen",
          "Hao Wu"
        ],
        "url": "https://www.mdpi.com/2076-3417/12/17/8707/pdf",
        "ref_texts": "32. Liu, S.; Qi, L.; Qin, H.; Shi, J.; Jia, J. Path aggregation network for instance segmentation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, Salt Lake City, UT, USA, 18\u201323 June 2018; pp. 8759\u20138768. Available online: https://ieeexplore.ieee.org/document/8579011 (accessed on 10 March 2022).",
        "ref_ids": [
          "32"
        ]
      },
      "Rapid target detection of fruit trees using UAV imaging and improved light YOLOv4 algorithm": {
        "authors": [
          "Yuchao Zhu",
          "Jun Zhou",
          "Yinhui Yang",
          "Lijuan Liu",
          "Fei Liu",
          "Wenwen Kong"
        ],
        "url": "https://www.mdpi.com/2072-4292/14/17/4324/pdf",
        "ref_texts": "38. Liu, S.; Qi, L.; Qin, H.; Shi, J.; Jia, J. Path aggregation network for instance segmentation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Salt Lake City, UT, USA, 18\u201322 June 2018; pp. 8759\u20138768.",
        "ref_ids": [
          "38"
        ]
      },
      "Ship detection in SAR images based on feature enhancement Swin transformer and adjacent feature fusion": {
        "authors": [
          "Kuoyang Li",
          "Min Zhang",
          "Maiping Xu",
          "Rui Tang",
          "Liang Wang",
          "Hai Wang"
        ],
        "url": "https://www.mdpi.com/2072-4292/14/13/3186/pdf",
        "ref_texts": "42. Liu, S.; Qi, L.; Qin, H.; Shi, J.; Jia, J. Path Aggregation Network for Instance Segmentation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Salt Lake City, UT, USA, 18\u201322 June 2018; pp. 8759\u20138768.",
        "ref_ids": [
          "42"
        ]
      },
      "Prompt-matched semantic segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2208.10159",
        "ref_texts": "[39] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 8759\u20138768, 2018. 1",
        "ref_ids": [
          "39"
        ]
      },
      "Large-field contextual feature learning for glass detection": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2209.04639",
        "ref_texts": "[19] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia, \u201cPath aggregation network for instance segmentation,\u201d in CVPR , 2018.",
        "ref_ids": [
          "19"
        ]
      },
      "High-quality entity segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2211.05776",
        "ref_texts": "[31] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In CVPR , 2018. 3[32] Ze Liu, Yutong Lin, Yue Cao, Han Hu, Yixuan Wei, Zheng Zhang, Stephen Lin, and Baining Guo. Swin transformer: Hierarchical vision transformer using shifted windows. In Proceedings of the IEEE/CVF International Conference on Computer Vision , 2021. 1, 8, 9",
        "ref_ids": [
          "31",
          "32"
        ]
      },
      "Rubber leaf disease recognition based on improved deep convolutional neural networks with a cross-scale attention mechanism": {
        "authors": [
          "Wei Fu",
          "Juan Wang"
        ],
        "url": "https://www.frontiersin.org/articles/10.3389/fpls.2022.829479/pdf",
        "ref_texts": "(2017). MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications . Available online at: http://arxiv.org/abs/1704.04861 (accessed October 24, 2021). Frontiers in Plant Science | www.frontiersin.org 11 February 2022 | Volume 13 | Article 829479 fpls-13-829479 February 22, 2022 Time: 14:10 # 12 Zeng et al. Diagnosis of Typical Rubber Leaf Diseases Hu, J., Shen, L., and Sun, G. (2018). \u201cSqueeze-and-excitation networks, \u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , (New Jersey, NJ: IEEE), 7132\u20137141. Hughes, D. P., and Salathe, M. (2015). An open Access Repository Of Images On Plant Health To Enable The Development Of Mobile Disease Diagnostics . Available online at: http://arxiv.org/abs/1511.08060 (accessed November 10, 2021). Li, D., and Zhang, S. (2020). Natural rubber industry development policy analysis:borders and bonus. Issues For. Econ. 40, 208\u2013215. Li, Z., Y ang, Y., Li, Y., Guo, R. H., Y ang, J., and Yue, J. (2020). A solanaceae disease recognition model based on SE-Inception. Comput. Electron. Agric. 178:105792. doi: 10.1016/j.compag.2020.105792 Liu, B., Ding, Z., Tian, L., He, D., Li, S., and Wang, H. (2020). Grape leaf disease identification using improved deep convolutional neural networks. Front. Plant Sci.11:1082. doi: 10.3389/fpls.2020.01082 Liu, S., Qi, L., Qin, H., Shi, J., and Jia, J. (2018). PANet: Path Aggregation Network for Instance Segmentation. (arXiv:1803.01534v3 [cs.CV] UPDATED). Cvpr, 8759\u2013"
      },
      "Deep learning based automatic grape downy mildew detection": {
        "authors": [
          "Yongliang Qiao",
          "Dongjian He"
        ],
        "url": "https://www.frontiersin.org/journals/plant-science/articles/10.3389/fpls.2022.872107/pdf",
        "ref_texts": "01082 Liu, E., Gold, K. M., Combs, D., Cadle-Davidson, L., and Jiang, Y . (2021). \u201cDeep learning-based autonomous downy mildew detection and severity es timation invineyards,\u201din 2021ASABEAnnualInternationalVirtualMeeting (American SocietyofAgriculturalandBiologicalEngineers). Liu, J., and Wang, X. (2020). Tomato diseases and pests detectio n based on improved yolo v3 convolutional neural network. Front. Plant Sci . 11, 8198. doi:10.3389/fpls.2020.00898 Liu, J., and Wang, X. (2021). Plant diseases and pests detection based on deep learning:areview. PlantMethods 17,1\u201318.doi:10.1186/s13007-021-00722-9 Liu, R., Cheng, Z., Zhang, L., and Li, J. (2019). Remote sensin g image change detection based on information transmission and attention mecha nism.IEEE Access7,1156349\u20131156359.doi:10.1109/ACCESS.2019.2947286 Liu, S., Qi, L., Qin, H., Shi, J., and Jia, J. (2018). \u201cPath aggre gation network for instance segmentation,\u201d in Proceedings of the IEEE Conference on Computer VisionandPatternRecognition (SaltLakeCity,UT:IEEE),8759\u20138768. Mahlein, A.-K. (2016). Plant disease detection by imaging sens ors-parallels and specific demands for precision agriculture and plant phenotyping. Plant Dis ."
      },
      "Learning to extract building footprints from off-nadir aerial images": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2204.13637",
        "ref_texts": "[21] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia, \u201cPath aggregation network for instance segmentation,\u201d in CVPR , 2018, pp. 8759\u20138768. 2, 5, 6",
        "ref_ids": [
          "21"
        ]
      },
      "Active pointly-supervised instance segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2207.11493",
        "ref_texts": "35. Liu, S., Qi, L., Qin, H., Shi, J., Jia, J.: Path aggregation network for instance segmentation. In: IEEE Conf. Comput. Vis. Pattern Recog. pp. 8759\u20138768 (2018)",
        "ref_ids": [
          "35"
        ]
      },
      "Walt: Watch and learn 2d amodal representation from time-lapse imagery": {
        "authors": [
          "Dinesh Reddy",
          "Robert Tamburo",
          "Srinivasa G. Narasimhan"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2022/papers/Reddy_WALT_Watch_and_Learn_2D_Amodal_Representation_From_Time-Lapse_Imagery_CVPR_2022_paper.pdf",
        "ref_texts": "[39] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , June 2018. 1",
        "ref_ids": [
          "39"
        ]
      },
      "Multimodal sarcasm target identification in tweets": {
        "authors": [],
        "url": "https://aclanthology.org/2022.acl-long.562.pdf",
        "ref_texts": "2018. Path aggregation network for instance segmentation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) .Diego Molla and Aditya Joshi. 2019. Overview of the 2019 ALTA shared task: Sarcasm target identification. InProceedings of the The 17th Annual Workshop of the Australasian Language Technology Association , pages 192\u2013196. Hongliang Pan, Zheng Lin, Peng Fu, Yatao Qi, and Weiping Wang. 2020. Modeling intra and intermodality incongruity for multi-modal sarcasm detection. In Findings of the Association for Computational Linguistics: EMNLP 2020 , pages 1383\u20131392. Pradeesh Parameswaran, Andrew Trotman, Veronica Liesaputra, and David Eyers. 2019. Detecting target of sarcasm using ensemble methods. In Proceedings of the The 17th Annual Workshop of the Australasian Language Technology Association , pages 197\u2013203. Pradeesh Parameswaran, Andrew Trotman, Veronica Liesaputra, and David Eyers. 2021. Detecting the target of sarcasm is hard: Really?? Information Processing & Management , 58(4):102599. Jasabanta Patro, Srijan Bansal, and Animesh Mukherjee.",
        "ref_ids": [
          "2018"
        ]
      },
      "Bridging multi-scale context-aware representation for object detection": {
        "authors": [
          "Boying Wang",
          "Ruyi Ji",
          "Libo Zhang",
          "Yanjun Wu"
        ],
        "url": "https://isrc.iscas.ac.cn/zhanglibo/pdfs/2022/IEEE_Transactions_on_Circuits_and_Systems_for_Video_Technology_2022.pdf",
        "ref_texts": "\u2022Extensive experiments are carried out on multiple visual tasks, including object detection, instance segmentation, semantic segmentation, panoptic segmentation, and object classification. The experimental results show that ourimprovement is promising co mpared to other FPN-based methods. The remainder of this paper is organized as follows. Section II gives a short overview of the related works. In Section III, the proposed MCFPN is presented in detail.Extensive experimental results and analysis are presented in Section IV and Section V. Finally, we summarize the entire paper in Section VI. II. R ELATED WORK A. Object Detection In recent years, thanks to the rapid development of deep learning techniques, remarkab le progress has been achieved in computer vision, especially object detection. Existing object detection methods can be roughly grouped into two strands, i.e., two-stage and one-stage. The methods in the first research strand resort to the metrics behind the different stages fo r better detection performance. As a pioneering approach to the two-stage detection methods [12], [13], [14], [15], [16], R-CNN [39] leverages selective search [40] to produce region proposals and applies a convolu-tional network to refine detection results. To boost the training and inference speed, SPP [15] and Fast R-CNN [13] use spatial pyramid pooling and RoI pooling respectively to incorporatethe feature extraction of the whole image and region features generation into a unified pipeline. Faster R-CNN [16] designs the region proposal network and implements an end-to-end trainable detector, which brings significant improvement in both detection performance and i nference speed. After that, a large number of efforts [12], [41], [42] have emerged to improve Faster R-CNN from different aspects. Contrastively, One-stage detectors [7], [8], [9], [10], [11] are proved more efficient compared with two-stage methods. For this branch, SSD [9] is a representative method, which makes predictions under the condition o f anchor boxes placed densely on multi-scale features. RetinaNet [8] utilizes an FPN-like architecture to abstract feature pyramid and designs a novel focal loss to mitigate the imbalance issue inside examples. Recently, anchor-free methods [11], [43], [44], [45] have emerged, which aim at getting rid of the limitation of the pre-defined sliding windows or proposals. e.g., ExtremeNet [11] formulates the problem of object detection as four coordinates detection of the objects. The methods mentioned abovemake plausible improvements i n detection performance with different considerations. In this paper, we focus on better exploitation of multi-scale features. B. Multi-Scale Learning Multi-scale learning, which exploits multi-scale information to boost performance, has attracted tremendous research attention. Some methods follow a bottom-up paradigm to form an accurate semantic context. For example, DenseNet [24] establishes the dense-connected pathways between each layerin the backbone. HRNet [25] adopts a parallel multi-scale strategy, which gradually augments the high-scale branch by aggregating context information from the low-scale branch. Authorized licensed use limited to: Institute of Software. Downloaded on May 10,2023 at 08:23:04 UTC from IEEE Xplore. Restrictions apply. W ANG et al.: BRIDGING MULTI-SCALE CONTEXT-AW ARE REPRESENTATION FOR OBJECT DETECTION 2319 HRNetv2 [46] further proposes to aggregate multi-scale representation for prediction instead of the only high-scale branch in HRNet. Even though this design concept brings significant performance improvement, it incurs a heavy computationburden. Inspired by the inherent feature hierarchy of convolution networks, feature pyramid technologies are proposed.FPN [26] builds an in-network feature pyramid and makes predictions for different scales of region proposals. PAFPN [35] proposes a path aggregation network to improve information flow in the proposal-based instance segmentation framework. CARAFE [33] proposes a lightweight and highly effectiveoperator to implement feature upsampling. SEPC [34] designs a modified 3-D convolution to extract s cale-invariant features. NAS-FPN [27] applies reinforcement learning to automati-cally search a powerful FPN network. AugFPN [30] jointly uses consistent supervision, residual feature augmentation, and soft RoI selection to further exploit the potential of features in different scales. D yFPN [31] adaptively executes the combinations of the convolutional layers according toa learnable gating operation. Motivated by imagery superresolution, EFPN [47] utilizes a feature texture transfer layer to detect small objects. ImFPN [17] takes two steps to extractsuperior representations: 1) Group channels of the feature twice to enhance intra-group channel interaction. 2) Apply a similarity-based fusion module to achieve cross-layer fusion in the pyramid. CE-FPN [37] employs sub-pixel convolution to enhance the original feature, and then learns the channelweights of different levels to focus on the relevant parts by channel attention guided module. CATFPN [36] constructs multiple feature pyramids and fuses the context informationbelonging to different pyramids through the designed scalewise feature concatenation module. Based on SSD, ESCNet [38] designs the enhanced context module and triple attention module for enhancing t he context information of the shallow layers. MHN [48] proposes a multi-branch and high-level semantic network by gradually splitting a base network into multiple different branches. Compared with the above methods, we propose a progressive learning scheme to unleash the power of feature pyramid representation. Based on the dilated contextual information, we first adopt an interactive strategy to fuse the context information of adjacent levels, and then narrow the semantic gap at different levels in an adaptive learning manner. C. Attention Mechanism Motivated by the human visual mechanism, attention mechanism has played a significant role in the domain of computer vision and is widely applied in various visual tasks, e.g.,i m a g e classification [49], [50], [51], image caption [52], [53], [54], and visual question answering [55], [56], [57]. Specifically, attention mechanisms are to guide the model focusing on the most informative part of the input and suppressing irrelevant parts. Recently, there are many efforts devoted to the studyof attention mechanisms. SENet [58] introduces the attention mechanism from the perspective of channels, allowing for different weights based on the contribution of each channel. Fig. 1. The illustration of the FPN and our MCFPN. For characterizing the discriminative presentation, the CBAMmodule [59] takes attention from spatial and channel viewsinto account simultaneously. Similar to CBAM [59], the BAM module [60] constructs a hierarchical attention at bottlenecks. In method [61], the attention mechanism is introduced to allow each neuron to adaptively adjust its receptive field size based on multiple scales of input information. In contrast to theaforementioned methods, we apply the attention mechanism on features in the FPN architecture to locate the discriminative regions from both spatial and channel perspectivesrespectively. III. T HEPROPOSED APPROACH In this section, we introduce a Multi-Scale Context-Aware Feature Pyramid Network (MCFPN) to unleash the power of feature pyramid representation. The overall framework of MCFPN is shown in Fig. 2. MCFPN is mainly formed by threecomponents: Dilated Residual Block, Cross-scale Context Aggregation Block, and Adaptive Context Aggregation Block. We will describe them in detail in the following subsections. A. Preliminaries Feature Pyramid Network (FPN) is widely adopted in the existing bottom-up framework to tackle the issue of scale variances. In the feature extraction stage, as shown in Fig. 1(a),FPN exploits the inherent multiscale, pyramidal hierarchy of the convolution network to produce enhanced feature representation through cross-scale interactions. The paradigm of FPN mainly consists of a bottom-up pathway, a top-down pathway, and lateral connecti ons, which are described in the following: Firstly, the bottom-up pathway is a feed-forward process of the backbone and derives a feature pyramid with diversescales. More formally, we denote the output of the backbone (e.g., ResNet) at each stages as C={C",
        "ref_ids": [
          "12",
          "13",
          "14",
          "15",
          "16",
          "39",
          "40",
          "15",
          "13",
          "16",
          "12",
          "41",
          "42",
          "7",
          "8",
          "9",
          "10",
          "11",
          "9",
          "8",
          "11",
          "43",
          "44",
          "45",
          "11",
          "24",
          "25",
          "46",
          "26",
          "35",
          "33",
          "34",
          "27",
          "30",
          "31",
          "47",
          "17",
          "37",
          "36",
          "38",
          "48",
          "49",
          "50",
          "51",
          "52",
          "53",
          "54",
          "55",
          "56",
          "57",
          "58",
          "59",
          "59",
          "60",
          "61"
        ]
      },
      "Comparison of CSPDarkNet53, CSPResNeXt-50, and EfficientNet-B0 backbones on YOLO v4 as object detector": {
        "authors": [],
        "url": "https://www.ijesty.org/index.php/ijesty/article/download/291/206",
        "ref_texts": "[15] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia, \u201cPath Aggregation Network for Instance Segmentat ion,\u201d CoRR , vol. abs/1803.0, 2018. ",
        "ref_ids": [
          "15"
        ]
      },
      "Eautodet: Efficient architecture search for object detection": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2203.10747",
        "ref_texts": "2020. Focal Loss for Dense Object Detection. TPAMI , 42(2): 318\u2013327. Lin, T.; Maire, M.; Belongie, S. J.; Hays, J.; Perona, P.; Ramanan, D.; Doll \u00b4ar, P.; and Zitnick, C. L. 2014. Microsoft COCO: Common Objects in Context. In Fleet, D. J.; Pajdla, T.; Schiele, B.; and Tuytelaars, T., eds., ECCV . Lin, T.-Y .; Doll \u00b4ar, P.; Girshick, R.; He, K.; Hariharan, B.; and Belongie, S. 2017. Feature pyramid networks for object detection. In CVPR . Liu, H.; Simonyan, K.; and Yang, Y . 2019. DARTS: Differentiable Architecture Search. In ICLR . Liu, S.; Huang, D.; and Wang, Y . 2019. Learning spatial fusion for single-shot object detection. arXiv preprint arXiv:1911.09516 . Liu, S.; Qi, L.; Qin, H.; Shi, J.; and Jia, J. 2018. Path Aggregation Network for Instance Segmentation. In CVPR . Liu, W.; Anguelov, D.; Erhan, D.; Szegedy, C.; Reed, S.; Fu, C.-Y .; and Berg, A. C. 2016. Ssd: Single shot multibox detector. In ECCV . Ming, Q.; Zhou, Z.; Miao, L.; Zhang, H.; and Li, L. 2021. Dynamic Anchor Learning for Arbitrary-Oriented Object Detection. In Proceedings of the AAAI Conference on Artificial Intelligence . Newell, A.; Yang, K.; and Deng, J. 2016. Stacked Hourglass Networks for Human Pose Estimation. In ECCV . Pan, X.; Ren, Y .; Sheng, K.; Dong, W.; Yuan, H.; Guo, X.; Ma, C.; and Xu, C. 2020. Dynamic Refinement Network for Oriented and Densely Packed Object Detection. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , 11207\u201311216. Real, E.; Aggarwal, A.; Huang, Y .; and Le, Q. V . 2019. Regularized Evolution for Image Classifier Architecture Search. InAAAI . Redmon, J. 2013\u20132016. Darknet: Open Source Neural Networks in C. http://pjreddie.com/darknet/. Redmon, J.; Divvala, S. K.; Girshick, R. B.; and Farhadi, A. 2016. You Only Look Once: Unified, Real-Time Object Detection. In CVPR . Ren, S.; He, K.; Girshick, R. B.; and Sun, J. 2015. Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks. In Cortes, C.; Lawrence, N. D.; Lee, D. D.; Sugiyama, M.; and Garnett, R., eds., NeurIPS . Stamoulis, D.; Ding, R.; Wang, D.; Lymberopoulos, D.; Priyantha, B.; Liu, J.; and Marculescu, D. 2019. Single-Path NAS: Designing Hardware-Efficient ConvNets in Less Than 4 Hours. In ECML . Tan, M.; Pang, R.; and Le, Q. V . 2020. Efficientdet: Scalable and efficient object detection. In CVPR . Wan, A.; Dai, X.; Zhang, P.; He, Z.; Tian, Y .; Xie, S.; Wu, B.; Yu, M.; Xu, T.; Chen, K.; Vajda, P.; and Gonzalez, J. E.",
        "ref_ids": [
          "2020"
        ]
      },
      "SHOMY: Detection of Small Hazardous Objects using the You Only Look Once Algorithm.": {
        "authors": [],
        "url": "https://koreascience.kr/article/JAKO202226461372785.pdf",
        "ref_texts": "[21] S. Liu, L. Qi, H. Qin, J. Shi , and J. Jia, \u201c Path aggregation network for instance segmentation, \u201d in Proc . of 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) , Utah, USA, pp. 8759\u2013 8768, 2018. Article (CrossRef Link) ",
        "ref_ids": [
          "21"
        ]
      },
      "Instance shadow detection with a single-stage detector": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2207.04614",
        "ref_texts": "[51] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia, \u201cPath aggregation network for instance segmentation,\u201d in IEEE Conference on Computer Vision and Pattern Recognition , 2018, pp. 8759\u20138768.",
        "ref_ids": [
          "51"
        ]
      },
      "Efficient one-stage video object detection by exploiting temporal consistency": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2402.09241",
        "ref_texts": "21. Liu, S., Qi, L., Qin, H., Shi, J., Jia, J.: Path aggregation network for instance segmentation. In: CVPR (2018)",
        "ref_ids": [
          "21"
        ]
      },
      "Flexible neural network for fast and accurate road scene perception": {
        "authors": [],
        "url": "https://link.springer.com/content/pdf/10.1007/s11042-022-11933-0.pdf",
        "ref_texts": "26. Liu S, Qi L, Qin H, Shi J, Jia J (2018) Path aggregation network for instance segmentation. In: IEEE Conference on Computer Vision and Pattern Recognition, pp 8759 \u20138768",
        "ref_ids": [
          "26"
        ]
      },
      "Seedling maize counting method in complex backgrounds based on YOLOV5 and Kalman filter tracking algorithm": {
        "authors": [
          "Yang Li"
        ],
        "url": "https://www.frontiersin.org/articles/10.3389/fpls.2022.1030962/pdf",
        "ref_texts": "282. doi: 10.1002/rob.21902 Hu, L., Luo, X., Zeng, S., Zhang, Z., Chen, X., and Lin, C. (2013). Plant recognition and localization for intra-row mechanical weeding device based onmachine vision. Transactions of the Chinese Society of Agricultural Engineering 29, 10, 12 \u201318. doi: 10.3969/j.issn.1002-6819.2013.10.002 Hu, J., Shen, L., and Sun, G. (2018). \u201cSqueeze-and-excitation networks, \u201dinIEEE/ CVF Conference on Computer Vision and Pattern Recognition . (New York, NY, USA: IEEE). pp. 7132 \u20137141 Jiang, Y., Li, C., Paterson, A. H., and Robertson, J. S. (2019). DeepSeedling: deep convolutional network and kalman filter for plant seedling detection and counting in the field.Plant Methods 15 (1), 141. doi: 10.1186/s13007-019-0528-3 Jin, X., Madec, S., Dutartre, D., de Solan, B., Comar, A., and Baret, F. (2019). High-throughput measurements of stem characteristics to estimate ear density andabove-ground biomass Plant Phenom. 2019, 10. doi: 10.34133/2019/4820305 Kalman, R. E. (1960). A new approach to linear filtering and prediction problems. J. Fluids Eng. Trans. ASME 82, 35 \u201345. doi: 10.1115/1.3662552 Koirala, A., Walsh, K. B., Wang, Z., and McCarthy, C. (2019). Deep learning for real-time fruit detection and orchard fruit load estimation: Benchmarking of\u2018MangoYOLO \u2019.Precis. Agric. 20 (6), 1107 \u20131135. doi: 10.1007/s11119-019-09642-0 Kuhn, H. W. (2005). The Hungarian method for the assignment problem. Naval Res. Logist. 52 (1), 7 \u201321. doi: 10.1002/nav.20053 Lin, Y., Chen, T., Liu, S., Cai, Y., Shi, H., Zheng, D., et al. (2022). Quick and accurate monitoring peanut seedlings emergence rate through UAV video and deep learning. Comput. Electron. Agric. 197, 106938. doi: 10.1016/ j.compag.2022.106938 Lin, T., Maire, M., Belongie, S., Bourdev, L., Girshick, R., Hays, J., et al. (2015). Microsoft COCO: Common objects in context (Berlin, Germany: Springer Verlag).Liu, S., Qi, L., Qin, H., Shi, J., and Jia, J. (2018). \u201cPath aggregation network for instance segmentation, \u201dinIEEE/CVF Conference on Computer Vision and Pattern Recognition . (New York, NY, USA: IEEE). 8759 \u20138768. Lv, J., Ni, H., Wang, Q., Yang, B., and Xu, L. (2019). A segmentation method of red apple image. Sci. Hortic. 256, 108615. doi: 10.1016/j.scienta.2019.108615 Ndou, V., Gasura, E., Chivenge, P., and Derera, J. (2021). Grain yield gains and associated traits in tropical x temperate maize germplasm under high and low plantdensity. Euphytica 217 (10), 186. doi: 10.1007/s10681-021-02918-5 Qi, J., Liu, X., Liu, K., Xu, F., Guo, H., Tian, X., et al. (2022). An improved YOLOv5 model based on visual attention mechanism: Application to recognition of tomato virusdisease. Comput. Electron. Agric. 194, 106780. doi: 10.1016/j.compag.2022.106780 Redmon, J., and Farhadi, A. (2018). \u201cYolov3: An incremental improvement, \u201din arXiv preprint . Ithaca, NY, USA: Cornell University. Stein, M., Bargoti, S., and Underwood, J. (2016). Image based mango fruit detection, localisation and yield estimation using multiple view geometry. Sensors 16 (11), 1915. doi: 10.3390/s16111915 Tzutalin, (2015) LabelImg. git code . Available at: https://github.com/tzutalin/ labelImg (Accessed 1 Feb 2020). Wang, C. Y., Liao, H. Y. M., Wu, Y. H., Chen, P. Y., Hsieh, J. W., and Yeh, I. H.",
        "ref_ids": [
          "282"
        ]
      },
      "SDTP: Semantic-aware decoupled transformer pyramid for dense image prediction": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2109.08963",
        "ref_texts": "[18] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 8759\u20138768, 2018.",
        "ref_ids": [
          "18"
        ]
      },
      "Localization and classification of space objects using EfficientDet detector for space situational awareness": {
        "authors": [
          "Nouar Al"
        ],
        "url": "https://www.nature.com/articles/s41598-022-25859-y.pdf",
        "ref_texts": ""
      },
      "Panoptic, instance and semantic relations: A relational context encoder to enhance panoptic segmentation": {
        "authors": [
          "Shubhankar Borse",
          "Hyojin Park",
          "Hong Cai",
          "Debasmit Das",
          "Risheek Garrepalli",
          "Fatih Porikli"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2022/papers/Borse_Panoptic_Instance_and_Semantic_Relations_A_Relational_Context_Encoder_To_CVPR_2022_paper.pdf",
        "ref_texts": "[31] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia. Path aggregation network for instance segmentation. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 8759\u20138768, 2018. 2",
        "ref_ids": [
          "31"
        ]
      },
      "MSR-RCNN: a multi-class crop pest detection network based on a multi-scale super-resolution feature enhancement module": {
        "authors": [
          "Liu Liu"
        ],
        "url": "https://www.frontiersin.org/journals/plant-science/articles/10.3389/fpls.2022.810546/pdf",
        "ref_texts": "(2019). Pestnet: an end-to-end deep learning approach for large-s cale multi-class pest detection and classification. IEEE Access 7, 45301\u201345312. doi:10.1109/ACCESS.2019.2909522 Liu, L., Xie, C., Wang, R., Yang, P., Sudirman, S., Zhang, J., et a l. (2020). Deep learning based automatic multi-class wild pest monitoring approach using hybrid global and local activated features. IEEE Trans. Ind. Inform . 17, 7589\u20137598.doi:10.1109/TII.2020.2995208 Liu, S., Qi, L., Qin, H., Shi, J., and Jia, J. (2018). \u201cPath aggre gation network for instance segmentation,\u201d in Proceedings of the IEEE Conference on Computer VisionandPatternRecognition (SaltLakeCity,UT:IEEE),8759\u20138768. Liu, Z., Gao, J., Yang, G., Zhang, H., and He, Y. (2016). Localiza tion and classification of paddy field pests using a saliency map and deep conv olutional neuralnetwork. Sci.Rep.6,1\u201312.doi:10.1038/srep20410 Pang, J., Chen, K., Shi, J., Feng, H., Ouyang, W., and Lin, D. (2 019). \u201cLibra r-cnn: towardsbalancedlearningforobjectdetection,\u201din ProceedingsoftheIEEE/CVF Conference on Computer Vision and Pattern Recognition (Long Beach, CA), 821\u2013830. Qin, Z., Li, Z., Zhang, Z., Bao, Y., Yu, G., Peng, Y., et al. (201 9). \u201cThundernet: towards real-time generic object detection on mobile devices,\u201d in Proceedings of the IEEE/CVF International Conference on Computer Vision (Seoul: IEEE), 6718\u20136727. Qing,Y.,Jun,L.,Liu,Q.-,j.,Diao,G.-,q.,Yang,B.-,j.,C hen,H.-,m.,etal.(2012).An insect imaging system to automate rice light-trap pest identificat ion.J. Integr. Agric.11,978\u2013985.doi:10.1016/S2095-3119(12)60089-6 Redmon,J.,Divvala,S.,Girshick,R.,andFarhadi,A.(2016). \u201cYouonlylookonce: Unified, real-time object detection,\u201d in Proceedings of the IEEE Conference on ComputerVisionandPatternRecognition (LasVegas,NV:iEEE),779\u2013788. Redmon,J.,andFarhadi,A.(2018).YOLOv3:anincrementalimprove ment.arXiv [Preprint] .arXiv:1804.02767. Redmon, J., and Farhadi, A. (2017). \u201cYolo9000: better, faster , stronger,\u201d in ProceedingsoftheIEEEConferenceonComputerVisionandPat ternRecognition (Honolulu,HI:IEEE),7263\u20137271. Ren, S., He, K., Girshick, R., and Sun, J. (2017). \u201cFaster R-CN N: Towards realtime object detection with region proposal networks,\u201d in IEEE Transactions on Pattern Analysis and Machine Intelligence , Vol. 39 (IEEE), 1137\u20131149. doi:10.1109/TPAMI.2016.2577031 Shen, Y., Zhou, H., Li, J., Jian, F., and Jayas, D. S. (2018). De tection of storedgrain insects using deep learning. Comput. Electron. Agric . 145, 319\u2013325. doi:10.1016/j.compag.2017.11.039Shrivastava, A., Gupta, A., and Girshick, R. (2016). \u201cTraining region-based object detectors with online hard example mining,\u201d in Proceedings of the IEEE ConferenceonComputerVisionandPatternRecognition (LasVegas,NV:IEEE), 761\u2013769. Singh, B., and Davis, L. S. (2018). \u201cAn analysis of scale invaria nce in object detection SNIP,\u201d in 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition (Salt Lake City, UT: IEEE), 3578\u20133587. doi:10.1109/CVPR.2018.00377 Singh,B.,Najibi,M.,andDavis,L.S.(2018).SNIPER:Efficie ntmulti-scaletraining. arXiv[Preprint] .arXiv:1805.09300. Thenmozhi, K., and Reddy, U. S. (2019). Crop pest classification based on deep convolutional neural network and transfer learning. Comput. Electron. Agric . 164, 104906. doi: 10.1016/j.compag.201"
      },
      "BTS: a bi-lingual benchmark for text segmentation in the wild": {
        "authors": [
          "Xixi Xu",
          "Zhongang Qi",
          "Jianqi Ma",
          "Honglun Zhang",
          "Ying Shan",
          "Xiaohu Qie"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_BTS_A_Bi-Lingual_Benchmark_for_Text_Segmentation_in_the_Wild_CVPR_2022_paper.pdf",
        "ref_texts": "[38] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia. Path aggregation network for instance segmentation. In 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) , 2018. 3",
        "ref_ids": [
          "38"
        ]
      },
      "Real-time object detection for UAV images based on improved YOLOv5s": {
        "authors": [],
        "url": "https://www.oejournal.org/data/article/export-pdf?id=623d39f499d881176fdf95d2",
        "ref_texts": " Liu S, Qi L, Qin H F, et al. Path aggregation network for instance segmentation[C]//Proceedings of 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2018: 8759\u20138768. doi: 10.1109/CVPR.2018.00913.[20]",
        "ref_ids": [
          "20"
        ]
      },
      "A detection method of the rescue targets in the marine casualty based on improved YOLOv5s": {
        "authors": [
          "Shujie Yang"
        ],
        "url": "https://www.frontiersin.org/articles/10.3389/fnbot.2022.1053124/pdf",
        "ref_texts": "2-1_48 Liu, S., Qi, L., Qin, H., Shi, J., and Jia, J. (2018). \u201cPath aggregation network for instance segmentation, \u201d in Proceedings of the IEEE conference on computer vision and pattern recognition , (Piscataway, NJ: IEEE), 8759\u20138768. doi: 10.1109/CVPR."
      },
      "Efficient decoder-free object detection with transformers": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2206.06829",
        "ref_texts": "[23] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 8759\u20138768, 2018.",
        "ref_ids": [
          "23"
        ]
      },
      "Automatic cattle identification using yolov5 and mosaic augmentation: A comparative analysis": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2210.11939",
        "ref_texts": "[57] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia, \u201cPath aggregation network for instance segmentation,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition , 2018, pp. ",
        "ref_ids": [
          "57"
        ]
      },
      "KTN: Knowledge transfer network for learning multiperson 2D-3D correspondences": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2206.10090",
        "ref_texts": "[25] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia, \u201cPath aggregation network for instance segmentation,\u201d in CVPR , 2018.",
        "ref_ids": [
          "25"
        ]
      },
      "High accuracy real-time insulator string defect detection method based on improved yolov5": {
        "authors": [],
        "url": "https://www.frontiersin.org/articles/10.3389/fenrg.2022.928164/pdf",
        "ref_texts": "2834-1104013444 Dai, J., Li, Y., He, K., and Sun, J. (2016). \u201cR-fcn: Object Detection via Region-Based Fully Convolutional Networks, \u201din Advances in neural information processing systems, 29. Feng, Z., Guo, L., Huang, D., and Li, R. (2021). \u201cElectrical Insulator Defects Detection Method Based on YOLOv5, \u201din 2021 IEEE 10th Data Driven Control and Learning Systems Conference (DDCLS) (IEEE). Fischer, P., and Brox, T. (2015). \u201cU-net: Convolutional Networks for Biomedical Image Segmentation, \u201din Medical Image Computing and Computer-Assisted Intervention (MICCAI). Gao, K., Lyu, L., Huang, H., Fu, C., Chen, F., and Jin, L. (2019). \u201cInsulation Defect Detection of Electrical Equipment Based on Infrared and UltravioletPhotoelectric Sensing Technology, \u201din IECON 2019-45th Annual Conference of the IEEE Industrial Electronics Society (IEEE).He, K., Zhang, X., Ren, S., and Sun, J. (2015). Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition. IEEE Trans. Pattern Anal. Mach. Intell. 37 (9), 1904 \u20131916. doi:10.1109/tpami.2015.2389824 Huang, X. (2017). Research of Composite Insulator Detection Device Based on Electric Field Method and Resistance Method . DEStech Transactions on Computer Science and Engineering icitia. Krishna, K., and Narasimha Murty, M. (1999). Genetic K-Means Algorithm. IEEE Trans. Syst. Man. Cybern. B 29 (3), 433 \u2013439. doi:10.1109/3477.764879 Li, D., Zhang, G., Hou, Y., and Zhang, B. (2019). Charge Distribution on Polymer Insulator Surface under AC Voltage. IEEE Trans. Dielect. Electr. Insul. 26 (5), 1709 \u20131715. doi:10.1109/tdei.2019.008260 Li, W. (2010). \u201cRecognition of Insulator Based on Developed MPEG-7 Texture Feature, \u201din 2010 3rd International Congress on Image and Signal Processing (IEEE). doi:10.1109/cisp.2010.5648283 Liu, S. (2018). \u201cPath Aggregation Network for Instance Segmentation, \u201din Proceedings of the IEEE conference on computer vision and patternrecognition. doi:10.1109/cvpr.2018.00913 Liu, W., Anguelov, D., Erhan, D., Szegedy, C., and Reed, S. (2016). SSD: Single Shot MultiBox Detector . Amsterdam, NETHERLANDS: 14th European Conference on Computer Vision. Lu, W. (2021). \u201cInsulator Detection Method Based on Improved Faster R-CNN with Aerial Images, \u201din 2021 2nd International Symposium on Computer Engineering and Intelligent Communications (ISCEIC) (IEEE). doi:10.1109/isceic53685.2021.00093 Montavon, G., Samek, W., and M\u00fcller, K.-R. (2018). Methods for Interpreting and Understanding Deep Neural Networks. Digit. Signal Process. 73, 1 \u201315. doi:10."
      },
      "Context augmentation and feature refinement network for tiny object detection": {
        "authors": [],
        "url": "https://openreview.net/pdf?id=q2ZaVU6bEsT",
        "ref_texts": "9 Under review as a conference paper at ICLR 2022 Yukang Chen, Peizhen Zhang, Zeming Li, Yanwei Li, Xiangyu Zhang, Gaofeng Meng, Shiming Xiang, Jian Sun, and Jiaya Jia. Stitcher: Feedback-driven data provider for object detection. arXiv e-prints , pp. arXiv\u20132004, 2020. Chunfang Deng, Mengmeng Wang, Liang Liu, Yong Liu, and Yunliang Jiang. Extended feature pyramid network for small object detection. IEEE Transactions on Multimedia , 2021. Kaiwen Duan, Song Bai, Lingxi Xie, Honggang Qi, Qingming Huang, and Qi Tian. Centernet: Keypoint triplets for object detection. In Proceedings of the IEEE/CVF International Conference on Computer Vision , pp. 6569\u20136578, 2019. Di Feng, Ali Harakeh, Steven Waslander, and Klaus Dietmayer. A review and comparative study on probabilistic object detection in autonomous driving. arXiv preprint arXiv:2011.10671 , 2020. Golnaz Ghiasi, Tsung-Yi Lin, and Quoc V Le. Nas-fpn: Learning scalable feature pyramid architecture for object detection. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pp. 7036\u20137045, 2019. Kaiming He, Georgia Gkioxari, Piotr Doll \u00b4ar, and Ross Girshick. Mask r-cnn. In Proceedings of the IEEE international conference on computer vision , pp. 2961\u20132969, 2017. Seung-Wook Kim, Hyong-Keun Kook, Jee-Young Sun, Mun-Cheon Kang, and Sung-Jea Ko. Parallel feature pyramid network for object detection. In Proceedings of the European Conference on Computer Vision (ECCV) , pp. 234\u2013250, 2018. Mate Kisantal, Zbigniew Wojna, Jakub Murawski, Jacek Naruniec, and Kyunghyun Cho. Augmentation for small object detection. arXiv preprint arXiv:1902.07296 , 2019. Tao Kong, Fuchun Sun, Chuanqi Tan, Huaping Liu, and Wenbing Huang. Deep feature pyramid reconfiguration for object detection. In Proceedings of the European conference on computer vision (ECCV) , pp. 169\u2013185, 2018. Tsung-Yi Lin, Piotr Doll \u00b4ar, Ross Girshick, Kaiming He, Bharath Hariharan, and Serge Belongie. Feature pyramid networks for object detection. In Proceedings of the IEEE conference on computer vision and pattern recognition , pp. 2117\u20132125, 2017. Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In Proceedings of the IEEE conference on computer vision and pattern recognition , pp. 8759\u20138768, 2018. Wei Liu, Dragomir Anguelov, Dumitru Erhan, Christian Szegedy, Scott Reed, Cheng-Yang Fu, and Alexander C Berg. Ssd: Single shot multibox detector. In European conference on computer vision , pp. 21\u201337. Springer, 2016. Yang Liu, Peng Sun, Nickolas Wergeles, and Yi Shang. A survey and performance evaluation of deep learning methods for small object detection. Expert Systems with Applications , pp. 114602, 2021. Ziming Liu, Guangyu Gao, Lin Sun, and Li Fang. Ipg-net: Image pyramid guidance network for small object detection. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops , pp. 1026\u20131027, 2020. Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, et al. Pytorch: An imperative style, high-performance deep learning library. Advances in neural information processing systems , 32: 8026\u20138037, 2019. Joseph Redmon and Ali Farhadi. Yolo9000: better, faster, stronger. In Proceedings of the IEEE conference on computer vision and pattern recognition , pp. 7263\u20137271, 2017. Joseph Redmon and Ali Farhadi. Yolov3: An incremental improvement. arXiv preprint arXiv:1804.02767 , 2018."
      },
      "Aiding airway obstruction diagnosis with computational fluid dynamics and convolutional neural network: A new perspective and numerical case study": {
        "authors": [
          "Pingfan Hu"
        ],
        "url": "https://par.nsf.gov/servlets/purl/10320673",
        "ref_texts": "[43] Liu, S., Qi, L., Qin, H., Shi, J., and Jia, J., 2018, \u201cPath Aggregation Network for Instance Segmentation,\u201d Proceedings of the IEEE Conference on ComputerVision and Pattern Recognition.",
        "ref_ids": [
          "43"
        ]
      },
      "MFA-net: Object detection for complex X-ray cargo and baggage security imagery": {
        "authors": [
          "Thanaporn Viriyasaranon",
          "Hoon Chae",
          "Hwan Choi"
        ],
        "url": "https://journals.plos.org/plosone/article/file?id=10.1371/journal.pone.0272961&type=printable",
        "ref_texts": ""
      },
      "Machine-learning-based top-view safety monitoring of ground workforce on complex industrial sites": {
        "authors": [
          "Gelayol Golcarenarenji"
        ],
        "url": "https://link.springer.com/content/pdf/10.1007/s00521-021-06489-3.pdf",
        "ref_texts": "26. Liu S, Qi L, Qin H, Shi J, Jia J (2018) Path aggregation network for instance segmentation. In: 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp 8759\u20138768. https:// doi.org/10.1109/CVPR.2018.00913",
        "ref_ids": [
          "26"
        ]
      },
      "A review on anchor assignment and sampling heuristics in deep learning-based object detection": {
        "authors": [
          "Thuy Vo"
        ],
        "url": "http://islab.ulsan.ac.kr/files/publications/2021-Neurocomputing-Xuan-Thuy_Vo-PublishedVersion.pdf",
        "ref_texts": "[122] S. Liu, L. Qi, H. Qin, J. Shi, J. Jia, Path aggregation network for instance segmentation, in: Proceedings of the IEEE conference on computer vision and pattern recognition, 2018, pp. 8759\u20138768 .",
        "ref_ids": [
          "122"
        ]
      },
      "SFPN: Synthetic FPN for object detection": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2203.02445",
        "ref_texts": "[16] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia, \u201cPath aggregation network for instance segmentation,\u201d inProceedings of the IEEE conference on computer vision and pattern recognition , 2018, pp. 8759\u20138768.",
        "ref_ids": [
          "16"
        ]
      },
      "3-d instance segmentation of mvs buildings": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2112.09902",
        "ref_texts": "[20] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia, \u201cPath aggregation network for instance segmentation,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition , 2018, pp. 8759\u20138768.",
        "ref_ids": [
          "20"
        ]
      },
      "Semantic segmentation of 3D car parts using UAV-based images": {
        "authors": [],
        "url": "https://helvia.uco.es/bitstream/handle/10396/26664/semantic_segmentation_of_3d_car_parts.pdf?sequence=3&isAllowed=n",
        "ref_texts": "[27] Liu, S, Qi, L, Qin, H, Shi, J, Jia, J. Path aggregation network for instance segmentation. In: Proceedings of the IEEE conference on computer vision and pattern recognition. 2018, p.",
        "ref_ids": [
          "27"
        ]
      },
      "Research on efficient feature extraction: Improving YOLOv5 backbone for facial expression detection in live streaming scenes": {
        "authors": [
          "Zhenyu Li"
        ],
        "url": "https://www.frontiersin.org/articles/10.3389/fncom.2022.980063/pdf",
        "ref_texts": "(2017). \u201cFeature pyramid networks for object detection,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (Honolulu, HI), 2117\u20132125.doi:10.1109/CVPR.2017.106Liu, S., Qi, L., Qin, H., Shi, J., and Jia, J. (2018). \u201cPath agg regation network for instance segmentation,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (Salt Lake City, UT), 8759\u20138768. doi:10.1109/CVPR.2018.00913 Lucey, P., Cohn, J. F., Kanade, T., Saragih, J., Ambadar, Z., and Matthews, I. (2010). \u201cThe extended Cohn\u2013Kanade dataset (ck +): A complete dataset for action unit and emotion-specified expression,\u201d in 2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition-Workshop s(San Francisco,CA),94\u2013101.doi:10.1109/CVPRW.2010.5543262 Luo, H. (2005). \u201cOptimization design of cascaded classifiers, \u201d in2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (San Diego,CA),480\u2013485.doi:10.1109/CVPR.2005.266 Miao, S., Du, S., Feng, R., Zhang, Y., Li, H., Liu, T., et al. (20 22). Balanced single-shotobjectdetectionusingcross-contextattentio n-guidednetwork. Pattern Recognit. 122,108258.doi:10.1016/j.patcog.2021.108258 Mnih,V.,Heess,N.,andGraves,A.(2014).Recurrentmodelsof visualattention. Adv.NeuralInf.Process.Syst. 27,1\u201312.doi:10.48550/arXiv.1406.6247 Mollahosseini, A., Chan, D., and Mahoor, M. H. (2016). \u201cGoing de eper in facial expression recognition using deep neural networks ,\u201d inIEEE Winter Conference on Applications of Computer Vision (Lake Placid, NY), 1\u201310. doi:10.1109/WACV.2016.7477450 Ojala, T., Pietikainen, M., and Harwood, D. (1996). A comparat ive study of texture measures with classification based on feature dist ributions. Pattern Recognit. 29,51\u201359.doi:10.1016/0031-3203(95)00067-4 Oliveira, L. S., Britto, A. S., and Sabourin, R. (2005). \u201cImpro ving cascading classifiers with particle swarm optimization,\u201d in Eighth International Conference on Document Analysis and Recognition (Seoul), 570\u2013574. doi:10.1109/ICDAR.2005.138 Pantic, M., Valstar, M., Rademaker, R., and Maat, L. (2005). \u201c Web-based database for facial expression analysis,\u201d in 2005 IEEE International Conference on MultimediaandExpo ,5.doi:10.1109/ICME.2005.1521424 Pei, J. Y., and Shan, P. (2019). A micro-expression recogniti on algorithm for students in classroom learning based on convoluti onal neural network. Traitement Du Signal 36, 557\u2013563. doi: 10.18280/ts."
      },
      "Deyo: Detr with yolo for step-by-step object detection": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2211.06588",
        "ref_texts": "[27] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation.",
        "ref_ids": [
          "27"
        ]
      },
      "Sar ship detection based on swin transformer and feature enhancement feature pyramid network": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2209.10421",
        "ref_texts": "[14] S. Liu, L. Qi, H. Qin, J. Shi and J. Jia, \"Path Aggregatio n Network for Instance Segmentation,\" 2018 IEEE/CVF Con ference on Computer Vision and Pattern Recognition, 2018, pp. 8759-8768 , doi: 10.1109/CVPR.2018.0091 3.Table 1 Ablation Experiments Backbone Neck mAP(%) ResNet-50 FPN 90.30 Swin-T FPN 92.51 Swin-T PAFPN 88.60 Swin-T FEFPN 93.08 ",
        "ref_ids": [
          "14"
        ]
      },
      "Deep learning in bladder cancer imaging: A review": {
        "authors": [
          "Mingyang Li"
        ],
        "url": "https://www.frontiersin.org/articles/10.3389/fonc.2022.930917/pdf",
        "ref_texts": "35. Liu S, Qi L, Qin HF, Shi JP, Jia JY. Path aggregation network for instance segmentation. Proc Cvpr IEEE (2018) 8759 \u201368. doi: 10.1109/Cvpr.2018.00913",
        "ref_ids": [
          "35"
        ]
      },
      "Ca-ssl: Class-agnostic semi-supervised learning for detection and segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2112.04966",
        "ref_texts": "35. Liu, S., Qi, L., Qin, H., Shi, J., Jia, J.: Path aggregation network for instance segmentation. In: CVPR (2018) 1, 4",
        "ref_ids": [
          "35"
        ]
      },
      "Region rebalance for long-tailed semantic segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2204.01969",
        "ref_texts": "[37] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In CVPR , 2018. 1",
        "ref_ids": [
          "37"
        ]
      },
      "MTP: multi-task pruning for efficient semantic segmentation networks": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2007.08386",
        "ref_texts": "[20] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia, \u201cPath aggregation network for instance segmentation,\u201d in CVPR , 2018, pp. 8759\u20138768.",
        "ref_ids": [
          "20"
        ]
      },
      "Pai3d: Painting adaptive instance-prior for 3d object detection": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2211.08055",
        "ref_texts": "37. S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia, \u201cPath aggregation network for instance segmentation,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition , 2018, pp. 8759\u20138768.",
        "ref_ids": [
          "37"
        ]
      },
      "Self-supervised learning for panoptic segmentation of multiple fruit flower species": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2209.04618",
        "ref_texts": "[10] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia, \u201cPath aggregation network for instance segmentation,\u201d in IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) , 2018.",
        "ref_ids": [
          "10"
        ]
      },
      "ShortcutFusion: From tensorflow to FPGA-based accelerator with a reuse-aware memory allocation for shortcut data": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2106.08167",
        "ref_texts": "[35] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia , \u201cPath aggregation network for instance segmentation,\u201d ,\u201d in Proc. IEEE Conf. Comput. Vis. Pattern Recognit . (CVPR), 2018. [36] T.-Y. Lin, P. Doll\u00b4ar, R. Girshick, K. He, B. Hariharan, and S. Belongie, ",
        "ref_ids": [
          "35",
          "36"
        ]
      },
      "Improving single-stage object detectors for nighttime pedestrian detection": {
        "authors": [],
        "url": "https://www.osti.gov/pages/servlets/purl/1887022",
        "ref_texts": "25. S. Liu, L. Qi, H. Qin, J. Shi and J. Jia, Path aggregation network for instance segmentation, in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) (June 2018)",
        "ref_ids": [
          "25"
        ]
      },
      "D^ 2ETR: Decoder-Only DETR with Computationally Efficient Cross-Scale Attention": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2203.00860",
        "ref_texts": "[14] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 8759{",
        "ref_ids": [
          "14"
        ]
      },
      "STC: spatio-temporal contrastive learning for video instance segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2202.03747",
        "ref_texts": "28. Liu, S., Qi, L., Qin, H., Shi, J., Jia, J.: Path aggregation network for instance segmentation. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. pp. 8759\u20138768 (2018)",
        "ref_ids": [
          "28"
        ]
      },
      "Video instance segmentation by instance flow assembly": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2110.10599",
        "ref_texts": "[25] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 8759\u20138768, 2018. 1, 2",
        "ref_ids": [
          "25"
        ]
      },
      "TIA-YOLOv5: An improved YOLOv5 network for real-time detection of crop and weed in the field": {
        "authors": [
          "Aichen Wang",
          "Tao Peng",
          "Huadong Cao",
          "Yifei Xu",
          "Xinhua Wei",
          "Bingbo Cui"
        ],
        "url": "https://www.frontiersin.org/articles/10.3389/fpls.2022.1091655/pdf",
        "ref_texts": "67, 43 \u201353. doi: 10.1016/j.jag.2017.12.012 G i r s h i c k ,R .(2 0 1 5 ) . \u201cFast r-CNN, \u201dinProceedings of the IEEE international conference on computer vision . (Santiago: IEEE), 1440 \u20131448. doi: 10.1109/ICCV.2015.169 Glenn, J. (2020) yolov5 . Available at: https://github.com/ultralytics/yolov5 . Hasan, A. M., Sohel, F., Diepeveen, D., Laga, H., and Jones, M. G. (2021). A survey of deep learning techniques for weed detection from images. Comput. Electron. Agric. 184, 106067. doi: 10.1016/j.compag.2021.106067 Hu, J., Shen, L., and Sun, G. (2018). \u201cSqueeze-and-Excitation networks, \u201dinProceedings of the IEEE conference on computer vision and pattern recognition . (Salt Lake City: IEEE), 7132 \u20137141. doi: 10.1109/CVPR.2018.00745 Jiang, H., Zhang, C., Qiao, Y., Zhang, Z., Zhang, W., and Song, C. (2020). CNN Feature based graph convolutional network for weed and crop recognition in smartfarming. Comput. Electron. Agric. 174, 105450. doi: 10.1016/j.compag.2020.105450 K i m ,Y .H . ,a n dP a r k ,K .R .(2 0 2 2 ) .M T S C N N :M u l t i t a s ks e m a n t i c segmentation-convolutional neural network for detecting crops and weeds. Comput. Electron. Agric. 199, 107146. doi: 10.1016/j.compag.2022.107146 Lee, W.-S., Alchanatis, V., Yang, C., Hirafuji, M., Moshou, D., and Li, C. (2010). Sensing technologies for precision specialty crop production. Comput. Electron. Agric. 74 (1), 2 \u201333. doi: 10.1016/j.compag.2010.08.005 Li, D., Hu, J., Wang, C., Li, X., She, Q., Zhu, L., et al. (2021a). \u201cInvolution: Inverting the inherence of convolution for visual recognition, \u201dinProceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition . (Nashville: IEEE), 12321 \u201312330. doi: 10.1109/CVPR46437.2021.01214 Li, Z., Li, Y., Yang, Y., Guo, R., Yang, J., Yue, J., et al. (2021b). A high-precision detection method of hydroponic lettuce seedlings status based on improved fasterRCNN. Comput. Electron. Agric. 182, 106054. doi: 10.1016/j.compag.2021.106054 Lin, T.-Y., Goyal, P., Girshick, R., He, K., and Dolla \u0301r, P. (2017). \u201c Focal loss for dense object detection, \u201dinProceedings of the IEEE international conference on computer vision . 2980 \u20132988. doi: 10.1109/TPAMI.2018.2858826 L i u ,W . ,A n g u e l o v ,D . ,E r h a n ,D . ,S z e g e d y ,C . ,R e e d ,S . ,F u ,C . Y . ,e ta l .(2 0 1 6 ) . \u201cSSD: Single shot MultiBox detector, \u201dinEuropean Conference on computer vision (Cham: Springer), 21 \u201337. doi:10.1007/978-3-319-46448-0_2 Liu, S., Huang, D., and Wang, Y. (2019) Learning spatial fusion for single-shot object detection arXiv. preprint. arXiv:1911.09516. doi:10.48550/arXiv.1911.09516 Liu, S., Qi, L., Qin, H., Shi, J., and Jia, J. (2018). \u201cPath aggregation network for instance segmentation, \u201dinProceedings of the IEEE conference on computer vision and pattern recognition . 8759 \u20138768. Lottes, P., Behley, J., Milioto, A., and Stachniss, C. (2018). Fully convolutional networks with sequential information for robust crop and weed detection in precision farming. IEEE Robotics. Automation. Lett. 3 (4), 2870 \u20132877. doi: 10.1109/LRA.2018.2846289 Luo, Y., Cao, X., Zhang, J., Guo, J., Shen, H., Wang, T., et al. (2022). CE-FPN: enhancing channel information for object detection. Multimedia. Tools Appl. 81"
      },
      "A radar signal deinterleaving method based on semantic segmentation with neural network": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2110.13706",
        "ref_texts": "[51] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia, \u201cPath aggregation network for instance segmentation,\u201d IEEE , 2018. III-C",
        "ref_ids": [
          "51"
        ]
      },
      "Where and what: Driver attention-based object detection": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2204.12150",
        "ref_texts": "[27] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. 2018. Path aggregation network for instance segmentation. In CVPR . 8759\u20138768.",
        "ref_ids": [
          "27"
        ]
      },
      "A more compact object detector head network with feature enhancement and relational reasoning": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2106.14475",
        "ref_texts": "[13] S. Liu, L. Qi, H. Qin, J. Shi, J. Jia, Path aggregation network for instance segmentation, in: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2018, pp. 8759\u20138768.",
        "ref_ids": [
          "13"
        ]
      },
      "Deeply unsupervised patch re-identification for pre-training object detectors": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2103.04814",
        "ref_texts": "[22] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia, \u201cPath aggregation network for instance segmentation,\u201d in CVPR , 2018, pp. 8759\u20138768.",
        "ref_ids": [
          "22"
        ]
      },
      "Towards robust part-aware instance segmentation for industrial bin picking": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2203.02767",
        "ref_texts": "[17] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia, \u201cPath aggregation network for instance segmentation,\u201d in IEEE Conf. on Computer Vision and Pattern Recognition (CVPR) , 2018, pp. 8759\u20138768.",
        "ref_ids": [
          "17"
        ]
      },
      "UniInst: Unique representation for end-to-end instance segmentation": {
        "authors": [
          "Yimin Ou",
          "Rui Yang",
          "Lufan Ma",
          "Yong Liu",
          "Jiangpeng Yan",
          "Shang Xu",
          "Chengjie Wang",
          "Xiu Li"
        ],
        "url": "https://arxiv.org/pdf/2205.12646",
        "ref_texts": "[28] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In IEEE/CVF Conference on Computer Vision and Pattern Recognition, CVPR , pages 8759{8768, 2018.",
        "ref_ids": [
          "28"
        ]
      },
      "\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684 YOLO \u76ee\u6807\u68c0\u6d4b\u7efc\u8ff0": {
        "authors": [],
        "url": "https://jeit.ac.cn/cn/article/pdf/preview/10.11999/JEIT210790.pdf",
        "ref_texts": "2020\u00a0IEEE/CVF\u00a0Conference\u00a0on\u00a0Computer\u00a0Vision\u00a0and Pattern\u00a0Recognition\u00a0Workshops,\u00a0Seattle,\u00a0USA,\u00a02020: 1571\u20131580.\u00a0doi:\u00a010.1109/CVPRW50498.2020.00203.[21] MISRA\u00a0D.\u00a0Mish:\u00a0A\u00a0self\u00a0regularized\u00a0non-monotonic activation\u00a0function[J].\u00a0arXiv\u00a0preprint\u00a0arXiv:\u00a01908.08681, 2019.[22] LIU\u00a0Shu,\u00a0QI\u00a0Lu,\u00a0QIN\u00a0Haifang,\u00a0et al.\u00a0Path\u00a0aggregation network\u00a0for\u00a0instance\u00a0segmentation[C].\u00a02018\u00a0IEEE/CVF Conference\u00a0on\u00a0Computer\u00a0Vision\u00a0and\u00a0Pattern\u00a0Recognition, Salt\u00a0Lake\u00a0City,\u00a0USA,\u00a02018:\u00a08759\u20138768.\u00a0doi:\u00a010.1109/CVPR.",
        "ref_ids": [
          "21",
          "22"
        ]
      },
      "Sunflower seeds classification based on sparse convolutional neural networks in multi-objective scene": {
        "authors": [
          "Xiaowei Jin"
        ],
        "url": "https://www.nature.com/articles/s41598-022-23869-4.pdf",
        "ref_texts": ""
      },
      "RevBiFPN: the fully reversible bidirectional feature pyramid network": {
        "authors": [
          "Vitaliy Chiley",
          "Vithursan Thangarasa",
          "Abhay Gupta",
          "Anshul Samar",
          "Joel Hestness",
          "Dennis De"
        ],
        "url": "https://arxiv.org/pdf/2206.14098",
        "ref_texts": "2125, 2017a. Lin, T.-Y ., Goyal, P., Girshick, R., He, K., and Doll\u00e1r, P. Focal Loss for Dense Object Detection. In Proceedings of the IEEE international conference on computer vision , pp. 2980\u20132988, 2017b. RevBiFPN: The Fully Reversible Bidirectional Feature Pyramid Network Liu, S., Qi, L., Qin, H., Shi, J., and Jia, J. Path Aggregation Network for Instance Segmentation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pp. 8759\u20138768, 2018. Liu, Z., Lin, Y ., Cao, Y ., Hu, H., Wei, Y ., Zhang, Z., Lin, S., and Guo, B. Swin Transformer: Hierarchical Vision Transformer using Shifted Windows. arXiv preprint arXiv:2103.14030 , 2021. Loshchilov, I. and Hutter, F. SGDR: Stochastic Gradient Descent with Warm Restarts. In International Conference on Learning Representations , 2017. Lu, G., Zhang, W., and Wang, Z. Optimizing Depthwise Separable Convolution Operations on GPUs. IEEE Transactions on Parallel and Distributed Systems , 2021. MacKay, M., Vicol, P., Ba, J., and Grosse, R. B. Reversible Recurrent Neural Networks. In Bengio, S., Wallach, H., Larochelle, H., Grauman, K., Cesa-Bianchi, N., and Garnett, R. (eds.), Advances in Neural Information Processing Systems , volume 31. Curran Associates, Inc., 2018. Mehta, S. and Rastegari, M. MobileViT: Light-weight, General-purpose, and Mobile-friendly Vision Transformer. arXiv preprint arXiv:2110.02178 , 2021. MMSegmentation Contributors. MMSegmentation: OpenMMLab Semantic Segmentation Toolbox and Benchmark. https://github :com/openmmlab/mmsegmentation , 2020. Narayanan, D., Harlap, A., Phanishayee, A., Seshadri, V ., Devanur, N., Granger, G., Gibbons, P., and Zaharia, M. PipeDream: Generalized Pipeline Parallelism for DNN Training. In ACM Symposium on Operating Systems Principles (SOSP 2019) , October 2019. Nestler, L. and Gill, D. HomebrewNLP. https: //github:com/HomebrewNLP/HomebrewNLP , 2021. Newell, A., Yang, K., and Deng, J. Stacked Hourglass Networks for Human Pose Estimation. In European Conference on Computer Vision , pp. 483\u2013499. Springer, 2016. Papamakarios, G., Pavlakou, T., and Murray, I. Masked Autoregressive Flow for Density Estimation. In Guyon, I., Luxburg, U. V ., Bengio, S., Wallach, H., Fergus, R., Vishwanathan, S., and Garnett, R. (eds.), Advances in Neural Information Processing Systems , volume 30. Curran Associates, Inc., 2017. Pendse, M., Thangarasa, V ., Chiley, V ., Holmdahl, R., Hestness, J., and DeCoste, D. Memory Efficient 3D U-Net with Reversible Mobile Inverted Bottlenecks for Brain Tumor Segmentation. In BrainLes@MICCAI , 2020.P\u00e9trowski, A., Dreyfus, G., and Girault, C. Performance Analysis of a Pipelined Backpropagation Parallel Algorithm. IEEE Transactions on Neural Networks , 4 6:970\u2013"
      },
      "Alpha-SGANet: A multi-attention-scale feature pyramid network combined with lightweight network based on Alpha-IoU loss": {
        "authors": [
          "Hong Li",
          "Qian Zhou",
          "Yao Mao",
          "Bing Zhang",
          "Chao Liu"
        ],
        "url": "https://journals.plos.org/plosone/article/file?id=10.1371/journal.pone.0276581&type=printable",
        "ref_texts": "19. LiuS,QiL,QinH,etal.Path aggregation network forinstance segmentatio n[C]//Proc eedings ofthe IEEE conferenc eoncomputer vision andpattern recognition. 2018: 8759\u20138768. https://doi. org/10.",
        "ref_ids": [
          "19"
        ]
      },
      "Tomato seedling classification detection using improved YOLOv3-Tiny": {
        "authors": [],
        "url": "https://www.aeeisp.com/nygcxb/en/article/pdf/preview/10.11975/j.issn.1002-6819.2022.01.025.pdf",
        "ref_texts": "[26] Liu S, Qi L, Qin H, et al. Path aggregation network for instance segmentation[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2018: 8759-8768. ",
        "ref_ids": [
          "26",
          "C"
        ]
      },
      "Comparative study of activation functions and their impact on the YOLOv5 object detection model": {
        "authors": [],
        "url": "https://pure.ulster.ac.uk/files/101743416/Published_Version_June_2022.pdf",
        "ref_texts": "21. Liu, S., Qi, L., Qin, H., Shi, J., Jia, J.: Path aggregation network for instance segmentation. In: IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 8759\u20138768. IEEE(2018)",
        "ref_ids": [
          "21"
        ]
      },
      "100+ FPS detector of personal protective equipment for worker safety: A deep learning approach for green edge computing": {
        "authors": [
          "Xiao Ke"
        ],
        "url": "https://link.springer.com/content/pdf/10.1007/s12083-021-01258-4.pdf",
        "ref_texts": ""
      },
      "YOLO-Rip: A modified lightweight network for Rip currents detection": {
        "authors": [
          "Daoheng Zhu"
        ],
        "url": "https://www.frontiersin.org/articles/10.3389/fmars.2022.930478/pdf",
        "ref_texts": "\u201cFeature pyramid networks for object detection, \u201dinProceedings of the IEEE conference on computer vision and pattern recognition , IEEE. 2117 \u20132125. doi:10.48550/arXiv.1612.03144 Liu, T. Y. (2009). \u201cLearning to rank for information retrieval, \u201dinFoundations and trends\u00aein information retrieval . 3 (3), 225 \u2013331. doi: 10.1561/1500000016 Liu, S., Qi, L., Qin, H., Shi, J., and Jia, J. (2018). \u201cPath aggregation network for instance segmentation, \u201dinProceedings of the IEEE conference on computer vision and pattern recognition , 8759 \u20138768. doi: 10.48550/ arXiv.1803.01534 Liu, Y., and Wu, C. H. (2019). Lifeguarding operational camera kiosk system (LOCKS) for flash rip warning: Development and application. Coast. Eng. 152, 103537. doi: 10.1016/j.coastaleng.2019.103537 Maryan, C., Hoque, M. T., Michael, C., Ioup, E., and Abdelguer fi, M. (2019). Machine learning applications in detecting rip channels from images. Appl. Soft. Comput. 78, 84 \u201393. doi: 10.1016/j.asoc.2019.02.017 Mori, I., De Silva, A., Dusek, G., Davis, J., and Pang, A. (2022). Flow-based rip current detection and visualization . (IEEE Access) 10, 6483 \u201395. doi: 10.1109/ ACCESS.2022.3140340 Mouragues, A., Bonneton, P., Castelle, B., and Martins, K. (2021). Headland rip modelling at a natural beach under high-energy wave conditions. J. Mar. Sci. Eng. 9"
      },
      "WRICNet: A weighted rich-scale inception coder network for remote sensing image change detection": {
        "authors": [
          "Tiffany Mc"
        ],
        "url": "https://arxiv.org/pdf/2108.07955",
        "ref_texts": ""
      },
      "Developing a diagnosis model for dry eye disease in dogs using object detection": {
        "authors": [
          "Joon Young"
        ],
        "url": "https://www.nature.com/articles/s41598-022-25867-y.pdf",
        "ref_texts": ""
      },
      "Crowdsourced-based deep convolutional networks for urban flood depth mapping": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2209.09200",
        "ref_texts": "Alfieri, L., Bisselink, B., Dottori, F., Naumann, G., de Roo, A., Salamon, P., Wyser, K., & Feyen, L. (2017) Global projections of river flood risk in a warmer world. Earth\u2019s Future, 5(2), p.pp. 171-182. https://doi.org/10.1002/2016EF000485 Alizadeh Kharazi, B., & Behzadan, A. H. (2021) Flood depth mapping in street photos with image processing and deep neural networks. Computers, Environment and Urban Systems, 88, p.pp. 101628. https://doi.org/10.1016/j.compenvurbsys.2021.101628 Alizadeh, B., Li, D., Zhang, Z., & Behzadan, A. H. (2021) Feasibility study of urban flood mapping using traffic signs for route optimization. In the proceeding of 28th EG-ICE International Workshop on Intelligent Computing in Engineering, p.pp. 572-581, Berlin, Germany. https://arxiv.org/abs/2109.11712 Arabi, M., Hyun, K., & Mattingly, S. P. (2021) Adaptable resilience assessment framework to evaluate an impact of a disruptive event on freight operations. Transportation Research Record, 2675(12), p.pp. 1327-1344. https://doi.org/10.1177/03611981211033864 Arnell, N. W., & Gosling, S. N. (2016) The impacts of climate change on river flood risk at the global scale. Climatic Change, 134(3), p.pp. 387-401. https://doi.org/10.1007/s10584-014-1084-5 Bochkovskiy, A., Wang, C. Y., & Liao, H. Y. M. (2020) Yolov4: Optimal speed and accuracy of object detection. arXiv preprint. https://arxiv.org/abs/2004.10934 Bowes, B. D., Tavakoli, A., Wang, C., Heydarian, A., Behl, M., Beling, P. A., & Goodall, J. L. (2021) Flood mitigation in coastal urban catchments using real-time stormwater infrastructure control and reinforcement learning. Journal of Hydroinformatics, 23(3), p.pp. 529-547. https://doi.org/10.2166/hydro.2020.080 Center for western weather and water extremes (CW3E) (2021) CW3E Event Summary: 10-16 November 2021, Accessed at 12/14/2021 from https://cw3e.ucsd.edu/cw3e-event-summary-10-16-november-2021/ Chaudhary, P., D'Aronco, S., Moy de Vitry, M., Leit\u00e3o, J. P., & Wegner, J. D. (2019) Flood-water level estimation from social media images. ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial Information Sciences, 4(2/W5), p.pp. 5-12. https://doi.org/10.3929/ethz-b-000351581 Cohen, S., Raney, A., Munasinghe, D., & Loftis, J. D. (2019). The floodwater depth estimation tool (FwDET v2. 0) for improved remote sensing analysis of coastal flooding. Natural Hazards and Earth System Sciences, 19(9), p.pp. 2053. https://doi.org/10.5194/nhess-19-2053-2019 Cross, C., Farhadmanesh, M., & Rashidi, A. (2020) Assessing close-range photogrammetry as an alternative for lidar technology at UDOT divisions No. UT-20.18. Utah. Dept. of Transportation. Division of Research. https://rosap.ntl.bts.gov/view/dot/54923 Fan, Q., Yang, J., Hua, G., Chen, B., & Wipf, D. (2017) A generic deep architecture for single image reflection removal and image smoothing. In Proceedings of the IEEE International Conference on Computer Vision, p.pp. 3238-3247. https://doi.org/10.48550/arXiv.1708.03474 Federal Emergency Management Agency (FEMA) (2007) Floodplain management: principles and current practices. Academic Emergency Management and Related Courses (AEMRC) for the Higher Education Program. https://training.fema.gov/hiedu/aemrc/courses/coursetreat/fm.aspx Federal Highway Administration (2004) Manual on uniform traffic control devices (MUTCD): standard highway signs. Accessed at 08/03/2021 from https://mutcd.fhwa.dot.gov/ser-shs_millennium_eng.htm Fetanat, M., Stevens, M., Jain, P., Hayward, C., Meijering, E., & Lovell, N. H. (2021) Fully elman neural network: a novel deep recurrent neural network optimized by an improved Harris Hawks algorithm for classification of pulmonary arterial wedge pressure. IEEE Transactions on Biomedical Engineering. https://doi.org/10.1109/TBME.2021.3129459 Forati, A. M., & Ghose, R. (2021) Examining community vulnerabilities through multi-scale geospatial analysis of social media activity during Hurricane Irma. International Journal of Disaster Risk Reduction, p.pp. 102701. https://doi.org/10.1016/j.ijdrr.2021.102701 Fu, C. Y., Liu, W., Ranga, A., Tyagi, A., & Berg, A. C. (2017) DSSD: Deconvolutional single shot detector. arXiv preprint. https://arxiv.org/abs/1701.06659 Gebrehiwot, L. Hashemi-Beni, G. Thompson, P., & Kordjamshidi, T.E. (2019) Langan deep convolutional neural network for flood extent mapping using unmanned aerial vehicles data. Sensors, 19 (7), p.pp. 1486. https://doi.org/10.3390/s19071486 Han, D., Liu, Q., & Fan, W. (2018) A new image classification method using CNN transfer learning and web data augmentation. Expert Systems with Applications, 95, p.pp. 43-56. https://doi.org/10.1016/j.eswa.2017.11.028 Han, Z., & Sharif, H. O. (2020) Vehicle-related flood fatalities in Texas, 1959\u20132019. Water, 12(10), p.pp. 2884. https://doi.org/10.3390/w12102884 Hao, W., & Zhili, S. (2020) Improved mosaic: algorithms for more complex images. In Journal of Physics: Conference Series, 1684(1), p.pp. 012094. IOP Publishing. https://iopscience.iop.org/article/10.1088/1742-6596/1684/1/012094/pdf He, K., Zhang, X., Ren, S., & Sun, J. (2015) Spatial pyramid pooling in deep convolutional networks for visual recognition. IEEE Transactions on Pattern Analysis and Machine Intelligence, 37(9), p.pp. 1904-1916. https://doi.org/10.1109/TPAMI.2015.2389824 Hu, R., Zhang, S., Wang, P., Xu, G., Wang, D., & Qian, Y. (2020) The identification of corn leaf diseases based on transfer learning and data augmentation. In Proceedings of the 2020 3rd International Conference on Computer Science and Software Engineering, p.pp. 58-65. https://doi.org/10.1145/3403746.3403905 Hu, T. Y., Armandpour, M., Shrivastava, A., Chang, J. H. R., Koppula, H., & Tuzel, O. (2021) Synt++: Utilizing imperfect synthetic data to improve speech recognition. arXiv preprint, https://arxiv.org/abs/2110.11479 Insurance Bureau of Canada (2021) British Columbia floods cause $450 million in insured damage, Accessed at 12/09/2021 from http://www.ibc.ca/bc/resources/media-centre/media-releases/british-columbia-floods-cause-450-million-in-insured-damage Kamari, M., & Ham, Y., (2021) Vision-based volumetric measurements via deep learning-based point cloud segmentation for material management in jobsites. Automation in Construction, 121, p.pp. 103430. https://doi.org/10.1016/j.autcon.2020.103430 Kingma, D. P., & Ba, J. (2014) Adam: A method for stochastic optimization. arXiv preprint https://arxiv.org/abs/1412.6980 Kong, N., Tai, Y. W., & Shin, J. S. (2013) A physically-based approach to reflection separation: from physical modeling to constrained optimization. IEEE Transactions on Pattern Analysis and Machine Intelligence, 36(2), p.pp. 209-221. https://doi.org/10.1109/TPAMI.2013.45 Lin, T. Y., Doll\u00e1r, P., Girshick, R., He, K., Hariharan, B., & Belongie, S. (2017) Feature pyramid networks for object detection. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, p.pp. 2117-2125. https://arxiv.org/abs/1612.03144 Lin, T. Y., Maire, M., Belongie, S., Hays, J., Perona, P., Ramanan, D., Doll\u00e1r, P., & Zitnick, C. L. (2014) Microsoft COCO: Common objects in context. In European Conference on Computer Vision. Springer, Cham, p.pp. 740-755. https://doi.org/10.1007/978-3-319-10602-1_48 Liu S, Qi L, Qin H, Shi J, & Jia J. (2018) Path aggregation network for instance segmentation. Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition, p.pp. 8759\u201368. https://arxiv.org/abs/1803.01534v4 Liu, W., Anguelov, D., Erhan, D., Szegedy, C., Reed, S., Fu, C. Y., & Berg, A. C. (2016) SSD: Single shot multibox detector. In European Conference on Computer Vision. Springer, Cham, p.pp. 21-37. https://doi.org/10.1007/978-3-319-46448-02 Lo, S. W., Wu, J. H., Lin, F. P., & Hsu, C. H. (2015) Visual sensing for urban flood monitoring. Sensors, 15(8), p.pp. 20006-20029. https://doi.org/10.3390/s150820006 Lyons, M. B., Keith, D. A., Phinn, S. R., Mason, T. J., & Elith, J. (2018) A comparison of resampling methods for remote sensing classification and accuracy assessment. Remote Sensing of Environment, 208, p.pp. 145-153. https://doi.org/10.1016/j.rse.2018.02.026 Mishra, A., Mukherjee, S., Merz, B., Singh, V. P., Wright, D. B., Villarini, G., Paul, S., Kumar, D. N., Khedun, C. P., Niyogi, D., Schumann, G., & Stedinger, J. R. (2022) An overview of flood concepts, challenges, and future directions. Journal of Hydrologic Engineering, 27(6), p.pp. 03122001. https://doi.org/10.1061/(ASCE)HE.1943-5584.0002164 Nath, N. D., & Behzadan, A. H., (2020) Deep convolutional networks for construction object detection under different visual conditions. Frontiers in Built Environment, 6, p.pp. 97. https://doi.org/10.3389/fbuil.2020.00097 National Oceanic and Atmospheric Administration (NOAA) (2021) Northwest River forecast center (NWRFC). Accessed at 12/14/2021 from https://www.nwrfc.noaa.gov/rfc/ Park, S., Baek, F., Sohn, J., & Kim, H. (2021) Computer vision\u2013based estimation of flood depth in flooded-vehicle images. Journal of Computing in Civil Engineering, 35(2), p.pp. 04020072. https://doi.org/10.1061/(ASCE)CP.1943-5487.0000956 Redmon, J., Divvala, S., Girshick, R., & Farhadi, A. (2016) You only look once: Unified, real-time object detection. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, p.pp. 779-788. https://www.cv-foundation.org/openaccess/content_cvpr_2016/html/Redmon_You_Only_Look_CVPR_2016_paper.html Ruder, S. (2016) An overview of gradient descent optimization algorithms. arXiv preprint. https://doi.org/10.48550/arXiv.1609.04747 Sarel, B., & Irani, M. (2004) Separating transparent layers through layer information exchange. In European Conference on Computer Vision. Springer, Berlin, Heidelberg, p.pp. 328-341. https://doi.org/10.1007/978-3-540-24673-2_27 Shaghaghian, Z., & Yan, W. (2019) Application of deep learning in generating desired design options: experiments using synthetic training dataset. arXiv preprint. https://arxiv.org/abs/2001.05849 Sharif, H. O., Hossain, M. M., Jackson, T., & Bin-Shafique, S. (2012) Person-place-time analysis of vehicle fatalities caused by flash floods in Texas. Geomatics, Natural Hazards and Risk, 3(4), p.pp. 311-323. https://doi.org/10.1080/19475705.2011.615343 Sharif, H. O., Jackson, T. L., Hossain, M. M., & Zane, D. (2015) Analysis of flood fatalities in Texas. Natural Hazards Review, 16(1), p.pp. 04014016. https://doi.org/10.1061/(ASCE)NH.1527-6996.0000145 Sharma, K., Aggarwal, A., Singhania, T., Gupta, D., & Khanna, A. (2019) Hiding data in images using cryptography and deep neural network. arXiv preprint. https://doi.org/10.48550/arXiv.1912.10413 Smith, A., (2021) 2020 U.S. billion-dollar weather and climate disasters in historical context. Beyond the Data. Climate news, stories, images, & video. Accessed at 08/08/2021 from https://www.climate.gov/news-features/blogs/beyond-data/2020-us-billion-dollar-weather-and-climate-disasters-historical Stone, W. C., Cheok, G., & Lipman, R. (2000) Automated earthmoving status determination. In Robotics 2000, p.pp. 111-119. https://doi.org/10.1061/40476(299)14 Tammina, S. (2019) Transfer learning using VGG-16 with deep convolutional neural network for classifying images. International Journal of Scientific and Research Publications (IJSRP), 9(10), p.pp. 143-150. http://dx.doi.org/10.29322/IJSRP.9.10.2019.p9420 Tremblay, J., Prakash, A., Acuna, D., Brophy, M., Jampani, V., Anil, C., To, T., Cameracci, E., Boochoon, S., & Birchfield, S. (2018) Training deep networks with synthetic data: Bridging the reality gap by domain randomization. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops, p.pp. 969-977. https://arxiv.org/abs/1804.06516v3 Turpin, A., & Scholer, F. (2006) User performance versus precision measures for simple search tasks. In 29th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, Seattle, WA, p.pp. 11\u201318. https://doi.org/10.1145/1148170.1148176 Wan, R., Shi, B., Hwee, T. A., & Kot, A. C. (2016) Depth of field guided reflection removal. In 2016 IEEE International Conference on Image Processing (ICIP) IEEE, p.pp. 21-25. https://doi.org/10.1109/ICIP.2016.7532311 Wang, C. Y., Liao, H. Y. M., Wu, Y. H., Chen, P. Y., Hsieh, J. W., & Yeh, I. H. (2020) CSPNet: A new backbone that can enhance learning capability of CNN. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops, p.pp. 390-391. https://arxiv.org/abs/1911.11929 Ward, P. J., Van Pelt, S. C., De Keizer, O., Aerts, J. C. J. H., Beersma, J. J., Van den Hurk, B. J. J. M., & Te Linde, A. H. (2014) Including climate change projections in probabilistic flood risk assessment. Journal of Flood Risk Management, 7(2), p.pp. 141-151. https://doi.org/10.1111/jfr3.12029 Zhan, C., Ghaderibaneh, M., Sahu P., & Gupta, H. (2021) DeepMTL: Deep learning based multiple transmitter localization, In 2021 IEEE 22nd International Symposium on a World of Wireless, Mobile and Multimedia Networks (WoWMoM), p.pp. 41-50, https://doi.org/10.1109/WoWMoM51794.2021.00017 Zhu, L., Xie, Z., Liu, L., Tao, B., & Tao, W. (2021) IoU-uniform R-CNN: Breaking through the limitations of RPN. Pattern Recognition, 112, p.pp. 107816. https://doi.org/10.1016/j.patcog.2021.107816 "
      },
      "Towards disturbance rejection in feature pyramid network": {
        "authors": [],
        "url": "https://umji.sjtu.edu.cn/~jzhang/IEEETAI_2023.pdf",
        "ref_texts": "[18] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia, \u201cPath aggregation network for instance segmentation,\u201d in Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit. , 2018, pp. 8759\u20138768.",
        "ref_ids": [
          "18"
        ]
      },
      "The compliance of head-mounted industrial PPE by using deep learning object detectors": {
        "authors": [
          "Velibor Isailovic"
        ],
        "url": "https://www.nature.com/articles/s41598-022-20282-9.pdf",
        "ref_texts": ""
      },
      "Unifying visual perception by dispersible points learning": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2208.08630",
        "ref_texts": "25. Liu, S., Qi, L., Qin, H., Shi, J., Jia, J.: Path aggregation network for instance segmentation. In: CVPR. pp. 8759\u20138768 (2018)",
        "ref_ids": [
          "25"
        ]
      },
      "An anchor-free object detector based on soften optimized bi-directional FPN": {
        "authors": [],
        "url": "https://opus.lib.uts.edu.au/rest/bitstreams/e148446d-1f67-410a-aa4d-37ad99359826/retrieve",
        "ref_texts": "[39] S. Liu, L. Qi, H. Qin, J. Shi, J. Jia, Path aggregation network for instance segmentation, in: Proceedings of the IEEE conference on computer vision and pattern recognition, 2018, pp. 8759\u20138768.",
        "ref_ids": [
          "39"
        ]
      },
      "Streamyolo: Real-time object detection for streaming perception": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2207.10433",
        "ref_texts": "[24] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia, \u201cPath aggregation network for instance segmentation,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition , 2018, pp. 8759\u20138768. 3",
        "ref_ids": [
          "24"
        ]
      },
      "Improving video instance segmentation via temporal pyramid routing": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2107.13155",
        "ref_texts": "[12] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia, \u201cPath aggregation network for instance segmentation,\u201d CVPR , Jun 2018.",
        "ref_ids": [
          "12"
        ]
      },
      "A robust pedestrian detection approach for autonomous vehicles": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2210.10489",
        "ref_texts": "[30] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia, \u201cPath aggregation network for instance segmentation,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition , 2018, pp. 8759\u20138768.",
        "ref_ids": [
          "30"
        ]
      },
      "Deep multi-task networks for occluded pedestrian pose estimation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2206.07510",
        "ref_texts": "[Liu et al., 2018] Liu, S., Qi, L., Qin, H., Shi, J., and Jia, J. (2018). Path aggregation network for instance segmentation. In CVPR .",
        "ref_ids": [
          "Liu et al\\., 2018"
        ]
      },
      "Traffic Sign Detection and Recognition Based onDeep Learning.": {
        "authors": [],
        "url": "http://www.engineeringletters.com/issues_v30/issue_2/EL_30_2_31.pdf",
        "ref_texts": "[23] S. Liu, L. Qi, H. Qin, J. Shi, J. Jia, \u201cPath Aggregation Network for Instance Segmentation,\u201d Proceeding of the IEEE Conference on Computer Vision and Pattern Recognition, 2018 ,pp.8759-8768.",
        "ref_ids": [
          "23"
        ]
      },
      "DPNET: Dual-path network for efficient object detection with Lightweight Self-Attention": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2111.00500",
        "ref_texts": "[23] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia, \u201cPath aggregation network for instance segmentation,\u201d in CVPR , pp. 8759\u2013",
        "ref_ids": [
          "23"
        ]
      },
      "HoughNet: Integrating near and long-range evidence for visual detection": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2104.06773",
        "ref_texts": "[59] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia, \u201cPath aggregation network for instance segmentation,\u201d in IEEE Conference on Computer Vision and Pattern Recognition , 2018, pp. 8759\u20138768.",
        "ref_ids": [
          "59"
        ]
      },
      "Traffic incident detection based on a global trajectory spatiotemporal map": {
        "authors": [
          "Haoxiang Liang"
        ],
        "url": "https://link.springer.com/content/pdf/10.1007/s40747-021-00602-8.pdf",
        "ref_texts": "24. Liu S, Qi L, Qin H, Shi J, Jia J (2018) Path aggregation network for instance segmentation. In: Proceedings of the IEEE conferenceon computer vision and pattern recognition, pp 8759\u2013876825. Yun S, Han D, Oh SJ, Chun S, Choe J, Yoo Y (2019) Cutmix: Regularization strategy to train strong classifiers with localizablefeatures. In: Proceedings of the IEEE/CVF international conferenceon computer vision, pp 6023\u20136032",
        "ref_ids": [
          "24"
        ]
      },
      "Polybuilding: Polygon transformer for end-to-end building extraction": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2211.01589",
        "ref_texts": "[51] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia, \u201cPath aggregation network for instance segmentation,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition , 2018, pp. 8759\u20138768.",
        "ref_ids": [
          "51"
        ]
      },
      "Detr++: Taming your multi-scale detection transformer": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2206.02977",
        "ref_texts": "[15] Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva Ramanan, Piotr Doll \u00b4ar, and C Lawrence Zitnick. Microsoft coco: Common objects in context. In ECCV , 2014. 1, 4[16] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In CVPR , 2018. 2",
        "ref_ids": [
          "15",
          "16"
        ]
      },
      "Predicting students' performance using machine learning algorithms": {
        "authors": [],
        "url": "https://dl.acm.org/doi/pdf/10.1145/3564982.3564990",
        "ref_texts": "[6]Liu, S., Qi, L., Qin, H., Shi, J., & Jia, J. (2018). Path aggregation network for instance segmentation. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 8759-8768).",
        "ref_ids": [
          "6"
        ]
      },
      "Oriented object detection in aerial images based on area ratio of parallelogram": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2109.10187",
        "ref_texts": ""
      },
      "Online video instance segmentation via robust context fusion": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2207.05580",
        "ref_texts": "[39] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 12",
        "ref_ids": [
          "39"
        ]
      },
      "A method of the coverage ratio of street trees based on deep learning": {
        "authors": [],
        "url": "https://reunir.unir.net/bitstream/handle/123456789/13676/ijimai_7_5_3.pdf?sequence=1",
        "ref_texts": "[13] S. Liu, L. Qi, H.F. Qin, J.P. Shi, J.Y. Jia, \u201cPath Aggregation Network for Instance Segmentation,\u201d in 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 8759-8768,2018.",
        "ref_ids": [
          "13"
        ]
      },
      "Automatic worm detection to solve overlapping problems using a convolutional neural network": {
        "authors": [
          "Shinichiro Mori"
        ],
        "url": "https://www.nature.com/articles/s41598-022-12576-9.pdf",
        "ref_texts": ""
      },
      "Multi-Class on-Tree Peach Detection Using Improved YOLOv5s and Multi-Modal Images.": {
        "authors": [],
        "url": "https://www.smartag.net.cn/EN/article/downloadArticleFile.do?attachType=PDF&id=22023",
        "ref_texts": "[25]LIU S , QI L , QIN H , et al . Path aggregation network for instance segmentation [C]// Proceedings of the IEEE Conference on Computer Vision and Pattern Rec \u2010 ognition . Piscataway , New York , USA : IEEE , 2018 : ",
        "ref_ids": [
          "25",
          "C"
        ]
      },
      "The winning solution to the iflytek challenge 2021 cultivated land extraction from high-resolution remote sensing images": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2202.10974",
        "ref_texts": "[17] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia, \u201cPath aggregation network for instance segmentation,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , 2018, pp. 8759\u20138768.[18] H.-S. Fang, J. Sun, R. Wang, M. Gou, Y .-L. Li, and C. Lu, \u201cInstaboost: Boosting instance segmentation via probability map guided copypasting,\u201d in Proceedings of the IEEE/CVF International Conference on Computer Vision , 2019, pp. 682\u2013691.",
        "ref_ids": [
          "17",
          "18"
        ]
      },
      "Yolodrone+: Improved yolo architecture for object detection in uav images": {
        "authors": [],
        "url": "https://repository.bilkent.edu.tr/bitstream/11693/111266/1/YOLODrone_Improved_YOLO_Architecture_for_Object_Detection_in_UAV_Images.pdf",
        "ref_texts": "[24] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia, \u201cPath aggregation network for instance segmentation,\u201d in IEEE CVPR , 2018, pp. 8759\u20138768.",
        "ref_ids": [
          "24"
        ]
      },
      "Design and analysis of welding inspection robot": {
        "authors": [
          "Pengyu Zhang"
        ],
        "url": "https://www.nature.com/articles/s41598-022-27209-4.pdf",
        "ref_texts": ""
      },
      "Fruit stem clamping points location for table grape thinning using improved mask R-CNN": {
        "authors": [],
        "url": "https://www.aeeisp.com/nygcxb/en/article/pdf/preview/10.11975/j.issn.1002-6819.2022.01.019.pdf",
        "ref_texts": "[27] Liu S, Qi L, Qin H, et al. Path aggregation network for instance segmentation[C]//In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition ",
        "ref_ids": [
          "27",
          "C"
        ]
      },
      "Revisiting multi-scale feature fusion for semantic segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2203.12683",
        "ref_texts": "[25] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 8759\u20138768, 2018. 3, 8",
        "ref_ids": [
          "25"
        ]
      },
      "Variational feature pyramid networks": {
        "authors": [
          "Anonymous Submission"
        ],
        "url": "https://proceedings.mlr.press/v162/dimitrakopoulos22a/dimitrakopoulos22a.pdf",
        "ref_texts": "2125, 2017a. Lin, T.-Y ., Goyal, P., Girshick, R., He, K., and Doll \u00b4ar, P. Focal loss for dense object detection. In Proceedings of the IEEE International Conference on Computer Vision , pp. 2980\u20132988, 2017b. Liu, S., Qi, L., Qin, H., Shi, J., and Jia, J. Path aggregation network for instance segmentation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pp. 8759\u20138768, 2018. Louizos, C., Ullrich, K., and Welling, M. Bayesian compression for deep learning. Advances in Neural Information Processing Systems , 30, 2017. Miller, D., Nicholson, L., Dayoub, F., and S \u00a8underhauf, N. Dropout sampling for robust object detection in open-set conditions. In 2018 IEEE International Conference on Robotics and Automation (ICRA) , pp. 3243\u20133249. IEEE, 2018. Molchanov, D., Ashukha, A., and Vetrov, D. Variational dropout sparsifies deep neural networks. In International Conference on Machine Learning , pp. 2498\u20132507, 2017. Variational Feature Pyramid Networks Molchanov, P., Mallya, A., Tyree, S., Frosio, I., and Kautz, J. Importance estimation for neural network pruning. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pp. 11264\u201311272, 2019. Petersen, K. B., Pedersen, M. S., et al. The matrix cookbook. Technical University of Denmark , 7(15):510, 2008. Redmon, J., Divvala, S., Girshick, R., and Farhadi, A. You only look once: Unified, real-time object detection. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pp. 779\u2013788, 2016. Ren, S., He, K., Girshick, R., and Sun, J. Faster R-CNN: towards real-time object detection with Region Proposal Networks. IEEE Transactions in Pattern Analysis and Machine Intelligence , 39(6):1137\u20131149, 2016. Singh, D., Jain, N., Jain, P., Kayal, P., Kumawat, S., and Batra, N. Plantdoc: A dataset for visual plant disease detection, 2019. Srivastava, N., Hinton, G., Krizhevsky, A., Sutskever, I., and Salakhutdinov, R. Dropout: a simple way to prevent neural networks from overfitting. Journal of Machine Learning Research , 15(1):1929\u20131958, 2014. Sun, K., Zhao, Y ., Jiang, B., Cheng, T., Xiao, B., Liu, D., Mu, Y ., Wang, X., Liu, W., and Wang, J. High-resolution representations for labeling pixels and regions. arXiv preprint arXiv:1904.04514 , 2019. Szegedy, C., Liu, W., Jia, Y ., Sermanet, P., Reed, S., Anguelov, D., Erhan, D., Vanhoucke, V ., and Rabinovich, A. Going deeper with convolutions. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pp. 1\u20139, 2015. Tan, M., Pang, R., and Le, Q. V . Efficientdet: Scalable and efficient object detection. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pp. 10781\u201310790, 2020. Tian, Z., Shen, C., Chen, H., and He, T. Fcos: Fully convolutional one-stage object detection. In Proceedings of the IEEE/CVF International Conference on Computer Vision , pp. 9627\u20139636, 2019. Tibshirani, R. Regression shrinkage and selection via the Lasso. Journal of the Royal Statistical Society: Series B"
      },
      "Visual detection of personal protective equipment and safety gear on industry workers": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2212.04794",
        "ref_texts": ""
      },
      "Object detectors involving a NAS-gate convolutional module and capsule attention module": {
        "authors": [
          "Thanaporn Viriyasaranon"
        ],
        "url": "https://www.nature.com/articles/s41598-022-07898-7.pdf",
        "ref_texts": ""
      },
      "Instance-wise occlusion and depth orders in natural scenes": {
        "authors": [
          "Hyunmin Lee",
          "Jaesik Park"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2022/papers/Lee_Instance-Wise_Occlusion_and_Depth_Orders_in_Natural_Scenes_CVPR_2022_paper.pdf",
        "ref_texts": "[41] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path Aggregation Network for Instance Segmentation. In Proceedings of the IEEE International Conference on Computer Vision and Pattern Recognition (CVPR) , 2018. 1",
        "ref_ids": [
          "41"
        ]
      },
      "Pixdet: Prohibited items x-ray image detection in complex background": {
        "authors": [],
        "url": "https://ebooks.iospress.nl/pdf/doi/10.3233/FAIA220521",
        "ref_texts": "[12] Liu S, Qi L, Qin H, et al. Path aggregation network for instance segmentation[C]//Proceedings of the IEEE conference on computer vision and pattern recognition. 2018: 8759-8768.",
        "ref_ids": [
          "12",
          "C"
        ]
      },
      "Benchmarking performance of object detection under image distortions in an uncontrolled environment": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2210.15999",
        "ref_texts": "[25] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia, \u201cPath aggregation network for instance segmentation,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition , 2018, pp. 8759\u20138768.",
        "ref_ids": [
          "25"
        ]
      },
      "Automatic video analysis framework for exposure region recognition in X-ray imaging automation": {
        "authors": [],
        "url": "https://hal.science/hal-03719812/file/Sun%20et%20al-2022-Automatic%20video%20analysis%20framework%20for%20exposure%20region%20recognition%20in%20X-ray.pdf",
        "ref_texts": "[28] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia, \u201cPath aggregation network for instance segmentation,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition , 2018, pp. 8759\u20138768.",
        "ref_ids": [
          "28"
        ]
      },
      "Rethinking mask heads for partially supervised instance segmentation": {
        "authors": [],
        "url": "https://kaizhao.net/publications/neucom2022rethinking.pdf",
        "ref_texts": "[15] S. Liu, L. Qi, H. Qin, J. Shi, J. Jia, Path aggregation network for instance 415 segmentation, in: Proceedings of the IEEE conference on computer vision and pattern recognition, 2018, pp. 8759{8768.",
        "ref_ids": [
          "15"
        ]
      },
      "Consistent video instance segmentation with inter-frame recurrent attention": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2206.07011",
        "ref_texts": "[19] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 8759\u20138768, 2018.",
        "ref_ids": [
          "19"
        ]
      },
      "Unauthorized Unmanned Aerial vehicle detection using YOLOv5 and transfer learning": {
        "authors": [],
        "url": "https://www.preprints.org/manuscript/202202.0185/download/final_file",
        "ref_texts": "18. Liu, S.; Qi, L.; Qin, H.; Shi, J.; Jia, J. Path aggregation network for instance segmentation. In Proceedings of the IEEE conference on computer vision and pattern recognition 2018 (pp. 8759-8768).",
        "ref_ids": [
          "18"
        ]
      },
      "Automated physical distance estimation and crowd monitoring through surveillance video": {
        "authors": [
          "Masum Shah"
        ],
        "url": "https://link.springer.com/content/pdf/10.1007/s42979-022-01480-8.pdf",
        "ref_texts": ""
      },
      "Isda: Position-aware instance segmentation with deformable attention": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2202.12251",
        "ref_texts": "[10] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia, \u201cPath aggregation network for instance segmentation,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition , 2018, pp. 8759\u20138768. 1",
        "ref_ids": [
          "10"
        ]
      },
      "BFF R-CNN: Balanced feature fusion for object detection": {
        "authors": [],
        "url": "https://www.jstage.jst.go.jp/article/transinf/E105.D/8/E105.D_2021EDP7261/_pdf",
        "ref_texts": "[48] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia, \u201cPath aggregation network for instance segmentation,\u201d IEEE Conf. Comput. Vis. Pattern Recognit.",
        "ref_ids": [
          "48"
        ]
      },
      "Self-Balanced R-CNN for instance segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2404.16633",
        "ref_texts": "[36] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia, \u201cPath aggregation network for instance segmentation,\u201d in Proceedings of the IEEE conference on Computer Vision and Pattern Recognition , pp. 8759\u20138768, 2018.",
        "ref_ids": [
          "36"
        ]
      },
      "Instance segmentation convolutional neural network based on multi-scale attention mechanism": {
        "authors": [
          "Wang Gaihua",
          "Lin Jinheng",
          "Cheng Lei",
          "Dai Yingying",
          "Zhang Tianlun"
        ],
        "url": "https://journals.plos.org/plosone/article/file?id=10.1371/journal.pone.0263134&type=printable",
        "ref_texts": ""
      },
      "Surface defect detection and evaluation for marine vessels using multi-stage deep learning": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2203.09580",
        "ref_texts": "[15] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia, \u201cPath aggregation network for instance segmentation,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , 2018, pp. 8759\u20138768.",
        "ref_ids": [
          "15"
        ]
      },
      "\u57fa\u4e8e\u6539\u8fdb YOLOv5s \u7684\u65e0\u4eba\u673a\u56fe\u50cf\u5b9e\u65f6\u76ee\u6807\u68c0\u6d4b": {
        "authors": [],
        "url": "https://www.researching.cn/ArticlePdf/m00029/2022/49/3/210372.pdf",
        "ref_texts": " Liu S, Qi L, Qin H F, et al. Path aggregation network for instance segmentation[C]//Proceedings of 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2018: 8759\u20138768. doi: 10.1109/CVPR.2018.00913.[20]",
        "ref_ids": [
          "20"
        ]
      },
      "kMaX-DeepLab: k-means Mask Transformer": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2207.04044.pdf?trk=public_post_comment-text",
        "ref_texts": "68. Liu, S., Qi, L., Qin, H., Shi, J., Jia, J.: Path aggregation network for instance segmentation. In: CVPR (2018) 13, 24, 25",
        "ref_ids": [
          "68"
        ]
      },
      "Detecting and localizing strawberry centers for robotic harvesting in field environment": {
        "authors": [
          "N A",
          "O D",
          "E L",
          "A P",
          "E A"
        ],
        "url": "https://par.nsf.gov/servlets/purl/10451362",
        "ref_texts": "176, 105634. He, K., Zhang, X., Ren, S., & Sun, J. (2015). Spatial pyramid pooling in deep convolutional networks for visual recognition. IEEE transactions on pattern analysis and machine intelligence, 37 , 1904 \u20131916. He, Z., Karkee, M., & Upadhayay, P. (2021). Detection of strawberries with varying maturity levels for robotic harvesting using YOLOv4. 2021 ASABE Annual International Virtual Meeting , (p\u00e1g. 1). Hussain, I., He, Q., & Chen, Z. (2018). Automatic fruit recognition based on dcnn for commercial source trace system. Int. J. Comput. Sci. Appl, 8 , 01\u201314. Lin, T. -Y., Maire, M., Belongie, S., Hays, J., Perona, P., Ramanan, D., . . . Zitnick, C. L. (2014). Microsoft coco: Common objects in context. European conference on computer vision , (p\u00e1gs. 740 \u2013755). Liu, S., Qi, L., Qin, H., Shi, J., & Jia, J. (2018). Path aggregation network for instance segmentation. Proceedings of the IEEE conference on computer vision and pattern recognition , (p\u00e1gs. 8759 \u20138768). Redmon, J., & Farhadi, A. (2017). YOLO9000: better, faster, stronger. Proceedings of the IEEE conference on computer vision and pattern recognition , (p\u00e1gs. "
      },
      "Split-gcn: Effective interactive annotation for segmentation of disconnected instance": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2112.06454",
        "ref_texts": "[28] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 8759\u20138768, 2018. 1, 7",
        "ref_ids": [
          "28"
        ]
      },
      "Research on the identification and detection of field pests in the complex background based on the rotation detection algorithm": {
        "authors": [
          "Wei Zhang"
        ],
        "url": "https://www.frontiersin.org/journals/plant-science/articles/10.3389/fpls.2022.1011499/pdf",
        "ref_texts": "\u201cSsd: Single shot multibox detector, \u201dIn: B. Leibe, J. Matas, N. Sebe and M. Welling Computer Vision \u2013ECCV 2016. ECCV 2016. Lecture Notes in Computer Science (Cham: Springer), 21 \u201337. doi: 10.1007/978-3-319-46448-0_2Liu, L., Wang, R., Xie, C., Yang, P., Wang, F., Sudrman, S., et al. (2019). \u201cPestNet: An end-to-end deep learning approach for large-scale multi-class pest detectionand classi fication, \u201dinIEEE Access . vol 7, 45301 \u201345312. doi: 10.1109/ ACCESS.2019.2909522 Liu, S., Qi, L., Qin, H., Shi, J., and Jia, J. (2018). \u201cPath aggregation network for instance segmentation, \u201din2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition ., 8759 \u20138768. doi: 10.1109/CVPR.2018.00913 Ma, Y., Qu, X., Feng, D., Zhang, P., Huang, H., Zhang, Z., et al. (2022)."
      },
      "Trapped in texture bias? A large scale comparison of deep instance segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2401.09109",
        "ref_texts": "43. Liu, S., Qi, L., Qin, H., Shi, J., Jia, J.: Path aggregation network for instance segmentation. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) (Jun 2018)",
        "ref_ids": [
          "43"
        ]
      },
      "Deep Learning for Advanced Similar Musical Instrument Detection and Recognition": {
        "authors": [],
        "url": "https://ir.lib.cyut.edu.tw/bitstream/310901800/40795/2/IJCS_49_3_27.pdf",
        "ref_texts": "[50] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia, \u201cPath Aggregation Network for Instance Segmentation,\u201d in Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition , 2018, pp. 8759 \u20138768, doi: ",
        "ref_ids": [
          "50"
        ]
      },
      "Multiscale voting mechanism for rice leaf disease recognition under natural field conditions": {
        "authors": [
          "George Bray"
        ],
        "url": "https://rgu-repository.worktribe.com/preview/1898565/TANG%202022%20Multiscale%20voting%20mechanism%20%28AAM%29.pdf",
        "ref_texts": "28. Liu S, Qi L, Qin H, Shi J, Jia J. Path aggregation network for instance segmentation. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition ; 2018.",
        "ref_ids": [
          "28"
        ]
      },
      "Depth and thermal images in face detection-a detailed comparison between image modalities": {
        "authors": [],
        "url": "https://dl.acm.org/doi/pdf/10.1145/3523111.3523114",
        "ref_texts": "[16] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. 2018. Path aggregation network for instance segmentation. In Proceedings of the IEEE conference on computer vision and pattern recognition . 8759\u20138768.",
        "ref_ids": [
          "16"
        ]
      },
      "RC-net: Regression correction for end-to-end chromosome instance segmentation": {
        "authors": [],
        "url": "https://www.frontiersin.org/articles/10.3389/fgene.2022.895099/pdf",
        "ref_texts": "\u201cMicrosoft CoCo: Common Objects in Context, \u201din European Conference on Computer Vision, 740 \u2013755. doi:10.1007/978-3-319-10602-1_48 Liu, S., Qi, L., Qin, H., Shi, J., and Jia, J. (2018). \u201cPath Aggregation Network for Instance Segmentation, \u201din Proceeding of 31st IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 8759 \u20138768. doi:10.1109/ cvpr.2018.00913 McGuinness, K., and O \u2019Connor, N. E. (2010). A Comparative Evaluation of Interactive Segmentation Algorithms. Pattern Recognition 43 (2), 434 \u2013444. doi:10.1016/j.patcog.2009.03.008 Minaee, S., Fotouhi, M., and Khalaj, B. H. (2014). A Geometric Approach to Fully Automatic Chromosome Segmentation. in Proceeding of Signal Processing inMedicine & Biology Symposium. 1 \u20136. doi:10.1109/SPMB.2014.7163174 Nair, R. M., Remya, R. S., and Sabeena, K. (2015). Karyotyping Techniques of Chromosomes: a Survey. Ijctt22 (1), 30 \u201334. doi:10.14445/22312803/IJCTT-V22P107 Neubeck, A., and Van Gool, L. (2006). \u201cEfficient Non-maximum Suppression, \u201din Proceeding of 18th International Conference on Pattern Recognition (ICPR2006), 850 \u2013855. doi:10.1109/icpr.2006.479 Pravina, V. A. (2015). Survey on Techniques Used for M-FISH Image Segmentation for Classi fication of Chromosomes. Middle East. J. Sci. Res. 23"
      },
      "Deepaco: A robust deep learning-based automatic checkout system": {
        "authors": [
          "Long Hoang",
          "Duong Nguyen",
          "Ngoc Tran",
          "Hung Nguyen",
          "Tai Huu",
          "Phuong Tran",
          "Joon Jeon",
          "Min Jeon",
          "Jae Wook"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2022W/AICity/papers/Pham_DeepACO_A_Robust_Deep_Learning-Based_Automatic_Checkout_System_CVPRW_2022_paper.pdf",
        "ref_texts": "[13] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia. Path aggregation network for instance segmentation. In IEEE Conf. Comput. Vis. Pattern Recog. , pages 8759\u20138768, 2018. 4",
        "ref_ids": [
          "13"
        ]
      },
      "AAF-Net: Scene text detection based on attention aggregation features": {
        "authors": [
          "Mengmeng Chen",
          "Mayire Ibrayim",
          "Askar Hamdulla"
        ],
        "url": "https://journals.plos.org/plosone/article/file?id=10.1371/journal.pone.0272322&type=printable",
        "ref_texts": "31. LiuS,QiL,QinH,etal.Path aggregation network forinstance segmentatio n.Procee dings oftheIEEE conferen ceoncomputer vision andpattern recognition. 2018: 8759\u20138768.",
        "ref_ids": [
          "31"
        ]
      },
      "Joint multi-person body detection and orientation estimation via one unified embedding": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2210.15586",
        "ref_texts": "[25] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia, \u201cPath aggregation network for instance segmentation,\u201d inCVPR , 2018, pp. 8759\u20138768.",
        "ref_ids": [
          "25"
        ]
      },
      "Consistent targets provide better supervision in semi-supervised object detection": {
        "authors": [],
        "url": "https://openreview.net/pdf?id=HeEqRvCtN2-",
        "ref_texts": "2980\u20132988, 2017b. Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In Proceedings of the IEEE conference on computer vision and pattern recognition , pp. 8759\u20138768, 2018. Wei Liu, Dragomir Anguelov, Dumitru Erhan, Christian Szegedy, Scott Reed, Cheng-Yang Fu, and Alexander C Berg. Ssd: Single shot multibox detector. In European conference on computer vision , pp. 21\u201337. Springer, 2016. Yen-Cheng Liu, Chih-Yao Ma, Zijian He, Chia-Wen Kuo, Kan Chen, Peizhao Zhang, Bichen Wu, Zsolt Kira, and Peter Vajda. Unbiased teacher for semi-supervised object detection. arXiv preprint arXiv:2102.09480 , 2021. Yen-Cheng Liu, Chih-Yao Ma, and Zsolt Kira. Unbiased teacher v2: Semi-supervised object detection for anchor-free and anchor-based detectors. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pp. 9819\u20139828, 2022. Joseph Redmon and Ali Farhadi. Yolo9000: better, faster, stronger. In Proceedings of the IEEE conference on computer vision and pattern recognition , pp. 7263\u20137271, 2017. Joseph Redmon, Santosh Divvala, Ross Girshick, and Ali Farhadi. You only look once: Unified, real-time object detection. In Proceedings of the IEEE conference on computer vision and pattern recognition , pp. 779\u2013788, 2016. Shaoqing Ren, Kaiming He, Ross Girshick, and Jian Sun. Faster r-cnn: Towards real-time object detection with region proposal networks. Advances in neural information processing systems , 28, 2015. Hamid Rezatofighi, Nathan Tsoi, JunYoung Gwak, Amir Sadeghian, Ian Reid, and Silvio Savarese. Generalized intersection over union: A metric and a loss for bounding box regression. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , pp. 658\u2013666, 2019. Kihyuk Sohn, Zizhao Zhang, Chun-Liang Li, Han Zhang, Chen-Yu Lee, and Tomas Pfister. A simple semi-supervised learning framework for object detection. arXiv preprint arXiv:2005.04757 , 2020. Yihe Tang, Weifeng Chen, Yijun Luo, and Yuting Zhang. Humble teachers teach better students for semi-supervised object detection. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pp. 3132\u20133141, 2021. Antti Tarvainen and Harri Valpola. Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results. arXiv preprint arXiv:1703.01780 , 2017."
      },
      "Real-time Arabic Sign Language Recognition based on YOLOv5.": {
        "authors": [],
        "url": "https://www.scitepress.org/PublishedPapers/2022/109793/109793.pdf",
        "ref_texts": "618. Jiao, L., Zhang, F., Liu, F., Yang, S., Li, L., Feng, Z., and Qu, R. (2019). A survey of deep learning-based object detection. IEEE access , 7:128837\u2013128868. Krizhevsky, A., Sutskever, I., and Hinton, G. E. (2012). Imagenet classification with deep convolutional neural networks. Advances in neural information processing systems , 25:1097\u20131105. Latif, G., Mohammad, N., Alghazo, J., AlKhalaf, R., and AlKhalaf, R. (2019). Arasl: Arabic alphabets sign language dataset. Data in brief , 23:103777. Lin, T.-Y ., Maire, M., and Belongie, S. e. a. (2014). Microsoft coco: Common objects in context. In European conference on computer vision , pages 740\u2013755. Springer. Liu, S., Qi, L., Qin, H., Shi, J., and Jia, J. (2018). Path aggregation network for instance segmentation. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 8759\u20138768. Miko\u0142ajczyk, A. and Grochowski, M. (2018). Data augmentation for improving deep learning in image classifica-IMPROVE 2022 2nd International Conference on Image Processing and Vision Engineering 24",
        "ref_ids": [
          "618"
        ]
      },
      "Experimental large-scale jet flames' geometrical features extraction for risk management using infrared images and deep learning segmentation methods": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2201.07931",
        "ref_texts": "[15] S. Liu, L. Qi, H. Qin, J. Shi, J. Jia, Path aggregation network for instance segmentation, IEEE. CVF Conference on Computer Vision and Pattern Recognition 1 (2018) 8759{8768. doi:10.1109/CVPR.2018.00913 .",
        "ref_ids": [
          "15"
        ]
      },
      "Neural architecture search for dense prediction tasks in computer vision": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2202.07242",
        "ref_texts": "10.1007/s11263-019-01247-4 Liu S, Qi L, Qin H, Shi J, Jia J (2018b) Path aggregation network for instance segmentation. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) Liu W, Anguelov D, Erhan D, Szegedy C, Reed S, Fu CY, Berg AC (2016) Ssd: Single shot multibox detector. In: Leibe B, Matas J, Sebe N, Welling M (eds) Computer Vision { ECCV 2016, Springer International Publishing, Cham, pp 21{37 Long J, Shelhamer E, Darrell T (2015) Fully convolutional networks for semantic segmentation. In: 2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp 3431{3440 Lu Z, Whalen I, Boddeti V, Dhebar Y, Deb K, Goodman E, Banzhaf W (2019) Nsga-net: Neural architecture search using multi-objective genetic algorithm. In: Proceedings of the Genetic and Evolutionary Computation Conference, Association for Computing Machinery, New York, NY, USA, GECCO '19, p 419{427 Ma N, Zhang X, Zheng HT, Sun J (2018) Shu\u000fenet v2: Practical guidelines for eflcient cnn architecture design. In: The European Conference on Computer Vision (ECCV) Mayer N, Ilg E, H\u007f ausser P, Fischer P, Cremers D, Dosovitskiy A, Brox T (2016) A large dataset to train convolutional networks for disparity, optical sow, and scene ow estimation. In: 2016 IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2016, Las Vegas, NV, USA, June 27-30, 2016, IEEE Computer Society, pp 4040{4048 Mellor J, Turner J, Storkey A, Crowley EJ (2021) Neural architecture search without training. In: International Conference on Machine Learning Mendoza H, Klein A, Feurer M, Springenberg J, Hutter F"
      },
      "Fast Fourier Convolution Based Remote Sensor Image Object Detection for Earth Observation": {
        "authors": [
          "Philippe Moreels"
        ],
        "url": "https://arxiv.org/pdf/2209.00551",
        "ref_texts": "[17] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia, \u201cPath aggregation ne twork for instance segmentation,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition, 2018, pp. 8759\u2013",
        "ref_ids": [
          "17"
        ]
      },
      "DDBN: Dual detection branch network for semantic diversity predictions": {
        "authors": [
          "Qifeng Lin"
        ],
        "url": "https://www.chengjianglong.com/publications/DDBN_PR.pdf",
        "ref_texts": "[27] S. Liu , L. Qi , H. Qin , J. Shi , J. Jia , Path aggregation network for instance segmentation, in: Proceedings of the IEEE conference on computer vision and pattern recognition, 2018, pp. 8759\u20138768 . ",
        "ref_ids": [
          "27"
        ]
      },
      "Online rail fastener detection based on YOLO network": {
        "authors": [],
        "url": "https://cdn.techscience.cn/ueditor/files/cmc/TSP_CMC-72-3/TSP_CMC_27947/TSP_CMC_27947.pdf",
        "ref_texts": "[24] S. Liu, L. Qi, H. Qin, J. Shi and J. Jia, \u201cPath aggregation network for instance segmentation,\u201d in Proc. CVPR , Salt Lake City, UT, USA, pp. 8759\u20138768, 2018.",
        "ref_ids": [
          "24"
        ]
      },
      "Attention mechanism improves YOLOv5x for detecting vehicles on surveillance videos": {
        "authors": [],
        "url": "https://scholarworks.indianapolis.iu.edu/bitstreams/fd1c907b-0652-460f-a1d9-273d16a03965/download",
        "ref_texts": "[25] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia, 2018. Path aggregation network for instance segmentation. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 8759-8768).",
        "ref_ids": [
          "25"
        ]
      },
      "GH-Feat: Learning Versatile Generative Hierarchical Features From GANs": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2301.05315",
        "ref_texts": "[48] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia, \u201cPath aggregation network for instance segmentation,\u201d in IEEE Conf. Comput. Vis. Pattern Recog., 2018. 4",
        "ref_ids": [
          "48"
        ]
      },
      "Flaw detection in white porcelain wine bottles based on improved YOLOv4 algorithm": {
        "authors": [],
        "url": "https://www.frontiersin.org/articles/10.3389/fbioe.2022.928900/pdf",
        "ref_texts": "(2017). Feature Pyramid Networks for Object Detection. IEEE Conf. Comput. Vis. Pattern Recognit. , 936 \u2013944. doi:10.1109/CVPR.2017.106 Liu, Q., Wang, C., Li, Y., Gao, M., and Li, J. (2022a). A Fabric Defect Detection Method Based on Deep Learning. IEEE Access 10, 4284 \u20134296. doi:10.1109/ ACCESS.2021.3140118 Liu, S., Qi, L., Qin, H., Shi, J., and Jia, J. (2018). Path Aggregation Network for Instance Segmentation. IEEE/CVF Conf. Comput. Vis. Pattern Recognit. , 8759 \u20138768. doi:10.1109/CVPR.2018.00913 Liu, W., Anguelov, D., Erhan, D., Szegedy, C., Reed, S., Fu, C.-Y., et al. (2016). \u201cSSD: Single Shot MultiBox Detector, \u201din European Conference on Computer Vision (ECCV) (Cham: Springer), 21 \u201337. doi:10.1007/978-3-319-46448-0_2 Liu, X. M., Tian, H., Yang, Y. M., Wang, Y., and Zhao, X. X. (2022b). Research on Image Detection Method of Insulator Defects in Complex Environment.J. Electron. Meas. Instrum. (2), 57 \u201367. doi:10.13382/j.jemi.B2104557 Qiu, Y., Ai, Z., Lin, Y., Xu, Z., and Liu, X. (2022). \u201cDetecting Defects of Wooden Boards by Improved YOLOv4-Tiny Algorithm, \u201din Lecture Notes in Electrical Engineering,Proceedings of 2021 Chinese Intelligent Systems Conference (Singapore: Springer), 519 \u2013527. doi:10.1007/978-981-16-6320-8_53805 Redmon, J., Divvala, S., Girshick, R., and Farhadi, A. (2016). You Only Look once: Unified, Real-Time Object Detection. IEEE Conf. Comput. Vis. Pattern Recognit. , 779 \u2013788. doi:10.1109/CVPR.2016.91 Redmon, J., and Farhadi, A. (2017). \u201cYOLO9000: Better, Faster, Stronger, \u201din 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR),6517 \u20136525. doi:10.1109/CVPR.2017.690 Redmon, J., and Farhadi, A. (2018). Yolov3: An Incremental Improvement. arXiv preprint arXiv:1804.02767 . Ren, S., He, K., Girshick, R., and Sun, J. (2017). Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks. IEEE Trans. Pattern Anal. Mach. Intell. 39 (6), 1137 \u20131149. doi:10.1109/TPAMI.2016.2577031 Sun, Y. P., Zhong, P. S., Liu, M., Cao, A. X., and Li, L. (2022). Stamping Parts Defect Detection Based on YOLOv4 Algorithm. Forg. Stamp. Technol. 47 (01), 222"
      },
      "\u57fa\u4e8e\u6539\u8fdb YOLOv4 \u7b97\u6cd5\u7684\u5ba4\u5185\u573a\u666f\u76ee\u6807\u68c0\u6d4b": {
        "authors": [],
        "url": "https://www.researching.cn/ArticlePdf/m00002/2022/59/18/1815003.pdf",
        "ref_texts": "[20]LiuS,QiL,QinH F,etal.Pathaggregationnetwork forinstancesegmentation [C]\u22252018IEEE/CVF Conference onComputerVisionandPatternRecognition ,June18-23, 2018,Salt Lake City ,UT,USA.New York:IEEE Press,2018:8759 -8768.",
        "ref_ids": [
          "20",
          "C"
        ]
      },
      "Unleashing the Potential of Vision-Language Models for Long-Tailed Visual Recognition.": {
        "authors": [],
        "url": "https://bmvc2022.mpi-inf.mpg.de/0481.pdf",
        "ref_texts": "[21] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 8759\u20138768, 2018.",
        "ref_ids": [
          "21"
        ]
      },
      "Review of Optimal Convolutional Neural Network Accelerator Platforms for Mobile Devices.": {
        "authors": [],
        "url": "http://jcse.kiise.org/files/V16N2-06.pdf",
        "ref_texts": "32. S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia, \"Path aggregation network for instance segmentation,\" in Proceedings of 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition , Salt Lake City, UT, USA, 2018, pp. 8759-8768.",
        "ref_ids": [
          "32"
        ]
      },
      "Identification and localization of walnut varieties based on YOLOv5": {
        "authors": [],
        "url": "http://zgnjhxb.niam.com.cn/EN/article/downloadArticleFile.do?attachType=PDF&id=1519",
        "ref_texts": "[12]LiuS,QiL,QinH,etal.PathAggregationNetworkfor InstanceSegmentation[J].IEEE,2018.",
        "ref_ids": [
          "12",
          "J"
        ]
      },
      "Real-time parking sign detection for smart street parking": {
        "authors": [],
        "url": "https://digital.lib.washington.edu/researchworks/bitstream/handle/1773/48418/Jin_washington_0250O_23911.pdf?sequence=1",
        "ref_texts": " 24 References. [1] P. F. Felzenszwalb, R. B. Girshick, D. McAllester, and D. Ramanan. Object detection with discriminatively trained part based models. IEEE Transactions on Pattern Analysis and Machine Intelligence, 32(9):1627\u20131645, 2010. [2] R. Girshick, J. Donahue, T. Darrell, and J. Malik. Rich feature hierarchies for accurate object detection and semantic segmentation. In Computer Vision and Pattern Recognition (CVPR), 2014 IEEE Conference on, pages 580\u2013587. IEEE, 2014. [3] Redmon, J., Divvala, S., Girshick, R., and Farhadi, A., \u201cYou Only Look Once: Unified, Real-Time Object Detection\u201d, arXiv e-prints, 2015. arXiv:1506.02640 [4] Bochkovskiy, A., Wang, C.-Y., and Liao, H.-Y. M., \u201cYOLOv4: Optimal Speed and Accuracy of Object Detection\u201d, arXiv e-prints, 2020. arXiv:2004.10934 [5] Girshick, R., \u201cFast R-CNN\u201d, arXiv preprint, Apr 2015. arXiv:1504.08083 [6] Chien-Yao Wang, Hong-Yuan Mark Liao, Yueh-Hua Wu, Ping-Yang Chen, Jun-Wei Hsieh, and I-Hau Yeh. CSPNet: A new backbone that can enhance learning capability of cnn. Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshop (CVPR Workshop), 2020. [7] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 8759\u20138768, 2018. [8] Joseph Redmonand, Ali Farhadi. YOLOv3: Anincremental improvement. arXiv preprint arXiv:1804.02767, 2018. [9] Nelson, Joseph, and Jacob Solawetz. \u201cYOLOv5 Is Here: State-of-the-Art Object Detection at 140 FPS.\u201d Roboflow, Jun 10, 2020, blog.roboflow.com/yolov5-is-here/ [10] Rajput, M., \u201cYOLO V5 Is Here! Custom Object Detection Tutorial with YOLO V5.\u201d Towards AI, 14 Jun 2020, pub.towardsai.net/yolo-v5-is-here-custom-object-detection-tutorial-with-yolo-v5-12666ee1774e [11] Solawetz, J., \u201cYOLOv5 New Version Improvements And Evaluation\u201d roboflow, 29 Jun, 2020 https://blog.roboflow.com/yolov5-improvements-and-evaluation/ [12] Mariusz Bojarski, Davide Del Testa, Daniel Dworakowski, Bernhard Firner, Beat Flepp, Prasoon Goyal, Lawrence D. Jackel, Mathew Monfort, Urs Muller, Jiakai Zhang, Xin Zhang, Jake Zhao and Karol Zieba.\u201d End to End Learning for Self-Driving Cars\u201d, 2016; arXiv:1604.07316. [13] Yolo v5: https://github.com/ultralytics/yolov5 [14] Mastromichalakis, S., \u201cALReLU: A different approach on Leaky ReLU activation function to improve Neural Networks Performance\u201d, arXiv e-prints, 2020. arXiv:2012.07564 [15] Li, J., \u201cAn Algorithm for Street Parking Sign Rule Generatio\u201d University of Washington Tacoma, 2020 [16] Duran-Vega, M. A., Gonzalez-Mendoza, M., Chang-Fernandez, L., & Suarez-Ramirez, C. D. (2021). TYolov5: A Temporal Yolov5 Detector Based on Quasi-Recurrent Neural ",
        "ref_ids": [
          "1",
          "2",
          "3",
          "4",
          "5",
          "6",
          "7",
          "8",
          "9",
          "10",
          "11",
          "12",
          "13",
          "14",
          "15",
          "16"
        ]
      },
      "Research of apple leaf disease defect based on improved YOLOv4 algorithm": {
        "authors": [],
        "url": "http://zgnjhxb.niam.com.cn/EN/article/downloadArticleFile.do?attachType=PDF&id=1650",
        "ref_texts": "[16]LiuS,QiL,QinH,etal.Pathaggregationnetworkfor instancesegmentation[C].IEEEConferenceonComputer VisionandPatternRecognition.2018:8759-8768.",
        "ref_ids": [
          "16",
          "C"
        ]
      },
      "Deep learning for gastroscopic images: computer-aided techniques for clinicians": {
        "authors": [
          "Ziyi Jin"
        ],
        "url": "https://link.springer.com/content/pdf/10.1186/s12938-022-00979-8.pdf",
        "ref_texts": ""
      },
      "Improving Semantic Segmentation in Transformers using Hierarchical Inter-Level Attention": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2207.02126",
        "ref_texts": "28. Liu, S., Qi, L., Qin, H., Shi, J., Jia, J.: Path aggregation network for instance segmentation. In: Proceedings of the IEEE conference on computer vision and pattern recognition. pp. 8759\u20138768 (2018)",
        "ref_ids": [
          "28"
        ]
      },
      "Sistem Inspeksi Cacat pada Permukaan Kayu menggunakan Model Deteksi Obyek YOLOv5": {
        "authors": [
          "Arsyad R"
        ],
        "url": "https://ejurnal.itenas.ac.id/index.php/elkomika/article/download/7280/3057",
        "ref_texts": " Sistem Inspeksi Cacat pada Permukaan Kayu menggunakan Model Deteksi Obyek YOLOv5 ELKOMIKA \u2013 1003 4. KESIMPULAN Penelitian ini mengusulkan sistem deteksi cacat pada permukaan kayu pinus dan kayu karet menggunakan model YOLOv5 dan image enhancement . Pada citra kayu pinus, model terbaik pada YOLOv5s. Performa akurasi yang dihasilkan juga konsisten. Nilai mAP tertinggi pada dataset kayu pinus yaitu mencapai 94,3% tanpa menggunakan image enhancement , namun saat dilakukan penambahan image enhancement edge filter , FPS pada dataset ini mengalami peningkatan yang pesat mencapai 125 FPS. Sedangkan pada dataset kayu karet yaitu model terbaik pada YOLOv5s-Transformer. Nilai mAP tertinggi pada dataset kayu karet yang memiliki jenis cacat yang lebih kompleks yaitu mencapai 94,7% dengan penambahan image enhancement , yaitu Real ESRGAN . Namun FPS tertinggi pada dataset ini mengalami peningkatan yang pesat mencapai 139 FPS saat menggunakan image enhancement edge filter . YOLOv5s-Transformer dengan penambahan image enhancement Real ESRGAN memiliki performa paling baik dibandingkan dengan citra karet orisinal dan citra karet dengan penambahan edge filter. DAFTAR RUJUKAN Abdulfattah, M. E., Novamizanti, L., & Rizal, S. (2021). Super Resolution pada Citra Udara menggunakan Convolutional Neural Network. ELKOMIKA: Jurnal Teknik Energi Elektrik, Teknik Telekomunikasi, & Teknik Elektronika, 9 (1), 71. Bayu, I. G., Novamizanti, L., & Atmaja, R. D. (2015). Deteksi Ada Tidaknya Cacat Pada Kayu Menggunakan Metode Ekstraksi Ciri Statistik. eProceeding, 2 (1), 1-8. Cheng, Z., & Zhang, F. (2020). Flower end-to-end detection based on YOLOv4 using a mobile device. Wireless Communications and Mobile Computing . Dosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn, D., Zhai, X., Unterthiner, T., . . . Houlsby, N. (2020). An image is worth 16x16 words: Transformers for image recognition at scale . Diambil kembali dari arXiv preprint arXiv:2010.11929. Fang, Y., Guo, X., Chen, K., Zhou, Z., & Ye, Q. (2021). Accurate and Automated Detection of Surface Knots on Sawn Timbers Using YOLO-V5 Model. BioResources, 16 (3). Hu, J., Song, W., Zhang, W., Zhao, Y., & Yilmaz, A. (2019). Deep learning for use in lumber classification tasks. Wood Science and Technology, 53 (2), 505-517. Jocher, G., Stoken, A., Borovec, J., Chaurasia, A., & Changyu, L. (2020). ultralytics/yolov5 . Diambil kembali dari Github Repository, YOLOv5. Jung, S. Y., Tsai, Y. H., Chiu, W. Y., & Sun, C. T. (2018). Defect detection on randomly textured surfaces by convolutional neural networks. 2018 IEEE/ASME International Conference on Advanced Intelligent Mechatronics (AIM), (pp. 1456-1461). Auckland: IEEE. Kurnadi, K., Marsudi, M., & Maulana, Y. (2020). Analisis Pengendalian Produk Cacat Pada Kayu Lapis Menggunakan Sqc (Statistical Quality Control) Pada Pabrik Pt. Wijaya Tri Utama Plywood Industry. Journal of Industrial Engineering and Operation Management, 3 (2). Akhyar, dkk ELKOMIKA \u2013 1004 Lathifah, H., Novamizanti, L., & Rizal, a. S. (2020). Fast and Accurate Fish Classification from Underwater Video using You Only Look Once. Conference Series: Materials Science and Engineering , 982(1), 012003. IOP Publishing. Li, C., Zhang, Y., Tu, W., Jun, C., Liang, H., & Yu, H. (2017). Soft measurement of wood defects based on LDA feature fusion and compressed sensor images. Journal of Forestry Research, 28 (6), 1285-1292. Li, S., Li, D., & Yuan, W. (2019). Wood defect classification based on two-dimensional histogram constituted by LBP and local binary differential excitation pattern. IEEE Access, 7 , 145829-145842. Lin, T. Y., Doll\u00e1r, P., Girshick, R., He, K., Hariharan, B., & Belongie, S. (2017). Feature pyramid networks for object detection. Proceedings of the IEEE conference on computer vision and pattern recognition , (pp. 2117-2125). Liu, S., Qi, L., Qin, H., Shi, J., & Jia, J. (2018). Path aggregation network for instance segmentation. Proceedings of the IEEE conference on computer vision and pattern recognition , (pp. 8759-8768). Liu, Y., Lu, B., Peng, J., & Zhang, Z. (2020). Research on the use of YOLOv5 object detection algorithm in mask wearing recognition. World Sci. Res. J, 6 , 276\u2013284. Mutaqin, D. J., Nurhayani, F. O., & Rahayu, N. H. (2022). Performa Industri Hutan Kayu dan Strategi Pemulihan Pascapandemi Covid-19. Bappenas Working Papers, 5 (1), 48-62. Redmon, J., Divvala, S., Girshick, R., & Farhadi, A. (2016). You only look once: Unified, realtime object detection. Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 779-788). IEEE. Ren, R., Hung, T., & Tan, K. C. (2017). A generic deep-learning-based approach for automated surface inspection. IEEE transactions on cybernetics, 48 (3), 929-940. Shapiro, L. G., & Stockman, G. C. (2001). Computer vision (Vol. 3). New Jersey: Prentice Hall. Diambil kembali dari Pythonic: pythonic.com Shorten, C., & Khoshgoftaar, T. M. (2019). A Survey on Image Data Augmentation for Deep Learning. Journal of big data, 6 (1), 1-48. Suyanto. (2018). Machine Learning Tingkat Dasar dan Lanjut. Bandung: Informatika. Tan, M., Pang, R., & Le, Q. V. (2020). Efficientdet: Scalable and efficient object detection. Proceedings of the IEEE/CVF conference on computer vision and pattern recognition "
      },
      "Automatic scan range for dose-reduced multiphase ct imaging of the liver utilizing cnns and gaussian models": {
        "authors": [
          "Manh Ha",
          "Hong Son",
          "Daniel Franklin",
          "Thi Thu",
          "Thao Nguyen",
          "Thi My",
          "Adriaan Moelker",
          "Van Khang",
          "Dang Luu",
          "Ngoc Ha",
          "Quoc Long",
          "Duc Trinh",
          "Nguyen Linh"
        ],
        "url": "https://pure.eur.nl/ws/portalfiles/portal/100701345/LuuMH_Automatic_MediA_R2.pdf",
        "ref_texts": "978-3-319-10602-1_48 . 474 Lip-Pauwels, W., Dijkshoorn, M.L., Booij, R., Willemssen, F., Krestin, G.P., 2012. Optimizing 3-Phase Liver CT in Hepatocellular Carcinoma: Achieve better 475 lesion depiction and reduce radiation dose and contrast material. URL: https://epos.myesr.org/poster/esr/ecr2012/C-0092 . publisher: European 476 Congress of Radiology ECR 2012. 477 Liu, S., Qi, L., Qin, H., Shi, J., Jia, J., 2018. Path Aggregation Network for Instance Segmentation, in: 2018 IEEE /CVF Conference on Computer Vision and Pattern 478 Recognition, pp. 8759\u20138768. doi: 10.1109/CVPR.2018.00913 . iSSN: 2575-7075. 479 Liu, W., Anguelov, D., Erhan, D., Szegedy, C., Reed, S., Fu, C.Y ., Berg, A.C., 2016. SSD: Single Shot MultiBox Detector. arXiv:1512.02325 [cs] 9905, 21\u201337. 480 URL: http://arxiv.org/abs/1512.02325 , doi: 10.1007/978-3-319-46448-0_2 . arXiv: 1512.02325. 481 Luu, H.M., Moelker, A., Klein, S., Niessen, W., van Walsum, T., 2018. Quantification of nonrigid liver deformation in radiofrequency ablation interventions using 482 image registration. Physics in Medicine and Biology 63, 175005. doi: 10.1088/1361-6560/aad706 . 483 Luu, H.M., Walsum, T.v., Franklin, D., Pham, P.C., Vu, L.D., Moelker, A., Staring, M., VanHoang, X., Niessen, W., Trung, N.L., 2021. E flciently compressing 484"
      },
      "Task-specific data augmentation and inference processing for vipriors instance segmentation challenge": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2211.11282",
        "ref_texts": "[8] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 8759\u20138768, 2018.",
        "ref_ids": [
          "8"
        ]
      },
      "Aerial image segmentation via noise dispelling and content distilling": {
        "authors": [
          "Yongqing Sun",
          "Xiaomeng Wu",
          "Yukihiro Bandoh",
          "Masaki Kitahara"
        ],
        "url": "https://openaccess.thecvf.com/content/ACCV2022W/MLCSA/papers/Sun_Aerial_Image_Segmentation_via_Noise_Dispelling_and_Content_Distilling_ACCVW_2022_paper.pdf",
        "ref_texts": "12. Liu, S., Qi, L., Qin, H., Shi, J., Jia, J.: Path aggregation network for instance segmentation. In: Proceedings of the IEEE conference on computer vision and pattern recognition. pp. 8759\u20138768 (2018)",
        "ref_ids": [
          "12"
        ]
      },
      "Fqdet: Fast-converging query-based detector": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2210.02318",
        "ref_texts": "[19] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 8759\u20138768, 2018.",
        "ref_ids": [
          "19"
        ]
      },
      "Densely-packed object detection via hard negative-aware anchor attention": {
        "authors": [
          "Sungmin Cho",
          "Jinwook Paeng",
          "Junseok Kwon"
        ],
        "url": "https://openaccess.thecvf.com/content/WACV2022/papers/Cho_Densely-Packed_Object_Detection_via_Hard_Negative-Aware_Anchor_Attention_WACV_2022_paper.pdf",
        "ref_texts": "[21] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In CVPR , 2018.",
        "ref_ids": [
          "21"
        ]
      },
      "\u57fa\u4e8e\u6539\u8fdb YOLO v5 \u7684\u7535\u5382\u7ba1\u9053\u6cb9\u6db2\u6cc4\u6f0f\u68c0\u6d4b": {
        "authors": [],
        "url": "http://jemi.cnjournals.com/jemi/article/pdf/20221223?file_name=8101D5DAB1C08948B0992B13035C0C5B81E988912E5E36D219B796992E91B43241C79ED2FB994A545E6FE45F81C0DB2C917F2660FC61B1CA836BAC15DE67C152&open_type=self",
        "ref_texts": "[13] LIU S, QI L, QIN H, et al. Path aggregation network for instance segmentation[C].Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, ",
        "ref_ids": [
          "13",
          "C"
        ]
      },
      "\u57fa\u4e8e\u6539\u8fdb Ghost-YOLOv5s-BiFPN \u7b97\u6cd5\u68c0\u6d4b\u68a8\u6811\u82b1\u5e8f": {
        "authors": [],
        "url": "http://www.smartag.net.cn/CN/article/downloadArticleFile.do?attachType=PDF&id=21651",
        "ref_texts": "[22]LIU S ,QI L,QIN H ,et al.Path aggregation network for instance segmentation [C]//The IEEE Conference on Computer Vision and Pattern Recognition .Piscat\u2010 away,New York ,USA:IEEE ,2018:8759-8768.",
        "ref_ids": [
          "22",
          "C"
        ]
      },
      "\u7ed3\u5408\u6570\u636e\u878d\u5408\u4e0e\u7279\u5f81\u9009\u62e9\u7684\u9065\u611f\u5f71\u50cf\u5c3a\u5ea6\u591a\u6837\u76ee\u6807\u68c0\u6d4b": {
        "authors": [],
        "url": "https://www.ygxb.ac.cn/rc-pub/front/front-article/download/29465773/lowqualitypdf/%E7%BB%93%E5%90%88%E6%95%B0%E6%8D%AE%E8%9E%8D%E5%90%88%E4%B8%8E%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9%E7%9A%84%E9%81%A5%E6%84%9F%E5%BD%B1%E5%83%8F%E5%B0%BA%E5%BA%A6%E5%A4%9A%E6%A0%B7%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B.pdf",
        "ref_texts": "1109/ICCV .2017.324] Liu S ,Qi L,Qin H F ,Shi J P and Jia J Y .2018.Path aggregation net \u2010 work for instance segmentation// 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition .Salt Lake City ,UT: IEEE :8759-8768 [DOI:10.1109/CVPR .2018.00913 ] Liu W ,Anguelov D ,Erhan D ,Szegedy C ,Reed S ,Fu C Y and Berg A C.2016.SSD:single shot MultiBox detector// 14th European Con \u2010 ference on Computer Vision .Amsterdam :Springer :21-37[DOI: 10.1007/978-3-319-46448 -0_2] Long Y ,Gong Y P ,Xiao Z F and Liu Q .2017.Accurate object localiza \u2010 tion in remote sensing images based on convolutional neural net \u2010 works .IEEE Transactions on Geoscience and Remote Sensing ,55"
      },
      "\u57fa\u4e8e\u7279\u5f81\u878d\u5408\u7684\u81ea\u9002\u5e94\u591a\u5c3a\u5ea6\u65e0\u951a\u6846\u76ee\u6807\u68c0\u6d4b\u7b97\u6cd5": {
        "authors": [],
        "url": "http://jemi.cnjournals.com/jemi/ch/reader/create_pdf.aspx?file_no=20221127&flag=1&journal_id=spzljcxb",
        "ref_texts": "[12] LIU S, QI L, QIN H, et al. Path aggregation network for instance segmentation[C].Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2018: ",
        "ref_ids": [
          "12",
          "C"
        ]
      },
      "\u52a8\u6001\u7279\u5f81\u878d\u5408\u7684\u9065\u611f\u56fe\u50cf\u76ee\u6807\u68c0\u6d4b": {
        "authors": [],
        "url": "http://159.226.43.17/online/onlinepaper/003-%E8%B0%A2%E6%98%9F%E6%98%9F-H-2022425171008.pdf",
        "ref_texts": "[9]LiuS,QiL,QinH,ShiJ,andJiaJ.Pathaggregationnetwork forinstancesegmentation//ProceedingsoftheIEEEConferenceon Computer Vision and Pattern Recognition .Salt Lake City,USA,",
        "ref_ids": [
          "9"
        ]
      },
      "\u57fa\u4e8e\u6539\u8fdb YOLOv5s \u7684\u5149\u5b66\u9065\u611f\u56fe\u50cf\u8230\u8239\u5206\u7c7b\u68c0\u6d4b\u65b9\u6cd5": {
        "authors": [],
        "url": "https://www.researching.cn/ArticlePdf/m00002/2022/59/16/1628008.pdf",
        "ref_texts": "[14]LiuS,QiL,QinH F,etal.Pathaggregationnetwork forinstancesegmentation [C]\u22252018IEEE/CVF Conference on Computer Vis ion and Pattern Recognition ,June1823,2018,SaltLakeCity,UT,USA.NewYork:IEEE Press,2018:8759 -8768.",
        "ref_ids": [
          "14",
          "C"
        ]
      },
      "\u57fa\u4e8e\u81ea\u9002\u5e94\u7a7a\u95f4\u7279\u5f81\u878d\u5408\u7684\u8f7b\u91cf\u5316\u76ee\u6807\u68c0\u6d4b\u7b97\u6cd5": {
        "authors": [],
        "url": "https://www.researching.cn/ArticlePdf/m00002/2022/59/4/0415004.pdf",
        "ref_texts": "\u7814\u7a76\u8bba\u6587 \u7b2c59\u5377\u7b2c4\u671f/2022\u5e742\u6708/\u6fc0\u5149\u4e0e\u5149\u7535\u5b50\u5b66\u8fdb\u5c55 network for instance segmentation [C]//2018IEEE/ CVF Conference on Computer Vision and Pattern Recognition,June18-23,2018,Salt Lake City , UT,USA.New York:IEEE Press,2018:8759 8768."
      },
      "\u6539\u8fdb YOLOv5 \u7b97\u6cd5\u4e0b\u7684\u8f93\u7535\u7ebf\u8def\u5916\u7834\u9690\u60a3\u76ee\u6807\u68c0\u6d4b\u7814\u7a76": {
        "authors": [],
        "url": "http://jemi.cnjournals.com/jemi/ch/reader/create_pdf.aspx?file_no=20221128&flag=1&journal_id=spzljcxb",
        "ref_texts": "[13] LIU S, QI L, QIN H, et al. Path aggregation network for instance segmentation[C]. Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), ",
        "ref_ids": [
          "13",
          "C"
        ]
      },
      "Image segmentation using deep learning: A survey": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2001.05566",
        "ref_texts": "[65] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia, \u201cPath aggregation network for instance segmentation,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , 2018, pp. 8759\u20138768.",
        "ref_ids": [
          "65"
        ]
      },
      "TPH-YOLOv5: Improved YOLOv5 based on transformer prediction head for object detection on drone-captured scenarios": {
        "authors": [
          "Xingkui Zhu",
          "Shuchang Lyu",
          "Xu Wang",
          "Qi Zhao"
        ],
        "url": "https://openaccess.thecvf.com/content/ICCV2021W/VisDrone/papers/Zhu_TPH-YOLOv5_Improved_YOLOv5_Based_on_Transformer_Prediction_Head_for_Object_ICCVW_2021_paper.pdf",
        "ref_texts": "[33] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 8759\u20138768, 2018.",
        "ref_ids": [
          "33"
        ]
      },
      "Scaled-yolov4: Scaling cross stage partial network": {
        "authors": [
          "Yao Wang",
          "Alexey Bochkovskiy",
          "Yuan Mark"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wang_Scaled-YOLOv4_Scaling_Cross_Stage_Partial_Network_CVPR_2021_paper.pdf",
        "ref_texts": "[20] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , pages 8759\u20138768, 2018. 5",
        "ref_ids": [
          "20"
        ]
      },
      "Bottleneck transformers for visual recognition": {
        "authors": [
          "Aravind Srinivas",
          "Yi Lin",
          "Niki Parmar",
          "Jonathon Shlens",
          "Pieter Abbeel",
          "Ashish Vaswani"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2021/papers/Srinivas_Bottleneck_Transformers_for_Visual_Recognition_CVPR_2021_paper.pdf",
        "ref_texts": "[41] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 8759\u20138768, 2018.",
        "ref_ids": [
          "41"
        ]
      },
      "You only look one-level feature": {
        "authors": [
          "Qiang Chen",
          "Yingming Wang",
          "Tong Yang",
          "Xiangyu Zhang",
          "Jian Cheng",
          "Jian Sun"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2021/papers/Chen_You_Only_Look_One-Level_Feature_CVPR_2021_paper.pdf",
        "ref_texts": "[22] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 8759\u20138768, 2018. 1,2",
        "ref_ids": [
          "22"
        ]
      },
      "Varifocalnet: An iou-aware dense object detector": {
        "authors": [
          "Haoyang Zhang",
          "Ying Wang",
          "Feras Dayoub",
          "Niko Sunderhauf"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhang_VarifocalNet_An_IoU-Aware_Dense_Object_Detector_CVPR_2021_paper.pdf",
        "ref_texts": "[48] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In CVPR , 2018.",
        "ref_ids": [
          "48"
        ]
      },
      "Dynamic head: Unifying object detection heads with attentions": {
        "authors": [
          "Xiyang Dai",
          "Yinpeng Chen",
          "Bin Xiao",
          "Dongdong Chen",
          "Mengchen Liu",
          "Lu Yuan",
          "Lei Zhang"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2021/papers/Dai_Dynamic_Head_Unifying_Object_Detection_Heads_With_Attentions_CVPR_2021_paper.pdf",
        "ref_texts": "[17] Shu Liu, Lu Qi, Haifang Qin, J. Shi, and J. Jia. Path aggregation network for instance segmentation. 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 8759\u20138768, 2018. 2",
        "ref_ids": [
          "17"
        ]
      },
      "Max-deeplab: End-to-end panoptic segmentation with mask transformers": {
        "authors": [
          "Huiyu Wang",
          "Yukun Zhu",
          "Hartwig Adam",
          "Alan Yuille",
          "Chieh Chen"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2021/papers/Wang_MaX-DeepLab_End-to-End_Panoptic_Segmentation_With_Mask_Transformers_CVPR_2021_paper.pdf",
        "ref_texts": "[63] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In CVPR , 2018.",
        "ref_ids": [
          "63"
        ]
      },
      "See through gradients: Image batch recovery via gradinversion": {
        "authors": [
          "Hongxu Yin",
          "Arun Mallya",
          "Arash Vahdat",
          "Jose M. Alvarez",
          "Jan Kautz",
          "Pavlo Molchanov"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2021/papers/Yin_See_Through_Gradients_Image_Batch_Recovery_via_GradInversion_CVPR_2021_paper.pdf",
        "ref_texts": "[29] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia. Path aggregation network for instance segmentation. In CVPR , 2018.",
        "ref_ids": [
          "29"
        ]
      },
      "Detectors: Detecting objects with recursive feature pyramid and switchable atrous convolution": {
        "authors": [
          "Siyuan Qiao",
          "Chieh Chen",
          "Alan Yuille"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2021/papers/Qiao_DetectoRS_Detecting_Objects_With_Recursive_Feature_Pyramid_and_Switchable_Atrous_CVPR_2021_paper.pdf",
        "ref_texts": "[53] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 8759\u20138768, 2018. 2,7",
        "ref_ids": [
          "53"
        ]
      },
      "Dynamic detr: End-to-end object detection with dynamic attention": {
        "authors": [
          "Xiyang Dai",
          "Yinpeng Chen",
          "Jianwei Yang",
          "Pengchuan Zhang",
          "Lu Yuan",
          "Lei Zhang"
        ],
        "url": "https://openaccess.thecvf.com/content/ICCV2021/papers/Dai_Dynamic_DETR_End-to-End_Object_Detection_With_Dynamic_Attention_ICCV_2021_paper.pdf",
        "ref_texts": "[17] Shu Liu, Lu Qi, Haifang Qin, J. Shi, and J. Jia. Path aggregation network for instance segmentation. 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 8759\u20138768, 2018. 2",
        "ref_ids": [
          "17"
        ]
      },
      "Parametric contrastive learning": {
        "authors": [
          "Jiequan Cui",
          "Zhisheng Zhong",
          "Shu Liu",
          "Bei Yu",
          "Jiaya Jia"
        ],
        "url": "https://openaccess.thecvf.com/content/ICCV2021/papers/Cui_Parametric_Contrastive_Learning_ICCV_2021_paper.pdf",
        "ref_texts": "[34] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In CVPR , 2018. 1",
        "ref_ids": [
          "34"
        ]
      },
      "A normalized Gaussian Wasserstein distance for tiny object detection": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2110.13389",
        "ref_texts": "[17] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In IEEE Conference on Computer Vision and Pattern Recognition , pages 8759\u20138768, 2018.",
        "ref_ids": [
          "17"
        ]
      },
      "Instances as queries": {
        "authors": [
          "Yuxin Fang",
          "Shusheng Yang",
          "Xinggang Wang",
          "Yu Li",
          "Chen Fang",
          "Ying Shan",
          "Bin Feng",
          "Wenyu Liu"
        ],
        "url": "https://openaccess.thecvf.com/content/ICCV2021/papers/Fang_Instances_As_Queries_ICCV_2021_paper.pdf",
        "ref_texts": "[32] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In CVPR , 2018.",
        "ref_ids": [
          "32"
        ]
      },
      "Fapn: Feature-aligned pyramid network for dense image prediction": {
        "authors": [
          "Shihua Huang",
          "Zhichao Lu",
          "Ran Cheng",
          "Cheng He"
        ],
        "url": "https://openaccess.thecvf.com/content/ICCV2021/papers/Huang_FaPN_Feature-Aligned_Pyramid_Network_for_Dense_Image_Prediction_ICCV_2021_paper.pdf",
        "ref_texts": "[25] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In CVPR , 2018. 1",
        "ref_ids": [
          "25"
        ]
      },
      "Simultaneously localize, segment and rank the camouflaged objects": {
        "authors": [
          "Yunqiu Lv",
          "Jing Zhang",
          "Yuchao Dai",
          "Aixuan Li",
          "Bowen Liu",
          "Nick Barnes",
          "Ping Fan"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2021/papers/Lv_Simultaneously_Localize_Segment_and_Rank_the_Camouflaged_Objects_CVPR_2021_paper.pdf",
        "ref_texts": "[31] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In IEEE Conf. Comput. Vis. Pattern Recog. , pages 8759\u20138768, 2018.",
        "ref_ids": [
          "31"
        ]
      },
      "Fourier contour embedding for arbitrary-shaped text detection": {
        "authors": [
          "Yiqin Zhu",
          "Jianyong Chen",
          "Lingyu Liang",
          "Zhanghui Kuang",
          "Lianwen Jin",
          "Wayne Zhang"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhu_Fourier_Contour_Embedding_for_Arbitrary-Shaped_Text_Detection_CVPR_2021_paper.pdf",
        "ref_texts": "[11] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In Proc. CVPR , pages 8759\u20138768, 2018. 1",
        "ref_ids": [
          "11"
        ]
      },
      "Rangedet: In defense of range view for lidar-based 3d object detection": {
        "authors": [
          "Lue Fan",
          "Xuan Xiong",
          "Feng Wang",
          "Naiyan Wang",
          "Xiang Zhang"
        ],
        "url": "http://openaccess.thecvf.com/content/ICCV2021/papers/Fan_RangeDet_In_Defense_of_Range_View_for_LiDAR-Based_3D_Object_ICCV_2021_paper.pdf",
        "ref_texts": "[16] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path Aggregation Network for Instance Segmentation. In CVPR , pages 8759\u20138768, 2018. 2",
        "ref_ids": [
          "16"
        ]
      },
      "ViT-YOLO: Transformer-based YOLO for object detection": {
        "authors": [
          "Zixiao Zhang",
          "Xiaoqiang Lu",
          "Guojin Cao",
          "Yuting Yang",
          "Licheng Jiao",
          "Fang Liu"
        ],
        "url": "https://openaccess.thecvf.com/content/ICCV2021W/VisDrone/papers/Zhang_ViT-YOLOTransformer-Based_YOLO_for_Object_Detection_ICCVW_2021_paper.pdf",
        "ref_texts": "[5]Jacob Devlin, Ming-Wei Chang, Kenton Lee, and KristinaToutanova. BERT: Pre-training of Deep Bidirectional Trans-formers for Language Understanding.arXiv:1810.04805[cs], May 2019. arXiv: 1810.04805.[6]Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov,Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner,Mostafa Dehghani, Matthias Minderer, Georg Heigold, Syl-vain Gelly, Jakob Uszkoreit, and Neil Houlsby. An Imageis Worth 16x16 Words: Transformers for Image Recogni-tion at Scale.arXiv:2010.11929 [cs], June 2021. arXiv:2010.11929.[7]Ross Girshick. Fast R-CNN. pages 1440\u20131448, 2015.[8]Ross Girshick, Jeff Donahue, Trevor Darrell, and JitendraMalik. Rich feature hierarchies for accurate object detec-tion and semantic segmentation.arXiv:1311.2524 [cs], Oct.2014. arXiv: 1311.2524.[9]Kaiming He, Georgia Gkioxari, Piotr Dollar, and Ross Gir-shick. Mask R-CNN. pages 2961\u20132969, 2017.[10]Kaiming He, Xiangyu Zhang, Shaoqing Ren, and JianSun. Deep Residual Learning for Image Recognition.arXiv:1512.03385 [cs], Dec. 2015. arXiv: 1512.03385.[11]Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.Spatial Pyramid Pooling in Deep Convolutional Networksfor Visual Recognition.IEEE Transactions on Pattern Anal-ysis and Machine Intelligence, 37(9):1904\u20131916, Sept. 2015.Conference Name: IEEE Transactions on Pattern Analysisand Machine Intelligence.[12]Seung-Wook Kim, Hyong-Keun Kook, Jee-Young Sun,Mun-Cheon Kang, and Sung-Jea Ko. Parallel Feature Pyra-mid Network for Object Detection. In Vittorio Ferrari, Mar-tial Hebert, Cristian Sminchisescu, and Yair Weiss, editors,Computer Vision \u2013 ECCV 2018, volume 11209, pages 239\u2013256. Springer International Publishing, Cham, 2018. SeriesTitle: Lecture Notes in Computer Science.[13]Tao Kong, Fuchun Sun, Wenbing Huang, and Huaping Liu.Deep Feature Pyramid Reconfiguration for Object Detection.arXiv:1808.07993 [cs], Aug. 2018. arXiv: 1808.07993.[14]Yann LeCun, Yoshua Bengio, and Geoffrey Hinton. Deeplearning.Nature, 521(7553):436\u2013444, May 2015.[15]Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvinine-jad, Abdelrahman Mohamed, Omer Levy, Ves Stoyanov, andLuke Zettlemoyer. BART: Denoising Sequence-to-SequencePre-training for Natural Language Generation, Translation,and Comprehension.arXiv:1910.13461 [cs, stat], Oct. 2019.arXiv: 1910.13461.[16]Tsung-Yi Lin, Piotr Doll\u00b4ar, Ross Girshick, Kaiming He,Bharath Hariharan, and Serge Belongie. Feature PyramidNetworks for Object Detection.arXiv:1612.03144 [cs], Apr.2017. arXiv: 1612.03144.[17]Tsung-Yi Lin, Priya Goyal, Ross Girshick, Kaiming He, andPiotr Dollar. Focal Loss for Dense Object Detection. pages2980\u20132988, 2017.[18]Tsung-Yi Lin, Michael Maire, Serge Belongie, LubomirBourdev, Ross Girshick, James Hays, Pietro Perona, DevaRamanan, C. Lawrence Zitnick, and Piotr Doll\u00b4ar. MicrosoftCOCO: Common Objects in Context.arXiv:1405.0312 [cs],Feb. 2015. arXiv: 1405.0312.[19]Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia.Path Aggregation Network for Instance Segmentation. Mar.2018.[20]Wei Liu, Dragomir Anguelov, Dumitru Erhan, ChristianSzegedy, Scott Reed, Cheng-Yang Fu, and Alexander C.Berg. SSD: Single Shot MultiBox Detector. In BastianLeibe, Jiri Matas, Nicu Sebe, and Max Welling, editors,Computer Vision \u2013 ECCV 2016, Lecture Notes in ComputerScience, pages 21\u201337, Cham, 2016. Springer InternationalPublishing.[21]Diganta Misra. Mish: A Self Regularized Non-MonotonicNeural Activation Function. page 13.[22]Muzammal Naseer, Kanchana Ranasinghe, Salman Khan,Munawar Hayat, Fahad Shahbaz Khan, and Ming-HsuanYang. Intriguing Properties of Vision Transformers.arXiv:2105.10497 [cs], June 2021. arXiv: 2105.10497.[23]Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee,Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, andPeter J Liu. Exploring the Limits of Transfer Learning witha Unified Text-to-Text Transformer. page 67.[24]Joseph Redmon, Santosh Divvala, Ross Girshick, and AliFarhadi. You Only Look Once: Unified, Real-Time Ob-ject Detection.arXiv:1506.02640 [cs], May 2016. arXiv:1506.02640.[25]Joseph Redmon and Ali Farhadi. YOLO9000: Better, Faster,Stronger. pages 7263\u20137271, 2017.[26]Joseph Redmon and Ali Farhadi. YOLOv3: An IncrementalImprovement.arXiv:1804.02767 [cs], Apr. 2018. arXiv:1804.02767.[27]Shaoqing Ren, Kaiming He, Ross Girshick, and Jian Sun.Faster R-CNN: Towards Real-Time Object Detection withRegion Proposal Networks.IEEE Transactions on PatternAnalysis and Machine Intelligence, 39(6):1137\u20131149, June2017. Conference Name: IEEE Transactions on PatternAnalysis and Machine Intelligence.[28]Pierre Sermanet, David Eigen, Xiang Zhang, Michael Math-ieu, Rob Fergus, and Yann LeCun. OverFeat: IntegratedRecognition, Localization and Detection using Convolu-tional Networks.arXiv:1312.6229 [cs], Feb. 2014. arXiv:1312.6229.[29]Karen Simonyan and Andrew Zisserman. Very Deep Con-volutional Networks for Large-Scale Image Recognition.arXiv:1409.1556 [cs], Apr. 2015. arXiv: 1409.1556.[30]Roman Solovyev, Weimin Wang, and Tatiana Gabruseva.Weighted boxes fusion: Ensembling boxes from differentobject detection models.Image and Vision Computing,107:104117, Mar. 2021. arXiv: 1910.13302.[31]Mingxing Tan, Ruoming Pang, and Quoc V . Le. EfficientDet:Scalable and Efficient Object Detection.arXiv:1911.09070[cs, eess], July 2020. arXiv: 1911.09070.[32]Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszko-reit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, and IlliaPolosukhin. Attention Is All You Need.arXiv:1706.03762[cs], Dec. 2017. arXiv: 1706.03762.[33]Xingxing Zhang, Furu Wei, and Ming Zhou. hiBERT: Docu-ment Level Pre-training of Hierarchical Bidirectional Trans-formers for Document Summarization.arXiv:1905.06566[cs], May 2019. arXiv: 1905.06566.",
        "ref_ids": [
          "5",
          "cs",
          "6",
          "cs",
          "7",
          "8",
          "cs",
          "9",
          "10",
          "cs",
          "11",
          "12",
          "13",
          "cs",
          "14",
          "15",
          "cs, stat",
          "16",
          "cs",
          "17",
          "18",
          "cs",
          "19",
          "20",
          "21",
          "22",
          "cs",
          "23",
          "24",
          "cs",
          "25",
          "26",
          "cs",
          "27",
          "28",
          "cs",
          "29",
          "cs",
          "30",
          "31",
          "cs, eess",
          "32",
          "cs",
          "33",
          "cs"
        ]
      },
      "Seesaw loss for long-tailed instance segmentation": {
        "authors": [
          "Jiaqi Wang",
          "Wenwei Zhang",
          "Yuhang Zang",
          "Yuhang Cao",
          "Jiangmiao Pang",
          "Tao Gong",
          "Kai Chen",
          "Ziwei Liu",
          "Chen Change",
          "Dahua Lin"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2021/papers/Wang_Seesaw_Loss_for_Long-Tailed_Instance_Segmentation_CVPR_2021_paper.pdf",
        "ref_texts": ""
      },
      "Effective fusion factor in FPN for tiny object detection": {
        "authors": [
          "Yuqi Gong",
          "Xuehui Yu",
          "Yao Ding",
          "Xiaoke Peng",
          "Jian Zhao",
          "Zhenjun Han"
        ],
        "url": "http://openaccess.thecvf.com/content/WACV2021/papers/Gong_Effective_Fusion_Factor_in_FPN_for_Tiny_Object_Detection_WACV_2021_paper.pdf",
        "ref_texts": "[19] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. CVPR , pages 8759\u20138768, 2018.[20] Xin Lu, Buyu Li, Yuxin Yue, Quanquan Li, and Junjie Yan. Grid r-cnn. In CVPR , 2019.",
        "ref_ids": [
          "19",
          "20"
        ]
      },
      "Sg-net: Spatial granularity network for one-stage video instance segmentation": {
        "authors": [
          "Dongfang Liu",
          "Yiming Cui",
          "Wenbo Tan",
          "Yingjie Chen"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2021/papers/Liu_SG-Net_Spatial_Granularity_Network_for_One-Stage_Video_Instance_Segmentation_CVPR_2021_paper.pdf",
        "ref_texts": "[23] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 8759\u20138768, 2018. 3",
        "ref_ids": [
          "23"
        ]
      },
      "Hierarchical aggregation for 3d instance segmentation": {
        "authors": [
          "Shaoyu Chen",
          "Jiemin Fang",
          "Qian Zhang",
          "Wenyu Liu",
          "Xinggang Wang"
        ],
        "url": "https://openaccess.thecvf.com/content/ICCV2021/papers/Chen_Hierarchical_Aggregation_for_3D_Instance_Segmentation_ICCV_2021_paper.pdf",
        "ref_texts": "[27] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In CVPR , 2018.",
        "ref_ids": [
          "27"
        ]
      },
      "Deep occlusion-aware instance segmentation with overlapping bilayers": {
        "authors": [
          "Lei Ke",
          "Wing Tai",
          "Keung Tang"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2021/papers/Ke_Deep_Occlusion-Aware_Instance_Segmentation_With_Overlapping_BiLayers_CVPR_2021_paper.pdf",
        "ref_texts": "[42] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In CVPR , 2018. 1,2,7,8",
        "ref_ids": [
          "42"
        ]
      },
      "Vision-based robotic grasping from object localization, object pose estimation to grasp estimation for parallel grippers: a review": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1905.06658",
        "ref_texts": "[Liuet al. , 2018b ]Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 8759\u2013",
        "ref_ids": [
          "Liuet al\\. , 2018b "
        ]
      },
      "Medical image segmentation using squeeze-and-expansion transformers": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2105.09511",
        "ref_texts": "[Liuet al. , 2018 ]S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia. Path aggregation network for instance segmentation. In CVPR , 2018.",
        "ref_ids": [
          "Liuet al\\. , 2018 "
        ]
      },
      "Encoder fusion network with co-attention embedding for referring image segmentation": {
        "authors": [
          "Guang Feng",
          "Zhiwei Hu",
          "Lihe Zhang",
          "Huchuan Lu"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2021/papers/Feng_Encoder_Fusion_Network_With_Co-Attention_Embedding_for_Referring_Image_Segmentation_CVPR_2021_paper.pdf",
        "ref_texts": "[28] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In IEEE",
        "ref_ids": [
          "28"
        ]
      },
      "Fully convolutional networks for panoptic segmentation": {
        "authors": [
          "Yanwei Li",
          "Hengshuang Zhao",
          "Xiaojuan Qi",
          "Liwei Wang",
          "Zeming Li",
          "Jian Sun",
          "Jiaya Jia"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2021/papers/Li_Fully_Convolutional_Networks_for_Panoptic_Segmentation_CVPR_2021_paper.pdf",
        "ref_texts": "[32] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In CVPR , 2018.",
        "ref_ids": [
          "32"
        ]
      },
      "Pan++: Towards efficient and accurate end-to-end spotting of arbitrarily-shaped text": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2105.00405",
        "ref_texts": "[74] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia, \u201cPath aggregation network for instance segmentation,\u201d in Proc. IEEE Conf. Comp. Vis. Patt. Recogn. , 2018.",
        "ref_ids": [
          "74"
        ]
      },
      "Efficientps: Efficient panoptic segmentation": {
        "authors": [
          "Rohit Mohan"
        ],
        "url": "https://link.springer.com/content/pdf/10.1007/s11263-021-01445-z.pdf",
        "ref_texts": "6172\u20136181). Liu, S., Jia, J., Fidler, S., & Urtasun, R. (2017). Sgn: Sequential grouping networks for instance segmentation. In Proceedings of the international conference on computer vision (pp. 3496\u20133504). Liu, S., Qi, L., Qin, H., Shi, J., & Jia, J. (2018). Path aggregation network for instance segmentation. In Proceedings of the conference on computer vision and pattern recognition (pp. 8759\u20138768). Liu, W., Rabinovich, A., & Berg, A. C. (2015). Parsenet: Looking wider to see better. arXiv preprint arXiv:1506.04579 . Long, J., Shelhamer, E., & Darrell, T. (2015). Fully convolutional networks for semantic segmentation. In Proceedings of the conference on computer vision and pattern recognition . Neuhold, G., Ollmann, T., Rota, B. S., & Kontschieder, P . (2017). The mapillary vistas dataset for semantic understanding of streetscenes. In Proceedings of the international conference on computer vision (pp. 4990\u20134999).Paszke, A., Gross, S., Massa, F., Lerer, A., Bradbury, J., Chanan, G., Killeen, T., Lin, Z., Gimelshein, N., Antiga, L., et al. (2019).Pytorch: An imperative style, high-performance deep learninglibrary. In Advances in neural information processing systems (pp."
      },
      "Refine myself by teaching myself: Feature refinement via self-knowledge distillation": {
        "authors": [
          "Mingi Ji",
          "Seungjae Shin",
          "Seunghyun Hwang",
          "Gibeom Park",
          "Chul Moon"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2021/papers/Ji_Refine_Myself_by_Teaching_Myself_Feature_Refinement_via_Self-Knowledge_Distillation_CVPR_2021_paper.pdf",
        "ref_texts": "[20] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 8759\u20138768, 2018. 3",
        "ref_ids": [
          "20"
        ]
      },
      "Video self-stitching graph network for temporal action localization": {
        "authors": [
          "Chen Zhao",
          "Ali K. Thabet",
          "Bernard Ghanem"
        ],
        "url": "http://openaccess.thecvf.com/content/ICCV2021/papers/Zhao_Video_Self-Stitching_Graph_Network_for_Temporal_Action_Localization_ICCV_2021_paper.pdf",
        "ref_texts": "[24] Shu Liu, Lu Qi, Haifang Qin, J. Shi, and J. Jia. Path aggregation network for instance segmentation. In Proceedings of IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) , pages 8759\u20138768, 2018. 2",
        "ref_ids": [
          "24"
        ]
      },
      "PP-PicoDet: A better real-time object detector on mobile devices": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2111.00902",
        "ref_texts": "[41] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 8759\u20138768, 2018. 4",
        "ref_ids": [
          "41"
        ]
      },
      "Solq: Segmenting objects by learning queries": {
        "authors": [],
        "url": "https://proceedings.neurips.cc/paper/2021/file/b7087c1f4f89e63af8d46f3b20271153-Paper.pdf",
        "ref_texts": "[5]Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In Proc. IEEE Conf. Comp. Vis. Patt. Recogn. , 2018.",
        "ref_ids": [
          "5"
        ]
      },
      "Sample and computation redistribution for efficient face detection": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2105.04714",
        "ref_texts": "[21] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In CVPR , 2018. 4",
        "ref_ids": [
          "21"
        ]
      },
      "GraphFPN: Graph feature pyramid network for object detection": {
        "authors": [
          "Gangming Zhao",
          "Weifeng Ge",
          "Yizhou Yu"
        ],
        "url": "http://openaccess.thecvf.com/content/ICCV2021/papers/Zhao_GraphFPN_Graph_Feature_Pyramid_Network_for_Object_Detection_ICCV_2021_paper.pdf",
        "ref_texts": "[32] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. InProceedings of the IEEE conference on computer vision andpattern recognition , pages 8759\u20138768, 2018. 1,2,6",
        "ref_ids": [
          "32"
        ]
      },
      "Pointflow: Flowing semantics through points for aerial image segmentation": {
        "authors": [
          "Xiangtai Li",
          "Hao He",
          "Xia Li",
          "Duo Li",
          "Guangliang Cheng",
          "Jianping Shi",
          "Lubin Weng",
          "Yunhai Tong",
          "Zhouchen Lin"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2021/papers/Li_PointFlow_Flowing_Semantics_Through_Points_for_Aerial_Image_Segmentation_CVPR_2021_paper.pdf",
        "ref_texts": "[35] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia. Path aggregation network for instance segmentation. In CVPR , pages 8759\u2013",
        "ref_ids": [
          "35"
        ]
      },
      "Towards real-world prohibited item detection: A large-scale x-ray benchmark": {
        "authors": [
          "Boying Wang",
          "Libo Zhang",
          "Longyin Wen",
          "Xianglong Liu",
          "Yanjun Wu"
        ],
        "url": "http://openaccess.thecvf.com/content/ICCV2021/papers/Wang_Towards_Real-World_Prohibited_Item_Detection_A_Large-Scale_X-Ray_Benchmark_ICCV_2021_paper.pdf",
        "ref_texts": "[22] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In CVPR , pages 8759\u20138768, 2018. 3",
        "ref_ids": [
          "22"
        ]
      },
      "Person re-identification via attention pyramid": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2108.05340",
        "ref_texts": "[57] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia, \u201cPath aggregation network for instance segmentation,\u201d in CVPR , 2018, pp. 8759\u20138768.",
        "ref_ids": [
          "57"
        ]
      },
      "Istr: End-to-end instance segmentation with transformers": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2105.00637",
        "ref_texts": "[28] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , 2018. 1, 2, 3",
        "ref_ids": [
          "28"
        ]
      },
      "Video instance segmentation with a propose-reduce paradigm": {
        "authors": [
          "Huaijia Lin",
          "Ruizheng Wu",
          "Shu Liu",
          "Jiangbo Lu",
          "Jiaya Jia"
        ],
        "url": "https://openaccess.thecvf.com/content/ICCV2021/papers/Lin_Video_Instance_Segmentation_With_a_Propose-Reduce_Paradigm_ICCV_2021_paper.pdf",
        "ref_texts": "[24] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In CVPR , 2018. 2",
        "ref_ids": [
          "24"
        ]
      },
      "Colonoscopy polyp detection and classification: Dataset creation and comparative evaluations": {
        "authors": [
          "Kaidong Li",
          "Mohammad I. Fathan",
          "Krushi Patel",
          "Tianxiao Zhang",
          "Cuncong Zhong",
          "Ajay Bansal",
          "Amit Rastogi",
          "Jean S. Wang",
          "Guanghui Wang"
        ],
        "url": "https://journals.plos.org/plosone/article/file?id=10.1371/journal.pone.0255809&type=printable",
        "ref_texts": "63. LiuS,QiL,QinH,ShiJ,JiaJ.Path aggregation network forinstance segmentatio n.In:Proceedings of theIEEE conferen ceoncomputer vision andpattern recognition; 2018. p.8759\u20138768.",
        "ref_ids": [
          "63"
        ]
      },
      "Generative hierarchical features from synthesizing images": {
        "authors": [
          "Yinghao Xu",
          "Yujun Shen",
          "Jiapeng Zhu",
          "Ceyuan Yang",
          "Bolei Zhou"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2021/papers/Xu_Generative_Hierarchical_Features_From_Synthesizing_Images_CVPR_2021_paper.pdf",
        "ref_texts": "[38] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In IEEE Conf. Comput. Vis. Pattern Recog. , 2018. 3",
        "ref_ids": [
          "38"
        ]
      },
      "Look closer to segment better: Boundary patch refinement for instance segmentation": {
        "authors": [
          "Chufeng Tang",
          "Hang Chen",
          "Xiao Li",
          "Jianmin Li",
          "Zhaoxiang Zhang",
          "Xiaolin Hu"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2021/papers/Tang_Look_Closer_To_Segment_Better_Boundary_Patch_Refinement_for_Instance_CVPR_2021_paper.pdf",
        "ref_texts": "[25] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In IEEE Conf. Comput. Vis. Pattern Recog. , pages 8759\u20138768, 2018.",
        "ref_ids": [
          "25"
        ]
      },
      "Solo: A simple framework for instance segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2106.15947",
        "ref_texts": "[26] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia, \u201cPath aggregation network for instance segmentation,\u201d in Proc. IEEE Conf. Comp. Vis. Patt. Recogn. , 2018.",
        "ref_ids": [
          "26"
        ]
      },
      "A2-FPN: Attention aggregation based feature pyramid network for instance segmentation": {
        "authors": [
          "Miao Hu",
          "Yali Li",
          "Lu Fang",
          "Shengjin Wang"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2021/papers/Hu_A2-FPN_Attention_Aggregation_Based_Feature_Pyramid_Network_for_Instance_Segmentation_CVPR_2021_paper.pdf",
        "ref_texts": "[26] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 8759\u20138768, 2018. 1,2,6,7,8",
        "ref_ids": [
          "26"
        ]
      },
      "SSPNet: Scale selection pyramid network for tiny person detection from UAV images": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2107.01548",
        "ref_texts": "[22] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia, \u201cPath aggregation network for instance segmentation,\u201d in CVPR , 2018, pp. 8759\u20138768.",
        "ref_ids": [
          "22"
        ]
      },
      "HRDNet: High-resolution detection network for small objects": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2006.07607",
        "ref_texts": "[Liuet al. , 2018a ]Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In CVPR , pages 8759\u20138768, 2018.",
        "ref_ids": [
          "Liuet al\\. , 2018a "
        ]
      },
      "BAF-detector: An efficient CNN-based detector for photovoltaic cell defect detection": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2012.10631",
        "ref_texts": "[17] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia, \u201cPath aggregation network for instance segmentation,\u201d in Proc. IEEE Conf. Comput. Vis. Pattern Recognit. , Jun. 2018, pp. 8759\u20138768. IEEE TRANSACTIONS ON INDUSTRIAL ELECTRONICS",
        "ref_ids": [
          "17"
        ]
      },
      "Polygonal building extraction by frame field learning": {
        "authors": [
          "Nicolas Girard",
          "Dmitriy Smirnov",
          "Justin Solomon",
          "Yuliya Tarabalka"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2021/papers/Girard_Polygonal_Building_Extraction_by_Frame_Field_Learning_CVPR_2021_paper.pdf",
        "ref_texts": "[24] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2018. 7",
        "ref_ids": [
          "24"
        ]
      },
      "Enhanced feature pyramid network with deep semantic embedding for remote sensing scene classification": {
        "authors": [],
        "url": "https://figshare.le.ac.uk/articles/journal_contribution/Enhanced_Feature_Pyramid_Network_with_Deep_Semantic_Embedding_for_Remote_Sensing_Scene_Classification/13365539/1/files/25756280.pdf",
        "ref_texts": "[38] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia, \u201cPath aggregation network for instance segmentation,\u201d In Proceedings of IEEE Conference on Computer Vision and Pattern Recognition , 2018, 8759-8768. ",
        "ref_ids": [
          "38"
        ]
      },
      "Multi-scale aligned distillation for low-resolution detection": {
        "authors": [
          "Lu Qi",
          "Jason Kuen",
          "Jiuxiang Gu",
          "Zhe Lin",
          "Yi Wang",
          "Yukang Chen",
          "Yanwei Li",
          "Jiaya Jia"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2021/papers/Qi_Multi-Scale_Aligned_Distillation_for_Low-Resolution_Detection_CVPR_2021_paper.pdf",
        "ref_texts": "[36] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In CVPR , 2018. 1,2,5",
        "ref_ids": [
          "36"
        ]
      },
      "Spatial feature calibration and temporal fusion for effective one-stage video instance segmentation": {
        "authors": [
          "Minghan Li",
          "Shuai Li",
          "Lida Li",
          "Lei Zhang"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2021/papers/Li_Spatial_Feature_Calibration_and_Temporal_Fusion_for_Effective_One-Stage_Video_CVPR_2021_paper.pdf",
        "ref_texts": "[28] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In IEEE Conf. Comput. Vis. Pattern Recog. , pages 8759\u20138768, 2018.",
        "ref_ids": [
          "28"
        ]
      },
      "Parallel residual bi-fusion feature pyramid network for accurate single-shot object detection": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2012.01724.pdf?trk=public_post_comment-text",
        "ref_texts": "[10] Shu Liu et al. Path aggregation network for instance segmentation. In Computer Vision and Pattern Recognition (CVPR) , 2018.",
        "ref_ids": [
          "10"
        ]
      },
      "Drone-vs-bird detection challenge at IEEE AVSS2021": {
        "authors": [],
        "url": "https://opus.lib.uts.edu.au/bitstream/10453/126337/4/E0FE7792-B60F-4AC3-93B3-1320157609BB_am.pdf",
        "ref_texts": ""
      },
      "Polarmask++: Enhanced polar representation for single-shot instance segmentation and beyond": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2105.02184",
        "ref_texts": "[39] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia. Path aggregation network for instance segmentation. In Proc. IEEE Conf. Comp. Vis. Patt. Recogn. , pages 8759\u20138768, 2018.",
        "ref_ids": [
          "39"
        ]
      },
      "Cdnet: Centripetal direction network for nuclear instance segmentation": {
        "authors": [
          "Hongliang He",
          "Zhongyi Huang",
          "Yao Ding",
          "Guoli Song",
          "Lin Wang",
          "Qian Ren",
          "Pengxu Wei",
          "Zhiqiang Gao",
          "Jie Chen"
        ],
        "url": "http://openaccess.thecvf.com/content/ICCV2021/papers/He_CDNet_Centripetal_Direction_Network_for_Nuclear_Instance_Segmentation_ICCV_2021_paper.pdf",
        "ref_texts": "[14] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 8759\u20138768, 2018. ",
        "ref_ids": [
          "14"
        ]
      },
      "Dct-mask: Discrete cosine transform mask representation for instance segmentation": {
        "authors": [
          "Xing Shen",
          "Jirui Yang",
          "Chunbo Wei",
          "Bing Deng",
          "Jianqiang Huang",
          "Sheng Hua",
          "Xiaoliang Cheng",
          "Kewei Liang"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2021/papers/Shen_DCT-Mask_Discrete_Cosine_Transform_Mask_Representation_for_Instance_Segmentation_CVPR_2021_paper.pdf",
        "ref_texts": "[23] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In Proceedings of the IEEE conference on Computer Vision and Pattern Recognition , pages 8759\u20138768, 2018. 1,2",
        "ref_ids": [
          "23"
        ]
      },
      "Opanas: One-shot path aggregation network architecture search for object detection": {
        "authors": [
          "Tingting Liang",
          "Yongtao Wang",
          "Zhi Tang",
          "Guosheng Hu",
          "Haibin Ling"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2021/papers/Liang_OPANAS_One-Shot_Path_Aggregation_Network_Architecture_Search_for_Object_Detection_CVPR_2021_paper.pdf",
        "ref_texts": "[21] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In CVPR , pages 8759\u20138768, 2018. 1,2,3,6",
        "ref_ids": [
          "21"
        ]
      },
      "Multi-scale matching networks for semantic correspondence": {
        "authors": [
          "Dongyang Zhao",
          "Ziyang Song",
          "Zhenghao Ji",
          "Gangming Zhao",
          "Weifeng Ge",
          "Yizhou Yu"
        ],
        "url": "https://openaccess.thecvf.com/content/ICCV2021/papers/Zhao_Multi-Scale_Matching_Networks_for_Semantic_Correspondence_ICCV_2021_paper.pdf",
        "ref_texts": "[29] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In Proceedings of the IEEE conference on computer vision and pat-tern recognition , pages 8759\u20138768, 2018. 3",
        "ref_ids": [
          "29"
        ]
      },
      "SA-Net: A scale-attention network for medical image segmentation": {
        "authors": [
          "Jingfei Hu",
          "Hua Wang",
          "Jie Wang",
          "Yunqi Wang",
          "Fang He",
          "Jicong Zhang"
        ],
        "url": "https://journals.plos.org/plosone/article/file?id=10.1371/journal.pone.0247388&type=printable",
        "ref_texts": ""
      },
      "Deeplab2: A tensorflow library for deep labeling": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2106.09748",
        "ref_texts": "[43] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In CVPR , 2018. 1",
        "ref_ids": [
          "43"
        ]
      },
      "Target-aware object discovery and association for unsupervised video multi-object segmentation": {
        "authors": [
          "Tianfei Zhou",
          "Jianwu Li",
          "Xueyi Li",
          "Ling Shao"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2021/papers/Zhou_Target-Aware_Object_Discovery_and_Association_for_Unsupervised_Video_Multi-Object_Segmentation_CVPR_2021_paper.pdf",
        "ref_texts": "[29] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In CVPR , 2018. 3",
        "ref_ids": [
          "29"
        ]
      },
      "Rethinking text segmentation: A novel dataset and a text-specific refinement approach": {
        "authors": [
          "Xingqian Xu",
          "Zhifei Zhang",
          "Zhaowen Wang",
          "Brian Price",
          "Zhonghao Wang",
          "Humphrey Shi"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2021/papers/Xu_Rethinking_Text_Segmentation_A_Novel_Dataset_and_a_Text-Specific_Refinement_CVPR_2021_paper.pdf",
        "ref_texts": "[35] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , 2018.",
        "ref_ids": [
          "35"
        ]
      },
      "Bibliometric analysis of one-stage and two-stage object detection": {
        "authors": [
          "Aditya Lohia",
          "Kalyani Dhananjay",
          "Rahul Raghvendra",
          "Anupkumar M. Bongale"
        ],
        "url": "https://digitalcommons.unl.edu/context/libphilprac/article/9123/viewcontent/auto_convert.pdf",
        "ref_texts": "28. S Liu , L Qi , H Qin , J Shi , J Jia , \u201cPath Aggregation Network for Instance Segmentation\u201d, Proce edings of the IEEE \u2026, 2018 openaccess.thecvf.com arXiv:1803.01534v4 . ",
        "ref_ids": [
          "28"
        ]
      },
      "Dance: A deep attentive contour model for efficient instance segmentation": {
        "authors": [
          "Zichen Liu",
          "Jun Hao",
          "Xiangyu Chen",
          "Jiashi Feng"
        ],
        "url": "http://openaccess.thecvf.com/content/WACV2021/papers/Liu_DANCE_A_Deep_Attentive_Contour_Model_for_Efficient_Instance_Segmentation_WACV_2021_paper.pdf",
        "ref_texts": "[19] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , 2018.",
        "ref_ids": [
          "19"
        ]
      },
      "SyNet: An ensemble network for object detection in UAV images": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2012.12991",
        "ref_texts": "[37] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia, \u201cPath aggregation network for instance segmentation,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , 2018, pp. 8759\u20138768.",
        "ref_ids": [
          "37"
        ]
      },
      "Panoptic segmentation: A review": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2111.10250",
        "ref_texts": "[64] S. Liu, L. Qi, H. Qin, J. Shi, J. Jia, Path aggregation network for instance segmentation, in: Proceedings of the IEEE conference on computer vision and pattern recognition, 2018, pp. 8759\u20138768.",
        "ref_ids": [
          "64"
        ]
      },
      "A novel region of interest extraction layer for instance segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2004.13665",
        "ref_texts": "[8] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia, \u201cPath aggregation network for instance segmentation,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , 2018, pp. 8759\u20138768.",
        "ref_ids": [
          "8"
        ]
      },
      "TSingNet: Scale-aware and context-rich feature learning for traffic sign detection and recognition in the wild": {
        "authors": [
          "Jinghao Xue"
        ],
        "url": "https://discovery.ucl.ac.uk/id/eprint/10124611/1/YuanyuanLiu-NEUCOM-TSingNet-2021.pdf",
        "ref_texts": "[24]F. Shao, X. Wang, F. Meng, J. Zhu, D. Wang, J. Dai, Improved faster R-505CNN tra\u0000c sign detection based on a second region of interest and highlypossible regions proposal network, Sensors 19 (10) (2019) 2288.[25]Z. Zuo, K. Yu, Q. Zhou, X. Wang, T. Li, Tra\u0000c signs detection basedon Faster R-CNN, in: International Conference on Distributed ComputingSystems Workshops, IEEE, 2017, pp. 286\u2013288.510[26]I. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley,S. Ozair, A. Courville, Y. Bengio, Generative adversarial nets, in: Ad-vances in neural information processing systems, 2014, pp. 2672\u20132680.[27]Y. Bai, Y. Zhang, M. Ding, B. Ghanem, SOD-MTGAN: Small object de-tection via multi-task generative adversarial network, in: Proceedings of515the European Conference on Computer Vision, 2018, pp. 206\u2013221.[28]Y. Zhang, Y. Bai, M. Ding, B. Ghanem, Multi-task Generative AdversarialNetwork for Detecting Small Objects in the Wild, International Journal ofComputer Vision (2020) 1\u201319.[29]Z. Cai, Q. Fan, R. S. Feris, N. Vasconcelos, A unified multi-scale deep520convolutional neural network for fast object detection, in: European Con-ference on Computer Vision, Springer, 2016, pp. 354\u2013370.[30]S. Liu, L. Qi, H. Qin, J. Shi, J. Jia, Path Aggregation Network for InstanceSegmentation, in: Proceedings of the IEEE Conference on Computer Visionand Pattern Recognition, 2018, pp. 8759\u20138768.525[31]S. Bell, C. Lawrence Zitnick, K. Bala, R. Girshick, Inside-outside net: De-tecting objects in context with skip pooling and recurrent neural networks,in: Proceedings of the IEEE Conference on Computer Vision and PatternRecognition, 2016, pp. 2874\u20132883.[32]X. Chen, A. Gupta, Spatial memory for context reasoning in object detec-530tion, in: Proceedings of the IEEE International Conference on ComputerVision, 2017, pp. 4086\u20134096.30",
        "ref_ids": [
          "24",
          "25",
          "26",
          "27",
          "28",
          "29",
          "30",
          "31",
          "32"
        ]
      },
      "A deep learning-based vision system combining detection and tracking for fast on-line citrus sorting": {
        "authors": [],
        "url": "https://www.frontiersin.org/journals/plant-science/articles/10.3389/fpls.2021.622062/pdf",
        "ref_texts": "Bewley, A., Ge, Z., Ott, L., Ramos, F., and Upcroft, B. (2016). \u201cSimple online and realtime tracking,\u201d in 2016 IEEE International Conference on Image Processing (ICIP)(Phoenix,AZ:IEEE),3464\u20133468.doi:10.1109/ICIP.2016.7 533003 Burks, T., Villegas, F., Hannan, M., Flood, S., Sivaraman, B., Subra manian, V., et al. (2005). Engineering and horticultural aspects of robotic fruit harvesting: opportunities and constraints. HortTechnology 15, 79\u201387. doi:10.21273/HORTTECH.15.1.0079 Campbell, B. L., Nelson, R. G., Ebel, R. C., Dozier, W. A., Adrian, J. L., and Hockema, B. R. (2004). Fruit quality characteristics that a ffect consumer preferences for satsuma mandarins. HortScience 39, 1664\u20131669. doi:10.21273/HORTSCI.39.7.1664 Chen, L., Ai, H., Shang, C., Zhuang, Z., and Bai, B. (2017). \u201cOn line multi-object trackingwithconvolutionalneuralnetworks,\u201din IEEEInternationalConference onImageProcessing(ICIP) (Beijing),645\u2013649.doi:10.1109/ICIP.2017.8296360 Du, D., Qi, Y., Yu, H., Yang, Y., Duan, K., Li, G., et al. (2018). \u201c The unmanned aerial vehicle benchmark: object detection and tracking,\u201d in Proceedings of the European Conference on Computer Vision (ECCV) (Munich), 370\u2013386. doi:10.1007/978-3-030-01249-6_23 Fan,S.,Li,J.,Zhang,Y.,Tian,X.,Wang,Q.,He,X.,etal.(2020) .Onlinedetection ofdefectiveapplesusingcomputervisionsystemcombinedwithdee plearning methods. J.FoodEng .286:110102.doi:10.1016/j.jfoodeng.2020.110102 Han,J.,Zhang,D.,Cheng,G.,Liu,N.,andXu,D.(2018).Advan ceddeep-learning techniques for salient and category-specific object detection : a survey. IEEE SignalProcess.Mag .35,84\u2013100.doi:10.1109/MSP.2017.2749125 He, K., Zhang, X., Ren, S., and Sun, J. (2016). \u201cDeep residual learn ing for image recognition,\u201d in Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Las Vegas, NV), 770\u2013778. doi:10.1109/CVPR.2016.90 Holmes, G. J., and Eckert, J. W. (1999). Sensitivity of Penicillium digitatum and P. italicum to Postharvest citrus fungicides in California. Phytopathology 89, 716\u2013721.doi:10.1094/PHYTO.1999.89.9.716 Janai, J., Guney, F., Behl, A., and Geiger, A. (2017). Computer v ision for autonomous vehicles: problems, datasets and state-of-the-art. Found. Trends Comput.Graph.Vis .12,1\u2013308.doi:10.1561/0600000079 Jiang, B., He, J., Yang, S., Fu, H., Li, T., Song, H., et al. (2019). Fusion of machine vision technology and AlexNet-CNNs deep learning network for the detection of postharvest apple pesticide residues. Artif. Intell. Agric . 1, 1\u20138. doi:10.1016/j.aiia.2019.02.001 Kang, H., and Chen, C. (2019). Fruit detection and segmentation for apple harvesting using visual sensor in orchards. Sensors 19:4599. doi:10.3390/s19204599 Kang, H., and Chen, C. (2020a). Fast implementation of real-time fruit detection in apple orchards using deep learning. Comput. Electron. Agric . 168:105108. doi:10.1016/j.compag.2019.105108 Kang,H.,andChen,C.(2020b).Fruitdetection,segmentationa nd3Dvisualisation of environments in apple orchards. Comput. Electron. Agric . 171:105302. doi:10.1016/j.compag.2020.105302 Kang, H., Zhou, H., Wang, X., and Chen, C. (2020). Real-time fruit rec ognition and grasping estimation for robotic apple harvesting. Sensors20:5670. doi:10.3390/s20195670 Kosiorek,A.R.,Kim,H.,Posner,I.,andTeh,Y.W.(2018).Seque ntialattend,infer, repeat: generative modelling of moving objects. Adv. Neural Inform. Process. Syst.31,8606\u20138616. Lee, W. H., Kim, M. S., Lee, H., Delwiche, S. R., Bae, H., Kim, D. Y., et al. (2014). Hyperspectral near-infrared imaging for the detection of physical d amages of pear.J.FoodEng .130,1\u20137.doi:10.1016/j.jfoodeng.2013.12.032 Liu, S., Qi, L., Qin, H., Shi, J., and Jia, J. (2018). \u201cPath aggre gation network for instancesegmentation,\u201din ProceedingsoftheIEEEComputerSocietyConferenceon Computer Vision and Pattern Recognition (Salt Lake City, UT), 8759\u20138768. doi:10.1109/CVPR.2018.00913 Liu, Z., He, Y., Cen, H., and Lu, R. (2018). Deep feature representat ion with stacked sparse auto-encoder and convolutional neural net work for hyperspectralimaging-baseddetectionofcucumberdefects. Trans.ASABE 61, 1\u20134.doi:10.13031/trans.12214 Nazirul,S.I.,Barman,S.C.,Islam,M.,Islam,R.,andChakma,A.S.(20 17).Roleof lemon(Citruslimon)productiononlivelihoodsofruralpeopleinBangladesh . JournalofAgriculturalEcon.RuralDev .2,167\u2013175. Picon, A., Alvarez-Gila, A., Seitz, M., Ortiz-Barredo, A., Echaza rra, J., and Johannes, A. (2019). Deep convolutional neural networks for mob ile capture device-based crop disease classification in the wild. Comput. Electron. Agric ."
      },
      "Shared cross-modal trajectory prediction for autonomous driving": {
        "authors": [
          "Chiho Choi",
          "Joon Hee",
          "Jiachen Li",
          "Srikanth Malla"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2021/papers/Choi_Shared_Cross-Modal_Trajectory_Prediction_for_Autonomous_Driving_CVPR_2021_paper.pdf",
        "ref_texts": ""
      },
      "Multipatch feature pyramid network for weakly supervised object detection in optical remote sensing images": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2108.08063",
        "ref_texts": "[17] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia, \u201cPath aggregation network for instance segmentation,\u201d in Proc. IEEE Conf. Comput. Vis. Pattern Recognit. , 2018, pp. 8759\u20138768.",
        "ref_ids": [
          "17"
        ]
      },
      "Robust instance segmentation through reasoning about multi-object occlusion": {
        "authors": [
          "Xiaoding Yuan",
          "Adam Kortylewski",
          "Yihong Sun",
          "Alan Yuille"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2021/papers/Yuan_Robust_Instance_Segmentation_Through_Reasoning_About_Multi-Object_Occlusion_CVPR_2021_paper.pdf",
        "ref_texts": "[21] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , June 2018. 2",
        "ref_ids": [
          "21"
        ]
      },
      "Malaria parasite detection in thick blood smear microscopic images using modified YOLOV3 and YOLOV4 models": {
        "authors": [
          "Fetulhak Abdurahman"
        ],
        "url": "https://link.springer.com/content/pdf/10.1186/s12859-021-04036-4.pdf",
        "ref_texts": ""
      },
      "A simple long-tailed recognition baseline via vision-language model": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2111.14745",
        "ref_texts": "[40] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 8759\u20138768, 2018. 1",
        "ref_ids": [
          "40"
        ]
      },
      "Point cloud instance segmentation using probabilistic embeddings": {
        "authors": [
          "Biao Zhang",
          "Peter Wonka"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhang_Point_Cloud_Instance_Segmentation_Using_Probabilistic_Embeddings_CVPR_2021_paper.pdf",
        "ref_texts": "[24] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 8759\u20138768, 2018.",
        "ref_ids": [
          "24"
        ]
      },
      "Semantic attention and scale complementary network for instance segmentation in remote sensing images": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2107.11758",
        "ref_texts": "[16] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia, \u201cPath aggregation network for instance segmentation,\u201d in Proc. IEEE Int. Conf. Comput. Vis. Pattern Recognit. (CVPR) , Jun. 2018, pp. 8759\u20138768.",
        "ref_ids": [
          "16"
        ]
      },
      "SRPN: similarity-based region proposal networks for nuclei and cells detection in histology images": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2106.13556",
        "ref_texts": "[65] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia, \u201cPath aggregation network for instance segmentation,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition , 2018, pp.",
        "ref_ids": [
          "65"
        ]
      },
      "Object detection in optical remote sensing images: A survey and a new benchmark": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1909.00133",
        "ref_texts": "7132\u20107141.\u00a0 Huang,\u00a0G.,\u00a0Liu,\u00a0Z.,\u00a0Laurens, \u00a0V.D.M.,\u00a0Weinberger, \u00a0K.Q.,\u00a02017.\u00a0Densely\u00a0Connected \u00a0Convolutional \u00a0Networks. \u00a0In:\u00a0Proc.\u00a0IEEE\u00a0Int.\u00a0 Conf.\u00a0Comput. \u00a0Vision\u00a0Pattern\u00a0Recognit., \u00a0pp.\u00a04700\u20104708.\u00a0 Ioffe,\u00a0S.,\u00a0Szegedy, \u00a0C.,\u00a02015.\u00a0Batch\u00a0Normalization: \u00a0Accelerating \u00a0Deep\u00a0Network \u00a0Training \u00a0by\u00a0Reducing \u00a0Internal\u00a0Covariate \u00a0Shift.\u00a0In:\u00a0 Proc.\u00a0IEEE\u00a0Int.\u00a0Conf.\u00a0Machine \u00a0Learning, \u00a0pp.\u00a0448\u2010456.\u00a0 Jia,\u00a0Y.,\u00a0Shelhamer, \u00a0E.,\u00a0Donahue, \u00a0J.,\u00a0Karayev, \u00a0S.,\u00a0Long,\u00a0J.,\u00a0Girshick, \u00a0R.,\u00a0Guadarrama, \u00a0S.,\u00a0Darrell,\u00a0T.,\u00a02014.\u00a0Caffe:\u00a0Convolutional \u00a0 architecture \u00a0for\u00a0fast\u00a0feature\u00a0embedding. \u00a0In:\u00a0Proc.\u00a0ACM\u00a0Int.\u00a0Conf.\u00a0Multimedia, \u00a0pp.\u00a0675\u2010678.\u00a0 Kong,\u00a0T.,\u00a0Yao,\u00a0A.,\u00a0Chen,\u00a0Y.,\u00a0Sun,\u00a0F.,\u00a02016.\u00a0Hypernet: \u00a0Towards \u00a0accurate\u00a0region\u00a0proposal \u00a0generation \u00a0and\u00a0joint\u00a0object\u00a0detection. \u00a0In:\u00a0 Proc.\u00a0IEEE\u00a0Int.\u00a0Conf.\u00a0Comput. \u00a0Vision\u00a0Pattern\u00a0Recognit., \u00a0pp.\u00a0845\u2010853.\u00a0 Krizhevsky, \u00a0A.,\u00a0Sutskever, \u00a0I.,\u00a0Hinton,\u00a0G.E.,\u00a02012.\u00a0ImageNet \u00a0Classification \u00a0with\u00a0Deep\u00a0Convolutional \u00a0Neural\u00a0Networks. \u00a0In:\u00a0Proc.\u00a0 Conf.\u00a0Adv.\u00a0Neural\u00a0Inform.\u00a0Process.\u00a0Syst.,\u00a0pp.\u00a01097\u20101105.\u00a0 Law,\u00a0H.,\u00a0Deng,\u00a0J.,\u00a02018.\u00a0Cornernet: \u00a0Detecting \u00a0objects\u00a0as\u00a0paired\u00a0keypoints. \u00a0In:\u00a0Proc.\u00a0Eur.\u00a0Conf.\u00a0Comput. \u00a0Vis.,\u00a0pp.\u00a0734\u2010750.\u00a0 Li,\u00a0K.,\u00a0Cheng,\u00a0G.,\u00a0Bu,\u00a0S.,\u00a0You,\u00a0X.,\u00a02018.\u00a0Rotation \u2010Insensitive \u00a0and\u00a0Context\u2010Augmented \u00a0Object\u00a0Detection \u00a0in\u00a0Remote\u00a0Sensing\u00a0Images.\u00a0 IEEE\u00a0Trans.\u00a0Geosci.\u00a0Remote\u00a0Sens.\u00a056,\u00a02337\u20102348.\u00a0 Li,\u00a0Z.,\u00a0Peng,\u00a0C.,\u00a0Yu,\u00a0G.,\u00a0Zhang,\u00a0X.,\u00a0Deng,\u00a0Y.,\u00a0Sun,\u00a0J.,\u00a02017.\u00a0Light\u2010head\u00a0r\u2010cnn:\u00a0In\u00a0defense\u00a0of\u00a0two\u2010stage\u00a0object\u00a0detector. \u00a0arXiv\u00a0preprint\u00a0 arXiv:1711.07264. \u00a0 Lin,\u00a0H.,\u00a0Shi,\u00a0Z.,\u00a0Zou,\u00a0Z.,\u00a02017a.\u00a0Fully\u00a0Convolutional \u00a0Network \u00a0With\u00a0Task\u00a0Partitioning \u00a0for\u00a0Inshore\u00a0Ship\u00a0Detection \u00a0in\u00a0Optical\u00a0Remote\u00a0 Sensing\u00a0Images.\u00a0IEEE\u00a0Geosci.\u00a0Remote\u00a0Sens.\u00a0Lett.\u00a014,\u00a01665\u20101669.\u00a0 Lin,\u00a0T.\u2010Y.,\u00a0Doll\u00e1r,\u00a0P.,\u00a0Girshick, \u00a0R.B.,\u00a0He,\u00a0K.,\u00a0Hariharan, \u00a0B.,\u00a0Belongie, \u00a0S.J.,\u00a02017b.\u00a0Feature\u00a0Pyramid \u00a0Networks \u00a0for\u00a0Object\u00a0Detection. \u00a0In:\u00a0 Proc.\u00a0IEEE\u00a0Int.\u00a0Conf.\u00a0Comput. \u00a0Vision\u00a0Pattern\u00a0Recognit., \u00a0pp.\u00a02117\u20102125.\u00a0 Lin,\u00a0T.\u2010Y.,\u00a0Maire,\u00a0M.,\u00a0Belongie, \u00a0S.,\u00a0Hays,\u00a0J.,\u00a0Perona,\u00a0P.,\u00a0Ramanan, \u00a0D.,\u00a0Doll\u00e1r,\u00a0P.,\u00a0Zitnick,\u00a0C.L.,\u00a02014.\u00a0Microsoft \u00a0coco:\u00a0Common \u00a0 objects\u00a0in\u00a0context.\u00a0In:\u00a0Proc.\u00a0Eur.\u00a0Conf.\u00a0Comput. \u00a0Vis.,\u00a0pp.\u00a0740\u2010755.\u00a0 Lin,\u00a0T.Y.,\u00a0Goyal,\u00a0P.,\u00a0Girshick, \u00a0R.,\u00a0He,\u00a0K.,\u00a0Dollar,\u00a0P.,\u00a02017c.\u00a0Focal\u00a0loss\u00a0for\u00a0dense\u00a0object\u00a0detection. \u00a0IEEE\u00a0Trans.\u00a0Pattern\u00a0Anal.\u00a0Mach.\u00a0 Intell.\u00a0PP,\u00a02999\u20103007.\u00a0 Liu,\u00a0K.,\u00a0Mattyus, \u00a0G.,\u00a02015.\u00a0Fast\u00a0Multiclass \u00a0Vehicle\u00a0Detection \u00a0on\u00a0Aerial\u00a0Images.\u00a0IEEE\u00a0Geosci.\u00a0Remote\u00a0Sens.\u00a0Lett.\u00a012,\u00a01938\u20101942.\u00a0 Liu,\u00a0L.,\u00a0Ouyang, \u00a0W.,\u00a0Wang,\u00a0X.,\u00a0Fieguth,\u00a0P.,\u00a0Chen,\u00a0J.,\u00a0Liu,\u00a0X.,\u00a0Pietik\u00e4inen, \u00a0M.,\u00a02018a.\u00a0Deep\u00a0learning\u00a0for\u00a0generic\u00a0object\u00a0detection: \u00a0A\u00a0 survey.\u00a0arXiv\u00a0preprint\u00a0arXiv:1809.02165. \u00a0 Liu,\u00a0L.,\u00a0Pan,\u00a0Z.,\u00a0Lei,\u00a0B.,\u00a02017a.\u00a0Learning \u00a0a\u00a0Rotation \u00a0Invariant \u00a0Detector \u00a0with\u00a0Rotatable \u00a0Bounding \u00a0Box.\u00a0arXiv\u00a0preprint\u00a0 arXiv:1711.09405. \u00a0 Liu,\u00a0S.,\u00a0Huang,\u00a0D.,\u00a0Wang,\u00a0Y.,\u00a02017b.\u00a0Receptive \u00a0Field\u00a0Block\u00a0Net\u00a0for\u00a0Accurate \u00a0and\u00a0Fast\u00a0Object\u00a0Detection. \u00a0arXiv\u00a0preprint\u00a0 arXiv:1711.07767. \u00a0 Liu,\u00a0S.,\u00a0Qi,\u00a0L.,\u00a0Qin,\u00a0H.,\u00a0Shi,\u00a0J.,\u00a0Jia,\u00a0J.,\u00a02018b.\u00a0Path\u00a0aggregation \u00a0network\u00a0for\u00a0instance\u00a0segmentation. \u00a0In:\u00a0Proc.\u00a0IEEE\u00a0Int.\u00a0Conf.\u00a0Comput. \u00a0 Vision\u00a0Pattern\u00a0Recognit., \u00a0pp.\u00a08759\u20108768.\u00a0 Liu,\u00a0W.,\u00a0Anguelov, \u00a0D.,\u00a0Erhan,\u00a0D.,\u00a0Szegedy, \u00a0C.,\u00a0Reed,\u00a0S.,\u00a0Fu,\u00a0C.Y.,\u00a0Berg,\u00a0A.C.,\u00a02016a.\u00a0SSD:\u00a0Single\u00a0Shot\u00a0MultiBox \u00a0Detector. \u00a0In:\u00a0Proc.\u00a0 Eur.\u00a0Conf.\u00a0Comput. \u00a0Vis.,\u00a0pp.\u00a021\u201037.\u00a0 Liu,\u00a0W.,\u00a0Ma,\u00a0L.,\u00a0Chen,\u00a0H.,\u00a02018c.\u00a0Arbitrary \u2010Oriented \u00a0Ship\u00a0Detection \u00a0Framework \u00a0in\u00a0Optical\u00a0Remote\u2010Sensing\u00a0Images.\u00a0IEEE\u00a0Geosci.\u00a0 Remote\u00a0Sens.\u00a0Lett.\u00a015,\u00a0937\u2010941.\u00a0 Liu,\u00a0Z.,\u00a0Wang,\u00a0H.,\u00a0Weng,\u00a0L.,\u00a0Yang,\u00a0Y.,\u00a02016b.\u00a0Ship\u00a0Rotated\u00a0Bounding \u00a0Box\u00a0Space\u00a0for\u00a0Ship\u00a0Extraction \u00a0From\u00a0High\u2010Resolution \u00a0Optical\u00a0 Satellite\u00a0Images\u00a0With\u00a0Complex \u00a0Backgrounds. \u00a0IEEE\u00a0Geosci.\u00a0Remote\u00a0Sens.\u00a0Lett.\u00a013,\u00a01074\u20101078.\u00a0 Long,\u00a0J.,\u00a0Shelhamer, \u00a0E.,\u00a0Darrell,\u00a0T.,\u00a02015.\u00a0Fully\u00a0convolutional \u00a0networks \u00a0for\u00a0semantic \u00a0segmentation. \u00a0In:\u00a0Proc.\u00a0IEEE\u00a0Int.\u00a0Conf.\u00a0 Comput. \u00a0Vision\u00a0Pattern\u00a0Recognit., \u00a0pp.\u00a03431\u20103440.\u00a0 Long,\u00a0Y.,\u00a0Gong,\u00a0Y.,\u00a0Xiao,\u00a0Z.,\u00a0Liu,\u00a0Q.,\u00a02017.\u00a0Accurate \u00a0Object\u00a0Localization \u00a0in\u00a0Remote\u00a0Sensing\u00a0Images\u00a0Based\u00a0on\u00a0Convolutional \u00a0Neural\u00a0 Networks. \u00a0IEEE\u00a0Trans.\u00a0Geosci.\u00a0Remote\u00a0Sens.\u00a055,\u00a02486\u20102498.\u00a0 Luan,\u00a0S.,\u00a0Chen,\u00a0C.,\u00a0Zhang,\u00a0B.,\u00a0Han,\u00a0J.,\u00a0Liu,\u00a0J.,\u00a02018.\u00a0Gabor\u00a0Convolutional \u00a0Networks. \u00a0IEEE\u00a0Trans.\u00a0Image\u00a0Process.\u00a027,\u00a04357\u20104366.\u00a0 Mikolov, \u00a0T.,\u00a0Deoras,\u00a0A.,\u00a0Povey,\u00a0D.,\u00a0Burget,\u00a0L.,\u00a0Cernocky, \u00a0J.,\u00a02012.\u00a0Strategies \u00a0for\u00a0training\u00a0large\u00a0scale\u00a0neural\u00a0network\u00a0language \u00a0 models.\u00a0In:\u00a0Proc.\u00a0IEEE\u00a0Workshop \u00a0Autom.\u00a0Speech\u00a0Recognit. \u00a0Underst., \u00a0pp.\u00a0196\u2010201.\u00a0"
      },
      "Recent advances in deep learning for object detection": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1908.03673",
        "ref_texts": "[238] S. Liu, L. Qi, H. Qin, J. Shi, J. Jia, Path aggregation network for instance segmentation, in: CVPR, 2018.",
        "ref_ids": [
          "238"
        ]
      },
      "Deformable detr: Deformable transformers for end-to-end object detection": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2010.04159",
        "ref_texts": "9 Published as a conference paper at ICLR 2021 Jifeng Dai, Haozhi Qi, Yuwen Xiong, Yi Li, Guodong Zhang, Han Hu, and Yichen Wei. Deformable convolutional networks. In ICCV , 2017. Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei. Imagenet: A large-scale hierarchical image database. In CVPR , 2009. Golnaz Ghiasi, Tsung-Yi Lin, and Quoc V Le. Nas-fpn: Learning scalable feature pyramid architecture for object detection. In CVPR , 2019. Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In CVPR , 2016. Jonathan Ho, Nal Kalchbrenner, Dirk Weissenborn, and Tim Salimans. Axial attention in multidimensional transformers. arXiv preprint arXiv:1912.12180 , 2019. Han Hu, Zheng Zhang, Zhenda Xie, and Stephen Lin. Local relation networks for image recognition. InICCV , 2019. Zilong Huang, Xinggang Wang, Lichao Huang, Chang Huang, Yunchao Wei, and Wenyu Liu. Ccnet: Criss-cross attention for semantic segmentation. In ICCV , 2019. Angelos Katharopoulos, Apoorv Vyas, Nikolaos Pappas, and Franc \u00b8ois Fleuret. Transformers are rnns: Fast autoregressive transformers with linear attention. arXiv preprint arXiv:2006.16236 , 2020. Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In ICLR , 2015. Nikita Kitaev, \u0141ukasz Kaiser, and Anselm Levskaya. Reformer: The efficient transformer. In ICLR , 2020. Tao Kong, Fuchun Sun, Chuanqi Tan, Huaping Liu, and Wenbing Huang. Deep feature pyramid reconfiguration for object detection. In ECCV , 2018. Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva Ramanan, Piotr Doll\u00b4ar, and C Lawrence Zitnick. Microsoft coco: Common objects in context. In ECCV , 2014. Tsung-Yi Lin, Piotr Doll \u00b4ar, Ross Girshick, Kaiming He, Bharath Hariharan, and Serge Belongie. Feature pyramid networks for object detection. In CVPR , 2017a. Tsung-Yi Lin, Priya Goyal, Ross Girshick, Kaiming He, and Piotr Doll \u00b4ar. Focal loss for dense object detection. In ICCV , 2017b. Li Liu, Wanli Ouyang, Xiaogang Wang, Paul Fieguth, Jie Chen, Xinwang Liu, and Matti Pietik \u00a8ainen. Deep learning for generic object detection: A survey. IJCV , 2020. Peter J Liu, Mohammad Saleh, Etienne Pot, Ben Goodrich, Ryan Sepassi, Lukasz Kaiser, and Noam Shazeer. Generating wikipedia by summarizing long sequences. In ICLR , 2018a. Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In CVPR , 2018b. Niki Parmar, Ashish Vaswani, Jakob Uszkoreit, \u0141ukasz Kaiser, Noam Shazeer, Alexander Ku, and Dustin Tran. Image transformer. In ICML , 2018. Jiezhong Qiu, Hao Ma, Omer Levy, Scott Wen-tau Yih, Sinong Wang, and Jie Tang. Blockwise self-attention for long document understanding. arXiv preprint arXiv:1911.02972 , 2019. Prajit Ramachandran, Niki Parmar, Ashish Vaswani, Irwan Bello, Anselm Levskaya, and Jonathon Shlens. Stand-alone self-attention in vision models. In NeurIPS , 2019. Shaoqing Ren, Kaiming He, Ross Girshick, and Jian Sun. Faster r-cnn: Towards real-time object detection with region proposal networks. In NeurIPS , 2015. Aurko Roy, Mohammad Saffar, Ashish Vaswani, and David Grangier. Efficient content-based sparse attention with routing transformers. arXiv preprint arXiv:2003.05997 , 2020."
      },
      "Efficientdet: Scalable and efficient object detection": {
        "authors": [
          "Mingxing Tan",
          "Ruoming Pang",
          "Quoc V. Le"
        ],
        "url": "https://openaccess.thecvf.com/content_CVPR_2020/papers/Tan_EfficientDet_Scalable_and_Efficient_Object_Detection_CVPR_2020_paper.pdf",
        "ref_texts": "[23] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. CVPR , 2018. 2,3,7",
        "ref_ids": [
          "23"
        ]
      },
      "CSPNet: A new backbone that can enhance learning capability of CNN": {
        "authors": [
          "Yao Wang",
          "Yuan Mark",
          "Hua Wu",
          "Yang Chen",
          "Wei Hsieh",
          "Hau Yeh"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPRW_2020/papers/w28/Wang_CSPNet_A_New_Backbone_That_Can_Enhance_Learning_Capability_of_CVPRW_2020_paper.pdf",
        "ref_texts": "[19] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , pages 8759\u20138768, 2018. 7",
        "ref_ids": [
          "19"
        ]
      },
      "Deep high-resolution representation learning for visual recognition": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1908.07919",
        "ref_texts": "[97] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia. Path aggregation network for instance segmentation. In CVPR , pages 8759\u20138768, 2018. 9",
        "ref_ids": [
          "97"
        ]
      },
      "Deep learning for generic object detection: A survey": {
        "authors": [
          "Li Liu"
        ],
        "url": "https://link.springer.com/content/pdf/10.1007/s11263-019-01247-4.pdf",
        "ref_texts": "(2017a). Feature pyramid networks for object detection. In CVPR . Lin, T., Goyal, P., Girshick, R., He, K., & Doll\u00e1r, P. (2017b). Focal loss for dense object detection. In ICCV . Lin, T., Maire, M., Belongie, S., Hays, J., Perona, P., Ramanan, D., Doll\u00e1r, P., & Zitnick, L. (2014). Microsoft COCO: Common objectsin context. In ECCV (pp. 740\u2013755). Lin, X., Zhao, C., & Pan, W. (2017c). Towards accurate binary convolutional neural network. In NIPS (pp. 344\u2013352). Litjens, G., Kooi, T., Bejnordi, B., Setio, A., Ciompi, F., Ghafoorian, M., et al. (2017). A survey on deep learning in medical image analysis. Medical Image Analysis ,42, 60\u201388. Liu, C., Zoph, B., Neumann, M., Shlens, J., Hua, W., Li, L., FeiFei, L., Yuille, A., Huang, J., & Murphy, K. (2018a). Progressive neuralarchitecture search. In ECCV (pp. 19\u201334). Liu, L., Fieguth, P., Guo, Y ., Wang, X., & Pietik\u00e4inen, M. (2017). Local binary features for texture classification: Taxonomy and experi-mental study. Pattern Recognition ,62, 135\u2013160. Liu, S., Huang, D., & Wang, Y . (2018b). Receptive field block net for accurate and fast object detection. In ECCV . Liu, S., Qi, L., Qin, H., Shi, J., & Jia, J. (2018c). Path aggregation network for instance segmentation. In CVPR (pp. 8759\u20138768). Liu, W., Anguelov, D., Erhan, D., Szegedy, C., Reed, S., Fu, C., & Berg, A. (2016). SSD: Single shot multibox detector. In ECCV"
      },
      "Pointrend: Image segmentation as rendering": {
        "authors": [
          "Alexander Kirillov",
          "Yuxin Wu",
          "Kaiming He",
          "Ross Girshick"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPR_2020/papers/Kirillov_PointRend_Image_Segmentation_As_Rendering_CVPR_2020_paper.pdf",
        "ref_texts": "[29] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In CVPR , 2018. 3",
        "ref_ids": [
          "29"
        ]
      },
      "Axial-deeplab: Stand-alone axial-attention for panoptic segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2003.07853",
        "ref_texts": "62. Liu, S., Qi, L., Qin, H., Shi, J., Jia, J.: Path aggregation network for instance segmentation. In: CVPR (2018) 13",
        "ref_ids": [
          "62"
        ]
      },
      "Solov2: Dynamic and fast instance segmentation": {
        "authors": [],
        "url": "https://proceedings.neurips.cc/paper_files/paper/2020/file/cd3afef9b8b89558cd56638c3631868a-Paper.pdf",
        "ref_texts": "[25] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In Proc. IEEE Conf. Comp. Vis. Patt. Recogn. , 2018.",
        "ref_ids": [
          "25"
        ]
      },
      "Solo: Segmenting objects by locations": {
        "authors": [],
        "url": "https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123630630.pdf",
        "ref_texts": "19. Liu, S., Qi, L., Qin, H., Shi, J., Jia, J.: Path aggregation network for instance segmentation. In: Proc. IEEE Conf. Comp. Vis. Patt. Recogn. (2018)",
        "ref_ids": [
          "19"
        ]
      },
      "A survey on instance segmentation: state of the art": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2007.00047",
        "ref_texts": "79. Liu S, Qi L, Qin H, Shi J, Jia J Path aggregation network for instance segmentation. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2018. pp 8759 -8768 ",
        "ref_ids": [
          "79"
        ]
      },
      "Conditional convolutions for instance segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2003.05664",
        "ref_texts": "25. Liu, S., Qi, L., Qin, H., Shi, J., Jia, J.: Path aggregation network for instance segmentation. In: Proc. IEEE Conf. Comp. Vis. Patt. Recogn. pp. 8759{8768 (2018)",
        "ref_ids": [
          "25"
        ]
      },
      "Panoptic-deeplab: A simple, strong, and fast baseline for bottom-up panoptic segmentation": {
        "authors": [
          "Bowen Cheng",
          "Maxwell D. Collins",
          "Yukun Zhu",
          "Ting Liu",
          "Thomas S. Huang",
          "Hartwig Adam",
          "Chieh Chen"
        ],
        "url": "https://openaccess.thecvf.com/content_CVPR_2020/papers/Cheng_Panoptic-DeepLab_A_Simple_Strong_and_Fast_Baseline_for_Bottom-Up_Panoptic_CVPR_2020_paper.pdf",
        "ref_texts": "[49] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In CVPR , 2018. 5",
        "ref_ids": [
          "49"
        ]
      },
      "Polarmask: Single shot instance segmentation with polar representation": {
        "authors": [
          "Enze Xie",
          "Peize Sun",
          "Xiaoge Song",
          "Wenhai Wang",
          "Xuebo Liu",
          "Ding Liang",
          "Chunhua Shen",
          "Ping Luo"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPR_2020/papers/Xie_PolarMask_Single_Shot_Instance_Segmentation_With_Polar_Representation_CVPR_2020_paper.pdf",
        "ref_texts": "[25] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In Proc. IEEE Conf. Comp. Vis. Patt. Recogn. , pages 8759\u20138768, 2018.",
        "ref_ids": [
          "25"
        ]
      },
      "Centermask: Real-time anchor-free instance segmentation": {
        "authors": [
          "Youngwan Lee",
          "Jongyoul Park"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPR_2020/papers/Lee_CenterMask_Real-Time_Anchor-Free_Instance_Segmentation_CVPR_2020_paper.pdf",
        "ref_texts": "[24] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In CVPR , pages 8759\u20138768, 2018. 1",
        "ref_ids": [
          "24"
        ]
      },
      "Computer vision for autonomous vehicles: Problems, datasets and state of the art": {
        "authors": [],
        "url": "https://www.nowpublishers.com/article/DownloadSummary/CGV-079",
        "ref_texts": "[430]Liu, S., L. Qi, H. Qin, J. Shi, and J. Jia (2018). \u201cPath aggregation network for instance segmentation\u201d. In: Proc. IEEE Conf. on Computer Vision and Pattern Recognition (CVPR) . 8759\u20138768.",
        "ref_ids": [
          "430"
        ]
      },
      "Imbalance problems in object detection: A review": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1909.00169",
        "ref_texts": "[75] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia, \u201cPath aggregation network for instance segmentation,\u201d in The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2018.",
        "ref_ids": [
          "75"
        ]
      },
      "Revisiting the sibling head in object detector": {
        "authors": [
          "Guanglu Song",
          "Yu Liu",
          "Xiaogang Wang"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPR_2020/papers/Song_Revisiting_the_Sibling_Head_in_Object_Detector_CVPR_2020_paper.pdf",
        "ref_texts": "[24] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 8759\u20138768, 2018. 7",
        "ref_ids": [
          "24"
        ]
      },
      "Augfpn: Improving multi-scale feature learning for object detection": {
        "authors": [
          "Chaoxu Guo",
          "Bin Fan",
          "Qian Zhang",
          "Shiming Xiang",
          "Chunhong Pan"
        ],
        "url": "https://openaccess.thecvf.com/content_CVPR_2020/papers/Guo_AugFPN_Improving_Multi-Scale_Feature_Learning_for_Object_Detection_CVPR_2020_paper.pdf",
        "ref_texts": "[25] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In CVPR , 2018. 2,5,8",
        "ref_ids": [
          "25"
        ]
      },
      "Temporal pyramid network for action recognition": {
        "authors": [
          "Ceyuan Yang",
          "Yinghao Xu",
          "Jianping Shi",
          "Bo Dai",
          "Bolei Zhou"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPR_2020/papers/Yang_Temporal_Pyramid_Network_for_Action_Recognition_CVPR_2020_paper.pdf",
        "ref_texts": "[20] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In Proc. CVPR , 2018. 2,4",
        "ref_ids": [
          "20"
        ]
      },
      "Pointgroup: Dual-set point grouping for 3d instance segmentation": {
        "authors": [
          "Li Jiang",
          "Hengshuang Zhao",
          "Shaoshuai Shi",
          "Shu Liu",
          "Wing Fu",
          "Jiaya Jia"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPR_2020/papers/Jiang_PointGroup_Dual-Set_Point_Grouping_for_3D_Instance_Segmentation_CVPR_2020_paper.pdf",
        "ref_texts": "[29] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In CVPR , 2018.",
        "ref_ids": [
          "29"
        ]
      },
      "Feature pyramid transformer": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2007.09451",
        "ref_texts": "13. Liu, S., Qi, L., Qin, H., Shi, J., Jia, J.: Path aggregation network for instance segmentation. In: CVPR. (2018)",
        "ref_ids": [
          "13"
        ]
      },
      "Boundary-preserving mask r-cnn": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2007.08921",
        "ref_texts": "37. Liu, S., Qi, L., Qin, H., Shi, J., Jia, J.: Path aggregation network for instance segmentation. In: CVPR. pp. 8759{8768 (2018)",
        "ref_ids": [
          "37"
        ]
      },
      "Deep snake for real-time instance segmentation": {
        "authors": [
          "Sida Peng",
          "Wen Jiang",
          "Huaijin Pi",
          "Xiuli Li",
          "Hujun Bao",
          "Xiaowei Zhou"
        ],
        "url": "https://openaccess.thecvf.com/content_CVPR_2020/papers/Peng_Deep_Snake_for_Real-Time_Instance_Segmentation_CVPR_2020_paper.pdf",
        "ref_texts": "[27] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In CVPR , 2018. 1,2,6,7",
        "ref_ids": [
          "27"
        ]
      },
      "Face mask recognition system with YOLOV5 based on image recognition": {
        "authors": [],
        "url": "https://scholar.archive.org/work/jjut6kph7vdz3b66haqrwj4ype/access/wayback/https://ieeexplore.ieee.org/ielx7/9344865/9344866/09345042.pdf",
        "ref_texts": "[4] Liu, S., Qi, L., Qin, H., Shi, J., & Jia, J. (2018). Pathaggregation network for instance segmentation. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 8759",
        "ref_ids": [
          "4"
        ]
      },
      "Segfix: Model-agnostic boundary refinement for segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2007.04269",
        "ref_texts": "39. Liu, S., Qi, L., Qin, H., Shi, J., Jia, J.: Path aggregation network for instance segmentation. In: CVPR (2018)",
        "ref_ids": [
          "39"
        ]
      },
      "Evolution of image segmentation using deep convolutional neural network: A survey": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2001.04074",
        "ref_texts": "[173] S. Liu, L. Qi, H. Qin, J. Shi, J. Jia, Path aggregation network for instance segmentation (2018)",
        "ref_ids": [
          "173"
        ]
      },
      "Sipmask: Spatial information preservation for fast image and video instance segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2007.14772",
        "ref_texts": "31. Liu, S., Qi, L., Qin, H., Shi, J., Jia, J.: Path aggregation network for instance segmentation. Proc. IEEE Conf. Computer Vision and Pattern Recognition (2018)",
        "ref_ids": [
          "31"
        ]
      },
      "Improving multispectral pedestrian detection by addressing modality imbalance problems": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2008.03043",
        "ref_texts": "28. Liu, S., Qi, L., Qin, H., Shi, J., Jia, J.: Path aggregation network for instance segmentation. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. pp. 8759{8768 (2018)",
        "ref_ids": [
          "28"
        ]
      },
      "The devil is in classification: A simple framework for long-tail instance segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2007.11978",
        "ref_texts": "34. Liu, S., Qi, L., Qin, H., Shi, J., Jia, J.: Path aggregation network for instance segmentation. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. pp. 8759{8768 (2018)",
        "ref_ids": [
          "34"
        ]
      },
      "Oriented objects as pairs of middle lines": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1912.10694",
        "ref_texts": "39. Liu, S., Qi, L., Qin, H., Shi, J., Jia, J.: Path aggregation network for instance segmentation. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. (2018) 8759{8768",
        "ref_ids": [
          "39"
        ]
      },
      "Cascadepsp: Toward class-agnostic and very high-resolution segmentation via global and local refinement": {
        "authors": [
          "Ho Kei",
          "Jihoon Chung",
          "Wing Tai",
          "Keung Tang"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPR_2020/papers/Cheng_CascadePSP_Toward_Class-Agnostic_and_Very_High-Resolution_Segmentation_via_Global_and_CVPR_2020_paper.pdf",
        "ref_texts": "[27] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In CVPR , 2018.",
        "ref_ids": [
          "27"
        ]
      },
      "D2det: Towards high quality object detection and instance segmentation": {
        "authors": [
          "Jiale Cao",
          "Hisham Cholakkal",
          "Rao Muhammad",
          "Fahad Shahbaz",
          "Yanwei Pang",
          "Ling Shao"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPR_2020/papers/Cao_D2Det_Towards_High_Quality_Object_Detection_and_Instance_Segmentation_CVPR_2020_paper.pdf",
        "ref_texts": "[34] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. Proc. IEEE Conf. Computer Vision and Pattern Recognition , 2018.",
        "ref_ids": [
          "34"
        ]
      },
      "Naive-student: Leveraging semi-supervised learning in video sequences for urban scene segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2005.10266",
        "ref_texts": "51. Liu, S., Qi, L., Qin, H., Shi, J., Jia, J.: Path aggregation network for instance segmentation. In: CVPR (2018) 7, 8",
        "ref_ids": [
          "51"
        ]
      },
      "Centripetalnet: Pursuing high-quality keypoint pairs for object detection": {
        "authors": [
          "Zhiwei Dong",
          "Guoxuan Li",
          "Yue Liao",
          "Fei Wang",
          "Pengju Ren",
          "Chen Qian"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPR_2020/papers/Dong_CentripetalNet_Pursuing_High-Quality_Keypoint_Pairs_for_Object_Detection_CVPR_2020_paper.pdf",
        "ref_texts": "[24] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In CVPR , 2018.",
        "ref_ids": [
          "24"
        ]
      },
      "Polytransform: Deep polygon transformer for instance segmentation": {
        "authors": [
          "Justin Liang",
          "Namdar Homayounfar",
          "Chiu Ma",
          "Yuwen Xiong",
          "Rui Hu",
          "Raquel Urtasun"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPR_2020/papers/Liang_PolyTransform_Deep_Polygon_Transformer_for_Instance_Segmentation_CVPR_2020_paper.pdf",
        "ref_texts": "[42] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In CVPR , 2018.",
        "ref_ids": [
          "42"
        ]
      },
      "Retina U-Net: Embarrassingly simple exploitation of segmentation supervision for medical object detection": {
        "authors": [],
        "url": "http://proceedings.mlr.press/v116/jaeger20a/jaeger20a.pdf",
        "ref_texts": "181 Retina U-Net Mark Everingham, Luc Van Gool, Christopher K. I. Williams, John Winn, and Andrew Zisserman. The pascal visual object classes (voc) challenge. IJCV , 88(2):303{338, Jun 2010. ISSN 1573-1405. Ross Girshick. Fast r-cnn. In ICCV , pages 1440{1448, 2015. Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In CVPR , pages 770{778, 2016. Kaiming He, Georgia Gkioxari, Piotr Doll\u0013 ar, and Ross Girshick. Mask r-cnn. In ICCV , pages 2980{2988. IEEE, 2017. Fabian Isensee, Jens Petersen, Andre Klein, David Zimmerer, Paul F Jaeger, Simon Kohl, Jakob Wasserthal, Gregor Koehler, Tobias Norajitra, Sebastian Wirkert, et al. nnu-net: Self-adapting framework for u-net-based medical image segmentation. arXiv preprint arXiv:1809.10486 , 2018. Tsung-Yi Lin, Piotr Doll\u0013 ar, Ross B Girshick, Kaiming He, Bharath Hariharan, and Serge J Belongie. Feature pyramid networks for object detection. In CVPR , volume 1, page 4, 2017. Tsung-Yi Lin, Priyal Goyal, Ross Girshick, Kaiming He, and Piotr Doll\u0013 ar. Focal loss for dense object detection. TPAMI , 2018. Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In CVPR , pages 8759{8768, 2018. Wei Liu, Dragomir Anguelov, Dumitru Erhan, Christian Szegedy, Scott Reed, Cheng-Yang Fu, and Alexander C Berg. Ssd: Single shot multibox detector. In ECCV , pages 21{37. Springer, 2016. Jiayuan Mao, Tete Xiao, Yuning Jiang, and Zhimin Cao. What can help pedestrian detection? In CVPR , pages 6034{6043. IEEE, 2017. Chao Peng, Tete Xiao, Zeming Li, Yuning Jiang, Xiangyu Zhang, Kai Jia, Gang Yu, and Jian Sun. Megdet: A large mini-batch object detector. In CVPR , 2018. Joseph Redmon, Santosh Divvala, Ross Girshick, and Ali Farhadi. You only look once: Uniffed, real-time object detection. In CVPR , pages 779{788, 2016. Olaf Ronneberger, Philipp Fischer, and Thomas Brox. U-net: Convolutional networks for biomedical image segmentation. In MICCAI , pages 234{241. Springer, 2015. Meet P. Shah, S. N. Merchant, and Suyash P. Awate. Ms-net: Mixed-supervision fullyconvolutional networks for full-resolution segmentation. In MICCAI , pages 379{387. Springer, 2018. Abhinav Shrivastava and Abhinav Gupta. Contextual priming and feedback for faster r-cnn. InECCV , pages 330{348. Springer, 2016."
      },
      "Corner proposal network for anchor-free, two-stage object detection": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2007.13816",
        "ref_texts": "26. Liu, S., Qi, L., Qin, H., Shi, J., Jia, J.: Path aggregation network for instance segmentation. In: Proceedings of the IEEE conference on computer vision and pattern recognition. pp. 8759{8768 (2018) 11, 12",
        "ref_ids": [
          "26"
        ]
      },
      "Attention-guided context feature pyramid network for object detection": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2005.11475",
        "ref_texts": "[19] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In IEEE Conference on Computer Vision and Pattern Recognition , pages 8759\u20138768, 2018.",
        "ref_ids": [
          "19"
        ]
      },
      "Mask encoding for single shot instance segmentation": {
        "authors": [
          "Rufeng Zhang",
          "Zhi Tian",
          "Chunhua Shen",
          "Mingyu You",
          "Youliang Yan"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPR_2020/papers/Zhang_Mask_Encoding_for_Single_Shot_Instance_Segmentation_CVPR_2020_paper.pdf",
        "ref_texts": "[22] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In Proc. IEEE Conf. Comp. Vis. Patt. Recogn. , pages 8759\u20138768, 2018. 1,2",
        "ref_ids": [
          "22"
        ]
      },
      "Triple U-net: Hematoxylin-aware nuclei segmentation with progressive dense feature aggregation": {
        "authors": [
          "Bingchao Zhao"
        ],
        "url": "https://chuhan89.com/publication/zhao-2020-nuclei/zhao-2020-nuclei.pdf",
        "ref_texts": "Bejnordi, B.E. , Veta, M. , Van Diest, P.J. , Van Ginneken, B. , Karssemeijer, N. , Litjens, G. , Van Der Laak, J.A. , Hermsen, M. , Manson, Q.F. , Balkenhol, M. , et al. , 2017. Diagnostic assessment of deep learning algorithms for detection of lymph node metastases in women with breast cancer. JAMA 318 (22), 2199\u20132210 . Chan, L. , Hosseini, M.S. , Rowsell, C. , Plataniotis, K.N. , Damaskinos, S. , 2019. HistoSegNet: semantic segmentation of histological tissue type in whole slide images. In: Proceedings of the IEEE International Conference on Computer Vision, pp. 10662\u201310671 . B. Zhao, X. Chen and Z. Li et al. / Medical Image Analysis 65 (2020) 101786 11 Chen, H. , Qi, X. , Yu, L. , Heng, P.-A. , 2016. DCAN: Deep contour-aware networks for accurate gland segmentation. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 24 87\u201324 96 . Chen, L.-C. , Papandreou, G. , Kokkinos, I. , Murphy, K. , Yuille, A.L. , 2017. DeepLab: Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected crfs. IEEE Trans Pattern Anal Mach Intell 40 (4), 834\u2013848 . Chen, L.-C., Papandreou, G., Schroff, F., Adam, H., 2017b. Rethinking atrous convolution for semantic image segmentation. arXiv: 1706.05587 . Chen, L.-C. , Zhu, Y. , Papandreou, G. , Schroff, F. , Adam, H. , 2018. Encoder-decoder with atrous separable convolution for semantic image segmentation. In: Proceedings of the European Conference on Computer Vision (ECCV), pp. 801\u2013818 . Cheng, J. , Rajapakse, J.C. , et al. , 2008. Segmentation of clustered nuclei with shape markers and marking function. IEEE Trans. Biomed. Eng. 56 (3), 741\u2013748 . Chidester, B. , Ton, T.-V. , Tran, M.-T. , Ma, J. , Do, M.N. , 2019. Enhanced rotation-equivariant U-net for nuclear segmentation. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops . 0\u20130 Christ, P.F. , Elshaer, M.E.A. , Ettlinger, F. , Tatavarty, S. , Bickel, M. , Bilic, P. , Rempfler, M. , Armbruster, M. , Hofmann, F. , D\u2019Anastasi, M. , et al. , 2016. Automatic liver and lesion segmentation in CT using cascaded fully convolutional neural networks and 3d conditional random fields. In: International Conference on Medical Image Computing and Computer-Assisted Intervention. Springer, pp. 415\u2013423 . de Geus, D., Meletis, P., Dubbelman, G., 2018. Panoptic segmentation with a joint semantic and instance segmentation network. arXiv: 1809.02110 . Graham, S. , Rajpoot, N.M. , 2018. SAMS-NET: Stain-aware multi-scale network for instance-based nuclei segmentation in histology images. In: 2018 IEEE 15th International Symposium on Biomedical Imaging (ISBI 2018), pp. 590\u2013594 . Graham, S. , Vu, Q.D. , Raza, S.E.A. , Azam, A. , Tsang, Y.W. , Kwak, J.T. , Rajpoot, N. , 2019. HoVer-Net: Simultaneous segmentation and classification of nuclei in multi-tissue histology images. Med. Image Anal. 58, 101563 . Havaei, M. , Davy, A. , Warde-Farley, D. , Biard, A . , Courville, A . , Bengio, Y. , Pal, C. , Jodoin, P.-M. , Larochelle, H. , 2017. Brain tumor segmentation with deep neural networks. Med. Image Anal. 35, 18\u201331 . He, K. , Gkioxari, G. , Doll\u00e1r, P. , Girshick, R. , 2017. Mask R-CNN. In: Proceedings of the IEEE International Conference on Computer Vision, pp. 2961\u20132969 . Huang, G. , Liu, Z. , Van Der Maaten, L. , Weinberger, K.Q. , 2017. Densely connected convolutional networks. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 4700\u20134708 . Kirillov, A., He, K., Girshick, R., Rother, C., Doll\u00e1r, P., 2020. Panoptic segmentation. Koohbanani, N.A. , Jahanifar, M. , Gooya, A. , Rajpoot, N. , 2019. Nuclear instance segmentation using a proposal-free spatially aware deep learning framework. In: International Conference on Medical Image Computing and Computer-Assisted Intervention. Springer, pp. 622\u2013630 . Kumar, N. , Verma, R. , Sharma, S. , Bhargava, S. , Vahadane, A. , Sethi, A. , 2017. A dataset and a technique for generalized nuclear segmentation for computational pathology. IEEE Trans. Med. Imaging 36 (7), 1550\u20131560 . Li, X. , Chen, H. , Qi, X. , Dou, Q. , Fu, C.-W. , Heng, P.-A. , 2018. H-DenseUNet: Hybrid densely connected UNet for liver and tumor segmentation from CT volumes. IEEE Trans. Med. Imaging 37 (12), 2663\u20132674 . Liu, D. , Zhang, D. , Song, Y. , Zhang, C. , Zhang, F. , O\u2019Donnell, L. , Cai, W. , 2019. Nuclei segmentation via a deep panoptic model with semantic feature fusion. In: Proceedings of the 28th International Joint Conference on Artificial Intelligence. AAAI Press, pp. 861\u2013868 . Liu, S. , Qi, L. , Qin, H. , Shi, J. , Jia, J. , 2018. Path aggregation network for instance segmentation. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 8759\u20138768 . Liu, Y., Gadepalli, K., Norouzi, M., Dahl, G. E., Kohlberger, T., Boyko, A., Venugopalan, S., Timofeev, A., Nelson, P. Q., Corrado, G. S., et al., 2017. Detecting cancer metastases on gigapixel pathology images. arXiv: 1703.02442 . Long, J. , Shelhamer, E. , Darrell, T. , 2015. Fully convolutional networks for semantic segmentation. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 3431\u20133440 . Man, Y. , Huang, Y. , Li, J.F.X. , Wu, F. , 2019. Deep Q learning driven CT pancreas segmentation with geometry-aware u-net. IEEE Trans. Med. Imaging 38 (8), "
      },
      "Interactive object segmentation with inside-outside guidance": {
        "authors": [
          "Shiyin Zhang",
          "Jun Hao",
          "Yunchao Wei",
          "Shikui Wei",
          "Yao Zhao"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPR_2020/papers/Zhang_Interactive_Object_Segmentation_With_Inside-Outside_Guidance_CVPR_2020_paper.pdf",
        "ref_texts": "[43] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In CVPR , pages 8759\u20138768, 2018.",
        "ref_ids": [
          "43"
        ]
      },
      "Scale-equalizing pyramid convolution for object detection": {
        "authors": [
          "Xinjiang Wang",
          "Shilong Zhang",
          "Zhuoran Yu",
          "Litong Feng",
          "Wayne Zhang"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPR_2020/papers/Wang_Scale-Equalizing_Pyramid_Convolution_for_Object_Detection_CVPR_2020_paper.pdf",
        "ref_texts": "[23] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 8759\u20138768, 2018.",
        "ref_ids": [
          "23"
        ]
      },
      "Don't hit me! glass detection in real-world scenes": {
        "authors": [
          "Haiyang Mei",
          "Xin Yang",
          "Yang Wang",
          "Yuanyuan Liu",
          "Shengfeng He",
          "Qiang Zhang",
          "Xiaopeng Wei",
          "Rynson W"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPR_2020/papers/Mei_Dont_Hit_Me_Glass_Detection_in_Real-World_Scenes_CVPR_2020_paper.pdf",
        "ref_texts": "[19] Nian Liu, Junwei Han, and Ming-Hsuan Yang. Picanet: Learning pixel-wise contextual attention for saliency detection. In CVPR , 2018.[20] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In CVPR , 2018.",
        "ref_ids": [
          "19",
          "20"
        ]
      },
      "Side-aware boundary localization for more precise object detection": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1912.04260",
        "ref_texts": "27.Liu, S., Qi, L., Qin, H., Shi, J., Jia, J.: Path aggregation network for instance segmentation. In: CVPR (2018)",
        "ref_ids": [
          "27"
        ]
      },
      "Hit-detector: Hierarchical trinity architecture search for object detection": {
        "authors": [
          "Jianyuan Guo",
          "Kai Han",
          "Yunhe Wang",
          "Chao Zhang",
          "Zhaohui Yang",
          "Han Wu",
          "Xinghao Chen",
          "Chang Xu"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPR_2020/papers/Guo_Hit-Detector_Hierarchical_Trinity_Architecture_Search_for_Object_Detection_CVPR_2020_paper.pdf",
        "ref_texts": "[32] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In CVPR , 2018.",
        "ref_ids": [
          "32"
        ]
      },
      "Centermask: single shot instance segmentation with point representation": {
        "authors": [
          "Yuqing Wang",
          "Zhaoliang Xu",
          "Hao Shen",
          "Baoshan Cheng",
          "Lirong Yang"
        ],
        "url": "https://openaccess.thecvf.com/content_CVPR_2020/papers/Wang_CenterMask_Single_Shot_Instance_Segmentation_With_Point_Representation_CVPR_2020_paper.pdf",
        "ref_texts": "[21] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In CVPR , pages 8759\u20138768, 2018.",
        "ref_ids": [
          "21"
        ]
      },
      "Learning to segment the tail": {
        "authors": [
          "Xinting Hu",
          "Yi Jiang",
          "Kaihua Tang",
          "Jingyuan Chen",
          "Chunyan Miao",
          "Hanwang Zhang"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPR_2020/papers/Hu_Learning_to_Segment_the_Tail_CVPR_2020_paper.pdf",
        "ref_texts": "[25] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path Aggregation Network for Instance Segmentation. In CVPR , 2018. 2",
        "ref_ids": [
          "25"
        ]
      },
      "Real-time face mask and social distancing violation detection system using yolo": {
        "authors": [],
        "url": "https://scholar.archive.org/work/xgoqxnupqzbfdhlwwb5lytkjia/access/wayback/https://ieeexplore.ieee.org/ielx7/9297828/9297848/09297902.pdf",
        "ref_texts": "[20] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia, \u201dPath aggregation network for instance segmentation\u201d, IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2018, pages 8759\u20138768.",
        "ref_ids": [
          "20"
        ]
      },
      "Weakly supervised instance segmentation by learning annotation consistent instances": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2007.09397",
        "ref_texts": "26. Liu, S., Qi, L., Qin, H., Shi, J., Jia, J.: Path aggregation network for instance segmentation. In: CVPR (2018)",
        "ref_ids": [
          "26"
        ]
      },
      "Forest r-cnn: Large-vocabulary long-tailed object detection and instance segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2008.05676",
        "ref_texts": "[26] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. 2018. Path aggregation network for instance segmentation. In Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR) . 8759\u20138768.",
        "ref_ids": [
          "26"
        ]
      },
      "Video instance segmentation tracking with a modified vae architecture": {
        "authors": [
          "Ching Lin",
          "Ying Hung",
          "Rogerio Feris",
          "Linglin He"
        ],
        "url": "https://openaccess.thecvf.com/content_CVPR_2020/papers/Lin_Video_Instance_Segmentation_Tracking_With_a_Modified_VAE_Architecture_CVPR_2020_paper.pdf",
        "ref_texts": "[45] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 8759\u20138768, 2018. 2",
        "ref_ids": [
          "45"
        ]
      },
      "Instance shadow detection": {
        "authors": [
          "Tianyu Wang",
          "Xiaowei Hu",
          "Qiong Wang",
          "Ann Heng",
          "Wing Fu"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPR_2020/papers/Wang_Instance_Shadow_Detection_CVPR_2020_paper.pdf",
        "ref_texts": "[31] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In CVPR , pages 8759\u20138768, 2018. 3",
        "ref_ids": [
          "31"
        ]
      },
      "Fgn: Fully guided network for few-shot instance segmentation": {
        "authors": [
          "Zhibo Fan",
          "Gang Yu",
          "Zhihao Liang",
          "Jiarong Ou",
          "Changxin Gao",
          "Song Xia",
          "Yuanqing Li"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPR_2020/papers/Fan_FGN_Fully_Guided_Network_for_Few-Shot_Instance_Segmentation_CVPR_2020_paper.pdf",
        "ref_texts": "[19] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In IEEE Conference on Computer Vision and Pattern Recognition , pages 8759\u20138768, 2018. 4321 ,4322",
        "ref_ids": [
          "19"
        ]
      },
      "Banet: Bidirectional aggregation network with occlusion handling for panoptic segmentation": {
        "authors": [
          "Yifeng Chen",
          "Guangchen Lin",
          "Songyuan Li",
          "Omar Bourahla",
          "Yiming Wu",
          "Fangfang Wang",
          "Junyi Feng",
          "Mingliang Xu",
          "Xi Li"
        ],
        "url": "https://openaccess.thecvf.com/content_CVPR_2020/papers/Chen_BANet_Bidirectional_Aggregation_Network_With_Occlusion_Handling_for_Panoptic_Segmentation_CVPR_2020_paper.pdf",
        "ref_texts": "[30] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia. Path aggregation network for instance segmentation. In CVPR , pages 8759\u2013",
        "ref_ids": [
          "30"
        ]
      },
      "Real-time panoptic segmentation from dense detections": {
        "authors": [
          "Rui Hou",
          "Jie Li",
          "Arjun Bhargava",
          "Allan Raventos",
          "Vitor Guizilini",
          "Chao Fang",
          "Jerome Lynch",
          "Adrien Gaidon"
        ],
        "url": "https://openaccess.thecvf.com/content_CVPR_2020/papers/Hou_Real-Time_Panoptic_Segmentation_From_Dense_Detections_CVPR_2020_paper.pdf",
        "ref_texts": "[22] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 8759\u20138768, 2018.",
        "ref_ids": [
          "22"
        ]
      },
      "Adaptive period embedding for representing oriented objects in aerial images": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1906.09447",
        "ref_texts": "[13] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia, \u201cPath aggregation network for instance segmentation,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , 2018, pp. 8759\u20138768.",
        "ref_ids": [
          "13"
        ]
      },
      "Scaling wide residual networks for panoptic segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2011.11675",
        "ref_texts": "[59] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In CVPR , 2018. 8",
        "ref_ids": [
          "59"
        ]
      },
      "Houghnet: Integrating near and long-range evidence for bottom-up object detection": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2007.02355",
        "ref_texts": "29. Liu, S., Qi, L., Qin, H., Shi, J., Jia, J.: Path aggregation network for instance segmentation. In: IEEE Conference on Computer Vision and Pattern Recognition. pp. 8759{8768 (2018)",
        "ref_ids": [
          "29"
        ]
      },
      "Phraseclick: toward achieving flexible interactive segmentation by phrase and click": {
        "authors": [],
        "url": "https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123480426.pdf",
        "ref_texts": "37. Liu, S., Qi, L., Qin, H., Shi, J., Jia, J.: Path aggregation network for instance segmentation. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. pp. 8759{8768 (2018)",
        "ref_ids": [
          "37"
        ]
      },
      "SP-NAS: Serial-to-parallel backbone search for object detection": {
        "authors": [
          "Chenhan Jiang",
          "Hang Xu",
          "Wei Zhang",
          "Xiaodan Liang",
          "Zhenguo Li"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPR_2020/papers/Jiang_SP-NAS_Serial-to-Parallel_Backbone_Search_for_Object_Detection_CVPR_2020_paper.pdf",
        "ref_texts": "[26] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In CVPR , 2018. 3.2",
        "ref_ids": [
          "26"
        ]
      },
      "IPG-net: Image pyramid guidance network for small object detection": {
        "authors": [
          "Ziming Liu",
          "Guangyu Gao",
          "Lin Sun",
          "Li Fang"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPRW_2020/papers/w69/Liu_IPG-Net_Image_Pyramid_Guidance_Network_for_Small_Object_Detection_CVPRW_2020_paper.pdf",
        "ref_texts": "[18] Songtao Liu, Di Huang, and Yunhong Wang. Receptive field block net for accurate and fast object detection. Lecture Notes in Computer Science , page 404\u2013419, 2018.[19] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. CVPR , Jun 2018.",
        "ref_ids": [
          "18",
          "19"
        ]
      },
      "A computer-aided diagnosis of brain tumors using a fine-tuned YOLO-based model with transfer learning": {
        "authors": [],
        "url": "https://koreascience.kr/article/JAKO202009135419641.pdf",
        "ref_texts": "[44] S. Liu, L. Qi, H. Qin, J. Shi , and J. Jia, \u201cPath Aggregation Network for Instance Segmentation,\u201d in Proc. of 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition , pp. 8759 -8768 , ",
        "ref_ids": [
          "44"
        ]
      },
      "SPRNet: single-pixel reconstruction for one-stage instance segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1904.07426",
        "ref_texts": "[7] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia, \u201cPath aggregation network for instance segmentation,\u201d in IEEE Conference on Computer Vision and Pattern Recognition , 2018, pp. 8759\u20138768.",
        "ref_ids": [
          "7"
        ]
      },
      "Approximating shapes in images with low-complexity polygons": {
        "authors": [
          "Muxingzi Li",
          "Florent Lafarge",
          "Renaud Marlet"
        ],
        "url": "https://openaccess.thecvf.com/content_CVPR_2020/papers/Li_Approximating_shapes_in_images_with_low-complexity_polygons_CVPR_2020_paper.pdf",
        "ref_texts": "[28] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia. Path aggregation network for instance segmentation. In CVPR , 2018. 7",
        "ref_ids": [
          "28"
        ]
      },
      "Learning gaussian instance segmentation in point clouds": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2007.09860",
        "ref_texts": "26.Liu, S., Qi, L., Qin, H., Shi, J., Jia, J.: Path aggregation network for instance segmentation. In: 2018 IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2018, Salt Lake City, UT, USA, June 18-22, 2018. pp. 8759{8768 (2018)",
        "ref_ids": [
          "26"
        ]
      },
      "Exploring data augmentation for multi-modality 3d object detection": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2012.12741",
        "ref_texts": "[28] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In CVPR , 2018. 9",
        "ref_ids": [
          "28"
        ]
      },
      "3-D RoI-aware U-net for accurate and efficient colorectal tumor segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1806.10342",
        "ref_texts": "[39] Liu Shu, Qi Lu, Haifang Qin, Jianping Shi, and Jiaya Jia, \\Path aggregation network for instance segmentation,\" 2018.",
        "ref_ids": [
          "39"
        ]
      },
      "Noh-nms: Improving pedestrian detection by nearby objects hallucination": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2007.13376",
        "ref_texts": "[19] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. 2018. Path Aggregation Network for Instance Segmentation. In Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR) .",
        "ref_ids": [
          "19"
        ]
      },
      "Feature pyramid grids": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2004.03580",
        "ref_texts": "24.Liu, S., Qi, L., Qin, H., Shi, J., Jia, J.: Path aggregation network for instance segmentation. In: Proc. CVPR (2018) 3, 8, 15, 16",
        "ref_ids": [
          "24"
        ]
      },
      "Fine-grained dynamic head for object detection": {
        "authors": [],
        "url": "https://proceedings.neurips.cc/paper/2020/file/7f6caf1f0ba788cd7953d817724c2b6e-Paper.pdf",
        "ref_texts": "[7]Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In IEEE Conference on Computer Vision and Pattern Recognition , 2018.",
        "ref_ids": [
          "7"
        ]
      },
      "Dynamic motion representation for human action recognition": {
        "authors": [
          "Sadjad Asghari",
          "Mario Sznaier",
          "Octavia Camps"
        ],
        "url": "http://openaccess.thecvf.com/content_WACV_2020/papers/Asghari-Esfeden_Dynamic_Motion_Representation_for_Human_Action_Recognition_WACV_2020_paper.pdf",
        "ref_texts": "[36] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia. Path aggregation network for instance segmentation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 8759\u20138768, 2018.",
        "ref_ids": [
          "36"
        ]
      },
      "Robust 6d object pose estimation by learning rgb-d features": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2003.00188",
        "ref_texts": "[31] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia, \u201cPath aggregation network for instance segmentation,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , 2018, pp. 8759\u20138768.",
        "ref_ids": [
          "31"
        ]
      },
      "3D instance embedding learning with a structure-aware loss function for point cloud segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1902.05247",
        "ref_texts": "[Wang et al. , 2018a ]Weiyue Wang, Ronald Yu, Qiangui Huang, and Ulrich Neumann. Sgpn: Similarity group proposal network for 3d point cloud instance segmentation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 2569\u20132578, 2018.",
        "ref_ids": [
          "Wang et al\\. , 2018a "
        ]
      },
      "Implicit feature pyramid network for object detection": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2012.13563",
        "ref_texts": "[30] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In CVPR , 2018. 1, 2",
        "ref_ids": [
          "30"
        ]
      },
      "A novel and efficient tumor detection framework for pancreatic cancer via CT images": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2002.04493",
        "ref_texts": "[13] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia, \u201cPath aggregation network for instance segmentation,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , 2018, pp. 8759\u20138768.",
        "ref_ids": [
          "13"
        ]
      },
      "NETNet: Neighbor erasing and transferring network for better single shot object detection": {
        "authors": [
          "Yazhao Li",
          "Yanwei Pang",
          "Jianbing Shen",
          "Jiale Cao",
          "Ling Shao"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPR_2020/papers/Li_NETNet_Neighbor_Erasing_and_Transferring_Network_for_Better_Single_Shot_CVPR_2020_paper.pdf",
        "ref_texts": "[34] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In CVPR , 2018. 4",
        "ref_ids": [
          "34"
        ]
      },
      "Dynamic scale training for object detection": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2004.12432",
        "ref_texts": "[21] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In CVPR , pages 8759\u20138768, 2018. 1, 2",
        "ref_ids": [
          "21"
        ]
      },
      "Multi-layer representation fusion for neural machine translation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2002.06714",
        "ref_texts": "2017. A structured self-attentive sentence embedding. Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. 2018 . Path aggregation network for instance segmentation. arXiv preprint arXiv:1803.01534. Thang Luong, Ilya Sutskever, Quoc Le, Oriol Vinyals, and Woj ciech Zaremba. 2015. Addressing the rare word problem in neural machine translation. In Proceedings ofthe53rd Annual Meeting oftheAssociation for Computational Linguistics andthe7thInternational Joint Conference onNatural Language Processing (V olume 1:Long Papers), pages 11\u201319. Association for Computational Lingu istics. Minh-Thang Luong, Eugene Brevdo, and Rui Zhao. 2017. Neural machine translation (seq2seq) tutorial. https://github.com/tensorflow/nmt. Marc\u2019Aurelio Ranzato, Sumit Chopra, Michael Auli, and Wojc iech Zaremba. 2015. Sequence level training with recurrent neural networks. arXiv preprint arXiv:1511.06732. Rico Sennrich, Barry Haddow, and Alexandra Birch. 2016. Neu ral machine translation of rare words with subword units. In Proceedings ofthe54th Annual Meeting oftheAssociation forComputational Linguistics, ACL 2016, August 7-12, 2016, Berlin, Germany, V olume 1:Long Papers. Rico Sennrich, Orhan Firat, Kyunghyun Cho, Alexandra Birch , Barry Haddow, Julian Hitschler, Marcin JunczysDowmunt, Samuel L\u00a8 aubli, Antonio Valerio Miceli Barone, Jo zef Mokry, and Maria Nadejde. 2017. Nematus: a toolkit for neural machine translation. In Proceedings oftheSoftware Demonstrations ofthe15th Conference oftheEuropean Chapter oftheAssociation forComputational Linguistics, pages 65\u201368, Valencia, Spain, April. Association for Computational Linguistics. Tao Shen, Tianyi Zhou, Guodong Long, Jing Jiang, Shirui Pan, and Chengqi Zhang. 2018. Disan: Directional self-attention network for rnn/cnn-free language underst anding. In AAAI Conference onArtificial Intelligence. Rupesh K Srivastava, Klaus Greff, and J\u00a8 urgen Schmidhuber. 2015. Training very deep networks. In C. Cortes, N. D. Lawrence, D. D. Lee, M. Sugiyama, and R. Garnett, editor s,Advances inNeural Information Processing Systems 28, pages 2377\u20132385. Curran Associates, Inc. Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit , Llion Jones, Aidan N Gomez, \u0141ukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. In Advances inNeural Information Processing Systems, pages 6000\u20136010. Mingxuan Wang, Zhengdong Lu, Jie Zhou, and Qun Liu. 2017. Dee p neural machine translation with linear associative unit. In Proceedings ofthe55th Annual Meeting oftheAssociation forComputational Linguistics, ACL 2017, Vancouver, Canada, July 30-August 4,V olume 1:Long Papers, pages 136\u2013145. Sam Wiseman and Alexander M. Rush. 2016. Sequence-to-seque nce learning as beam-search optimization. In Proceedings ofthe2016 Conference onEmpirical Methods inNatural Language Processing, EMNLP 2016, Austin, Texas, USA, November 1-4,2016, pages 1296\u20131306. Yonghui Wu, Mike Schuster, Zhifeng Chen, Quoc V Le, Mohammad Norouzi, Wolfgang Macherey, Maxim Krikun, Yuan Cao, Qin Gao, Klaus Macherey, et al. 2016. Googl e\u2019s neural machine translation system: Bridging the gap between human and machine translation. arXiv preprint arXiv:1609.08144. Tong Xiao, Jingbo Zhu, Hao Zhang, and Qiang Li. 2012. Niutran s: an open source toolkit for phrase-based and syntax-based machine translation. In Proceedings oftheACL 2012 System Demonstrations, pages 19\u201324. Association for Computational Linguistics. Hao Xiong, Zhongjun He, Xiaoguang Hu, and Hua Wu. 2017. Multi -channel encoder for neural machine translation. arXiv preprint arXiv:1712.02109. Jie Zhou, Ying Cao, Xuguang Wang, Peng Li, and Wei Xu. 2016. De ep recurrent models with fast-forward connections for neural machine translation. Transactions oftheAssociation ofComputational Linguistics, 4:371\u2013383.",
        "ref_ids": [
          "2017"
        ]
      },
      "Learning saliency propagation for semi-supervised instance segmentation": {
        "authors": [
          "Yanzhao Zhou",
          "Xin Wang",
          "Jianbin Jiao",
          "Trevor Darrell",
          "Fisher Yu"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPR_2020/papers/Zhou_Learning_Saliency_Propagation_for_Semi-Supervised_Instance_Segmentation_CVPR_2020_paper.pdf",
        "ref_texts": "[25] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , pages 8759\u20138768, 2018. 1,2",
        "ref_ids": [
          "25"
        ]
      },
      "Levelset r-cnn: A deep variational method for instance segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2007.15629.pdf?utm_source=",
        "ref_texts": "47. Liu, S., Qi, L., Qin, H., Shi, J., Jia, J.: Path aggregation network for instance segmentation. In: CVPR (2018)",
        "ref_ids": [
          "47"
        ]
      },
      "Learning to manipulate individual objects in an image": {
        "authors": [
          "Yanchao Yang",
          "Yutong Chen",
          "Stefano Soatto"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPR_2020/papers/Yang_Learning_to_Manipulate_Individual_Objects_in_an_Image_CVPR_2020_paper.pdf",
        "ref_texts": "[27] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 8759\u20138768, 2018. 2",
        "ref_ids": [
          "27"
        ]
      },
      "Commonality-parsing network across shape and appearance for partially supervised instance segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2007.12387",
        "ref_texts": "36. Liu, S., Qi, L., Qin, H., Shi, J., Jia, J.: Path aggregation network for instance segmentation. In: CVPR (2018)",
        "ref_ids": [
          "36"
        ]
      },
      "Deep learning methods for human behavior recognition": {
        "authors": [
          "Lu Jia"
        ],
        "url": "https://openrepository.aut.ac.nz/bitstream/handle/10292/14058/JiaL2.pdf?sequence=5&isAllowed=y",
        "ref_texts": " Vision (pp. 816 -833) Liu, J., Wang, G., Hu, P., Duan, L. Y ., & Kot, A. C. (2017). Global context -aware attention LSTM networks for 3 D action recognition. In IEEE Conference on Computer Vision and Pattern Recognition (pp. 1647 -1656) Liu, Q., Zhou, F., Hang, R., & Yuan, X. (2017). Bidirectional -convolutional LSTM based spectral -spatial feature learning for hyperspectral image classification. Remote Sensing , 9(12), 1330 Liu, S., Qi, L., Qin, H., Shi, J., & Jia, J. (2018). Path aggregation network for instance segmentation. In IEEE Conference on Computer Vision and Pattern Recognition (pp. 8759 -8768) Liu, W., Anguelov, D., Erhan, D., Szegedy, C., Reed, S., Fu, C. -Y ., & Berg, A. C. (2016). SSD: Single shot multibox detector. In European Conference on Computer Vision , "
      },
      "Spatialflow: Bridging all tasks for panoptic segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1910.08787",
        "ref_texts": "[58] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia, \u201cPath aggregation network for instance segmentation,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , 2018, pp. 8759\u20138768.",
        "ref_ids": [
          "58"
        ]
      },
      "Dual refinement feature pyramid networks for object detection": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2012.01733",
        "ref_texts": "[30] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia. Path aggregation network for instance segmentation. In CVPR , 2018. 1, 2, 3, 8",
        "ref_ids": [
          "30"
        ]
      },
      "Asfd: Automatic and scalable face detector": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2003.11228",
        "ref_texts": "21. Liu, S., Qi, L., Qin, H., Shi, J., Jia, J.: Path aggregation network for instance segmentation. In: CVPR. pp. 8759{8768 (2018)",
        "ref_ids": [
          "21"
        ]
      },
      "Regularized building segmentation by frame field learning": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2004.14875",
        "ref_texts": "[24] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2018. 7, 20",
        "ref_ids": [
          "24"
        ]
      },
      "Bidirectional pyramid networks for semantic segmentation": {
        "authors": [
          "Dong Nie",
          "Jia Xue",
          "Xiaofeng Ren"
        ],
        "url": "https://openaccess.thecvf.com/content/ACCV2020/papers/Nie_Bidirectional_Pyramid_Networks_for_Semantic_Segmentation_ACCV_2020_paper.pdf",
        "ref_texts": "12. Liu, S., Qi, L., Qin, H., Shi, J., Jia, J.: Path aggregation network for instance segmentation. In: Proceedings of the IEEE Conference on Comput er Vision and Pattern Recognition. (2018) 8759\u20138768",
        "ref_ids": [
          "12"
        ]
      },
      "Bshapenet: Object detection and instance segmentation with bounding shape masks": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1810.10327",
        "ref_texts": "[21] S. Liu, J. Jia, S. Fidler, and R. Urtasun. Sgn: Sequential grouping networks for instance segmentation. In The IEEE International Conference on Computer Vision (ICCV) , 2017.",
        "ref_ids": [
          "21"
        ]
      },
      "Generating positive bounding boxes for balanced training of object detectors": {
        "authors": [
          "Kemal Oksuz",
          "Baris Can",
          "Emre Akbas",
          "Sinan Kalkan"
        ],
        "url": "https://openaccess.thecvf.com/content_WACV_2020/papers/Oksuz_Generating_Positive_Bounding_Boxes_for_Balanced_Training_of_Object_Detectors_WACV_2020_paper.pdf",
        "ref_texts": "[22] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia. Path aggregation network for instance segmentation. In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2018.",
        "ref_ids": [
          "22"
        ]
      },
      "Localize to classify and classify to localize: Mutual guidance in object detection": {
        "authors": [
          "Heng Zhang",
          "Elisa Fromont",
          "Sebastien Lefevre",
          "Bruno Avignon"
        ],
        "url": "http://openaccess.thecvf.com/content/ACCV2020/papers/Zhang_Localize_to_Classify_and_Classify_to_Localize_Mutual_Guidance_in_ACCV_2020_paper.pdf",
        "ref_texts": "4. Liu, S., Qi, L., Qin, H., Shi, J., Jia, J.: Path aggregation n etwork for instance segmentation. In: 2018 IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2018, Salt Lake City, UT, USA, June 18-22, 2018, IEEE Computer Society (2018) 8759\u20138768",
        "ref_ids": [
          "4"
        ]
      },
      "Efficient golf ball detection and tracking based on convolutional neural networks and kalman filter": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2012.09393",
        "ref_texts": "[17] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia, \u201cPath aggregation network for instance segmentation,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition , 2018, pp. 8759\u20138768.",
        "ref_ids": [
          "17"
        ]
      },
      "EPSNet: efficient panoptic segmentation network with cross-layer attention fusion": {
        "authors": [
          "Yuan Chang",
          "En Chang",
          "Yung Hsiao",
          "Chen Fu"
        ],
        "url": "https://openaccess.thecvf.com/content/ACCV2020/papers/Chang_EPSNet_Efficient_Panoptic_Segmentation_Network_with_Cross-layer_Attention_Fusion_ACCV_2020_paper.pdf",
        "ref_texts": "7. Liu, S., Qi, L., Qin, H., Shi, J., Jia, J.: Path aggregation n etwork for instance segmentation. The IEEE Conference on Computer Vision and Patt ern Recognition (CVPR) (2018) 8759\u20138768",
        "ref_ids": [
          "7"
        ]
      },
      "Recognition of cooking activities through air quality sensor data for supporting food journaling": {
        "authors": [
          "Federica Gerina"
        ],
        "url": "https://link.springer.com/content/pdf/10.1186/s13673-020-00235-9.pdf",
        "ref_texts": ""
      },
      "Deep learning for automatic target recognition with real and synthetic infrared maritime imagery": {
        "authors": [],
        "url": "https://dspace.lib.cranfield.ac.uk/bitstream/handle/1826/16654/Deep_learning_%20automatic_target_recognition_with_real_and_synthetic_infrared-2020.pdf?sequence=1&isAllowed=y",
        "ref_texts": "[10] Liu, S., Qi, L., Qin, H., Shi, J., and Jia, J., \\Path aggregation network for instance segmentation,\" in [Proceedings of the IEEE conference on computer vision and pattern recognition ], 8759{8768 (2018).",
        "ref_ids": [
          "10",
          "Proceedings of the IEEE conference on computer vision and pattern recognition "
        ]
      },
      "Learning hierarchical graph for occluded pedestrian detection": {
        "authors": [
          "Gang Li",
          "Jian Li",
          "Shanshan Zhang",
          "Jian Yang"
        ],
        "url": "https://dl.acm.org/doi/pdf/10.1145/3394171.3413983",
        "ref_texts": "[13] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. 2018. Path aggregation network for instance segmentation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 8759\u20138768.",
        "ref_ids": [
          "13"
        ]
      },
      "Traffic surveillance using vehicle license plate detection and recognition in bangladesh": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2012.02218",
        "ref_texts": "[17] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia, \u201cPath aggregation network for instance segmentation,\u201d in 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition , 2018, pp. 8759\u20138768.",
        "ref_ids": [
          "17"
        ]
      },
      "Learning affordance segmentation: An investigative study": {
        "authors": [],
        "url": "https://www.conferences.com.au/wp-content/uploads/2020/09/59_CameraReady-1.pdf",
        "ref_texts": "[19] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia, \u201cPath aggregation network for instance segmentation,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , 2018, pp. 8759\u20138768.",
        "ref_ids": [
          "19"
        ]
      },
      "Deep variational instance segmentation": {
        "authors": [],
        "url": "https://proceedings.neurips.cc/paper_files/paper/2020/file/3341f6f048384ec73a7ba2e77d2db48b-Paper.pdf",
        "ref_texts": "[28] Liu, S., Qi, L., Qin, H., Shi, J., Jia, J.: Path aggregation network for instance segmentation. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. pp.",
        "ref_ids": [
          "28"
        ]
      },
      "Instance segmentation model created from three semantic segmentations of mask, boundary and centroid pixels verified on GlaS dataset": {
        "authors": [],
        "url": "https://annals-csis.org/Volume_21/drp/pdf/175.pdf",
        "ref_texts": "[12] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia, \u201cPath aggregation network for instance segmentation,\u201d in 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition , Salt Lake City, UT, June 2018, pp.",
        "ref_ids": [
          "12"
        ]
      },
      "PanoNet: Real-time panoptic segmentation through position-sensitive feature embedding": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2008.00192",
        "ref_texts": "[45] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia, \u201cPath aggregation network for instance segmentation,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , 2018, pp. 8759\u20138768.",
        "ref_ids": [
          "45"
        ]
      },
      "A study on deep learning optimization by land cover classification item using satellite imagery": {
        "authors": [],
        "url": "https://koreascience.kr/article/JAKO202002654792812.pdf",
        "ref_texts": "\u2013 1602 \u201309\uc774\uc131\ud601(1591~1604)(\ubcc4\uc1c410\ubd80)ok.qxp_\uc6d0\uaca936-6-2_2020 2020. 12. 30. \uc624\uc804 9:23 \ud398\uc774\uc9c0 1602 aggregation network for instance segmentation, Proc. of the 2018 IEEE conference on computer vision and pattern recognition , Salt Lake City, UT, Jun. 19-21, pp. 8759-8768. Long, J., E. Shelhamer, and T. Darrell, 2015. Fully convolutional networks for semantic segmentation, Proc. of the 2015 IEEE conference on computer vision and pattern recognition , Boston, MA, Jun. 7-12, pp. 3431-3440. Ma, L., M. Li, X. Ma, L. Cheng, P. Du, and Y. Liu, "
      },
      "FANet: Feature aggregation network for semantic segmentation": {
        "authors": [],
        "url": "https://espace.curtin.edu.au/bitstream/handle/20.500.11937/93644/Singha%20T%202023%20Public.pdf?sequence=1&isAllowed=y#page=153",
        "ref_texts": "[7] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia, \u201cPath aggregation network for instance segmentation,\u201d in Proc. CVPR, 2018, pp. 8759\u20138768.",
        "ref_ids": [
          "7"
        ]
      },
      "A method for wheat head detection based on yolov4": {
        "authors": [],
        "url": "https://pdfs.semanticscholar.org/f2a1/661d90e7995f8f751602c4984e26097a6a99.pdf",
        "ref_texts": "22. Liu S, Qi L, Qin H, Shi J, Jia J. Path Aggregation Network for Instance Segmentation. Proc IEEE Comput Soc Conf Comput Vis Pattern Recognit. 2018;8759\u2013",
        "ref_ids": [
          "22"
        ]
      },
      "1st Place Solutions of Waymo Open Dataset Challenge 2020--2D Object Detection Track": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2008.01365",
        "ref_texts": "[16] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In CVPR , 2018.",
        "ref_ids": [
          "16"
        ]
      },
      "Automatic detection of cardiac chambers using an attention-based YOLOv4 framework from four-chamber view of fetal echocardiography": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2011.13096",
        "ref_texts": "[34] S.Liu, L.Qi, H.Qin, and et al. Path aggregation network for instance segmentation. IEEE Conference on Computer Vision and Pattern Recognition , pages 8759\u20138768, 2018.",
        "ref_ids": [
          "34"
        ]
      },
      "Deep instance segmentation of laboratory animals in thermal images": {
        "authors": [],
        "url": "https://www.mdpi.com/2076-3417/10/17/5979/pdf",
        "ref_texts": "27. Liu, S.; Qi, L.; Qin, H.; Shi, J.; Jia, J. Path Aggregation Network for Instance Segmentation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Salt Lake City, UT, USA, 18\u201323 June 2018; pp. 8759\u20138768.",
        "ref_ids": [
          "27"
        ]
      },
      "Reducing label noise in anchor-free object detection": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2008.01167",
        "ref_texts": "[15] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In IEEE Conference on Computer Vision and Pattern Recognition , pages 8759\u2013",
        "ref_ids": [
          "15"
        ]
      },
      "Rpm-net: Robust pixel-level matching networks for self-supervised video object segmentation": {
        "authors": [
          "Youngeun Kim",
          "Seokeon Choi",
          "Hankyeol Lee",
          "Taekyung Kim",
          "Changick Kim"
        ],
        "url": "http://openaccess.thecvf.com/content_WACV_2020/papers/Kim_RPM-Net_Robust_Pixel-Level_Matching_Networks_for_Self-Supervised_Video_Object_Segmentation_WACV_2020_paper.pdf",
        "ref_texts": "[23] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia. Path aggregation network for instance segmentation. In CVPR . 2018.",
        "ref_ids": [
          "23"
        ]
      },
      "Geometry-aware instance segmentation with disparity maps": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2006.07802",
        "ref_texts": ""
      },
      "Deep affinity net: Instance segmentation via affinity": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2003.06849",
        "ref_texts": "36. Liu, S., Qi, L., Qin, H., Shi, J., Jia, J.: Path aggregation network for instance segmentation. In: IEEE Conference on Computer Vision and Pattern Recognition (2018)",
        "ref_ids": [
          "36"
        ]
      },
      "Multiple instance segmentation in brachial plexus ultrasound image using BPMSegNet": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2012.12012",
        "ref_texts": "[27] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia, \u201cPath aggregation network for instance segmentation,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , 2018, pp. 8759\u20138768.",
        "ref_ids": [
          "27"
        ]
      },
      "MixModule: Mixed CNN kernel module for medical image segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1910.08728",
        "ref_texts": "[16] Shaoqing Ren, Kaiming He, Ross Girshick, and Jian Sun, \u201cFaster r-cnn: Towards real-time object detection with region proposal networks,\u201d in Advances in neural information processing systems , 2015, pp. 91\u201399.[17] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia, \u201cPath aggregation network for instance segmentation,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , 2018, pp. 8759\u2013",
        "ref_ids": [
          "16",
          "17"
        ]
      },
      "M2-Net: A Multi-scale Multi-level Feature Enhanced Network for Object Detection in Optical Remote Sensing Images": {
        "authors": [],
        "url": "https://conferences.com.au/wp-content/uploads/2020/09/29_CameraReady-1.pdf",
        "ref_texts": "[38] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia, \u201cPath aggregatio n network for instance segmentation,\u201d in Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR) , 2018.",
        "ref_ids": [
          "38"
        ]
      },
      "Semantic synthesis of pedestrian locomotion": {
        "authors": [
          "Maria Priisalu",
          "Ciprian Paduraru",
          "Aleksis Pirinen",
          "Cristian Sminchisescu"
        ],
        "url": "https://openaccess.thecvf.com/content/ACCV2020/papers/Priisalu_Semantic_Synthesis_of_Pedestrian_Locomotion_ACCV_2020_paper.pdf",
        "ref_texts": "62.Liu, S., Qi, L., Qin, H., Shi, J., Jia, J.: Path aggregation net work for instance segmentation. In: CVPR. (2018)",
        "ref_ids": [
          "62"
        ]
      },
      "Permo: Perceiving more at once from a single image for autonomous driving": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2007.08116",
        "ref_texts": "[39] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia, \u201cPath aggregation network for instance segmentation,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , 2018, pp. 8759\u20138768.",
        "ref_ids": [
          "39"
        ]
      },
      "Instance-level microtubule tracking": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1901.06006",
        "ref_texts": "[30] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia, \u201cPath Aggregation Network for Instance Segmentation,\u201d in Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition , 2018.[31] R. Hu, P. Dollar, K. He, T. Darrell, and R. Girshick, \u201cLearning to Segment Every Thing,\u201d in Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition , 2018.",
        "ref_ids": [
          "30",
          "31"
        ]
      },
      "Monitoring COVID-19 prevention measures on CCTV cameras using deep learning": {
        "authors": [],
        "url": "https://webthesis.biblio.polito.it/secure/15970/1/tesi.pdf",
        "ref_texts": "[18]Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path Aggregation Network for Instance Segmentation . 2018. arXiv: 1803.",
        "ref_ids": [
          "18"
        ]
      },
      "Towards better object detection in scale variation with adaptive feature selection": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2012.03265",
        "ref_texts": "[29] S. Liu, L. Qi, H. Qin, J. Shi, J. Jia, Path aggregation network for instance segmentation, in: Proceedings of the IEEE conference on computer vision and pattern recognition, 2018, pp. 8759{8768.",
        "ref_ids": [
          "29"
        ]
      },
      "The One-Stage Detector Algorithm Based on Background Prediction and Group Normalization for Vehicle Detection": {
        "authors": [],
        "url": "https://www.mdpi.com/2076-3417/10/17/5883/pdf",
        "ref_texts": "19. Liu, S.; Qi, L.; Qin, H.; Shi, J.; Jia, J. Path Aggregation Network for Instance Segmentation. In Proceedings of the 2018 IEEE /CVF Conference on Computer Vision and Pattern Recognition, Salt Lake City, UT, USA, 18\u201322 June 2018; pp. 8759\u20138768. [CrossRef]",
        "ref_ids": [
          "19"
        ]
      },
      "\u57fa\u4e8e\u591a\u5149\u8c31\u6210\u50cf\u548c\u6539\u8fdb YOLO v4 \u7684\u7164\u77f8\u77f3\u68c0\u6d4b": {
        "authors": [],
        "url": "https://www.researching.cn/ArticlePdf/m00006/2020/40/24/2411001.pdf",
        "ref_texts": " 31 Liu S Qi L Qin H F et al Path aggregation network for instance segmentation C 2018 IEEE CVF Conference on Computer Vision and Pattern Recognition June "
      },
      "Asap-nms: Accelerating non-maximum suppression using spatially aware priors": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2007.09785",
        "ref_texts": "24. Liu, S., Qi, L., Qin, H., Shi, J., Jia, J.: Path aggregation network for instance segmentation. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. pp. 8759{8768 (2018) 1",
        "ref_ids": [
          "24"
        ]
      },
      "Backbone based feature enhancement for object detection": {
        "authors": [
          "Haoqin Ji",
          "Weizeng Lu",
          "Linlin Shen"
        ],
        "url": "https://openaccess.thecvf.com/content/ACCV2020/papers/Ji_Backbone_Based_Feature_Enhancement_for_Object_Detection_ACCV_2020_paper.pdf",
        "ref_texts": "10. Liu, S., Qi, L., Qin, H., Shi, J., Jia, J.: Path aggregation network for instance segmentation. In: Proceedings of the IEEE Conference on Comput er Vision and Pattern Recognition. (2018) 8759\u20138768",
        "ref_ids": [
          "10"
        ]
      },
      "Application of pruning Yolo-V4 with center loss in mask wearing recognition for gymnasiums and sports grounds of colleges and universities": {
        "authors": [],
        "url": "https://scholar.archive.org/work/fjpkf5neejg5nl64h52tyx2xe4/access/wayback/https://ieeexplore.ieee.org/ielx7/9344865/9344866/09345257.pdf",
        "ref_texts": "[6] Liu, S., Qi, L., Qin, H., Shi, J ., & Jia, J. (2018). Path aggregation network for instance segmentation. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 87598768). ",
        "ref_ids": [
          "6"
        ]
      },
      "Hierarchical fish species detection in real-time video using YOLO": {
        "authors": [],
        "url": "https://uia.brage.unit.no/uia-xmlui/bitstream/handle/11250/2683060/Espen%20Stausland%20Kalhagen.pdf?sequence=1",
        "ref_texts": "[30] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 8759{8768, 2018.",
        "ref_ids": [
          "30"
        ]
      },
      "Maskplus: Improving mask generation for instance segmentation": {
        "authors": [
          "Shichao Xu",
          "Shuyue Lan",
          "Zhu Qi"
        ],
        "url": "http://openaccess.thecvf.com/content_WACV_2020/papers/Xu_MaskPlus_Improving_Mask_Generation_for_Instance_Segmentation_WACV_2020_paper.pdf",
        "ref_texts": "[23] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia. Path aggregation network for instance segmentation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 8759\u20138768, 2018.[24] J. Long, E. Shelhamer, and T. Darrell. Fully convolutional networks for semantic segmentation. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 3431\u20133440, 2015.",
        "ref_ids": [
          "23",
          "24"
        ]
      },
      "Analysis and synthesis of traffic scenes from road image sequences": {
        "authors": [],
        "url": "https://www.mdpi.com/1424-8220/20/23/6939/pdf",
        "ref_texts": "30. Liu, S.; Qi, L.; Qin, H.; Shi, J.; Jia, J. Path Aggregation Network for Instance Segmentation. In Proceedings of the 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition, Salt Lake City, UT, USA, 18\u201323 June 2018; pp. 8759\u20138768.",
        "ref_ids": [
          "30"
        ]
      },
      "Pbrnet: Pyramidal bounding box refinement to improve object localization accuracy": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2003.04541",
        "ref_texts": "20. Liu, S., Qi, L., Qin, H., Shi, J., Jia, J.: Path aggregation network for instance segmentation. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. pp. 8759{8768 (2018) 2",
        "ref_ids": [
          "20"
        ]
      },
      "Efficient scale-permuted backbone with learned resource distribution": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2010.11426",
        "ref_texts": "18. Liu, S., Qi, L., Qin, H., Shi, J., Jia, J.: Path aggregation network for instance segmentation. In: CVPR (2018) 3",
        "ref_ids": [
          "18"
        ]
      },
      "Centralized information interaction for salient object detection": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2012.11294",
        "ref_texts": "[35] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In CVPR , pages 8759\u20138768, 2018. 2",
        "ref_ids": [
          "35"
        ]
      },
      "Deep multicameral decoding for localizing unoccluded object instances from a single rgb image": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1906.07480",
        "ref_texts": "2039 Liu G, Si J, Hu Y, Li S (2018a) Photographic image synthesis with improved U-net. In: International Conference on Advanced Computational Intelligence (ICACI) , IEEE, pp 402{407 Liu R, Lehman J, Molino P, Such FP, Frank E, Sergeev A, Yosinski J (2018b) An Intriguing Failing of Convo-lutional Neural Networks and the CoordConv Solution. In: Advances in Neural Information Processing Systems (NeurIPS) , pp 9628{9639 Liu S, Qi L, Qin H, Shi J, Jia J (2018c) Path Aggregation Network for Instance Segmentation. In: Conference on Computer Vision and Pattern Recognition (CVPR) , IEEE Computer Society, pp 8759{8768 Liu S, Johns E, Davison AJ (2019) End-to-End MultiTask Learning with Attention. In: Conference on Computer Vision and Pattern Recognition (CVPR) , Computer Vision Foundation / IEEE, pp 1871{1880 Liu Y, Cheng MM, Hu X, Wang K, Bai X (2017) Richer Convolutional Features for Edge Detection. In: Conference on Computer Vision and Pattern Recognition (CVPR) , IEEE Computer Society, pp 5872|5881 Luo P, Wang G, Lin L, Wang X (2017) Deep Dual Learning for Semantic Image Segmentation. In: International Conference on Computer Vision (ICCV) , IEEE Computer Society, pp 2737{2745 Maninis KK, Pont-Tuset J, Arbel\u0013 aez PA, Gool LJV"
      },
      "Object detection technology trend and development direction using deep learning": {
        "authors": [
          "Eiji Hiraki"
        ],
        "url": "https://koreascience.kr/article/JAKO202008351737523.pdf",
        "ref_texts": "[18] S. Liu, L . Qi, Q. Haifang, S. Jianping, and J. Jiaya , \u201cPath aggregatio n network for instance segmentation ,\u201d In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. ",
        "ref_ids": [
          "18"
        ]
      },
      "Instance semantic segmentation benefits from generative adversarial networks": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2010.13757",
        "ref_texts": "[19] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 8759\u20138768, 2018.",
        "ref_ids": [
          "19"
        ]
      },
      "FourierNet: Compact mask representation for instance segmentation using differentiable shape decoders": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2002.02709",
        "ref_texts": "[3] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia, \u201cPath aggregation network for instance segmentation,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , 2018, pp. 8759\u20138768.[4] Zhaojin Huang, Lichao Huang, Yongchao Gong, Chang Huang, and Xinggang Wang, \u201cMask scoring r-cnn,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , 2019, pp.",
        "ref_ids": [
          "3",
          "4"
        ]
      },
      "Dense multiscale feature fusion pyramid networks for object detection in UAV-captured images": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2012.10643",
        "ref_texts": "[22]S.Liu,L.Qi,H.Qin,J.ShiandJ.Jia,\"PathAggregationNetworkforInstanceSegmentation,\" 2018IEEE/CVFConferenceonComputerVisionandPatternRecognition,SaltLakeCity,UT,2018, pp.8759-8768,doi:10.1109/CVPR.2018.00913.",
        "ref_ids": [
          "22"
        ]
      },
      "SRF-GAN: Super-resolved feature GAN for multi-scale representation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2011.08459",
        "ref_texts": "[28] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In CVPR , pages 8759\u20138768, 2018. 1, 2, 3, 6",
        "ref_ids": [
          "28"
        ]
      },
      "Object Detection for Perceptually-Degraded Environments": {
        "authors": [
          "Xianmei Lei"
        ],
        "url": "https://scholarworks.calstate.edu/downloads/qb98mk754",
        "ref_texts": "[44] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia, \u201cPath aggregation network for instance segmentation,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition , 2018, pp. 8759\u20138768. ",
        "ref_ids": [
          "44"
        ]
      },
      "An end-to-end framework for unsupervised pose estimation of occluded pedestrians": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2002.06429",
        "ref_texts": "[20] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia, \u201cPath aggregation network for instance segmentation,\u201d inCVPR , 2018, pp. 8759\u20138768.",
        "ref_ids": [
          "20"
        ]
      },
      "Single-Shot Object Detection with Split and Combine Blocks": {
        "authors": [],
        "url": "https://www.mdpi.com/2076-3417/10/18/6382/pdf",
        "ref_texts": "34. Liu, S.; Qi, L.; Qin, H.; Shi, J.; Jia, J. Path aggregation network for instance segmentation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Salt Lake City, UT, USA, 18\u201322 June 2018; pp. 8759\u20138768.",
        "ref_ids": [
          "34"
        ]
      },
      "Plug & play convolutional regression tracker for video object detection": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2003.00981",
        "ref_texts": "[28] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In CVPR , pages 8759\u20138768, 2018. 2",
        "ref_ids": [
          "28"
        ]
      },
      "Hardware Detection Method of Transmission Line Patrol Inspection Image Based on Improved YOLOV4 Model": {
        "authors": [],
        "url": "https://ebooks.iospress.nl/pdf/doi/10.3233/FAIA200748",
        "ref_texts": "[12] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia., Path aggregation network for instance segmentation. In Proceedings of the IEEE Co nference on Computer Vision and Pattern Recognition ",
        "ref_ids": [
          "12"
        ]
      },
      "DATNet: Dense auxiliary tasks for object detection": {
        "authors": [
          "Alex Levinshtein",
          "Alborz Rezazadeh",
          "Konstantinos Derpanis"
        ],
        "url": "https://openaccess.thecvf.com/content_WACV_2020/papers/Levinshtein_DATNet_Dense_Auxiliary_Tasks_for_Object_Detection_WACV_2020_paper.pdf",
        "ref_texts": "[21] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia. Path aggregation network for instance segmentation. In CVPR , pages 8759\u2013",
        "ref_ids": [
          "21"
        ]
      },
      "Interdependent Multi-task Learning for Simultaneous Segmentation and Detection.": {
        "authors": [],
        "url": "https://www.scitepress.org/Papers/2020/89495/89495.pdf",
        "ref_texts": "(2018). Focal loss for dense object detection. IEEETransactions on Pattern Analysis and Machine Intelligence, PP:1\u20131. Liu, S., Qi, L., Qin, H., Shi, J., and Jia, J. (2018). Path aggregation network for instance segmentation. In CVPR,pages 8759\u20138768. IEEEComputer Society. Liu,W.,Anguelov,D.,Erhan,D.,Szegedy,C.,Reed,S.,Fu, C.-Y.,andBerg,A.(2016). Ssd: Singleshot multibox detector. volume 9905, pages 21\u201337. Long, J., Shelhamer, E., and Darrell, T. (2015). Fully convolutional networks for semantic segmentation. In The IEEE Conference on Computer Vision and PatternRecognition (CVPR) . Misra,I.,Shrivastava,A.,Gupta,A.,andHebert,M.(2016) . Cross-stitch networks for multi-task learning. CoRR, abs/1604.03539. Redmon, J. and Farhadi, A. (2017). Yolo9000: Better, faster,stronger. In TheIEEEConferenceonComputer Visionand PatternRecognition (CVPR) . Ren, S., He, K., Girshick, R. B., and Sun, J. (2015). Faster r-cnn: Towards real-time object detection with region proposal networks. In Cortes, C., Lawrence, N. D., Lee, D. D., Sugiyama, M., and Garnett, R., editors, NIPS,pages 91\u201399. Shrivastava, A., Sukthankar, R., Malik, J., and Gupta, A."
      },
      "Learning universal shape dictionary for realtime instance segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2012.01050",
        "ref_texts": "2019. Mask Scoring R-CNN. In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) . Jain, A.; Zappella, L.; McClure, P.; and Vidal, R. 2012. Visual dictionary learning for joint object categorization a nd segmentation. In European Conference on Computer Vision , 718\u2013731. Springer. Jetley, S.; Sapienza, M.; Golodetz, S.; and Torr, P. H. 2017. Straight to shapes: real-time detection of encoded shapes. InProceedings of the IEEE Conference on Computer Vision and Pattern Recognition , 6550\u20136559. Kuo, W.; Angelova, A.; Malik, J.; and Lin, T.-Y . 2019. ShapeMask: Learning to Segment Novel Objects by Refining Shape Priors. In The IEEE International Conference on Computer Vision (ICCV) . Lee, Y .; and Park, J. 2020. CenterMask: Real-Time AnchorFree Instance Segmentation . Li, Y .; Qi, H.; Dai, J.; Ji, X.; and Wei, Y . 2017. Fully Convolutional Instance-Aware Semantic Segmentation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , 2359\u20132367. Lin, T.-Y .; Dollar, P.; Girshick, R.; He, K.; Hariharan, B.; and Belongie, S. 2017. Feature Pyramid Networks for Object Detection. In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) . Lin, T.-Y .; Maire, M.; Belongie, S.; Hays, J.; Perona, P.; Ra manan, D.; Doll\u00b4 ar, P.; and Zitnick, C. L. 2014. Microsoft COCO: Common Objects in Context. In Fleet, D.; Pajdla, T.; Schiele, B.; and Tuytelaars, T., eds., Computer Vision \u2013 ECCV 2014 , 740\u2013755. Cham: Springer International Publishing. ISBN 978-3-319-10602-1. Liu, S.; Qi, L.; Qin, H.; Shi, J.; and Jia, J. 2018. Path Aggregation Network for Instance Segmentation. In Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR) . Mairal, J.; Bach, F.; Ponce, J.; and Sapiro, G. 2009. Online dictionary learning for sparse coding. In Proceedings of the 26th annual international conference on machine learning , 689\u2013696. ACM. Mallat, S. G.; and Zhang, Z. 1993. Matching pursuits with time-frequency dictionaries. IEEE Transactions on signal processing 41(12): 3397\u20133415. Neven, D.; Brabandere, B. D.; Proesmans, M.; and Gool, L. V . 2019. Instance Segmentation by Jointly Optimizing Spatial Embeddings and Clustering Bandwidth. In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) . Rao, K. R.; and Yip, P. 1990. Discrete Cosine Transform: Algorithms, Advantages, Applications . San Diego, CA, USA: Academic Press Professional, Inc. ISBN 0-12-580203-X. Redmon, J.; and Farhadi, A. 2018. Yolov3: An incremental improvement. arXiv preprint arXiv:1804.02767 . Ren, X.; and Ramanan, D. 2013. Histograms of sparse codes for object detection. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , 3246\u20133253. Schmidt, U.; Weigert, M.; Broaddus, C.; and Myers, G.",
        "ref_ids": [
          "2019"
        ]
      },
      "\u57fa\u4e8e\u52a8\u6001\u611f\u53d7\u91ce\u7684\u822a\u62cd\u56fe\u50cf\u76ee\u6807\u68c0\u6d4b\u7b97\u6cd5": {
        "authors": [],
        "url": "https://www.researching.cn/ArticlePdf/m00006/2020/40/4/0415001.pdf",
        "ref_texts": " 21  LiuS QiL QinHF etal\u656dPathaggregation networkforinstancesegmentation C \u22252018IEEE CVFConferenceonComputerVisionandPattern Recognition June18G23 2018 SaltLakeCity UT USA\u656dNewYork IEEE 2018 8759G8768\u656d"
      },
      "U2-ONet: A two-level nested octave U-structure with multiscale attention mechanism for moving instances segmentation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2007.13092",
        "ref_texts": "[25] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia, \u201cPath aggregation network for instance segmentation,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition , 2018, pp. 8759\u20138768.",
        "ref_ids": [
          "25"
        ]
      },
      "Extracting effective image attributes with refined universal detection": {
        "authors": [
          "Qiang Yu",
          "Xinyu Xiao",
          "Chunxia Zhang",
          "Lifei Song",
          "Chunhong Pan"
        ],
        "url": "https://www.mdpi.com/1424-8220/21/1/95/pdf",
        "ref_texts": ""
      },
      "Learning to Generate Content-Aware Dynamic Detectors": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2012.04265",
        "ref_texts": "[20] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 8759\u20138768, 2018. 2",
        "ref_ids": [
          "20"
        ]
      },
      "Attention-based Instance Segmentation Network for Cell Segmentation": {
        "authors": [],
        "url": "https://dl.acm.org/doi/pdf/10.1145/3425577.3425588",
        "ref_texts": "[15] Shu, L., et al. Path Aggregation Network for Instance Segmentation . IEEE Conference on Computer Vision and Pattern Recognition. 2018.p.8759-8768",
        "ref_ids": [
          "15"
        ]
      },
      "The design of dynamic neural networks for efficient learning and inference": {
        "authors": [],
        "url": "https://www2.eecs.berkeley.edu/Pubs/TechRpts/2020/EECS-2020-236.pdf",
        "ref_texts": "[119] Shu Liu et al. \u201cPath aggregation network for instance segmentation\u201d. In: IEEE Conference on Computer Vision and Pattern Recognition (CVPR) . 2018, pp. 8759\u20138768.",
        "ref_ids": [
          "119"
        ]
      },
      "Efficient object detection and discovery for real-world robotics applications": {
        "authors": [],
        "url": "https://ora.ox.ac.uk/objects/uuid:13cefafb-89e5-42dd-990e-822ecd9224ba/download_file?safe_filename=Engelcke_2021_Efficient_object_detection.pdf&file_format=pdf&type_of_work=Thesis",
        "ref_texts": "[120]S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia. \u201cPath Aggregation Network for Instance Segmentation\u201d. In: IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) (2018).",
        "ref_ids": [
          "120"
        ]
      },
      "Assessment of conformal use of personal protective equipment by object and human pose recognition": {
        "authors": [],
        "url": "https://imt-atlantique.hal.science/hal-03001159/document",
        "ref_texts": "[Liu et al., 2018] Liu, S., Qi, L., Qin, H., Shi, J., and Jia, J. (2018). Path aggregation network for instance segmentation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 8759\u20138768.",
        "ref_ids": [
          "Liu et al\\., 2018"
        ]
      },
      "Automatic Detection of Display Defects for Smart Meters based on Deep Learning": {
        "authors": [],
        "url": "https://hrcak.srce.hr/file/384991",
        "ref_texts": "[24] S. Liu et al., ''Path Aggregation Network for Instance Segmentation'', in Proc. of the IEEE Conference on Computer Vision and Pattern Recog nition , 2018, pp. 8759\u20128768. https://doi.org/10.1109/CVPR.2018.00913",
        "ref_ids": [
          "24"
        ]
      },
      "Learning Robust Feature Representations for Scene Text Detection": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2005.12466",
        "ref_texts": "[25] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia. Path aggregation network for instance segmentation. In CVPR , pages 8759\u20138768, 2018.",
        "ref_ids": [
          "25"
        ]
      },
      "A Deep Learning-based approach for Fault Detection of Power Lines": {
        "authors": [],
        "url": "https://uia.brage.unit.no/uia-xmlui/bitstream/handle/11250/2683588/Christer%20Steffensen%20Mathisen.pdf",
        "ref_texts": "[31] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia, \\Path aggregation network for instance segmentation,\" CoRR , vol. abs/1803.01534, 2018. arXiv: 1803.01534 . [Online]. Available: http://arxiv.org/abs/1803.",
        "ref_ids": [
          "31",
          "Online"
        ]
      },
      "Scene parsing with deep neural networks": {
        "authors": [],
        "url": "https://dr.ntu.edu.sg/bitstream/10356/142935/2/Thesis_NTU_2020_Henghui.pdf",
        "ref_texts": "[126] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia, \\Path aggregation network for instance segmentation,\" in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , 2018, pp. 8759{8768. 19",
        "ref_ids": [
          "126"
        ]
      },
      "Utilisation de m\u00e9thodes de Deep learning pour l'extraction de texte dans les images": {
        "authors": [
          "Maamouli Abdelouaheb"
        ],
        "url": "http://archives.univ-biskra.dz/bitstream/123456789/18881/1/MAAMOULI_ABDELOUAHEB.pdf",
        "ref_texts": "[27].Liu, S., et al. (2018). Path aggregation net work for instance segmentation. Proceedings of the IEEE conference on co mputer vision and pattern recognition. ",
        "ref_ids": [
          "27"
        ]
      },
      "Decoupled Self Attention for Accurate One Stage Object Detection": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2012.07630",
        "ref_texts": " S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia, \"Path Aggregation Network for Instance Segmentation,\" "
      },
      "SMPR: Single-Stage Multi-Person Pose Regression": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2006.15576",
        "ref_texts": "[17] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia. Path aggregation network for instance segmentation. In CVPR , pages 8759\u20138768, 2018.",
        "ref_ids": [
          "17"
        ]
      },
      "YOLO-based Obstacle Avoidance for Drones": {
        "authors": [],
        "url": "https://theses.liacs.nl/pdf/2019-2020-CorselCW.pdf",
        "ref_texts": "[43]S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia. Path aggregation network for instance segmentation. In 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 8759\u20138768, 2018.",
        "ref_ids": [
          "43"
        ]
      },
      "Improving Object Detection with MatrixNets": {
        "authors": [],
        "url": "https://uwspace.uwaterloo.ca/bitstream/handle/10012/16509/Agarwal_Rishav.pdf?sequence=5&isAllowed=y",
        "ref_texts": "[34] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 8759{8768, 2018.",
        "ref_ids": [
          "34"
        ]
      },
      "Nighttime object tracking for intelligent vehicles": {
        "authors": [
          "Elias Frantar"
        ],
        "url": "https://scholar.archive.org/work/wip3rlaz5bb33k3vx5myoks5pe/access/wayback/https://repositum.tuwien.at/bitstream/20.500.12708/16046/2/Nighttime%20Object%20Tracking%20for%20Intelligent%20Vehicles.pdf",
        "ref_texts": "[LQQ+18] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In IEEE Conference on Computer Vision and Pattern Recognition , pages 8759\u20138768, 2018.",
        "ref_ids": [
          "LQQ\\+18"
        ]
      },
      "Interpretability of deep convolutional neural networks in image analysis": {
        "authors": [
          "Johnny Canuck"
        ],
        "url": "https://open.library.ubc.ca/media/download/pdf/24/1.0391992/3",
        "ref_texts": "[53] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia. Path aggregation network for instance segmentation. In 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 8759\u20138768, 2018. !page 1",
        "ref_ids": [
          "53"
        ]
      },
      "License Plate Detection Using One-stage Object Detection Algorithms": {
        "authors": [
          "Niloofar Baghdadi"
        ],
        "url": "https://spectrum.library.concordia.ca/id/eprint/987700/7/Baghdadi_%20MCompSc_S2021.pdf",
        "ref_texts": "[47] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia, \u201cPath aggregation network for instance segmentation,\u201d CoRR , vol. abs/1803.01534, 2018. [Online]. Available: http://arxiv.org/abs/1803.01534",
        "ref_ids": [
          "47",
          "Online"
        ]
      },
      "NOVEL MODEL-BASED AND DEEP LEARNING APPROACHES TO SEGMENTATION AND OBJECT DETECTION IN 3D MICROSCOPY IMAGES": {
        "authors": [],
        "url": "https://hammer.purdue.edu/articles/thesis/NOVEL_MODEL-BASED_AND_DEEP_LEARNING_APPROACHES_TO_SEGMENTATION_AND_OBJECT_DETECTION_IN_3D_MICROSCOPY_IMAGES/12798536/1/files/24230798.pdf",
        "ref_texts": "[25] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia, \u201cPath aggregation network for instance segmentation,\u201d 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition , pp. 8759\u20138768, 2018.",
        "ref_ids": [
          "25"
        ]
      },
      "An investigation of regression as an avenue to find precision-runtime trade-off for object segmentation": {
        "authors": [
          "Arun Rajendra"
        ],
        "url": "https://scholar.archive.org/work/jwhzcmya65gshk3ubmdosa5aku/access/wayback/https://pub.h-brs.de/frontdoor/deliver/index/docId/5111/file/brsu_techreport_05_2020_Prabhu_pdf1-4.pdf",
        "ref_texts": "2.3. Instance Segmentation Figure 2.29: PANet architecture introduced by Liu et al. [32].(a)Typical FPN backbone, (b)Bottom-up Path Aggregation, (c)Adaptive feature pooling, (d)Box branch, (e)Fully-connected fusion. Feature Pooling and these pooled features are used for all the proposals. The rest of the network is more or less similar to Mask R-CNN (He et al. [18]) except that PANet uses a fully connected layer to generate a class-agnostic background/foreground mask for each proposal. The class-spec ific mask output is added to the class-agnostic mask to generate the final instance mask. Figure 2.30: YOLACT architecture introduced by Bolya et al. [2] As seen before, Mask R-CNN (He et al. [18]) adds a parallel mask branch to the Faster R-CNN (Ren et al.[48]) object detection network. YOLACT introduced by Bolya et al. [2]intends to emulate that by adding a mask branch to a single-stage object detection network without an explicit localization step (like the ROIAlign used in Mask R-CNN). This enables YOLACT to achieve real-ti me performance on the MS COCO (Lin et al. [29]) dataset. To achieve this, the authors break the instance segmentation task into two parallel sub-tasks which can be performed by two parallel branche s.",
        "ref_ids": [
          "32",
          "18",
          "2",
          "18",
          "48",
          "2",
          "29"
        ]
      },
      "\u57fa\u4e8e\u6539\u8fdb Mask R-CNN \u7684\u6a21\u7cca\u56fe\u50cf\u5b9e\u4f8b\u5206\u5272\u7684\u7814\u7a76": {
        "authors": [],
        "url": "https://jeit.ac.cn/cn/article/pdf/preview/10.11999/JEIT190604.pdf",
        "ref_texts": "265. CHEN\u00a0L\u00a0C,\u00a0HERMANS\u00a0A,\u00a0PAPANDREOU\u00a0G,\u00a0et al. MaskLab:\u00a0Instance\u00a0segmentation\u00a0by\u00a0refining\u00a0object detection\u00a0with\u00a0semantic\u00a0and\u00a0direction\u00a0features[C].\u00a0The IEEE/CVF\u00a0Conference\u00a0on\u00a0Computer\u00a0Vision\u00a0and\u00a0Pattern Recognition,\u00a0Salt\u00a0Lake\u00a0City,\u00a0USA,\u00a02018:\u00a04013\u20134022.[24] LIU\u00a0Shu,\u00a0QI\u00a0Lu,\u00a0QIN\u00a0Haifang,\u00a0et al.\u00a0Path\u00a0aggregation network\u00a0for\u00a0instance\u00a0segmentation[C].\u00a02018\u00a0IEEE/CVF Conference\u00a0on\u00a0Computer\u00a0Vision\u00a0and\u00a0Pattern\u00a0Recognition, Salt\u00a0Lake\u00a0City,\u00a0USA,\u00a02018:\u00a08759\u20138768.\u00a0doi:\u00a010.1109/ CVPR.2018.00913.[25]",
        "ref_ids": [
          "265"
        ]
      },
      "Joint COCO and Mapillary Workshop at ICCV 2019: COCO Instance Segmentation Challenge Track Technical Report: Boundary-Aware Localization with \u2026": {
        "authors": [],
        "url": "https://cocodataset.org/files/detection_2019_reports/Technical%20Report%20of%20mmdet.pdf",
        "ref_texts": "[14] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In IEEE Conference on Computer Vision and Pattern Recognition , 2018. 1, 2, 3",
        "ref_ids": [
          "14"
        ]
      },
      "HPS: Holistic End-to-End Panoptic Segmentation Network with Interrelations": {
        "authors": [],
        "url": "https://scholar.archive.org/work/rnwlzn5jarb6pnhut3hg2modoi/access/wayback/https://diglib.tugraz.at/download.php?id=5f6b18043d47d&location=datacite",
        "ref_texts": "[21] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia. Path Aggregation Network for Instance Segmentation. In Conference on Computer Vision and Pattern Recognition , pages 8759\u20138768, 2018.",
        "ref_ids": [
          "21"
        ]
      },
      "Shape-aware Segmentation of Biomedical Images using Deep Learning": {
        "authors": [],
        "url": "https://is.muni.cz/th/wzv56/filip_lux_rigo_Archive.pdf",
        "ref_texts": "[19] Hao Chen, Xiaojuan Qi, Lequan Yu, Qi Dou, Jing Qin, and Pheng-Ann Heng, \"DCAN: Deep contour-aware networks for object instance segmentation from histol\u00ad ogy images,\" Medical Image Analysis, vol. 36, pp. 135146, feb 2017. ",
        "ref_ids": [
          "19"
        ]
      },
      "Delving into the Imbalance of Positive Proposals in Two-stage Object Detection": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2005.11472",
        "ref_texts": "15. Liu, S., Qi, L., Qin, H., Shi, J., Jia, J.: Path aggregation network for instance segmentation. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. pp.",
        "ref_ids": [
          "15"
        ]
      },
      "A New Panoptic Segmentation Model Based on Offset Fields": {
        "authors": [],
        "url": "https://www.xhuqk.com/xhdxxbzkb/en/article/pdf/preview/10.12198/j.issn.1673-159X.3612.pdf",
        "ref_texts": "[17]\u00a0LIU\u00a0Shu,\u00a0QI\u00a0Lu,\u00a0QIN\u00a0Haifang,\u00a0et\u00a0al.\u00a0Path\u00a0aggregation\u00a0network\u00a0for\u00a0instance\u00a0segmentation[J].\u00a0Proceedings\u00a0of the\u00a0IEEE\u00a0Conference\u00a0on\u00a0Computer\u00a0Vision\u00a0and\u00a0Pattern\u00a0Recognition.Salt \u00a0Lake \u00a0City, \u00a0UT, \u00a0USA: \u00a0IEEE, \u00a02018: 8759\u00a0\u2212\u00a08768.\u00a0",
        "ref_ids": [
          "17",
          "J"
        ]
      },
      "Condensing Two-stage Detection with Automatic Object Key Part Discovery": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2006.05597",
        "ref_texts": "[11] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In CVPR , pages 8759\u20138768, 2018.",
        "ref_ids": [
          "11"
        ]
      },
      "Improving object detection performance by lightweight approaches": {
        "authors": [
          "Yingwei Zhou"
        ],
        "url": "https://eprints.soton.ac.uk/439322/1/Final_thesis.pdf",
        "ref_texts": "64 BIBLIOGRAPHY. Jeesoo Kim, Jangho Kim, Jaeyoung Yoo, Daesik Kim, and Nojun Kwak. Vehicle image generation going well with the surroundings. arXiv preprint arXiv:1807.02925, 2018. Tae-Houn Kim, Maik B\u007f ohmer, Honghong Hu, Noriyuki Nishimura, and Julian I. Schroeder. Guard cell signal transduction network: Advances in understanding abscisic acid, co2, and ca2+ signaling. Annual Review ofPlant Biology, 61(1):561{591, 2010. Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980, 2014. M.B. Kirkham. Chapter 24 stomatal anatomy and stomatal resistance. In M.B. Kirkham, editor, Principles ofSoilandPlant Water Relations (Second Edition), pages 431 { 451. Academic Press, Boston, second edition edition, 2014. Mate Kisantal, Zbigniew Wojna, Jakub Murawski, Jacek Naruniec, and Kyunghyun Cho. Augmentation for small object detection. CoRR, abs/1902.07296, 2019. Alex Krizhevsky and Geofirey Hinton. Learning multiple layers of features from tiny images. Technical report, Citeseer, 2009. Alex Krizhevsky, Ilya Sutskever, and Geofirey E Hinton. Imagenet classiffcation with deep convolutional neural networks. In Advances inneural information processing systems, pages 1097{1105, 2012. Hamid Laga, Fahimeh Shahinnia, and Delphine Fleury. Image-based plant stomata phenotyping. 12 2014. Yann LeCun, Yoshua Bengio, and Geofirey Hinton. Deep learning. nature, 521(7553): 436, 2015. Yann LeCun and Corinna Cortes. MNIST handwritten digit database. 2010. Hankyeol Lee, SEOK EON CHOI, and Changick Kim. A memory model based on the siamese network for long-term tracking. In European Conference onComputer Vision Workshop. Springer, 2018. Tsung-Yi Lin, Piotr Doll\u0013 ar, Ross Girshick, Kaiming He, Bharath Hariharan, and Serge Belongie. Feature pyramid networks for object detection. In Proceedings oftheIEEE Conference onComputer Vision andPattern Recognition, pages 2117{2125, 2017a. Tsung-Yi Lin, Priya Goyal, Ross Girshick, Kaiming He, and Piotr Dollar. Focal loss for dense object detection. In 2017 IEEE International Conference onComputer Vision (ICCV), pages 2999{3007. IEEE, 2017b. Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva Ramanan, Piotr Doll\u0013 ar, and C Lawrence Zitnick. Microsoft coco: Common objects in context. In European conference oncomputer vision, pages 740{755. Springer, 2014. BIBLIOGRAPHY. 65 Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In Proceedings oftheIEEE Conference onComputer Vision andPattern Recognition, pages 8759{8768, 2018. Wei Liu, Dragomir Anguelov, Dumitru Erhan, Christian Szegedy, Scott Reed, ChengYang Fu, and Alexander C Berg. Ssd: Single shot multibox detector. In European conference oncomputer vision, pages 21{37. Springer, 2016. Francisco Massa and Ross Girshick. maskrcnn-benchmark: Fast, modular reference implementation of Instance Segmentation and Object Detection algorithms in PyTorch. https://github.com/facebookresearch/maskrcnn-benchmark , 2018. Accessed: 28/04/2019. Wes McKinney. pandas: a foundational python library for data analysis and statistics. Python forHigh Performance andScientiffc Computing, 14, 2011. Deirdre H McLachlan, Michaela Kopischke, and Silke Robatzek. Gate control: guard cell regulation by microbial stress. New Phytologist, 203(4):1049{1063, 2014. Maeli Melotto, William Underwood, and Sheng Yang He. Role of stomata in plant innate immunity and foliar bacterial diseases. Annu. Rev. Phytopathol., 46:101{122, 2008. Aude Oliva and Antonio Torralba. Modeling the shape of the scene: A holistic representation of the spatial envelope. International journal ofcomputer vision, 42(3): 145{175, 2001. Adam Paszke, Sam Gross, Soumith Chintala, Gregory Chanan, Edward Yang, Zachary DeVito, Zeming Lin, Alban Desmaison, Luca Antiga, and Adam Lerer. Automatic difierentiation in pytorch. In NIPS-W, 2017. Alexander J Ratner, Henry Ehrenberg, Zeshan Hussain, Jared Dunnmon, and Christopher R\u0013 e. Learning to compose domain-speciffc transformations for data augmentation. InAdvances inneural information processing systems, pages 3236{3246, 2017. Joseph Redmon, Santosh Divvala, Ross Girshick, and Ali Farhadi. You only look once: Uniffed, real-time object detection. In Proceedings oftheIEEE conference oncomputer vision andpattern recognition, pages 779{788, 2016. Joseph Redmon and Ali Farhadi. Yolov3: An incremental improvement. arXiv preprint arXiv:1804.02767, 2018. Shaoqing Ren, Kaiming He, Ross Girshick, and Jian Sun. Faster r-cnn: Towards real-time object detection with region proposal networks. In Advances inneural information processing systems, pages 91{99, 2015a."
      },
      "Joint COCO and LVIS workshop at ECCV 2020: LVIS Challenge Track Technical Report: Seesaw Loss for Long-Tailed Instance Segmentation": {
        "authors": [],
        "url": "https://www.lvisdataset.org/assets/challenge_reports/2020/MMDet.pdf",
        "ref_texts": "14.Liu, S., Qi, L., Qin, H., Shi, J., Jia, J.: Path aggregation network for instance segmentation. In: CVPR (2018)",
        "ref_ids": [
          "14"
        ]
      },
      "Deep Learning for Polyp Detection in Colonoscopy": {
        "authors": [],
        "url": "https://www.csie.ntu.edu.tw/~fuh/personal/DeepLearningforPolypDetectioninColonoscopy.pdf",
        "ref_texts": "[1] Yamada, M., Saito, Y., Imaoka, H. et al. Development of a real-time endoscopic image diagnosis support system using deep learning technology in colonoscopy. Sci Rep 9, 14465 (2019). [2] Wang, P., Xiao, X., Glissen Brown, J.R. et al. Development and validation of a deep-learning algorithm for the detection of polyps during colonoscopy. Nat Biomed Eng 2, 741\u2013748 (2018). [3] Bernal, J.; S\u00e1nchez, F.J.; Fern\u00e1ndez-Esparrach, G.; Gil, D.; Rodr\u00edguez, C.; Vilari\u00f1o, F. WM-DOVA maps for accurate polyp highlighting in colonoscopy: Validation vs. saliency maps from physicians. Comput. Med. Imaging Graph. 2015, 43, 99\u2013111. [4] Debesh Jha, Pia H. Smedsrud, Michael A. Riegler, P\u00e5l Halvorsen, Dag Johansen, Thomas de Lange, and H\u00e5vard D. Johansen, Kvasir-SEG: A Segmented Polyp Dataset, In Proceedings of the ternational conference on Multimedia Modeling, Republic of Korea, 2020. [5] J. Silva, A. Histace, O. Romain, X. Dray and B. Granado, \"Toward embedded detection of polyps in WCE images for early diagnosis of colorectal cancer\", International Journal of Computer Assisted Radiology and Surgery, vol. 9, no. 2, pp. 283-293, 2014. [6] K. Simonyan and A. Zisserman, \"Very deep convolutional networks for large-scale image recognition\", Int. Conf. on Learning Representations, 2015. [7] Bengio, Y. (2011). Deep learning of representations for unsupervised and transfer learning. In JMLR W&CP: Proc. Unsupervised and Transfer Learning. [8] Krizhevsky, Alex & Sutskever, Ilya & Hinton, Geoffrey. (2012). ImageNet Classification with Deep Convolutional Neural Networks. Neural Information Processing Systems. 25. 10.1145/3065386. [9] N. Tajbakhsh et al., \u201cConvolutional Neural Networks for Medical Image Analysis: Full Training or Fine Tuning?,\u201d IEEE Trans. Med.Imaging, vol. 35, no. 5, pp. 1299\u20131312, 2016. [10] Zhang X, Chen F, Yu T, An J, Huang Z, Liu J, et al. (2019) Real-time gastric polyp detection using convolutional neural networks. PLoS ONE 14 (3): e0214133.https://doi.org/10.1371/journal.pone.0214133 [11] LabelImg.https://github.com/tzutalin/labelImg [12] Bochkovskiy, Alexey & Wang, Chien-Yao & Liao, Hong-yuan. (2020). YOLOv4: Optimal Speed and Accuracy of Object Detection. [13] Chien-Yao Wang, Hong-Yuan Mark Liao, Yueh-Hua Wu, Ping-Yang Chen, Jun-Wei Hsieh, and I-Hau Yeh. CSPNet: A new backbone that can enhance learning capability of cnn. Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshop (CVPR Workshop), 2020. [14] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Spatial pyramid pooling in deep convolutional networks for visual recognition. IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 37(9):1904\u20131916, 2015. [15] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 8759\u20138768, 2018. [16] Redmon, Joseph & Farhadi, Ali. (2018). YOLOv3: An Incremental Improvement. ",
        "ref_ids": [
          "1",
          "2",
          "3",
          "4",
          "5",
          "6",
          "7",
          "8",
          "9",
          "10",
          "11",
          "12",
          "13",
          "14",
          "15",
          "16"
        ]
      },
      "Supplementary for \u201cSegFix: Model-Agnostic Boundary Refinement for Segmentation\u201d": {
        "authors": [],
        "url": "https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123570477-supp.pdf",
        "ref_texts": "7. Liu, S., Qi, L., Qin, H., Shi, J., Jia, J.: Path aggregation network for instance segmentation. In: CVPR (2018)",
        "ref_ids": [
          "7"
        ]
      },
      "Fully Convolutional Networks (FCNs) for Medical Image Segmentation": {
        "authors": [
          "Zhewei Wang"
        ],
        "url": "https://etd.ohiolink.edu/acprod/odb_etd/ws/send_file/send?accession=ohiou1605199701509179&disposition=inline",
        "ref_texts": "[LQQ+18] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 8759\u20138768, 2018.",
        "ref_ids": [
          "LQQ\\+18"
        ]
      },
      "DanielBolya ChongZhou FanyiXiao YongJaeLee": {
        "authors": [
          "Daniel Bolya",
          "Chong Zhou",
          "Fanyi Xiao",
          "Yong Jae"
        ],
        "url": "https://par.nsf.gov/servlets/purl/10140339",
        "ref_texts": "[29] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In CVPR, 2018.",
        "ref_ids": [
          "29"
        ]
      },
      "PointRend: Image Segmentation as Rendering": {
        "authors": [],
        "url": "https://static.aminer.cn/upload/pdf/1259/1112/1624/5dfa02473a55aca6f2786732_0.pdf",
        "ref_texts": "[32] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In CVPR , 2018. 3[33] Wei Liu, Dragomir Anguelov, Dumitru Erhan, Christian Szegedy, Scott Reed, Cheng-Yang Fu, and Alexander C Berg. SSD: Single shot multibox detector. In ECCV , 2016.",
        "ref_ids": [
          "32",
          "33"
        ]
      },
      "Working with scarce annotations in computational pathology": {
        "authors": [
          "Navid Alemi"
        ],
        "url": "https://wrap.warwick.ac.uk/153064/1/WRAP_Theses_Koohbanani_2020.pdf",
        "ref_texts": "[46] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 8759{",
        "ref_ids": [
          "46"
        ]
      },
      "Deep Snake for Real-Time Instance Segmentation": {
        "authors": [],
        "url": "https://ask.qcloudimg.com/draft/6837186/79j1ad13cu.pdf",
        "ref_texts": "[25] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In CVPR , 2018. 1, 2, 6, 7",
        "ref_ids": [
          "25"
        ]
      },
      "The Discriminative Generalized Hough Transform for Localization of Highly Variable Objects and its Application for Surveillance Recordings": {
        "authors": [
          "Georg Ferdinand"
        ],
        "url": "https://macau.uni-kiel.de/servlets/MCRFileNodeServlet/macau_derivate_00001977/thesis_hahmann_dght.pdf",
        "ref_texts": "[122]Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path Aggregation Network for Instance Segmentation. In Conference on Computer Vision and Pattern Recognition (CVPR) , 2018.",
        "ref_ids": [
          "122"
        ]
      },
      "Aquaculture fish quality control using synthetic data": {
        "authors": [],
        "url": "https://repositorio-aberto.up.pt/bitstream/10216/128137/2/410895.pdf",
        "ref_texts": "1105, 2012. Yevhen Kuznietsov, J\u00f6rg St\u00fcckler, and Bastian Leibe. Semi-supervised deep learning for monocular depth map prediction. Proceedings 30th IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2017 , pages 2215\u20132223, 2017. Y . Lecun, L. Bottou, Y . Bengio, and P. Haffner. Gradient-based learning applied to document recognition. Proceedings of the IEEE , pages 2278\u20132324, November 1998. Stan Z Li. Markov random field models in computer vision. Lecture Notes in Computer Science , pages 361\u2013370, 1994. Guosheng Lin, Anton Milan, Chunhua Shen, and Ian Reid. Refinenet: Multi-path refinement networks for high-resolution semantic segmentation. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 1925\u20131934, 2017. Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva Ramanan, Piotr Doll\u00e1r, and C Lawrence Zitnick. Microsoft coco: Common objects in context. In European conference on computer vision , pages 740\u2013755. Springer, 2014. Xiao Lin, Dalila S\u00e1nchez-Escobedo, Josep R Casas, and Montse Pard\u00e0s. Depth estimation and semantic segmentation from a single rgb image using a hybrid convolutional neural network. Sensors , 19(8):1795, 2019. Fayao Liu, Chunhua Shen, Guosheng Lin, and Ian Reid. Learning depth from single monocular images using deep convolutional neural fields. IEEE Transactions on Pattern Analysis and Machine Intelligence , pages 2024\u20132039, 2015. Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 8759\u20138768, 2018. Yudong Liu, Yongtao Wang, Siwei Wang, TingTing Liang, Qijie Zhao, Zhi Tang, and Haibin Ling. Cbnet: A novel composite backbone network architecture for object detection. arXiv preprint arXiv:1909.03625 , 2019. Jonathan Long, Evan Shelhamer, and Trevor Darrell. Fully convolutional networks for semantic segmentation. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 3431\u20133440, 2015."
      },
      "\u57fa\u4e8e\u8ddd\u79bb\u8c31\u56de\u5f52\u7684\u5168\u666f\u5206\u5272\u65b9\u6cd5": {
        "authors": [],
        "url": "https://www.xhuqk.com/xhdxxbzkb/cn/article/pdf/preview/10.12198/j.issn.1673-159X.3612.pdf",
        "ref_texts": "[17]\u00a0LIU\u00a0Shu,\u00a0QI\u00a0Lu,\u00a0QIN\u00a0Haifang,\u00a0et\u00a0al.\u00a0Path\u00a0aggregation\u00a0network\u00a0for\u00a0instance\u00a0segmentation[J].\u00a0Proceedings\u00a0of the\u00a0IEEE\u00a0Conference\u00a0on\u00a0Computer\u00a0Vision\u00a0and\u00a0Pattern\u00a0Recognition.Salt \u00a0Lake \u00a0City, \u00a0UT, \u00a0USA: \u00a0IEEE, \u00a02018: 8759\u00a0\u2212\u00a08768.\u00a0",
        "ref_ids": [
          "17",
          "J"
        ]
      },
      "\u041a\u043e\u043c\u043f'\u044e\u0442\u0435\u0440\u043d\u0430 \u0441\u0438\u0441\u0442\u0435\u043c\u0430 \u0434\u043b\u044f \u0432\u0438\u0434\u0456\u043b\u0435\u043d\u043d\u044f \u043e\u0431'\u0454\u043a\u0442\u0456\u0432 \u0443 \u0432\u0456\u0434\u0435\u043e\u043f\u043e\u0442\u043e\u0446\u0456 \u0456\u0437 \u0437\u0430\u043c\u0456\u0449\u0435\u043d\u043d\u044f\u043c \u0432\u043c\u0456\u0441\u0442\u0443": {
        "authors": [
          "Volodymyr Ishchenko"
        ],
        "url": "https://dspace.znu.edu.ua/xmlui/bitstream/handle/12345/4985/%D0%86%D1%89%D0%B5%D0%BD%D0%BA%D0%BE.pdf?sequence=1&isAllowed=y",
        "ref_texts": "58. Liu S., Qi L., Qin H., Shi J., Jia J. Path Aggregation Network for I nstance Segmentation . 2018 Conference on Computer Vision and Pattern Recogn ition. Salt Lake City , UT, USA , 2018. \u0421. 8759\u20138768 . ",
        "ref_ids": [
          "58"
        ]
      },
      "Generalized intersection over union: A metric and a loss for bounding box regression": {
        "authors": [
          "Hamid Rezatofighi",
          "Nathan Tsoi",
          "Young Gwak",
          "Amir Sadeghian",
          "Ian Reid",
          "Silvio Savarese"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPR_2019/papers/Rezatofighi_Generalized_Intersection_Over_Union_A_Metric_and_a_Loss_for_CVPR_2019_paper.pdf",
        "ref_texts": "[15] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia. Path aggregation network for instance segmentation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 8759\u20138768, 2018. 1",
        "ref_ids": [
          "15"
        ]
      },
      "Centernet: Keypoint triplets for object detection": {
        "authors": [
          "Kaiwen Duan",
          "Song Bai",
          "Lingxi Xie",
          "Honggang Qi",
          "Qingming Huang",
          "Qi Tian"
        ],
        "url": "https://openaccess.thecvf.com/content_ICCV_2019/papers/Duan_CenterNet_Keypoint_Triplets_for_Object_Detection_ICCV_2019_paper.pdf",
        "ref_texts": "[27] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 8759\u20138768, 2018.",
        "ref_ids": [
          "27"
        ]
      },
      "Yolact: Real-time instance segmentation": {
        "authors": [
          "Daniel Bolya",
          "Chong Zhou",
          "Fanyi Xiao",
          "Yong Jae"
        ],
        "url": "http://openaccess.thecvf.com/content_ICCV_2019/papers/Bolya_YOLACT_Real-Time_Instance_Segmentation_ICCV_2019_paper.pdf",
        "ref_texts": "[29] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In CVPR , 2018.",
        "ref_ids": [
          "29"
        ]
      },
      "Nas-fpn: Learning scalable feature pyramid architecture for object detection": {
        "authors": [
          "Golnaz Ghiasi",
          "Yi Lin",
          "Quoc V. Le"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPR_2019/papers/Ghiasi_NAS-FPN_Learning_Scalable_Feature_Pyramid_Architecture_for_Object_Detection_CVPR_2019_paper.pdf",
        "ref_texts": "[25] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia. Path aggregation network for instance segmentation. In CVPR , 2018. 1,2",
        "ref_ids": [
          "25"
        ]
      },
      "Libra r-cnn: Towards balanced learning for object detection": {
        "authors": [
          "Jiangmiao Pang",
          "Kai Chen",
          "Jianping Shi",
          "Huajun Feng",
          "Wanli Ouyang",
          "Dahua Lin"
        ],
        "url": "https://openaccess.thecvf.com/content_CVPR_2019/papers/Pang_Libra_R-CNN_Towards_Balanced_Learning_for_Object_Detection_CVPR_2019_paper.pdf",
        "ref_texts": "[22] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In IEEE Conference on Computer Vision and Pattern Recognition , 2018.",
        "ref_ids": [
          "22"
        ]
      },
      "Hybrid task cascade for instance segmentation": {
        "authors": [
          "Kai Chen",
          "Jiangmiao Pang",
          "Jiaqi Wang",
          "Yu Xiong",
          "Xiaoxiao Li",
          "Shuyang Sun",
          "Wansen Feng",
          "Ziwei Liu",
          "Jianping Shi",
          "Wanli Ouyang",
          "Chen Change",
          "Dahua Lin"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPR_2019/papers/Chen_Hybrid_Task_Cascade_for_Instance_Segmentation_CVPR_2019_paper.pdf",
        "ref_texts": "[28] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In IEEE Conference on Computer Vision and Pattern Recognition , 2018.",
        "ref_ids": [
          "28"
        ]
      },
      "Panoptic feature pyramid networks": {
        "authors": [
          "Alexander Kirillov",
          "Ross Girshick",
          "Kaiming He",
          "Piotr Dollar"
        ],
        "url": "http://openaccess.thecvf.com/content_CVPR_2019/papers/Kirillov_Panoptic_Feature_Pyramid_Networks_CVPR_2019_paper.pdf",
        "ref_texts": "[39] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In CVPR , 2018. 3",
        "ref_ids": [
          "39"
        ]
      },
      "Rethinking imagenet pre-training": {
        "authors": [
          "Kaiming He",
          "Ross Girshick",
          "Piotr Dollar"
        ],
        "url": "https://openaccess.thecvf.com/content_ICCV_2019/papers/He_Rethinking_ImageNet_Pre-Training_ICCV_2019_paper.pdf",
        "ref_texts": "[27] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In CVPR , 2018. 3,4",
        "ref_ids": [
          "27"
        ]
      },
      "Context encoding for semantic segmentation": {
        "authors": [
          "Hang Zhang",
          "Kristin Dana",
          "Jianping Shi",
          "Zhongyue Zhang",
          "Xiaogang Wang",
          "Ambrish Tyagi",
          "Amit Agrawal"
        ],
        "url": "http://openaccess.thecvf.com/content_cvpr_2018/papers/Zhang_Context_Encoding_for_CVPR_2018_paper.pdf",
        "ref_texts": ""
      },
      "The apolloscape dataset for autonomous driving": {
        "authors": [
          "Xinyu Huang",
          "Xinjing Cheng",
          "Qichuan Geng",
          "Binbin Cao",
          "Dingfu Zhou",
          "Peng Wang",
          "Yuanqing Lin",
          "Ruigang Yang"
        ],
        "url": "http://openaccess.thecvf.com/content_cvpr_2018_workshops/papers/w14/Huang_The_ApolloScape_Dataset_CVPR_2018_paper.pdf",
        "ref_texts": ""
      },
      "Personlab: Person pose estimation and instance segmentation with a bottom-up, part-based, geometric embedding model": {
        "authors": [
          "George Papandreou",
          "Tyler Zhu",
          "Chieh Chen",
          "Spyros Gidaris",
          "Jonathan Tompson",
          "Kevin Murphy"
        ],
        "url": "https://openaccess.thecvf.com/content_ECCV_2018/papers/George_Papandreou_PersonLab_Person_Pose_ECCV_2018_paper.pdf",
        "ref_texts": "51. Liu, S., Qi, L., Qin, H., Shi, J., Jia, J.: Path aggregation network for instance segmentation. In: CVPR. (2018)",
        "ref_ids": [
          "51"
        ]
      },
      "Sniper: Efficient multi-scale training": {
        "authors": [
          "Bharat Singh",
          "Mahyar Najibi",
          "Larry S. Davis"
        ],
        "url": "https://proceedings.neurips.cc/paper/2018/file/166cee72e93a992007a89b39eb29628b-Paper.pdf",
        "ref_texts": "[22] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia. Path aggregation network for instance segmentation. CVPR , 2018.",
        "ref_ids": [
          "22"
        ]
      },
      "Evaluating the robustness of neural networks: An extreme value theory approach": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1801.10578",
        "ref_texts": ""
      },
      "Deep feature pyramid reconfiguration for object detection": {
        "authors": [
          "Tao Kong",
          "Fuchun Sun",
          "Wenbing Huang",
          "Hua Ping"
        ],
        "url": "https://openaccess.thecvf.com/content_ECCV_2018/papers/Tao_Kong_Deep_Feature_Pyramid_ECCV_2018_paper.pdf",
        "ref_texts": "33. Liu, S., Qi, L., Qin, H., Shi, J., Jia, J.: Path aggregation network for instance segmentation. arXiv preprint arXiv:1803.01534 (2018)",
        "ref_ids": [
          "33"
        ]
      },
      "Weakly-and semi-supervised panoptic segmentation": {
        "authors": [
          "Anurag Arnab",
          "Philip Torr",
          "Qizhu Li"
        ],
        "url": "https://openaccess.thecvf.com/content_ECCV_2018/papers/Anurag_Arnab_Weakly-_and_Semi-Supervised_ECCV_2018_paper.pdf",
        "ref_texts": "25. Liu, S., Qi, L., Qin, H., Shi, J., Jia, J.: Path aggregation network for instance segmentation. In: arXiv preprint arXiv:1803.01534. (2018)",
        "ref_ids": [
          "25"
        ]
      },
      "Learning to fuse things and stuff": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1812.01192",
        "ref_texts": "[25] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia. Path aggregation network for instance segmentation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 8759\u20138768, 2018. 1, 2",
        "ref_ids": [
          "25"
        ]
      },
      "Panoptic segmentation with a joint semantic and instance segmentation network": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1809.02110",
        "ref_texts": "[10] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia. Path Aggregation Network for Instance Segmentation. arXiv preprint arXiv:1803.01534 , Mar. 2018.",
        "ref_ids": [
          "10"
        ]
      },
      "Soft sampling for robust object detection": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1806.06986",
        "ref_texts": "[15] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. CVPR , 2018.",
        "ref_ids": [
          "15"
        ]
      },
      "Instance segmentation by deep coloring": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1807.10007",
        "ref_texts": "[37] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia, \u201cPath aggregation network for instance segmentation,\u201d arXiv preprint arXiv:1803.01534 , 2018.",
        "ref_ids": [
          "37"
        ]
      },
      "Sequential context encoding for duplicate removal": {
        "authors": [
          "Lu Qi",
          "Shu Liu",
          "Jianping Shi",
          "Jiaya Jia"
        ],
        "url": "https://proceedings.neurips.cc/paper_files/paper/2018/file/ce5140df15d046a66883807d18d0264b-Paper.pdf",
        "ref_texts": "[27] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia. Path aggregation network for instance segmentation. CVPR , 2018.",
        "ref_ids": [
          "27"
        ]
      },
      "Solution for large-scale hierarchical object detection datasets with incomplete annotation and data imbalance": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1810.06208",
        "ref_texts": "[15] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia. Path aggregation network for instance segmentation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 8759\u20138768, 2018. 1",
        "ref_ids": [
          "15"
        ]
      },
      "Outline objects using deep reinforcement learning": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1804.04603",
        "ref_texts": "34. Liu, S., Qi, L., Qin, H., Shi, J., Jia, J.: Path aggregation network for instance segmentation. arXiv preprint arXiv:1803.01534 (2018)",
        "ref_ids": [
          "34"
        ]
      },
      "Learning 3D scene semantics and structure from a single depth image": {
        "authors": [
          "Bo Yang",
          "Zihang Lai",
          "Xiaoxuan Lu",
          "Shuyu Lin",
          "Hongkai Wen",
          "Andrew Markham",
          "Niki Trigoni"
        ],
        "url": "http://openaccess.thecvf.com/content_cvpr_2018_workshops/papers/w9/Yang_Learning_3D_Scene_CVPR_2018_paper.pdf",
        "ref_texts": "[12] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia. Path Aggregation Network for Instance Segmentation. CVPR , 2018. 3",
        "ref_ids": [
          "12"
        ]
      },
      "ZoomNet: Deep aggregation learning for high-performance small pedestrian detection": {
        "authors": [],
        "url": "http://proceedings.mlr.press/v95/shang18a/shang18a.pdf",
        "ref_texts": "499 Shang Ai Zhuang Chen Xing T. Kong, F. Sun, A. Yao, H. Liu, M. Lu, and Y. Chen. Ron: Reverse connection with objectness prior networks for object detection. In Proceeding of IEEE Conference of Computer Vision and Pattern Recognition (CVPR) , 2017. J. Li, X. Liang, S. Shen, T. Xu, J. Feng, and S. Yan. Scale-aware fast r-cnn for pedestrian detection. arXiv preprint arXiv:1510.08160 , 2015. X. Li, Z. Jie, W. Wang, C. Liu, J. Yang, X. Shen, Z. Lin, Q. Chen, S. Yan, and J. Feng. Foveanet: Perspective-aware urban scene parsing. arXiv preprint arXiv:1708.02421 , 2017. Z. Li, C. Peng, G. Yu, X. Zhang, Y. Deng, and J. Sun. Detnet: A backbone network for object detection. In Proceeding of European conference on computer vision (ECCV) , 2018. T. Y. Lin, P. Doll\u0013 ar, R. Girshick, K. He, B. Hariharan, and S. Belongie. Feature pyramid networks for object detection. arXiv preprint arXiv:1612.03144 , 2016. S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia. Path aggregation network for instance segmentation. arXiv preprint arXiv:1803.01534 , 2018. W. Liu, D. Anguelov, D. Erhan, C. Szegedy, S. Reed, C. Y. Fu, and A. C. Berg. Ssd: Single shot multibox detector. In Proceeding of European Conference on Computer Vision (ECCV) , 2016. J. Mao, T. Xiao, Y. Jiang, and Z. Cao. What can help pedestrian detection? In Proceeding of IEEE Conference of Computer Vision and Pattern Recognition (CVPR) , 2017. J. Marin, D. V\u0013 azquez, A. M L\u0013 opez, J. Amores, and B. Leibe. Random forests of local experts for pedestrian detection. In Proceeding of IEEE Conference of Computer Vision and Pattern Recognition (CVPR) , 2013. W. Ouyang, H. Zhou, H. Li, Q. Li, J. Yan, and X. Wang. Jointly learning deep features, deformable parts, occlusion and classiffcation for pedestrian detection. IEEE transactions on pattern analysis and machine intelligence (TPAMI) , 40(8):1874{1887, 2018. J. Redmon, S. Divvala, R. Girshick, and A. Farhadi. You only look once: Uniffed, real-time object detection. In Proceeding of IEEE Conference of Computer Vision and Pattern Recognition (CVPR) , 2016. S. Ren, R. He, K.and Girshick, and J. Sun. Faster R-CNN: Towards real-time object detection with region proposal networks. In Proceeding of Advances in Neural Information Processing Systems (NIPS) , 2015. B. Singh and L. S Davis. An analysis of scale invariance in object detection-snip. arXiv preprint arXiv:1711.08189 , 2017. P. Viola and M. Jones. Rapid object detection using a boosted cascade of simple features. InProceeding of IEEE Conference of Computer Vision and Pattern Recognition (CVPR) , 2001."
      },
      "Efficient video understanding via layered multi frame-rate analysis": {
        "authors": [],
        "url": "https://arxiv.org/pdf/1811.09834",
        "ref_texts": "[25] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia. Path aggregation network for instance segmentation,. In CVPR , 2018.",
        "ref_ids": [
          "25"
        ]
      },
      "Deep Learning for Image-based Plant Growth Stage Detection": {
        "authors": [
          "Yezi Zhu"
        ],
        "url": "https://research.tue.nl/files/109393372/CSE_648_Zhu_Y._1034823_Definitief_.pdf",
        "ref_texts": "[40] Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. arXiv preprint arXiv:1803.01534 , 2018. 29",
        "ref_ids": [
          "40"
        ]
      },
      "Deep on Bogot\u00e1's Streets": {
        "authors": [],
        "url": "https://repositorio.uniandes.edu.co/bitstream/1992/39324/1/u821253.pdf",
        "ref_texts": "\"Path aggregation network for instance segmentation.\" \u00a0"
      },
      "YOLO Network-based URL Detection in Varied Conditions with Small-Sample Insights": {
        "authors": [],
        "url": "https://dergipark.org.tr/en/download/article-file/3606576",
        "ref_texts": "20. Shu Liu, Lu Qi, Haifang Qin, Jianping Shi, and Jiaya Jia. Path aggregation network for instance segmentation. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 8759\u20138768, 2018.",
        "ref_ids": [
          "20"
        ]
      },
      "Deep on Bogot\u00e1's streets": {
        "authors": [],
        "url": "https://repositorio.uniandes.edu.co/bitstreams/3b78d50f-07bd-41b6-8171-d4606e52a136/download",
        "ref_texts": "\"Path aggregation network for instance segmentation.\" \u00a0"
      },
      "Exploring Aspects of Image Segmentation: Diversity, Global Reasoning, and Panoptic Formulation": {
        "authors": [],
        "url": "https://archiv.ub.uni-heidelberg.de/volltextserver/25750/1/thesis_kirillov.pdf",
        "ref_texts": "(a) InstanceCut Prediction (b) Ground Truth Figure 5.1: Left car is occluded by the person in front. InstanceCut identifies two split parts of the car as independent car instances. Grouping of connected components. By design InstanceCut inference is not able to recognize instances split by occlusion for several connected components. Instead it recognizes each instance as a separate instance, see Fig. 5.1 for illustration. Note, however, that each connected component segmentation is fine-grained. Hence, instances that split into several connected components can be recovered via some post-processing scheme. In fact, recent instance segmentation work [Liu+17b] that follows the bottomup paradigm has shown that such grouping is quite effective. Making the grouping step a part of the whole training procedure is an interesting direction for future work. End-to-end training. In InstanceCut two FCNs were trained independently to produce per-pixel scores of semantic labels and per-pixel probabilities of instance edges respectively. A unified end-to-end training technique that trains both FCNs together towards the final goal of great instance segmentation performance is a promising direction for future research. In fact, currently neither top-down based methods nor bottom-up methods are fully end-to-end trainable. State-of-the-art top-down approaches like Mask R-CNN [He+17] and the Path Aggregation Network [Liu+18] use Non-Maximal Suppression (NMS) to filter out duplicates. Recent bottom-up approaches for instance segmentation [Liu+17b; BU17; DBNVG17] use a pipeline of neural networks with heuristics on top to produce the final output. As a first step, recent work proposes a fully end-to-end trainable system [Sal+17] based on recurrent neural networks. Some work has been done to make NMS trainable [Hu+18] and to train it together with the whole system. We expect more progress in this direction by the computer vision community in the next few years. Hybrid approach. InstanceCut and more recent bottom-up instance segmentation frameworks have shown great performance being able to segment out heavily occluded 93 objects based on local information like object boundaries. These methods are able to segment such objects even when state-of-the-art recognition approaches (the backbone of top-down approaches) fail to recognize them. At the same time, due to the usage of strong recognition sub-networks, top-down based methods are able to segment out very small and distant objects with very little visual information. These advantages of the two paradigms are, in fact, complementary. This observation is backed by evaluation metrics. Mask R-CNN [He+17] (strong top-down approach) shows 26.2overall average precision (AP) and 40.1AP-50m (AP for objects that are not further than 50meters from the camera). At the same time the state-of-the-art bottom-up approach Sequential Grouping Network [Liu+17b] demonstrates lower overall AP 25.0, showing significantly better performance for close objects \u2013 44.5AP-50m. These numbers imply that the bottom-up approach works better in cases of rich visual information and the recognition system in top-down approaches helps them to work better for other objects. Given this observation, development of a hybrid method that combines both bottom-up and top-down paradigms is a very promising direction for future work. Recently, [Che+17b] proposed a hybrid system for fine-grained instance segmentation."
      }
    }
  },
  {
    "title": "loftr: detector-free local feature matching with transformers",
    "id": 2,
    "valid_pdf_number": "653/811",
    "matched_pdf_number": "0/653",
    "matched_rate": 0.0,
    "citations": {
      "A comprehensive survey on applications of transformers for deep learning tasks": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2306.07303",
        "ref_texts": "4505\u20134514). Association for Computational Linguistics. Su, W., Zhu, X., Cao, Y ., Li, B., Lu, L., Wei, F., & Dai, J. (2020). VL-BERT: pre-training of generic visual-linguistic representations. In 8th International Conference on Learning Representations, ICLR, Addis Ababa, Ethiopia, April 26-30 . OpenReview.net. Subakan, C., Ravanelli, M., Cornell, S., Bronzi, M., & Zhong, J. (2021). Attention is all you need in speech separation. In IEEE International Conference on Acoustics, Speech and Signal Processing, ICASSP, Toronto, ON, Canada, June 6-11 (pp. 21\u201325). IEEE. Subramanyam, K., Rajasekharan, A., & Sangeetha, S. (2021a). Ammu: A survey of transformer-based biomedical pretrained language models. arXiv e-prints , (pp. arXiv\u20132105). Subramanyam, K., Rajasekharan, A., & Sangeetha, S. (2021b). AMMUS : A survey of transformer-based pretrained models in natural language processing. CoRR ,abs/2108.05542 . URL: https://arxiv.org/abs/2108.05542 .arXiv:2108.05542 . Sun, H., Chen, X., Shi, Q., Hong, M., Fu, X., & Sidiropoulos, N. D. (2017). Learning to optimize: Training deep neural networks for wireless resource management. In 18th IEEE International Workshop on Signal Processing Advances in Wireless Communications, SPAWC, Sapporo, Japan, July 3-6 (pp. 1\u20136). IEEE. Sun, J., Shen, Z., Wang, Y ., Bao, H., & Zhou, X. (2021a). Loftr: Detector-free local feature matching with transformers. In IEEE Conference on Computer Vision and Pattern Recognition, CVPR virtual, June 19-25 (pp. 8922\u20138931). Computer Vision Foundation / IEEE. Sun, Q., Fang, N., Liu, Z., Zhao, L., Wen, Y ., Lin, H. et al. (2021b). Hybridctrm: Bridging cnn and transformer for multimodal brain image segmentation. Journal of Healthcare Engineering ,2021 . Suzuki, M., & Matsuo, Y . (2022). A survey of multimodal deep generative models. Adv. Robotics ,36, 261\u2013278. Szummer, M., & Picard, R. W. (1998). Indoor-outdoor image classification. In 1998 International Workshop on Content-Based Access of Image and Video Databases, CAIVD 1998, Bombay, India, January 3, 1998 (pp. 42\u201351). IEEE Computer Society. Tan, H., & Bansal, M. (2019). LXMERT: learning cross-modality encoder representations from transformers. In K. Inui, J. Jiang, V . Ng, & X. Wan (Eds.), Proceedings of the Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing, EMNLP-IJCNLP, Hong Kong, China, November 3-7 (pp. 5099\u20135110). Association for Computational Linguistics. Tas, O., & Kiyani, F. (2007). A survey automatic text summarization. PressAcademia Procedia ,5, 205\u2013213. Tay, Y ., Dehghani, M., Bahri, D., & Metzler, D. (2023). Efficient transformers: A survey. ACM Comput. Surv. ,55, 109:1\u2013109:28. Tay, Y ., Tran, V . Q., Ruder, S., Gupta, J. P., Chung, H. W., Bahri, D., Qin, Z., Baumgartner, S., Yu, C., & Metzler, D. (2022). Charformer: Fast character transformers via gradient-based subword tokenization. In The Tenth International Conference on Learning Representations, ICLR 2022, Virtual Event, April 25-29 . OpenReview.net. Touvron, H., Cord, M., Douze, M., Massa, F., Sablayrolles, A., & J \u00b4egou, H. (2021). Training data-efficient image transformers & distillation through attention. In M. Meila, & T. Zhang (Eds.), Proceedings of the 38th International Conference on Machine Learning, ICML, 18-24 July, Virtual Event (pp. 10347\u201310357). PMLR volume 139 of Proceedings of Machine Learning Research . Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, L., & Polosukhin, I. (2017). Attention is all you need. In I. Guyon, U. von Luxburg, S. Bengio, H. M. Wallach, R. Fergus, S. V . N. Vishwanathan, & R. Garnett (Eds.), Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems, December 4-9, Long Beach, CA, USA (pp. 5998\u20136008). Vig, J., Madani, A., Varshney, L. R., Xiong, C., Socher, R., & Rajani, N. F. (2021). Bertology meets biology: Interpreting attention in protein language models. In 9th International Conference on Learning Representations, ICLR, Virtual Event, Austria, May 3-7 . OpenReview.net. Wang, D., & Chen, J. (2018). Supervised speech separation based on deep learning: An overview. IEEE ACM Trans. Audio Speech Lang. Process. ,26, 1702\u20131726. Wang, G., Smetannikov, I., & Man, T. (2020a). Survey on automatic text summarization and transformer models applicability. In CCRIS: International Conference on Control, Robotics and Intelligent System, Xiamen, China, October 27-29 (pp. 176\u2013184). ACM. Wang, J., Yang, Z., Hu, X., Li, L., Lin, K., Gan, Z., Liu, Z., Liu, C., & Wang, L. (2022a). GIT: A generative image-to-text transformer for vision and language. CoRR ,abs/2205.14100 . URL: https://doi.org/10.48550/arXiv.2205.14100 . doi:10.48550/ arXiv.2205.14100 .arXiv:2205.14100 . Wang, P., Cheng, Y ., & Dong, B. (2021a). Augmented convolutional neural networks with transformer for wireless interference identification. In IEEE Global Communications Conference, GLOBECOM, Madrid, Spain, December 7-11 (pp. 1\u20136). IEEE. Wang, S., Bi, S., & Zhang, Y .-J. A. (2022b). Deep reinforcement learning with communication transformer for adaptive live streaming in wireless edge networks. IEEE Journal on Selected Areas in Communications ,40, 308\u2013322. Wang, T., Lai, Z., & Kong, H. (2021b). Tfnet: Transformer fusion network for ultrasound image segmentation. In C. Wallraven, Q. Liu, & H. Nagahara (Eds.), Pattern Recognition 6th Asian Conference, ACPR, Jeju Island, South Korea, November 9-12, Revised Selected Papers, Part I (pp. 314\u2013325). Springer volume 13188 of Lecture Notes in Computer Science . Wang, T., Lan, J., Han, Z., Hu, Z., Huang, Y ., Deng, Y ., Zhang, H., Wang, J., Chen, M., Jiang, H. et al. (2022c). O-net: a novel framework with deep fusion of cnn and transformer for simultaneous segmentation and classification. Frontiers in Neuroscience ,16. Wang, W., Liang, D., Chen, Q., Iwamoto, Y ., Han, X.-H., Zhang, Q., Hu, H., Lin, L., & Chen, Y .-W. (2020b). Medical image classification using deep learning. Deep learning in healthcare: paradigms and applications , (pp. 33\u201351). Wang, Z., Ma, Y ., Liu, Z., & Tang, J. (2019). R-transformer: Recurrent neural network enhanced transformer. CoRR ,abs/1907.05572 . URL: http://arxiv.org/abs/1907.05572 .arXiv:1907.05572 . Wang, Z., Yu, J., Yu, A. W., Dai, Z., Tsvetkov, Y ., & Cao, Y . (2022d). Simvlm: Simple visual language model pretraining with weak supervision. In The Tenth International Conference on Learning Representations, ICLR, Virtual Event, April 25-29 . OpenReview.net. Wu, D., Pigou, L., Kindermans, P., Le, N. D., Shao, L., Dambre, J., & Odobez, J. (2016). Deep dynamic neural networks for multimodal gesture segmentation and recognition. IEEE Trans. Pattern Anal. Mach. Intell. ,38, 1583\u20131597. Wu, Y ., Wang, G., Wang, Z., Wang, H., & Li, Y . (2022). Di-unet: Dimensional interaction self-attention for medical image segmentation. Biomed. Signal Process. Control. ,78, 103896. Xie, W., Zou, J., Xiao, J., Li, M., & Peng, X. (2022). Quan-transformer based channel feedback for ris-aided wireless communication systems. IEEE Commun. Lett. ,26, 2631\u20132635. Xing, Y ., Shi, Z., Meng, Z., Lakemeyer, G., Ma, Y ., & Wattenhofer, R. (2021). KM-BART: knowledge enhanced multimodal BART for visual commonsense generation. In C. Zong, F. Xia, W. Li, & R. Navigli (Eds.), Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, ACL/IJCNLP, (Volume 1: Long Papers), Virtual Event, August 1-6 (pp. 525\u2013535). Association for Computational Linguistics. Xu, Y ., Wei, H., Lin, M., Deng, Y ., Sheng, K., Zhang, M., Tang, F., Dong, W., Huang, F., & Xu, C. (2022). Transformers in computational visual media: A survey. Computational Visual Media ,8, 33\u201362. Xu, Y ., & Zhao, J. (2022). Actor-critic with transformer for cloud computing resource three stage job scheduling. In 7th International Conference on Cloud Computing and Big Data Analytics (ICCCBDA), Chengdu, China, 22-24 April (pp. 33\u201337). Yan, J., Li, J., Xu, H., Yu, Y ., & Xu, T. (2022a). Seizure prediction based on transformer using scalp electroencephalogram. Applied Sciences ,12, 4158. Yan, S., Wang, C., Chen, W., & Lyu, J. (2022b). Swin transformer-based GAN for multi-modal medical image translation. Frontiers in Oncology ,12. Yan, W., Zhang, Y ., Abbeel, P., & Srinivas, A. (2021). Videogpt: Video generation using VQ-V AE and transformers. CoRR , abs/2104.10157 . URL: https://arxiv.org/abs/2104.10157 .arXiv:2104.10157 . Yang, H., & Yang, D. (2023). Cswin-pnet: A cnn-swin transformer combined pyramid network for breast lesion segmentation in ultrasound images. Expert Syst. Appl. ,Volume 213, Part B , 119024. Yang, M., Lee, D., & Park, S. (2022). Automated diagnosis of atrial fibrillation using ECG component-aware transformer. Comput. Biol. Medicine ,150, 106115. Yeh, C., Mahadeokar, J., Kalgaonkar, K., Wang, Y ., Le, D., Jain, M., Schubert, K., Fuegen, C., & Seltzer, M. L. (2019). Transformertransducer: End-to-end speech recognition with self-attention. CoRR ,abs/1910.12977 . URL: http://arxiv.org/abs/1910."
      },
      "One-2-3-45: Any single image to 3d mesh in 45 seconds without per-shape optimization": {
        "authors": [],
        "url": "https://proceedings.neurips.cc/paper_files/paper/2023/file/4683beb6bab325650db13afd05d1a14a-Paper-Conference.pdf",
        "ref_texts": "[74] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , pages 8922\u20138931, 2021.",
        "ref_ids": [
          "74"
        ]
      },
      "Dust3r: Geometric 3d vision made easy": {
        "authors": [
          "Shuzhe Wang",
          "Vincent Leroy",
          "Yohann Cabon",
          "Boris Chidlovskii",
          "Jerome Revaud"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Wang_DUSt3R_Geometric_3D_Vision_Made_Easy_CVPR_2024_paper.pdf",
        "ref_texts": "[92] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. LoFTR: Detector-free local feature matching with transformers. CVPR , 2021. 1, 2, 6, 7",
        "ref_ids": [
          "92"
        ]
      },
      "Probing the 3d awareness of visual foundation models": {
        "authors": [
          "Mohamed El",
          "Amit Raj",
          "Kokitsi Maninis",
          "Abhishek Kar",
          "Yuanzhen Li",
          "Michael Rubinstein",
          "Deqing Sun",
          "Leonidas Guibas",
          "Justin Johnson",
          "Varun Jampani"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Banani_Probing_the_3D_Awareness_of_Visual_Foundation_Models_CVPR_2024_paper.pdf",
        "ref_texts": "[82] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. LoFTR: Detector-free local feature matching with transformers. CVPR , 2021. 5",
        "ref_ids": [
          "82"
        ]
      },
      "Foundationpose: Unified 6d pose estimation and tracking of novel objects": {
        "authors": [
          "Bowen Wen",
          "Wei Yang",
          "Jan Kautz",
          "Stan Birchfield"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Wen_FoundationPose_Unified_6D_Pose_Estimation_and_Tracking_of_Novel_Objects_CVPR_2024_paper.pdf",
        "ref_texts": "[52] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. LoFTR: Detector-free local feature matching with transformers. In IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) , pages 8922\u20138931, 2021. 6",
        "ref_ids": [
          "52"
        ]
      },
      "Deep patch visual odometry": {
        "authors": [],
        "url": "https://proceedings.neurips.cc/paper_files/paper/2023/file/7ac484b0f1a1719ad5be9aa8c8455fbb-Paper-Conference.pdf",
        "ref_texts": "[34] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , pages 8922\u20138931, 2021.",
        "ref_ids": [
          "34"
        ]
      },
      "Realfill: Reference-driven generation for authentic image completion": {
        "authors": [
          "Luming Tang"
        ],
        "url": "https://dl.acm.org/doi/pdf/10.1145/3658237",
        "ref_texts": "2014. Photo uncrop. In Computer Vision\u2013ECCV 2014: 13th European Conference, Zurich, Switzerland, September 6-12, 2014, Proceedings, Part VI 13 . Springer, 16\u201331. Kihyuk Sohn, Nataniel Ruiz, Kimin Lee, Daniel Castro Chin, Irina Blok, Huiwen Chang, Jarred Barber, Lu Jiang, Glenn Entis, Yuanzhen Li, et al .2023. StyleDrop: Textto-Image Generation in Any Style. ArXiv preprint abs/2306.00983 (2023). https: //arxiv.org/abs/2306.00983 Yang Song, Jascha Sohl-Dickstein, Diederik P. Kingma, Abhishek Kumar, Stefano Ermon, and Ben Poole. 2021. Score-Based Generative Modeling through Stochastic Differential Equations. In 9th International Conference on Learning Representations, ICLR 2021, Virtual Event, Austria, May 3-7, 2021 . OpenReview.net. https://openreview.net/forum?id=PxTIG12RRHS Stability AI. 2022. Stable-Diffusion-2-Inpainting. https://huggingface.co/stabilityai/ stable-diffusion-2-inpainting. Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. 2021. LoFTR: Detector-Free Local Feature Matching With Transformers. In IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2021, virtual, June 19-25, 2021 . Computer Vision Foundation / IEEE, 8922\u20138931. https://doi.org/10.1109/CVPR46437.",
        "ref_ids": [
          "2014"
        ]
      },
      "Motion-i2v: Consistent and controllable image-to-video generation with explicit motion modeling": {
        "authors": [],
        "url": "https://dl.acm.org/doi/pdf/10.1145/3641519.3657497",
        "ref_texts": "2021. Motion Representations for Articulated Animation. In CVPR . Uriel Singer, Adam Polyak, Thomas Hayes, Xi Yin, Jie An, Songyang Zhang, Qiyuan Hu, Harry Yang, Oron Ashual, Oran Gafni, Devi Parikh, Sonal Gupta, and Yaniv Taigman. 2022. Make-A-Video: Text-to-Video Generation without Text-Video Data. arXiv:2209.14792 [cs.CV] Jiaming Song, Chenlin Meng, and Stefano Ermon. 2021. Denoising Diffusion Implicit Models. In International Conference on Learning Representations . https://openreview. net/forum?id=St1giarCHLP Deqing Sun, Stefan Roth, and Michael J Black. 2014. A quantitative analysis of current practices in optical flow estimation and the principles behind them. International Journal of Computer Vision 106, 2 (2014), 115\u2013137. Deqing Sun, Xiaodong Yang, Ming-Yu Liu, and Jan Kautz. 2018. Pwc-net: Cnns for optical flow using pyramid, warping, and cost volume. In Proceedings of the IEEE conference on computer vision and pattern recognition . 8934\u20138943. Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. 2021. LoFTR: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition . 8922\u20138931. Zachary Teed and Jia Deng. 2020. Raft: Recurrent all-pairs field transforms for optical flow. In European conference on computer vision . Springer, 402\u2013419. Jiawei Wang, Yuchen Zhang, Jiaxin Zou, Yan Zeng, Guoqiang Wei, Liping Yuan, and Hang Li. 2024. Boximator: Generating Rich and Controllable Motions for Video Synthesis. arXiv preprint arXiv:2402.01566 (2024). Wen Wang, kangyang Xie, Zide Liu, Hao Chen, Yue Cao, Xinlong Wang, and Chunhua Shen. 2023a. Zero-Shot Video Editing Using Off-The-Shelf Image Diffusion Models. arXiv preprint arXiv:2303.17599 (2023). Xiang* Wang, Hangjie* Yuan, Shiwei* Zhang, Dayou* Chen, Jiuniu Wang, Yingya Zhang, Yujun Shen, Deli Zhao, and Jingren Zhou. 2023c. VideoComposer: Compositional Video Synthesis with Motion Controllability. (2023). Yaohui WANG, Piotr Bilinski, Francois Bremond, and Antitza Dantcheva. 2020. ImaGINator: Conditional Spatio-Temporal GAN for Video Generation. In The IEEE Winter Conference on Applications of Computer Vision (WACV) . Yaohui Wang, Piotr Bilinski, Francois Bremond, and Antitza Dantcheva. 2020. ImaGINator: Conditional Spatio-Temporal GAN for Video Generation. In 2020 IEEE Winter Conference on Applications of Computer Vision (WACV) . 1149\u20131158. https: //doi.org/10.1109/WACV45572.2020.9093492 Yaohui Wang, Di Yang, Francois Bremond, and Antitza Dantcheva. 2022. Latent Image Animator: Learning to Animate Images via Latent Space Navigation. In International Conference on Learning Representations . Zhouxia Wang, Ziyang Yuan, Xintao Wang, Tianshui Chen, Menghan Xia, Ping Luo, and Ying Shan. 2023b. Motionctrl: A unified and flexible motion controller for video generation. arXiv preprint arXiv:2312.03641 (2023). BIAN Weikang, Zhaoyang Huang, Xiaoyu Shi, Yitong Dong, Yijin Li, and Hongsheng Li. 2023. Context-PIPs: Persistent Independent Particles Demands Context Features. InThirty-seventh Conference on Neural Information Processing Systems . Chung-Yi Weng, Brian Curless, and Ira Kemelmacher-Shlizerman. 2018. Photo WakeUp: 3D Character Animation From a Single Photo. 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) (2018), 5901\u20135910. https: //api.semanticscholar.org/CorpusID:54446715 Changming Xiao, Qi Yang, Xiaoqiang Xu, Jianwei Zhang, Feng Zhou, and Changshui Zhang. 2023b. Where you edit is what you get: Text-guided image editing with region-based attention. Pattern Recognition 139 (2023), 109458. Wenpeng Xiao, Wentao Liu, Yitong Wang, Bernard Ghanem, and Bing Li. 2023a. Automatic animation of hair blowing in still portrait photos. In Proceedings of the IEEE/CVF International Conference on Computer Vision . 22963\u201322975. Jinbo Xing, Menghan Xia, Yong Zhang, Haoxin Chen, Wangbo Yu, Hanyuan Liu, Xintao Wang, Tien-Tsin Wong, and Ying Shan. 2023. DynamiCrafter: Animating Open-domain Images with Video Diffusion Priors. arXiv preprint arXiv:2310.12190",
        "ref_ids": [
          "2021"
        ]
      },
      "Driving into the future: Multiview visual forecasting and planning with world model for autonomous driving": {
        "authors": [
          "Yuqi Wang",
          "Jiawei He",
          "Lue Fan",
          "Hongxin Li",
          "Yuntao Chen",
          "Zhaoxiang Zhang"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Wang_Driving_into_the_Future_Multiview_Visual_Forecasting_and_Planning_with_CVPR_2024_paper.pdf",
        "ref_texts": "[56] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In CVPR , pages 8922\u20138931, 2021. 6,20, 21",
        "ref_ids": [
          "56"
        ]
      },
      "Unsupervised semantic correspondence using stable diffusion": {
        "authors": [],
        "url": "https://proceedings.neurips.cc/paper_files/paper/2023/file/1a074a28c3a6f2056562d00649ae6416-Paper-Conference.pdf",
        "ref_texts": "[18] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. LoFTR: Detectorfree local feature matching with transformers. Conference on Computer Vision and Pattern Recognition , 2021.",
        "ref_ids": [
          "18"
        ]
      },
      "NTIRE 2024 challenge on HR depth from images of specular and transparent surfaces": {
        "authors": [
          "Pierluigi Zama",
          "Fabio Tosi",
          "Luigi Di",
          "Radu Timofte",
          "Alex Costanzino",
          "Matteo Poggi",
          "Samuele Salti",
          "Stefano Mattoccia",
          "Yangyang Zhang",
          "Cailin Wu",
          "Zhuangda He",
          "Shuangshuang Yin",
          "Jiaxu Dong",
          "Yangchenxu Liu",
          "Hao Jiang",
          "Jun Shi",
          "Yong A",
          "Yixiang Jin",
          "Dingzhe Li",
          "Bingxin Ke",
          "Anton Obukhov",
          "Tinafu Wang",
          "Nando Metzger",
          "Shengyu Huang",
          "Konrad Schindler",
          "Yachuan Huang",
          "Jiaqi Li",
          "Junrui Zhang",
          "Yiran Wang",
          "Zihao Huang",
          "Tianqi Liu",
          "Zhiguo Cao",
          "Pengzhi Li",
          "Lin Wang",
          "Wenjie Zhu",
          "Hui Geng",
          "Yuxin Zhang",
          "Long Lan",
          "Kele Xu",
          "Tao Sun",
          "Qisheng Xu",
          "Sourav Saini",
          "Aashray Gupta",
          "Sahaj K. Mistry",
          "Aryan Shukla",
          "Vinit Jakhetiya",
          "Sunil Jaiswal",
          "Yuejin Sun",
          "Zhuofan Zheng",
          "Yi Ning",
          "Hao Cheng",
          "I Liu",
          "Wei Huang",
          "Yen Yang",
          "Zhongyu Jiang",
          "Hao Peng",
          "Aishi Huang",
          "Neng Hwang"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024W/NTIRE/papers/Ramirez_NTIRE_2024_Challenge_on_HR_Depth_from_Images_of_Specular_CVPRW_2024_paper.pdf",
        "ref_texts": "[73] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. LoFTR: Detector-free local feature matching with transformers. CVPR , 2021.",
        "ref_ids": [
          "73"
        ]
      },
      "Panacea: Panoramic and controllable video generation for autonomous driving": {
        "authors": [
          "Yuqing Wen",
          "Yucheng Zhao",
          "Yingfei Liu",
          "Fan Jia",
          "Yanhui Wang",
          "Chong Luo",
          "Chi Zhang",
          "Tiancai Wang",
          "Xiaoyan Sun",
          "Xiangyu Zhang"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Wen_Panacea_Panoramic_and_Controllable_Video_Generation_for_Autonomous_Driving_CVPR_2024_paper.pdf",
        "ref_texts": "[39] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2021, virtual, June 1925, 2021 , pages 8922\u20138931. Computer Vision Foundation / IEEE, 2021. 6",
        "ref_ids": [
          "39"
        ]
      },
      "Detector-free structure from motion": {
        "authors": [
          "Xingyi He",
          "Jiaming Sun",
          "Yifan Wang",
          "Sida Peng",
          "Qixing Huang",
          "Hujun Bao",
          "Xiaowei Zhou"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024/papers/He_Detector-Free_Structure_from_Motion_CVPR_2024_paper.pdf",
        "ref_texts": "[44] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. CVPR , 2021. 2, 3, 6, 8",
        "ref_ids": [
          "44"
        ]
      },
      "Sam-6d: Segment anything model meets zero-shot 6d object pose estimation": {
        "authors": [
          "Jiehong Lin",
          "Lihua Liu",
          "Dekun Lu",
          "Kui Jia"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Lin_SAM-6D_Segment_Anything_Model_Meets_Zero-Shot_6D_Object_Pose_Estimation_CVPR_2024_paper.pdf",
        "ref_texts": "[52] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , pages 8922\u20138931, 2021. 3",
        "ref_ids": [
          "52"
        ]
      },
      "RoMa: Robust dense feature matching": {
        "authors": [
          "Johan Edstedt",
          "Qiyu Sun",
          "Georg Bokman",
          "Marten Wadenback",
          "Michael Felsberg"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Edstedt_RoMa_Robust_Dense_Feature_Matching_CVPR_2024_paper.pdf",
        "ref_texts": "[48] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. LoFTR: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 8922\u20138931, 2021. 1, 3, 7, 8",
        "ref_ids": [
          "48"
        ]
      },
      "Optimal transport aggregation for visual place recognition": {
        "authors": [
          "Sergio Izquierdo",
          "Javier Civera"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Izquierdo_Optimal_Transport_Aggregation_for_Visual_Place_Recognition_CVPR_2024_paper.pdf",
        "ref_texts": "[52] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , pages 8922\u20138931, 2021.",
        "ref_ids": [
          "52"
        ]
      },
      "Nerfiller: Completing scenes via generative 3d inpainting": {
        "authors": [
          "Ethan Weber",
          "Aleksander Holynski",
          "Varun Jampani",
          "Saurabh Saxena",
          "Noah Snavely",
          "Abhishek Kar",
          "Angjoo Kanazawa"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Weber_NeRFiller_Completing_Scenes_via_Generative_3D_Inpainting_CVPR_2024_paper.pdf",
        "ref_texts": "[46] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In CVPR , 2021. 7",
        "ref_ids": [
          "46"
        ]
      },
      "Street-view image generation from a bird's-eye view layout": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2301.04634",
        "ref_texts": "[29] J. Sun, Z. Shen, Y . Wang, H. Bao, and X. Zhou, \u201cLoFTR: Detector-Free Local Feature Matching With Transformers,\u201d inIEEE Conference on Computer Vision and Pattern Recognition, CVPR 2021, Virtual, June 19-25, 2021 , 2021, pp. 8922\u2013",
        "ref_ids": [
          "29"
        ]
      },
      "Deepmatcher: a deep transformer-based network for robust and accurate local feature matching": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2301.02993",
        "ref_texts": "[2] J. Sun, Z. Shen, Y . Wang, H. Bao, and X. Zhou, \u201cLoftr: Detectorfree local feature matching with transformers,\u201d in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , 2021, pp. 8922\u20138931.",
        "ref_ids": [
          "2"
        ]
      },
      "POPE: 6-DoF Promptable Pose Estimation of Any Object in Any Scene with One Reference": {
        "authors": [
          "Zhiwen Fan",
          "Panwang Pan",
          "Peihao Wang",
          "Yifan Jiang",
          "Dejia Xu",
          "Zhangyang Wang"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024W/LIMIT/papers/Fan_POPE_6-DoF_Promptable_Pose_Estimation_of_Any_Object_in_Any_CVPRW_2024_paper.pdf",
        "ref_texts": "[53] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , pages 8922\u20138931, 2021. 3, 5, 6, 7",
        "ref_ids": [
          "53"
        ]
      },
      "Steerers: A framework for rotation equivariant keypoint descriptors": {
        "authors": [
          "Georg Bokman",
          "Johan Edstedt",
          "Michael Felsberg",
          "Fredrik Kahl"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Bokman_Steerers_A_Framework_for_Rotation_Equivariant_Keypoint_Descriptors_CVPR_2024_paper.pdf",
        "ref_texts": "[50] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. LoFTR: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 8922\u20138931, 2021. 2,3,7",
        "ref_ids": [
          "50"
        ]
      },
      "DeDoDe: Detect, Don't Describe\u2014Describe, Don't Detect for Local Feature Matching": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2308.08479",
        "ref_texts": "[29] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. LoFTR: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 8922\u20138931, 2021. 6, 8, 11",
        "ref_ids": [
          "29"
        ]
      },
      "Fine-grained cross-view geo-localization using a correlation-aware homography estimator": {
        "authors": [],
        "url": "https://proceedings.neurips.cc/paper_files/paper/2023/file/112d8e0c7563de6e3408b49a09b4d8a3-Paper-Conference.pdf",
        "ref_texts": "[28] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , pages 8922\u20138931, 2021.",
        "ref_ids": [
          "28"
        ]
      },
      "Learning structure-from-motion with graph attention networks": {
        "authors": [
          "Lucas Brynte",
          "Jose Pedro",
          "Carl Olsson",
          "Fredrik Kahl"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Brynte_Learning_Structure-from-Motion_with_Graph_Attention_Networks_CVPR_2024_paper.pdf",
        "ref_texts": "[40] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. LoFTR: Detector-free local feature matching with transformers. In IEEE Conf. Comput. Vis. Pattern Recog. , pages 8922\u20138931, 2021. 8",
        "ref_ids": [
          "40"
        ]
      },
      "Earthloc: Astronaut photography localization by indexing earth from space": {
        "authors": [
          "Gabriele Berton",
          "Alex Stoken",
          "Barbara Caputo",
          "Carlo Masone"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Berton_EarthLoc_Astronaut_Photography_Localization_by_Indexing_Earth_from_Space_CVPR_2024_paper.pdf",
        "ref_texts": "[59] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. LoFTR: Detector-free local feature matching with transformers. CVPR , 2021. 3",
        "ref_ids": [
          "59"
        ]
      },
      "Efficient LoFTR: Semi-dense local feature matching with sparse-like speed": {
        "authors": [
          "Yifan Wang",
          "Xingyi He",
          "Sida Peng",
          "Dongli Tan",
          "Xiaowei Zhou"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Wang_Efficient_LoFTR_Semi-Dense_Local_Feature_Matching_with_Sparse-Like_Speed_CVPR_2024_paper.pdf",
        "ref_texts": "[46] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In CVPR , pages 8922\u20138931, 2021. 1, 2, 4, 5, 6, 7, 8",
        "ref_ids": [
          "46"
        ]
      },
      "Single-stage visual query localization in egocentric videos": {
        "authors": [],
        "url": "https://proceedings.neurips.cc/paper_files/paper/2023/file/4bfe7af38d4e5cd85ae0da639a933652-Paper-Conference.pdf",
        "ref_texts": "[45] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. 2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) , pages 8918\u20138927, 2021.",
        "ref_ids": [
          "45"
        ]
      },
      "Neural Markov Random Field for Stereo Matching": {
        "authors": [
          "Tongfan Guan",
          "Chen Wang",
          "Hui Liu"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Guan_Neural_Markov_Random_Field_for_Stereo_Matching_CVPR_2024_paper.pdf",
        "ref_texts": "[45] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , pages 8922\u20138931, 2021. 2",
        "ref_ids": [
          "45"
        ]
      },
      "Snap: Self-supervised neural maps for visual positioning and semantic understanding": {
        "authors": [],
        "url": "https://proceedings.neurips.cc/paper_files/paper/2023/file/182c433412b33c14e32a7c4fc2c3e290-Paper-Conference.pdf",
        "ref_texts": "[91] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. LoFTR: DetectorFree Local Feature Matching with Transformers. CVPR , 2021. 7",
        "ref_ids": [
          "91"
        ]
      },
      "Gmsf: Global matching scene flow": {
        "authors": [],
        "url": "https://proceedings.neurips.cc/paper_files/paper/2023/file/cb1c4782f159b55380b4584671c4fd88-Paper-Conference.pdf",
        "ref_texts": "[43] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , pages 8922\u20138931, 2021.",
        "ref_ids": [
          "43"
        ]
      },
      "Matchu: Matching unseen objects for 6d pose estimation from rgb-d images": {
        "authors": [
          "Junwen Huang",
          "Hao Yu",
          "Ting Yu",
          "Nassir Navab",
          "Slobodan Ilic",
          "Benjamin Busam"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Huang_MatchU_Matching_Unseen_Objects_for_6D_Pose_Estimation_from_RGB-D_CVPR_2024_paper.pdf",
        "ref_texts": "[46] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In CVPR , 2021. 3, 4",
        "ref_ids": [
          "46"
        ]
      },
      "Revisiting sampson approximations for geometric estimation problems": {
        "authors": [
          "Felix Rydell",
          "Angelica Torres",
          "Viktor Larsson"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Rydell_Revisiting_Sampson_Approximations_for_Geometric_Estimation_Problems_CVPR_2024_paper.pdf",
        "ref_texts": "[25] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In Computer Vision and Pattern Recognition (CVPR) , 2021. 6",
        "ref_ids": [
          "25"
        ]
      },
      "Learning to estimate 6dof pose from limited data: A few-shot, generalizable approach using rgb images": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2306.07598",
        "ref_texts": "[91] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , pages 8922\u20138931, 2021. 3, 4",
        "ref_ids": [
          "91"
        ]
      },
      "Context-PIPs: Persistent Independent Particles Demands Context Features": {
        "authors": [],
        "url": "https://proceedings.neurips.cc/paper_files/paper/2023/file/ad2fa437f7c23e4e9875599c6065d18a-Paper-Conference.pdf",
        "ref_texts": "[36] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 8922\u20138931, 2021.",
        "ref_ids": [
          "36"
        ]
      },
      "Hscnet++: Hierarchical scene coordinate classification and regression for visual localization with transformer": {
        "authors": [
          "Shuzhe Wang"
        ],
        "url": "https://link.springer.com/content/pdf/10.1007/s11263-023-01982-9.pdf",
        "ref_texts": "765). Springer International Publishing. Sattler, T., Leibe, B., & Kobbelt, L. (2016). Efficient & effective prioritized matching for large-scale image-based localization. IEEE Transactions on Pattern Analysis and Machine Intelligence, 39 (9), 1744\u20131756. Sattler, T., Leibe, B., & Kobbelt, L. (2016). Efficient & effective prioritized matching for large-scale image-based localization. IEEE Transactions on Pattern Analysis And Machine Intelligence, 39 (9), 1744\u20131756. Sattler, T., Maddern, W., Toft, C., Torii, A., Hammarstrand, L., Stenborg, E., Safari, D., Okutomi, M., Pollefeys, M., Sivic, J., Kahl,F., Pajdla, T. (2018). Benchmarking 6DoF outdoor visual local-ization in changing conditions. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition (CVPR)(pp. 8601\u20138610). Sattler, T., Zhou, Q., Pollefeys, M. & Leal-Taixe, L. (2019). Understanding the limitations of CNN-based absolute camera pose regression.InProceedings of the IEEE/CVF conference on computer vision and pattern recognition (CVPR) (pp. 3302\u20133312). Sch\u00f6nberger, J.L., Zheng, E., Pollefeys, M. & Frahm, J.M. (2016). Pixelwise view selection for unstructured multi-view stereo. InProceedings of the European conference on computer vision(ECCV) Shavit, Y ., Ferens, R. & Keller, Y . (2021). Learning multi-scene absolute pose regression with transformers. In Proceedings of the IEEE/CVF international conference on computer vision (ICCV)(pp 2733\u20132742). Shavit, Y . & Keller, Y . (2022). Camera pose auto-encoders for improving pose regression. In Proceedings of the European conference on computer vision (ECCV) (pp. 140\u2013157). Springer International Publishing Shotton, J., Glocker, B., Zach, C., Izadi, S., Criminisi, A., & Fitzgibbon, A. (2013). Scene coordinate regression forests for camerarelocalization in RGB-D images. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition (CVPR)(pp. 2930\u20132937). Simo-Serra, E., Trulls, E., Ferraz, L., Kokkinos, I., Fua, P ., & MorenoNoguer, F. (2015). Discriminative learning of deep convolutionalfeature point descriptors. In Proceedings of the IEEE/CVF international conference on computer vision (ICCV) (pp. 118\u2013126). Sun, J., Shen, Z., Wang, Y ., Bao, H. & Xiaowei, Z. (2021). LoFTR: Detector-free local feature matching with transformers. In Pro123"
      },
      "Global Occlusion-Aware Transformer for Robust Stereo Matching": {
        "authors": [
          "Zihua Liu",
          "Yizhou Li",
          "Masatoshi Okutomi"
        ],
        "url": "https://openaccess.thecvf.com/content/WACV2024/papers/Liu_Global_Occlusion-Aware_Transformer_for_Robust_Stereo_Matching_WACV_2024_paper.pdf"
      },
      "Printed smart devices for anti-counterfeiting allowing precise identification with household equipment": {
        "authors": [
          "Junfang Zhang"
        ],
        "url": "https://www.nature.com/articles/s41467-024-45428-3.pdf",
        "ref_texts": "28. Sun, J. et al. LoFTR: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) ,8 9 2 2 \u20138931 (IEEE/ CVF, 2021).",
        "ref_ids": [
          "28"
        ]
      },
      "CBARF: Cascaded Bundle-Adjusting Neural Radiance Fields From Imperfect Camera Poses": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2310.09776",
        "ref_texts": ""
      },
      "VGGSfM: Visual Geometry Grounded Deep Structure From Motion": {
        "authors": [
          "Jianyuan Wang",
          "Nikita Karaev",
          "Christian Rupprecht",
          "David Novotny"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Wang_VGGSfM_Visual_Geometry_Grounded_Deep_Structure_From_Motion_CVPR_2024_paper.pdf",
        "ref_texts": "[64] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , pages 8922\u20138931, 2021. 2, 3",
        "ref_ids": [
          "64"
        ]
      },
      "Global and Hierarchical Geometry Consistency Priors for Few-shot NeRFs in Indoor Scenes": {
        "authors": [
          "Xiaotian Sun",
          "Qingshan Xu",
          "Xinjie Yang",
          "Yu Zang",
          "Cheng Wang"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Sun_Global_and_Hierarchical_Geometry_Consistency_Priors_for_Few-shot_NeRFs_in_CVPR_2024_paper.pdf",
        "ref_texts": "[31] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , pages 8922\u20138931, 2021. 4",
        "ref_ids": [
          "31"
        ]
      },
      "Jigsaw: Learning to assemble multiple fractured objects": {
        "authors": [],
        "url": "https://proceedings.neurips.cc/paper_files/paper/2023/file/30ae2af8612ac74357363e8ae877d80c-Paper-Conference.pdf",
        "ref_texts": "[20] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. LoFTR: Detector-free local feature matching with transformers. CVPR , 2021.",
        "ref_ids": [
          "20"
        ]
      },
      "Gyroflow+: Gyroscope-guided unsupervised deep homography and optical flow learning": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2301.10018",
        "ref_texts": "[86] J. Sun, Z. Shen, Y . Wang, H. Bao, and X. Zhou, \u201cLoftr: Detector-free local feature matching with transformers,\u201d in Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , pp. 8922\u20138931, 2021. 10",
        "ref_ids": [
          "86"
        ]
      },
      "Object Detection in Remote Sensing Images Based on Adaptive Multi-Scale Feature Fusion Method": {
        "authors": [
          "Chun Liu",
          "Sixuan Zhang",
          "Mengjie Hu",
          "Qing Song"
        ],
        "url": "https://www.mdpi.com/2072-4292/16/5/907/pdf",
        "ref_texts": "15. Sun, J.; Shen, Z.; Wang, Y.; Bao, H.; Zhou, X. LoFTR: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, Seattle, WA, USA, 14\u201319 June 2020; pp. 8922\u20138931.",
        "ref_ids": [
          "15"
        ]
      },
      "FAR: Flexible Accurate and Robust 6DoF Relative Camera Pose Estimation": {
        "authors": [
          "Chris Rockwell",
          "Nilesh Kulkarni",
          "Linyi Jin",
          "Jeong Joon",
          "Justin Johnson",
          "David F. Fouhey"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Rockwell_FAR_Flexible_Accurate_and_Robust_6DoF_Relative_Camera_Pose_Estimation_CVPR_2024_paper.pdf",
        "ref_texts": "[67] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. LoFTR: Detector-free local feature matching with transformers. In CVPR , 2021. 1, 2, 3, 5, 6, 7, 8",
        "ref_ids": [
          "67"
        ]
      },
      "Unifying Correspondence Pose and NeRF for Generalized Pose-Free Novel View Synthesis": {
        "authors": [
          "Sunghwan Hong",
          "Jaewoo Jung",
          "Heeseong Shin",
          "Jiaolong Yang",
          "Seungryong Kim",
          "Chong Luo"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Hong_Unifying_Correspondence_Pose_and_NeRF_for_Generalized_Pose-Free_Novel_View_CVPR_2024_paper.pdf",
        "ref_texts": "[54] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , pages 8922\u20138931, 2021. 3",
        "ref_ids": [
          "54"
        ]
      },
      "PuzzleFusion: unleashing the power of diffusion models for spatial puzzle solving": {
        "authors": [],
        "url": "https://proceedings.neurips.cc/paper_files/paper/2023/file/1e70ac91ad26ba5b24cf11b12a1f90fe-Paper-Conference.pdf",
        "ref_texts": "13 Hiroshi Sasaki, Chris G. Willcocks, and Toby P. Breckon. 2021. UNIT-DDPM: UNpaired Image Translation with Denoising Diffusion Probabilistic Models. CoRR abs/2104.05358 (2021). arXiv:2104.05358 https://arxiv.org/abs/2104.05358 Mohammad Amin Shabani, Sepidehsadat Hosseini, and Yasutaka Furukawa. 2022. HouseDiffusion: Vector Floorplan Generation via a Diffusion Model with Discrete and Continuous Denoising. arXiv preprint arXiv:2211.13287 (2022). Mohammad Amin Shabani, Weilian Song, Makoto Odamaki, Hirochika Fujiki, and Yasutaka Furukawa. 2021. Extreme Structure from Motion for Indoor Panoramas without Visual Overlaps. InProceedings of the IEEE/CVF International Conference on Computer Vision (ICCV) .https: //aminshabani.github.io/publications/extreme_sfm/pdfs/iccv2021_2088.pdf Wenkang Shan, Zhenhua Liu, Xinfeng Zhang, Zhao Wang, Kai Han, Shanshe Wang, Siwei Ma, and Wen Gao. 2023. Diffusion-Based 3D Human Pose Estimation with Multi-Hypothesis Aggregation. arXiv preprint arXiv:2303.11579 (2023). Huang-Chia Shih and Chien-Liang Lu. 2018. Divide-and-conquer jigsaw puzzle solving. In 2018 IEEE Visual Communications and Image Processing (VCIP) . IEEE, 1\u20132. Noah Snavely, Steven M Seitz, and Richard Szeliski. 2006. Photo tourism: exploring photo collections in 3D. ACM siggraph (2006), 835\u2013846. Yang Song, Jascha Sohl-Dickstein, Diederik P. Kingma, Abhishek Kumar, Stefano Ermon, and Ben Poole. 2020. Score-Based Generative Modeling through Stochastic Differential Equations. CoRR abs/2011.13456 (2020). arXiv:2011.13456 https://arxiv.org/abs/2011.13456 Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. 2021. LoFTR: DetectorFree Local Feature Matching with Transformers. CVPR (2021). Corey Toler-Franklin, Benedict Brown, Tim Weyrich, Thomas Funkhouser, and Szymon Rusinkiewicz. 2010. Multi-feature matching of fresco fragments. ACM Transactions on Graphics (TOG) 29, 6 (2010), 1\u201312. Qiuhong Anna Wei, Sijie Ding, Jeong Joon Park, Rahul Sajnani, Adrien Poulenard, Srinath Sridhar, and Leonidas Guibas. 2023. LEGO-Net: Learning Regular Rearrangements of Objects in Rooms. arXiv preprint arXiv:2301.09629 (2023). Haim Wolfson, Edith Schonberg, Alan Kalvin, and Yehezkel Lamdan. 1988. Solving jigsaw puzzles by computer. Annals of Operations Research 12, 1 (1988), 51\u201364. Julia Wolleb, Robin Sandk\u00fchler, Florentin Bieder, Philippe Valmaggia, and Philippe C. Cattin. 2021. Diffusion Models for Implicit Image Segmentation Ensembles. (2021). arXiv:cs.CV/2112.03145 Wenming Wu, Xiao-Ming Fu, Rui Tang, Yuhan Wang, Yu-Hao Qi, and Ligang Liu. 2019. Datadriven interior plan generation for residential buildings. ACM Transactions on Graphics (TOG)"
      },
      "Multi-Session SLAM with Differentiable Wide-Baseline Pose Optimization": {
        "authors": [
          "Lahav Lipson",
          "Jia Deng"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Lipson_Multi-Session_SLAM_with_Differentiable_Wide-Baseline_Pose_Optimization_CVPR_2024_paper.pdf",
        "ref_texts": "[41] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , pages 8922\u20138931, 2021. 7",
        "ref_ids": [
          "41"
        ]
      },
      "Enhanced multi-class pathology lesion detection in gastric neoplasms using deep learning-based approach and validation": {
        "authors": [
          "Byeong Soo"
        ],
        "url": "https://www.nature.com/articles/s41598-024-62494-1.pdf",
        "ref_texts": ""
      },
      "Neural Implicit Representation for Building Digital Twins of Unknown Articulated Objects": {
        "authors": [
          "Yijia Weng",
          "Bowen Wen",
          "Jonathan Tremblay",
          "Valts Blukis",
          "Dieter Fox",
          "Leonidas Guibas",
          "Stan Birchfield"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Weng_Neural_Implicit_Representation_for_Building_Digital_Twins_of_Unknown_Articulated_CVPR_2024_paper.pdf"
      },
      "A critical analysis of image-based camera pose estimation techniques": {
        "authors": [
          "Meng Xu",
          "Youchen Wang",
          "Bin Xu",
          "Jun Zhang",
          "Jian Ren",
          "Stefan Poslad",
          "Pengfei Xu"
        ],
        "url": "https://arxiv.org/pdf/2201.05816",
        "ref_texts": ""
      },
      "Species-Agnostic Patterned Animal Re-identification by Aggregating Deep Local Features": {
        "authors": [
          "Ekaterina Nepovinnykh"
        ],
        "url": "https://link.springer.com/content/pdf/10.1007/s11263-024-02071-1.pdf",
        "ref_texts": "2003.1238663 Smeulders, A., Worring, M., Santini, S., et al. (2000). Content-based image retrieval at the end of the early years. IEEE Transactions on Pattern Analysis and Machine Intelligence, 22 , 1349\u20131380. https:// doi.org/10.1109/34.895972 Suessle, V ., Arandjelovic, M., Kalan, A. K., et al. (2023). Automatic individual identification of patterned solitary species based onunlabeled video data. arXiv preprint arXiv:2304.09657 Sun, J., Shen, Z., Wang, Y ., et al. (2021) LoFTR: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition (pp. 8922\u2013"
      },
      "Affine-based Deformable Attention and Selective Fusion for Semi-dense Matching": {
        "authors": [
          "Hongkai Chen",
          "Zixin Luo",
          "Yurun Tian",
          "Xuyang Bai",
          "Ziyu Wang",
          "Lei Zhou",
          "Mingmin Zhen",
          "Tian Fang",
          "David Mckinnon",
          "Yanghai Tsin",
          "Long Quan"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024W/IMW/papers/Chen_Affine-based_Deformable_Attention_and_Selective_Fusion_for_Semi-dense_Matching_CVPRW_2024_paper.pdf"
      },
      "NeRFDeformer: NeRF Transformation from a Single View via 3D Scene Flows": {
        "authors": [
          "Zhenggang Tang",
          "Zhongzheng Ren",
          "Xiaoming Zhao",
          "Bowen Wen",
          "Jonathan Tremblay",
          "Stan Birchfield",
          "Alexander Schwing"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Tang_NeRFDeformer_NeRF_Transformation_from_a_Single_View_via_3D_Scene_CVPR_2024_paper.pdf",
        "ref_texts": "[38] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matchingwith transformers. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , pages 8922\u20138931, 2021. 2",
        "ref_ids": [
          "38"
        ]
      },
      "Novel oct mosaicking pipeline with feature-and pixel-based registration": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2311.13052",
        "ref_texts": "[18] J Sun, Z Shen, Y Wang, H Bao, and X Zhou, \u201cLoftr: Detector-free local feature matching with transformers,\u201d inCVPR , 2021, pp. 8922\u20138931.",
        "ref_ids": [
          "18"
        ]
      },
      "Matching 2D Images in 3D: Metric Relative Pose from Metric Correspondences": {
        "authors": [
          "Axel Barroso",
          "Sowmya Munukutla",
          "Victor Adrian",
          "Eric Brachmann"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Barroso-Laguna_Matching_2D_Images_in_3D_Metric_Relative_Pose_from_Metric_CVPR_2024_paper.pdf",
        "ref_texts": "[67] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. LoFTR: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 8922\u20138931, 2021. 2,3,5,6,7,8",
        "ref_ids": [
          "67"
        ]
      },
      "Sparse Global Matching for Video Frame Interpolation with Large Motion": {
        "authors": [
          "Chunxu Liu",
          "Guozhen Zhang",
          "Rui Zhao",
          "Limin Wang"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Liu_Sparse_Global_Matching_for_Video_Frame_Interpolation_with_Large_Motion_CVPR_2024_paper.pdf",
        "ref_texts": "[31] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , pages 8922\u20138931, 2021. 3",
        "ref_ids": [
          "31"
        ]
      },
      "Map-Relative Pose Regression for Visual Re-Localization": {
        "authors": [
          "Shuai Chen",
          "Tommaso Cavallari",
          "Victor Adrian",
          "Eric Brachmann"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Chen_Map-Relative_Pose_Regression_for_Visual_Re-Localization_CVPR_2024_paper.pdf",
        "ref_texts": "[50] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. LoFTR: Detector-free local feature matching with transformers. CVPR , 2021. 4, 6",
        "ref_ids": [
          "50"
        ]
      },
      "Tame a wild camera: in-the-wild monocular camera calibration": {
        "authors": [],
        "url": "https://proceedings.neurips.cc/paper_files/paper/2023/file/8db9279f593652ee9bb2223b4a2c43fa-Paper-Conference.pdf",
        "ref_texts": "[57] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. LoFTR: Detector-free local feature matching with transformers. In CVPR , 2021. 10",
        "ref_ids": [
          "57"
        ]
      },
      "The NeRFect match: Exploring NeRF features for visual localization": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2403.09577",
        "ref_texts": "59. Sun, J., Shen, Z., Wang, Y., Bao, H., Zhou, X.: Loftr: Detector-free local feature matching with transformers. In: Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. pp. 8922\u20138931 (2021)",
        "ref_ids": [
          "59"
        ]
      },
      "The Unreasonable Effectiveness of Pre-Trained Features for Camera Pose Refinement": {
        "authors": [
          "Gabriele Trivigno",
          "Carlo Masone",
          "Barbara Caputo",
          "Torsten Sattler"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Trivigno_The_Unreasonable_Effectiveness_of_Pre-Trained_Features_for_Camera_Pose_Refinement_CVPR_2024_paper.pdf",
        "ref_texts": "[105] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , pages 8922\u20138931, 2021. 1, 7",
        "ref_ids": [
          "105"
        ]
      },
      "Unifying Feature and Cost Aggregation with Transformers for Semantic and Visual Correspondence": {
        "authors": [],
        "url": "https://openreview.net/pdf?id=fQHb1uZzl7",
        "ref_texts": "12 Published as a conference paper at ICLR 2024 Ignacio Rocco, Mircea Cimpoi, Relja Arandjelovi \u00b4c, Akihiko Torii, Tomas Pajdla, and Josef Sivic. Neighbourhood consensus networks. arXiv preprint arXiv:1810.10510 , 2018. Ignacio Rocco, Relja Arandjelovi \u00b4c, and Josef Sivic. Efficient neighbourhood consensus networks via submanifold sparse convolutions. In ECCV , 2020. Paul-Edouard Sarlin, Daniel DeTone, Tomasz Malisiewicz, and Andrew Rabinovich. Superglue: Learning feature matching with graph neural networks. In CVPR , 2020. Daniel Scharstein and Richard Szeliski. A taxonomy and evaluation of dense two-frame stereo correspondence algorithms. International journal of computer vision , 2002. Johannes L Schonberger and Jan-Michael Frahm. Structure-from-motion revisited. In Proceedings of the IEEE conference on computer vision and pattern recognition , pp. 4104\u20134113, 2016. Thomas Schops, Johannes L Schonberger, Silvano Galliani, Torsten Sattler, Konrad Schindler, Marc Pollefeys, and Andreas Geiger. A multi-view stereo benchmark with high-resolution images and multi-camera videos. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pp. 3260\u20133269, 2017. Xi Shen, Franc \u00b8ois Darmon, Alexei A Efros, and Mathieu Aubry. Ransac-flow: generic two-stage image alignment. In European Conference on Computer Vision , pp. 618\u2013637. Springer, 2020. Richard Sinkhorn. Diagonal equivalence to matrices with prescribed row and column sums. The American Mathematical Monthly , 1967. Xiao Song, Guorun Yang, Xinge Zhu, Hui Zhou, Zhe Wang, and Jianping Shi. Adastereo: A simple and efficient approach for adaptive stereo matching. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pp. 10328\u201310337, 2021. Deqing Sun, Xiaodong Yang, Ming-Yu Liu, and Jan Kautz. Pwc-net: Cnns for optical flow using pyramid, warping, and cost volume. In CVPR , 2018. Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , pp. 8922\u20138931, 2021. Dongli Tan, Jiang-Jiang Liu, Xingyu Chen, Chao Chen, Ruixin Zhang, Yunhang Shen, Shouhong Ding, and Rongrong Ji. Eco-tr: Efficient correspondences finding via coarse-to-fine refinement. InEuropean Conference on Computer Vision , pp. 317\u2013334. Springer, 2022. Engin Tola, Vincent Lepetit, and Pascal Fua. Daisy: An efficient dense descriptor applied to widebaseline stereo. IEEE transactions on pattern analysis and machine intelligence , 32(5):815\u2013830, 2009. Prune Truong, Martin Danelljan, Luc V Gool, and Radu Timofte. Gocor: Bringing globally optimized correspondence volumes into your neural network. Advances in Neural Information Processing Systems , 33:14278\u201314290, 2020a. Prune Truong, Martin Danelljan, and Radu Timofte. Glu-net: Global-local universal network for dense flow and correspondences. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , pp. 6258\u20136268, 2020b. Prune Truong, Martin Danelljan, Luc Van Gool, and Radu Timofte. Learning accurate dense correspondences and when to trust them. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , 2021. Prune Truong, Martin Danelljan, Fisher Yu, and Luc Van Gool. Probabilistic warp consistency for weakly-supervised semantic correspondences. arXiv preprint arXiv:2203.04279 , 2022. Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, \u0141ukasz Kaiser, and Illia Polosukhin. Attention is all you need. In Advances in neural information processing systems , 2017."
      },
      "ColorPCR: Color Point Cloud Registration with Multi-Stage Geometric-Color Fusion": {
        "authors": [
          "Juncheng Mu",
          "Lin Bie",
          "Shaoyi Du",
          "Yue Gao"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Mu_ColorPCR_Color_Point_Cloud_Registration_with_Multi-Stage_Geometric-Color_Fusion_CVPR_2024_paper.pdf",
        "ref_texts": "[23] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. LoFTR: Detector-free local feature matching with transformers. In IEEE Conf. Comput. Vis. Pattern Recog. , pages 8922\u20138931, 2021. 1",
        "ref_ids": [
          "23"
        ]
      },
      "Local feature matching using deep learning: A survey": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2401.17592",
        "ref_texts": "[72] J. Sun, Z. Shen, Y . Wang, H. Bao, X. Zhou, Loftr: Detector-free local feature matching with transformers, in: Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, 2021, pp. 8922\u2013",
        "ref_ids": [
          "72"
        ]
      },
      "Object Reprojection Error (ORE): Camera pose benchmarks from lightweight tracking annotations": {
        "authors": [],
        "url": "https://proceedings.neurips.cc/paper_files/paper/2023/file/eb206443c93d07da8b1974b768d8a0d4-Paper-Datasets_and_Benchmarks.pdf",
        "ref_texts": "[82] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , pages 8922\u20138931, 2021.",
        "ref_ids": [
          "82"
        ]
      },
      "3DFIRES: Few Image 3D REconstruction for Scenes with Hidden Surfaces": {
        "authors": [
          "Linyi Jin",
          "Nilesh Kulkarni",
          "David F. Fouhey"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Jin_3DFIRES_Few_Image_3D_REconstruction_for_Scenes_with_Hidden_Surfaces_CVPR_2024_paper.pdf",
        "ref_texts": "[37] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. LoFTR: Detector-free local feature matching with transformers. CVPR , 2021. 2,8",
        "ref_ids": [
          "37"
        ]
      },
      "DVMNet: Computing Relative Pose for Unseen Objects Beyond Hypotheses": {
        "authors": [
          "Chen Zhao",
          "Tong Zhang",
          "Zheng Dang",
          "Mathieu Salzmann"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Zhao_DVMNet_Computing_Relative_Pose_for_Unseen_Objects_Beyond_Hypotheses_CVPR_2024_paper.pdf",
        "ref_texts": "[31] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 8922\u20138931, 2021. 2,3,6,7,8",
        "ref_ids": [
          "31"
        ]
      },
      "EarthMatch: Iterative Coregistration for Fine-grained Localization of Astronaut Photography": {
        "authors": [
          "Gabriele Berton",
          "Gabriele Goletto",
          "Gabriele Trivigno",
          "Alex Stoken",
          "Barbara Caputo",
          "Carlo Masone"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024W/IMW/papers/Berton_EarthMatch_Iterative_Coregistration_for_Fine-grained_Localization_of_Astronaut_Photography_CVPRW_2024_paper.pdf",
        "ref_texts": "[54] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. LoFTR: Detector-free local feature matching with transformers. CVPR , 2021. 3, 7",
        "ref_ids": [
          "54"
        ]
      },
      "XoFTR: Cross-modal Feature Matching Transformer": {
        "authors": [
          "Onder Tuzcuoglu",
          "Aybora Koksal",
          "Bugra Sofu",
          "Sinan Kalkan",
          "Aydin Alatan"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024W/IMW/papers/Tuzcuoglu_XoFTR_Cross-modal_Feature_Matching_Transformer_CVPRW_2024_paper.pdf",
        "ref_texts": "[69] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , pages 8922\u20138931, 2021. 1,2,3,6,7,8",
        "ref_ids": [
          "69"
        ]
      },
      "DeMatch: Deep Decomposition of Motion Field for Two-View Correspondence Learning": {
        "authors": [
          "Shihua Zhang",
          "Zizhuo Li",
          "Yuan Gao",
          "Jiayi Ma"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2024/papers/Zhang_DeMatch_Deep_Decomposition_of_Motion_Field_for_Two-View_Correspondence_Learning_CVPR_2024_paper.pdf",
        "ref_texts": "[31] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 8922\u2013",
        "ref_ids": [
          "31"
        ]
      },
      "360Loc: A Dataset and Benchmark for Omnidirectional Visual Localization with Cross-device Queries": {
        "authors": [
          "Huajian Huang",
          "Changkun Liu",
          "Yipeng Zhu",
          "Hui Cheng",
          "Tristan Braud",
          "Kit Yeung"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Huang_360Loc_A_Dataset_and_Benchmark_for_Omnidirectional_Visual_Localization_with_CVPR_2024_paper.pdf",
        "ref_texts": "[52] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , pages 8922\u20138931, 2021. 2",
        "ref_ids": [
          "52"
        ]
      },
      "Fast-poly: A fast polyhedral framework for 3d multi-object tracking": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2403.13443",
        "ref_texts": ""
      },
      "XFeat: Accelerated Features for Lightweight Image Matching": {
        "authors": [
          "Guilherme Potje",
          "Felipe Cadar",
          "Andre Araujo",
          "Renato Martins",
          "Erickson R. Nascimento"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Potje_XFeat_Accelerated_Features_for_Lightweight_Image_Matching_CVPR_2024_paper.pdf",
        "ref_texts": "[40] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In CVPR , pages 8922\u20138931, 2021. 1, 2, 4, 5, 6",
        "ref_ids": [
          "40"
        ]
      },
      "SplatPose & Detect: Pose-Agnostic 3D Anomaly Detection": {
        "authors": [
          "Mathis Kruse",
          "Marco Rudolph",
          "Dominik Woiwode",
          "Bodo Rosenhahn"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024W/VAND/papers/Kruse_SplatPose__Detect_Pose-Agnostic_3D_Anomaly_Detection_CVPRW_2024_paper.pdf",
        "ref_texts": "[38] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2021, virtual, June 1925, 2021 , pages 8922\u20138931. Computer Vision Foundation / IEEE, 2021. 3, 6",
        "ref_ids": [
          "38"
        ]
      },
      "SOS-SLAM: Segmentation for Open-Set SLAM in Unstructured Environments": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2401.04791",
        "ref_texts": "[35] J. Sun, Z. Shen, Y . Wang, H. Bao, and X. Zhou, \u201cLoFTR: Detectorfree local feature matching with transformers,\u201d CVPR , 2021.",
        "ref_ids": [
          "35"
        ]
      },
      "Large Spatial Model: End-to-end Unposed Images to Semantic 3D": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2410.18956",
        "ref_texts": "[51] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , pages 8922\u20138931, 2021.",
        "ref_ids": [
          "51"
        ]
      },
      "Kick Back & Relax++: Scaling Beyond Ground-Truth Depth with SlowTV & CribsTV": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2403.01569",
        "ref_texts": ""
      },
      "Eto: Efficient transformer-based local feature matching by organizing multiple homography hypotheses": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2410.22733",
        "ref_texts": "[20] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 8922\u20138931, 2021.",
        "ref_ids": [
          "20"
        ]
      },
      "Playing to Vision Foundation Model's Strengths in Stereo Matching": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2404.06261",
        "ref_texts": "[26] J. Sun et al. , \u201cLoFTR: Detector-free local feature matching with Transformers,\u201d in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) , 2021, pp. 8922\u20138931.",
        "ref_ids": [
          "26"
        ]
      },
      "From Correspondences to Pose: Non-minimal Certifiably Optimal Relative Pose without Disambiguation": {
        "authors": [
          "Javier Tirado",
          "Javier Civera"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Tirado-Garin_From_Correspondences_to_Pose_Non-minimal_Certifiably_Optimal_Relative_Pose_without_CVPR_2024_paper.pdf",
        "ref_texts": "[58] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In CVPR, 2021. 1",
        "ref_ids": [
          "58"
        ]
      },
      "Dynamic Cues-Assisted Transformer for Robust Point Cloud Registration": {
        "authors": [
          "Hong Chen",
          "Pei Yan",
          "Sihe Xiang",
          "Yihua Tan"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Chen_Dynamic_Cues-Assisted_Transformer_for_Robust_Point_Cloud_Registration_CVPR_2024_paper.pdf",
        "ref_texts": "[24] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In CVPR , pages 8922\u20138931, 2021. 6",
        "ref_ids": [
          "24"
        ]
      },
      "Learning to Produce Semi-dense Correspondences for Visual Localization": {
        "authors": [
          "Khang Truong",
          "Soohwan Song",
          "Sungho Jo"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Giang_Learning_to_Produce_Semi-dense_Correspondences_for_Visual_Localization_CVPR_2024_paper.pdf",
        "ref_texts": "[53] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , pages 8922\u20138931, 2021. 1, 2, 3, 8",
        "ref_ids": [
          "53"
        ]
      },
      "DeDoDe v2: Analyzing and Improving the DeDoDe Keypoint Detector": {
        "authors": [
          "Johan Edstedt",
          "Georg Bokman",
          "Zhenjun Zhao"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024W/IMW/papers/Edstedt_DeDoDe_v2_Analyzing_and_Improving_the_DeDoDe_Keypoint_Detector_CVPRW_2024_paper.pdf",
        "ref_texts": "[25] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. LoFTR: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 8922\u20138931, 2021. 2, 5",
        "ref_ids": [
          "25"
        ]
      },
      "Doduo: Learning dense visual correspondence from unsupervised semantic-aware flow": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2309.15110",
        "ref_texts": "[18] J. Sun, Z. Shen, Y . Wang, H. Bao, and X. Zhou, \u201cLoftr: Detector-free local feature matching with transformers,\u201d 2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) , pp. 8918\u20138927, 2021.[19] W. Jiang, E. Trulls, J. H. Hosang, A. Tagliasacchi, and K. M. Yi, \u201cCotr: Correspondence transformer for matching across images,\u201d 2021 IEEE/CVF International Conference on Computer Vision (ICCV) , pp.",
        "ref_ids": [
          "18",
          "19"
        ]
      },
      "Fusing Personal and Environmental Cues for Identification and Segmentation of First-Person Camera Wearers in Third-Person Views": {
        "authors": [
          "Ziwei Zhao",
          "Yuchen Wang",
          "Chuhua Wang"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Zhao_Fusing_Personal_and_Environmental_Cues_for_Identification_and_Segmentation_of_CVPR_2024_paper.pdf",
        "ref_texts": "[44] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , pages 8922\u20138931, 2021. 2",
        "ref_ids": [
          "44"
        ]
      },
      "RadarCam-Depth: Radar-Camera Fusion for Depth Estimation with Learned Metric Scale": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2401.04325",
        "ref_texts": "[32] J. Sun, Z. Shen, Y . Wang, H. Bao, and X. Zhou. \u201cLoFTR: Detector-free local feature matching with transformers\u201d. In:Proceedings of the IEEE/CVF conference on computer vision and pattern recognition . 2021, pp. 8922\u20138931.",
        "ref_ids": [
          "32"
        ]
      },
      "A Survey on Monocular Re-Localization: From the Perspective of Scene Map Representation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2311.15643",
        "ref_texts": "[161] J. Sun, Z. Shen, Y . Wang, H. Bao, and X. Zhou, \u201cLoftr: Detector-free local feature matching with transformers,\u201d in Proceedings of IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) , pp. 8918\u20138927, 2021.",
        "ref_ids": [
          "161"
        ]
      },
      "Robust Self-calibration of Focal Lengths from the Fundamental Matrix": {
        "authors": [
          "Viktor Kocur",
          "Daniel Kyselica",
          "Zuzana Kukelova"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Kocur_Robust_Self-calibration_of_Focal_Lengths_from_the_Fundamental_Matrix_CVPR_2024_paper.pdf",
        "ref_texts": "[43] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , pages 8922\u20138931, 2021. 7",
        "ref_ids": [
          "43"
        ]
      },
      "FC-GNN: Recovering Reliable and Accurate Correspondences from Interferences": {
        "authors": [
          "Haobo Xu",
          "Jun Zhou",
          "Hua Yang",
          "Renjie Pan",
          "Cunyan Li"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Xu_FC-GNN_Recovering_Reliable_and_Accurate_Correspondences_from_Interferences_CVPR_2024_paper.pdf",
        "ref_texts": "[40] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In CVPR , 2021. 2, 7",
        "ref_ids": [
          "40"
        ]
      },
      "A point cloud registration framework with color information integration": {
        "authors": [
          "Tianyu Han",
          "Ruijie Zhang",
          "Jiangming Kan",
          "Ruifang Dong",
          "Xixuan Zhao",
          "Shun Yao"
        ],
        "url": "https://www.mdpi.com/2072-4292/16/5/743/pdf",
        "ref_texts": "16. Sun, J.; Shen, Z.; Wang, Y.; Bao, H.; Zhou, X. LoFTR: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, Nashville, TN, USA, 20\u201325 June 2021; pp. 8922\u20138931.",
        "ref_ids": [
          "16"
        ]
      },
      "DITTO: Demonstration Imitation by Trajectory Transformation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2403.15203",
        "ref_texts": "[8] J. Sun, Z. Shen, Y . Wang, H. Bao, and X. Zhou, \u201cLoftr: Detector-free local feature matching with transformers,\u201d Proc. IEEE Conf. Comput. Vis. Pattern Recog. , pp. 8918\u20138927, 2021.",
        "ref_ids": [
          "8"
        ]
      },
      "(Street) Lights Will Guide You: Georeferencing Nighttime Astronaut Photography of Earth": {
        "authors": [
          "Alex Stoken",
          "Peter Ilhardt",
          "Mark Lambert",
          "Kenton Fisher"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024W/EarthVision/papers/Stoken_Street_Lights_Will_Guide_You_Georeferencing_Nighttime_Astronaut_Photography_of_CVPRW_2024_paper.pdf",
        "ref_texts": "[42] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. LoFTR: Detector-free local feature matching with transformers. CVPR, 2021. 3",
        "ref_ids": [
          "42"
        ]
      },
      "Radiation-Variation Insensitive Coarse-to-Fine Image Registration for Infrared and Visible Remote Sensing Based on Zero-Shot Learning": {
        "authors": [
          "Jiaqi Li",
          "Guoling Bi",
          "Xiaozhen Wang",
          "Ting Nie",
          "Liang Huang"
        ],
        "url": "https://www.mdpi.com/2072-4292/16/2/214/pdf",
        "ref_texts": "31. Sun, J.M.; Shen, Z.H.; Wang, Y.A.; Bao, H.J.; Zhou, X.W.; IEEE Computer Society. LoFTR: Detector-Free Local Feature Matching with Transformers. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), Nashville, TN, USA, 20\u201325 June 2021; pp. 8918\u20138927.",
        "ref_ids": [
          "31"
        ]
      },
      "RIDE: Self-supervised learning of rotation-equivariant keypoint detection and invariant description for endoscopy": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2309.09563",
        "ref_texts": "[35] J. Sun, Z. Shen, Y . Wang, H. Bao, and X. Zhou, \u201cLoftr: Detectorfree local feature matching with transformers,\u201d in Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , 2021, pp. 8922\u20138931.",
        "ref_ids": [
          "35"
        ]
      },
      "Evit: Privacy-preserving image retrieval via encrypted vision transformer in cloud computing": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2208.14657",
        "ref_texts": "[71] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. 2021. LoFTR: Detector-Free Local Feature Matching With Transformers. InIEEE Conference on Computer Vision and Pattern Recognition, CVPR 2021 . Computer Vision Foundation / IEEE, 8922\u20138931.",
        "ref_ids": [
          "71"
        ]
      },
      "Fully Geometric Panoramic Localization": {
        "authors": [
          "Junho Kim",
          "Jiwon Jeong",
          "Young Min"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Kim_Fully_Geometric_Panoramic_Localization_CVPR_2024_paper.pdf",
        "ref_texts": "[51] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. LoFTR: Detector-free local feature matching with transformers. CVPR , 2021. 7",
        "ref_ids": [
          "51"
        ]
      },
      "ColonMapper: topological mapping and localization for colonoscopy": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2305.05546",
        "ref_texts": "[26] J. Sun, Z. Shen, Y . Wang, H. Bao, and X. Zhou, \u201cLoFTR: Detector-free local feature matching with transformers,\u201d CVPR , 2021.",
        "ref_ids": [
          "26"
        ]
      },
      "Efficient object rearrangement via multi-view fusion": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2309.08994",
        "ref_texts": "[30] J. Sun, Z. Shen, Y . Wang, H. Bao, and X. Zhou, \u201cLoFTR: Detectorfree local feature matching with transformers,\u201d in Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , 2021, pp. 8922\u20138931.",
        "ref_ids": [
          "30"
        ]
      },
      "Neural Refinement for Absolute Pose Regression with Feature Synthesis": {
        "authors": [
          "Shuai Chen",
          "Yash Bhalgat",
          "Xinghui Li",
          "Wang Bian",
          "Kejie Li",
          "Zirui Wang",
          "Victor Adrian"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Chen_Neural_Refinement_for_Absolute_Pose_Regression_with_Feature_Synthesis_CVPR_2024_paper.pdf",
        "ref_texts": "[54] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. LoFTR: Detector-free local feature matching with transformers. CVPR , 2021. 2, 3",
        "ref_ids": [
          "54"
        ]
      },
      "Retinal IPA: Iterative KeyPoints Alignment for Multimodal Retinal Imaging": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2407.18362",
        "ref_texts": "26. Sun, J., Shen, Z., Wang, Y., Bao, H., Zhou, X.: Loftr: Detector-free local feature matching with transformers. In: Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. pp. 8922\u20138931 (2021)",
        "ref_ids": [
          "26"
        ]
      },
      "Transplat: Generalizable 3d gaussian splatting from sparse multi-view images with transformers": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2408.13770",
        "ref_texts": "10695. Shi, R.; Wei, X.; Wang, C.; and Su, H. 2024. ZeroRF: Fast Sparse View 360deg Reconstruction with Zero Pretraining. InProceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , 21114\u201321124. Sun, J.; Shen, Z.; Wang, Y .; Bao, H.; and Zhou, X. 2021. LoFTR: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , 8922\u20138931. Truong, P.; Rakotosaona, M.-J.; Manhardt, F.; and Tombari, F. 2023. Sparf: Neural radiance fields from sparse and noisy poses. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , 4190\u20134200. Wang, P.; Chen, X.; Chen, T.; Venugopalan, S.; Wang, Z.; et al. 2022a. Is Attention All That NeRF Needs? arXiv preprint arXiv:2207.13298 . Wang, X.; Zhu, Z.; Huang, G.; Qin, F.; Ye, Y .; He, Y .; Chi, X.; and Wang, X. 2022b. Mvster: Epipolar transformer for efficient multi-view stereo. In European Conference on Computer Vision , 573\u2013591. Springer. Wang, Z.; Bovik, A. C.; Sheikh, H. R.; and Simoncelli, E. P.",
        "ref_ids": [
          "10695"
        ]
      },
      "ADFactory: An Effective Framework for Generalizing Optical Flow with NeRF": {
        "authors": [
          "Han Ling",
          "Quansen Sun",
          "Yinghui Sun",
          "Xian Xu",
          "Xinfeng Li"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Ling_ADFactory_An_Effective_Framework_for_Generalizing_Optical_Flow_with_NeRF_CVPR_2024_paper.pdf",
        "ref_texts": "[32] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition (CVPR) , pages 8922\u20138931, 2021. 2",
        "ref_ids": [
          "32"
        ]
      },
      "Image matching by bare homography": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2305.08946",
        "ref_texts": "[4] J. Sun, Z. Shen, Y . Wang, H. Bao, and X. Zhou, \u201cLoFTR: Detector-free local feature matching with transformers,\u201d in Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit. (CVPR) , 2021.",
        "ref_ids": [
          "4"
        ]
      },
      "MESA: Matching Everything by Segmenting Anything": {
        "authors": [
          "Yesheng Zhang",
          "Xu Zhao"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Zhang_MESA_Matching_Everything_by_Segmenting_Anything_CVPR_2024_paper.pdf",
        "ref_texts": "[40] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. LoFTR: Detector-free local feature matching with transformers. CVPR , 2021. 1,2,5,6,7,8,3,4",
        "ref_ids": [
          "40"
        ]
      },
      "WildFusion: Individual animal identification with calibrated similarity fusion": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2408.12934",
        "ref_texts": "57. Sun, J., Shen, Z., Wang, Y., Bao, H., Zhou, X.: LoFTR: Detector-free local feature matching with transformers. In: Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. pp. 8922\u20138931 (2021)",
        "ref_ids": [
          "57"
        ]
      },
      "Zero123-6d: Zero-shot novel view synthesis for rgb category-level 6d pose estimation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2403.14279",
        "ref_texts": "[35] J. Sun, Z. Shen, Y . Wang, H. Bao, and X. Zhou, \u201cLoftr: Detectorfree local feature matching with transformers,\u201d in Proceedings ofthe IEEE/CVF conference oncomputer vision and pattern recognition, 2021, pp. 8922\u20138931.",
        "ref_ids": [
          "35"
        ]
      },
      "Lfm-3d: Learnable feature matching across wide baselines using 3d signals": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2303.12779",
        "ref_texts": "[41] J. Sun, Z. Shen, Y . Wang, H. Bao, and X. Zhou. LoFTR: Detector-Free Local Feature Matching with Transformers. In Proc. CVPR , 2021. 2, 3, 6",
        "ref_ids": [
          "41"
        ]
      },
      "MCPDepth: Omnidirectional Depth Estimation via Stereo Matching from Multi-Cylindrical Panoramas": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2408.01653",
        "ref_texts": "[39] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. LoFTR: Detector-free local feature matching with transformers. CVPR , 2021. 3[40] Vladimir Tankovich, Christian Hane, Yinda Zhang, Adarsh Kowdle, Sean Fanello, and Sofien Bouaziz. Hitnet: Hierarchical iterative tile refinement network for real-time stereo matching. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 14362\u2013",
        "ref_ids": [
          "39",
          "40"
        ]
      },
      "Mismatched: Evaluating the Limits of Image Matching Approaches and Benchmarks": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2408.16445",
        "ref_texts": "42. Sun, J., Shen, Z., Wang, Y., Bao, H., Zhou, X.: Loftr: Detector-free local feature matching with transformers. In: Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. pp. 8922\u20138931 (2021). https://doi.org/10.",
        "ref_ids": [
          "42"
        ]
      },
      "Revisiting RGBT Tracking Benchmarks from the Perspective of Modality Validity: A New Benchmark, Problem, and Method": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2405.00168",
        "ref_texts": "[29] J. Sun, Z. Shen, Y . Wang, H. Bao, and X. Zhou, \u201cLoftr: Detectorfree local feature matching with transformers,\u201d in Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , 2021, pp. 8922\u20138931.",
        "ref_ids": [
          "29"
        ]
      },
      "Deep-image-matching: a toolbox for multiview image matching of complex scenarios": {
        "authors": [],
        "url": "https://isprs-archives.copernicus.org/articles/XLVIII-2-W4-2024/309/2024/isprs-archives-XLVIII-2-W4-2024-309-2024.pdf",
        "ref_texts": "835-846. Sun, J., Shen, Z., Wang, Y., Bao, H. and Zhou, X., 2021. LoFTR: Detector -free local feature matching with transformers. Proc. CVPR, pp. 8922 -8931. Tyszkiewicz, M., Fua, P. and Trulls, E., 2020. DISK: Learning local features with policy gradient. Advances in Neural Information Processing Systems, 33, pp.14254 -14265. Vincent, M. L., Coughenour, C., Flores Gutierrez, M., LopezMenchero Bendicho, V. M., Remondino, F., Frtisch , D., "
      },
      "Quantity-aware coarse-to-fine correspondence for image-to-point cloud registration": {
        "authors": [],
        "url": "https://researchportal.hw.ac.uk/files/141460014/Quantity-Aware_Coarse-to-Fine_Correspondence_for_Image-to-Point_Cloud_Registration.pdf"
      },
      "Gs-pose: Cascaded framework for generalizable segmentation-based 6d object pose estimation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2403.10683",
        "ref_texts": "[46] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , pages 8922\u20138931, 2021. 8",
        "ref_ids": [
          "46"
        ]
      },
      "Maplocnet: Coarse-to-fine feature registration for visual re-localization in navigation maps": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2407.08561",
        "ref_texts": "[41] J. Sun, Z. Shen, Y . Wang, H. Bao, and X. Zhou, \u201cLoFTR: Detector-free local feature matching with transformers,\u201d CVPR , 2021.",
        "ref_ids": [
          "41"
        ]
      },
      "Deep Learning Low-cost Photogrammetry for 4D Short-term Glacier Dynamics Monitoring": {
        "authors": [],
        "url": "https://link.springer.com/content/pdf/10.1007/s41064-023-00272-w.pdf",
        "ref_texts": "10.1029/2009JF001509Sun J, Shen Z, Wang Y , Bao H, Zhou X (2021) LoFTR: Detector-free local feature matching with transformers. In: Proc. CVPR IEEE Taylor LS, Quincey DJ, Smith MW (2023) Evaluation of low-cost raspberry pi sensors for structure-from-motion reconstructions ofglacier calving fronts. Nat Hazards Earth Sys 23(1):329\u2013341. htt ps://doi.org/10.5194/nhess-23-329-2023 Tonolo GF, Cina A, Manzino A, Fronteddu M (2020) 3D glacier mapping by means of satellite stereo images: the Belvedere Glaciercase study in the Italian Alps. The International Archives of thePhotogrammetry, Remote Sensing and Spatial Information Sci-ences, vol XLIII-B2-2020. https://doi.org/10.5194/isprs-archivesXLIII-B2-2020-1073-2020 Travelletti J, Delacourt C, Allemand P , Malet JP , Schmittbuhl J, Toussaint R, Bastard M (2012) Correla tion of multi-te mporal groundbased optical images for landslide monitoring: Application,potential and limitations. ISPRS J Photogramm Remote Sens70:39\u201355. https://doi.org/10.1016/j.isprsjprs.2012.03.007 Tsai DY , Lee Y , Matsuyama E (2008) Information entropy measure for evaluation of ima ge qua lity. J Digit I maging 21:338\u2013347. https:// doi.org/10.1007/s10278-007-9044-5 Vaswani A, Shazeer N, Parmar N, Uszkoreit J, Jones L, Gomez AN, Kaiser L, Polosukhin I (2023) Attention is all you need.1706.03762 Vincent C, Moreau L et al (2016) Sliding velocity fluctuations and subglacial hydrology over the last two decades on argenti\u00e8re glacier,mont blanc area. J Glaciol 62:805\u2013815. https://doi.org/10.1017/ jog.2016.35 V oordendag A, Goger B, Klug C, Prinz R, Rutzinger M, Sauter T, Kaser G (2023) Uncertainty assessment of a permanent long-range terrestrial laser scanning system for the quantification ofsnow dynamics on hintereisferner (Austria). Front Earth Sci.https://doi.org/10.3389/feart.2023.1085416 Willis IC (1995) Intra-annual variations in glacier motion: a review. Prog Phys Geogr 19:61\u2013106. https://doi.org/10.1177/"
      },
      "Tracking Everything in Robotic-Assisted Surgery": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2409.19821",
        "ref_texts": "[40] J. Sun, Z. Shen, Y . Wang, H. Bao, and X. Zhou, \u201cLoftr: Detectorfree local feature matching with transformers,\u201d in Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , 2021, pp. 8922\u20138931.",
        "ref_ids": [
          "40"
        ]
      },
      "HOLD: Category-agnostic 3d reconstruction of interacting hands and objects from video": {
        "authors": [
          "Zicong Fan",
          "Maria Parelli",
          "Maria Eleni",
          "Xu Chen",
          "Muhammed Kocabas",
          "Michael J. Black",
          "Otmar Hilliges"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Fan_HOLD_Category-agnostic_3D_Reconstruction_of_Interacting_Hands_and_Objects_from_CVPR_2024_paper.pdf",
        "ref_texts": "[57] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. LoFTR: Detector-free local feature matching with transformers. Computer Vision and Pattern Recognition (CVPR) , 2021. 8",
        "ref_ids": [
          "57"
        ]
      },
      "Sound3DVDet: 3D Sound Source Detection using Multiview Microphone Array and RGB Images": {
        "authors": [
          "Yuhang He",
          "Sangyun Shin",
          "Anoop Cherian",
          "Niki Trigoni",
          "Andrew Markham"
        ],
        "url": "https://openaccess.thecvf.com/content/WACV2024/papers/He_Sound3DVDet_3D_Sound_Source_Detection_Using_Multiview_Microphone_Array_and_WACV_2024_paper.pdf",
        "ref_texts": "[65] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. LoFTR: Detector-Free Local Feature Matching with Transformers. IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) , 2021. 2, 5, 8",
        "ref_ids": [
          "65"
        ]
      },
      "UDC-SIT: a real-world dataset for under-display cameras": {
        "authors": [],
        "url": "https://proceedings.neurips.cc/paper_files/paper/2023/file/d612971396f825dbf8e0e736f99a1955-Paper-Datasets_and_Benchmarks.pdf",
        "ref_texts": "[42] Jiaming Sun et al. \u201cLoFTR: Detector-free local feature matching with transformers\u201d. In: Proceedings of the IEEE/CVF conference on computer vision and pattern recognition . 2021, pp. 8922\u20138931.",
        "ref_ids": [
          "42"
        ]
      },
      "Topological SLAM in colonoscopies leveraging deep features and topological priors": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2409.16806",
        "ref_texts": "28. Sun, J., Shen, Z., Wang, Y., Bao, H., Zhou, X.: LoFTR: Detector-free local feature matching with transformers. CVPR (2021)",
        "ref_ids": [
          "28"
        ]
      },
      "GauStudio: A Modular Framework for 3D Gaussian Splatting and Beyond": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2403.19632",
        "ref_texts": "[42] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , 2021. 4",
        "ref_ids": [
          "42"
        ]
      },
      "Comparative Analysis of Novel View Synthesis and Photogrammetry for 3D Forest Stand Reconstruction and extraction of individual tree parameters": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2410.05772",
        "ref_texts": "14, e0211392. Croce, V., Caroti, G., De Luca, L., Piemonte, A., V\u00e9 ron, P., 2023. Neural radiance fields (nerf): Review and potential applic ations to digital cultural heritage. The International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences 48, 453 -460. Fan, Z., Cong, W., Wen, K., Wang, K., Zhang, J., Ding, X., Xu, D., Ivanovic, B., Pavone, M., Pavlakos, G., 20 24. Instantsplat: Unbounded sparse -view pose -free gaussian splatting in 40 seconds. arXiv preprint arXiv:20309. Hu, K., Ying, W., Pan, Y., Kang, H., Chen, C., 2024. High -fidelity 3D reconstruction of plants using Neural Radiance Fields. Computers Electroni cs in Agriculture 220, 108848. Huang, H., Tian, G., Chen, C., 2024. Evaluating the point cloud of individual trees generated from images based on Neural Radiance fields (NeRF) method. Remote Sensing 16, 967. Jaskierniak, D., Lucieer, A., Kuczera, G., Turne r, D., Lane, P., Benyon, R., Haydon, S., 2021. Individual tree detection and crown delineation from Unmanned Aircraft System (UAS) LiDAR in structurally complex mixed species eucalypt forests. ISPRS Journal of Photogrammetry Remote Sensing 171, 171 -187. Kameyama, S., Sugiura, K., 2020. Estimating tree height and volume using unmanned aerial vehicle photography and SfM technology, with verification of result accuracy. Drones 4, 19. Kankare, V., Joensuu, M., Vauhkonen, J., Holopainen, M., Tanhuanp\u00e4 \u00e4 , T., Vast aranta, M., Hyypp\u00e4 , J., Hyypp\u00e4 , H., Alho, P., Rikala, J., 2014. Estimation of the timber quality of Scots pine with terrestrial laser scanning. Forests 5, 1879 -1895. Kerbl, B., Kopanas, G., Leimk\u00fc hler, T., Drettakis, G., 2023. 3D Gaussian Splatting for Rea l-Time Radiance Field Rendering. ACM Transactions on Graphics 42, 139:131 -139:114. Liang, X., Kukko, A., Balenovi\u0107, I., Saarinen, N., Junttila, S., Kankare, V., Holopainen, M., Mokro\u0161, M., Surov\u00fd, P., Kaartin en, H., 2022. Close -Range Remote Sensing of Forests: The state of the art, challenges, and opportunities for systems and data acquisitions. IEEE geoscience remote sensing magazine 10, 32 -71. Liao, K., Li, Y., Zou, B., Li, D., Lu, D., 2022. Examining the role of UAV Lidar data in improving tree volum e calculation accuracy. Remote Sensing 14, 4410. Lu, X., Du, S., 2024. Raising the Ceiling: Conflict -Free Local Feature Matching with Dynamic View Switching, Proceedings of the European Conference on Computer Vision (ECCV). McGlade, J., Wallace, L., Reinke , K., Jones, S., 2022. The potential of low -cost 3D imaging technologies for forestry applications: Setting a research agenda for low -cost remote sensing inventory tasks. Forests 13, 204. Merrell, P., Akbarzadeh, A., Wang, L., Mordohai, P., Frahm, J. -M., Y ang, R., Nist\u00e9 r, D., Pollefeys, M., 2007. Real -time visibility based fusion of depth maps, 2007 IEEE 11th International Conference on Computer Vision. Ieee, pp. 1 -8. Mildenhall, B., Srinivasan, P.P., Tancik, M., Barron, J.T., Ramamoorthi, R., Ng, R., 2021. Nerf: Representing scenes as neural radiance fields for view synthesis. Communications of the ACM 65, 99 -106. M\u00fc ller, T., Evans, A., Schied, C., Keller, A., 2022. Instant neural graphics primitives with a multiresolution hash encoding. ACM transactions on graphics 41, 1 -15. Pan, L., Bar\u00e1 th, D., Pollefeys, M., Sch\u00f6 nberger, J.L., 2024. Global Structure -from -Motion Revisited, European Conference on Computer Vision (ECCV). Rahaman, N., Baratin, A., Arpit, D., Draxler, F., Lin, M., Hamprecht, F., Bengio, Y., Courville, A., 2019. On the spectral bias of neural networks, International conference on machine learning. PMLR, pp. 5301 -5310. Ren, K., Jiang, L., Lu, T., Yu, M., Xu, L., Ni, Z., Dai, B., 2024. Octree -gs: Towards consistent real -time rendering with lod structured 3d gaussians. arXiv preprint arXiv:17898. Schneider, F.D., K\u00fc kenbrink, D., Schaepman, M.E., Schimel, D.S., Morsdorf, F., 2019. Quantifying 3D structure and occlusion i n dense tropical and temperate forests using close -range LiDAR. Agricultural Fo rest Meteorology 268, 249 -257. Schonberger, J.L., Frahm, J. -M., 2016. Structure -from -motion revisited. In: Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 4104 -4113. Seitz, S.M., Curless, B., Diebel, J., Scharstein, D., S zeliski, R., 2006. A comparison and evaluation of multi -view stereo reconstruction algorithms, 2006 IEEE computer society conference on computer vision and pattern recognition (CVPR'06). IEEE, pp. 519 -528. Smith, C., Charatan, D., Tewari, A., Sitzmann, V., 2024. FlowMap: High -Quality Camera Poses, Intrinsics, and Depth via Gradient Descent. arXiv preprint arXiv:15259. Sun, J., Shen, Z., Wang, Y., Bao, H., Zhou, X., 2021. LoFTR: Detector -free local feature matching with transformers. In: Proceedings of the I EEE/CVF conference on computer vision and pattern recognition, pp. 8922 -8931. Tancik, M., Casser, V., Yan, X., Pradhan, S., Mildenhall, B., Srinivasan, P.P., Barron, J.T., Kretzschmar, H., 2022. Block -nerf: Scalable large scene neural view synthesis. In: P roceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 8248 -8258. Tancik, M., Weber, E., Ng, E., Li, R., Yi, B., Wang, T., Kristoffersen, A., Austin, J., Salahi, K., Ahuja, A., 2023. Nerfstud io: A modular framework for neural radiance field development, ACM SIGGRAPH 2023 Conference Proceedings, pp. 1 -12. Wang, Y., Han, Q., Habermann, M., Daniilidis, K., Theobalt, C., Liu, L., 2023. Neus2: Fast learning of neural implicit surfac es for multi -view reconstruction. In: Proceedings of the IEEE/CVF International Conference on Computer Vision, pp. 3295 -3306. Xu, Z., Shen, X., Cao, L., 2023. Extraction of Forest Structural Parameters by the Comparison of Structure from Motion (SfM) and Backpack Laser Scanning (BLS) Point Clouds. Remote Sensing 15, 2144. Yan, X., Chai, G., Han, X., Lei, L., Wang, G., Jia, X., Zhang, X., 2024. SA -Pmnet: Utilizing Close -Range Photogrammetry Combined with Image Enhancement and Self -Attention Mechanisms for 3D Reconstruction of Forests. Remote Sensing 16, "
      },
      "Learning Geometry Consistent Neural Radiance Fields from Sparse and Unposed Views": {
        "authors": [],
        "url": "https://openreview.net/pdf?id=CqjO5w70cA",
        "ref_texts": "[37] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. 2021. LoFTR: Detector-Free Local Feature Matching With Transformers. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition . 8922\u2013",
        "ref_ids": [
          "37"
        ]
      },
      "Indoor Visual Localization using Point and Line Correspondences in dense colored point cloud": {
        "authors": [
          "Yuya Matsumoto",
          "Gaku Nakano",
          "Kazumine Ogura"
        ],
        "url": "https://openaccess.thecvf.com/content/WACV2024/papers/Matsumoto_Indoor_Visual_Localization_Using_Point_and_Line_Correspondences_in_Dense_WACV_2024_paper.pdf",
        "ref_texts": "[34] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , pages 8922\u20138931, 2021. 2",
        "ref_ids": [
          "34"
        ]
      },
      "Using outlier elimination to assess learning-based correspondence matching methods": {
        "authors": [],
        "url": "http://sure.sunderland.ac.uk/id/eprint/17204/1/INS-D-23-5555-R2.pdf",
        "ref_texts": "[14] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. LoFTR: Detector-free local feature matching with Transformers. InProceedings of the IEEE conference on computer vision and pattern recognition , pages 8922\u20138931, 2021.",
        "ref_ids": [
          "14"
        ]
      },
      "Semantic-aware Representation Learning for Homography Estimation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2407.13284",
        "ref_texts": "[37] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. 2021. LoFTR: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition . 8922\u20138931.",
        "ref_ids": [
          "37"
        ]
      },
      "A Review of Crowdsourcing Update Methods for High-Definition Maps": {
        "authors": [
          "Yuan Guo",
          "Jian Zhou",
          "Xicheng Li",
          "Youchen Tang",
          "Zhicheng Lv"
        ],
        "url": "https://www.mdpi.com/2220-9964/13/3/104/pdf",
        "ref_texts": "74. Sun, J.; Shen, Z.; Wang, Y.; Bao, H.; Zhou, X. LoFTR: Detector-Free Local Feature Matching With Transformers. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, Nashville, TN, USA, 19\u201325 June 2021; pp. 8922\u2013",
        "ref_ids": [
          "74"
        ]
      },
      "Topicfm+: Boosting accuracy and efficiency of topic-assisted feature matching": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2307.00485",
        "ref_texts": "[20] J. Sun, Z. Shen, Y . Wang, H. Bao, and X. Zhou, \u201cLoftr: Detectorfree local feature matching with transformers,\u201d in Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , 2021, pp. 8922\u20138931.",
        "ref_ids": [
          "20"
        ]
      },
      "View-consistent Object Removal in Radiance Fields": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2408.02100",
        "ref_texts": "[41] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. 2021. LoFTR: Detector-Free Local Feature Matching with Transformers. CVPR (2021).",
        "ref_ids": [
          "41"
        ]
      },
      "Towards RGB-NIR Cross-modality Image Registration and Beyond": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2405.19914",
        "ref_texts": "38. Sun, J., Shen, Z., Wang, Y., Bao, H., Zhou, X.: Loftr: Detector-free local feature matching with transformers. In: Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. pp. 8922\u20138931 (2021) 2, 4, 6, 12, 13",
        "ref_ids": [
          "38"
        ]
      },
      "A Novel Framework for Image Matching and Stitching for Moving Car Inspection under Illumination Challenges": {
        "authors": [
          "Andreas El",
          "Lazaros Grammatikopoulos",
          "Giorgos Sfikas",
          "George Karras",
          "Elli Petsa"
        ],
        "url": "https://www.mdpi.com/1424-8220/24/4/1083/pdf",
        "ref_texts": "14. Sun, J.; Shen, Z.; Wang, Y.; Bao, H.; Zhou, X. LoFTR: Detector-Free Local Feature Matching with Transformers. In Proceedings of the 2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), Nashville, TN, USA, 20\u201325 June 2021; pp.",
        "ref_ids": [
          "14"
        ]
      },
      "Effective descriptor extraction strategies for correspondence matching in coronary angiography images": {
        "authors": [
          "Woo Kim"
        ],
        "url": "https://www.nature.com/articles/s41598-024-69153-5.pdf",
        "ref_texts": ""
      },
      "Handbook on Leveraging Lines for Two-View Relative Pose Estimation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2309.16040",
        "ref_texts": ""
      },
      "Towards Foundation Models for 3D Vision: How Close Are We?": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2410.10799?",
        "ref_texts": "[77] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. LoFTR: Detector-Free Local Feature Matching with Transformers, April 2021. arXiv:2104.00680 [cs].",
        "ref_ids": [
          "77",
          "cs"
        ]
      },
      "DAC: Detector-Agnostic Spatial Covariances for Deep Local Features": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2305.12250",
        "ref_texts": "[54] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , pages 8922\u20138931, 2021. 2",
        "ref_ids": [
          "54"
        ]
      },
      "SSGA-Net: Stepwise Spatial Global-local Aggregation Networks for for Autonomous Driving": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2405.18857",
        "ref_texts": "[94] J. Sun, Z. Shen, Y . Wang, H. Bao, and X. Zhou, \u201cLoftr: Detector-free local feature matching with transformers,\u201d in CVPR . Virtual: IEEE, 2021, pp. 8922\u20138931.",
        "ref_ids": [
          "94"
        ]
      },
      "Structure Consistent Gaussian Splatting with Matching Prior for Few-shot Novel View Synthesis": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2411.03637",
        "ref_texts": "[48] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In CVPR , pages 8922\u20138931, 2021.",
        "ref_ids": [
          "48"
        ]
      },
      "Local positional graphs and attentive local features for a data and runtime-efficient hierarchical place recognition pipeline": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2403.10283",
        "ref_texts": "[8]J. Sun, Z. Shen, Y . Wang, H. Bao, and X. Zhou, \u201cLoFTR: Detector-free local feature matching with transformers,\u201d in Conference on Computer Vision and Pattern Recognition (CVPR) , 2021, pp. 8922\u20138931.",
        "ref_ids": [
          "8"
        ]
      },
      "Dusk Till Dawn: Self-supervised Nighttime Stereo Depth Estimation using Visual Foundation Models": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2405.11158",
        "ref_texts": "[32] J. Sun, Z. Shen, Y . Wang, H. Bao, and X. Zhou, \u201cLoftr: Detectorfree local feature matching with transformers,\u201d in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) , 2021, pp. 8922\u20138931.",
        "ref_ids": [
          "32"
        ]
      },
      "MonoLoT: Self-Supervised Monocular Depth Estimation in Low-Texture Scenes for Automatic Robotic Endoscopy": {
        "authors": [],
        "url": "https://discovery.ucl.ac.uk/id/eprint/10194872/1/MonoLoT_Self-Supervised_Monocular_Depth_Estimation_in_Low-Texture_Scenes_for_Automatic_Robotic_Endoscopy.pdf",
        "ref_texts": "[15] J. Sun, Z. Shen, Y . Wang, H. Bao, and X. Zhou, \u201cLoftr: Detectorfree local feature matching with transformers,\u201d in Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , 2021, pp. 8922\u20138931.",
        "ref_ids": [
          "15"
        ]
      },
      "Efficient 3D Instance Mapping and Localization with Neural Fields": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2403.19797",
        "ref_texts": "[17] J. Sun, Z. Shen, Y . Wang, H. Bao, and X. Zhou, \u201cLoftr: Detectorfree local feature matching with transformers,\u201d in Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , 2021, pp. 8922\u20138931. 2",
        "ref_ids": [
          "17"
        ]
      },
      "AMES: Asymmetric and Memory-Efficient Similarity Estimation for Instance-level Retrieval": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2408.03282?",
        "ref_texts": "60. Sun, J., Shen, Z., Wang, Y., Bao, H., Zhou, X.: Loftr: Detector-free local feature matching with transformers. In: CVPR (2021)",
        "ref_ids": [
          "60"
        ]
      },
      "Deep Learning-Based Object Pose Estimation: A Comprehensive Survey": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2405.07801",
        "ref_texts": "[304] J. Sun and Z. Shen, \u201cLoftr: Detector-free local feature matching with transformers,\u201d in CVPR , 2021.",
        "ref_ids": [
          "304"
        ]
      },
      "A Registration Method of Overlap Aware Point Clouds Based on Transformer-to-Transformer Regression": {
        "authors": [
          "Yafei Zhao",
          "Lineng Chen",
          "Quanchen Zhou",
          "Jiabao Zuo",
          "Hua Wang",
          "Mingwu Ren"
        ],
        "url": "https://www.mdpi.com/2072-4292/16/11/1898/pdf",
        "ref_texts": "21. Sun, J.; Shen, Z.; Wang, Y.; Bao, H.; Zhou, X. LoFTR: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, Nashville, TN, USA, 19\u201325 June 2021; pp. 8922\u20138931.",
        "ref_ids": [
          "21"
        ]
      },
      "HO-Cap: A Capture System and Dataset for 3D Reconstruction and Pose Tracking of Hand-Object Interaction": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2406.06843",
        "ref_texts": "40. Sun, J., Shen, Z., Wang, Y., Bao, H., Zhou, X.: Loftr: Detector-free local feature matching with transformers. In: Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. pp. 8922\u20138931 (2021) 6, 8",
        "ref_ids": [
          "40"
        ]
      },
      "Geometric Constraints in Deep Learning Frameworks: A Survey": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2403.12431",
        "ref_texts": "[81] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , pages 8922\u20138931, 2021.",
        "ref_ids": [
          "81"
        ]
      },
      "Quasi-Dense Matching for Oblique Stereo Images through Semantic Segmentation and Local Feature Enhancement": {
        "authors": [
          "Guobiao Yao",
          "Jin Zhang",
          "Fengqi Zhu",
          "Jianya Gong",
          "Fengxiang Jin",
          "Qingqing Fu",
          "Xiaofang Ren"
        ],
        "url": "https://www.mdpi.com/2072-4292/16/4/632/pdf",
        "ref_texts": ""
      },
      "Extreme Two-View Geometry From Object Poses with Diffusion Models": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2402.02800",
        "ref_texts": "[14] J. Sun, Z. Shen, Y . Wang, H. Bao, and X. Zhou, \u201cLoftr: Detectorfree local feature matching with transformers,\u201d in Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , 2021, pp. 8922\u20138931.",
        "ref_ids": [
          "14"
        ]
      },
      "L-DYNO: Framework to Learn Consistent Visual Features Using Robot's Motion": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2310.06249",
        "ref_texts": "[31] J. Sun, Z. Shen, Y . Wang, H. Bao, and X. Zhou, \u201cLoftr: Detectorfree local feature matching with transformers,\u201d in Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , 2021, pp. 8922\u20138931.",
        "ref_ids": [
          "31"
        ]
      },
      "UAVD4L: A Large-Scale Dataset for UAV 6-DoF Localization": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2401.05971",
        "ref_texts": "[42] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In CVPR , 2021. 4, 6",
        "ref_ids": [
          "42"
        ]
      },
      "These Maps Are Made by Propagation: Adapting Deep Stereo Networks to Road Scenarios with Decisive Disparity Diffusion": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2411.03717",
        "ref_texts": "[40] J. Sun et al. , \u201cLoFTR: Detector-free local feature matching with Transformers,\u201d in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) , 2021, pp. 8922\u20138931.",
        "ref_ids": [
          "40"
        ]
      },
      "RU-SLAM: A Robust Deep-Learning Visual Simultaneous Localization and Mapping (SLAM) System for Weakly Textured Underwater Environments": {
        "authors": [
          "Zhuo Wang",
          "Qin Cheng",
          "Xiaokai Mu"
        ],
        "url": "https://www.mdpi.com/1424-8220/24/6/1937/pdf",
        "ref_texts": "35. Sun, J.; Shen, Z.; Wang, Y.; Bao, H.; Zhou, X. LoFTR: Detector-Free Local Feature Matching with Transformers. In Proceedings of the 2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition, CVPR 2021, Nashville, TN, USA, 20\u201325 June 2021; IEEE Computer Society: Los Alamitos, CA, USA, 2021; pp. 8918\u20138927.",
        "ref_ids": [
          "35"
        ]
      },
      "LoD-Loc: Aerial Visual Localization using LoD 3D Map with Neural Wireframe Alignment": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2410.12269",
        "ref_texts": "[66] J. Sun, Z. Shen, Y . Wang, H. Bao, and X. Zhou. Loftr: Detector-free local feature matching with transformers. In CVPR , 2021.",
        "ref_ids": [
          "66"
        ]
      },
      "DGC-GNN: Leveraging Geometry and Color Cues for Visual Descriptor-Free 2D-3D Matching": {
        "authors": [
          "Shuzhe Wang",
          "Juho Kannala",
          "Daniel Barath"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Wang_DGC-GNN_Leveraging_Geometry_and_Color_Cues_for_Visual_Descriptor-Free_2D-3D_CVPR_2024_paper.pdf",
        "ref_texts": "[46] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. LoFTR: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , 2021. 3, 4",
        "ref_ids": [
          "46"
        ]
      },
      "MASt3R-SfM: a Fully-Integrated Solution for Unconstrained Structure-from-Motion": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2409.19152",
        "ref_texts": "[52]Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In CVPR, 2021. 2, 8",
        "ref_ids": [
          "52"
        ]
      },
      "MVSFormer++: Revealing the Devil in Transformer's Details for Multi-View Stereo": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2401.11673",
        "ref_texts": "12 Published as a conference paper at ICLR 2024 Jianlin Su. Scale operation of attention from the perspective of entropy invariance, Dec 2021. URL https://spaces.ac.cn/archives/8823 . Jianlin Su, Yu Lu, Shengfeng Pan, Ahmed Murtadha, Bo Wen, and Yunfeng Liu. Roformer: Enhanced transformer with rotary position embedding. arXiv preprint arXiv:2104.09864 , 2021. Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , pp. 8922\u20138931, 2021. Shitao Tang, Jiahui Zhang, Siyu Zhu, and Ping Tan. Quadtree attention for vision transformers. In International Conference on Learning Representations (ICLR) , 2022. Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timoth \u00b4ee Lacroix, Baptiste Rozi `ere, Naman Goyal, Eric Hambro, Faisal Azhar, et al. Llama: Open and efficient foundation language models. arXiv preprint arXiv:2302.13971 , 2023. Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, \u0141ukasz Kaiser, and Illia Polosukhin. Attention is all you need. Advances in neural information processing systems , 30, 2017. Matthew Walmer, Saksham Suri, Kamal Gupta, and Abhinav Shrivastava. Teaching matters: Investigating the role of supervision in vision transformers. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pp. 7486\u20137496, 2023. Fangjinhua Wang, Silvano Galliani, Christoph V ogel, Pablo Speciale, and Marc Pollefeys. Patchmatchnet: Learned multi-view patchmatch stereo. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , pp. 14194\u201314203, 2021a. Qiang Wang, Bei Li, Tong Xiao, Jingbo Zhu, Changliang Li, Derek F. Wong, and Lidia S. Chao. Learning deep transformer models for machine translation. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics , pp. 1810\u20131822, Florence, Italy, July 2019. Association for Computational Linguistics. doi: 10.18653/v1/P19-1176. URL https: //aclanthology.org/P19-1176 . Wenhai Wang, Enze Xie, Xiang Li, Deng-Ping Fan, Kaitao Song, Ding Liang, Tong Lu, Ping Luo, and Ling Shao. Pyramid vision transformer: A versatile backbone for dense prediction without convolutions. In Proceedings of the IEEE/CVF international conference on computer vision , pp."
      },
      "Obfuscation Based Privacy Preserving Representations are Recoverable Using Neighborhood Information": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2409.11536",
        "ref_texts": "[65] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. LoFTR: Detector-free local feature matching with transformers. CVPR , 2021. 5",
        "ref_ids": [
          "65"
        ]
      },
      "DiffGlue: Diffusion-Aided Image Feature Matching": {
        "authors": [],
        "url": "https://openreview.net/pdf?id=DVm3Bk2eHh",
        "ref_texts": "[60] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. 2021. LoFTR: Detector-free local feature matching with transformers. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition . 8922\u20138931.",
        "ref_ids": [
          "60"
        ]
      },
      "DPCalib: Dual-Perspective View Network for LiDAR-Camera Joint Calibration": {
        "authors": [
          "Jinghao Cao",
          "Xiong Yang",
          "Sheng Liu",
          "Tiejian Tang",
          "Yang Li",
          "Sidan Du"
        ],
        "url": "https://www.mdpi.com/2079-9292/13/10/1914/pdf",
        "ref_texts": "14. Sun, J.; Shen, Z.; Wang, Y.; Bao, H.; Zhou, X. LoFTR: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, Nashville, TN, USA, 20\u201325 June 2021; pp. 8922\u20138931.",
        "ref_ids": [
          "14"
        ]
      },
      "LiteVLoc: Map-Lite Visual Localization for Image Goal Navigation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2410.04419",
        "ref_texts": "[35] J. Sun, Z. Shen, Y . Wang, H. Bao, and X. Zhou, \u201cLoFTR: Detectorfree local feature matching with transformers,\u201d in Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , 2021, pp. 8922\u20138931.",
        "ref_ids": [
          "35"
        ]
      },
      "TP3M: Transformer-based Pseudo 3D Image Matching with Reference": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2405.08434",
        "ref_texts": "[11] J. Sun, Z. Shen, Y . Wang, H. Bao, and X. Zhou, \u201cLoftr: Detectorfree local feature matching with transformers,\u201d in CVPR , 2021, pp.",
        "ref_ids": [
          "11"
        ]
      },
      "X-Drive: Cross-modality consistent multi-sensor data synthesis for driving scenarios": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2411.01123",
        "ref_texts": "12 Preprint Cody Reading, Ali Harakeh, Julia Chae, and Steven L Waslander. Categorical depth distribution network for monocular 3d object detection. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pp. 8555\u20138564, 2021. Danilo Jimenez Rezende, Shakir Mohamed, and Daan Wierstra. Stochastic backpropagation and approximate inference in deep generative models. In International conference on machine learning , pp. 1278\u20131286. PMLR, 2014. Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Bj \u00a8orn Ommer. Highresolution image synthesis with latent diffusion models. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , pp. 10684\u201310695, 2022. Ludan Ruan, Yiyang Ma, Huan Yang, Huiguo He, Bei Liu, Jianlong Fu, Nicholas Jing Yuan, Qin Jin, and Baining Guo. Mm-diffusion: Learning multi-modal diffusion models for joint audio and video generation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pp. 10219\u201310228, 2023. Kyle Sargent, Zizhang Li, Tanmay Shah, Charles Herrmann, Hong-Xing Yu, Yunzhi Zhang, Eric Ryan Chan, Dmitry Lagun, Li Fei-Fei, Deqing Sun, et al. Zeronvs: Zero-shot 360-degree view synthesis from a single image. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pp. 9420\u20139429, 2024. Stefan Schubert, Peer Neubert, Johannes P \u00a8oschmann, and Peter Protzel. Circular convolutional neural networks for panoramic images and laser data. In 2019 IEEE intelligent vehicles symposium (IV), pp. 653\u2013660. IEEE, 2019. Jiahao Shao, Yuanbo Yang, Hongyu Zhou, Youmin Zhang, Yujun Shen, Matteo Poggi, and Yiyi Liao. Learning temporally consistent video depth from video diffusion priors. arXiv preprint arXiv:2406.01493 , 2024. Uriel Singer, Adam Polyak, Thomas Hayes, Xi Yin, Jie An, Songyang Zhang, Qiyuan Hu, Harry Yang, Oron Ashual, Oran Gafni, et al. Make-a-video: Text-to-video generation without text-video data. In The Eleventh International Conference on Learning Representations , 2022. Ibrahim Sobh, Loay Amin, Sherif Abdelkarim, Khaled Elmadawy, Mahmoud Saeed, Omar Abdeltawab, Mostafa Gamal, and Ahmad El Sallab. End-to-end multi-modal sensors fusion system for urban automated driving. 32nd Conference on Neural Information Processing Systems , 2018. Jascha Sohl-Dickstein, Eric Weiss, Niru Maheswaranathan, and Surya Ganguli. Deep unsupervised learning using nonequilibrium thermodynamics. In International conference on machine learning, pp. 2256\u20132265. PMLR, 2015. Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , pp. 8922\u20138931, 2021. Alexander Swerdlow, Runsheng Xu, and Bolei Zhou. Street-view image generation from a bird\u2019seye view layout. IEEE Robotics and Automation Letters , 2024. Xiaofeng Wang, Zheng Zhu, Guan Huang, Xinze Chen, and Jiwen Lu. Drivedreamer: Towards real-world-driven world models for autonomous driving. arXiv preprint arXiv:2309.09777 , 2023. Yuqing Wen, Yucheng Zhao, Yingfei Liu, Fan Jia, Yanhui Wang, Chong Luo, Chi Zhang, Tiancai Wang, Xiaoyan Sun, and Xiangyu Zhang. Panacea: Panoramic and controllable video generation for autonomous driving. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pp. 6902\u20136912, 2024. Yichen Xie, Chenfeng Xu, Marie-Julie Rakotosaona, Patrick Rim, Federico Tombari, Kurt Keutzer, Masayoshi Tomizuka, and Wei Zhan. Sparsefusion: Fusing multi-modal sparse representations for multi-sensor 3d object detection. In Proceedings of the IEEE/CVF International Conference on Computer Vision , pp. 17591\u201317602, 2023."
      },
      "SCENES: Subpixel Correspondence Estimation With Epipolar Supervision": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2401.10886",
        "ref_texts": "[38] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. LoFTR: detector-free local feature matching with transformers. In CVPR , pages 8922\u20138931, 2021. 1, 2, 3, 6, 7",
        "ref_ids": [
          "38"
        ]
      },
      "EI-Nexus: Towards Unmediated and Flexible Inter-Modality Local Feature Extraction and Matching for Event-Image Data": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2410.21743",
        "ref_texts": "[44] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. LoFTR: Detector-free local feature matching with transformers. In CVPR , 2021. 1, 3, 5",
        "ref_ids": [
          "44"
        ]
      },
      "GV-Bench: Benchmarking Local Feature Matching for Geometric Verification of Long-term Loop Closure Detection": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2407.11736",
        "ref_texts": "[18] J. Sun, Z. Shen, Y . Wang, H. Bao, and X. Zhou, \u201cLoftr: Detectorfree local feature matching with transformers,\u201d in Proc. IEEE Conf. Comput. Vis. Pattern Recognit. , 2021, pp. 8922\u20138931.",
        "ref_ids": [
          "18"
        ]
      },
      "TieBot: Learning to Knot a Tie from Visual Demonstration through a Real-to-Sim-to-Real Approach": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2407.03245",
        "ref_texts": "[44] J. Sun, Z. Shen, Y . Wang, H. Bao, and X. Zhou. LoFTR: Detector-free local feature matching with transformers. CVPR , 2021.",
        "ref_ids": [
          "44"
        ]
      },
      "OmniPose6D: Towards Short-Term Object Pose Tracking in Dynamic Scenes from Monocular RGB": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2410.06694",
        "ref_texts": "[49] J. Sun, Z. Shen, Y . Wang, H. Bao, and X. Zhou, \u201cLoFTR: Detector-free local feature matching with transformers,\u201d in IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) , 2021.",
        "ref_ids": [
          "49"
        ]
      },
      "From a Bird's Eye View to See: Joint Camera and Subject Registration without the Camera Calibration": {
        "authors": [
          "Zekun Qian",
          "Ruize Han",
          "Wei Feng",
          "Song Wang"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Qian_From_a_Birds_Eye_View_to_See_Joint_Camera_and_CVPR_2024_paper.pdf"
      },
      "Layer-Wise Feature Metric of Semantic-Pixel Matching for Few-Shot Learning": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2411.06363",
        "ref_texts": "[31] J. Sun, Z. Shen, Y. Wang, H. Bao, X. Zhou, Loftr: Detector-free local feature matching with transformers, in: Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, 2021, pp. 8922\u20138931.",
        "ref_ids": [
          "31"
        ]
      },
      "Self-Assessed Generation: Trustworthy Label Generation for Optical Flow and Stereo Matching in Real-world": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2410.10453",
        "ref_texts": "[30] J. Sun, Z. Shen, Y . Wang, H. Bao, and X. Zhou, \u201cLoftr: Detectorfree local feature matching with transformers,\u201d in Proceedings of the IEEE/CVF conference on computer vision and pattern recognition (CVPR) , 2021, pp. 8922\u20138931. 2",
        "ref_ids": [
          "30"
        ]
      },
      "Free-Moving Object Reconstruction and Pose Estimation with Virtual Camera": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2405.05858",
        "ref_texts": "[41] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. LoFTR: Detector-Free Local Feature Matching with Transformers. CVPR , 2021. 5",
        "ref_ids": [
          "41"
        ]
      },
      "A Light-weight Transformer-based Self-supervised Matching Network for Heterogeneous Images": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2404.19311",
        "ref_texts": "[55] J. Sun, Z. Shen, Y . Wang, H. Bao, and X. Zhou, \u201cLoftr: Detector-free local feature matching with transformers,\u201d in CVPR , 2021, pp. 8918\u2013",
        "ref_ids": [
          "55"
        ]
      },
      "RING#: PR-by-PE Global Localization with Roto-translation Equivariant Gram Learning": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2409.00206",
        "ref_texts": "[35] J. Sun, Z. Shen, Y . Wang, H. Bao, and X. Zhou, \u201cLoftr: Detector-free local feature matching with transformers,\u201d in Proc. of the IEEE/CVF Conf. on Computer Vision and Pattern Recognition (CVPR) , 2021, pp.",
        "ref_ids": [
          "35"
        ]
      },
      "Aerial Image-based Inter-day Registration for Precision Agriculture": {
        "authors": [],
        "url": "https://www.research-collection.ethz.ch/bitstream/handle/20.500.11850/662288/ICRA_2024_crop_alignment_camera_ready.pdf?sequence=1",
        "ref_texts": "[1] J. Sun, Z. Shen, Y . Wang, H. Bao, and X. Zhou, \u201cLoftr: Detectorfree local feature matching with transformers,\u201d in Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , 2021, pp. 8922\u20138931.",
        "ref_ids": [
          "1"
        ]
      },
      "PF3plat: Pose-Free Feed-Forward 3D Gaussian Splatting": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2410.22128",
        "ref_texts": "14 PF3plat: Pose-Free Feed-Forward 3D Gaussian Splatting Andrew Liu, Richard Tucker, Varun Jampani, Ameesh Makadia, Noah Snavely, and Angjoo Kanazawa. Infinite nature: Perpetual view generation of natural scenes from a single image. In Proceedings of the IEEE/CVF International Conference on Computer Vision , pp. 14458\u201314467, 2021. David G Lowe. Distinctive image features from scale-invariant keypoints. International journal of computer vision , 60:91\u2013110, 2004. Iaroslav Melekhov, Juha Ylioinas, Juho Kannala, and Esa Rahtu. Relative camera pose estimation using convolutional neural networks. In Advanced Concepts for Intelligent Vision Systems: 18th International Conference, ACIVS 2017, Antwerp, Belgium, September 18-21, 2017, Proceedings 18, pp. 675\u2013687. Springer, 2017. Ben Mildenhall, Pratul P Srinivasan, Matthew Tancik, Jonathan T Barron, Ravi Ramamoorthi, and Ren Ng. Nerf: Representing scenes as neural radiance fields for view synthesis. Communications of the ACM , 65(1):99\u2013106, 2021. David Nist \u00b4er. An efficient solution to the five-point relative pose problem. IEEE transactions on pattern analysis and machine intelligence , 26(6):756\u2013770, 2004. Adam Paszke, Sam Gross, Soumith Chintala, Gregory Chanan, Edward Yang, Zachary DeVito, Zeming Lin, Alban Desmaison, Luca Antiga, and Adam Lerer. Automatic differentiation in pytorch. 2017. Luigi Piccinelli, Yung-Hsu Yang, Christos Sakaridis, Mattia Segu, Siyuan Li, Luc Van Gool, and Fisher Yu. Unidepth: Universal monocular metric depth estimation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pp. 10106\u201310116, 2024. Chris Rockwell, Justin Johnson, and David F Fouhey. The 8-point algorithm as an inductive bias for relative pose prediction by vits. In 2022 International Conference on 3D Vision (3DV) , pp. 1\u201311. IEEE, 2022. Radu Bogdan Rusu, Nico Blodow, and Michael Beetz. Fast point feature histograms (fpfh) for 3d registration. In 2009 IEEE international conference on robotics and automation , pp. 3212\u20133217. IEEE, 2009. Samuele Salti, Federico Tombari, and Luigi Di Stefano. Shot: Unique signatures of histograms for surface and texture description. Computer Vision and Image Understanding , 125:251\u2013264, 2014. Paul-Edouard Sarlin, Daniel DeTone, Tomasz Malisiewicz, and Andrew Rabinovich. Superglue: Learning feature matching with graph neural networks. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , pp. 4938\u20134947, 2020. Vincent Sitzmann, Semon Rezchikov, Bill Freeman, Josh Tenenbaum, and Fredo Durand. Light field networks: Neural scene representations with single-evaluation rendering. Advances in Neural Information Processing Systems , 34:19313\u201319325, 2021. Brandon Smart, Chuanxia Zheng, Iro Laina, and Victor Adrian Prisacariu. Splatt3r: Zero-shot gaussian splatting from uncalibarated image pairs. arXiv preprint arXiv:2408.13912 , 2024. Cameron Smith, Yilun Du, Ayush Tewari, and Vincent Sitzmann. Flowcam: Training generalizable 3d radiance fields without camera poses via pixel-aligned scene flow. arXiv preprint arXiv:2306.00180 , 2023. Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , pp. 8922\u20138931, 2021. Stanislaw Szymanowicz, Christian Rupprecht, and Andrea Vedaldi. Splatter image: Ultra-fast single-view 3d reconstruction. Conference on Computer Vision and Pattern Recognition (CVPR) , 2024. Engin Tola, Vincent Lepetit, and Pascal Fua. A fast local descriptor for dense matching. In 2008 IEEE conference on computer vision and pattern recognition , pp. 1\u20138. IEEE, 2008."
      },
      "CT-NeRF: Incremental Optimizing Neural Radiance Field and Poses with Complex Trajectory": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2404.13896",
        "ref_texts": "[30] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. 2021. LoFTR: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition . 8922\u20138931.",
        "ref_ids": [
          "30"
        ]
      },
      "RESFM: Robust Equivariant Multiview Structure from Motion": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2404.14280",
        "ref_texts": "34. Sun, J., Shen, Z., Wang, Y., Bao, H., Zhou, X.: LoFTR: Detector-free local feature matching with transformers. CVPR (2021)",
        "ref_ids": [
          "34"
        ]
      },
      "RIDERS: Radar-Infrared Depth Estimation for Robust Sensing": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2402.02067",
        "ref_texts": "[35] J. Sun, Z. Shen, Y . Wang, H. Bao, and X. Zhou. \u201cLoFTR: Detector-free local feature matching with transformers\u201d. In: Proceedings of the IEEE/CVF conference on computer vision and pattern recognition . 2021, pp. 8922\u20138931.",
        "ref_ids": [
          "35"
        ]
      },
      "CoViS-Net: A Cooperative Visual Spatial Foundation Model for Multi-Robot Applications": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2405.01107",
        "ref_texts": "[40] J. Sun, Z. Shen, Y . Wang, H. Bao, and X. Zhou. LoFTR: Detector-Free Local Feature Matching With Transformers. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) , pages 8922\u20138931, June 2021. URL https: //openaccess.thecvf.com/content/CVPR2021/html/Sun_LoFTR_Detector-Free_ Local_Feature_Matching_With_Transformers_CVPR_2021_paper.html .",
        "ref_ids": [
          "40"
        ]
      },
      "FilterGNN: Image feature matching with cascaded outlier filters and linear attention": {
        "authors": [],
        "url": "https://link.springer.com/content/pdf/10.1007/s41095-023-0363-3.pdf",
        "ref_texts": "[11] Sun, J.; Shen, Z.; Wang, Y.; Bao, H.; Zhou, X. LoFTR: Detector-free local feature matching with transformers. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 8922\u20138931, 2021.",
        "ref_ids": [
          "11"
        ]
      },
      "RetinaRegNet: A Versatile Approach for Retinal Image Registration": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2404.16017",
        "ref_texts": "(2021a). Prosregnet: A deep learning framework for registration of mri and histopathology images of the prostate. Medical image analysis , 68:101919. Shao,W.,Pan,Y.,Durumeric,O.C.,Reinhardt,J.M.,Bayouth,J.E.,Rusu, M., and Christensen, G. E. (2021b). Geodesic density regression for correcting 4dct pulmonary respiratory motion artifacts. Medical image analysis, 72:102140. Simonyan,K.andZisserman,A.(2014). Verydeepconvolutionalnetworks for large-scale image recognition. arXiv preprint arXiv:1409.1556 . Song, Y., Sohl-Dickstein, J., Kingma, D. P., Kumar, A., Ermon, S., and Poole, B. (2020). Score-based generative modeling through stochastic differential equations. arXiv preprint arXiv:2011.13456 . Sun,J.,Shen,Z.,Wang,Y.,Bao,H.,andZhou,X.(2021). Loftr:Detectorfree local feature matching with transformers. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , pages 8922\u20138931. Tang,L.,Jia,M.,Wang,Q.,Phoo,C.P.,andHariharan,B.(2024).Emergent correspondence from image diffusion. Advances in Neural Information Processing Systems , 36.Toga,A.W.andThompson,P.M.(2001). Theroleofimageregistrationin brain mapping. Image and vision computing , 19(1-2):3\u201324. Wang,G.,Wang,Z.,Chen,Y.,andZhao,W.(2015). Robustpointmatching method for multimodal retinal image registration. Biomedical Signal Processing and Control , 19:68\u201376. Wang,J.etal.(2019).Gaussianfieldestimatorwithmanifoldregularization for retinal image registration. Signal Processing , 157:225\u2013235. Wang, S., You, H., and Fu, K. (2011). Bfsift: A novel method to find featurematchesforsarimageregistration. IEEEGeoscienceandRemote Sensing Letters , 9(4):649\u2013653. Wang, Y. et al. (2020). A segmentation based robust deep learning framework for multimodal retinal image registration. In ICASSP 20202020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) , pages 1369\u20131373. IEEE. Yang, X. and Wang, X. (2023). Diffusion model as representation learner. InProceedingsoftheIEEE/CVFInternationalConferenceonComputer Vision, pages 18938\u201318949. Zhao, D., Song, Z., Ji, Z., Zhao, G., Ge, W., and Yu, Y. (2021). Multiscale matching networks for semantic correspondence. In Proceedings of the IEEE/CVF International Conference on Computer Vision , pages 3354\u20133364. Zhu,Y.-M.(2007). Mutualinformation-basedregistrationoftemporaland stereoretinalimagesusingconstrainedoptimization. Computermethods and programs in biomedicine , 86(3):210\u2013215. Zou, B., He, Z., Zhao, R., Zhu, C., Liao, W., and Li, S. (2020). Nonrigid retinal image registration using an unsupervised structure-driven regression network. Neurocomputing , 404:14\u201325. Sivaraman et al.: Preprint submitted to Elsevier Page 11 of 11"
      },
      "Marrying NeRF with Feature Matching for One-step Pose Estimation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2404.00891",
        "ref_texts": "[47] J. Sun, Z. Shen, Y . Wang, H. Bao, and X. Zhou, \u201cLoftr: Detectorfree local feature matching with transformers,\u201d in Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , 2021, pp. 8922\u20138931.",
        "ref_ids": [
          "47"
        ]
      },
      "HCPM: Hierarchical Candidates Pruning for Efficient Detector-Free Matching": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2403.12543",
        "ref_texts": "[33] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , 2021. 1, 2, 3, 6, 7, 8",
        "ref_ids": [
          "33"
        ]
      },
      "InterNet: Unsupervised Cross-modal Homography Estimation Based on Interleaved Modality Transfer and Self-supervised Homography Prediction": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2409.17993",
        "ref_texts": "[30] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. LoFTR: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 8922\u20138931, 2021.",
        "ref_ids": [
          "30"
        ]
      },
      "Structure similarity virtual map generation network for optical and SAR image matching": {
        "authors": [],
        "url": "https://www.frontiersin.org/articles/10.3389/fphy.2024.1287050/pdf",
        "ref_texts": "27. Sun J, Shen Z, Wang Y, Bao H, Zhou X. LoFTR: detector-free local feature matching with transformers. Proc IEEE/CVF Conf Comput Vis pattern recognition (2021) 8922 \u201331.28. Zhang H, Le Z, Shao Z, Xu H, Ma J. MFF-GAN: an unsupervised generative adversarial network with adaptive and gradient joint constraints for multi-focus image fusion. Inf Fusion (2021) 66:40 \u201353. doi:10.1016/j.inffus.2020.08.022",
        "ref_ids": [
          "27"
        ]
      },
      "Learning Visual Information Utility with PIXER": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2409.13151",
        "ref_texts": "[28] J. Sun, Z. Shen, Y . Wang, H. Bao, and X. Zhou, \u201cLoFTR: Detector-Free Local Feature Matching with Transformers,\u201d Apr. 2021. arXiv:2104.00680 [cs].",
        "ref_ids": [
          "28",
          "cs"
        ]
      },
      "ArCSEM: Artistic Colorization of SEM Images via Gaussian Splatting": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2410.21310",
        "ref_texts": "54. Sun, J., Shen, Z., Wang, Y., Bao, H., Zhou, X.: Loftr: Detector-free local feature matching with transformers. In: Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. pp. 8922\u20138931 (2021)",
        "ref_ids": [
          "54"
        ]
      },
      "Implicit\u2013Explicit Coupling Enhancement for UAV Scene 3D Reconstruction": {
        "authors": [
          "Xiaobo Lin",
          "Shibiao Xu"
        ],
        "url": "https://www.mdpi.com/2076-3417/14/6/2425/pdf",
        "ref_texts": "37. Sun, J.; Shen, Z.; Wang, Y.; Bao, H.; Zhou, X. LoFTR: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, Nashville, TN, USA, 20\u201325 June 2021; pp. 8922\u20138931.",
        "ref_ids": [
          "37"
        ]
      },
      "Learning accurate template matching with differentiable coarse-to-fine correspondence refinement": {
        "authors": [],
        "url": "https://link.springer.com/content/pdf/10.1007/s41095-023-0333-9.pdf",
        "ref_texts": "[13]Sun, J. M.; Shen, Z. H.; Wang, Y. A.; Bao, H. J.; Zhou, X. W. LoFTR: Detector-free local feature matching with transformers. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 8918\u20138927, 2021.",
        "ref_ids": [
          "13"
        ]
      },
      "Generalized Correspondence Matching via Flexible Hierarchical Refinement and Patch Descriptor Distillation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2403.05388"
      },
      "U-ETMVSNet: Uncertainty-Epipolar Transformer Multi-View Stereo Network for Object Stereo Reconstruction": {
        "authors": [
          "Ning Zhao",
          "Heng Wang",
          "Quanlong Cui",
          "Lan Wu"
        ],
        "url": "https://www.mdpi.com/2076-3417/14/6/2223/pdf",
        "ref_texts": "32. Sun, J.; Shen, Z.; Wang, Y.; Bao, H.; Zhou, X. LoFTR: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, Nashville, TN, USA, 20\u201325 June 2021; pp. 8922\u20138931.",
        "ref_ids": [
          "32"
        ]
      },
      "PARMESAN: Parameter-Free Memory Search and Transduction for Dense Prediction Tasks": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2403.11743",
        "ref_texts": "78. J. Sun, Z. Shen, Y. Wang, H. Bao, and X. Zhou. LoFTR: Detector-free local feature matching with transformers. CVPR , pages 8922\u20138931, 2021.",
        "ref_ids": [
          "78"
        ]
      },
      "REMM: Rotation-Equivariant Framework for End-to-End Multimodal Image Matching": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2407.11637",
        "ref_texts": "[19] J. Sun, Z. Shen, Y . Wang, H. Bao, and X. Zhou, \u201cLoftr: Detectorfree local feature matching with transformers,\u201d in Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , 2021, pp. 8922\u20138931.",
        "ref_ids": [
          "19"
        ]
      },
      "Grasp, See and Place: Efficient Unknown Object Rearrangement with Policy Structure Prior": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2402.15402",
        "ref_texts": "[81] J. Sun, Z. Shen, Y . Wang, H. Bao, and X. Zhou, \u201cLoftr: Detectorfree local feature matching with transformers,\u201d in Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , 2021, pp. 8922\u20138931.",
        "ref_ids": [
          "81"
        ]
      },
      "4Seasons: Benchmarking Visual SLAM and Long-Term Localization for Autonomous Driving in Challenging Conditions": {
        "authors": [
          "Patrick Wenzel"
        ],
        "url": "https://link.springer.com/content/pdf/10.1007/s11263-024-02230-4.pdf",
        "ref_texts": "Angeli, A., Filliat, D., Doncieux, S., et al. (2008) Fast and incremental method for loop-closure detection using bags of visual words.IEEE Transactions on Robotics (T-RO) 24(5), 1027\u20131037 Arandjelovic, R., & Zisserman, A. (2013). All about VLAD. In: Proceedings of the IEEE Conference on Computer Vision and PatternRecognition (CVPR) , pp. 1578\u20131585. Arandjelovic, R., Gronat, P ., Torii, A., et al. (2016). NetVLAD: CNN architecture for weakly supervised place recognition. In: Proceedings of the IEEE Conference on Computer Vision and PatternRecognition (CVPR) , pp. 5297\u20135307. Babenko, A., Slesarev, A., Chigorin, A., et al. (2014). Neural codes for image retrieval. In: Proceedings of the European Conference on Computer Vision (ECCV) , pp. 584\u2013599 Badino, H., Huber, D., & Kanade, T. (2011). Visual topometric localization. In: textitProceedings of the IEEE Intelligent V ehiclesSymposium (IV), pp. 794\u2013799. Barnes, D., Gadd, M., Murcutt, P ., et al. (2020). The oxford radar robotcar dataset: A radar extension to the oxford robotcar dataset. In:Proceedings of the IEEE International Conference on Roboticsand Automation (ICRA) Bijelic, M., Gruber, T., Mannan, F., et al. (2020). Seeing through fog without seeing fog: Deep multimodal sensor fusion in unseenadverse weather. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) Blanco-Claraco, J. L., \u00c1ngel Moreno-Due\u00f1as, F., & Gonz\u00e1lez-Jim\u00e9nez, J. (2014). The M\u00e1laga urban dataset: High-rate stereo and LiDARin a realistic urban scenario. International Journal of Robotics Research (IJRR), 33 (2), 207\u2013214. Burri, M., Nikolic, J., Gohl, P ., et al. (2016). The EuRoC micro aerial vehicle datasets. International Journal of Robotics Research (IJRR), 35 (10), 1157\u20131163. Caesar, H., Bankiti, V ., Lang, A.H., et al. (2020). nuScenes: A multimodal dataset for autonomous driving. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , pp. 11,621\u201311,631 Campos, C., Elvira, R., G\u00f3mez, J.J., et al. (2020). ORB-SLAM3: An accurate open-source library for visual, visual-inertial and multi-map SLAM. In: arXiv preprint arXiv:2007.11898 Cordts, M., Omran, M., Ramos, S., et al. (2016). The cityscapes dataset for semantic urban scene understanding. In: Proceedings of theIEEE Conference on Computer Vision and Pattern Recognition(CVPR), pp 3213\u20133223 DeTone, D., Malisiewicz, T., Rabinovich, A. (2018). SuperPoint: Selfsupervised interest point detection and description. In: Proceedingsof the IEEE Conference on Computer Vision and Pattern Recog-nition Workshops (CVPRW), pp 224\u2013236 Diaz-Ruiz, C.A., Xia, Y ., Y ou, Y ., et al. (2022). Ithaca365: Dataset and driving perception under repeated and challenging weather 123 International Journal of Computer Vision conditions. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp 21,351\u201321,360 Dusmanu, M., Rocco, I., Pajdla, T., et al. (2019). D2-Net: A trainable CNN for joint detection and description of local features. In: Pro-ceedings of the IEEE Conference on Computer Vision and PatternRecognition (CVPR), pp 8092\u20138101 Engel, J., Sch\u00f6ps, T., Cremers, D. (2014). LSD-SLAM: Large-scale direct monocular SLAM. In: Proceedings of the European Con-ference on Computer Vision (ECCV), pp 834\u2013849 Engel, J., St\u00fcckler, J., Cremers, D. (2015). Large-scale direct SLAM with stereo cameras. In: Proceedings of the IEEE/RSJ Conferenceon Intelligent Robots and Systems (IROS), pp 1935\u20131942 Engel, J., Usenko, V ., Cremers, D. (2016). A photometrically calibrated benchmark for monocular visual odometry. In: arXiv preprintarXiv:1607.02555 Engel, J., Koltun, V ., & Cremers, D. (2017). Direct sparse odometry. IEEE Transactions on Pattern Analysis and Machine Intelligence(PAMI), 40 (3), 611\u2013625. Fan, B., Zhou, J., Feng, W., et al. (2022). Learning semantic-aware local features for long term visual localization. IEEE Transactions on Image Processing, 31 , 4842\u20134855. Fischler, M. A., & Bolles, R. C. (1981). Random sample consensus: a paradigm for model fitting with applications to image analysis and automated cartography. Communications of the ACM, 24 (6), 381\u2013395. G\u00e1lvez-L\u00f3pez, D., Tardos, J.D. (2012). Bags of binary words for fast place recognition in image sequences. IEEE Transactions onRobotics (T-RO) 28(5):1188\u20131197 Geiger, A., Lenz, P ., Urtasun, R. (2012). Are we ready for autonomous driving? the KITTI vision benchmark suite. In: Proceedings of theIEEE Conference on Computer Vision and Pattern Recognition(CVPR), pp 3354\u20133361 Geiger, A., Lenz, P ., Stiller, C., et al. (2013). Vision meets robotics: The KITTI dataset. International Journal of Robotics Research (IJRR), 32(11), 1231\u20131237. Gordo, A., Almaz\u00e1n, J., Revaud, J., et al. (2016). Deep image retrieval: Learning global representations for image search. In: Proceedingsof the European Conference on Computer Vision (ECCV), pp 241\u2013257 Gordo, A., Almazan, J., Revaud, J., et al. (2017). End-to-end learning of deep visual representations for image retrieval. International Journal of Computer Vision (IJCV), 124 (2), 237\u2013254. Hartley, R., Trumpf, J., Dai, Y ., et al. (2013). Rotation averaging. International Journal of Computer Vision (IJCV), 103 (3), 267\u2013305. He, K., Zhang, X., Ren, S., et al. (2016). Deep residual learning for image recognition. In: Proceedings of the IEEE Conference onComputer Vision and Pattern Recognition (CVPR), pp 770\u2013778 Hu, H., & de Haan, G. (2006). Low cost robust blur estimator. In: Proceedings of the IEEE International Conference on Image Pro-cessing (ICIP), pp 617\u2013620 Huang, X., Cheng, X., Geng, Q., et al. (2018). The ApolloScape dataset for autonomous driving. In: Proceedings of the IEEE Confer-ence on Computer Vision and Pattern Recognition Workshops(CVPRW), pp 954\u2013960 Jafarzadeh, A., Antequera, M.L., Gargallo, P ., et al. (2021). Crowddriven: A new challenging dataset for outdoor visual localization.In: Proceedings of the International Conference on ComputerVision (ICCV), pp 9845\u20139855 Jaramillo, C. (2017). Direct multichannel tracking. In: Proceedings of the International Conference on 3D Vision (3DV), pp 347\u2013355 J\u00e9gou, H., Douze, M., Schmid, C., et al. (2010). Aggregating local descriptors into a compact image representation. In: Proceedings ofthe IEEE Conference on Computer Vision and Pattern Recognition(CVPR), pp 3304\u20133311Jung, E., Yang, N., Cremers, D. (2019). Multi-frame GAN: Image enhancement for stereo visual odometry in low light. In: Con-ference on Robot Learning (CoRL), pp 651\u2013660 Kannala, J., & Brandt, S. S. (2006). A generic camera model and calibration method for conventional, wide-angle, and fish-eye lenses.IEEE Transactions on Pattern Analysis and Machine Intelligence(PAMI), 28 (8), 1335\u20131340. Kendall, A., Grimes, M., Cipolla, R. (2015). Posenet: A convolutional network for real-time 6-dof camera relocalization. In: Proceedingsof the International Conference on Computer Vision (ICCV), pp2938\u20132946 Kenk, M.A., Hassaballah, M. (2020). Dawn: V ehicle detection in adverse weather nature. In: arXiv preprint arXiv:2008.05402 Krizhevsky, A., Sutskever, I., Hinton, G.E. (2012). Imagenet classification with deep convolutional neural networks. In: NeuralInformation Processing Systems (NIPS), pp 1097\u20131105 K\u00fcmmerle, R., Grisetti, G., Strasdat, H., et al. (2011). g2o: A general framework for graph optimization. In: Proceedings of the IEEEInternational Conference on Robotics and Automation (ICRA),pp 3607\u20133613 Lowe, D. G. (2004). Distinctive image features from scale-invariant keypoints. International Journal of Computer Vision (IJCV), 60 (2), 91\u2013110. Lowry, S., S\u00fcnderhauf, N., Newman, P ., et al. (2015). Visual place recognition: A survey. IEEE Transactions on Robotics (T-RO)32(1):1\u201319 Maddern, W., Pascoe, G., Linegar, C., et al. (2017). 1 year, 1000 km: The oxford robotcar dataset. International Journal of Robotics Research (IJRR), 36 (1), 3\u201315. Mur-Artal, R., & Tard\u00f3s, J.D. (2017). ORB-SLAM2: An open-source SLAM system for monocular, stereo, and RGB-D cameras. IEEETransactions on Robotics (T-RO) 33(5):1255\u20131262 Mur-Artal, R., Montiel, J.M.M., & Tardos, J.D. (2015). ORB-SLAM: a versatile and accurate monocular SLAM system. IEEE Transac-tions on Robotics (T-RO) 31(5):1147\u20131163 Newcombe, R.A., Lovegrove, S.J., & Davison, A.J. (2011). DTAM: dense tracking and mapping in real-time. In: Proceedings of theInternational Conference on Computer Vision (ICCV), pp 2320\u20132327 Pitropov, M., Garcia, D. E., Rebello, J., et al. (2021). Canadian adverse driving conditions datasett. International Journal of Robotics Research (IJRR), 40 (4\u20135), 681\u2013690. Radenovi\u00b4 c, F., Tolias, G., & Chum, O. (2016). CNN image retrieval learns from BoW: Unsupervised fine-tuning with hard examples.In: Proceedings of the European Conference on Computer Vision(ECCV), pp 3\u201320 Radenovi\u00b4 c, F., Tolias, G., & Chum, O. (2018). Fine-tuning CNN image retrieval with no human annotation. IEEE Transactions on Pattern Analysis and Machine Intelligence (PAMI), 41 (7), 1655\u20131668. Rehder, J., Nikolic, J., Schneider, T., et al. (2016). Extending kalibr: Calibrating the extrinsics of multiple IMUs and of individual axes.In: Proceedings of the IEEE International Conference on Roboticsand Automation (ICRA), pp 4304\u20134311 Revaud, J., Almazan, J., Rezende, R., et al. (2019a). Learning with average precision: Training image retrieval with a listwise loss. In:Proceedings of the International Conference on Computer Vision(ICCV), pp 5107\u20135116 Revaud, J., Weinzaepfel, P ., de Souza, C.R., et al. (2019b). R2D2: repeatable and reliable detector and descriptor. In: Neural Infor-mation Processing Systems (NeurIPS), pp 12,405\u201312,415 Sakaridis, C., Dai, D., V an Gool, L. (2021). ACDC: The adverse conditions dataset with correspondences for semantic driving sceneunderstanding. In: Proceedings of the International Conference onComputer Vision (ICCV) Sarlin, P .E., Cadena, C., Siegwart, R., et al. (2019). From coarse to fine: Robust hierarchical localization at large scale. In: Proceedings of 123 International Journal of Computer Vision the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) Sarlin, P .E., DeTone, D., Malisiewicz, T., et al. (2020). SuperGlue: Learning feature matching with graph neural networks. In: Pro-ceedings of the IEEE Conference on Computer Vision and PatternRecognition (CVPR) Sarlin, P .E., Dusmanu, M., Sch\u00f6nberger, J.L., et al. (2022). Lamar: Benchmarking localization and mapping for augmented reality.In: Proceedings of the European Conference on Computer Vision(ECCV) Sattler, T., Weyand, T., Leibe, B., et al. (2012). Image retrieval for image-based localization revisited. In: Proceedings of the BritishMachine Vision Conference (BMVC) Sattler, T., Maddern, W., Toft, C., et al. (2018). Benchmarking 6DOF outdoor visual localization in changing conditions. In: Proceedingsof the IEEE Conference on Computer Vision and Pattern Recog-nition (CVPR), pp 8601\u20138610 Sch\u00f6nberger, J.L., & Frahm, J.M. (2016). Structure-from-motion revisited. In: Proceedings of the IEEE Conference on Computer Visionand Pattern Recognition (CVPR), pp 4104\u20134113 Schonberger, J.L., Radenovic, F., Chum, O., et al. (2015). From single image query to detailed 3D reconstruction. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp 5126\u20135134 Schubert, D., Goll, T., Demmel, N., et al. (2018). The TUM VI benchmark for evaluating visual-inertial odometry. In: Proceedings of theIEEE/RSJ Conference on Intelligent Robots and Systems (IROS),pp 1680\u20131687 Sheeny, M., De Pellegrin, E., Mukherjee, S., et al. (2021). Radiate: A radar dataset for automotive perception in bad weather. In: Pro-ceedings of the IEEE International Conference on Robotics andAutomation (ICRA) Simonyan, K., & Zisserman, A. (2015). V ery deep convolutional networks for large-scale image recognition. In: Proceedings of theInternational Conference on Learning Representations (ICLR) Spencer, J., Bowden, R., & Hadfield, S. (2020). Same features, different day: Weakly supervised feature learning for seasonal invariance.In: Proceedings of the IEEE Conference on Computer Vision andPattern Recognition (CVPR), pp 6459\u20136468 von Stumberg, L., & Cremers, D. (2022). DM-VIO: Delayed marginalization visual-inertial odometry. IEEE Robotics and AutomationLetters (RA-L) 7(2):1408\u20131415 von Stumberg, L., Wenzel, P ., Khan, Q., et al. (2020). GN-Net: The gauss-newton loss for multi-weather relocalization. IEEE Roboticsand Automation Letters (RA-L) 5(2):890\u2013897 Sturm, J., Engelhard, N., Endres, F., et al. (2012). A benchmark for the evaluation of RGB-D SLAM systems. In: Proceedings of the IEEE/RSJ Conference on Intelligent Robots and Systems (IROS), pp 573\u2013580 Sun, J., Shen, Z., Wang, Y ., et al. (2021). Loftr: Detector-free local feature matching with transformers. In: Proceedings of the IEEEConference on Computer Vision and Pattern Recognition (CVPR),pp 8922\u20138931 Szegedy, C., Liu, W., Jia, Y ., et al. (2015). Going deeper with convolutions. In: Proceedings of the IEEE Conference on Computer Visionand Pattern Recognition (CVPR), pp 1\u20139Taira, H., Okutomi, M., Sattler, T., et al. (2018). Inloc: Indoor visual localization with dense matching and view synthesis. In: Proceed-ings of the IEEE Conference on Computer Vision and PatternRecognition (CVPR), pp 7199\u20137209 Teed, Z., Lipson, L., & Deng, J. (2023). Deep patch visual odometry. In: Neural Information Processing Systems (NeurIPS) Tolias, G., Sicre, R., & J\u00e9gou, H. (2015). Particular object retrieval with integral max-pooling of CNN activations. In: arXiv preprintarXiv:1511.05879 Torii, A., Sivic, J., Pajdla, T., et al. (2013). Visual place recognition with repetitive structures. In: Proceedings of the IEEE Conference onComputer Vision and Pattern Recognition (CVPR), pp 883\u2013890 Torii, A., Arandjelovic, R., Sivic, J., et al. (2015). 24/7 place recognition by view synthesis. In: Proceedings of the IEEE Conference onComputer Vision and Pattern Recognition (CVPR), pp 1808\u20131817 Umeyama, S. (1991). Least-squares estimation of transformation parameters between two point patterns. IEEE Transactions on Pattern Analysis and Machine Intelligence (PAMI), 13 (4), 376\u2013380. Usenko, V ., Demmel, N., Schubert, D., et al. (2019). Visual-inertial mapping with non-linear factor recovery. IEEE Robotics andAutomation Letters (RA-L) 5(2):422\u2013429 V alentin, J., Dai, A., Nie\u00dfner, M., et al. (2016). Learning to navigate the energy landscape. In: Proceedings of the International Conference on 3D Vision (3DV), pp 323\u2013332 V on Stumberg, L., Usenko, V ., & Cremers, D. (2018). Direct sparse visual-inertial odometry using dynamic marginalization. In: Pro-ceedings of the IEEE International Conference on Robotics andAutomation (ICRA), pp 2510\u20132517 Wang, R., Schw\u00f6rer, M., & Cremers, D. (2017a). Stereo DSO: Largescale direct sparse visual odometry with stereo cameras. In:Proceedings of the International Conference on Computer Vision(ICCV), pp 3903\u20133911 Wang, S., Bai, M., Mattyus, G., et al. (2017b). TorontoCity: Seeing the world with a million eyes. In: Proceedings of the InternationalConference on Computer Vision (ICCV) Warburg, F., Hauberg, S., Lopez-Antequera, M., et al. (2020). Mapillary street-level sequences: A dataset for lifelong place recognition.In: Proceedings of the IEEE Conference on Computer Vision andPattern Recognition (CVPR), pp 2626\u20132635 Wenzel, P ., Wang, R., Yang, N., et al. (2020). 4Seasons: A crossseason dataset for multi-weather SLAM in autonomous driving.In: Proceedings of the German Conference on Pattern Recogni-tion (GCPR) Yang, N., Wang, R., St\u00fcckler, J., et al. (2018). Deep virtual stereo odometry: Leveraging deep depth prediction for monocular direct sparseodometry. In: Proceedings of the European Conference on Com-puter Vision (ECCV), pp 817\u2013833 Publisher\u2019s Note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations."
      },
      "Geometry-aware Feature Matching for Large-Scale Structure from Motion": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2409.02310",
        "ref_texts": "[40] Johannes Lutz Sch \u00a8onberger, Enliang Zheng, Marc Pollefeys, and Jan-Michael Frahm. Pixelwise view selection for unstructured multi-view stereo. In European Conference on Computer Vision (ECCV) , 2016. 3, 4, 6[41] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. LoFTR: Detector-free local feature matching with transformers. CVPR , 2021. 2, 3, 5, 7",
        "ref_ids": [
          "40",
          "41"
        ]
      },
      "Aligning Motion-Blurred Images Using Contrastive Learning on Overcomplete Pixels": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2410.07410",
        "ref_texts": "18, pages 234\u2013241. Springer, 2015. Jianing Song, Duarte Rondao, and Nabil Aouf. Deep learning-based spacecraft relative navigation methods: A survey. Acta Astronautica , 191:22\u201340, 2022. Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , pages 8922\u20138931, 2021. Evelyn Tang, Marcelo G Mattar, Chad Giusti, David M Lydon-Staley, Sharon L Thompson-Schill, and Danielle S Bassett. Effective learning is accompanied by high-dimensional and efficient representations of neural activity. Nature neuroscience , 22(6):1000\u20131009, 2019. Jeya Maria Jose Valanarasu and Vishal M Patel. Overcomplete deep subspace clustering networks. InProceedings of the IEEE/CVF winter conference on applications of computer vision , pages 746\u2013755, 2021. Xinlong Wang, Rufeng Zhang, Chunhua Shen, Tao Kong, and Lei Li. Dense contrastive learning for self-supervised visual pre-training. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , pages 3024\u20133033, 2021. Enze Xie, Wenhai Wang, Zhiding Yu, Anima Anandkumar, Jose M Alvarez, and Ping Luo. Segformer: Simple and efficient design for semantic segmentation with transformers. Advances in neural information processing systems , 34:12077\u201312090, 2021."
      },
      "CMR-Agent: Learning a Cross-Modal Agent for Iterative Image-to-Point Cloud Registration": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2408.02394?",
        "ref_texts": "[5] J. Sun, Z. Shen, Y . Wang, H. Bao, and X. Zhou, \u201cLoftr: Detector-free local feature matching with transformers,\u201d in Computer Vision and Pattern Recognition , 2021.",
        "ref_ids": [
          "5"
        ]
      },
      "UWStereo: A Large Synthetic Dataset for Underwater Stereo Matching": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2409.01782",
        "ref_texts": "[47] J. Sun, Z. Shen, Y . Wang, H. Bao, and X. Zhou, \u201cLoftr: Detector-Free Local Feature Matching With Transformers,\u201d in CVPR , 2021, pp. 8922\u2013",
        "ref_ids": [
          "47"
        ]
      },
      "Design and Identification of Keypoint Patches in Unstructured Environments": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2410.00521",
        "ref_texts": "8. Sun, J., Shen, Z., Wang, Y., Bao, H., Zhou, X.: Loftr: Detector-free local feature matching with transformers. In: conference on Computer Vision and Pattern Recognition. (2021) 8922\u20138931",
        "ref_ids": [
          "8"
        ]
      },
      "CCTNet: A Circular Convolutional Transformer Network for LiDAR-based Place Recognition Handling Movable Objects Occlusion": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2405.10793",
        "ref_texts": "[27] J. Sun, Z. Shen, Y . Wang, H. Bao, and X. Zhou, \u201cLoftr: Detectorfree local feature matching with transformers,\u201d in Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , Conference Proceedings, pp. 8922\u20138931.",
        "ref_ids": [
          "27"
        ]
      },
      "MinBackProp--Backpropagating through Minimal Solvers": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2404.17993",
        "ref_texts": ""
      },
      "Unsupervised Skin Feature Tracking with Deep Neural Networks": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2405.04943",
        "ref_texts": "10 Gulbadan Sikander and Shahzad Anwar. Driver fatigue detection systems: A review. IEEE Transactions on Intelligent Transportation Systems , 20(6):2339\u20132352, 2018. Marzuraikah Mohd Stofa, Mohd Asyraf Zulkifley, and Muhammad Ammirrul Atiqi Mohd Zainuri. Skin lesions classification and segmentation: A review. International Journal of Advanced Computer Science and Applications , 12(10), 2021. Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free localfeaturematching wi th transformers. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , pages 8922\u2013"
      },
      "SDGE: Stereo Guided Depth Estimation for 360 {\\deg} Camera Sets": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2402.11791",
        "ref_texts": "[40] J. Sun, Z. Shen, Y . Wang, H. Bao, and X. Zhou, \u201cLoftr: Detectorfree local feature matching with transformers,\u201d in Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , 2021, pp. 8922\u20138931.",
        "ref_ids": [
          "40"
        ]
      },
      "LoFLAT: Local Feature Matching using Focused Linear Attention Transformer": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2410.22710",
        "ref_texts": "[15] J. Sun, Z. Shen, Y . Wang, H. Bao, and X. Zhou, \u201cLoftr: Detector-free local feature matching with transformers,\u201d inProceedings of the IEEE/CVF conference on computer vision and pattern recognition , 2021, pp. 8922\u2013",
        "ref_ids": [
          "15"
        ]
      },
      "HomoMatcher: Dense Feature Matching Results with Semi-Dense Efficiency by Homography Estimation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2411.06700",
        "ref_texts": "4947. Schonberger, J. L.; and Frahm, J.-M. 2016. Structure-frommotion revisited. In Proceedings of the IEEE conference on computer vision and pattern recognition , 4104\u20134113. Sun, J.; Shen, Z.; Wang, Y .; Bao, H.; and Zhou, X. 2021. LoFTR: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , 8922\u20138931. Vaswani, A. 2017. Attention is all you need. arXiv preprint arXiv:1706.03762 . Wang, X.; Xu, R.; Cui, Z.; Wan, Z.; and Zhang, Y .",
        "ref_ids": [
          "4947"
        ]
      },
      "XPoint: A Self-Supervised Visual-State-Space based Architecture for Multispectral Image Registration": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2411.07430",
        "ref_texts": "[15] J. Sun, Z. Shen, Y . Wang, H. Bao, and X. Zhou, \u201cLoFTR: Detector-free local feature matching with transformers,\u201d CVPR , 2021.",
        "ref_ids": [
          "15"
        ]
      },
      "Application of non-contact video quantitative measurement method in reservoir bank landslide monitoring": {
        "authors": [],
        "url": "https://www.frontiersin.org/articles/10.3389/feart.2024.1378046/pdf",
        "ref_texts": "(2024). Higher temperature sensitivity of retrogressive thaw slump activity in the arctic compared to the third pole. Science of The Total Environment (914), 170007. doi:10.1016/j.scitotenv.2024.170007 Ming, Z. Z., Bing, Z., Weng, Y. Z., Xu, D. Y., and Li, H. X. (2020). Design and practice of high precision landslide displacement monitoring system based on VRS.Chin.J.Geol.HazardControl (06), 54\u201359. doi: 10.16031/j.cnki.issn.10038035.2020.06.07 Peng, J. B. (2006). Some important problems to be addressed in reserch of active tectinics and environmental disasters in China. Journal of Engineering Geology (01), 5\u201312.Chinese. Peng,T.,Xu,G.,andXia,D.(2004).Trendofgeologicalhazardsandcountermeasure of disaster reduction in the three gorges reservoir area. Journal Of Mountain Science (06),719\u2013724.Chinese.doi: 10.16089/j.cnki.1008-2786.2004.06.014 Rocco, I., Cimpoi, M., Arandjelovi, R., Torii, A., Pajdla, T., and Sivic, J. (2018). Neighbourhoodconsensusnetworks .doi:10.48550/arXiv.1810.10510 Rohrbaugh,N.B.(2015).Anewtechniqueformodelingthegeomorphologyofaslow moving,soft-slopelandslideusingterrestrialLiDAR.Rosone,M.,Ziccarelli,M.,Ferrari,A.,andCamillo,A.F.(2018).Onthereactivation ofalargelandslideinducedbyrainfallinhighlyfissuredclays[J]. Eng.Geol. 235,20\u201338. doi:10.1016/j.enggeo.2018.01.016 Ru, Y. X., and Xiu, F. H. (2019). Deformation monitoring of reservoirs and dams using time-series InSAR. Geomatics Inf. Sci. Wuhan Univ. (09), 1334\u20131341. doi:10.13203/j.whugis20170327 Rui,W.,Yu,L.X.,Shi,Z.W.,Yu,L.Z.,andTing,Z.(2021).Studyoncumulativetime seriesdeformationmonitoringinminingareabasedonDInSARtechnology. Industrial MineralsProcess. (11),44\u201347+53.doi: 10.16283/j.cnki.hgkwyjg.2021.11.008 Song, L. L., Qiang, X., Liang, M. T., and Dong, X. Z. (2020). Study on spatial distribution and key influencing factors of landslides in three Gorges reservoir area. EarthSci. (01),341\u2013354.doi: 10.3799/dqkx.2017.576 Spreafico, M. C., Francioni, M., Cervi, F., Stead, D., Bitelli, G., Ghirotti, M., et al. (2016). Back analysis of the 2014 san leo landslide using combined terrestrial laser scanning and 3d distinct element modelling. Rock Mechanics&Rock Eng . doi:10.1007/s00603-015-0763-5 Sun,J.,Shen,Z.,Wang,Y.,Bao,H.,andZhou,X.(2021).LoFTR:detector-freelocal feature matching with transformers. Computer Vision and Pattern Recognition. IEEE . doi:10.1109/CVPR46437.2021.00881 Tao, P., Gang, X., and Da, Q. X. (2004). Trend of geological hazards and countermeasureofdisasterreductioninthethreeGorgesreservoirarea. J.Mt.Sci. (06), 719\u2013724.doi: 10.16089/j.cnki.1008-2786.2004.06.014 Tian, Y., Zhu, J. H., Li, Q., et al. (2020). Spatial and temporal distribution of soil conservationanditsdrivingforcesinthethreegorgesreservoirarea. ChineseJournalof Ecology(04),1164\u20131174.Chinese.doi: 10.13292/j.1000-4890.202004.019 Wang, R., Xue, Y. L., Wan, S. Z., Zheng, Y. L., and Zhang, T. (2021). Study on cumulative time series deformation monitoring in mining area based on DInSAR technology. Industrial Minerals And Procession (04), 44\u201347. Chinese. doi:10.16283/j.cnki.hgkwyjg.2021.11.008 Wei, H., Lun, N. Z., Cheng, C. H., Xiao, L., and Lian, K. S. (2019). Research and application of big data information platform for geological disaster monitoring. Bull. Surv.Mapp. (01),127\u2013131.doi: 10.13474/j.cnki.11-2246.2019.0026 Xiao, R. Y., and He, X. F. (2019). Deformation monitoring of reservoirs and dams usingtime-seriesInSAR. GeomaticsandInformationScienceofWuhanUniversity (09), 1334\u20131341.Chinese.doi: 10.13203/j.whugis20170327 Ya, L., Jun, H. Q., Ulrich, K., Wang, N., Wang, J., Huang, C., et al. (2024). Higher temperature sensitivity of retrogressive thaw slump activity in the Arctic compared to theThirdPole. Sci.TotalEnviron. 914(914),170007.doi: 10.1016/j.scitotenv.2024.170007 Yang, D. D., Qiu, H. J., Hu, S., Pei, Y. Q., Wang, X. G., Du, C., et al. (2021). Influence of successive landslides on topographic changes revealed by multitemporal high-resolution UAS-based DEM. Catena: An Interdisciplinary Journal of Soil Science Hydrology-Geomorphology Focusing on Geoecology and Landscape Evolution (202), 105229.doi: 10.1016/j.catena.2021.105229 Yang, L., Pan, F., Wei, F. J., Sheng, W. S., Yong, Z., and Zhang, T. (2016). Predictive method of nonlinear system based on artificial neural network and svm. Oxid. Commun. (1A),1226\u20131235. Yang, Y. S., Shu, L. Y., Fu, C. H., Shao, W., Kui, N. W., Zhao, K., et al. (2019). Superpixel-based automatic image recognition for landslide deformation areas. Eng. Geol.259,105166.doi: 10.1016/j.enggeo.2019.105166 Ye, B. F., Qiu, H. J., Tang, B. J., Liu, Y., Liu, Z. J., Jiang, X. Y., et al. (2024). Creep deformation monitoring of landslides in a reservoir area. Journal of Hydrology (632), 130905.doi: 10.1016/j.jhydrol.2024.130905 Yin,Z.K.,Liao,W.H.,Lei,X.H.,andWang,H.(2018).Comparingthehydrological responsesofconceptualandprocess-basedmodelswithvaryingrainGaugedensityand distribution[J]. Sustainability 10(9),130905.doi: 10.3390/su10093209 Yu, T., Jian, H. Z., Qi, L., Yuan, F., Chen, Y. L., and Weng, F. X. (2020). Spatial and temporal distribution of soil conservation and its driving forces in the Three Gorges ReservoirArea. Chin.J.Ecol. (04),1164\u20131174.doi: 10.13292/j.1000-4890.202004.019 Zhang, M. Z., Zhan, B., Zhao, W. Y., et al. (2020). Design and practice of high precision landslide displacement monitoring system based on VRS. The Chinese JournalofGeologicalHazardandControl (06),54\u201359.doi: 10.16031/j.cnki.issn.10038035.2020.06.07 Zhao, K. Z., Wei, H. L., Xiao, H. L., Hao, W., and Ruo, J. W. (2018). Comparing the hydrologicalresponsesofconceptualandprocess-basedmodelswithvaryingraingauge densityanddistribution. Sustainability 10(9),3209.doi: 10.3390/su10093209 Frontiers in Earth Science 11 frontiersin.org "
      },
      "Visual place recognition for autonomous mobile robot navigation using LoFTR and MAGSAC++": {
        "authors": [],
        "url": "https://e-jurnal.pnl.ac.id/polimesin/article/download/4992/3833",
        "ref_texts": "[20] J. Sun, Z. Shen, Y. Wang, H. Bao, and X. Zhou, \u201cLoFTR: Detector -Free Local Feature Matching with Transformers,\u201d Proc. IEEE Comput. Soc. Conf. Comput. Vis. Pattern Recognit. , vol. 4, pp. 8918 \u20138927, 2021, doi: ",
        "ref_ids": [
          "20"
        ]
      },
      "Leveraging Semantic Cues from Foundation Vision Models for Enhanced Local Feature Correspondence": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2410.09533",
        "ref_texts": "19. Sun, J., Shen, Z., Wang, Y., Bao, H., Zhou, X.: Loftr: Detector-free local feature matching with transformers. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). pp. 8922\u20138931 (2021)",
        "ref_ids": [
          "19"
        ]
      },
      "Descriptor Distillation: A Teacher-Student-Regularized Framework for Learning Local Descriptors": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2209.11795",
        "ref_texts": "(2021). Loftr: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 8922\u20138931. Tian, Y., Barroso-Laguna, A., Ng, T., Balntas, V., and Mikolajczyk, K. (2020). Hynet: Learning local descriptor with hybrid similarity measure and triplet loss. In Neural Information Processing Systems , volume 33, pages 7401\u20137412. Tian, Y., Fan, B., and Wu, F. (2017). L2-net: Deep learning of discriminative patch descriptor in euclidean space. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 661\u2013669. Tian, Y., Yu, X., Fan, B., Wu, F., Heijnen, H., and Balntas, V. (2019). Sosnet: Second order similarity regularization for local descriptor learning. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 11016\u201311025. Tyszkiewicz, M., Fua, P., and Trulls, E. (2020). Disk: Learning local features with policy gradient. Neural Information Processing Systems , 33:14254\u201314265. Wang, C., Zhang, X., and Lan, X. (2017). How to train triplet networks with 100k identities? InProceedings of the IEEE International Conference on Computer Vision Workshops , pages 1907\u20131915. Yu, B., Liu, T., Gong, M., Ding, C., and Tao, D. (2018). Correcting the triplet selection bias Submitted to IJCV"
      },
      "A Robust Multisource Remote Sensing Image Matching Method Utilizing Attention and Feature Enhancement Against Noise Interference": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2410.11848?",
        "ref_texts": "[24] J. Sun, Z. Shen, Y . Wang, H. Bao and X. Zhou, \u201cLoFTR: DetectorFree Local Feature Matching with transformers,\u201d in Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR) , Nashville, TN, USA, 2021, pp.",
        "ref_ids": [
          "24"
        ]
      },
      "Robust Two-View Geometry Estimation with Implicit Differentiation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2410.17983",
        "ref_texts": "[11] J. Sun, Z. Shen, Y . Wang, H. Bao, and X. Zhou, \u201cLoftr: Detectorfree local feature matching with transformers,\u201d in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) , June 2021, pp. 8922\u20138931.",
        "ref_ids": [
          "11"
        ]
      },
      "DD_RoTIR: Dual-Domain Image Registration via Image Translation and Hierarchical Feature-matching": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2407.11223",
        "ref_texts": "[27] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , pages 8922\u20138931, 2021.",
        "ref_ids": [
          "27"
        ]
      },
      "Map-Free Visual Relocalization Enhanced by Instance Knowledge and Depth Knowledge": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2408.13085",
        "ref_texts": "[10] J. Sun, Z. Shen, Y . Wang, H. Bao, and X. Zhou, \u201cLoftr: Detectorfree local feature matching with transformers,\u201d in Computer Vision and Pattern Recognition Conference , 2021.",
        "ref_ids": [
          "10"
        ]
      },
      "BronchoTrack: Airway Lumen Tracking for Branch-Level Bronchoscopic Localization": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2402.12763",
        "ref_texts": "[40] J. Sun, Z. Shen, Y . Wang, H. Bao, and X. Zhou, \u201cLoftr: Detector-free local feature matching with transformers,\u201d inProceedings of the IEEE/CVF conference on computer vision and pattern recognition , 2021, pp. 8922\u20138931.",
        "ref_ids": [
          "40"
        ]
      },
      "Towards Human-Level 3D Relative Pose Estimation: Generalizable, Training-Free, with Single Reference": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2406.18453",
        "ref_texts": "[56] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. LoFTR: Detector-free local feature matching with transformers. CVPR , 2021. 2, 4, 6",
        "ref_ids": [
          "56"
        ]
      },
      "Towards Real-World Aerial Vision Guidance with Categorical 6D Pose Tracker": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2401.04377",
        "ref_texts": "[56] J. Sun, Z. Shen, Y. Wang, H. Bao, and X. Zhou, \u201cLoftr: Detectorfree local feature matching with transformers,\u201d in Proc. IEEE Conf. Comput. Vis. Pattern Recognit. , 2021, pp. 8922\u20138931.",
        "ref_ids": [
          "56"
        ]
      },
      "CT-MVSNet: Efficient Multi-view Stereo with Cross-Scale Transformer": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2312.08594",
        "ref_texts": "20. Sun, J., Shen, Z., Wang, Y., Bao, H., Zhou, X.: Loftr: Detector-free local feature matching with transformers. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 8922\u20138931 (2021)",
        "ref_ids": [
          "20"
        ]
      },
      "EasyHeC++: Fully Automatic Hand-Eye Calibration with Pretrained Image Models": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2410.09293",
        "ref_texts": "[31] J. Sun, Z. Shen, Y . Wang, H. Bao, and X. Zhou, \u201cLoftr: Detectorfree local feature matching with transformers,\u201d in CVPR , 2021, pp.",
        "ref_ids": [
          "31"
        ]
      },
      "JointLoc: A Real-time Visual Localization Framework for Planetary UAVs Based on Joint Relative and Absolute Pose Estimation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2405.07429",
        "ref_texts": "[9] J. Sun, Z. Shen, Y . Wang, H. Bao, and X. Zhou, \u201cLoFTR: Detectorfree local feature matching with transformers,\u201d in Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, 2021, pp. 8922\u20138931.",
        "ref_ids": [
          "9"
        ]
      },
      "RoTIR: Rotation-Equivariant Network and Transformers for Fish Scale Image Registration": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2401.11270",
        "ref_texts": "[8]J. Sun, Z. Shen, Y . Wang, H. Bao, and X. Zhou. Loftr: Detector-free local feature matching with transformers. In CVPR , pages 8922\u20138931, 2021.",
        "ref_ids": [
          "8"
        ]
      },
      "Keypoint Matching for Instrument-Free 3D Registration in Video-Based Surgical Navigation": {
        "authors": [],
        "url": "https://papers.miccai.org/miccai-2024/paper/3454_paper.pdf",
        "ref_texts": "22. Sun, J., Shen, Z., Wang, Y., Bao, H., Zhou, X.: LoFTR: Detector-Free Local Feature Matching With Transformers. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). pp. 8922\u20138931 (June 2021)",
        "ref_ids": [
          "22"
        ]
      },
      "Automatic Image Unfolding and Stitching Framework for Esophageal Lining Video Based on Density-Weighted Feature Matching": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2410.01148",
        "ref_texts": "[13] Sun, J., Shen, Z., Wang, Y., Bao, H., and Zhou, X., \u201cLoFTR: Detector-Free Local Feature Matching with Transformers,\u201d arXiv e-prints , arXiv:2104.00680 (Apr. 2021).",
        "ref_ids": [
          "13"
        ]
      },
      "MEDPNet: Achieving High-Precision Adaptive Registration for Complex Die Castings": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2403.09996",
        "ref_texts": "[46] J. Sun, Z. Shen, Y. Wang, H. Bao, and X. Zhou, \u201cLoftr: Detector-free local feature matching with transformers,\u201d in Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , 2021, pp. 8922\u20138931.",
        "ref_ids": [
          "46"
        ]
      },
      "MonoPlane: Exploiting Monocular Geometric Cues for Generalizable 3D Plane Reconstruction": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2411.01226",
        "ref_texts": "[51] J. Sun, Z. Shen, Y . Wang, H. Bao, and X. Zhou, \u201cLoftr: Detectorfree local feature matching with transformers,\u201d in CVPR , 2021, pp.",
        "ref_ids": [
          "51"
        ]
      },
      "VRHCF: Cross-Source Point Cloud Registration via Voxel Representation and Hierarchical Correspondence Filtering": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2403.10085"
      },
      "Matching Non-Identical Objects": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2403.08227",
        "ref_texts": "[36] Sun, J., Shen, Z., Wang, Y ., Bao, H., Zhou, X.: LoFTR: Detector-free local feature matching with transformers. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) (2021) 1, 2, 5, 6, 7, 8",
        "ref_ids": [
          "36"
        ]
      },
      "The FIP 1.0 Data Set: Highly Resolved Annotated Image Time Series of 4,000 Wheat Plots Grown in Six Years": {
        "authors": [],
        "url": "https://www.biorxiv.org/content/biorxiv/early/2024/10/26/2024.10.04.616624.full.pdf",
        "ref_texts": "33. Sun J, Shen Z, Wang Y, Bao H, Zhou X. LoFTR: Detector-free local feature matching with transformers. In: Proceedings of the IEEE/CVF conference on computer vision and pattern recognition; 2021. p. 8922\u20138931.",
        "ref_ids": [
          "33"
        ]
      },
      "SuperPose: Improved 6D Pose Estimation with Robust Tracking and Mask-Free Initialization": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2409.19986",
        "ref_texts": "4938\u20134947, 2020. Shugurov, I., Li, F., Busam, B., and Ilic, S. Osop: A multistage one shot object pose estimation framework. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pp. 6835\u20136844, 2022. Sun, J., Shen, Z., Wang, Y ., Bao, H., and Zhou, X. Loftr: Detector-free local feature matching with transformers. InProceedings of the IEEE/CVF conference on computer vision and pattern recognition , pp. 8922\u20138931, 2021. Tian, M., Ang, M. H., and Lee, G. H. Shape prior deformation for categorical 6d object pose and size estimation. InComputer Vision\u2013ECCV 2020: 16th European Conference, Glasgow, UK, August 23\u201328, 2020, Proceedings, Part XXI 16 , pp. 530\u2013546. Springer, 2020. Tian, Y ., Yu, X., Fan, B., Wu, F., Heijnen, H., and Balntas, V . Sosnet: Second order similarity regularization for local descriptor learning. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) , June 2019. Tremblay, J., To, T., Sundaralingam, B., Xiang, Y ., Fox, D., and Birchfield, S. Deep object pose estimation for semantic robotic grasping of household objects. arXiv preprint arXiv:1809.10790 , 2018. Tyszkiewicz, M., Fua, P., and Trulls, E. Disk: Learning local features with policy gradient. In Larochelle, H., Ranzato, M., Hadsell, R., Balcan, M., and Lin, H. (eds.), Advances in Neural Information Processing Systems , volume 33, pp. 14254\u201314265. Curran Associates, Inc., 2020. URL https://proceedings.neurips. cc/paper_files/paper/2020/file/ a42a596fc71e17828440030074d15e74-Paper. pdf. Vaswani, A. Attention is all you need. Advances in Neural Information Processing Systems , 2017.Wang, H., Sridhar, S., Huang, J., Valentin, J., Song, S., and Guibas, L. J. Normalized object coordinate space for category-level 6d object pose and size estimation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pp. 2642\u20132651, 2019. Wen, B., Mitash, C., Soorian, S., Kimmel, A., Sintov, A., and Bekris, K. E. Robust, occlusion-aware pose estimation for objects grasped by adaptive hands. In 2020 IEEE International Conference on Robotics and Automation (ICRA) , pp. 6210\u20136217. IEEE, 2020. Wen, B., Lian, W., Bekris, K., and Schaal, S. Catgrasp: Learning category-level task-relevant grasping in clutter from simulation. In 2022 International Conference on Robotics and Automation (ICRA) , pp. 6401\u20136408. IEEE, 2022a. Wen, B., Lian, W., Bekris, K., and Schaal, S. You only demonstrate once: Category-level manipulation from single visual demonstration. arXiv preprint arXiv:2201.12716 , 2022b. Wen, B., Yang, W., Kautz, J., and Birchfield, S. Foundationpose: Unified 6d pose estimation and tracking of novel objects. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pp."
      },
      "Silver medal Solution for Image Matching Challenge 2024": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2411.01851",
        "ref_texts": "[33] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , pages 8922\u20138931, 2021.",
        "ref_ids": [
          "33"
        ]
      },
      "CLAP: Concave Linear APproximation for Quadratic Graph Matching": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2410.17101?",
        "ref_texts": "21. Sun, J., Shen, Z., Wang, Y., Bao, H., Zhou, X.: Loftr: Detector-free local feature matching with transformers. In: CVPR. pp. 8922\u20138931 (2021)",
        "ref_ids": [
          "21"
        ]
      },
      "AnyOKP: One-Shot and Instance-Aware Object Keypoint Extraction with Pretrained ViT": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2309.08134",
        "ref_texts": "[22] J. Sun, Z. Shen, Y. Wang, et al., \u201cLoFTR: Detector -free local feature matching with transformers ,\u201d in Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit. , 2021, pp. 8922 -8931. ",
        "ref_ids": [
          "22"
        ]
      },
      "MaFreeI2P: A Matching-Free Image-to-Point Cloud Registration Paradigm with Active Camera Pose Retrieval": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2408.02392",
        "ref_texts": "[2] J. Sun, Z. Shen, Y . Wang, and et al., \u201cLoFTR: Detector-free local feature matching with transformers,\u201d in CVPR , 2021.",
        "ref_ids": [
          "2"
        ]
      },
      "Rethink Predicting the Optical Flow with the Kinetics Perspective": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2405.12512",
        "ref_texts": "[47] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In CVPR , 2021. 8",
        "ref_ids": [
          "47"
        ]
      },
      "Image Plagiarism Detection Pipeline for Vast Databases": {
        "authors": [],
        "url": "https://fruct.org/publications/volume-35/fruct35/files/Kap.pdf",
        "ref_texts": ""
      },
      "Find the Assembly Mistakes: Error Segmentation for Industrial Applications": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2408.12945",
        "ref_texts": "26. Sun, J., Shen, Z., Wang, Y., Bao, H., Zhou, X.: LoFTR: Detector-free local feature matching with transformers. CVPR (2021)",
        "ref_ids": [
          "26"
        ]
      },
      "ConDL: Detector-Free Dense Image Matching": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2408.02766",
        "ref_texts": "20. Sun, J., Shen, Z., Wang, Y., Bao, H., Zhou, X.: LoFTR: Detector-free local feature matching with transformers. CVPR (2021)",
        "ref_ids": [
          "20"
        ]
      },
      "Exploiting Motion Prior for Accurate Pose Estimation of Dashboard Cameras": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2409.18673",
        "ref_texts": "[5] J. Sun, Z. Shen, Y . Wang, H. Bao, and X. Zhou, \u201cLoftr: Detectorfree local feature matching with transformers,\u201d in Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , 2021, pp. 8922\u20138931.",
        "ref_ids": [
          "5"
        ]
      },
      "SuperVINS: A Real-Time Visual-Inertial SLAM Framework for Challenging Imaging Conditions": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2407.21348",
        "ref_texts": "[14] J. Sun, Z. Shen, Y . Wang, H. Bao, and X. Zhou, \u201cLoFTR: Detector-free local feature matching with transformers,\u201d in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , 2021, pp. 8922\u20138931.",
        "ref_ids": [
          "14"
        ]
      },
      "Skin feature point tracking using deep feature encodings": {
        "authors": [
          "Jose Ramon"
        ],
        "url": "https://link.springer.com/content/pdf/10.1007/s13042-024-02405-y.pdf",
        "ref_texts": ""
      },
      "Multi-Camera Multi-Person Association using Transformer-Based Dense Pixel Correspondence Estimation and Detection-Based Masking": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2408.09295",
        "ref_texts": "[9] J. Sun, Z. Shen, Y. Wang, H. Bao, and X. Zhou, \u201cLoFTR: Detector-Free Local Feature Matching with Transformers,\u201d arXiv.org , 2021, doi: ",
        "ref_ids": [
          "9"
        ]
      },
      "GMTR: Graph Matching Transformers": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2311.08141",
        "ref_texts": "[11] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou, \u201cLoftr: Detector-free local feature matching with transformers,\u201d in CVPR , 2021.",
        "ref_ids": [
          "11"
        ]
      },
      "Attention-based multimodal image matching": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2103.11247",
        "ref_texts": "[23] J. Sun, Z. Shen, Y . Wang, H. Bao, and X. Zhou, \u201cLoFTR: Detector-free local feature matching with transformers,\u201d Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) , pp.",
        "ref_ids": [
          "23"
        ]
      },
      "Comparative Analysis of Advanced Feature Matching Algorithms in Challenging High Spatial Resolution Optical Satellite Stereo Scenarios": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2405.06246",
        "ref_texts": ""
      },
      "Transformer-based local feature matching for multimodal image registration": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2404.16802",
        "ref_texts": "[10] Sun, J., Shen, Z., Wang, Y., Bao, H., and Zhou, X., \u201cLoftr: Detector-free local feature matching with transformers,\u201d in [Proceedings of the IEEE/CVF conference on computer vision and pattern recognition ], 8922\u20138931 (2021).",
        "ref_ids": [
          "10",
          "Proceedings of the IEEE/CVF conference on computer vision and pattern recognition "
        ]
      },
      "Reliable Image Matching Using Optimal Combination of Color and Intensity Information Based on Relationship with Surrounding Objects": {
        "authors": [],
        "url": "https://www.jstage.jst.go.jp/article/transinf/E107.D/10/E107.D_2024EDP7039/_pdf",
        "ref_texts": "[25] J. Sun, Z. Shen, Y. Wang, H. Bao, and X. Zhou, \u201cLoFTR: Detectorfree local feature matching with transformers,\u201d Proc. IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp.8922\u20138931, 2021.",
        "ref_ids": [
          "25"
        ]
      },
      "Ground-to-Aerial Image Matching for Vehicle Localization": {
        "authors": [],
        "url": "https://research.tudelft.nl/files/227816055/Phd_thesis_20241114.pdf",
        "ref_texts": "[73] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 8922\u20138931, 2021.",
        "ref_ids": [
          "73"
        ]
      },
      "Learnable Graph Matching: A Practical Paradigm for Data Association": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2303.15414",
        "ref_texts": "[46] J. Sun, Z. Shen, Y. Wang, H. Bao, and X. Zhou, \u201cLoFTR: Detectorfree local feature matching with transformers,\u201d in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2021, pp. 8922\u20138931.",
        "ref_ids": [
          "46"
        ]
      },
      "Learning Visual Representations from Cross-Modal Correspondence": {
        "authors": [],
        "url": "https://deepblue.lib.umich.edu/bitstream/handle/2027.42/193255/mbanani_1.pdf?sequence=1",
        "ref_texts": "[272] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. LoFTR: Detector-free local feature matching with transformers. CVPR , 2021. 48, 49, 55, 56, 68",
        "ref_ids": [
          "272"
        ]
      },
      "SemFE: A Feature Matching Method for Learnable Local Semantic Feature Enhancement in Multimodal images": {
        "authors": [],
        "url": "https://www.researchsquare.com/article/rs-5275064/latest.pdf",
        "ref_texts": "19.Sun, J., Shen, Z., Wang, Y . et al. Loftr: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , 8922\u20138931 (2021).",
        "ref_ids": [
          "19"
        ]
      },
      "Learning and Optimizing Camera Pose": {
        "authors": [],
        "url": "https://research.chalmers.se/publication/539208/file/539208_Fulltext.pdf",
        "ref_texts": "[35] J. Sun, Z. Shen, Y . Wang, H. Bao, and X. Zhou, \u201cLoftr: Detector-free local feature matching with transformers,\u201d in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) , Jun. 2021, pp. 8922\u2013",
        "ref_ids": [
          "35"
        ]
      },
      "Unsupervised Neural Network-Based Image Stitching Method for Bladder Endoscopy": {
        "authors": [],
        "url": "https://www.biorxiv.org/content/10.1101/2024.09.24.614700.full.pdf",
        "ref_texts": "[24] Sun J, Shen Z, Wang Y, et al. (2021) LoFTR: Detector-free local feature matching with transformers. Proc. IEEE/CVF Conf Comp Vision Pattern Recog 8922-8931.",
        "ref_ids": [
          "24"
        ]
      },
      "Cross-modal semi-dense image matching": {
        "authors": [],
        "url": "https://open.metu.edu.tr/bitstream/handle/11511/111012/Master_Thesis_Onder_Tuzcuoglu.pdf",
        "ref_texts": "[11] J. Sun, Z. Shen, Y . Wang, H. Bao, and X. Zhou, \u201cLoftr: Detector-free local feature matching with transformers,\u201d in Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , pp. 8922\u20138931, 2021.",
        "ref_ids": [
          "11"
        ]
      },
      "Adaptive Visual-Inertial Odometry Using SuperGlue and Dynamic EKF with Information-Based Confidence Estimation": {
        "authors": [],
        "url": "https://www.researchsquare.com/article/rs-4935014/latest.pdf",
        "ref_texts": "[14]Sun, J., Shen, Z., Wang, Y., Bao, H., Zhou, X.: Loftr: Detector-free local f eature matching with transformers. In: Proceedings of the IEEE/CVF Confere nce on Computer Vision and Pattern Recognition, pp. 8922\u20138931 (2021)",
        "ref_ids": [
          "14"
        ]
      },
      "Vision-Based 6D Pose Estimation and Tracking: From Known to Novel Objects": {
        "authors": [],
        "url": "https://qmro.qmul.ac.uk/xmlui/bitstream/handle/123456789/99018/PhD_Thesis_Long.pdf?sequence=2",
        "ref_texts": "[120] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. LoFTR: Detector-free local feature matching with transformers. In IEEE conference on Computer Vision and Pattern Recognition , pages 8922\u20138931, 2021.",
        "ref_ids": [
          "120"
        ]
      },
      "Application of deep learning for enhancing simultaneous localization and mapping in autonomous driving": {
        "authors": [],
        "url": "https://dr.ntu.edu.sg/bitstream/10356/174794/2/Thesis-GeJintian.pdf",
        "ref_texts": "[91] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. CoRR , abs/2104.00680, 2021. 49",
        "ref_ids": [
          "91"
        ]
      },
      "Cross-modal image feature matching between infrared and visual images. Adapting intra-modal feature matching models for cross-modal matching": {
        "authors": [],
        "url": "https://odr.chalmers.se/bitstreams/d8e4679b-f582-45f7-a92b-1d0e451b81c0/download",
        "ref_texts": "[12] J. Sun, Z. Shen, Y. Wang, H. Bao, and X. Zhou, \u201cLoFTR: Detector-Free Local Feature Matching with Transformers,\u201d Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition , pp. 8918\u2013",
        "ref_ids": [
          "12"
        ]
      },
      "Sparse-to-dense Multimodal Image Registration via Multi-Task Learning": {
        "authors": [],
        "url": "https://openreview.net/pdf?id=q0vILV7zAw",
        "ref_texts": "4938\u20134947, 2020.Sarlin, P.-E., Unagar, A., Larsson, M., Germain, H., Toft, C., Larsson, V ., Pollefeys, M., Lepetit, V ., Hammarstrand, L., Kahl, F., et al. Back to the feature: Learning robust camera localization from pixels to pose. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pp. 3247\u20133257, 2021. Schonberger, J. L. and Frahm, J.-M. Structure-from-motion revisited. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pp. 4104\u20134113, 2016. Sener, O. and Koltun, V . Multi-task learning as multiobjective optimization. Advances in Neural Information Processing Systems , 31, 2018. Standley, T., Zamir, A., Chen, D., Guibas, L., Malik, J., and Savarese, S. Which tasks should be learned together in multi-task learning? In Proceedings of the International Conference on Machine Learning , pp. 9120\u20139132, 2020. Sun, J., Shen, Z., Wang, Y ., Bao, H., and Zhou, X. Loftr: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pp. 8922\u20138931, 2021. Sun, Y ., Cao, B., Zhu, P., and Hu, Q. Drone-based rgbinfrared cross-modality vehicle detection via uncertaintyaware learning. IEEE Transactions on Circuits and Systems for Video Technology , 32(10):6700\u20136713, 2022. Tang, C. and Tan, P. Ba-net: Dense bundle adjustment networks. In Proceedings of the International Conference on Learning Representations , pp. 1\u201311, 2018. Wang, Y ., Chen, Y ., Jamieson, K., and Du, S. S. Improved active multi-task representation learning via lasso. In Proceedings of the International Conference on Machine Learning , pp. 35548\u201335578, 2023. Weinzaepfel, P., Lucas, T., Larlus, D., and Kalantidis, Y . Learning super-features for image retrieval. In Proceedings of the International Conference on Learning Representations , pp. 1\u201312, 2022. Xiang, Y ., Wang, F., and You, H. Os-sift: A robust siftlike algorithm for high-resolution optical-to-sar image registration in suburban areas. IEEE Transactions on Geoscience and Remote Sensing , 56(6):3078\u20133090, 2018. Xing, B., Ying, X., Wang, R., Yang, J., and Chen, T. Crossmodal contrastive learning for domain adaptation in 3d semantic segmentation. In Proceedings of the AAAI Conference on Artificial Intelligence , pp. 2974\u20132982, 2023. Xu, H., Yuan, J., and Ma, J. Murf: Mutually reinforcing multi-modal image registration and fusion. IEEE Transactions on Pattern Analysis and Machine Intelligence , 45"
      },
      "Real-time photogrammetry based on parallel architecture for 3D applications": {
        "authors": [],
        "url": "https://theses.lib.polyu.edu.hk/bitstream/200/12799/3/7250.pdf",
        "ref_texts": " Spangenberg, R., Langner, T., Rojas, R., 2013. Weighted semi-global matching and center-symmetric census transform for robust driver assistance, Computer Analysis of Images and Patterns: 15th International Conference, CAIP 2013, Part II, 15, pp. 34-41. Stentoumis, C., Karkalou, E., Karras, G., 2015. A review and evaluation of penalty functions for semi-global matching, 2015 IEEE International Conference on Intelligent Computer Communication and Processing (ICCP). IEEE, pp. 167172. Studholme, C., Hill, D.L., Hawkes, D.J., 1999. An overlap invariant entropy measure of 3D medical image alignment. Pattern recognition, 32(1), pp. 71-86. Sun, J., Shen, Z., Wang, Y., Bao, H., Zhou, X., 2021. LoFTR: Detector-free local feature matching with transformers. Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 8922-8931. Szeliski, R., 2022. Computer vision: Algorithms and applications. Springer Nature. Technology, S.f.U., Turner, J., Yule, D.J., Zanre, J., 1991. Real Time Photogrammetry "
      },
      "Robust and Fast Schemes for Generation of Matched Features in MIS Images": {
        "authors": [],
        "url": "https://spectrum.library.concordia.ca/id/eprint/994576/1/Pourshahabi_PhD_F2024.pdf",
        "ref_texts": "[21] J. Sun, Z. Shen, Y. Wang, H. Bao and X. Zhou, \u201cLoFTR: Detector -free local feature matching with transformers, \u201d in Proc. CVPR , 2021, pp. 8918 \u20138927 . ",
        "ref_ids": [
          "21"
        ]
      },
      "Real-time tracking of surgical tissue": {
        "authors": [],
        "url": "https://open.library.ubc.ca/media/download/pdf/24/1.0440696/3",
        "ref_texts": "[256] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. LoFTR: Detector-Free Local Feature Matching With Transformers. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 8922\u20138931, 2021. \u2192page 56",
        "ref_ids": [
          "256"
        ]
      },
      "Novel Alignment and Segmentation Methods for Optical Retinal Images with Application to Non-Invasive Estimation of Intracranial Pressure": {
        "authors": [],
        "url": "https://researchportal.murdoch.edu.au/esploro/fulltext/doctoral/Novel-Alignment-and-Segmentation-Methods-for/991005687464007891?repId=12165634000007891&mId=13165633990007891&institution=61MUN_INST",
        "ref_texts": " matching rather than the overall image. However , the solution alleviates the concept of keypoint detection by generating two probabilistic maps to assess the reliability and repeatability of each pixel. In [100] , a graph deep neural network SuperGlue was proposed for matching two sets of local features between comparing images. It simultaneously identified correspondences and filtered out keypoints that were not matchable by solving an optimal transport problem. It also incorporated an attention -based context aggregation mechanism for reasoning feature assignment and 3D pose estimation. Recently, a fully -CNN called neighbourhood consensus network (NCNet) [101] was proposed for effective correspondence matching. It identified the matched keypoints with spatial consistency by assessing consensus patterns in the 4D space encompassing all potential correspondences between two images, eliminating the necessity for a comprehensive global geometric model. The feature map used for matching needs to undergo significant downsizing to ensure affordable computation because of quadratic complexity. A U-Net-based deep learning network in [102] aligned multispectral retinal images in a group. The aim was to find the template image by reducing dimensionality by PCA rather than averaging. A spatial transformer was also utilised, and a similarity loss function was optimised to estimate the deformable transformation between the moving and target images. Another hybrid deep neural network [103] comprised a U -Net and Mask -RCNN for segmenting the vasculature maps and extracting the junctions as landmarks for matching. These landmarks were utilised to estimate the affine transformation between the images. A generative adversarial network was proposed for multimodal retinal image registration, utilising conditional and cyclic constraints. The generator computed content loss using normalised mutual information loss, structural similarity loss and V GG loss. The discriminator incorporated the adversarial loss with cycle consistency loss to learn the reverse deformations effectively . Transformer -based correspondence matching has also gained attention in recent years. LoFTR [104] is a deep neural network incorporating transformers to leverage intercorrelations within densely positioned local features to simultaneously detect, describe, and match images . It employed self and cross -attention layers within a transformer framework to generate feature descriptors and dense matches in low -texture areas utilising a global receptive field. Another transformer -based deep neural network , COTR [80], captured local and global contexts to query specific points of interest, resulting in sparse correspondences or all points in an image, yielding dense mappings. Such methods were considered adequate for various image -matching tasks without data -specific retraining. These dense features are effective in identifying correspondences in regions with low texture. However , in the context of matching retinal images, this approach results in numerous undesired matches in non -vascular areas. GLAMpoints [105] were proposed to detect and learn key points between the comparing images to be matched for transformation estimation. The network was designed as a 4 -level U -Net [106] , which was trained based on a groundtruth homography matrix between each pair. The method used root -SIFT ",
        "ref_ids": [
          "100",
          "101",
          "102",
          "103",
          "104",
          "80",
          "105",
          "106"
        ]
      },
      "Utilizing Radiomic Features for Automated MRI Keypoint Detection: Enhancing Graph Applications.": {
        "authors": [],
        "url": "https://www.scitepress.org/Papers/2024/125688/125688.pdf",
        "ref_texts": "(2017). Hpatches: A benchmark and evaluation of handcrafted and learned local descriptors. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 5173\u20135182. Bridle, J. (1989). Training stochastic model recognition algorithms as networks can lead to maximum mutual information estimation of parameters. Advances in neural information processing systems , 2. Chen, J., Frey, E. C., He, Y ., Segars, W. P., Li, Y ., and Du, Y . (2022). Transmorph: Transformer for unsupervised medical image registration. Medical image analysis , 82:102615. Christiansen, P. H., Kragh, M. F., Brodskiy, Y ., and Karstoft, H. (2019). Unsuperpoint: End-to-end unsupervised interest point detector and descriptor. arXiv preprint arXiv:1907.04011 . DeTone, D., Malisiewicz, T., and Rabinovich, A. (2018). Superpoint: Self-supervised interest point detection and description. In Proceedings of the IEEE conference on computer vision and pattern recognition workshops , pages 224\u2013236. Hatamizadeh, A., Nath, V ., Tang, Y ., Yang, D., Roth, H. R., and Xu, D. (2021). Swin unetr: Swin transformers for semantic segmentation of brain tumors in mri images. In International MICCAI Brainlesion Workshop , pages 272\u2013284. Springer. He, X., Hooi, B., Laurent, T., Perold, A., LeCun, Y ., and Bresson, X. (2023). A generalization of vit/mlp-mixer to graphs. In International Conference on Machine Learning , pages 12724\u201312745. PMLR. Lindeberg, T. (2012). Scale invariant feature transform. Liu, J., Li, X., Wei, Q., Xu, J., and Ding, D. (2022). Semisupervised keypoint detector and descriptor for retinal image matching. In Computer Vision\u2013ECCV 2022: 17th European Conference, Tel Aviv, Israel, October 23\u201327, 2022, Proceedings, Part XXI , pages 593\u2013609. Springer. Lowe, D. G. (2004). Distinctive image features from scaleinvariant keypoints. International journal of computer vision , 60:91\u2013110. Marcus, D. S., Wang, T. H., Parker, J., Csernansky, J. G., Morris, J. C., and Buckner, R. L. (2007). Open access series of imaging studies (oasis): cross-sectional mri data in young, middle aged, nondemented, and demented older adults. Journal of cognitive neuroscience , 19(9):1498\u20131507. Ronneberger, O., Fischer, P., and Brox, T. (2015). Unet: Convolutional networks for biomedical image segmentation. In Medical Image Computing and Computer-Assisted Intervention\u2013MICCAI 2015: 18th International Conference, Munich, Germany, October 5-9, 2015, Proceedings, Part III 18 , pages 234\u2013241. Springer. Sarlin, P.-E., DeTone, D., Malisiewicz, T., and Rabinovich, A. (2020). Superglue: Learning feature matching with graph neural networks. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , pages 4938\u20134947. Sattler, T., Maddern, W., Toft, C., Torii, A., Hammarstrand, L., Stenborg, E., Safari, D., Okutomi, M., Pollefeys,M., Sivic, J., et al. (2018). Benchmarking 6dof outdoor visual localization in changing conditions. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 8601\u20138610. Sun, J., Shen, Z., Wang, Y ., Bao, H., and Zhou, X. (2021). Loftr: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , pages 8922\u20138931. Truong, P., Apostolopoulos, S., Mosinska, A., Stucky, S., Ciller, C., and Zanet, S. D. (2019). Glampoints: Greedily learned accurate match points. In Proceedings of the IEEE/CVF International Conference on Computer Vision , pages 10732\u201310741. Van Griethuysen, J. J., Fedorov, A., Parmar, C., Hosny, A., Aucoin, N., Narayan, V ., Beets-Tan, R. G., FillionRobin, J.-C., Pieper, S., and Aerts, H. J. (2017). Computational radiomics system to decode the radiographic phenotype. Cancer research , 77(21):e104\u2013 e107.Utilizing Radiomic Features for Automated MRI Keypoint Detection: Enhancing Graph Applications 325"
      },
      "Unified Interest Point Detection and Description for Perspective and Fisheye Images": {
        "authors": [
          "Cherry Ma",
          "Springer Beijing"
        ],
        "url": "https://www.researchsquare.com/article/rs-5268868/latest.pdf",
        "ref_texts": "22. J. Sun, Z. Shen, Y. Wang, H. Bao, X. Zhou, Loftr: Detector-free local feature matching with transformers, in: Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, ",
        "ref_ids": [
          "22"
        ]
      },
      "Multi-scale Consistency for Robust 3D Registration via Hierarchical Sinkhorn Tree": {
        "authors": [],
        "url": "https://openreview.net/pdf?id=sfPxUqzdPI",
        "ref_texts": "[10] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , pages 8922\u20138931, 2021.",
        "ref_ids": [
          "10"
        ]
      },
      "FAR: Flexible, Accurate and Robust 6DoF Relative Camera Pose Estimation: Supplemental Material": {
        "authors": [],
        "url": "https://openaccess.thecvf.com/content/CVPR2024/supplemental/Rockwell_FAR_Flexible_Accurate_CVPR_2024_supplemental.pdf",
        "ref_texts": "[7] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. LoFTR: Detector-free local feature matching with transformers. In CVPR , 2021. 2, 9",
        "ref_ids": [
          "7"
        ]
      },
      "Weak texture aircraft skin curved image feature matching and stitching": {
        "authors": [],
        "url": "http://jemi.cnjournals.com/emten/article/pdf/E2315207",
        "ref_texts": "[20] SUN J,SHEN Z,WANG Y,et al. LoFTR: Detectorfree local feature matching with transformers[C]. Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition,2021: ",
        "ref_ids": [
          "20",
          "C"
        ]
      },
      "MambaMatch: Learning Two-View Correspondences with Selective State Spaces": {
        "authors": [],
        "url": "https://openreview.net/pdf?id=YuJdtpPV4n",
        "ref_texts": "701Under review as a conference paper at ICLR 2025 Jimmy TH Smith, Andrew Warrington, and Scott Linderman. Simplified state space layers for sequence modeling. In Proceedings of the International Conference on Learning Representations , 2022. Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pp. 8922\u20138931, 2021. Weiwei Sun, Wei Jiang, Eduard Trulls, Andrea Tagliasacchi, and Kwang Moo Yi. Acne: Attentive context normalization for robust permutation-equivariant learning. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pp. 11286\u201311295, 2020. Shitao Tang, Jiahui Zhang, Siyu Zhu, and Ping Tan. Quadtree attention for vision transformers. In Proceedings of the International Conference on Learning Representations , pp. 1\u201316, 2022. Bart Thomee, David A Shamma, Gerald Friedland, Benjamin Elizalde, Karl Ni, Douglas Poland, Damian Borth, and Li-Jia Li. Yfcc100m: The new data in multimedia research. Communications of the ACM , 59(2):64\u201373, 2016. Giorgos Tolias, Yannis Avrithis, and Herv \u00b4e J\u00b4egou. Image search with selective match kernels: aggregation across single and multiple images. International Journal of Computer Vision , 116: 247\u2013261, 2016. Philip HS Torr and Andrew Zisserman. Mlesac: A new robust estimator with application to estimating image geometry. Computer Vision and Image Understanding , 78(1):138\u2013156, 2000. Prune Truong, Martin Danelljan, Luc Van Gool, and Radu Timofte. Learning accurate dense correspondences and when to trust them. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pp. 5714\u20135724, 2021. Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, \u0141ukasz Kaiser, and Illia Polosukhin. Attention is all you need. Advances in Neural Information Processing Systems , 30, 2017. Sinong Wang, Belinda Z Li, Madian Khabsa, Han Fang, and Hao Ma. Linformer: Self-attention with linear complexity. arXiv preprint arXiv:2006.04768 , 2020. Chuhan Wu, Fangzhao Wu, Tao Qi, Yongfeng Huang, and Xing Xie. Fastformer: Additive attention can be all you need. arXiv preprint arXiv:2108.09084 , 2021. Jianxiong Xiao, Andrew Owens, and Antonio Torralba. Sun3d: A database of big spaces reconstructed using sfm and object labels. In Proceedings of the IEEE International Conference on Computer Vision , pp. 1625\u20131632, 2013. Kwang Moo Yi, Eduard Trulls, Vincent Lepetit, and Pascal Fua. Lift: Learned invariant feature transform. In Proceedings of the European Conference on Computer Vision , pp. 467\u2013483, 2016. Kwang Moo Yi, Eduard Trulls, Yuki Ono, Vincent Lepetit, Mathieu Salzmann, and Pascal Fua. Learning to find good correspondences. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pp. 2666\u20132674, 2018. Jiahui Zhang, Dawei Sun, Zixin Luo, Anbang Yao, Lei Zhou, Tianwei Shen, Yurong Chen, Long Quan, and Hongen Liao. Learning two-view correspondences and geometry using order-aware network. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pp."
      },
      "\u89c6\u5dee\u4fe1\u606f\u5f15\u5bfc\u7684\u5149\u573a\u7279\u5f81\u5339\u914d\u5ea6\u91cf\u65b9\u6cd5 (\u7279\u9080)": {
        "authors": [],
        "url": "https://www.opticsjournal.net/Articles/GetArticlePDF/OJ5a5ea13df28c6c85",
        "ref_texts": "[21]Sun J M , Shen Z H , Wang Y A , et al . LoFTR : detector free local feature matching with transformers [C]\u22252021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR ), June 20-25, 2021 , Nashville , TN, USA . New York : IEEE Press , 2021 : 8918 -8927 .",
        "ref_ids": [
          "21",
          "C"
        ]
      },
      "From a Bird's Eye View to See: Joint Camera and Subject Registration without the Camera Calibration Supplementary Material": {
        "authors": [],
        "url": "https://openaccess.thecvf.com/content/CVPR2024/supplemental/Qian_From_a_Birds_CVPR_2024_supplemental.pdf"
      },
      "EcoMatcher: Efficient Clustering Oriented Matcher for Detector-free Image Matching": {
        "authors": [],
        "url": "https://fq.pkwyx.com/default/https/www.ecva.net/papers/eccv_2024/papers_ECCV/papers/08613.pdf",
        "ref_texts": "26. Sun, J., Shen, Z., Wang, Y., Bao, H., Zhou, X.: Loftr: Detector-free local feature matching with transformers. In: CVPR (2021)",
        "ref_ids": [
          "26"
        ]
      },
      "LiDAR-camera Online Calibration by Representing Local Feature and Global Spatial Context": {
        "authors": [],
        "url": "https://sgvr.kaist.ac.kr/wp-content/uploads/2024/09/CalibFormerNet_Moon.pdf",
        "ref_texts": "[35] J. Sun, Z. Shen, Y . Wang, H. Bao, and X. Zhou, \u201cLoftr: Detectorfree local feature matching with transformers,\u201d in Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , 2021, pp. 8922\u20138931.",
        "ref_ids": [
          "35"
        ]
      },
      "Observation Of Ocean Wave Based On Binocular Vision In The Swash Zone Of Yazhou Bay": {
        "authors": [],
        "url": "https://proceedings.open.tudelft.nl/coastlab24/article/download/762/743",
        "ref_texts": "1117. De Vries, S.; Hill, D. F.; De Schipper, M. A.; Stive, M. J. F, 2011. Remote sensing of surf zone waves using stereo imaging. Coastal Engineering , 58(3), 239 -250. Harry, M.; Zhang, H.; Lemckert, C.; Colleter, G.; Blenkinsopp, C, 2018. Observation of surf zone wave transformation using LiDAR. Applied Ocean Research , 78, 88 -98. Sun, J.; Shen, Z.; Wang, Y.; Bao, H.; Zhou, X, 2021. LoFTR: Detector -free local feature matching with transformers. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , Beijing, China, 19 -25. Wanek, J. M.; Wu, C. H. Automated trinocular stereo imaging system for three -dimensional surface wave measurements. Ocean engineering ",
        "ref_ids": [
          "1117"
        ]
      },
      "BUILDING INTERACTABLE REPLICAS OF COMPLEX AR-TICULATED OBJECTS VIA GAUSSIAN SPLATTING": {
        "authors": [],
        "url": "https://openreview.net/pdf?id=ix2yRWarPn",
        "ref_texts": "755Under review as a conference paper at ICLR 2025 Zhiyin Qian, Shaofei Wang, Marko Mihajlovic, Andreas Geiger, and Siyu Tang. 3dgs-avatar: Animatable avatars via deformable 3d gaussian splatting. In Proceedings of Conference on Computer Vision and Pattern Recognition (CVPR) , pp. 5020\u20135030, 2024. 2 Javier Romero, Dimitrios Tzionas, and Michael J Black. Embodied hands: Modeling and capturing hands and bodies together. arXiv preprint arXiv:2201.02610 , 2022. 3 Chaoyue Song, Tianyi Chen, Yiwen Chen, Jiacheng Wei, Chuan Sheng Foo, Fayao Liu, and Guosheng Lin. Moda: Modeling deformable 3d objects from casual videos. arXiv preprint arXiv:2304.08279 , 2023a. 3 Chaoyue Song, Jiacheng Wei, Chuan Sheng Foo, Guosheng Lin, and Fayao Liu. Reacto: Reconstructing articulated objects from a single video. In Proceedings of Conference on Computer Vision and Pattern Recognition (CVPR) , 2024. 2, 5 Chonghyuk Song, Gengshan Yang, Kangle Deng, Jun-Yan Zhu, and Deva Ramanan. Total-recon: Deformable scene reconstruction for embodied view synthesis. In Proceedings of International Conference on Computer Vision (ICCV) , 2023b. 3 J\u00fcrgen Sturm, Cyrill Stachniss, and Wolfram Burgard. A probabilistic framework for learning kinematic models of articulated objects. Journal of Artificial Intelligence Research , 41, 2011. 3 Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In Proceedings of Conference on Computer Vision and Pattern Recognition (CVPR) , 2021. 1 Xiaohao Sun, Hanxiao Jiang, Manolis Savva, and Angel Xuan Chang. Opdmulti: Openable part detection for multiple objects. arXiv preprint arXiv:2303.14087 , 2023. 3 Archana Swaminathan, Anubhav Gupta, Kamal Gupta, Shishira R Maiya, Vatsal Agarwal, and Abhinav Shrivastava. Leia: Latent view-invariant embeddings for implicit 3d articulation. arXiv preprint arXiv:2409.06703 , 2024. 3 Jeff Tan, Gengshan Yang, and Deva Ramanan. Distilling neural fields for real-time articulated shape reconstruction. In Proceedings of Conference on Computer Vision and Pattern Recognition (CVPR) , 2023. 3 Marcel Torne, Anthony Simeonov, Zechu Li, April Chan, Tao Chen, Abhishek Gupta, and Pulkit Agrawal. Reconciling reality through simulation: A real-to-sim-to-real approach for robust manipulation. arXiv preprint arXiv:2403.03949 , 2024. 1 Wei-Cheng Tseng, Hung-Ju Liao, Lin Yen-Chen, and Min Sun. Cla-nerf: Category-level articulated neural radiance field. In Proceedings of International Conference on Robotics and Automation (ICRA) . IEEE, 2022. 3 Diwen Wan, Ruijie Lu, and Gang Zeng. Superpoint gaussian splatting for real-time high-fidelity dynamic scene reconstruction. arXiv preprint arXiv:2406.03697 , 2024. 2 Peng Wang, Lingjie Liu, Yuan Liu, Christian Theobalt, Taku Komura, and Wenping Wang. Neus: Learning neural implicit surfaces by volume rendering for multi-view reconstruction. arXiv preprint arXiv:2106.10689 , 2021. 19 Xiaogang Wang, Bin Zhou, Yahao Shi, Xiaowu Chen, Qinping Zhao, and Kai Xu. Shape2motion: Joint analysis of motion parts and attributes from 3d shapes. In Proceedings of Conference on Computer Vision and Pattern Recognition (CVPR) , 2019. 3 Fangyin Wei, Rohan Chabra, Lingni Ma, Christoph Lassner, Michael Zollh\u00f6fer, Szymon Rusinkiewicz, Chris Sweeney, Richard Newcombe, and Mira Slavcheva. Self-supervised neural articulated shape and appearance models. In Proceedings of Conference on Computer Vision and Pattern Recognition (CVPR) , 2022. 3 Bowen Wen, Jonathan Tremblay, Valts Blukis, Stephen Tyree, Thomas M\u00fcller, Alex Evans, Dieter Fox, Jan Kautz, and Stan Birchfield. Bundlesdf: Neural 6-dof tracking and 3d reconstruction of unknown objects. In Proceedings of Conference on Computer Vision and Pattern Recognition (CVPR) , 2023. 19"
      },
      "Highly Accurate and Fast Two-view Pose Estimation by Fast Reduction of Spherical Image Distortion Effects": {
        "authors": [
          "Taisei Ando",
          "Junwoon Lee",
          "Mitsuru S",
          "Toshihiro Kitajima",
          "Qi An",
          "Atsushi Yamashita"
        ],
        "url": "https://www.robot.t.u-tokyo.ac.jp/~yamashita/paper/B/B323Final.pdf",
        "ref_texts": "[12] J. Sun, Z. Shen, Y . Wang, H. Bao, and X. Zhou, \u201cLoFTR: Detector-Free Local Feature Matching with Transformers,\u201d Proceedings of the 2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR2021) , pp. 8918\u20138927, 2021.",
        "ref_ids": [
          "12"
        ]
      },
      "\u533b\u7528\u753b\u50cf AI \u958b\u767a\u652f\u63f4\u30bd\u30d5\u30c8\u30a6\u30a7\u30a2\u3092\u7528\u3044\u305f\u6b6f\u79d1\u7528 CBCT \u753b\u50cf\u306b\u304a\u3051\u308b\u4e0b\u984e\u7ba1\u306e\u30bb\u30b0\u30e1\u30f3\u30c6\u30fc\u30b7\u30e7\u30f3": {
        "authors": [],
        "url": "https://www.jstage.jst.go.jp/article/dentalradiology/64/1/64_11/_pdf",
        "ref_texts": "14. Sun J, Shen Z, Wang Y, Bao H, Zhou X. LoFTR: DetectorFree Local Feature Matching with Transformers. Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2021;8922-8931.",
        "ref_ids": [
          "14"
        ]
      },
      "\u57fa\u4e8e\u5149\u5b66\u663e\u5fae\u89c6\u89c9\u7684\u7cbe\u5bc6\u5b9a\u4f4d\u6d4b\u91cf\u7efc\u8ff0": {
        "authors": [],
        "url": "https://www.opticsjournal.net/Articles/GetArticlePDF/OJeeca7d324c71279f",
        "ref_texts": "[123]Sun J M , Shen Z H , Wang Y , et al . LoFTR : detector free local feature matching with transformers [C]\u22252021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR ), June 20-25, 2021 , Nashville , TN, USA . New York : IEEE Press , 2021 : 8918 -8927 .",
        "ref_ids": [
          "123",
          "C"
        ]
      },
      "\u57fa\u4e8e\u6539\u8fdb DFM \u7684\u5bc6\u96c6\u7279\u5f81\u5339\u914d\u7b97\u6cd5": {
        "authors": [],
        "url": "https://www.opticsjournal.net/Articles/GetArticlePDF/OJe8de3d4dab883c2f",
        "ref_texts": "[14]Sun J M , Shen Z H , Wang Y A , et al . LoFTR : detector free local feature matching with transformers [C]\u22252021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR ), June 20-25, 2021 , Nashville , TN, USA . New York : IEEE Press , 2021 : 8918 -8927 .",
        "ref_ids": [
          "14",
          "C"
        ]
      },
      "Lightglue: Local feature matching at light speed": {
        "authors": [
          "Philipp Lindenberger",
          "Edouard Sarlin",
          "Marc Pollefeys"
        ],
        "url": "http://openaccess.thecvf.com/content/ICCV2023/papers/Lindenberger_LightGlue_Local_Feature_Matching_at_Light_Speed_ICCV_2023_paper.pdf",
        "ref_texts": "[65] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. LoFTR: Detector-free local feature matching with Transformers. CVPR , 2021. 2, 6, 7",
        "ref_ids": [
          "65"
        ]
      },
      "Tracking everything everywhere all at once": {
        "authors": [
          "Qianqian Wang",
          "Yu Chang",
          "Ruojin Cai",
          "Zhengqi Li",
          "Bharath Hariharan",
          "Aleksander Holynski",
          "Noah Snavely"
        ],
        "url": "http://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Tracking_Everything_Everywhere_All_at_Once_ICCV_2023_paper.pdf",
        "ref_texts": "[60] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In Proc. Computer Vision and Pattern Recognition (CVPR) , pages 8922\u20138931, 2021. 2",
        "ref_ids": [
          "60"
        ]
      },
      "Bundlesdf: Neural 6-dof tracking and 3d reconstruction of unknown objects": {
        "authors": [
          "Bowen Wen",
          "Jonathan Tremblay",
          "Valts Blukis",
          "Stephen Tyree",
          "Thomas Muller",
          "Alex Evans",
          "Dieter Fox",
          "Jan Kautz",
          "Stan Birchfield"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Wen_BundleSDF_Neural_6-DoF_Tracking_and_3D_Reconstruction_of_Unknown_Objects_CVPR_2023_paper.pdf",
        "ref_texts": "[57] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , pages 8922\u20138931, 2021. 2",
        "ref_ids": [
          "57"
        ]
      },
      "Hierarchical dense correlation distillation for few-shot segmentation": {
        "authors": [
          "Bohao Peng",
          "Zhuotao Tian",
          "Xiaoyang Wu",
          "Chengyao Wang",
          "Shu Liu",
          "Jingyong Su",
          "Jiaya Jia"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2023/papers/Peng_Hierarchical_Dense_Correlation_Distillation_for_Few-Shot_Segmentation_CVPR_2023_paper.pdf",
        "ref_texts": "[35] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , pages 8922\u20138931, 2021. 2, 3",
        "ref_ids": [
          "35"
        ]
      },
      "Rotation-invariant transformer for point cloud matching": {
        "authors": [
          "Hao Yu",
          "Zheng Qin",
          "Ji Hou",
          "Mahdi Saleh",
          "Dongsheng Li",
          "Benjamin Busam",
          "Slobodan Ilic"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2023/papers/Yu_Rotation-Invariant_Transformer_for_Point_Cloud_Matching_CVPR_2023_paper.pdf",
        "ref_texts": "[37] Jiaming Sun, Zehong Shen, Y uang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matchingwith transformers. In CVPR , 2021. 6",
        "ref_ids": [
          "37"
        ]
      },
      "Silk: Simple learned keypoints": {
        "authors": [
          "Pierre Gleize",
          "Weiyao Wang",
          "Matt Feiszli"
        ],
        "url": "http://openaccess.thecvf.com/content/ICCV2023/papers/Gleize_SiLK_Simple_Learned_Keypoints_ICCV_2023_paper.pdf",
        "ref_texts": "[47] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In Proceedings oftheIEEE/CVF conference oncomputer vision and pattern recognition, pages 8922\u20138931, 2021.",
        "ref_ids": [
          "47"
        ]
      },
      "Learning visual representations via language-guided sampling": {
        "authors": [
          "Mohamed El",
          "Karan Desai",
          "Justin Johnson"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Banani_Learning_Visual_Representations_via_Language-Guided_Sampling_CVPR_2023_paper.pdf",
        "ref_texts": "[90] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. LoFTR: Detector-free local feature matching with transformers. Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2021. 2",
        "ref_ids": [
          "90"
        ]
      },
      "Featurenerf: Learning generalizable nerfs by distilling foundation models": {
        "authors": [
          "Jianglong Ye",
          "Naiyan Wang",
          "Xiaolong Wang"
        ],
        "url": "https://openaccess.thecvf.com/content/ICCV2023/papers/Ye_FeatureNeRF_Learning_Generalizable_NeRFs_by_Distilling_Foundation_Models_ICCV_2023_paper.pdf",
        "ref_texts": "[51] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. 2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) , pages 8918\u2013",
        "ref_ids": [
          "51"
        ]
      },
      "Eigenplaces: Training viewpoint robust models for visual place recognition": {
        "authors": [
          "Gabriele Berton",
          "Gabriele Trivigno",
          "Barbara Caputo",
          "Carlo Masone"
        ],
        "url": "http://openaccess.thecvf.com/content/ICCV2023/papers/Berton_EigenPlaces_Training_Viewpoint_Robust_Models_for_Visual_Place_Recognition_ICCV_2023_paper.pdf",
        "ref_texts": "[46] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. LoFTR: Detector-free local feature matching with transformers. CVPR , 2021. 3",
        "ref_ids": [
          "46"
        ]
      },
      "An all-in-one nanoprinting approach for the synthesis of a nanofilm library for unclonable anti-counterfeiting applications": {
        "authors": [
          "Junfang Zhang"
        ],
        "url": "https://www.nature.com/articles/s41565-023-01405-3.pdf",
        "ref_texts": "44. Sun, J., Shen, Z., Wang, Y., Bao, H., & Zhou, X. LoFTR: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 8922\u20138931 (IEEE/CVF, 2021).",
        "ref_ids": [
          "44"
        ]
      },
      "Rethinking optical flow from geometric matching consistent perspective": {
        "authors": [
          "Qiaole Dong",
          "Chenjie Cao",
          "Yanwei Fu"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Dong_Rethinking_Optical_Flow_From_Geometric_Matching_Consistent_Perspective_CVPR_2023_paper.pdf",
        "ref_texts": "[46] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , pages 8922\u20138931, 2021. 2, 3, 4",
        "ref_ids": [
          "46"
        ]
      },
      "Gluestick: Robust image matching by sticking points and lines together": {
        "authors": [
          "Remi Pautrat",
          "Iago Suarez",
          "Yifan Yu",
          "Marc Pollefeys",
          "Viktor Larsson"
        ],
        "url": "https://openaccess.thecvf.com/content/ICCV2023/papers/Pautrat_GlueStick_Robust_Image_Matching_by_Sticking_Points_and_Lines_Together_ICCV_2023_paper.pdf",
        "ref_texts": "[57] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. LoFTR: Detector-free local feature matching with transformers. In IEEE Conf. Comput. Vis. Pattern Recog. (CVPR) , 2021. 1, 2, 3, 4, 6, 7, 8",
        "ref_ids": [
          "57"
        ]
      },
      "Corresnerf: Image correspondence priors for neural radiance fields": {
        "authors": [],
        "url": "https://proceedings.neurips.cc/paper_files/paper/2023/file/7f77492bb8070a5c825a87c0c5181da2-Paper-Conference.pdf",
        "ref_texts": "[23] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In CVPR , 2021. 2, 3, 4",
        "ref_ids": [
          "23"
        ]
      },
      "RayMVSNet++: learning ray-based 1D implicit fields for accurate multi-view stereo": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2307.10233",
        "ref_texts": "[54] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF conference on computer vision and pattern IEEE TRANSACTIONS ON PATTERN ANAL YSIS AND MACHINE INTELLIGENCE 16 recognition , pages 8922\u20138931, 2021.",
        "ref_ids": [
          "54"
        ]
      },
      "DKM: Dense kernelized feature matching for geometry estimation": {
        "authors": [
          "Johan Edstedt",
          "Ioannis Athanasiadis",
          "Marten Wadenback",
          "Michael Felsberg"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Edstedt_DKM_Dense_Kernelized_Feature_Matching_for_Geometry_Estimation_CVPR_2023_paper.pdf",
        "ref_texts": "[41] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. LoFTR: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 8922\u20138931, 2021. 1, 2, 5, 6, 7",
        "ref_ids": [
          "41"
        ]
      },
      "Geotransformer: Fast and robust point cloud registration with geometric transformer": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2308.03768",
        "ref_texts": "[10] J. Sun, Z. Shen, Y. Wang, H. Bao, and X. Zhou, \u201cLoftr: Detectorfree local feature matching with transformers,\u201d in CVPR , 2021, pp.",
        "ref_ids": [
          "10"
        ]
      },
      "Sparsepose: Sparse-view camera pose regression and refinement": {
        "authors": [
          "Samarth Sinha",
          "Jason Y. Zhang",
          "Andrea Tagliasacchi",
          "Igor Gilitschenski",
          "David B. Lindell"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2023/papers/Sinha_SparsePose_Sparse-View_Camera_Pose_Regression_and_Refinement_CVPR_2023_paper.pdf",
        "ref_texts": "[61] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In CVPR , 2021. 2",
        "ref_ids": [
          "61"
        ]
      },
      "SFD2: Semantic-guided feature detection and description": {
        "authors": [
          "Fei Xue",
          "Ignas Budvytis",
          "Roberto Cipolla"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2023/papers/Xue_SFD2_Semantic-Guided_Feature_Detection_and_Description_CVPR_2023_paper.pdf",
        "ref_texts": "[67] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. LoFTR: Detector-free local feature matching with transformers. In CVPR , 2021. 1, 3, 6",
        "ref_ids": [
          "67"
        ]
      },
      "Doppelgangers: Learning to disambiguate images of similar structures": {
        "authors": [
          "Ruojin Cai",
          "Joseph Tung",
          "Qianqian Wang",
          "Hadar Averbuch",
          "Bharath Hariharan",
          "Noah Snavely"
        ],
        "url": "http://openaccess.thecvf.com/content/ICCV2023/papers/Cai_Doppelgangers_Learning_to_Disambiguate_Images_of_Similar_Structures_ICCV_2023_paper.pdf",
        "ref_texts": "[34] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In CVPR , pages 8922\u20138931, 2021. 5, 6",
        "ref_ids": [
          "34"
        ]
      },
      "Peal: Prior-embedded explicit attention learning for low-overlap point cloud registration": {
        "authors": [
          "Junle Yu",
          "Luwei Ren",
          "Yu Zhang",
          "Wenhui Zhou",
          "Lili Lin",
          "Guojun Dai"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Yu_PEAL_Prior-Embedded_Explicit_Attention_Learning_for_Low-Overlap_Point_Cloud_Registration_CVPR_2023_paper.pdf",
        "ref_texts": "[30] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In CVPR , pages 8922\u20138931, 2021. 2",
        "ref_ids": [
          "30"
        ]
      },
      "3dmotformer: Graph transformer for online 3d multi-object tracking": {
        "authors": [
          "Shuxiao Ding",
          "Eike Rehder",
          "Lukas Schneider",
          "Marius Cordts",
          "Juergen Gall"
        ],
        "url": "http://openaccess.thecvf.com/content/ICCV2023/papers/Ding_3DMOTFormer_Graph_Transformer_for_Online_3D_Multi-Object_Tracking_ICCV_2023_paper.pdf",
        "ref_texts": "[34] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) , pages 8918\u20138927, 2021.",
        "ref_ids": [
          "34"
        ]
      },
      "Pats: Patch area transportation with subdivision for local feature matching": {
        "authors": [
          "Junjie Ni",
          "Yijin Li",
          "Zhaoyang Huang",
          "Hongsheng Li",
          "Hujun Bao",
          "Zhaopeng Cui",
          "Guofeng Zhang"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Ni_PATS_Patch_Area_Transportation_With_Subdivision_for_Local_Feature_Matching_CVPR_2023_paper.pdf",
        "ref_texts": "[49] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 8922\u20138931, 2021.",
        "ref_ids": [
          "49"
        ]
      },
      "Kick back & relax: Learning to reconstruct the world by watching slowtv": {
        "authors": [
          "Jaime Spencer",
          "Chris Russell",
          "Simon Hadfield",
          "Richard Bowden"
        ],
        "url": "http://openaccess.thecvf.com/content/ICCV2023/papers/Spencer_Kick_Back__Relax_Learning_to_Reconstruct_the_World_by_ICCV_2023_paper.pdf",
        "ref_texts": "[58] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , pages 8922\u20138931, 2021. 8",
        "ref_ids": [
          "58"
        ]
      },
      "3d line mapping revisited": {
        "authors": [
          "Shaohui Liu",
          "Yifan Yu",
          "Remi Pautrat",
          "Marc Pollefeys",
          "Viktor Larsson"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Liu_3D_Line_Mapping_Revisited_CVPR_2023_paper.pdf",
        "ref_texts": "[70] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In CVPR , 2021. 2",
        "ref_ids": [
          "70"
        ]
      },
      "Aliked: A lighter keypoint and descriptor extraction network via deformable transformation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2304.03608.pdf?trk=public_post_comment-text",
        "ref_texts": "[53] J. Sun, Z. Shen, Y . Wang, H. Bao, and X. Zhou, \u201cLoftr: Detectorfree local feature matching with transformers,\u201d in Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , 2021, pp. 8922\u20138931.",
        "ref_ids": [
          "53"
        ]
      },
      "Explicit motion disentangling for efficient optical flow estimation": {
        "authors": [
          "Changxing Deng",
          "Ao Luo",
          "Haibin Huang",
          "Shaodan Ma",
          "Jiangyu Liu",
          "Shuaicheng Liu"
        ],
        "url": "https://openaccess.thecvf.com/content/ICCV2023/papers/Deng_Explicit_Motion_Disentangling_for_Efficient_Optical_Flow_Estimation_ICCV_2023_paper.pdf",
        "ref_texts": "[31] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In CVPR , 2021.",
        "ref_ids": [
          "31"
        ]
      },
      "Deep geometrized cartoon line inbetweening": {
        "authors": [
          "Li Siyao",
          "Tianpei Gu",
          "Weiye Xiao",
          "Henghui Ding",
          "Ziwei Liu",
          "Chen Change"
        ],
        "url": "https://openaccess.thecvf.com/content/ICCV2023/papers/Siyao_Deep_Geometrized_Cartoon_Line_Inbetweening_ICCV_2023_paper.pdf",
        "ref_texts": "[31] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In CVPR , 2021. 5",
        "ref_ids": [
          "31"
        ]
      },
      "Learning symmetry-aware geometry correspondences for 6d object pose estimation": {
        "authors": [
          "Heng Zhao",
          "Shenxing Wei",
          "Dahu Shi",
          "Wenming Tan",
          "Zheyang Li",
          "Ye Ren",
          "Xing Wei",
          "Yi Yang",
          "Shiliang Pu"
        ],
        "url": "http://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_Learning_Symmetry-Aware_Geometry_Correspondences_for_6D_Object_Pose_Estimation_ICCV_2023_paper.pdf",
        "ref_texts": "[51] Yongzhi Su, Mahdi Saleh, Torben Fetzer, Jason Rambach, Nassir Navab, Benjamin Busam, Didier Stricker, and Federico Tombari. Zebrapose: Coarse to fine surface encoding for 6dof object pose estimation. In CVPR , 2022. 1[52] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In CVPR , 2021. 5",
        "ref_ids": [
          "51",
          "52"
        ]
      },
      "Navi: Category-agnostic image collections with high-quality 3d shape and pose annotations": {
        "authors": [],
        "url": "https://proceedings.neurips.cc/paper_files/paper/2023/file/efc90033e6e1b05485312dd09fe302b8-Paper-Datasets_and_Benchmarks.pdf",
        "ref_texts": "[57] J. Sun, Z. Shen, Y . Wang, H. Bao, and X. Zhou. Loftr: Detector-free local feature matching with transformers. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , pages 8922\u20138931, 2021.",
        "ref_ids": [
          "57"
        ]
      },
      "Generating aligned pseudo-supervision from non-aligned data for image restoration in under-display camera": {
        "authors": [
          "Ruicheng Feng",
          "Chongyi Li",
          "Huaijin Chen",
          "Shuai Li",
          "Jinwei Gu",
          "Chen Change"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2023/papers/Feng_Generating_Aligned_Pseudo-Supervision_From_Non-Aligned_Data_for_Image_Restoration_in_CVPR_2023_paper.pdf",
        "ref_texts": "[37] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. LoFTR: Detector-free local feature matching with transformers. In CVPR , 2021. 8",
        "ref_ids": [
          "37"
        ]
      },
      "Pmatch: Paired masked image modeling for dense geometric matching": {
        "authors": [
          "Shengjie Zhu",
          "Xiaoming Liu"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Zhu_PMatch_Paired_Masked_Image_Modeling_for_Dense_Geometric_Matching_CVPR_2023_paper.pdf",
        "ref_texts": "[48] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In CVPR , 2021. 1, 2, 4, 5, 6, 7, 8",
        "ref_ids": [
          "48"
        ]
      },
      "The change you want to see (now in 3d)": {
        "authors": [
          "Ragav Sachdeva",
          "Andrew Zisserman"
        ],
        "url": "https://openaccess.thecvf.com/content/ICCV2023W/OpenSUN3D/papers/Sachdeva_The_Change_You_Want_to_See_Now_in_3D_ICCVW_2023_paper.pdf",
        "ref_texts": "[30] Jiaming Sun, Zehong Shen, Y uang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , pages 8922\u20138931, 2021. 5",
        "ref_ids": [
          "30"
        ]
      },
      "Generalized differentiable RANSAC": {
        "authors": [
          "Tong Wei",
          "Yash Patel",
          "Alexander Shekhovtsov",
          "Jiri Matas",
          "Daniel Barath"
        ],
        "url": "https://openaccess.thecvf.com/content/ICCV2023/papers/Wei_Generalized_Differentiable_RANSAC_ICCV_2023_paper.pdf",
        "ref_texts": "[66] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In CVPR , 2021. 1, 2, 6, 9",
        "ref_ids": [
          "66"
        ]
      },
      "Lu-nerf: Scene and pose estimation by synchronizing local unposed nerfs": {
        "authors": [
          "Zezhou Cheng",
          "Carlos Esteves",
          "Varun Jampani",
          "Abhishek Kar",
          "Subhransu Maji",
          "Ameesh Makadia"
        ],
        "url": "http://openaccess.thecvf.com/content/ICCV2023/papers/Cheng_LU-NeRF_Scene_and_Pose_Estimation_by_Synchronizing_Local_Unposed_NeRFs_ICCV_2023_paper.pdf",
        "ref_texts": "[51] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In CVPR , 2021. 2, 7",
        "ref_ids": [
          "51"
        ]
      },
      "Constraining depth map geometry for multi-view stereo: A dual-depth approach with saddle-shaped depth cells": {
        "authors": [
          "Xinyi Ye",
          "Weiyue Zhao",
          "Tianqi Liu",
          "Zihao Huang",
          "Zhiguo Cao",
          "Xin Li"
        ],
        "url": "http://openaccess.thecvf.com/content/ICCV2023/papers/Ye_Constraining_Depth_Map_Geometry_for_Multi-View_Stereo_A_Dual-Depth_Approach_ICCV_2023_paper.pdf",
        "ref_texts": "[30] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In Proc. IEEE Conf. Comput. Vis. Pattern Recogn. , pages 8922\u20138931, 2021.",
        "ref_ids": [
          "30"
        ]
      },
      "Nerf-loc: Visual localization with conditional neural radiance field": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2304.07979",
        "ref_texts": "[29] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. InProceedings of the IEEE/CVF conference on computer vision and pattern recognition , pages 8922\u20138931, 2021.",
        "ref_ids": [
          "29"
        ]
      },
      "S-TREK: Sequential Translation and Rotation Equivariant Keypoints for local feature extraction": {
        "authors": [
          "Emanuele Santellani",
          "Christian Sormann",
          "Mattia Rossi",
          "Andreas Kuhn",
          "Friedrich Fraundorfer"
        ],
        "url": "https://openaccess.thecvf.com/content/ICCV2023/papers/Santellani_S-TREK_Sequential_Translation_and_Rotation_Equivariant_Keypoints_for_Local_Feature_ICCV_2023_paper.pdf",
        "ref_texts": "[38] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. LoFTR: Detector-free local feature matching with transformers. CVPR , 2021.",
        "ref_ids": [
          "38"
        ]
      },
      "2d3d-matr: 2d-3d matching transformer for detection-free registration between images and point clouds": {
        "authors": [
          "Minhao Li",
          "Zheng Qin",
          "Zhirui Gao",
          "Renjiao Yi",
          "Chenyang Zhu",
          "Yulan Guo",
          "Kai Xu"
        ],
        "url": "http://openaccess.thecvf.com/content/ICCV2023/papers/Li_2D3D-MATR_2D-3D_Matching_Transformer_for_Detection-Free_Registration_Between_Images_and_ICCV_2023_paper.pdf",
        "ref_texts": "[46] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In CVPR , pages 8922\u20138931, 2021. 2, 4",
        "ref_ids": [
          "46"
        ]
      },
      "Are local features all you need for cross-domain visual place recognition?": {
        "authors": [
          "Giovanni Barbarani",
          "Mohamad Mostafa",
          "Hajali Bayramov",
          "Gabriele Trivigno",
          "Gabriele Berton",
          "Carlo Masone",
          "Barbara Caputo"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2023W/IMW/papers/Barbarani_Are_Local_Features_All_You_Need_for_Cross-Domain_Visual_Place_CVPRW_2023_paper.pdf",
        "ref_texts": "[49] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. LoFTR: Detector-free local feature matching with transformers. CVPR , 2021. 1, 2, 3, 4, 5",
        "ref_ids": [
          "49"
        ]
      },
      "Supervised homography learning with realistic dataset generation": {
        "authors": [
          "Hai Jiang",
          "Haipeng Li",
          "Songchen Han",
          "Haoqiang Fan",
          "Bing Zeng",
          "Shuaicheng Liu"
        ],
        "url": "https://openaccess.thecvf.com/content/ICCV2023/papers/Jiang_Supervised_Homography_Learning_with_Realistic_Dataset_Generation_ICCV_2023_paper.pdf",
        "ref_texts": "[36] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In Proc. CVPR , pages 8922\u20138931, 2021.",
        "ref_ids": [
          "36"
        ]
      },
      "Autorecon: Automated 3d object discovery and reconstruction": {
        "authors": [
          "Yuang Wang",
          "Xingyi He",
          "Sida Peng",
          "Haotong Lin",
          "Hujun Bao",
          "Xiaowei Zhou"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2023/papers/Wang_AutoRecon_Automated_3D_Object_Discovery_and_Reconstruction_CVPR_2023_paper.pdf",
        "ref_texts": "[37] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In CVPR , 2021. 3",
        "ref_ids": [
          "37"
        ]
      },
      "3d video object detection with learnable object-centric global optimization": {
        "authors": [
          "Jiawei He",
          "Yuntao Chen",
          "Naiyan Wang",
          "Zhaoxiang Zhang"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2023/papers/He_3D_Video_Object_Detection_With_Learnable_Object-Centric_Global_Optimization_CVPR_2023_paper.pdf",
        "ref_texts": "[39] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In CVPR , 2021. 3",
        "ref_ids": [
          "39"
        ]
      },
      "Adaptive assignment for geometry aware local feature matching": {
        "authors": [
          "Dihe Huang",
          "Ying Chen",
          "Yong Liu",
          "Jianlin Liu",
          "Shang Xu",
          "Wenlong Wu",
          "Yikang Ding",
          "Fan Tang",
          "Chengjie Wang"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Huang_Adaptive_Assignment_for_Geometry_Aware_Local_Feature_Matching_CVPR_2023_paper.pdf",
        "ref_texts": "[29] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In CVPR , pages 8922\u20138931, 2021. 2, 3, 4, 5, 6, 7, 8",
        "ref_ids": [
          "29"
        ]
      },
      "Adaptive spot-guided transformer for consistent local feature matching": {
        "authors": [
          "Jiahuan Yu",
          "Jiahao Chang",
          "Jianfeng He",
          "Tianzhu Zhang",
          "Jiyang Yu",
          "Feng Wu"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Yu_Adaptive_Spot-Guided_Transformer_for_Consistent_Local_Feature_Matching_CVPR_2023_paper.pdf"
      },
      "A small-target forest fire smoke detection model based on deformable transformer for end-to-end object detection": {
        "authors": [
          "Jingwen Huang",
          "Jiashun Zhou",
          "Huizhou Yang",
          "Yunfei Liu",
          "Han Liu"
        ],
        "url": "https://www.mdpi.com/1999-4907/14/1/162/pdf",
        "ref_texts": "31. Sun, J.; Shen, Z.; Wang, Y.; Bao, H.; Zhou, X. LoFTR: Detector-Free Local Feature Matching with Transformers. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Virtual Event, 19\u201325 June 2021; pp. 8918\u20138927.",
        "ref_ids": [
          "31"
        ]
      },
      "Deep geometry-aware camera self-calibration from video": {
        "authors": [
          "Annika Hagemann",
          "Moritz Knorr",
          "Christoph Stiller"
        ],
        "url": "http://openaccess.thecvf.com/content/ICCV2023/papers/Hagemann_Deep_Geometry-Aware_Camera_Self-Calibration_from_Video_ICCV_2023_paper.pdf",
        "ref_texts": "[37] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , pages 8922\u20138931, 2021. 3",
        "ref_ids": [
          "37"
        ]
      },
      "Leap: Liberate sparse-view 3d modeling from camera poses": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2310.01410",
        "ref_texts": "10 Ruoshi Liu, Rundi Wu, Basile Van Hoorick, Pavel Tokmakov, Sergey Zakharov, and Carl V ondrick. Zero-1-to-3: Zero-shot one image to 3d object. ICCV , 2023. Ilya Loshchilov and Frank Hutter. Decoupled weight decay regularization. In International Conference on Learning Representations , 2017. Ben Mildenhall, Pratul P. Srinivasan, Matthew Tancik, Jonathan T. Barron, Ravi Ramamoorthi, and Ren Ng. Nerf: Representing scenes as neural radiance fields for view synthesis. ArXiv , abs/2003.08934, 2020. Michael Niemeyer, Jonathan T. Barron, Ben Mildenhall, Mehdi S. M. Sajjadi, Andreas Geiger, and Noha Radwan. Regnerf: Regularizing neural radiance fields for view synthesis from sparse inputs. CVPR , pp. 5470\u20135480, 2022. Maxime Oquab, Timoth\u2019ee Darcet, Th\u2019eo Moutakanni, Huy Q. V o, Marc Szafraniec, Vasil Khalidov, Pierre Fernandez, Daniel Haziza, Francisco Massa, Alaaeldin El-Nouby, Mahmoud Assran, Nicolas Ballas, Wojciech Galuba, Russ Howes, Po-Yao (Bernie) Huang, Shang-Wen Li, Ishan Misra, Michael G. Rabbat, Vasu Sharma, Gabriel Synnaeve, Huijiao Xu, Herv\u00e9 J\u00e9gou, Julien Mairal, Patrick Labatut, Armand Joulin, and Piotr Bojanowski. Dinov2: Learning robust visual features without supervision. ArXiv , abs/2304.07193, 2023. C. Qi, Hao Su, Kaichun Mo, and Leonidas J. Guibas. Pointnet: Deep learning on point sets for 3d classification and segmentation. CVPR , pp. 77\u201385, 2017. Chris Rockwell, Justin Johnson, and David F Fouhey. The 8-point algorithm as an inductive bias for relative pose prediction by vits. In 2022 International Conference on 3D Vision (3DV) , pp. 1\u201311. IEEE, 2022. Mehdi S. M. Sajjadi, Henning Meyer, Etienne Pot, Urs M. Bergmann, Klaus Greff, Noha Radwan, Suhani V ora, Mario Lucic, Daniel Duckworth, Alexey Dosovitskiy, Jakob Uszkoreit, Thomas A. Funkhouser, and Andrea Tagliasacchi. Scene representation transformer: Geometry-free novel view synthesis through set-latent scene representations. CVPR , 2022. Johannes Lutz Sch\u00f6nberger and Jan-Michael Frahm. Structure-from-Motion Revisited. In Conference on Computer Vision and Pattern Recognition (CVPR) , 2016. Samarth Sinha, Jason Y . Zhang, Andrea Tagliasacchi, Igor Gilitschenski, and David B. Lindell. Sparsepose: Sparse-view camera pose regression and refinement. ArXiv , abs/2211.16991, 2022. Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , pp. 8922\u20138931, 2021. Prune Truong, Marie-Julie Rakotosaona, Fabian Manhardt, and Federico Tombari. Sparf: Neural radiance fields from sparse and noisy poses. ArXiv , abs/2211.11738, 2022. Ashish Vaswani, Noam M. Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. Attention is all you need. In NIPS , 2017. Peng Wang, Lingjie Liu, Yuan Liu, Christian Theobalt, Taku Komura, and Wenping Wang. Neus: Learning neural implicit surfaces by volume rendering for multi-view reconstruction. In NeurIPS , 2021a. Qianqian Wang, Zhicheng Wang, Kyle Genova, Pratul P. Srinivasan, Howard Zhou, Jonathan T. Barron, Ricardo Martin-Brualla, Noah Snavely, and Thomas A. Funkhouser. Ibrnet: Learning multi-view image-based rendering. CVPR , pp. 4688\u20134697, 2021b. Zhou Wang, Alan Conrad Bovik, Hamid R. Sheikh, and Eero P. Simoncelli. Image quality assessment: from error visibility to structural similarity. IEEE Transactions on Image Processing , 13:600\u2013612, 2004. Zirui Wang, Shangzhe Wu, Weidi Xie, Min Chen, and Victor Adrian Prisacariu. Nerf-: Neural radiance fields without known camera parameters. ArXiv , abs/2102.07064, 2021c."
      },
      "Neumap: Neural coordinate mapping by auto-transdecoder for camera localization": {
        "authors": [
          "Shitao Tang",
          "Sicong Tang",
          "Andrea Tagliasacchi",
          "Ping Tan",
          "Yasutaka Furukawa"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Tang_NeuMap_Neural_Coordinate_Mapping_by_Auto-Transdecoder_for_Camera_Localization_CVPR_2023_paper.pdf",
        "ref_texts": "[42] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , pages 8922\u20138931, 2021. 2, 5",
        "ref_ids": [
          "42"
        ]
      },
      "Recurrent homography estimation using homography-guided image warping and focus transformer": {
        "authors": [
          "Yuan Cao",
          "Runmin Zhang",
          "Lun Luo",
          "Beinan Yu",
          "Zehua Sheng",
          "Junwei Li",
          "Liang Shen"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2023/papers/Cao_Recurrent_Homography_Estimation_Using_Homography-Guided_Image_Warping_and_Focus_Transformer_CVPR_2023_paper.pdf",
        "ref_texts": "[36] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. LoFTR: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , pages 8922\u20138931, 2021. 4",
        "ref_ids": [
          "36"
        ]
      },
      "Long-term visual localization with mobile sensors": {
        "authors": [
          "Shen Yan",
          "Yu Liu",
          "Long Wang",
          "Zehong Shen",
          "Zhen Peng",
          "Haomin Liu",
          "Maojun Zhang",
          "Guofeng Zhang",
          "Xiaowei Zhou"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2023/papers/Yan_Long-Term_Visual_Localization_With_Mobile_Sensors_CVPR_2023_paper.pdf",
        "ref_texts": "[60] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In CVPR , 2021. 2, 4, 5, 8",
        "ref_ids": [
          "60"
        ]
      },
      "OFVL-MS: Once for visual localization across multiple indoor scenes": {
        "authors": [
          "Tao Xie",
          "Kun Dai",
          "Siyi Lu",
          "Ke Wang",
          "Zhiqiang Jiang",
          "Jinghan Gao",
          "Dedong Liu",
          "Jie Xu",
          "Lijun Zhao",
          "Ruifeng Li"
        ],
        "url": "http://openaccess.thecvf.com/content/ICCV2023/papers/Xie_OFVL-MS_Once_for_Visual_Localization_across_Multiple_Indoor_Scenes_ICCV_2023_paper.pdf",
        "ref_texts": "[42] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , pages 8922\u20138931, 2021. 2",
        "ref_ids": [
          "42"
        ]
      },
      "D2former: Jointly learning hierarchical detectors and contextual descriptors via agent-based transformers": {
        "authors": [
          "Jianfeng He",
          "Yuan Gao",
          "Tianzhu Zhang",
          "Zhe Zhang",
          "Feng Wu"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2023/papers/He_D2Former_Jointly_Learning_Hierarchical_Detectors_and_Contextual_Descriptors_via_Agent-Based_CVPR_2023_paper.pdf",
        "ref_texts": "[42] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. LoFTR: Detector-free local feature matching with transformers. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 8922\u2013",
        "ref_ids": [
          "42"
        ]
      },
      "Etr: An efficient transformer for re-ranking in visual place recognition": {
        "authors": [
          "Hao Zhang",
          "Xin Chen",
          "Heming Jing",
          "Yingbin Zheng",
          "Yuan Wu",
          "Cheng Jin"
        ],
        "url": "https://openaccess.thecvf.com/content/WACV2023/papers/Zhang_ETR_An_Efficient_Transformer_for_Re-Ranking_in_Visual_Place_Recognition_WACV_2023_paper.pdf",
        "ref_texts": "[33] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In CVPR , pages 8922\u20138931, 2021.",
        "ref_ids": [
          "33"
        ]
      },
      "Asic: Aligning sparse in-the-wild image collections": {
        "authors": [
          "Kamal Gupta",
          "Varun Jampani",
          "Carlos Esteves",
          "Abhinav Shrivastava",
          "Ameesh Makadia",
          "Noah Snavely",
          "Abhishek Kar"
        ],
        "url": "https://openaccess.thecvf.com/content/ICCV2023/papers/Gupta_ASIC_Aligning_Sparse_in-the-wild_Image_Collections_ICCV_2023_paper.pdf",
        "ref_texts": "[73] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , pages 8922\u20138931, 2021. 2",
        "ref_ids": [
          "73"
        ]
      },
      "Pixel-perfect structure-from-motion with featuremetric refinement": {
        "authors": [
          "Philipp Lindenberger",
          "Edouard Sarlin",
          "Viktor Larsson",
          "Marc Pollefeys"
        ],
        "url": "https://openaccess.thecvf.com/content/ICCV2021/papers/Lindenberger_Pixel-Perfect_Structure-From-Motion_With_Featuremetric_Refinement_ICCV_2021_paper.pdf",
        "ref_texts": "[74] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. LoFTR: Detector-free local feature matching with Transformers. CVPR , 2021. 2",
        "ref_ids": [
          "74"
        ]
      },
      "Posematcher: One-shot 6d object pose estimation by deep feature matching": {
        "authors": [
          "Pedro Castro",
          "Kyun Kim"
        ],
        "url": "https://openaccess.thecvf.com/content/ICCV2023W/R6D/papers/Castro_PoseMatcher_One-Shot_6D_Object_Pose_Estimation_by_Deep_Feature_Matching_ICCVW_2023_paper.pdf",
        "ref_texts": "[37] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. LoFTR: Detector-free local feature matching with transformers. CVPR , 2021. 3,4,5,6",
        "ref_ids": [
          "37"
        ]
      },
      "Two-view geometry scoring without correspondences": {
        "authors": [
          "Axel Barroso",
          "Eric Brachmann",
          "Victor Adrian",
          "Gabriel J. Brostow",
          "Daniyar Turmukhambetov"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Barroso-Laguna_Two-View_Geometry_Scoring_Without_Correspondences_CVPR_2023_paper.pdf",
        "ref_texts": "[50] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. LoFTR: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , pages 8922\u20138931, 2021. 1, 2, 3, 4, 5, 6, 8",
        "ref_ids": [
          "50"
        ]
      },
      "Robustmat: Neural diffusion for street landmark patch matching under challenging environments": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2311.03904",
        "ref_texts": "[15] J. Sun, Z. Shen, Y . Wang, H. Bao, and X. Zhou, \u201cLoFTR: Detectorfree local feature matching with transformers,\u201d in Proc. IEEE Int. Conf. Comput. Vision Pattern Recognit. , 2021, pp. 8922\u20138931.",
        "ref_ids": [
          "15"
        ]
      },
      "Deep learning of partial graph matching via differentiable top-k": {
        "authors": [
          "Runzhong Wang",
          "Ziao Guo",
          "Shaofei Jiang",
          "Xiaokang Yang",
          "Junchi Yan"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2023/papers/Wang_Deep_Learning_of_Partial_Graph_Matching_via_Differentiable_Top-K_CVPR_2023_paper.pdf",
        "ref_texts": "[36] J. Sun, Z. Shen, Y . Wang, H. Bao, and X. Zhou. Loftr: Detector-free local feature matching with transformers. In Comput. Vis. Pattern Recog. , 2021. 6",
        "ref_ids": [
          "36"
        ]
      },
      "Target-referenced reactive grasping for dynamic objects": {
        "authors": [
          "Jirong Liu",
          "Ruo Zhang",
          "Shu Fang",
          "Minghao Gou",
          "Hongjie Fang",
          "Chenxi Wang",
          "Sheng Xu",
          "Hengxu Yan",
          "Cewu Lu"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2023/papers/Liu_Target-Referenced_Reactive_Grasping_for_Dynamic_Objects_CVPR_2023_paper.pdf",
        "ref_texts": "[33] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. LoFTR: Detector-free local feature matching with transformers. CVPR , 2021. 3",
        "ref_ids": [
          "33"
        ]
      },
      "A unified transformer based tracker for anti-uav tracking": {
        "authors": [
          "Qianjin Yu",
          "Yinchao Ma",
          "Jianfeng He",
          "Dawei Yang",
          "Tianzhu Zhang"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2023W/Anti-UAV/papers/Yu_A_Unified_Transformer_Based_Tracker_for_Anti-UAV_Tracking_CVPRW_2023_paper.pdf",
        "ref_texts": "[49] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. LoFTR: Detector-free local feature matching with transformers. CVPR , 2021. 5, 6",
        "ref_ids": [
          "49"
        ]
      },
      "Learning rotation-equivariant features for visual correspondence": {
        "authors": [
          "Jongmin Lee",
          "Byungjin Kim",
          "Seungwook Kim",
          "Minsu Cho"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Lee_Learning_Rotation-Equivariant_Features_for_Visual_Correspondence_CVPR_2023_paper.pdf",
        "ref_texts": "[27]David G Lowe. Distinctive image features from scale-invariant keypoints.International journal of computer vi-sion, 60(2):91\u2013110, 2004.1,2,3,4,5,6,7[28]Zixin Luo, Lei Zhou, Xuyang Bai, Hongkai Chen, JiahuiZhang, Yao Yao, Shiwei Li, Tian Fang, and Long Quan.Aslfeat: Learning local features of accurate shape and lo-calization. InProceedings of the IEEE/CVF conference oncomputer vision and pattern recognition, pages 6589\u20136598,2020.2,6[29]Simon Lynen, Bernhard Zeisl, Dror Aiger, Michael Bosse,Joel Hesch, Marc Pollefeys, Roland Siegwart, and TorstenSattler. Large-scale, real-time visual\u2013inertial localization re-visited.The International Journal of Robotics Research,39(9):1061\u20131084, 2020.1[30]Diego Marcos, Michele Volpi, Nikos Komodakis, and DevisTuia. Rotation equivariant vector field networks. InPro-ceedings of the IEEE International Conference on ComputerVision, pages 5048\u20135057, 2017.2[31]Roland Memisevic. On multi-view feature learning. InICML, 2012.2[32]Roland Memisevic and Geoffrey E Hinton. Learning torepresent spatial transformations with factored higher-orderboltzmann machines.Neural computation, 22(6):1473\u20131492, 2010.2[33]Krystian Mikolajczyk and Cordelia Schmid. Scale & affineinvariant interest point detectors.International journal ofcomputer vision, 60(1):63\u201386, 2004.5[34]Krystian Mikolajczyk and Cordelia Schmid. A performanceevaluation of local descriptors.IEEE transactions on patternanalysis and machine intelligence, 27(10):1615\u20131630, 2005.6[35]Juhong Min, Jongmin Lee, Jean Ponce, and Minsu Cho.Hyperpixel flow: Semantic correspondence with multi-layerneural features. InICCV, 2019.3[36]Anastasiia Mishchuk, Dmytro Mishkin, Filip Radenovic,and Jiri Matas. Working hard to know your neighbor\u2019s mar-gins: Local descriptor learning loss. InAdvances in NeuralInformation Processing Systems, pages 4826\u20134837, 2017.2[37]Dmytro Mishkin, Filip Radenovic, and Jiri Matas. Repeata-bility is not enough: Learning affine regions via discrim-inability. InProceedings of the European Conference onComputer Vision (ECCV), pages 284\u2013300, 2018.2[38]Daniel Moyer, Esra Abaci Turk, P Ellen Grant, William MWells, and Polina Golland. Equivariant filters for efficienttracking in 3d imaging. InInternational Conference on Med-ical Image Computing and Computer-Assisted Intervention,pages 193\u2013202. Springer, 2021.2[39]Raul Mur-Artal, Jose Maria Martinez Montiel, and Juan DTardos. Orb-slam: a versatile and accurate monocular slamsystem.IEEE transactions on robotics, 31(5):1147\u20131163,2015.1,6[40]Yuki Ono, Eduard Trulls, Pascal Fua, and Kwang Moo Yi.Lf-net: learning local features from images. InAdvancesin neural information processing systems, pages 6234\u20136244,2018.2,3,6,7,8[41]Aaron van den Oord, Yazhe Li, and Oriol Vinyals. Repre-sentation learning with contrastive predictive coding.arXivpreprint arXiv:1807.03748, 2018.5[42]R\u00b4emi Pautrat, Viktor Larsson, Martin R Oswald, and MarcPollefeys. Online invariance selection for local feature de-scriptors. InEuropean Conference on Computer Vision,pages 707\u2013724. Springer, 2020.2,6,7[43]Nicolas Pielawski, Elisabeth Wetzer, Johan\u00a8Ofverstedt, Ji-ahao Lu, Carolina W\u00a8ahlby, Joakim Lindblad, and Nata\u02c7saSladoje. CoMIR: Contrastive multimodal image representa-tion for registration. In H. Larochelle, M. Ranzato, R. Had-sell, M. F. Balcan, and H. Lin, editors,Advances in NeuralInformation Processing Systems, volume 33, pages 18433\u201318444. Curran Associates, Inc., 2020.2[44]Jerome Revaud, Cesar De Souza, Martin Humenberger, andPhilippe Weinzaepfel. R2d2: Reliable and repeatable detec-tor and descriptor.Advances in neural information process-ing systems, 32:12405\u201312415, 2019.1,2,5,6[45]J\u00b4erome Revaud, Vincent Leroy, Philippe Weinzaepfel, andBoris Chidlovskii. Pump: Pyramidal and uniqueness match-ing priors for unsupervised learning of local descriptors. InProceedings of the IEEE/CVF Conference on Computer Vi-sion and Pattern Recognition, pages 3926\u20133936, 2022.1[46]Ethan Rublee, Vincent Rabaud, Kurt Konolige, and GaryBradski. Orb: An efficient alternative to sift or surf. In2011International conference on computer vision, pages 2564\u20132571. Ieee, 2011.1,2,6,7[47]Torsten Sattler, Bastian Leibe, and Leif Kobbelt. Improvingimage-based localization by active correspondence search.InEuropean conference on computer vision, pages 752\u2013765.Springer, 2012.1[48]Torsten Sattler, Will Maddern, Carl Toft, Akihiko Torii,Lars Hammarstrand, Erik Stenborg, Daniel Safari, MasatoshiOkutomi, Marc Pollefeys, Josef Sivic, et al. Benchmark-ing 6dof outdoor visual localization in changing conditions.InProceedings of the IEEE Conference on Computer Visionand Pattern Recognition, pages 8601\u20138610, 2018.1[49]Johannes L Schonberger and Jan-Michael Frahm. Structure-from-motion revisited. InProceedings of the IEEE con-ference on computer vision and pattern recognition, pages4104\u20134113, 2016.1[50]Xuelun Shen, Cheng Wang, Xin Li, Zenglei Yu, JonathanLi, Chenglu Wen, Ming Cheng, and Zijian He. Rf-net: Anend-to-end image matching network based on receptive field.InProceedings of the IEEE Conference on Computer Visionand Pattern Recognition, pages 8132\u20138140, 2019.2,6,7,8[51]Kihyuk Sohn and Honglak Lee. Learning invariant represen-tations with local transformations. InICML, 2012.2[52]Ivan Sosnovik, Artem Moskalev, and Arnold Smeulders.How to transform kernels for scale-convolutions. InPro-ceedings of the IEEE/CVF International Conference onComputer Vision, pages 1092\u20131097, 2021.2[53]Christoph Strecha, Wolfgang Von Hansen, Luc Van Gool,Pascal Fua, and Ulrich Thoennessen. On benchmarking cam-era calibration and multi-view stereo for high resolution im-agery. In2008 IEEE conference on computer vision and pat-tern recognition, pages 1\u20138. Ieee, 2008.2,5,6,7[54]Yurun Tian, Axel Barroso Laguna, Tony Ng, Vassileios Bal-ntas, and Krystian Mikolajczyk. Hynet: Learning local de-scriptor with hybrid similarity measure and triplet loss.Ad21896",
        "ref_ids": [
          "27",
          "28",
          "29",
          "30",
          "31",
          "32",
          "33",
          "34",
          "35",
          "36",
          "37",
          "38",
          "39",
          "40",
          "41",
          "42",
          "43",
          "44",
          "45",
          "46",
          "47",
          "48",
          "49",
          "50",
          "51",
          "52",
          "53",
          "54"
        ]
      },
      "Guiding local feature matching with surface curvature": {
        "authors": [
          "Shuzhe Wang",
          "Juho Kannala",
          "Marc Pollefeys",
          "Daniel Barath"
        ],
        "url": "http://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Guiding_Local_Feature_Matching_with_Surface_Curvature_ICCV_2023_paper.pdf",
        "ref_texts": "[55] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. LoFTR: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , 2021. 1, 2, 3, 4, 5, 6, 7",
        "ref_ids": [
          "55"
        ]
      },
      "Sound localization from motion: Jointly learning sound direction and camera rotation": {
        "authors": [
          "Ziyang Chen",
          "Shengyi Qian",
          "Andrew Owens"
        ],
        "url": "http://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Sound_Localization_from_Motion_Jointly_Learning_Sound_Direction_and_Camera_ICCV_2023_paper.pdf",
        "ref_texts": "[85] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , pages 8922\u20138931, 2021. 6",
        "ref_ids": [
          "85"
        ]
      },
      "Shallow-guided transformer for semantic segmentation of hyperspectral remote sensing imagery": {
        "authors": [
          "Yuhan Chen",
          "Pengyuan Liu",
          "Jiechen Zhao",
          "Kaijian Huang",
          "Qingyun Yan"
        ],
        "url": "https://www.mdpi.com/2072-4292/15/13/3366/pdf",
        "ref_texts": "31. Sun, J.; Shen, Z.; Wang, Y.; Bao, H.; Zhou, X. LoFTR: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, Nashville, TN, USA, 20\u201325 June 2021; pp. 8922\u20138931.",
        "ref_ids": [
          "31"
        ]
      },
      "Graph-covis: Gnn-based multi-view panorama global pose estimation": {
        "authors": [
          "Negar Nejatishahidin",
          "Will Hutchcroft",
          "Manjunath Narayana",
          "Ivaylo Boyadzhiev",
          "Yuguang Li",
          "Naji Khosravan",
          "Jana Kosecka",
          "Sing Bing"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2023W/OmniCV/papers/Nejatishahidin_Graph-CoVis_GNN-Based_Multi-View_Panorama_Global_Pose_Estimation_CVPRW_2023_paper.pdf",
        "ref_texts": "[24] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. 2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) , pages 8918\u2013",
        "ref_ids": [
          "24"
        ]
      },
      "Joint appearance and motion learning for efficient rolling shutter correction": {
        "authors": [
          "Bin Fan",
          "Yuxin Mao",
          "Yuchao Dai",
          "Zhexiong Wan",
          "Qi Liu"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Fan_Joint_Appearance_and_Motion_Learning_for_Efficient_Rolling_Shutter_Correction_CVPR_2023_paper.pdf",
        "ref_texts": "[46] Jiaming Sun, Zehong Shen, Y uang Wang, Hujun Bao, and Xiaowei Zhou. LoFTR: detector-free local feature matching with transformers. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , pages 8922\u20138931, 2021. 3",
        "ref_ids": [
          "46"
        ]
      },
      "Segment anything model is a good teacher for local feature learning": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2309.16992",
        "ref_texts": "[32] J. Sun, Z. Shen, Y . Wang, H. Bao, and X. Zhou, \u201cLoftr: Detectorfree local feature matching with transformers,\u201d in Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , 2021, pp. 8922\u20138931.",
        "ref_ids": [
          "32"
        ]
      },
      "Deep corner": {
        "authors": [
          "Shanshan Zhao"
        ],
        "url": "https://link.springer.com/content/pdf/10.1007/s11263-023-01837-3.pdf",
        "ref_texts": "|DOIurl10.1109/ICCV .2003.1238663. Sturm, J., Engelhard, N., Endres, F., Burgard, W., & Cremers, D. (2012). A benchmark for the evaluation of RGB-D slam systems. In 2012 IEEE/RSJ international conference on intelligent robots and sys-tems . IEEE (pp. 573\u2013580). Sun, J., Shen, Z., Wang, Y ., Bao, H., & Zhou, X. (2021). Loftr: Detectorfree local feature matching with transformers. In Proceedings ofthe IEEE/CVF conference on computer vision and pattern recognition (pp. 8922\u20138931). Sun, S., Park, U., Sun, S., & Liu, R. (2022b). Fusion representation learning for keypoint detection and description. The Visual Computer pp 1\u201310. Sun, J., Zhu, J., & Ji, L. (2022a). Shared coupling-bridge for weakly supervised local feature learning. arXiv preprintarXiv:2212.07047 . Suwanwimolkul, S., Komorita, S., & Tasaka, K. (2021). Learning of low-level feature keypoints for accurate and robust detection. InProceedings of the IEEE/CVF winter conference on applicationsof computer vision (pp. 2262\u20132271). Sv\u00e4rm, L., Enqvist, O., Kahl, F., & Oskarsson, M. (2017). City-scale localization for cameras with known vertical direction. IEEE Transactions on Pattern Analysis and Machine Intelligence, 39 (7), 1455\u20131461. https://doi.org/10.1109/TPAMI.2016.2598331 Tian, Y ., Balntas, V ., Ng, T., Barroso-Laguna, A., Demiris, Y ., & Mikolajczyk, K. (2020a). D2d: Keypoint extraction with describe todetect approach. In Proceedings of the Asian conference on computer vision . Tian, Y ., Barroso Laguna, A., Ng, T., Balntas, V ., & Mikolajczyk, K."
      },
      "A light touch approach to teaching transformers multi-view geometry": {
        "authors": [
          "Yash Bhalgat",
          "Joao F. Henriques",
          "Andrew Zisserman"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Bhalgat_A_Light_Touch_Approach_to_Teaching_Transformers_Multi-View_Geometry_CVPR_2023_paper.pdf",
        "ref_texts": "[72] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , pages 8922\u20138931, 2021. 2, 6, 7, 8",
        "ref_ids": [
          "72"
        ]
      },
      "Multi-sensor data fusion for 3d reconstruction of complex structures: A case study on a real high formwork project": {
        "authors": [
          "Linlin Zhao",
          "Huirong Zhang",
          "Jasper Mbachu"
        ],
        "url": "https://www.mdpi.com/2072-4292/15/5/1264/pdf",
        "ref_texts": "92. Sun, J.; Shen, Z.; Wang, Y.; Bao, H.; Zhou, X. LoFTR: Detector-Free Local Feature Matching with Transformers. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), Nashville, TN, USA, 20\u201325 June 2021.",
        "ref_ids": [
          "92"
        ]
      },
      "Improving transformer-based image matching by cascaded capturing spatially informative keypoints": {
        "authors": [
          "Chenjie Cao",
          "Yanwei Fu"
        ],
        "url": "http://openaccess.thecvf.com/content/ICCV2023/papers/Cao_Improving_Transformer-based_Image_Matching_by_Cascaded_Capturing_Spatially_Informative_Keypoints_ICCV_2023_paper.pdf",
        "ref_texts": "[43] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , pages 8922\u20138931, 2021. 1, 2, 3, 4, 5, 6, 7",
        "ref_ids": [
          "43"
        ]
      },
      "Porf: Pose residual field for accurate neural surface reconstruction": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2310.07449",
        "ref_texts": "10 Published as a conference paper at ICLR 2024 Johannes Lutz Sch \u00a8onberger and Jan-Michael Frahm. Structure-from-motion revisited. CVPR , 2016. Johannes Lutz Sch \u00a8onberger, Enliang Zheng, Marc Pollefeys, and Jan-Michael Frahm. Pixelwise view selection for unstructured multi-view stereo. In ECCV , 2016. Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. LoFTR: Detector-free local feature matching with transformers. CVPR , 2021. Matthew Tancik, Ethan Weber, Evonne Ng, Ruilong Li, Brent Yi, Terrance Wang, Alexander Kristoffersen, Jake Austin, Kamyar Salahi, Abhik Ahuja, et al. Nerfstudio: A modular framework for neural radiance field development. In ACM SIGGRAPH 2023 Conference Proceedings , pp. 1\u201312, 2023. Prune Truong, Marie-Julie Rakotosaona, Fabian Manhardt, and Federico Tombari. Sparf: Neural radiance fields from sparse and noisy poses. In CVPR , pp. 4190\u20134200, 2023. Jiepeng Wang, Peng Wang, Xiaoxiao Long, Christian Theobalt, Taku Komura, Lingjie Liu, and Wenping Wang. Neuris: Neural reconstruction of indoor scenes using normal priors. In ECCV , pp. 139\u2013155. Springer, 2022a. Peng Wang, Lingjie Liu, Yuan Liu, Christian Theobalt, Taku Komura, and Wenping Wang. Neus: Learning neural implicit surfaces by volume rendering for multi-view reconstruction. In NeurIPS , 2021a. Yiqun Wang, Ivan Skorokhodov, and Peter Wonka. Hf-neus: Improved surface reconstruction using high-frequency details. NeurIPS , 35:1966\u20131978, 2022b. Zirui Wang, Shangzhe Wu, Weidi Xie, Min Chen, and Victor Adrian Prisacariu. NeRF \u2212\u2212: Neural radiance fields without known camera parameters. arXiv preprint arXiv:2102.07064 , 2021b. Tong Wu, Jiaqi Wang, Xingang Pan, Xudong Xu, Christian Theobalt, Ziwei Liu, and Dahua Lin. V oxurf: V oxel-based efficient and accurate neural surface reconstruction. In ICLR , 2023. Yitong Xia, Hao Tang, Radu Timofte, and Luc Van Gool. Sinerf: Sinusoidal neural radiance fields for joint pose estimation and scene reconstruction. arXiv preprint arXiv:2210.04553 , 2022. Qiangeng Xu, Zexiang Xu, Julien Philip, Sai Bi, Zhixin Shu, Kalyan Sunkavalli, and Ulrich Neumann. Point-nerf: Point-based neural radiance fields. In CVPR , pp. 5438\u20135448, 2022. Yao Yao, Zixin Luo, Shiwei Li, Tian Fang, and Long Quan. Mvsnet: Depth inference for unstructured multi-view stereo. In ECCV , pp. 767\u2013783, 2018. Yao Yao, Zixin Luo, Shiwei Li, Tianwei Shen, Tian Fang, and Long Quan. Recurrent mvsnet for high-resolution multi-view stereo depth inference. In CVPR , pp. 5525\u20135534, 2019. Lior Yariv, Yoni Kasten, Dror Moran, Meirav Galun, Matan Atzmon, Basri Ronen, and Yaron Lipman. Multiview neural surface reconstruction by disentangling geometry and appearance. NeurIPS , 33, 2020. Lior Yariv, Jiatao Gu, Yoni Kasten, and Yaron Lipman. V olume rendering of neural implicit surfaces. InThirty-Fifth Conference on Neural Information Processing Systems , 2021. Zehao Yu, Songyou Peng, Michael Niemeyer, Torsten Sattler, and Andreas Geiger. Monosdf: Exploring monocular geometric cues for neural implicit surface reconstruction. NeurIPS , 2022. Jingyang Zhang, Yao Yao, Shiwei Li, Zixin Luo, and Tian Fang. Visibility-aware multi-view stereo network. BMVC , 2020a. Jingyang Zhang, Yao Yao, Shiwei Li, Tian Fang, David McKinnon, Yanghai Tsin, and Long Quan. Critical regularizations for neural surface reconstruction in the wild. In CVPR , pp. 6270\u20136279, 2022. Kai Zhang, Gernot Riegler, Noah Snavely, and Vladlen Koltun. Nerf++: Analyzing and improving neural radiance fields. arXiv preprint arXiv:2010.07492 , 2020b. Qian-Yi Zhou, Jaesik Park, and Vladlen Koltun. Open3D: A modern library for 3D data processing. arXiv:1801.09847 , 2018."
      },
      "Unbalanced optimal transport: A unified framework for object detection": {
        "authors": [
          "Henri De",
          "Francois De",
          "Johan A. K",
          "Marc Proesmans",
          "Tinne Tuytelaars",
          "Luc Van"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2023/papers/De_Plaen_Unbalanced_Optimal_Transport_A_Unified_Framework_for_Object_Detection_CVPR_2023_paper.pdf",
        "ref_texts": ""
      },
      "Geometrized transformer for self-supervised homography estimation": {
        "authors": [
          "Jiazhen Liu",
          "Xirong Li"
        ],
        "url": "http://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Geometrized_Transformer_for_Self-Supervised_Homography_Estimation_ICCV_2023_paper.pdf",
        "ref_texts": "[26] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. LoFTR: Detector-free local feature matching with transformers. In CVPR , 2021. 1, 2, 3, 6, 7",
        "ref_ids": [
          "26"
        ]
      },
      "Nope-sac: Neural one-plane ransac for sparse-view planar 3d reconstruction": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2211.16799",
        "ref_texts": "[36] J. Sun, Z. Shen, Y. Wang, H. Bao, and X. Zhou, \u201cLoftr: Detector-free local feature matching with transformers,\u201d in IEEE Conf. Comput. Vis. Pattern Recog. , 2021, pp. 8922\u20138931. 3, 8, 9, 10, 12, 13, 14",
        "ref_ids": [
          "36"
        ]
      },
      "Visual localization using imperfect 3d models from the internet": {
        "authors": [
          "Vojtech Panek",
          "Zuzana Kukelova",
          "Torsten Sattler"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2023/papers/Panek_Visual_Localization_Using_Imperfect_3D_Models_From_the_Internet_CVPR_2023_paper.pdf",
        "ref_texts": "[91] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. LoFTR: Detector-Free Local Feature Matching With Transformers. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) , 2021. 1, 3, 7, 8",
        "ref_ids": [
          "91"
        ]
      },
      "Privacy-preserving representations are not enough: Recovering scene content from camera poses": {
        "authors": [
          "Kunal Chelani",
          "Torsten Sattler",
          "Fredrik Kahl",
          "Zuzana Kukelova"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Chelani_Privacy-Preserving_Representations_Are_Not_Enough_Recovering_Scene_Content_From_Camera_CVPR_2023_paper.pdf",
        "ref_texts": "[43] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. LoFTR: Detector-free local feature matching with transformers. CVPR , 2021. 2",
        "ref_ids": [
          "43"
        ]
      },
      "OmnimatteRF: Robust Omnimatte with 3D Background Modeling": {
        "authors": [
          "Geng Lin",
          "Chen Gao",
          "Bin Huang",
          "Changil Kim",
          "Yipeng Wang",
          "Matthias Zwicker",
          "Ayush Saraf"
        ],
        "url": "http://openaccess.thecvf.com/content/ICCV2023/papers/Lin_OmnimatteRF_Robust_Omnimatte_with_3D_Background_Modeling_ICCV_2023_paper.pdf",
        "ref_texts": "[28] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. LoFTR: Detector-free local feature matching with transformers. CVPR , 2021. 6",
        "ref_ids": [
          "28"
        ]
      },
      "Mipi 2023 challenge on rgb+ tof depth completion: Methods and results": {
        "authors": [
          "Qingpeng Zhu",
          "Wenxiu Sun",
          "Yuekun Dai",
          "Chongyi Li",
          "Shangchen Zhou",
          "Ruicheng Feng",
          "Qianhui Sun",
          "Chen Change",
          "Jinwei Gu",
          "Yi Yu",
          "Yangke Huang",
          "Kang Zhang",
          "Meiya Chen",
          "Yu Wang",
          "Yongchao Li",
          "Hao Jiang",
          "Amrit Kumar",
          "Vikash Kumar",
          "Kunal Swami",
          "Pankaj Kumar",
          "Yunchao Ma",
          "Jiajun Xiao",
          "Zhi Ling"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2023W/MIPI/papers/Zhu_MIPI_2023_Challenge_on_RGBToF_Depth_Completion_Methods_and_Results_CVPRW_2023_paper.pdf",
        "ref_texts": "[21] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) , pages 8922\u20138931, 2021. 4",
        "ref_ids": [
          "21"
        ]
      },
      "Self-supervised endoscopic image key-points matching": {
        "authors": [
          "Manel Farhat",
          "Houda Chaabouni",
          "Achraf Ben"
        ],
        "url": "https://arxiv.org/pdf/2208.11424",
        "ref_texts": "2571). Barcelona, Spain. Saha, S., Xiao, D., Frost, S., & Kanagasingam, Y. (2016). A two-step approach for longitudinal registration of retinal images. Journal of Medical Systems , 40. Sarlin, P.-E., DeTone, D., Malisiewicz, T., & Rabinovich, A. (2020). SuperGlue: Learning feature matching with graph neural networks. In CVPR . Schrofi, F., Kalenichenko, D., & Philbin, J. (2015). Facenet: A uniffed embedding for face recognition and clustering. 2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , . Shan, H., Jia, X., Yan, P., Li3, Y., Paganetti, H., & Wang, G. (2020). Synergizing medical imaging and radiotherapy with deep learning. Machine Learning: Science and Technology ,1. Sharib, A., C., D., Galbrun, E., Guillemin, F., & Blondel, W. (2016). Anisotropic motion estimation on edge preserving riesz wavelets for robust video mosaicing. Pattern Recognition ,51, 425{442. Sharib, A., Daul, C., Weibel, T., & Blondel, W. (2013). Fast mosaicing of cystoscopic images from dense correspondence: Combined surf and tv-l1 optical ow method. In 2013 IEEE Int. Conf. on Image Processing (pp. 1291{1295). Simo-Serra, E., Trulls, E., Ferraz, L., Kokkinos, I., Fua, P., & Moreno-Noguer, F. (2015). Discriminative learning of deep convolutional feature point descriptors. In 2015 IEEE Int. Conf. on Computer Vision (ICCV) (pp. 118{126). Spitzer, H., Kiwitz, K., Amunts, K., Harmeling, S., & Dickscheid, T. (2018). Improving cytoarchitectonic segmentation of human brain areas with self32 supervised siamese networks. In International Conference on Medical Image Computing and Computer-Assisted Intervention (pp. 663{671). Springer. Sun, J., Shen, Z., Wang, Y., Bao, H., & Zhou, X. (2021). LoFTR: Detector-free local feature matching with transformers. CVPR , . Sung, H., Ferlay, J., L., S. R., Laversanne, M., Soerjomataram, I., Jemal, A., & Bray, F. (2020). Global cancer statistics 2020: Globocan estimates of incidence and mortality worldwide for 36 cancers in 185 countries. CA: a cancer journal for clinicians ,0, 1{41. Tajbakhsh, N., Shin, J. Y., Gurudu, S. R., Hurst, R. T., Kendall, C. B., Gotway, M. B., & Liang, J. (2016). Convolutional neural networks for medical image analysis: Full training or ffne tuning? IEEE Transactions on Medical Imaging ,35, 1299{1312. Tian, Y., Barroso Laguna, A., Ng, T., Balntas, V., & Mikolajczyk, K. (2020). Hynet: Learning local descriptor with hybrid similarity measure and triplet loss. In NeurIPS . Tian, Y., Fan, B., & Wu, F. (2017). L2-net: Deep learning of discriminative patch descriptor in euclidean space. In 2017 IEEE Conf. on Computer Vision and Pattern Recognition (CVPR) (pp. 6128{6136). Tian, Y., Yu, X., Fan, B., Wu, F., Heijnen, H., & Balntas, V. (2019). Sosnet: Second order similarity regularization for local descriptor learning. In CVPR . Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, L. u., & Polosukhin, I. (2017). Attention is all you need. In I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, & R. Garnett (Eds.), Advances in Neural Information Processing Systems (p."
      },
      "Oamatcher: An overlapping areas-based network for accurate local feature matching": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2302.05846",
        "ref_texts": "[31] J. Sun, Z. Shen, Y . Wang, H. Bao, and X. Zhou, \u201cLoftr: Detectorfree local feature matching with transformers,\u201d in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , 2021, pp. 8922\u20138931.",
        "ref_ids": [
          "31"
        ]
      },
      "Improving the matching of deformable objects by learning to detect keypoints": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2309.00434",
        "ref_texts": "[12] J. Sun, Z. Shen, Y. Wang, H. Bao, X. Zhou, LoFTR: detectorfree local feature matching with transformers, in: CVPR, 2021.",
        "ref_ids": [
          "12"
        ]
      },
      "Find my astronaut photo: Automated localization and georectification of astronaut photography": {
        "authors": [
          "Alex Stoken",
          "Kenton Fisher"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2023W/IMW/papers/Stoken_Find_My_Astronaut_Photo_Automated_Localization_and_Georectification_of_Astronaut_CVPRW_2023_paper.pdf",
        "ref_texts": "[33] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. LoFTR: Detector-free local feature matching with transformers. CVPR , 2021. 3, 6",
        "ref_ids": [
          "33"
        ]
      },
      "Occ^ 2Net: Robust Image Matching Based on 3D Occupancy Estimation for Occluded Regions": {
        "authors": [
          "Miao Fan",
          "Mingrui Chen",
          "Chen Hu",
          "Shuchang Zhou"
        ],
        "url": "https://openaccess.thecvf.com/content/ICCV2023/papers/Fan_Occ2Net_Robust_Image_Matching_Based_on_3D_Occupancy_Estimation_for_ICCV_2023_paper.pdf",
        "ref_texts": "[40] Jiaming Sun, Zehong Shen, Y uang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matchingwith transformers. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , pages 8922\u20138931, 2021.",
        "ref_ids": [
          "40"
        ]
      },
      "Intertrack: Interaction transformer for 3d multi-object tracking": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2208.08041",
        "ref_texts": "[37] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. CVPR , 2021.",
        "ref_ids": [
          "37"
        ]
      },
      "Learning probabilistic coordinate fields for robust correspondences": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2306.04231",
        "ref_texts": "[18] J. Sun, Z. Shen, Y. Wang, H. Bao, and X. Zhou, \u201cLoftr: Detectorfree local feature matching with transformers,\u201d in Proc. IEEE Conf. Comput. Vis. Pattern Recogn. , 2021, pp. 8922\u20138931.",
        "ref_ids": [
          "18"
        ]
      },
      "Visual geometry grounded deep structure from motion": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2312.04563",
        "ref_texts": "[75] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , pages 8922\u20138931, 2021. 2, 3",
        "ref_ids": [
          "75"
        ]
      },
      "The evaluation of hand-crafted and learned-based features in Terrestrial Laser Scanning-Structure-from-Motion (TLS-SfM) indoor point cloud registration: the case \u2026": {
        "authors": [
          "Jakub Markiewicz"
        ],
        "url": "https://link.springer.com/content/pdf/10.1186/s40494-023-01099-9.pdf",
        "ref_texts": ""
      },
      "Dynamicstereo: Consistent dynamic depth from stereo videos": {
        "authors": [
          "Nikita Karaev",
          "Ignacio Rocco",
          "Benjamin Graham",
          "Natalia Neverova",
          "Andrea Vedaldi",
          "Christian Rupprecht"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Karaev_DynamicStereo_Consistent_Dynamic_Depth_From_Stereo_Videos_CVPR_2023_paper.pdf",
        "ref_texts": "[42] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. LoFTR: Detector-free local feature matching with transformers. CVPR , 2021. 2, 3, 4, 7",
        "ref_ids": [
          "42"
        ]
      },
      "Refinement for absolute pose regression with neural feature synthesis": {
        "authors": [],
        "url": "https://ora.ox.ac.uk/objects/uuid:19bccf1c-7d02-4aa5-884e-cec9d4a963c6/download_file?file_format=application%2Fpdf&safe_filename=Chen_et_al_2023_Refinement_for_absolute.pdf&type_of_work=Internet+publication",
        "ref_texts": "[52] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. LoFTR: Detector-free local feature matching with transformers. CVPR , 2021. 1, 3",
        "ref_ids": [
          "52"
        ]
      },
      "Objectmatch: Robust registration using canonical object correspondences": {
        "authors": [
          "Can Gumeli",
          "Angela Dai",
          "Matthias Niessner"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Gumeli_ObjectMatch_Robust_Registration_Using_Canonical_Object_Correspondences_CVPR_2023_paper.pdf",
        "ref_texts": "[42] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , pages 8922\u20138931, 2021. 2",
        "ref_ids": [
          "42"
        ]
      },
      "Costformer: Cost transformer for cost aggregation in multi-view stereo": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2305.10320",
        "ref_texts": "[Sunet al. , 2021 ]Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , pages 8922\u20138931, 2021.",
        "ref_ids": [
          "Sunet al\\. , 2021 "
        ]
      },
      "A2b: Anchor to barycentric coordinate for robust correspondence": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2306.02760",
        "ref_texts": "348 Sun D, Roth S, Lewis J, Black MJ (2008) Learning optical flow. In: Proc. Eur. Conf. Comput. Vis., Springer, pp 83\u201397 Sun J, Shen Z, Wang Y , Bao H, Zhou X (2021) Loftr: Detector-free local feature matching with transformers. A2B: Anchor to Barycentric Coordinate for Robust Correspondence 25 In: Proc. IEEE Conf. Comput. Vis. Pattern Recogn., pp 8922\u20138931 Sun W, Jiang W, Trulls E, Tagliasacchi A, Yi KM"
      },
      "Image patch-matching with graph-based learning in street scenes": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2311.04617",
        "ref_texts": "[50] J. Sun, Z. Shen, Y . Wang, H. Bao, and X. Zhou, \u201cLoFTR: Detectorfree local feature matching with transformers,\u201d in Proc. IEEE Int. Conf. Comput. Vision Pattern Recognit. , 2021, pp. 8922\u20138931.",
        "ref_ids": [
          "50"
        ]
      },
      "Self-supervised correspondence estimation via multiview registration": {
        "authors": [
          "Mohamed El",
          "Ignacio Rocco",
          "David Novotny",
          "Andrea Vedaldi",
          "Natalia Neverova",
          "Justin Johnson",
          "Ben Graham"
        ],
        "url": "https://openaccess.thecvf.com/content/WACV2023/papers/Banani_Self-Supervised_Correspondence_Estimation_via_Multiview_Registration_WACV_2023_paper.pdf",
        "ref_texts": "[62] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. LoFTR: Detector-free local feature matching with transformers. CVPR , 2021. 3, 6, 7",
        "ref_ids": [
          "62"
        ]
      },
      "Amatformer: Efficient feature matching via anchor matching transformer": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2305.19205",
        "ref_texts": "[25] J. Sun, Z. Shen, Y . Wang, H. Bao, and X. Zhou, \u201cLoftr: Detectorfree local feature matching with transformers,\u201d in Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , 2021, pp. 8922\u20138931.",
        "ref_ids": [
          "25"
        ]
      },
      "Enhancing Feature Detection and Matching in Low-Pixel-Resolution Hyperspectral Images Using 3D Convolution-Based Siamese Networks": {
        "authors": [
          "Chamika Janith",
          "Chinthaka Premachandra",
          "Hiroharu Kawanaka"
        ],
        "url": "https://www.mdpi.com/1424-8220/23/18/8004/pdf",
        "ref_texts": "4. Sun, J.; Shen, Z.; Wang, Y.; Bao, H.; Zhou, X. LoFTR: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, Nashville, TN, USA, 20\u201325 June 2021; pp. 8922\u20138931.",
        "ref_ids": [
          "4"
        ]
      },
      "A Review of Homography Estimation: Advances and Challenges": {
        "authors": [
          "Yinhui Luo",
          "Xingyi Wang",
          "Yanhao Liao",
          "Qiang Fu",
          "Chang Shu",
          "Yuezhou Wu",
          "Yuanqing He"
        ],
        "url": "https://www.mdpi.com/2079-9292/12/24/4977/pdf",
        "ref_texts": "53. Sun, J.; Shen, Z.; Wang, Y.; Bao, H.; Zhou, X. LoFTR: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, Nashville, TN, USA, 19\u201325 June 2021; pp. 8922\u20138931.",
        "ref_ids": [
          "53"
        ]
      },
      "Visualizing Skiers' Trajectories in Monocular Videos": {
        "authors": [
          "Matteo Dunnhofer",
          "Luca Sordi",
          "Christian Micheloni"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2023W/CVSports/papers/Dunnhofer_Visualizing_Skiers_Trajectories_in_Monocular_Videos_CVPRW_2023_paper.pdf",
        "ref_texts": "[57] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. LoFTR: Detector-free local feature matching with transformers. CVPR , 2021. 3, 5, 6, 14",
        "ref_ids": [
          "57"
        ]
      },
      "Featurebooster: Boosting feature descriptors with a lightweight neural network": {
        "authors": [
          "Xinjiang Wang",
          "Zeyu Liu",
          "Yu Hu",
          "Wei Xi",
          "Wenxian Yu",
          "Danping Zou"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2023/papers/Wang_FeatureBooster_Boosting_Feature_Descriptors_With_a_Lightweight_Neural_Network_CVPR_2023_paper.pdf",
        "ref_texts": "[41] Jiaming Sun, Zehong Shen, Y uang Wang, Hujun Bao, and Xiaowei Zhou. LoFTR: Detector-free local feature matching with transformers. In CVPR , pages 8922\u20138931, 2021. 2",
        "ref_ids": [
          "41"
        ]
      },
      "DualRC: A Dual-Resolution Learning Framework With Neighbourhood Consensus for Visual Correspondences": {
        "authors": [],
        "url": "https://ora.ox.ac.uk/objects/uuid:3638c68a-d9ad-4f1a-86fa-4ecfe3493bf3/files/r8k71nj075",
        "ref_texts": "[46] J. Sun, Z. Shen, Y. Wang, H. Bao, and X. Zhou, \u201cLoFTR: Detectorfree local feature matching with transformers,\u201d Proceedings of IEEE Intl. Conf. on Computer Vision and Pattern Recognition (CVPR) , 2021.",
        "ref_ids": [
          "46"
        ]
      },
      "Uncertainty-driven dense two-view structure from motion": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2302.00523",
        "ref_texts": "[17] J. Sun, Z. Shen, Y . Wang, H. Bao, and X. Zhou, \u201cLoftr: Detector-free local feature matching with transformers,\u201d in CVPR , 2021, pp. 8922\u2013",
        "ref_ids": [
          "17"
        ]
      },
      "Memory-efficient optical flow via radius-distribution orthogonal cost volume": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2312.03790",
        "ref_texts": "[32] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In IEEE Conf. Comput. Vis. Pattern Recog. , pages 8922\u20138931, 2021. 3",
        "ref_ids": [
          "32"
        ]
      },
      "3d-aware hypothesis & verification for generalizable relative object pose estimation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2310.03534",
        "ref_texts": "11 Preprint Ivan Shugurov, Fu Li, Benjamin Busam, and Slobodan Ilic. Osop: A multi-stage one shot object pose estimation framework. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pp. 6835\u20136844, 2022. Yongzhi Su, Mahdi Saleh, Torben Fetzer, Jason Rambach, Nassir Navab, Benjamin Busam, Didier Stricker, and Federico Tombari. Zebrapose: Coarse to fine surface encoding for 6dof object pose estimation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pp. 6738\u20136748, 2022. Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pp. 8922\u20138931, 2021. Jiaming Sun, Zihao Wang, Siyu Zhang, Xingyi He, Hongcheng Zhao, Guofeng Zhang, and Xiaowei Zhou. Onepose: One-shot object pose estimation without cad models. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pp. 6825\u20136834, 2022. Jonathan Tremblay, Thang To, Balakumar Sundaralingam, Yu Xiang, Dieter Fox, and Stan Birchfield. Deep object pose estimation for semantic robotic grasping of household objects. arXiv preprint arXiv:1809.10790 , 2018. Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, \u0141ukasz Kaiser, and Illia Polosukhin. Attention is all you need. Advances in neural information processing systems , 30, 2017. Chen Wang, Danfei Xu, Yuke Zhu, Roberto Mart \u00b4\u0131n-Mart \u00b4\u0131n, Cewu Lu, Li Fei-Fei, and Silvio Savarese. Densefusion: 6d object pose estimation by iterative dense fusion. In Proceedings of the IEEE conference on computer vision and pattern recognition , pp. 3343\u20133352, 2019a. Gu Wang, Fabian Manhardt, Federico Tombari, and Xiangyang Ji. Gdr-net: Geometry-guided direct regression network for monocular 6d object pose estimation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pp. 16611\u201316621, 2021. He Wang, Srinath Sridhar, Jingwei Huang, Julien Valentin, Shuran Song, and Leonidas J Guibas. Normalized object coordinate space for category-level 6d object pose and size estimation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pp. 2642\u2013"
      },
      "FreeReg: Image-to-point cloud registration leveraging pretrained diffusion models and monocular depth estimators": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2310.03420",
        "ref_texts": "12 Published as a conference paper at ICLR 2024 Paul-Edouard Sarlin, Daniel DeTone, Tsun-Yi Yang, Armen Avetisyan, Julian Straub, Tomasz Malisiewicz, Samuel Rota Bul `o, Richard Newcombe, Peter Kontschieder, and Vasileios Balntas. Orienternet: Visual localization in 2d public maps with neural matching. In CVPR , 2023. Saurabh Saxena, Charles Herrmann, Junhwa Hur, Abhishek Kar, Mohammad Norouzi, Deqing Sun, and David J Fleet. The surprising effectiveness of diffusion models for optical flow and monocular depth estimation. arXiv preprint arXiv:2306.01923 , 2023a. Saurabh Saxena, Abhishek Kar, Mohammad Norouzi, and David J Fleet. Monocular depth estimation using diffusion models. arXiv preprint arXiv:2302.14816 , 2023b. Christoph Schuhmann, Romain Beaumont, Richard Vencu, Cade Gordon, Ross Wightman, Mehdi Cherti, Theo Coombes, Aarush Katta, Clayton Mullis, Mitchell Wortsman, et al. Laion-5b: An open large-scale dataset for training next generation image-text models. In NeurIPS , 2022. Jiaming Song, Chenlin Meng, and Stefano Ermon. Denoising diffusion implicit models. arXiv preprint arXiv:2010.02502 , 2020a. Yang Song and Stefano Ermon. Generative modeling by estimating gradients of the data distribution. InNeurIPS , 2019. Yang Song, Jascha Sohl-Dickstein, Diederik P Kingma, Abhishek Kumar, Stefano Ermon, and Ben Poole. Score-based generative modeling through stochastic differential equations. arXiv preprint arXiv:2011.13456 , 2020b. Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In CVPR , 2021. Yifan Sun, Changmao Cheng, Yuhan Zhang, Chi Zhang, Liang Zheng, Zhongdao Wang, and Yichen Wei. Circle loss: A unified perspective of pair similarity optimization. In CVPR , 2020. Haoru Tan, Sitong Wu, and Jimin Pi. Semantic diffusion network for semantic segmentation. In NeurIPS , 2022. Luming Tang, Menglin Jia, Qianqian Wang, Cheng Perng Phoo, and Bharath Hariharan. Emergent correspondence from image diffusion. arXiv preprint arXiv:2306.03881 , 2023. Narek Tumanyan, Michal Geyer, Shai Bagon, and Tali Dekel. Plug-and-play diffusion features for text-driven image-to-image translation. In CVPR , 2023. Jonas Uhrig, Nick Schneider, Lukas Schneider, Uwe Franke, Thomas Brox, and Andreas Geiger. Sparsity invariant cnns. In 3DV, 2017. Bing Wang, Changhao Chen, Zhaopeng Cui, Jie Qin, Chris Xiaoxuan Lu, Zhengdi Yu, Peijun Zhao, Zhen Dong, Fan Zhu, Niki Trigoni, et al. P2-net: Joint description and detection of local features for pixel and point matching. In ICCV , 2021. Guangming Wang, Yu Zheng, Yanfeng Guo, Zhe Liu, Yixiang Zhu, Wolfram Burgard, and Hesheng Wang. End-to-end 2d-3d registration between image and lidar point cloud for vehicle localization. arXiv preprint arXiv:2306.11346 , 2023a. Haiping Wang, Yuan Liu, Zhen Dong, and Wenping Wang. You only hypothesize once: Point cloud registration with rotation-equivariant descriptors. In ACM MM , 2022a. Haiping Wang, Yuan Liu, Zhen Dong, Yulan Guo, Yu-Shen Liu, Wenping Wang, and Bisheng Yang. Robust multiview point cloud registration with reliable pose graph initialization and history reweighting. In CVPR , 2023b. Haiping Wang, Yuan Liu, Qingyong Hu, Bing Wang, Jianguo Chen, Zhen Dong, Yulan Guo, Wenping Wang, and Bisheng Yang. Roreg: Pairwise point cloud registration with oriented descriptors and local rotations. IEEE TPAMI , 2023c. Yuan Wang, Yuhao Li, Yiping Chen, Mingjun Peng, Haiting Li, Bisheng Yang, Chi Chen, and Zhen Dong. Automatic registration of point cloud and panoramic images in urban scenes based on pole matching. JAG, 115:103083, 2022b."
      },
      "Adaptive feature extraction method for capsule endoscopy images": {
        "authors": [
          "Dingchang Wu"
        ],
        "url": "https://link.springer.com/content/pdf/10.1186/s42492-023-00151-6.pdf",
        "ref_texts": ""
      },
      "D2s: Representing local descriptors and global scene coordinates for camera relocalization": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2307.15250",
        "ref_texts": ""
      },
      "icomma: Inverting 3d gaussians splatting for camera pose estimation via comparing and matching": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2312.09031",
        "ref_texts": "33. Sun, J., Shen, Z., Wang, Y., Bao, H., Zhou, X.: Loftr: Detector-free local feature matching with transformers. In: CVPR. pp. 8922\u20138931 (2021) 4, 7, 8, 12",
        "ref_ids": [
          "33"
        ]
      },
      "FocusFlow: Boosting Key-Points Optical Flow Estimation for Autonomous Driving": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2308.07104",
        "ref_texts": "[55] J. Sun, Z. Shen, Y . Wang, H. Bao, and X. Zhou, \u201cLoFTR: Detectorfree local feature matching with transformers,\u201d in 2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) , 2021, pp. 8922\u20138931.",
        "ref_ids": [
          "55"
        ]
      },
      "Affineglue: Joint matching and robust estimation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2307.15381",
        "ref_texts": "[88] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. LoFTR: Detector-free local feature matching with transformers. In Computer Vision and Pattern Recognition , pages 8922\u20138931, 2021. 1, 2, 6, 7, 8",
        "ref_ids": [
          "88"
        ]
      },
      "Lazy visual localization via motion averaging": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2307.09981",
        "ref_texts": "[69] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , pages 8922\u20138931, 2021. 2",
        "ref_ids": [
          "69"
        ]
      },
      "End2End multi-view feature matching with differentiable pose optimization": {
        "authors": [
          "Barbara Roessle",
          "Matthias Niessner"
        ],
        "url": "https://openaccess.thecvf.com/content/ICCV2023/papers/Roessle_End2End_Multi-View_Feature_Matching_with_Differentiable_Pose_Optimization_ICCV_2023_paper.pdf",
        "ref_texts": "[48] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. 2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) , pages 8918\u2013",
        "ref_ids": [
          "48"
        ]
      },
      "Structured epipolar matcher for local feature matching": {
        "authors": [
          "Jiahao Chang",
          "Jiahuan Yu",
          "Tianzhu Zhang"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2023W/IMW/papers/Chang_Structured_Epipolar_Matcher_for_Local_Feature_Matching_CVPRW_2023_paper.pdf"
      },
      "Simulation-Based Self-Supervised Line Extraction for LiDAR Odometry in Urban Road Scenes": {
        "authors": [
          "Peng Wang",
          "Ruqin Zhou",
          "Chenguang Dai",
          "Hanyun Wang",
          "Wanshou Jiang",
          "Yongsheng Zhang"
        ],
        "url": "https://www.mdpi.com/2072-4292/15/22/5322/pdf",
        "ref_texts": "16. Sun, J.; Shen, Z.; Wang, Y.; Bao, H.; Xiaowei, Z. LoFTR: Detector-Free Local Feature Matching with Transformers. In Proceedings of the 2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), Nashville, TN, USA, 20\u201325 June 2021; pp. 8922\u20138931. [CrossRef] Remote Sens. 2023 ,15, 5322 17 of 18",
        "ref_ids": [
          "16"
        ]
      },
      "A Novel Visual SLAM Based on Multiple Deep Neural Networks": {
        "authors": [
          "Bihong Zhu",
          "Aihua Yu",
          "Beiping Hou",
          "Gang Li",
          "Yong Zhang"
        ],
        "url": "https://www.mdpi.com/2076-3417/13/17/9630/pdf",
        "ref_texts": "30. Sun, J.; Shen, Z.; Wang, Y.; Bao, H.; Zhou, X. LoFTR: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, Nashville, TN, USA, 19\u201325 June 2021; pp. 8922\u20138931.",
        "ref_ids": [
          "30"
        ]
      },
      "DGC-GNN: Descriptor-free Geometric-Color Graph Neural Network for 2D-3D Matching": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2306.12547",
        "ref_texts": "[49] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. LoFTR: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , 2021. 3, 4, 12",
        "ref_ids": [
          "49"
        ]
      },
      "CFI2P: Coarse-to-Fine Cross-Modal Correspondence Learning for Image-to-Point Cloud Registration": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2307.07142"
      },
      "ADU-Depth: Attention-based Distillation with Uncertainty Modeling for Depth Estimation": {
        "authors": [],
        "url": "https://proceedings.mlr.press/v229/wu23c/wu23c.pdf",
        "ref_texts": ""
      },
      "PointCNT: A One-Stage Point Cloud Registration Approach Based on Complex Network Theory": {
        "authors": [
          "Xin Wu",
          "Xiaolong Wei",
          "Haojun Xu",
          "Caizhi Li",
          "Yuanhan Hou",
          "Yizhen Yin",
          "Weifeng He"
        ],
        "url": "https://www.mdpi.com/2072-4292/15/14/3545/pdf",
        "ref_texts": "45. Sun, J.; Shen, Z.; Wang, Y.; Bao, H.; Zhou, X. LoFTR: Detector-Free Local Feature Matching with Transformers. In Proceedings of the 2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), Nashville, TN, USA, 20\u201325 June 2021; pp. 8918\u20138927. [CrossRef]",
        "ref_ids": [
          "45"
        ]
      },
      "LoCUS: Learning Multiscale 3D-consistent Features from Posed Images": {
        "authors": [
          "Dominik A. Kloepfer",
          "Dylan Campbell",
          "Joao F. Henriques"
        ],
        "url": "http://openaccess.thecvf.com/content/ICCV2023/papers/Kloepfer_LoCUS_Learning_Multiscale_3D-consistent_Features_from_Posed_Images_ICCV_2023_paper.pdf",
        "ref_texts": "[39] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In Proc. CVPR , pages 8922\u20138931, 2021.",
        "ref_ids": [
          "39"
        ]
      },
      "COLMAP-SLAM: A framework for visual odometry": {
        "authors": [],
        "url": "https://isprs-archives.copernicus.org/articles/XLVIII-1-W1-2023/317/2023/isprs-archives-XLVIII-1-W1-2023-317-2023.pdf",
        "ref_texts": "[tutorial]. IEEE robotics & automation magazine , 18(4), pp.80 92. Schonberger, J.L. and Frahm, J.M., 2016. Structure -from -motion revisited. Proc. CVPR , pp. 4104 -4113. Singandhupe, A. and La, H.M., 2019, February. A review of slam techniques and security in autonomous driving. Proc. IEEE IRC, pp. 602 -607. Sumikura, S., Shibuya, M. and Sakurada, K., 2019, October. OpenVSLAM: A versatile visual SLAM framework. Proc. 27th ACM International Conference on Multimedia , pp. 2292 -2295. Sun, J., Shen, Z., Wang, Y., Bao, H. and Zhou, X., 2021. LoFTR: Detector -free local feature matching with transformers. Proc. CVPR, pp. 8922 -8931. Verdie, Y., Yi, K., Fua, P. and Lepetit, V., 2015. Tilde: A temporally invariant learned detector. Proc. CVPR , pp. 5279 5288. Younes, G., Asmar, D., Shammas, E. and Zelek, J., 2017. Keyframe -based monocular SLAM: design, survey, and future directions. Robotics and Autonomous Systems , 98, pp.67 -88. Zhao, X., Wu, X., Miao, J., Chen, W., Chen, P.C. and Li, Z., ",
        "ref_ids": [
          "tutorial"
        ]
      },
      "Tracking growth and decay of plant roots in minirhizotron images": {
        "authors": [
          "Alexander Gillert",
          "Bo Peters",
          "Uwe Freiherr",
          "Jurgen Kreyling",
          "Gesche Blume"
        ],
        "url": "https://openaccess.thecvf.com/content/WACV2023/papers/Gillert_Tracking_Growth_and_Decay_of_Plant_Roots_in_Minirhizotron_Images_WACV_2023_paper.pdf",
        "ref_texts": "[17] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. 2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) , pages 8918\u2013",
        "ref_ids": [
          "17"
        ]
      },
      "Flowformer: A transformer architecture and its masked cost volume autoencoding for optical flow": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2306.05442",
        "ref_texts": "[54] J. Sun, Z. Shen, Y. Wang, H. Bao, and X. Zhou, \u201cLoftr: Detectorfree local feature matching with transformers,\u201d in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , 2021, pp. 8922\u20138931.",
        "ref_ids": [
          "54"
        ]
      },
      "Deep Homography Prediction for Endoscopic Camera Motion Imitation Learning": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2307.12792",
        "ref_texts": "24. Sun, J., Shen, Z., Wang, Y., Bao, H., Zhou, X.: Loftr: Detector-free local feature matching with transformers. In: Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. pp. 8922\u20138931 (2021)",
        "ref_ids": [
          "24"
        ]
      },
      "E3CM: Epipolar-constrained cascade correspondence matching": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2308.16555"
      },
      "Unifying Correspondence, Pose and NeRF for Pose-Free Novel View Synthesis from Stereo Pairs": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2312.07246",
        "ref_texts": "[54] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , pages 8922\u20138931, 2021. 3",
        "ref_ids": [
          "54"
        ]
      },
      "Resmatch: Residual attention learning for local feature matching": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2307.05180"
      },
      "Fusing Visual Appearance and Geometry for Multi-modality 6DoF Object Tracking": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2302.11458",
        "ref_texts": "[41] J. Sun, Z. Shen, Y . Wang, H. Bao, and X. Zhou, \u201cLoFTR: Detectorfree local feature matching with transformers,\u201d in IEEE/CVF Conf. Comput. Vis. Pattern Recog. , 2021, pp. 8922\u20138931.",
        "ref_ids": [
          "41"
        ]
      },
      "Tkwinformer: Top k window attention in vision transformers for feature matching": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2308.15144",
        "ref_texts": "[16] J. Sun, Z. Shen, Y . Wang, H. Bao, and X. Zhou, \u201cLoftr: Detector-free local feature matching with transformers,\u201d in IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2021, virtual, June 19-25, 2021 . Computer Vision Foundation / IEEE, 2021, pp.",
        "ref_ids": [
          "16"
        ]
      },
      "Render-and-compare: Cross-view 6-DoF localization from noisy prior": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2302.06287",
        "ref_texts": "[4]J. Sun, Z. Shen, Y . Wang, H. Bao, and X. Zhou, \u201cLoftr: Detector-free local feature matching with transformers,\u201d in Proc. IEEE Conferenceon Computer Vision and Pattern Recognition(CVPR2021) , virtual, June 2021, pp. 8922\u20138931.",
        "ref_ids": [
          "4"
        ]
      },
      "SRTPN: Scale and Rotation Transform Prediction Net for Multimodal Remote Sensing Image Registration": {
        "authors": [
          "Xiangzeng Liu",
          "Xueling Xu",
          "Xiaodong Zhang",
          "Qiguang Miao",
          "Lei Wang",
          "Liang Chang",
          "Ruyi Liu"
        ],
        "url": "https://www.mdpi.com/2072-4292/15/14/3469/pdf",
        "ref_texts": "16. Sun, J.; Shen, Z.; Wang, Y.; Bao, H.; Zhou, X. LoFTR: Detector-Free Local Feature Matching with Transformers. In Proceedings of the 2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), Online, 19\u201325 June 2021; pp. 8922\u20138931.",
        "ref_ids": [
          "16"
        ]
      },
      "ImTooth: Neural Implicit Tooth for Dental Augmented Reality": {
        "authors": [
          "Hai Li",
          "Hongjia Zhai",
          "Xingrui Yang",
          "Zhirong Wu",
          "Yihao Zheng",
          "Haofan Wang",
          "Jianchao Wu",
          "Hujun Bao",
          "Guofeng Zhang"
        ],
        "url": "http://www.cad.zju.edu.cn/home/gfzhang/papers/VR-TVCG-2023-ImTooth/ImTooth.pdf",
        "ref_texts": "[49] J. Shotton, B. Glocker, C. Zach, S. Izadi, A. Criminisi, and A. W. Fitzgibbon. Scene coordinate regression forests for camera relocalization in RGB-D images. In IEEE Conference on Computer Vision and Pattern Recognition, pp. 2930\u20132937, 2013.[50] J. Sun, Z. Shen, Y . Wang, H. Bao, and X. Zhou. LoFTR: Detector-free local feature matching with transformers. In IEEE Conference on Computer Vision and Pattern Recognition, pp. 8922\u20138931, 2021.",
        "ref_ids": [
          "49",
          "50"
        ]
      },
      "Learning feature matching via matchable keypoint-assisted graph neural network": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2307.01447",
        "ref_texts": "[39] J. Sun, Z. Shen, Y . Wang, H. Bao, and X. Zhou, \u201cLoftr: Detectorfree local feature matching with transformers,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , 2021, pp. 8922\u20138931.",
        "ref_ids": [
          "39"
        ]
      },
      "Multi-Modal Image Registration Based on Phase Exponent Differences of the Gaussian Pyramid": {
        "authors": [
          "Xiaohu Yan",
          "Yihang Cao",
          "Yijun Yang",
          "Yongxiang Yao"
        ],
        "url": "https://www.mdpi.com/2072-4292/15/24/5764/pdf",
        "ref_texts": "30. Sun, J.; Shen, Z.; Wang, Y.; Bao, H.; Zhou, X. LoFTR: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, Nashville, TN, USA, 20\u201325 June 2021; pp. 8922\u20138931.",
        "ref_ids": [
          "30"
        ]
      },
      "Searching from area to point: A hierarchical framework for semantic-geometric combined feature matching": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2305.00194",
        "ref_texts": "[10] J. Sun, Z. Shen, Y . Wang, H. Bao, and X. Zhou, \u201cLoFTR: Detector-free local feature matching with transformers,\u201d CVPR , 2021.",
        "ref_ids": [
          "10"
        ]
      },
      "A deep learning-based visual map generation for mobile robot navigation": {
        "authors": [],
        "url": "https://www.mdpi.com/2673-4117/4/2/92/pdf",
        "ref_texts": "20. Sun, J.; Shen, Z.; Wang, Y.; Bao, H.; Zhou, X. LoFTR: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, Nashville, TN, USA, 15\u201320 June 2021; pp. 8922\u20138931.",
        "ref_ids": [
          "20"
        ]
      },
      "Guided Local Feature Matching with Transformer": {
        "authors": [
          "Siliang Du",
          "Yilin Xiao",
          "Jingwei Huang",
          "Mingwei Sun",
          "Mingzhong Liu"
        ],
        "url": "https://www.mdpi.com/2072-4292/15/16/3989/pdf",
        "ref_texts": "15. Sun, J.; Shen, Z.; Wang, Y.; Bao, H.; Zhou, X. LoFTR: Detector-Free Local Feature Matching With Transformers. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), Virtual Conference, 19\u201325 June 2021; pp. 8922\u20138931.",
        "ref_ids": [
          "15"
        ]
      },
      "RGM: A Robust Generalist Matching Model": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2310.11755",
        "ref_texts": "37. Sun, J., Shen, Z., Wang, Y., Bao, H., Zhou, X.: LoFTR: Detector-free local feature matching with transformers. In: Proc. IEEE Conf. Comp. Vis. Patt. Recogn. pp.",
        "ref_ids": [
          "37"
        ]
      },
      "GMIW-Pose: Camera Pose Estimation via Global Matching and Iterative Weighted Eight-Point Algorithm": {
        "authors": [
          "Fan Chen",
          "Yuting Wu",
          "Tianjian Liao",
          "Huiquan Zeng",
          "Sujian Ouyang",
          "Jiansheng Guan"
        ],
        "url": "https://www.mdpi.com/2079-9292/12/22/4689/pdf",
        "ref_texts": "7. Sun, J.; Shen, Z.; Wang, Y.; Bao, H.; Zhou, X. LoFTR: Detector-Free Local Feature Matching with Transformers. In Proceedings of the 2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), Nashville, TN, USA, 20\u201325 June 2021; pp. 8918\u20138927.",
        "ref_ids": [
          "7"
        ]
      },
      "Compensation Model of GF-7 Panchromatic and Multispectral Image Registration Error": {
        "authors": [],
        "url": "http://ch.whu.edu.cn/en/article/pdf/preview/10.13203/j.whugis20220714.pdf",
        "ref_texts": "[21] Sun J M , Shen Z H , Wang Y A , et al . LoFTR : Detector -Free Local Feature Matching with Trans \u2011 formers [C]//IEEE/CVF Conference on Computer Vision and Pattern Recognition ,Nashville ,USA ,",
        "ref_ids": [
          "21",
          "C"
        ]
      },
      "Breaking modality disparity: Harmonized representation for infrared and visible image registration": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2304.05646",
        "ref_texts": "[33] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 8922\u20138931, 2021.",
        "ref_ids": [
          "33"
        ]
      },
      "Residual Learning for Image Point Descriptors": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2312.15471",
        "ref_texts": "[33] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , pages 8922\u20138931, 2021.",
        "ref_ids": [
          "33"
        ]
      },
      "A Spatial Information Extraction Method Based on Multi-Modal Social Media Data: A Case Study on Urban Inundation": {
        "authors": [
          "Yilong Wu",
          "Yingjie Chen",
          "Rongyu Zhang",
          "Zhenfei Cui",
          "Xinyi Liu",
          "Jiayi Zhang",
          "Meizhen Wang",
          "Yong Wu"
        ],
        "url": "https://www.mdpi.com/2220-9964/12/9/368/pdf",
        "ref_texts": "32. Sun, J.; Shen, Z.; Wang, Y.; Bao, H.; Zhou, X. LoFTR: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, Nashville, TN, USA, 20\u201325 June 2021; pp. 8922\u20138931.",
        "ref_ids": [
          "32"
        ]
      },
      "FMRT: Learning Accurate Feature Matching with Reconciliatory Transformer": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2310.13605",
        "ref_texts": "[36] J. Sun, Z. Shen, Y . Wang, H. Bao, and X. Zhou, \u201cLoftr: Detectorfree local feature matching with transformers,\u201d in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , 2021, pp. 8922\u20138931.",
        "ref_ids": [
          "36"
        ]
      },
      "Learning-based relational object matching across views": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2305.02398",
        "ref_texts": "[32] J. Sun, Z. Shen, Y . Wang, H. Bao, and X. Zhou, \u201cLoFTR: Detector-free local feature matching with transformers,\u201d in IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) , 2021.",
        "ref_ids": [
          "32"
        ]
      },
      "UbiPose: Towards Ubiquitous Outdoor AR Pose Tracking using Aerial Meshes": {
        "authors": [
          "Weiwu Pang",
          "Chunyu Xia",
          "Branden Leong",
          "Fawad Ahmad",
          "Jeongyeup Paek",
          "Ramesh Govindan"
        ],
        "url": "https://dl.acm.org/doi/pdf/10.1145/3570361.3613263",
        "ref_texts": "[81] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. 2021. LoFTR: Detector-Free Local Feature Matching with Transformers. In IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). IEEE Computer Society, Los Alamitos, CA, USA,8918\u20138927. https://doi.org/10.1109/CVPR46437.2021.00881",
        "ref_ids": [
          "81"
        ]
      },
      "Feature-based Visual Odometry for Bronchoscopy: A Dataset and Benchmark": {
        "authors": [
          "Jianning Deng",
          "Peize Li",
          "Kev Dhaliwal",
          "Chris Xiaoxuan",
          "Mohsen Khadem"
        ],
        "url": "https://www.research.ed.ac.uk/files/368239029/Feature_based_Visual_Odometry_DENG_DOA21062023_AFV_CC_BY.pdf",
        "ref_texts": "[25] J. Sun, Z. Shen, Y . Wang, H. Bao, and X. Zhou, \u201cLoftr: Detectorfree local feature matching with transformers,\u201d in Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , 2021, pp. 8922\u20138931.",
        "ref_ids": [
          "25"
        ]
      },
      "Photomatch: An open-source tool for multi-view and multi-modal feature-based image matching": {
        "authors": [],
        "url": "https://www.mdpi.com/2076-3417/13/9/5467/pdf",
        "ref_texts": "38. Sun, J.; Shen, Z.; Wang, Y.; Bao, H.; Zhou, X. LoFTR: Detector-Free Local Feature Matching With Transformers. In Proceedings of the 2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), Nashville, TN, USA, 20\u201325 June 2021; pp.",
        "ref_ids": [
          "38"
        ]
      },
      "SASFF: A Video Synthesis Algorithm for Unstructured Array Cameras Based on Symmetric Auto-Encoding and Scale Feature Fusion": {
        "authors": [
          "Linliang Zhang",
          "Lianshan Yan",
          "Shuo Li",
          "Saifei Li"
        ],
        "url": "https://www.mdpi.com/1424-8220/24/1/5/pdf",
        "ref_texts": "41. Sun, J.; Shen, Z.; Wang, Y.; Bao, H.; Zhou, X. LoFTR: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, Nashville, TN, USA, 20\u201325 June 2021; pp. 8922\u20138931.",
        "ref_ids": [
          "41"
        ]
      },
      "Automatic Production of Deep Learning Benchmark Dataset for Affine-Invariant Feature Matching": {
        "authors": [
          "Guobiao Yao",
          "Jin Zhang",
          "Jianya Gong",
          "Fengxiang Jin"
        ],
        "url": "https://www.mdpi.com/2220-9964/12/2/33/pdf",
        "ref_texts": "23. Sun, J.; Shen, Z.; Wang, Y.; Bao, H.; Zhou, X. LoFTR: Detector-free local feature matching with transformers. arXiv 2021 , arXiv:2104.00680. [CrossRef]",
        "ref_ids": [
          "23"
        ]
      },
      "Simsc: A simple framework for semantic correspondence with temperature learning": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2305.02385",
        "ref_texts": "[38] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In CVPR , 2021. 2",
        "ref_ids": [
          "38"
        ]
      },
      "PanoPoint: Self-Supervised Feature Points Detection and Description for 360deg Panorama": {
        "authors": [
          "Hengzhi Zhang",
          "Hong Yi",
          "Haijing Jia",
          "Wei Wang",
          "Makoto Odamaki"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2023W/OmniCV/papers/Zhang_PanoPoint_Self-Supervised_Feature_Points_Detection_and_Description_for_360deg_Panorama_CVPRW_2023_paper.pdf",
        "ref_texts": "[47] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , pages 8922\u20138931, 2021. 7",
        "ref_ids": [
          "47"
        ]
      },
      "An Adaptive Remote Sensing Image-Matching Network Based on Cross Attention and Deformable Convolution": {
        "authors": [
          "Peiyan Chen",
          "Ying Fu",
          "Jinrong Hu",
          "Bing He",
          "Xi Wu",
          "Jiliu Zhou"
        ],
        "url": "https://www.mdpi.com/2079-9292/12/13/2889/pdf",
        "ref_texts": "23. Sun, J.; Shen, Z.; Wang, Y.; Bao, H.; Zhou, X. LoFTR: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, Montreal, QC, Canada, 11\u201317 October 2021; pp. 8922\u20138931.",
        "ref_ids": [
          "23"
        ]
      },
      "Scene-Aware Feature Matching": {
        "authors": [
          "Xiaoyong Lu",
          "Yaping Yan",
          "Tong Wei",
          "Songlin Du"
        ],
        "url": "https://openaccess.thecvf.com/content/ICCV2023/papers/Lu_Scene-Aware_Feature_Matching_ICCV_2023_paper.pdf",
        "ref_texts": "[30] J. Sun, Z. Shen, Y . Wang, H. Bao, and X. Zhou. LoFTR: Detector-Free Local Feature Matching With Transformers.InProceedings of the CVPR , pages 8922\u20138931, 2021.",
        "ref_ids": [
          "30"
        ]
      },
      "Local Consensus Enhanced Siamese Network with Reciprocal Loss for Two-view Correspondence Learning": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2308.03217",
        "ref_texts": "[18] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. 2021. LoFTR: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition . 8922\u20138931.",
        "ref_ids": [
          "18"
        ]
      },
      "G-MEMP: Gaze-Enhanced Multimodal Ego-Motion Prediction in Driving": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2312.08558",
        "ref_texts": "[41] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. LoFTR: Detector-free local feature matching with transformers. CVPR , 2021. 10",
        "ref_ids": [
          "41"
        ]
      },
      "Hwr200: New open access dataset of handwritten texts images in russian": {
        "authors": [
          "Potyashin I"
        ],
        "url": "https://www.dialog-21.ru/media/5925/potyashiniplusetal048.pdf",
        "ref_texts": "524. Denis Coquenet, Cl\u00e9ment Chatelain, and Thierry Paquet. 2023. Dan: a segmentation-free document attention network for handwritten document recognition. IEEE Transactions on Pattern Analysis and Machine Intelligence. Sharon Fogel, Hadar Averbuch-Elor, Sarel Cohen, Shai Mazor, and Roee Litman. 2020. Scrabblegan: Semisupervised varying length handwritten text generation. // The IEEE Conference on Computer Vision and Pattern Recognition (CVPR), June. Basilis Gatos, Georgios Louloudis, Tim Causer, Kris Grint, Ver\u00f3nica Romero, Joan Andreu S\u00e1nchez, Alejandro H. Toselli, and Enrique Vidal. 2014. Ground-truth production in the transcriptorium project. // 2014 11th IAPR International Workshop on Document Analysis Systems, P 237\u2013241. Idp-forms (2021). Available at: https://github.com/ai-forever/htr_datasets/tree/main/ IDP-forms. Jeff Johnson, Matthijs Douze, and Herv\u00e9 J\u00e9gou. 2017. Billion-scale similarity search with gpus. IEEE Transactions on Big Data, 7:535\u2013547. U.-V. Marti. 2002. The iam-database: an english sentence database for offline handwriting recognition. International Journal on Document Analysis and Recognition, 28(1):114\u2013133. Minesh Mathew, Dimosthenis Karatzas, R. Manmatha, and C. Jawahar. 2020. Docvqa: A dataset for vqa on document images. 07. Daniyar Nurseitov, Kairat Bostanbekov, Daniyar Kurmankhojayev, Anel Alimova, Abdelrahman Abdallah, and Rassul Tolegenov. 2021. Handwritten kazakh and russian (hkr) database for text recognition. Multimedia Tools and Applications, P 1\u201323. M. B. Potanin, Denis Dimitrov, A. Shonenkov, Vladimir Bataev, Denis Karachev, and Maxim Novopoltsev. 2021. Digital peter: New dataset, competition and handwriting recognition methods. The 6th International Workshop on Historical Document Imaging and Processing. School_notebooks_ru (2021). Available at: https://github.com/ai-forever/htr_datasets/tree/main/ school_notebooks. Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. 2021. LoFTR: Detector-free local feature matching with transformers. CVPR. Curtis Wigington, Chris Tensmeyer, Brian Davis, William Barrett, Brian Price, and Scott Cohen. 2018. Start, follow, read: End-to-end full-page handwriting recognition. // Computer Vision \u2013 ECCV 2018\", P 372\u2013388, Cham. Springer International Publishing. Stuart Wrigley. 2019. Avoiding \u2018de-plagiarism\u2019: Exploring the affordances of handwriting in the essay-writing process. Active Learning in Higher Education, 20(2):167\u2013179.Potyashin I., Kaprielova M., Chekhovich Y., Kildyakov A., Seil T., Finogeev E., Grabovoy A.",
        "ref_ids": [
          "524"
        ]
      },
      "Graph Self-Supervised Learning for Endoscopic Image Matching": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2306.11141",
        "ref_texts": "[48] J. Sun, Z. Shen, Y. Wang, H. Bao, X. Zhou, LoFTR: Detector-free local feature matching with transformers, CVPR.",
        "ref_ids": [
          "48"
        ]
      },
      "CoFiI2P: Coarse-to-fine correspondences for image-to-point cloud registration": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2309.14660",
        "ref_texts": "[10] J. Sun, Z. Shen, Y . Wang, H. Bao, and X. Zhou, \u201cLoftr: Detector-free local feature matching with transformers,\u201d in Proc. of the IEEE/CVF Conf. on Computer Vision and Pattern Recognition (CVPR) , 2021, pp.",
        "ref_ids": [
          "10"
        ]
      },
      "Context-PIPs: persistent independent particles demands spatial context features": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2306.02000",
        "ref_texts": "[36] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 8922\u20138931, 2021.",
        "ref_ids": [
          "36"
        ]
      },
      "Toward a navigation framework for fetoscopy": {
        "authors": [
          "Alessandro Casella"
        ],
        "url": "https://link.springer.com/content/pdf/10.1007/s11548-023-02974-3.pdf",
        "ref_texts": "20. Sun J, Shen Z, Wang Y , Bao H, Zhou X (2021) LoFTR: Detectorfree local feature matching with transformers. In: IEEE Conferenceon Computer Vision and Pattern Recognition (CVPR)",
        "ref_ids": [
          "20"
        ]
      },
      "Learning to Localize in Unseen Scenes with Relative Pose Regressors": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2303.02717",
        "ref_texts": "[40] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. LoFTR: Detector-free local feature matching with transformers. Proceedings of the IEEE/CVF",
        "ref_ids": [
          "40"
        ]
      },
      "EAR-Net: Pursuing End-to-End Absolute Rotations from Multi-View Images": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2310.10051",
        "ref_texts": "846. Sun, J., Shen, Z., Wang, Y., Bao, H., and Zhou, X. (2021). Loftr: Detector-free local feature matching with transformers. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 8922\u20138931. Tian, Y., Barroso-Laguna, A., Ng, T., Balntas, V., and Mikolajczyk, K. (2020). Hynet: Learning local descriptor with hybrid similarity measure and triplet loss. In Advances in Neural Information Processing Systems , volume 33, pages 7401\u20137412. Wang, Q., Zhang, J., Yang, K., Peng, K., and Stiefelhagen, R. (2022). Matchformer: Interleaving attention in transformers for feature matching. In Asian Conference on Computer Vision . Yang, L., Li, H., Rahim, J. A., Cui, Z., and Tan, P. (2021). End-to-end rotation averaging with multi-source propagation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 11774\u201311783. Yao, Y., Luo, Z., Li, S., Fang, T., and Quan, L.",
        "ref_ids": [
          "846"
        ]
      },
      "Local feature extraction from salient regions by feature map transformation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2301.10413",
        "ref_texts": "[38] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , pages 8922\u20138931, 2021.",
        "ref_ids": [
          "38"
        ]
      },
      "Perception Test 2023: A Summary of the First Challenge And Outcome": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2312.13090",
        "ref_texts": "2023-03-30-vicuna/ . D.Damen,H.Doughty,G.M.Farinella,A.Furnari, J. Ma, E. Kazakos, D. Moltisanti, J. Munro, T. Perrett, W. Price, and M. Wray. Rescaling egocentric vision: Collection, pipeline and challenges for EPIC-KITCHENS-100. International 8 Perception Test 2023: A Summary of the First Challenge And Outcome Journal of Computer Vision (IJCV) , 130:33\u201355, 2022. C. Doersch, A. Gupta, L. Markeeva, A. R. Continente, L. Smaira, Y. Aytar, J. Carreira, A. Zisserman, and Y. Yang. TAP-vid: A benchmark for tracking any point in a video. In Thirty-sixth Conference on Neural Information Processing Systems Datasets and Benchmarks Track, 2022. URL https://openreview. net/forum?id=Zmosb2KfzYd . C. Doersch, Y. Yang, M. Vecerik, D. Gokay, A. Gupta, Y. Aytar, J. Carreira, and A. Zisserman. Tapir: Tracking any point with per-frame initialization and temporal refinement. ICCV, 2023. A. Dosovitskiy, L. Beyer, A. Kolesnikov, D. Weissenborn, X. Zhai, T. Unterthiner, M. Dehghani, M. Minderer, G. Heigold, S. Gelly, J. Uszkoreit, and N. Houlsby. An image is worth 16x16 words: Transformers for image recognition at scale. ICLR, 2021. K.He, C.Zhang, S.Xie, Z.Li, andZ.Wang. Targetaware tracking with long-term context attention. arXiv preprint arXiv:2302.13840 , 2023. A. Kamath, M. Singh, Y. LeCun, I. Misra, G. Synnaeve, and N. Carion. Mdetr\u2013modulated detectionforend-to-endmulti-modalunderstanding. arXiv preprint arXiv:2104.12763 , 2021. K. Li, Y. Wang, Y. Li, Y. Wang, Y. He, L. Wang, and Y. Qiao. Unmasked teacher: Towards trainingefficient video foundation models, 2023. J. Luiten, A. Osep, P. Dendorfer, P. Torr, A. Geiger, L. Leal-Taix\u00e9, and B. Leibe. Hota: A higher order metric for evaluating multi-object tracking. International Journal of Computer Vision , pages 1\u201331, 2020. V. P\u0103tr\u0103ucean, L. Smaira, A. Gupta, A. R. Continente, L. Markeeva, D. Banarse, S. Koppula, J. Heyward, M. Malinowski, Y. Yang, C. Doersch, T. Matejovicova, Y. Sulsky, A. Miech, A. Frechette, H. Klimczak, R. Koster, J. Zhang, S. Winkler, Y. Aytar, S. Osindero, D. Damen, A. Zisserman, and J. Carreira. Perception test: A diagnostic bench-mark for multimodal video models. In Advances in Neural Information Processing Systems, 2023. URL https://openreview. net/forum?id=HYEGXFnPoq . R. Solovyev, W. Wang, and T. Gabruseva. Weightedboxesfusion: Ensemblingboxesfrom different object detection models. Image and Vision Computing , pages 1\u20136, 2021. J. Sun, Z. Shen, Y. Wang, H. Bao, and X. Zhou. LoFTR: Detector-free local feature matching with transformers. CVPR, 2021. Z. Wang, H. Zhao, Y.-L. Li, S. Wang, P. Torr, and L. Bertinetto. Do different tracking tasks require different appearance models? Advances in Neural Information Processing Systems , 34: 726\u2013738, 2021. A. Yang, A. Miech, J. Sivic, I. Laptev, and C. Schmid. Tubedetr: Spatio-temporal video grounding with transformers. In CVPR, 2022a. J. Yang, C. Li, X. Dai, and J. Gao. Focal modulation networks. Advances in Neural Information Processing Systems (NeurIPS) , 2022b. S. Yu, J. Cho, P. Yadav, and M. Bansal. Selfchained image-language model for video localization and question answering. arXiv preprint arXiv:2305.06988 , 2023. C. Zhang, J. Wu, and Y. Li. Actionformer: Localizing moments of actions with transformers. In European Conference on Computer Vision , 2022. H. Zhang, X. Li, and L. Bing. Video-llama: An instruction-tuned audio-visual language model for video understanding. arXiv preprint arXiv:2306.02858 , 2023. URL https:// arxiv.org/abs/2306.02858 ."
      },
      "Reuse your features: unifying retrieval and feature-metric alignment": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2204.06292",
        "ref_texts": "[28] J. Sun, Z. Shen, Y . Wang, H. Bao, and X. Zhou, \u201cLoFTR: Detector-free local feature matching with transformers,\u201d in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , 2021, pp. 8922\u20138931.",
        "ref_ids": [
          "28"
        ]
      },
      "A Visual Positioning Method of UAV in a Large-Scale Outdoor Environment": {
        "authors": [
          "Chenhao Zhao",
          "Dewei Wu",
          "Jing He",
          "Chuanjin Dai"
        ],
        "url": "https://www.mdpi.com/1424-8220/23/15/6941/pdf",
        "ref_texts": "25. Sun, J.; Shen, Z.; Wang, Y.; Bao, H.; Zhou, X. LoFTR: Detector-Free Local Feature Matching with Transformers. arXiv 2021 , arXiv:2104.00680.",
        "ref_ids": [
          "25"
        ]
      },
      "Bi-Resolution Hash Encoding in Neural Radiance Fields: A Method for Accelerated Pose Optimization and Enhanced Reconstruction Efficiency": {
        "authors": [
          "Zixuan Guo",
          "Qing Xie",
          "Song Liu",
          "Yao Xie"
        ],
        "url": "https://www.mdpi.com/2076-3417/13/24/13333/pdf",
        "ref_texts": "14. Sun, J.; Shen, Z.; Wang, Y.; Bao, H.; Zhou, X. LoFTR: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, Nashville, TN, USA, 20\u201325 June 2021; pp. 8922\u20138931.",
        "ref_ids": [
          "14"
        ]
      },
      "BusReF: Infrared-Visible images registration and fusion focus on reconstructible area using one set of features": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2401.00285",
        "ref_texts": "[29] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) , pages 8922\u20138931, 2021. 2",
        "ref_ids": [
          "29"
        ]
      },
      "Vehicle Offline Localization Based on Computer Vision: An Approach Based on Image Matching Retrieval Algorithms and Implementation": {
        "authors": [],
        "url": "https://fruct.org/publications/volume-33/fruct33/files/Kas.pdf",
        "ref_texts": "[11] J. Sun, Z. Shen, Y . Wang, H. Bao and X. Zhou, \u201dLoFTR: Detector-Free Local Feature Matching with Transformers,\u201d 2021 IEEE/CVF Confer-ence on Computer Vision and Pattern Recognition (CVPR), Nashville,TN, USA, 2021, pp. 8918-8927, doi: 10.1109/CVPR46437.2021.00881.",
        "ref_ids": [
          "11"
        ]
      },
      "Real-Time 2D Orthomosaic Mapping from Drone-Captured Images Using Feature-Based Sequential Image Registration": {
        "authors": [],
        "url": "https://www.preprints.org/manuscript/202312.0190/download/final_file",
        "ref_texts": "40. Sun, J.; Shen, Z.; Wang, Y.; Bao, H.; Zhou, X. LoFTR: Detector-free local feature matching with transformers. In Proceedings of the Proceedings of the IEEE/CVF conference on comp uter vision and pattern recognition , 2021 ; pp. ",
        "ref_ids": [
          "40"
        ]
      },
      "Distributed Global Structure-from-Motion with a Deep Front-End": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2311.18801",
        "ref_texts": "[64] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. LoFTR: Detector-free local feature matching with transformers. In CVPR , pages 8922\u20138931, 2021. 1, 4, 5, 7, 8",
        "ref_ids": [
          "64"
        ]
      },
      "Multi-Modal Scene Matching Location Algorithm Based on M2Det.": {
        "authors": [],
        "url": "https://cdn.techscience.cn/files/cmc/2023/TSP_CMC-77-1/TSP_CMC_39582/TSP_CMC_39582.pdf",
        "ref_texts": "[41] J. Sun, Z. Shen and Y . Wang, \u201cLoFTR: Detector-free local feature matching with transformers,\u201d in Proc. of IEEE Conf. on Computer Vision and Pattern Recognition (CVPR) , pp. 8918\u20138927, 2021. CMC, 2023, vol.77, no.1 1051",
        "ref_ids": [
          "41"
        ]
      },
      "Large-scale environment mapping and immersive human-robot interaction for agricultural mobile robot teleoperation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2308.07231",
        "ref_texts": "[32] Sun, J., Shen, Z., Wang, Y ., Bao, H., & Zhou, X. (2021). LoFTR: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition (pp. 8922-8931).",
        "ref_ids": [
          "32"
        ]
      },
      "UAV image matching of mountainous terrain using the LoFTR deep learning model": {
        "authors": [],
        "url": "https://www.frontiersin.org/articles/10.3389/feart.2023.1203078/pdf",
        "ref_texts": "2020.00499 Sun, J. M., Shen, Z. H., Wang, Y. A., Bao, H. J., and Zhou, X. W. (2021). \u201cLoFTR: detector-free local feature matching with transformers, \u201dinIEEE/CVF conference on computer vision and pattern recognition , 8918 \u20138927. doi:10.1109/CVPR46437.2021."
      },
      "Match and Locate: low-frequency monocular odometry based on deep feature matching": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2311.10034",
        "ref_texts": "[Sunet al. , 2021 ]Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , pages 8922\u20138931, 2021.",
        "ref_ids": [
          "Sunet al\\. , 2021 "
        ]
      },
      "Identifying Historic Buildings over Time through Image Matching": {
        "authors": [
          "Kyriaki A. Tychola",
          "Stamatis Chatzistamatis",
          "Eleni Vrochidou",
          "George E. Tsekouras",
          "George A. Papakostas"
        ],
        "url": "https://www.mdpi.com/2227-7080/11/1/32/pdf",
        "ref_texts": "60. Sun, J.; Shen, Z.; Wang, Y.; Bao, H.; Zhou, X. LoFTR: Detector-Free Local Feature Matching with Transformers. Comput. Vis. Pattern Recognit. 2021 , 8922\u20138931. [CrossRef]",
        "ref_ids": [
          "60"
        ]
      },
      "Learning by Aligning 2D Skeleton Sequences and Multi-Modality Fusion": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2305.19480",
        "ref_texts": "70. Sun, J., Shen, Z., Wang, Y ., Bao, H., Zhou, X.: Loftr: Detector-free local feature matching with transformers. In: Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. pp. 8922\u20138931 (2021)",
        "ref_ids": [
          "70"
        ]
      },
      "ADFactory: Automated Data Factory for Optical Flow Tasks": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2311.04246",
        "ref_texts": "[32] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition (CVPR) , pages 8922\u20138931, 2021. 2",
        "ref_ids": [
          "32"
        ]
      },
      "Coloring Deep CNN Layers with Activation Hue Loss": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2310.03911",
        "ref_texts": "12 Karen Simonyan and Andrew Zisserman. Very deep convolutional networks for large-scale image recognition. arXiv preprint arXiv:1409.1556 , 2014. Jake Snell, Kevin Swersky, and Richard Zemel. Prototypical networks for few-shot learning. Advances in neural information processing systems , 30, 2017. Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. arXiv preprint arXiv:2104.00680 , 2021. Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jon Shlens, and Zbigniew Wojna. Rethinking the inception architecture for computer vision. In Proceedings of the IEEE conference on computer vision and pattern recognition , pp. 2818\u20132826, 2016. Mingxing Tan and Quoc V . Le. Efficientnet: Rethinking model scaling for convolutional neural networks. CoRR , abs/1905.11946, 2019. URL http://arxiv.org/abs/1905.11946 . Yehui Tang, Kai Han, Jianyuan Guo, Chang Xu, Yanxi Li, Chao Xu, and Yunhe Wang. An image patch is a wave: Phase-aware vision mlp. arXiv preprint arXiv:2111.12294 , 2021. Giorgos Tolias, Ronan Sicre, and Herv \u00b4e J\u00b4egou. Particular object retrieval with integral max-pooling of cnn activations. arXiv preprint arXiv:1511.05879 , 2015. David C. Van Essen, Stephen M. Smith, Deanna M. Barch, Timothy E.J. Behrens, Essa Yacoub, and Kamil Ugurbil. The wu-minn human connectome project: An overview. NeuroImage , 80:62\u201379, 2013. ISSN 1053-8119. doi: https://doi.org/10.1016/j.neuroimage.2013.05.041. Mapping the Connectome. Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Lukasz Kaiser, and Illia Polosukhin. Attention is all you need. arXiv preprint arXiv:1706.03762 , 2017. Jian Wang, Feng Zhou, Shilei Wen, Xiao Liu, and Yuanqing Lin. Deep metric learning with angular loss. In Proceedings of the IEEE international conference on computer vision , pp. 2593\u20132601, 2017. Xiaolong Wang, Ross Girshick, Abhinav Gupta, and Kaiming He. Non-local neural networks. In Proceedings of the IEEE conference on computer vision and pattern recognition , pp. 7794\u20137803, 2018. Yan Wang, Wei-Lun Chao, Kilian Q. Weinberger, and Laurens van der Maaten. Simpleshot: Revisiting nearest-neighbor classification for few-shot learning. CoRR , abs/1911.04623, 2019. URL http://arxiv.org/abs/1911.04623 . Peter Welinder, Steve Branson, Takeshi Mita, Catherine Wah, Florian Schroff, Serge Belongie, and Pietro Perona. Caltech-ucsd birds 200. Technical Report CNS-TR-201, Caltech, 2010. URL /se3/wp-content/uploads/2014/09/WelinderEtal10_CUB-200. pdf,http://www.vision.caltech.edu/visipedia/CUB-200.html . Yandong Wen, Kaipeng Zhang, Zhifeng Li, and Yu Qiao. A discriminative feature learning approach for deep face recognition. In European conference on computer vision , pp. 499\u2013515. Springer, 2016. Sanghyun Woo, Jongchan Park, Joon-Young Lee, and In So Kweon. Cbam: Convolutional block attention module. In Proceedings of the European conference on computer vision (ECCV) , pp."
      },
      "Keypoint matching via random network consensus": {
        "authors": [],
        "url": "https://openreview.net/pdf?id=WhbWzFg8cZ",
        "ref_texts": "12 Under review as a conference paper at ICLR 2023 Torsten Sattler, Bastian Leibe, and Leif Kobbelt. Efficient & effective prioritized matching for largescale image-based localization. IEEE transactions on pattern analysis and machine intelligence , 39(9):1744\u20131756, 2016. Torsten Sattler, Will Maddern, Carl Toft, Akihiko Torii, Lars Hammarstrand, Erik Stenborg, Daniel Safari, Masatoshi Okutomi, Marc Pollefeys, Josef Sivic, et al. Benchmarking 6dof outdoor visual localization in changing conditions. In Proceedings of the IEEE conference on computer vision and pattern recognition , pp. 8601\u20138610, 2018. Nikolay Savinov, Lubor Ladicky, and Marc Pollefeys. Matching neural paths: transfer from recognition to correspondence search. Advances in Neural Information Processing Systems , 30, 2017a. Nikolay Savinov, Akihito Seki, Lubor Ladicky, Torsten Sattler, and Marc Pollefeys. Quad-networks: unsupervised learning to rank for interest point detection. In Proceedings of the IEEE conference on computer vision and pattern recognition , pp. 1822\u20131830, 2017b. Johannes Lutz Sch \u00a8onberger and Jan-Michael Frahm. Structure-from-motion revisited. In Conference on Computer Vision and Pattern Recognition (CVPR) , 2016. Jianbo Shi et al. Good features to track. In 1994 Proceedings of IEEE conference on computer vision and pattern recognition , pp. 593\u2013600. IEEE, 1994. Jamie Shotton, Ben Glocker, Christopher Zach, Shahram Izadi, Antonio Criminisi, and Andrew Fitzgibbon. Scene coordinate regression forests for camera relocalization in rgb-d images. In Proceedings of the IEEE conference on computer vision and pattern recognition , pp. 2930\u20132937, 2013. Edgar Simo-Serra, Eduard Trulls, Luis Ferraz, Iasonas Kokkinos, Pascal Fua, and Francesc MorenoNoguer. Discriminative learning of deep convolutional feature point descriptors. In Proceedings of the IEEE international conference on computer vision , pp. 118\u2013126, 2015. Karen Simonyan and Andrew Zisserman. Very deep convolutional networks for large-scale image recognition. arXiv preprint arXiv:1409.1556 , 2014. Karen Simonyan, Andrea Vedaldi, and Andrew Zisserman. Learning local feature descriptors using convex optimisation. IEEE Transactions on Pattern Analysis and Machine Intelligence , 36(8): 1573\u20131585, 2014. Noah Snavely, Steven M Seitz, and Richard Szeliski. Photo tourism: exploring photo collections in 3d. In ACM siggraph 2006 papers , pp. 835\u2013846. 2006. Henrik Stewenius, Christopher Engels, and David Nist \u00b4er. Recent developments on direct relative orientation. ISPRS Journal of Photogrammetry and Remote Sensing , 60(4):284\u2013294, 2006. Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , pp. 8922\u20138931, 2021. Supasorn Suwajanakorn, Noah Snavely, Jonathan J Tompson, and Mohammad Norouzi. Discovery of latent 3d keypoints via end-to-end geometric reasoning. Advances in neural information processing systems , 31, 2018. Hajime Taira, Masatoshi Okutomi, Torsten Sattler, Mircea Cimpoi, Marc Pollefeys, Josef Sivic, Tomas Pajdla, and Akihiko Torii. Inloc: Indoor visual localization with dense matching and view synthesis. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pp. 7199\u20137209, 2018. Shitao Tang, Chengzhou Tang, Rui Huang, Siyu Zhu, and Ping Tan. Learning camera localization via dense scene matching. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pp. 1831\u20131841, 2021. Micha\u0142 Tyszkiewicz, Pascal Fua, and Eduard Trulls. Disk: Learning local features with policy gradient. Advances in Neural Information Processing Systems , 33:14254\u201314265, 2020."
      },
      "\u9ad8\u5206\u4e03\u53f7\u536b\u661f\u5f71\u50cf\u878d\u5408\u4e2d\u7684\u5168\u8272-\u591a\u5149\u8c31\u914d\u51c6\u8bef\u5dee\u8865\u507f\u6a21\u578b": {
        "authors": [],
        "url": "http://ch.whu.edu.cn/cn/article/pdf/preview/10.13203/j.whugis20220714.pdf",
        "ref_texts": "[21] Sun J M , Shen Z H , Wang Y A , et al . LoFTR : Detector -Free Local Feature Matching with Trans \u2011 formers [C]//IEEE/CVF Conference on Computer Vision and Pattern Recognition ,Nashville ,USA ,",
        "ref_ids": [
          "21",
          "C"
        ]
      },
      "Closed-loop feedback registration for consecutive images of moving flexible targets": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2110.10772",
        "ref_texts": ""
      },
      "\u57fa\u4e8e\u6539\u8fdb\u7684\u6761\u4ef6\u751f\u6210\u5bf9\u6297\u7f51\u7edc\u7684\u53ef\u89c1\u5149\u7ea2\u5916\u56fe\u50cf\u8f6c\u6362\u7b97\u6cd5": {
        "authors": [],
        "url": "https://www.researching.cn/ArticlePdf/m00009/2023/52/4/0410003.pdf",
        "ref_texts": "[25] SUN J , SHEN Z , WANG Y , et al . LoFTR : detector -free local feature matching with transformers [C]. Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , 2021 : 8922-8931 . Visible-to-infrared Image Translation Based on an Improved Conditional Generative Adversarial Nets MA Decao1, XIAN Yong1, SU Juan2, LI Shaopeng1, LI Bing1",
        "ref_ids": [
          "25",
          "C"
        ]
      },
      "DRKF: Distilled Rotated Kernel Fusion for Efficient Rotation Invariant Descriptors in Local Feature Matching": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2209.10907",
        "ref_texts": "[22] J. Sun, Z. Shen, Y . Wang, H. Bao, and X. Zhou, \u201cLoftr: Detectorfree local feature matching with transformers,\u201d in Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR) , pp. 8922\u20138931, 2021.",
        "ref_ids": [
          "22"
        ]
      },
      "A detector-oblivious multi-arm network for keypoint matching": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2104.00947",
        "ref_texts": "[38] J. Sun, Z. Shen, Y . Wang, H. Bao, and X. Zhou, \u201cLoftr: Detector-free local feature matching with transformers,\u201d in CVPR , 2021.",
        "ref_ids": [
          "38"
        ]
      },
      "FindView: Precise Target View Localization Task for Look Around Agents": {
        "authors": [
          "Haruya Ishikawa",
          "Yoshimitsu Aoki"
        ],
        "url": "https://arxiv.org/pdf/2303.09054",
        "ref_texts": "(2):91\u2013110, 2004. 2, 7, 14, 15 Ethan Rublee, Vincent Rabaud, Kurt Konolige, and Gary Bradski. Orb: An efficient alternative to sift or surf. In 2011 International conference on computer vision , pages 2564\u20132571. Ieee, 2011. 2, 7, 14 Torsten Sattler, Will Maddern, Carl Toft, Akihiko Torii, Lars Hammarstrand, Erik Stenborg, Daniel Safari, Masatoshi Okutomi, Marc Pollefeys, Josef Sivic, et al. Benchmarking 6dof outdoor visual localization in changing conditions. InProceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 8601\u20138610, 2018. 2 Paul-Edouard Sarlin, Daniel DeTone, Tomasz Malisiewicz, and Andrew Rabinovich. Superglue: Learning feature matching with graph neural networks. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , pages 4938\u20134947, 2020. 2 Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 8922\u20138931, 2021. 2 Emilio Parisotto, Devendra Singh Chaplot, Jian Zhang, and Ruslan Salakhutdinov. Global pose estimation with an attention-based recurrent network. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops , pages 237\u2013246, 2018. 2 Dinesh Jayaraman and Kristen Grauman. Learning to look around: Intelligently exploring unseen environments for unknown tasks. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 1238\u20131247, 2018. 3 Santhosh K Ramakrishnan and Kristen Grauman. Sidekick policy learning for active visual exploration. In Proceedings of the European Conference on Computer Vision (ECCV) , pages 413\u2013430, 2018. 3 Santhosh K Ramakrishnan, Dinesh Jayaraman, and Kristen Grauman. Emergence of exploratory look-around behaviors through active observation completion. Science Robotics , 4(30), 2019. 3 Peter Anderson, Angel Chang, Devendra Singh Chaplot, Alexey Dosovitskiy, Saurabh Gupta, Vladlen Koltun, Jana Kosecka, Jitendra Malik, Roozbeh Mottaghi, Manolis Savva, et al. On evaluation of embodied navigation agents. arXiv preprint arXiv:1807.06757 , 2018. 4, 9 Jianxiong Xiao, Krista A Ehinger, Aude Oliva, and Antonio Torralba. Recognizing scene viewpoint using panoramic place representation. In 2012 IEEE Conference on Computer Vision and Pattern Recognition , pages 2695\u20132702. IEEE, 2012. 4, 16 Shih-Han Chou, Cheng Sun, Wen-Yen Chang, Wan-Ting Hsu, Min Sun, and Jianlong Fu. 360-indoor: towards learning real-world objects in 360deg indoor equirectangular images. In Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision , pages 845\u2013853, 2020. 4, 16 Claudio Michaelis, Benjamin Mitzkus, Robert Geirhos, Evgenia Rusak, Oliver Bringmann, Alexander S Ecker, Matthias Bethge, and Wieland Brendel. Benchmarking robustness in object detection: Autonomous driving when winter is coming. arXiv preprint arXiv:1907.07484 , 2019. 5, 9, 12 Richard S. Sutton and Andrew G. Barto. Introduction to Reinforcement Learning . MIT Press, Cambridge, MA, USA, 1st edition, 1998. ISBN 0262193981. 5, 13 Richard S. Sutton, David McAllester, Satinder Singh, and Yishay Mansour. Policy gradient methods for reinforcement learning with function approximation. In Proceedings of the 12th International Conference on Neural Information Processing Systems , NIPS\u201999, pages 1057\u20131063, Cambridge, MA, USA, 1999. MIT Press. URL http://dl.acm. org/citation.cfm?id=3009657.3009806 . 6, 13 Sanmit Narvekar, Bei Peng, Matteo Leonetti, Jivko Sinapov, Matthew E Taylor, and Peter Stone. Curriculum learning for reinforcement learning domains: A framework and survey. arXiv preprint arXiv:2003.04960 , 2020. 6 John Schulman, Filip Wolski, Prafulla Dhariwal, Alec Radford, and Oleg Klimov. Proximal policy optimization algorithms. CoRR , abs/1707.06347, 2017. URL http://arxiv.org/abs/1707.06347 . 6, 13 Christoph Kamann and Carsten Rother. Benchmarking the robustness of semantic segmentation models. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 8828\u20138838, 2020. 9"
      },
      "Image-Based 3D Reconstruction of Cleft Lip and Palate Using a Learned Shape Prior": {
        "authors": [],
        "url": "https://people.inf.ethz.ch/~sobarbar/paper/Lingens23.pdf",
        "ref_texts": "21. Sun, J., Shen, Z., Wang, Y., Bao, H., Zhou, X.: LoFTR: Detector-free local feature matching with transformers. CVPR (2021)",
        "ref_ids": [
          "21"
        ]
      },
      "Robust-DefReg: A Robust Deformable Point Cloud Registration Method based on Graph Convolutional Neural Networks": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2306.04701",
        "ref_texts": "21. Sun, J., Shen, Z., Wang, Y., Bao, H., Zhou, X.: Loftr: Detector-free local feature matching with transformers. In: Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. pp. 8922\u20138931 (2021)",
        "ref_ids": [
          "21"
        ]
      },
      "COmparative Study of Feature Localization Methods for Endoscopy Image Matching": {
        "authors": [],
        "url": "https://upcommons.upc.edu/bitstream/handle/2117/407947/2743-Comparative-study-of-feature-localization-methods-for-endoscopy-image-matching.pdf?sequence=1",
        "ref_texts": "[24] J. Sun, Z. Shen, Y . Wang, H. Bao, and X. Zhou, \u201cLoFTR: Detector-free local feature matching with transformers,\u201d in CVPR , 2021.",
        "ref_ids": [
          "24"
        ]
      },
      "Color Mismatches in Stereoscopic Video: Real-World Dataset and Deep Correction Method": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2303.06657",
        "ref_texts": "[22] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. LoFTR: Detector-free local feature matching with transformers. InProceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 8922\u20138931, 2021.",
        "ref_ids": [
          "22"
        ]
      },
      "Zero-shot virtual product placement in videos": {
        "authors": [
          "Divya Bhargavi"
        ],
        "url": "https://assets.amazon.science/79/e1/701ea41545be97195fc760818416/zero-shot-virtual-product-placement-in-videos.pdf"
      },
      "Pentagon-Match (PMatch): Identification of View-Invariant Planar Feature for Local Feature Matching-Based Homography Estimation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2305.17463",
        "ref_texts": "[21] Jiaming Sun, Zehong Shen. LoFTR: Detector -Free Local Feature Matching with Transformers. In CVPR , 2021 . ",
        "ref_ids": [
          "21"
        ]
      },
      "End-to-end evaluation of practical video analytics systems for face detection and recognition": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2310.06945",
        "ref_texts": "[17] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. LoFTR: Detector-free Local Feature Matching with Transformers. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , 2021.",
        "ref_ids": [
          "17"
        ]
      },
      "Utilizing Radiomic Feature Analysis For Automated MRI Keypoint Detection: Enhancing Graph Applications": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2311.18281",
        "ref_texts": "[8] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou, \u201cLoftr: Detector-free local feature matching with transformers,\u201d in Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , 2021, pp. 8922\u20138931.",
        "ref_ids": [
          "8"
        ]
      },
      "\u4e00\u79cd\u9c81\u68d2\u7684\u6708\u9762\u5bbd\u57fa\u7ebf\u56fe \u50cf \u7279 \u5f81 \u5339 \u914d \u65b9 \u6cd5": {
        "authors": [],
        "url": "https://www.opticsjournal.net/Articles/GetArticlePDF/OJd5b0cd73b1fbd632",
        "ref_texts": "[17]Sun J M , Shen Z H , Wang Y A , et al . LoFTR : detector -free local feature matching with transformers [C]//2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition ",
        "ref_ids": [
          "17",
          "C"
        ]
      },
      "Modularizing deep learning for geometry-aware registration and reconstruction": {
        "authors": [
          "Wei Jiang"
        ],
        "url": "https://open.library.ubc.ca/media/download/pdf/24/1.0427395/4",
        "ref_texts": "[246] J. Sun, Z. Shen, Y . Wang, H. Bao, and X. Zhou. LoFTR: Detector-Free Local Feature Matching with Transformers. CVPR , 2021.!page 58",
        "ref_ids": [
          "246"
        ]
      },
      "Efficient and Accurate Co-Visible Region Localization with Matching Key-Points Crop (MKPC): A Two-Stage Pipeline for Enhancing Image Matching Performance": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2303.13794",
        "ref_texts": "[5]Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou, \u201cLoftr: Detector-free local feature matching with transformers,\u201d in Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , 2021, pp. 8922\u20138931.",
        "ref_ids": [
          "5"
        ]
      },
      "Modular Mapping and Learning for Robotics": {
        "authors": [],
        "url": "https://www.research-collection.ethz.ch/bitstream/handle/20.500.11850/605735/1/phd_thesis_cramariuc_collection.pdf",
        "ref_texts": "[26]J. Sun, Z. Shen, Y. Wang, H. Bao, and X. Zhou, \u201cLoFTR: Detector-Free Local Feature Matching With Transformers,\u201d in IEEE Conference on Computer Vision and Pattern Recognition (CVPR) ,2021 , pp. 8922 \u20138931 .",
        "ref_ids": [
          "26"
        ]
      },
      "Visual Guidance for Unmanned Aerial Vehicles with Deep Learning": {
        "authors": [],
        "url": "https://unsworks.unsw.edu.au/bitstreams/3ba33ce8-066a-46ae-94c0-7f09c9224314/download",
        "ref_texts": "[311] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. LoFTR: Detector-free local feature matching with transformers. In Proceedings ofthe IEEE/CVF Conference onComputer Vision and Pattern Recognition, pages 8922{8931. IEEE, 2021.",
        "ref_ids": [
          "311"
        ]
      },
      "Revisiting Monocular Visual Odometry from Downward Facing Cameras": {
        "authors": [
          "Daniel Walton"
        ],
        "url": "https://etd.ohiolink.edu/acprod/odb_etd/ws/send_file/send?accession=osu1682013681124081&disposition=inline",
        "ref_texts": "[56] J. Sun, Z. Shen, Y. Wang, H. Bao and X. Zhou, \"LoFTR: Detector -Free Local Feature Matching with Transformers,\" 2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) , Nashville, TN, USA, 2021, pp. 89 188927, doi: 10.1109/CVPR46437.2021.00881. ",
        "ref_ids": [
          "56"
        ]
      },
      "Video Motion Analysis with Limited Labeled Training Data": {
        "authors": [],
        "url": "https://dukespace.lib.duke.edu/bitstreams/d5845795-4b5c-44d0-9b21-59b5deb6a30f/download",
        "ref_texts": "145 Stone, A., Maurer, D., Ayvaci, A., Angelova, A., and Jonschkowski, R. (2021), \u201cSMURF: Self-teaching multi-frame unsupervised RAFT with full-image warping,\u201d in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pp. 3887\u20133896. Su, H., Jampani, V., Sun, D., Gallo, O., Learned-Miller, E., and Kautz, J. (2019), \u201cPixel-adaptive convolutional neural networks,\u201d in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pp. 11166\u201311175. Sui, X., Li, S., Geng, X., Wu, Y., Xu, X., Liu, Y., Goh, R., and Zhu, H. (2022), \u201cCRAFT: Cross-Attentional Flow Transformer for Robust Optical Flow,\u201d in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 17602\u201317611. Sun, D., Yang, X., Liu, M.-Y., and Kautz, J. (2018a), \u201cPWC-Net: CNNs for Optical Flow Using Pyramid, Warping, and Cost Volume,\u201d in Conference on Computer Vision and Pattern Recognition . Sun, D., Yang, X., Liu, M.-Y., and Kautz, J. (2018b), \u201cPWC-Net: CNNs for Optical Flow Using Pyramid, Warping, and Cost Volume,\u201d in The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) . Sun, J., Shen, Z., Wang, Y., Bao, H., and Zhou, X. (2021), \u201cLoFTR: Detectorfree local feature matching with transformers,\u201d in Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , pp. 8922\u20138931. Sun, S., Akhtar, N., Song, H., Mian, A., and Shah, M. (2019), \u201cDeep affinity network for multiple object tracking,\u201d IEEE transactions on pattern analysis and machine intelligence , 43, 104\u2013119. Sundberg, P., Brox, T., Maire, M., Arbel\u00b4 aez, P., and Malik, J. (2011), \u201cOcclusion boundary detection and figure/ground assignment from optical flow,\u201d in CVPR"
      },
      "Scene Visual Perception and AR Navigation Applications": {
        "authors": [],
        "url": "http://zte.magtechjournal.com/CN/article/downloadArticleFile.do?attachType=PDF&id=815",
        "ref_texts": "[16] SUN J M , SHEN Z H , WANG Y A , et al . LoFTR : detector -free local feature matching with transformers [C]//IEEE/CVF Conference on Computer Vision and Pattern Recognition . IEEE , 2021 : 8918\u20138927 . DOI : 10.1109 / CVPR 46437 .2021 .00881",
        "ref_ids": [
          "16",
          "C"
        ]
      },
      "Scene Understanding for Intelligent Transportation and Mobility Assistance Systems": {
        "authors": [],
        "url": "https://scholar.archive.org/work/u67xl63g7zcqhhdgnji3jfqyaq/access/wayback/https://publikationen.bibliothek.kit.edu/1000164651/151762876",
        "ref_texts": "[194] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. \u201cLoFTR: Detector-free local feature matching with transformers.\u201d In: CVPR . 2021.",
        "ref_ids": [
          "194"
        ]
      },
      "Vision-based UAV autonomous landing in natural scenario": {
        "authors": [],
        "url": "https://trepo.tuni.fi/bitstream/handle/10024/148220/KalliolaJussi.pdf?sequence=2",
        "ref_texts": "8 Finally , the localization phase is used to estimate the pose of the UA V. One of the common methods is to use PnP algorithm to estimate the pose from a set of 2D-3D corresponding points [16], [31]. In this section, previous studies of visual localization and detection in autonomous landing are covered. One of the first studies performed in 2006 by T sai et al., [14] where they proposed visual localization system based on the three-step pipeline: image processing using image segmentation with edge detection, target identification using Hu\u2019s invariant moments [46], and finally state estimation using parallel lines of the cooperative target extracted with Hough transform [47]. The system had accurate performance, however, they identified that the pose estimation was challenging when the target was only partially visible in the image. A similar approach was proposed by Xu et al., in 2009, [27] where they extracted the cooperative target from the background using thresholding and edge detection. Affine invariant moments [48] were used for target recognition. In their work, only the yaw angle was estimated from the extracted feature points. They achieved an average recognition time of 17.2ms with a recognition accuracy of 97.2%. In 2013, Sanchez et al., [28] proposed a system where a cooperative target was extracted from the image using color thresholding, median filtering, and image binarization. Homography was calculated from the corner points of the \u201dH\u201d cooperative target. They demonstrated the system on the ship deck simulation platform. Morais et al., in 2015, [16] proposed a system for detecting light beacons by analyzing image luminance values. The beacons are identified by extracting blops and removing outliers. The pose of the UA V is estimated by using Efficient Perspective and Point (EPnP) algorithm, which uses a set of 2D3D corresponding points for estimating the absolute pose. The proposed system was tested in simulation and in real life. Real-time GPU-based pose estimation system was proposed in 2018 by Benini et al., [26] where they parallelized markerbased ellipse detection using GPU kernels. The pose is then estimated using PnP algorithm where the detected markers worked as 3D points for the algorithm. The pose estimation was able to run with a minimum of 30 fps with an image resolution of 640x480 pixels. All the previous studies were using a single method for visual localization regardless of the UA V altitude. In 2018, Haiwen et al., [20] proposed a hierarchical visual localization pipeline for the autonomous landing including three phases \u201dapproaching\u201d, \u201dadjustment\u201d, and \u201dtouchdown\u201d depending on the altitude. They designed RQRLP cooperative target which contained visual features in several scales. In the approaching -phase, the outline of the target is detected with a matching-based method, tracking the four corners and calculating the relative pose. In the next phase, location markers on the RQRLP are used for the exact pose recovery , and finally , optical flow is used in the touchdown phase when the UA V is too close to the 9 pad to cover all the location markers. Y ang et al., in 2018, [38] were the first ones to propose deep learning-based target detection and tracking method. They used Convolutional Neural Network model [49], YOLO, for landing site detection. Then landing site was tracked using SIFT features between frames, then the homography matrix of the two images is calculated which is used to map the location of the previous frame to the current frame. Finally , in 2019, Rodriquez et al., [21] proposed the reinforcement learning (RL) method Deep Deterministic Policy Gradient (DDPG)",
        "ref_ids": [
          "16",
          "31",
          "14",
          "46",
          "47",
          "27",
          "48",
          "28",
          "16",
          "26",
          "20",
          "38",
          "49",
          "21"
        ]
      },
      "Local Scenario Perception and Web AR Navigation": {
        "authors": [],
        "url": "https://www.zte.com.cn/content/dam/zte-site/res-www-zte-com-cn/mediares/magazine/publication/com_en/article/en202304/en20230407.pdf",
        "ref_texts": "[15] SUN J M , SHEN Z H , WANG Y A , et al . LoFTR : detector -free local feature matching with transformers [C]//Proc . 2021 IEEE/CVF Conference on Com \u2043 puter Vision and Pattern Recognition (CVPR ). IEEE , 2021 : 8918\u20138927 . DOI: 10.1109 /CVPR 46437 .2021 .00881",
        "ref_ids": [
          "15",
          "C"
        ]
      },
      "Kick Back & Relax: Learning to Reconstruct the World by Watching SlowTV": {
        "authors": [],
        "url": "https://openresearch.surrey.ac.uk/esploro/fulltext/conferenceProceeding/Kick-Back--Relax-Learning-to/99790766602346?repId=12187320980002346&mId=13187320970002346&institution=44SUR_INST",
        "ref_texts": "[58] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , pages 8922\u20138931, 2021. 8",
        "ref_ids": [
          "58"
        ]
      },
      "A deep learning-based pipeline for visual geolocation in the urban environment": {
        "authors": [],
        "url": "https://er.ucu.edu.ua/bitstreams/8267f892-a57e-4297-8d52-c3213654dbaf/download",
        "ref_texts": "[51] Jiaming Sun et al. LoFTR: Detector-Free Local Feature Matching with Transformers .",
        "ref_ids": [
          "51"
        ]
      },
      "Multi-Frame Super-Resolution for Enhancing Lunar South Pole Satellite Images": {
        "authors": [],
        "url": "https://www.duo.uio.no/bitstream/handle/10852/104445/1/masteroppgave.pdf",
        "ref_texts": "[39] Jiaming Sun et al. \u201cLoFTR: Detector-Free Local Feature Matching with Transformers\u201d. In: 2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) . 2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Nashville, TN, USA: IEEE, June 2021, pp. 8918\u20138927. ISBN : 978-1-66544-509-2. DOI: 10.1109/CVPR46437.2021.00881 .URL:https://ieeexplore. ieee.org/document/9578008/ (visited on 04/05/2023).",
        "ref_ids": [
          "39"
        ]
      },
      "Doppelgangers: Learning to Disambiguate Images of Similar Structures Supplemental Material": {
        "authors": [],
        "url": "https://openaccess.thecvf.com/content/ICCV2023/supplemental/Cai_Doppelgangers_Learning_to_ICCV_2023_supplemental.pdf",
        "ref_texts": "[14] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In CVPR , pages 8922\u20138931, 2021. 1, 3, 4",
        "ref_ids": [
          "14"
        ]
      },
      "TCD: TEXT IMAGE CHANGE DETECTION FOR MULTILINGUAL DOCUMENT COMPARISON": {
        "authors": [],
        "url": "https://openreview.net/pdf?id=zKgrmMOQjg",
        "ref_texts": "11 Under review as a conference paper at ICLR 2024 Tsung-Yi Lin, Piotr Doll \u00b4ar, Ross Girshick, Kaiming He, Bharath Hariharan, and Serge Belongie. Feature pyramid networks for object detection. In Proceedings of the IEEE conference on computer vision and pattern recognition , pp. 2117\u20132125, 2017. Jonathan Long, Evan Shelhamer, and Trevor Darrell. Fully convolutional networks for semantic segmentation. In Proceedings of the IEEE conference on computer vision and pattern recognition , pp. 3431\u20133440, 2015. Juhong Min, Dahyun Kang, and Minsu Cho. Hypercorrelation squeeze for few-shot segmentation. InProceedings of the IEEE/CVF international conference on computer vision , pp. 6941\u20136952, 2021. Shunji Mori, Ching Y Suen, and Kazuhiko Yamamoto. Historical review of ocr research and development. Proceedings of the IEEE , 80(7):1029\u20131058, 1992. Ishita Mukherjee. Impact of globalization on international trade. ICFAI Journal of International Business , 3(1), 2008. Prajit Ramachandran, Niki Parmar, Ashish Vaswani, Irwan Bello, Anselm Levskaya, and Jon Shlens. Stand-alone self-attention in vision models. Advances in neural information processing systems , 32, 2019. Joseph Redmon, Santosh Divvala, Ross Girshick, and Ali Farhadi. You only look once: Unified, real-time object detection. In Proceedings of the IEEE conference on computer vision and pattern recognition , pp. 779\u2013788, 2016. Shaoqing Ren, Kaiming He, Ross Girshick, and Jian Sun. Faster r-cnn: Towards real-time object detection with region proposal networks. Advances in neural information processing systems , 28, 2015. Olaf Ronneberger, Philipp Fischer, and Thomas Brox. U-net: Convolutional networks for biomedical image segmentation. In Medical Image Computing and Computer-Assisted Intervention\u2013 MICCAI 2015: 18th International Conference, Munich, Germany, October 5-9, 2015, Proceedings, Part III 18 , pp. 234\u2013241. Springer, 2015. Muhammad Sarfraz, Syed Nazim Nawaz, and Abdulaziz Al-Khuraidly. Offline arabic text recognition system. In 2003 International Conference on Geometric Modeling and Graphics, 2003. Proceedings , pp. 30\u201335. IEEE, 2003. Herbert F Schantz. History of OCR, optical character recognition . Recognition Technologies Users Association, 1982. Baoguang Shi, Xiang Bai, and Cong Yao. An end-to-end trainable neural network for image-based sequence recognition and its application to scene text recognition. IEEE transactions on pattern analysis and machine intelligence , 39(11):2298\u20132304, 2016. Karen Simonyan and Andrew Zisserman. Very deep convolutional networks for large-scale image recognition. arXiv preprint arXiv:1409.1556 , 2014. Amarjot Singh, Ketan Bacchuwar, and Akshay Bhasin. A survey of ocr applications. International Journal of Machine Learning and Computing , 2(3):314, 2012. Mohamed Sirajudeen and R Anitha. Forgery document detection in information management system using cognitive techniques. Journal of Intelligent & Fuzzy Systems , 39(6):8057\u20138068, 2020. Ray Smith. An overview of the tesseract ocr engine. In Ninth international conference on document analysis and recognition (ICDAR 2007) , volume 2, pp. 629\u2013633. IEEE, 2007. Sebastian Stoli \u00b4nski and Wojciech Bieniecki. Application of ocr systems to processing and digitization of paper documents. Information Systems in Management VIII , 102, 2011. Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , pp. 8922\u20138931, 2021."
      },
      "Rut depth estimation by distortion analysis of images taken by an in-vehicle camera": {
        "authors": [
          "Fabio Biondini"
        ],
        "url": "https://api.taylorfrancis.com/content/chapters/oa-edit/download?identifierName=doi&identifierValue=10.1201/9781003323020-470&type=chapterpdf",
        "ref_texts": "2022). Road Surface Investigation. NICHIREKI CO., LTD. Available at: https://www.nichireki.co.jp/product/ consult/consult_list05/consult05_01.html (Accessed: December 30, 2022). Structure from motion (2022) Wikipedia. Wikimedia Foundation. Available at: https://en.wikipedia.org/ wiki/Structure_from_motion (Accessed: December 30, 2022). Sun, J., Shen, Z., Wang, Y., Bao, H. & Zhou, X. 2021, \u201cLoFTR: Detector-free local feature matching with transformers\u201d, Proceedings of the IEEE/CVF conference on computer vision and pattern recogni tion , pp. 8922. Tomasi, C. & Kanade, T. 1993, \u201cShape and motion from image streams: a factorization method.\u201d, Proceedings of the National Academy of Sciences , vol. 90, no. 21, pp. 9795\u20139802. Zhao, B. & Nagayama, T. 2017, \u201cIRI estimation by the frequency domain analysis of vehicle dynamic responses\u201d, Procedia Engineering , vol. 188, pp. 9\u201316."
      },
      "deep learning meets visual localization": {
        "authors": [],
        "url": "https://mediatum.ub.tum.de/doc/1693333/document.pdf",
        "ref_texts": "[Sun+21] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. LoFTR: Detector-free local feature matching with transformers. In: Proceedings of the IEEE/CVF conference on computer vision and pattern recognition .",
        "ref_ids": [
          "Sun\\+21"
        ]
      },
      "Tame a Wild Camera: In-the-Wild Monocular Camera Calibration======= Supplementary=======": {
        "authors": [],
        "url": "https://proceedings.neurips.cc/paper_files/paper/2023/file/8db9279f593652ee9bb2223b4a2c43fa-Supplemental-Conference.pdf",
        "ref_texts": "[19] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. LoFTR: Detector-free local feature matching with transformers. In CVPR , 2021. 5",
        "ref_ids": [
          "19"
        ]
      },
      "Generating Aligned Pseudo-Supervision from Non-Aligned Data for Image Restoration in Under-Display Camera-Supplementary Material": {
        "authors": [],
        "url": "https://openaccess.thecvf.com/content/CVPR2023/supplemental/Feng_Generating_Aligned_Pseudo-Supervision_CVPR_2023_supplemental.pdf",
        "ref_texts": "[12] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. LoFTR: Detector-free local feature matching with transformers. In CVPR , 2021. 4",
        "ref_ids": [
          "12"
        ]
      },
      "Optimal Multiple Transport with Applications to Visual Matching, Model Fusion and Beyond": {
        "authors": [],
        "url": "https://openreview.net/pdf?id=3P87ptzvTm",
        "ref_texts": "10 Under review as a conference paper at ICLR 2024 Chang Liu, Chenfei Lou, Runzhong Wang, Alan Yuhan Xi, Li Shen, and Junchi Yan. Deep neural network fusion via graph matching with applications to model ensemble and federated learning. In International Conference on Machine Learning , pp. 13857\u201313869. PMLR, 2022b. Michael Matena and Colin Raffel. Merging models with fisher-weighted averaging, 2021. arXiv preprint arXiv:2111.09832 . Gaspard Monge. M \u00b4emoire sur la th \u00b4eorie des d \u00b4eblais et des remblais. Mem. Math. Phys. Acad. Royale Sci., pp. 666\u2013704, 1781. James Munkres. Algorithms for the assignment and transportation problems. Journal of the society for industrial and applied mathematics , 5(1):32\u201338, 1957. Dang Nguyen, Trang Nguyen, Khai Nguyen, Dinh Phung, Hung Bui, and Nhat Ho. On cross-layer alignment for model fusion of heterogeneous neural networks. In ICASSP 2023-2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) , pp. 1\u20135. IEEE, 2023. Gabriel Peyre and Marco Cuturi. Computational optimal transport. Foundations and Trends in Machine Learning , 11(5-6):355\u2013607, 2019. Paul-Edouard Sarlin, Daniel DeTone, Tomasz Malisiewicz, and Andrew Rabinovich. Superglue: Learning feature matching with graph neural networks. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , pp. 4938\u20134947, 2020. Sidak Pal Singh and Martin Jaggi. Model fusion via optimal transport. Advances in Neural Information Processing Systems , 33:22045\u201322055, 2020. George Stoica, Daniel Bolya, Jakob Bjorner, Taylor Hearn, and Judy Hoffman. Zipit! merging models from different tasks without training. arXiv preprint arXiv:2305.03053 , 2023. Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , pp. 8922\u20138931, 2021. Kun Sun, Jinhong Yu, Wenbing Tao, Xin Li, Chang Tang, and Yuhua Qian. A unified feature-spatial cycle consistency fusion framework for robust image matching. Information Fusion , 97:101810, 2023. Paul Swoboda, Ashkan Mokarian, Christian Theobalt, Florian Bernard, et al. A convex relaxation for multi-graph matching. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pp. 11156\u201311165, 2019. Siddharth Tourani, Carsten Rother, Muhammad Haris Khan, and Bogdan Savchynskkyy. Unsupervised deep graph matching based on cycle consistency. arXiv preprint arXiv:2307.08930 , 2023. Hongyi Wang, Mikhail Yurochkin, Yuekai Sun, Dimitris Papailiopoulos, and Yasaman Khazaeni. Federated learning with matched averaging. arXiv preprint arXiv:2002.06440 , 2020a. Runzhong Wang, Junchi Yan, and Xiaokang Yang. Learning combinatorial embedding networks for deep graph matching. In Proceedings of the IEEE/CVF international conference on computer vision , pp. 3056\u20133065, 2019. Runzhong Wang, Junchi Yan, and Xiaokang Yang. Combinatorial learning of robust deep graph matching: an embedding based approach. IEEE Transactions on Pattern Analysis and Machine Intelligence , 2020b. Runzhong Wang, Junchi Yan, and Xiaokang Yang. Neural graph matching network: Learning lawler\u2019s quadratic assignment problem with extension to hypergraph and multiple-graph matching. IEEE Transactions on Pattern Analysis and Machine Intelligence , 2021. Runzhong Wang, Junchi Yan, and Xiaokang Yang. Unsupervised learning of graph matching with mixture of modes via discrepancy minimization. IEEE Transactions on Pattern Analysis and Machine Intelligence , 45(8):10500\u201310518, 2023."
      },
      "Learning Fine-Grained Features for Pixel-wise Video Correspondences Supplementary Material": {
        "authors": [],
        "url": "https://openaccess.thecvf.com/content/ICCV2023/supplemental/Li_Learning_Fine-Grained_Features_ICCV_2023_supplemental.pdf",
        "ref_texts": "[7] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matchingwith transformers. In CVPR , pages 8922\u20138931, 2021.",
        "ref_ids": [
          "7"
        ]
      },
      "Learning Rotation-Equivariant Features for Visual Correspondence-supplementary material": {
        "authors": [
          "N L"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2023/supplemental/Lee_Learning_Rotation-Equivariant_Features_CVPR_2023_supplemental.pdf",
        "ref_texts": "[1]Vassileios Balntas, Karel Lenc, Andrea Vedaldi, and Krys-tian Mikolajczyk. Hpatches: A benchmark and evaluationof handcrafted and learned local descriptors. InProceed-ings of the IEEE Conference on Computer Vision and PatternRecognition, pages 5173\u20135182, 2017.1,5[2]Taco Cohen and Max Welling. Group equivariant convo-lutional networks. InInternational conference on machinelearning, pages 2990\u20132999. PMLR, 2016.1[3]Taco S Cohen, Mario Geiger, and Maurice Weiler. A gen-eral theory of equivariant cnns on homogeneous spaces. InProceedings of the 33rd International Conference on NeuralInformation Processing Systems, pages 9145\u20139156, 2019.1[4]Taco S Cohen and Max Welling. Steerable cnns.arXivpreprint arXiv:1612.08498, 2016.1[5]Daniel DeTone, Tomasz Malisiewicz, and Andrew Rabi-novich. Superpoint: Self-supervised interest point detectionand description. InCVPR Deep Learning for Visual SLAMWorkshop, 2018.2,3,4,7[6]Mihai Dusmanu, Ignacio Rocco, Tomas Pajdla, Marc Polle-feys, Josef Sivic, Akihiko Torii, and Torsten Sattler. D2-net: A trainable cnn for joint description and detection oflocal features. InProceedings of the ieee/cvf conference oncomputer vision and pattern recognition, pages 8092\u20138101,2019.2,3[7]Martin A Fischler and Robert C Bolles. Random sampleconsensus: a paradigm for model fitting with applications toimage analysis and automated cartography.Communicationsof the ACM, 24(6):381\u2013395, 1981.2[8]Yuhe Jin, Dmytro Mishkin, Anastasiia Mishchuk, Jiri Matas,Pascal Fua, Kwang Moo Yi, and Eduard Trulls. Imagematching across wide baselines: From paper to practice.International Journal of Computer Vision, 129(2):517\u2013547,2021.1,3[9]Axel Barroso Laguna and Krystian Mikolajczyk. Key. net:Keypoint detection by handcrafted and learned cnn filters re-visited.IEEE Transactions on Pattern Analysis and MachineIntelligence, 2022.2[10]Jongmin Lee, Yoonwoo Jeong, and Minsu Cho. Self-supervised learning of image scale and orientation. In31stBritish Machine Vision Conference 2021, BMVC 2021, Vir-tual Event, UK. BMV A Press, 2021.5[11]Jongmin Lee, Byungjin Kim, and Minsu Cho. Self-supervised equivariant learning for oriented keypoint detec-tion. InProceedings of the IEEE/CVF Conference on Com-puter Vision and Pattern Recognition, pages 4847\u20134857,2022.5[12]Kunhong Li, Longguang Wang, Li Liu, Qing Ran, Kai Xu,and Yulan Guo. Decoupling makes weakly supervised localfeature better. InProceedings of the IEEE/CVF Conferenceon Computer Vision and Pattern Recognition, pages 15838\u201315848, 2022.3[13]Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays,Pietro Perona, Deva Ramanan, Piotr Doll\u00b4ar, and C LawrenceZitnick. Microsoft coco: Common objects in context. InEuropean conference on computer vision, pages 740\u2013755.Springer, 2014.3[14]Yuan Liu, Zehong Shen, Zhixuan Lin, Sida Peng, Hujun Bao,and Xiaowei Zhou. Gift: Learning transformation-invariantdense visual descriptors via group cnns.Advances in NeuralInformation Processing Systems, 32:6992\u20137003, 2019.1,2,3,4,5,9[15]David G Lowe. Distinctive image features from scale-invariant keypoints.International journal of computer vi-sion, 60(2):91\u2013110, 2004.2,4[16]Anastasiia Mishchuk, Dmytro Mishkin, Filip Radenovic,and Jiri Matas. Working hard to know your neighbor\u2019s mar-gins: Local descriptor learning loss. InAdvances in NeuralInformation Processing Systems, pages 4826\u20134837, 2017.3[17]Yuki Ono, Eduard Trulls, Pascal Fua, and Kwang Moo Yi.Lf-net: learning local features from images. InAdvancesin neural information processing systems, pages 6234\u20136244,2018.3,5,7[18]R\u00b4emi Pautrat, Viktor Larsson, Martin R Oswald, and MarcPollefeys. Online invariance selection for local feature de-scriptors. InEuropean Conference on Computer Vision,pages 707\u2013724. Springer, 2020.1,2,3,6[19]Jerome Revaud, Cesar De Souza, Martin Humenberger, andPhilippe Weinzaepfel. R2d2: Reliable and repeatable detec-tor and descriptor.Advances in neural information process-ing systems, 32:12405\u201312415, 2019.2,3[20]Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, San-jeev Satheesh, Sean Ma, Zhiheng Huang, Andrej Karpathy,Aditya Khosla, Michael Bernstein, et al. Imagenet largescale visual recognition challenge.International journal ofcomputer vision, 115(3):211\u2013252, 2015.4[21]Paul-Edouard Sarlin, Daniel DeTone, Tomasz Malisiewicz,and Andrew Rabinovich. Superglue: Learning featurematching with graph neural networks. InProceedings ofthe IEEE/CVF conference on computer vision and patternrecognition, pages 4938\u20134947, 2020.4[22]Xuelun Shen, Cheng Wang, Xin Li, Zenglei Yu, JonathanLi, Chenglu Wen, Ming Cheng, and Zijian He. Rf-net: Anend-to-end image matching network based on receptive field.InProceedings of the IEEE Conference on Computer Visionand Pattern Recognition, pages 8132\u20138140, 2019.3,5,7[23]Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, andXiaowei Zhou. Loftr: Detector-free local feature matchingwith transformers. InProceedings of the IEEE/CVF Con-ference on Computer Vision and Pattern Recognition, pages8922\u20138931, 2021.4[24]Yurun Tian, Axel Barroso Laguna, Tony Ng, Vassileios Bal-ntas, and Krystian Mikolajczyk. Hynet: Learning local de-scriptor with hybrid similarity measure and triplet loss.Ad-vances in Neural Information Processing Systems, 33:7401\u20137412, 2020.2[25]Yurun Tian, Axel Barroso Laguna, Tony Ng, Vassileios Bal-ntas, and Krystian Mikolajczyk. Hynet: Learning local de-scriptor with hybrid similarity measure and triplet loss. InNeurIPS, 2020.3[26]Maurice Weiler and Gabriele Cesa. General e (2)-equivariantsteerable cnns.Advances in Neural Information ProcessingSystems, 32:14334\u201314345, 2019.1,3,5[27]Maurice Weiler, Fred A Hamprecht, and Martin Storath.Learning steerable filters for rotation equivariant cnns. In Proceedings of the IEEE Conference on Computer Visionand Pattern Recognition, pages 849\u2013858, 2018.1[28]Hao Zhou, Torsten Sattler, and David W Jacobs. Evaluatinglocal features for day-night matching. InEuropean Confer-ence on Computer Vision, pages 724\u2013736. Springer, 2016.1,2,6",
        "ref_ids": [
          "1",
          "2",
          "3",
          "4",
          "5",
          "6",
          "7",
          "8",
          "9",
          "10",
          "11",
          "12",
          "13",
          "14",
          "15",
          "16",
          "17",
          "18",
          "19",
          "20",
          "21",
          "22",
          "23",
          "24",
          "25",
          "26",
          "27",
          "28"
        ]
      },
      "Supplementary Material for Adaptive Assignment for Geometry Aware Local Feature Matching": {
        "authors": [],
        "url": "https://openaccess.thecvf.com/content/CVPR2023/supplemental/Huang_Adaptive_Assignment_for_CVPR_2023_supplemental.pdf",
        "ref_texts": "[13] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In CVPR , pages 8922\u20138931, 2021. 2",
        "ref_ids": [
          "13"
        ]
      },
      "ROBUST SPARSE AND DENSE MATCHING": {
        "authors": [],
        "url": "https://openreview.net/pdf?id=mjzwioGLux",
        "ref_texts": "11 Under review as a conference paper at ICLR 2024 Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In CVPR , pp. 8918\u20138927, 2021. Shitao Tang, Jiahui Zhang, Siyu Zhu, and Ping Tan. Quadtree attention for vision transformers. ICLR , 2022. Zachary Teed and Jia Deng. Raft: Recurrent all-pairs field transforms for optical flow. In ECCV , pp. 402\u2013419, 2020. ISBN 978-3-030-58536-5. Bart Thomee, David A Shamma, Gerald Friedland, Benjamin Elizalde, Karl Ni, Douglas Poland, Damian Borth, and Li-Jia Li. Yfcc100m: The new data in multimedia research. Communications of the ACM , 59(2):64\u201373, 2016. Prune Truong, Martin Danelljan, and Radu Timofte. GLU-Net: Global-local universal network for dense flow and correspondences. In CVPR , 2020. Prune Truong, Martin Danelljan, Luc Van Gool, and Radu Timofte. Learning accurate dense correspondences and when to trust them. In CVPR , pp. 5710\u20135720, 2021. doi: 10.1109/CVPR46437."
      },
      "Deep Learning Methods for Robust Image Matching and Visual Localization.": {
        "authors": [
          "Zhijie Wang"
        ],
        "url": "https://tohoku.repo.nii.ac.jp/record/2000371/files/230324-Song-796-1.pdf",
        "ref_texts": "[31] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In Proceedings of Conference on Computer Vision and Pattern Recognition , pages 8922\u20138931, 2021.",
        "ref_ids": [
          "31"
        ]
      },
      "GPR-Net: Multi-view Layout Estimation via a Geometry-aware Panorama Registration Network Supplemental Material": {
        "authors": [],
        "url": "https://openaccess.thecvf.com/content/CVPR2023W/OmniCV/supplemental/Su_GPR-Net_Multi-View_Layout_CVPRW_2023_supplemental.pdf",
        "ref_texts": "[5] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. LoFTR: Detector-free local feature matching with transformers. CVPR, 2021. 1",
        "ref_ids": [
          "5"
        ]
      },
      "PATS: Patch Area Transportation with Subdivision for Local Feature Matching\u2013Supplementary Material\u2013": {
        "authors": [],
        "url": "https://openaccess.thecvf.com/content/CVPR2023/supplemental/Ni_PATS_Patch_Area_CVPR_2023_supplemental.pdf",
        "ref_texts": "[10] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 8922\u20138931, 2021. 3",
        "ref_ids": [
          "10"
        ]
      },
      "Adaptive Spot-Guided Transformer for Consistent Local Feature Matching Supplementary Material": {
        "authors": [],
        "url": "https://openaccess.thecvf.com/content/CVPR2023/supplemental/Yu_Adaptive_Spot-Guided_Transformer_CVPR_2023_supplemental.pdf"
      },
      "DynamicStereo: Consistent Dynamic Depth from Stereo Videos Supplementary Material": {
        "authors": [],
        "url": "https://openaccess.thecvf.com/content/CVPR2023/supplemental/Karaev_DynamicStereo_Consistent_Dynamic_CVPR_2023_supplemental.pdf",
        "ref_texts": "[4] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. LoFTR: Detector-free local feature matching with transformers. CVPR , 2021. 1",
        "ref_ids": [
          "4"
        ]
      },
      "Rotation-Equivariance and Position Encodings for Enhancing Local Descriptors": {
        "authors": [],
        "url": "https://openreview.net/pdf?id=6tDPefQyvB",
        "ref_texts": "10 Under review as a conference paper at ICLR 2024 Abhishek Peri, Kinal Mehta, Avneesh Mishra, Michael Milford, Sourav Garg, and K Madhava Krishna. Ref\u2013rotation equivariant features for local feature matching. arXiv preprint arXiv:2203.05206 , 2022. Ethan Rublee, Vincent Rabaud, Kurt Konolige, and Gary Bradski. Orb: An efficient alternative to sift or surf. In 2011 International conference on computer vision , pp. 2564\u20132571. Ieee, 2011. Paul-Edouard Sarlin, Daniel DeTone, Tomasz Malisiewicz, and Andrew Rabinovich. Superglue: Learning feature matching with graph neural networks. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , pp. 4938\u20134947, 2020. Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , pp. 8922\u20138931, 2021. Guoliang Tang, Zhijing Liu, and Jing Xiong. Distinctive image features from illumination and scale invariant keypoints. Multimedia Tools and Applications , 78:23415\u201323442, 2019. Bart Thomee, David A Shamma, Gerald Friedland, Benjamin Elizalde, Karl Ni, Douglas Poland, Damian Borth, and Li-Jia Li. Yfcc100m: The new data in multimedia research. Communications of the ACM , 59(2):64\u201373, 2016. Changwei Wang, Rongtao Xu, Ke Lv, Shibiao Xu, Weiliang Meng, Yuyang Zhang, Bin Fan, and Xiaopeng Zhang. Attention weighted local descriptors. IEEE Transactions on Pattern Analysis and Machine Intelligence , 2023. Qing Wang, Jiaming Zhang, Kailun Yang, Kunyu Peng, and Rainer Stiefelhagen. Matchformer: Interleaving attention in transformers for feature matching. arXiv preprint arXiv:2203.09645 , 2022. Maurice Weiler and Gabriele Cesa. General e (2)-equivariant steerable cnns. Advances in Neural Information Processing Systems , 32, 2019. Maurice Weiler, Fred A Hamprecht, and Martin Storath. Learning steerable filters for rotation equivariant cnns. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pp. 849\u2013858, 2018. Qi Zheng, Mingming Gong, Xinge You, and Dacheng Tao. A unified b-spline framework for scaleinvariant keypoint detection. International Journal of Computer Vision , 130(3):777\u2013799, 2022."
      },
      "Multi-Modal Place Recognition in Aliased and Low-Texture Environments": {
        "authors": [
          "Alberto Garcia"
        ],
        "url": "https://elib.dlr.de/196289/1/Garcia_Hernandez_Alberto_741363_TFM.pdf",
        "ref_texts": "70 Bibliography.[1]Alex Kendall, Matthew Grimes, and Roberto Cipolla. Posenet: A convolutionalnetwork for real-time 6-dof camera relocalization. InProceedings of the IEEEinternational conference on computer vision,p a g e s2 9 3 8 \u2013 2 9 4 6 ,2 0 1 5 .[2]Jamie Shotton, Ben Glocker, Christopher Zach, Shahram Izadi, AntonioCriminisi, and Andrew Fitzgibbon. Scene coordinate regression forests for camerarelocalization in rgb-d images. InProceedings of the IEEE conference on computervision and pattern recognition,p a g e s2 9 3 0 \u2013 2 9 3 7 ,2 0 1 3 .[3]Maxime Ferrera, Vincent Creuze, Julien Moras, and Pauline Trouv\u00b4 e-Peloux.Aqualoc: An underwater dataset for visual\u2013inertial\u2013pressure localization.TheInternational Journal of Robotics Research,3 8 (1 4 ) : 1 5 4 9 \u2013 1 5 5 9 ,2 0 1 9 .[4]Lukas Meyer, Michal Sm\u00b4 \u0131\u02c7 sek, Alejandro Fontan Villacampa, Laura Oliva Maza,Daniel Medina, Martin J Schuster, Florian Steidle, Mallikarjuna Vayugundla,Marcus G M\u00a8 uller, Bernhard Rebele, et al. The madmax data set for visual-inertialrover navigation on mars.Journal of Field Robotics,3 8 (6 ) : 8 3 3 \u2013 8 5 3 ,2 0 2 1 .[5]Yang Zheng, Tolga Birdal, Fei Xia, Yanchao Yang, Yueqi Duan, and Leonidas JGuibas. 6d camera relocalization in visually ambiguous extreme environments.arXiv preprint arXiv:2207.06333,2 0 2 2 .[6]Riccardo Giubilato, Wolfgang St\u00a8 urzl, Armin Wedler, and Rudolph Triebel.Challenges of slam in extremely unstructured environments: The dlr planetarystereo, solid-state lidar, inertial dataset.IEEE Robotics and Automation Letters,7(4):8721\u20138728, 2022.[7]Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. LoFTR:Detector-free local feature matching with transformers. pages 8922\u20138931, April2021.[8]S. Lowry, N. S\u00a8 underhauf, P. Newman, et al. Visual place recognition: A survey.IEEE Transactions on Robotics,3 2 (1 ) : 1 \u2013 1 9 ,2 0 1 6 .71",
        "ref_ids": [
          "1",
          "2",
          "3",
          "4",
          "5",
          "6",
          "7",
          "8"
        ]
      },
      "SONIC (SONar Image Correspondence): Pose Supervised Learning for Forward Looking Sonar Image Matching": {
        "authors": [],
        "url": "https://oravus.github.io/vpr-workshop/assets/accepted_papers/9_sonic_sonar_image_corresponden.pdf",
        "ref_texts": "[11] J. Sun, Z. Shen, Y . Wang, H. Bao, and X. Zhou, \u201cLoftr: Detectorfree local feature matching with transformers,\u201d in Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , pp. 8922\u20138931, 2021.",
        "ref_ids": [
          "11"
        ]
      },
      "Few-Shot Object Pose Estimation for Functional Robotic Manipulation": {
        "authors": [],
        "url": "https://iplab.dmi.unict.it/acvr2023/program/Few-Shot%20Object%20Pose%20Estimation%20for%20Functional%20Robotic%20Manipulation.pdf",
        "ref_texts": "[10] J. Sun, Z. Shen, Y . Wang, H. Bao, and X. Zhou. LoFTR: Detector-free local feature matching with transformers. In IEEE/CVF Computer Vision and Pattern Recognition Conference (CVPR) , 2021. 2,3",
        "ref_ids": [
          "10"
        ]
      },
      "\u7ed3\u5408\u5f62\u72b6\u4fe1\u606f\u7684 SAR \u56fe\u50cf\u7279\u5f81\u5339\u914d\u65b9\u6cd5.": {
        "authors": [],
        "url": "https://signal.ejournal.org.cn/cn/article/pdf/preview/10.16798/j.issn.1003-0530.2023.02.007.pdf",
        "ref_texts": "[26]SUN Jiaming , SHEN Zehong , WANG Yuang , et al. LoFTR: detector -free local feature matching with transformers [C]//",
        "ref_ids": [
          "26",
          "C"
        ]
      },
      "AutoRecon: Automated 3D Object Discovery and Reconstruction Supplemental Material": {
        "authors": [],
        "url": "https://zju3dv.github.io/autorecon/files/autorecon_supp.pdf",
        "ref_texts": "[12] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In CVPR , 2021. 1",
        "ref_ids": [
          "12"
        ]
      },
      "Re-ranking methods for visual geo-localization with domain shift": {
        "authors": [],
        "url": "https://webthesis.biblio.polito.it/secure/26774/1/tesi.pdf",
        "ref_texts": "[70] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. \u00abLoFTR: Detector-Free Local Feature Matching with Transformers\u00bb. In: CVPR(2021).",
        "ref_ids": [
          "70"
        ]
      },
      "Learning to detect good keypoints to match non-rigid objects in RGB images": {
        "authors": [],
        "url": "https://repositorio.ufmg.br/bitstream/1843/67493/1/dissertacao_welerson_final_com_ficha_catalografica.pdf",
        "ref_texts": "[43] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. LoFTR: detector-free local feature matching with transformers. In CVPR , 2021.",
        "ref_ids": [
          "43"
        ]
      },
      "EagleAI: Estimation of Attitude Geo-localizing Landmarks on Earth": {
        "authors": [],
        "url": "https://webthesis.biblio.polito.it/secure/26817/1/tesi.pdf",
        "ref_texts": "[29]Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , pages 8922\u20138931, 2021.",
        "ref_ids": [
          "29"
        ]
      },
      "Detecci\u00f3n de patrones repetitivos en objetos arqueol\u00f3gicos texturizados": {
        "authors": [],
        "url": "https://repositorio.uchile.cl/bitstream/handle/2250/197399/Deteccion-de-patrones-repetitivos-en-objetos-arqueologicos-texturizados.pdf?sequence=1",
        "ref_texts": "[13] Sun, J., Shen, Z., Wang, Y., Bao, H., y Zhou, X., \u201cLoftr: Detector-free local feature 28 matching with transformers,\u201d en Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pp. 8922\u20138931, 2021.",
        "ref_ids": [
          "13"
        ]
      },
      "Visual slam: What are the current trends and what to expect?": {
        "authors": [
          "Ali Tourani",
          "Hriday Bavle",
          "Jose Luis",
          "Holger Voos"
        ],
        "url": "https://www.mdpi.com/1424-8220/22/23/9297/pdf",
        "ref_texts": "79. Sun, J.; Shen, Z.; Wang, Y.; Bao, H.; Zhou, X. LoFTR: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, Nashville, TN, USA, 20\u201325 June 2021; pp. 8922\u20138931.",
        "ref_ids": [
          "79"
        ]
      },
      "Transfusion: Robust lidar-camera fusion for 3d object detection with transformers": {
        "authors": [
          "Xuyang Bai",
          "Zeyu Hu",
          "Xinge Zhu",
          "Qingqiu Huang",
          "Yilun Chen",
          "Hongbo Fu",
          "Lan Tai"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2022/papers/Bai_TransFusion_Robust_LiDAR-Camera_Fusion_for_3D_Object_Detection_With_Transformers_CVPR_2022_paper.pdf",
        "ref_texts": "[41] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. LoFTR: Detector-free local feature matching with transformers. CVPR , 2021. 4",
        "ref_ids": [
          "41"
        ]
      },
      "Geometric transformer for fast and robust point cloud registration": {
        "authors": [
          "Zheng Qin",
          "Hao Yu",
          "Changjian Wang",
          "Yulan Guo",
          "Yuxing Peng",
          "Kai Xu"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2022/papers/Qin_Geometric_Transformer_for_Fast_and_Robust_Point_Cloud_Registration_CVPR_2022_paper.pdf",
        "ref_texts": "[25] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In CVPR , pages 8922\u20138931, 2021. 1, 3, 4, 5",
        "ref_ids": [
          "25"
        ]
      },
      "Gmflow: Learning optical flow via global matching": {
        "authors": [
          "Haofei Xu",
          "Jing Zhang",
          "Jianfei Cai",
          "Hamid Rezatofighi",
          "Dacheng Tao"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_GMFlow_Learning_Optical_Flow_via_Global_Matching_CVPR_2022_paper.pdf",
        "ref_texts": "[38] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In CVPR , pages 8922\u20138931, 2021. 1, 2, 3, 4",
        "ref_ids": [
          "38"
        ]
      },
      "Flowformer: A transformer architecture for optical flow": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2203.16194",
        "ref_texts": "44. Sun, J., Shen, Z., Wang, Y., Bao, H., Zhou, X.: Loftr: Detector-free local feature matching with transformers. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 8922\u20138931 (2021)",
        "ref_ids": [
          "44"
        ]
      },
      "Practical stereo matching via cascaded recurrent network with adaptive correlation": {
        "authors": [
          "Jiankun Li",
          "Peisen Wang",
          "Pengfei Xiong",
          "Tao Cai",
          "Ziwei Yan",
          "Lei Yang",
          "Jiangyu Liu",
          "Haoqiang Fan",
          "Shuaicheng Liu"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Practical_Stereo_Matching_via_Cascaded_Recurrent_Network_With_Adaptive_Correlation_CVPR_2022_paper.pdf",
        "ref_texts": "[41] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In Proc. CVPR , pages 8922\u20138931, 2021.",
        "ref_ids": [
          "41"
        ]
      },
      "Aspanformer: Detector-free image matching with adaptive span transformer": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2208.14201",
        "ref_texts": "13. Sun, J., Shen, Z., Wang, Y., Bao, H., Zhou, X.: Loftr: Detector-free local feature matching with transformers. In: CVPR. (2021)",
        "ref_ids": [
          "13"
        ]
      },
      "Transmvsnet: Global context-aware multi-view stereo network with transformers": {
        "authors": [
          "Yikang Ding",
          "Wentao Yuan",
          "Qingtian Zhu",
          "Haotian Zhang",
          "Xiangyue Liu",
          "Yuanjiang Wang",
          "Xiao Liu"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2022/papers/Ding_TransMVSNet_Global_Context-Aware_Multi-View_Stereo_Network_With_Transformers_CVPR_2022_paper.pdf"
      },
      "Onepose: One-shot object pose estimation without cad models": {
        "authors": [
          "Jiaming Sun",
          "Zihao Wang",
          "Siyu Zhang",
          "Xingyi He",
          "Hongcheng Zhao",
          "Guofeng Zhang",
          "Xiaowei Zhou"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2022/papers/Sun_OnePose_One-Shot_Object_Pose_Estimation_Without_CAD_Models_CVPR_2022_paper.pdf",
        "ref_texts": "[36] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. LoFTR: Detector-free local feature matching with transformers. CVPR , 2021. 2, 3, 4, 5, 6",
        "ref_ids": [
          "36"
        ]
      },
      "Matchformer: Interleaving attention in transformers for feature matching": {
        "authors": [
          "Qing Wang",
          "Jiaming Zhang",
          "Kailun Yang",
          "Kunyu Peng",
          "Rainer Stiefelhagen"
        ],
        "url": "https://openaccess.thecvf.com/content/ACCV2022/papers/Wang_MatchFormer_Interleaving_Attention_in_Transformers_for_Feature_Matching_ACCV_2022_paper.pdf",
        "ref_texts": "36. Sun, J., Shen, Z., Wang, Y., Bao, H., Zhou, X.: LoFTR: Detector-free local feature matching with transformers. In: CVPR (2021) 2, 3, 4, 7, 8, 9, 10, 11, 12, 13",
        "ref_ids": [
          "36"
        ]
      },
      "Lepard: Learning partial point cloud matching in rigid and deformable scenes": {
        "authors": [
          "Yang Li",
          "Tatsuya Harada"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Lepard_Learning_Partial_Point_Cloud_Matching_in_Rigid_and_Deformable_CVPR_2022_paper.pdf",
        "ref_texts": "[61] J. Sun, Z. Shen, Y . Wang, H. Bao, and X. Zhou. Loftr: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 8922\u20138931, 2021. 1, 4, 8",
        "ref_ids": [
          "61"
        ]
      },
      "Clustergnn: Cluster-based coarse-to-fine graph neural network for efficient feature matching": {
        "authors": [
          "Yan Shi",
          "Xiong Cai",
          "Yoli Shavit",
          "Jiang Mu",
          "Wensen Feng",
          "Kai Zhang"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2022/papers/Shi_ClusterGNN_Cluster-Based_Coarse-To-Fine_Graph_Neural_Network_for_Efficient_Feature_Matching_CVPR_2022_paper.pdf",
        "ref_texts": "[35] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In CVPR , pages 8922\u20138931, 2021. 1, 3, 4, 5",
        "ref_ids": [
          "35"
        ]
      },
      "Global matching with overlapping attention for optical flow estimation": {
        "authors": [
          "Shiyu Zhao",
          "Long Zhao",
          "Zhixing Zhang",
          "Enyu Zhou",
          "Dimitris Metaxas"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2022/papers/Zhao_Global_Matching_With_Overlapping_Attention_for_Optical_Flow_Estimation_CVPR_2022_paper.pdf",
        "ref_texts": "[40] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. LoFTR: Detector-free local feature matching with transformers. In CVPR , pages 8922\u20138931, 2021.",
        "ref_ids": [
          "40"
        ]
      },
      "Onepose++: Keypoint-free one-shot object pose estimation without CAD models": {
        "authors": [],
        "url": "https://proceedings.neurips.cc/paper_files/paper/2022/file/e43f900f571de6c96a70d5724a0fb565-Paper-Conference.pdf",
        "ref_texts": "[47] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. LoFTR: Detector-free local feature matching with transformers. CVPR , 2021. 1, 2, 4, 6, 7, 8",
        "ref_ids": [
          "47"
        ]
      },
      "Lamar: Benchmarking localization and mapping for augmented reality": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2210.10770",
        "ref_texts": "75.Sun, J., Shen, Z., Wang, Y ., Bao, H., Zhou, X.: LoFTR: Detector-free local feature matching with transformers. CVPR (2021) 13",
        "ref_ids": [
          "75"
        ]
      },
      "Fs6d: Few-shot 6d pose estimation of novel objects": {
        "authors": [
          "Yisheng He",
          "Yao Wang",
          "Haoqiang Fan",
          "Jian Sun",
          "Qifeng Chen"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2022/papers/He_FS6D_Few-Shot_6D_Pose_Estimation_of_Novel_Objects_CVPR_2022_paper.pdf",
        "ref_texts": "[46] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. LoFTR: Detector-free local feature matching with transformers. CVPR , 2021. 2, 4, 6, 7",
        "ref_ids": [
          "46"
        ]
      },
      "Dynast: Dynamic sparse transformer for exemplar-guided image generation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2207.06124",
        "ref_texts": "43. Sun, J., Shen, Z., Wang, Y., Bao, H., Zhou, X.: Loftr: Detector-free local feature matching with transformers. In: Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. pp. 8922\u20138931 (2021)",
        "ref_ids": [
          "43"
        ]
      },
      "MS2DG-Net: Progressive correspondence learning via multiple sparse semantics dynamic graph": {
        "authors": [
          "Luanyuan Dai",
          "Yizhang Liu",
          "Jiayi Ma",
          "Lifang Wei",
          "Taotao Lai",
          "Changcai Yang",
          "Riqing Chen"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2022/papers/Dai_MS2DG-Net_Progressive_Correspondence_Learning_via_Multiple_Sparse_Semantics_Dynamic_Graph_CVPR_2022_paper.pdf",
        "ref_texts": "[32] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , pages 8922\u20138931, 2021. 2",
        "ref_ids": [
          "32"
        ]
      },
      "Meshloc: Mesh-based visual localization": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2207.10762",
        "ref_texts": "80. Sun, J., Shen, Z., Wang, Y., Bao, H., Zhou, X.: Loftr: Detector-free local feature matching with transformers. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) (2021)",
        "ref_ids": [
          "80"
        ]
      },
      "Map-free visual relocalization: Metric pose relative to a single image": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2210.05494.pdf?trk=public_post_comment-text",
        "ref_texts": "66. Sun, J., Shen, Z., Wang, Y., Bao, H., Zhou, X.: LoFTR: Detector-free local feature matching with transformers. In: CVPR (2021) 3, 4, 6, 8",
        "ref_ids": [
          "66"
        ]
      },
      "Decoupling makes weakly supervised local feature better": {
        "authors": [
          "Kunhong Li",
          "Longguang Wang",
          "Li Liu",
          "Qing Ran",
          "Kai Xu",
          "Yulan Guo"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2022/papers/Li_Decoupling_Makes_Weakly_Supervised_Local_Feature_Better_CVPR_2022_paper.pdf",
        "ref_texts": "[42] Jiaming Sun, Zehong Shen, and Yuang Wang. LoFTR: Detector-Free Local Feature Matching With Transformers. InProceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) , pages 8922\u20138931, 2021. 3, 4, 7",
        "ref_ids": [
          "42"
        ]
      },
      "A case for using rotation invariant features in state of the art feature matchers": {
        "authors": [
          "Georg Bokman",
          "Fredrik Kahl"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2022W/IMW/papers/Bokman_A_Case_for_Using_Rotation_Invariant_Features_in_State_of_CVPRW_2022_paper.pdf",
        "ref_texts": "[39] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. LoFTR: Detector-free local feature matching with transformers. CVPR , 2021. 1, 2, 3, 5, 6, 7",
        "ref_ids": [
          "39"
        ]
      },
      "The 8-point algorithm as an inductive bias for relative pose prediction by vits": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2208.08988",
        "ref_texts": "[60] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In CVPR , 2021. 1, 2, 4, 6",
        "ref_ids": [
          "60"
        ]
      },
      "Transformatcher: Match-to-match attention for semantic correspondence": {
        "authors": [
          "Seungwook Kim",
          "Juhong Min",
          "Minsu Cho"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2022/papers/Kim_TransforMatcher_Match-to-Match_Attention_for_Semantic_Correspondence_CVPR_2022_paper.pdf",
        "ref_texts": "[49] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. LoFTR: Detector-free local feature matching with transformers. In Proceedings of the IEEE International Conference on Computer Vision and Pattern Recognition (CVPR) , 2021. 2",
        "ref_ids": [
          "49"
        ]
      },
      "Particlesfm: Exploiting dense point trajectories for localizing moving cameras in the wild": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2207.09137",
        "ref_texts": "67.Sun, J., Shen, Z., Wang, Y., Bao, H., Zhou, X.: Loftr: Detector-free local feature matching with transformers. In: Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. pp. 8922\u20138931 (2021)",
        "ref_ids": [
          "67"
        ]
      },
      "tsf: Transformer-based semantic filter for few-shot learning": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2211.00868",
        "ref_texts": "49. Sun, J., Shen, Z., Wang, Y ., Bao, H., Zhou, X.: Loftr: Detector-free local feature matching with transformers. In: CVPR (2021)",
        "ref_ids": [
          "49"
        ]
      },
      "Eco-tr: Efficient correspondences finding via coarse-to-fine refinement": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2209.12213",
        "ref_texts": "39. Sun, J., Shen, Z., Wang, Y., Bao, H., Zhou, X.: Loftr: Detector-free local feature matching with transformers. In: Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. pp. 8922\u20138931 (2021)",
        "ref_ids": [
          "39"
        ]
      },
      "Is geometry enough for matching in visual localization?": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2203.12979",
        "ref_texts": "69. Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , pages 8922\u20138931, 2021.",
        "ref_ids": [
          "69"
        ]
      },
      "Virtual correspondence: Humans as a cue for extreme-view geometry": {
        "authors": [
          "Chiu Ma",
          "Anqi Joyce",
          "Shenlong Wang",
          "Raquel Urtasun",
          "Antonio Torralba"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2022/papers/Ma_Virtual_Correspondence_Humans_as_a_Cue_for_Extreme-View_Geometry_CVPR_2022_paper.pdf",
        "ref_texts": "[74] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In CVPR , 2021. 2,6,8",
        "ref_ids": [
          "74"
        ]
      },
      "MVSFormer: Multi-view stereo by learning robust image features and temperature-based depth": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2208.02541",
        "ref_texts": "15 Under review as submission to TMLR Yanghao Li, Hanzi Mao, Ross Girshick, and Kaiming He. Exploring plain vision transformer backbones for object detection. arXiv preprint arXiv:2203.16527 , 2022. Tsung-Yi Lin, Piotr Doll\u00e1r, Ross Girshick, Kaiming He, Bharath Hariharan, and Serge Belongie. Feature pyramid networks for object detection. In Proceedings of the IEEE conference on computer vision and pattern recognition , pp. 2117\u20132125, 2017a. Tsung-Yi Lin, Priya Goyal, Ross Girshick, Kaiming He, and Piotr Doll\u00e1r. Focal loss for dense object detection. InProceedings of the IEEE international conference on computer vision , pp. 2980\u20132988, 2017b. Ze Liu, Yutong Lin, Yue Cao, Han Hu, Yixuan Wei, Zheng Zhang, Stephen Lin, and Baining Guo. Swin transformer: Hierarchical vision transformer using shifted windows. In Proceedings of the IEEE/CVF International Conference on Computer Vision , pp. 10012\u201310022, 2021. Keyang Luo, Tao Guan, Lili Ju, Haipeng Huang, and Yawei Luo. P-mvsnet: Learning patch-wise matching confidence aggregation for multi-view stereo. In Proceedings of the IEEE/CVF International Conference on Computer Vision , pp. 10452\u201310461, 2019. Xinjun Ma, Yue Gong, Qirui Wang, Jingwei Huang, Lei Chen, and Fan Yu. Epp-mvsnet: Epipolar-assembling based depth prediction for multi-view stereo. In Proceedings of the IEEE/CVF International Conference on Computer Vision , pp. 5732\u20135740, 2021. Zhenxing Mi, Di Chang, and Dan Xu. Generalized binary search network for highly-efficient multi-view stereo.arXiv preprint arXiv:2112.02338 , 2021. Rui Peng, Rongjie Wang, Zhenyu Wang, Yawen Lai, and Ronggang Wang. Rethinking depth estimation for multi-view stereo: A unified representation and focal loss. arXiv preprint arXiv:2201.01501 , 2022. Prajit Ramachandran, Barret Zoph, and Quoc V Le. Searching for activation functions. arXiv preprint arXiv:1710.05941 , 2017. Joseph Redmon and Ali Farhadi. Yolo9000: better, faster, stronger. In Proceedings of the IEEE conference on computer vision and pattern recognition , pp. 7263\u20137271, 2017. Johannes L Sch\u00f6nberger, Enliang Zheng, Jan-Michael Frahm, and Marc Pollefeys. Pixelwise view selection for unstructured multi-view stereo. In European Conference on Computer Vision , pp. 501\u2013518. Springer, 2016. Thomas Schops, Johannes L Schonberger, Silvano Galliani, Torsten Sattler, Konrad Schindler, Marc Pollefeys, and Andreas Geiger. A multi-view stereo benchmark with high-resolution images and multi-camera videos. InProceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pp. 3260\u20133269, 2017. Noam Shazeer. Glu variants improve transformer. arXiv preprint arXiv:2002.05202 , 2020. Christian Sormann, Patrick Kn\u00f6belreiter, Andreas Kuhn, Mattia Rossi, Thomas Pock, and Friedrich Fraundorfer. Bp-mvsnet: Belief-propagation-layers for multi-view-stereo. In 2020 International Conference on 3D Vision (3DV) , pp. 394\u2013403. IEEE, 2020. Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , pp. 8922\u20138931, 2021. Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, \u0141ukasz Kaiser, and Illia Polosukhin. Attention is all you need. Advances in neural information processing systems , 30, 2017. Fangjinhua Wang, Silvano Galliani, Christoph Vogel, Pablo Speciale, and Marc Pollefeys. Patchmatchnet: Learned multi-view patchmatch stereo. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pp. 14194\u201314203, 2021a."
      },
      "One-inlier is first: Towards efficient position encoding for point cloud registration": {
        "authors": [],
        "url": "https://proceedings.neurips.cc/paper_files/paper/2022/file/2e163450c1ae3167832971e6da29f38d-Paper-Conference.pdf",
        "ref_texts": "[35] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , pages 8922\u20138931, 2021.",
        "ref_ids": [
          "35"
        ]
      },
      "Wt-mvsnet: window-based transformers for multi-view stereo": {
        "authors": [],
        "url": "https://proceedings.neurips.cc/paper_files/paper/2022/file/38e511a690709603d4cc3a1c52b4a9fd-Paper-Conference.pdf"
      },
      "Input-level inductive biases for 3d reconstruction": {
        "authors": [
          "Wang Yifan",
          "Carl Doersch",
          "Relja Arandjelovic",
          "Joao Carreira",
          "Andrew Zisserman"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2022/papers/Yifan_Input-Level_Inductive_Biases_for_3D_Reconstruction_CVPR_2022_paper.pdf",
        "ref_texts": "[51] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In CVPR , pages 8922\u20138931, 2021. 2",
        "ref_ids": [
          "51"
        ]
      },
      "3dg-stfm: 3d geometric guided student-teacher feature matching": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2207.02375",
        "ref_texts": "44. Sun, J., Shen, Z., Wang, Y., Bao, H., Zhou, X.: Loftr: Detector-free local feature matching with transformers. Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition pp. 8922\u20138931 (2021) 1, 2, 4, 6, 7, 9, 10, 11, 12, 13",
        "ref_ids": [
          "44"
        ]
      },
      "Planeformers: From sparse view planes to 3d reconstruction": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2208.04307",
        "ref_texts": "49. Sun, J., Shen, Z., Wang, Y., Bao, H., Zhou, X.: LoFTR: Detector-free local feature matching with transformers. CVPR (2021) 3, 10, 11",
        "ref_ids": [
          "49"
        ]
      },
      "CoVisPose: Co-visibility Pose Transformer for Wide-Baseline Relative Pose Estimation in 360 Indoor Panoramas": {
        "authors": [],
        "url": "https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136920610.pdf",
        "ref_texts": "47. Sun, J., Shen, Z., Wang, Y., Bao, H., Zhou, X.: Loftr: Detector-free local feature matching with transformers. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). pp. 8922\u20138931 (June 2021)",
        "ref_ids": [
          "47"
        ]
      },
      "Fvor: Robust joint shape and pose optimization for few-view object reconstruction": {
        "authors": [
          "Zhenpei Yang",
          "Zhile Ren",
          "Miguel Angel",
          "Zaiwei Zhang",
          "Qi Shan",
          "Qixing Huang"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_FvOR_Robust_Joint_Shape_and_Pose_Optimization_for_Few-View_Object_CVPR_2022_paper.pdf",
        "ref_texts": "[51] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , pages 8922\u20138931, 2021. 3",
        "ref_ids": [
          "51"
        ]
      },
      "Visual localization via few-shot scene region classification": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2208.06933",
        "ref_texts": "[42] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , pages 8922\u20138931, 2021.",
        "ref_ids": [
          "42"
        ]
      },
      "Cats++: Boosting cost aggregation with convolutions and transformers": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2202.06817",
        "ref_texts": "[27] J. Sun, Z. Shen, Y . Wang, H. Bao, and X. Zhou, \u201cLoftr: Detectorfree local feature matching with transformers,\u201d arXiv preprint arXiv:2104.00680 , 2021.",
        "ref_ids": [
          "27"
        ]
      },
      "Semi-supervised keypoint detector and descriptor for retinal image matching": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2207.07932",
        "ref_texts": "29. Sun, J., Shen, Z., Wang, Y., Bao, H., Zhou, X.: LoFTR: Detector-free local feature matching with transformers. In: CVPR (2021) 4",
        "ref_ids": [
          "29"
        ]
      },
      "Global multi-modal 2d/3d registration via local descriptors learning": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2205.03439",
        "ref_texts": "23. Sun, J., Shen, Z., Wang, Y., Bao, H., Zhou, X.: LoFTR: Detector-free local feature matching with transformers. CVPR (2021)",
        "ref_ids": [
          "23"
        ]
      },
      "SIFT matching by context exposed": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2106.09584",
        "ref_texts": "[62] J. Sun, Z. Shen, Y. Wang, H. Bao, and X. Zhou, \u201cLoFTR: Detectorfree local feature matching with transformers,\u201d 2021.",
        "ref_ids": [
          "62"
        ]
      },
      "Semi-supervised learning of semantic correspondence with pseudo-labels": {
        "authors": [
          "Jiwon Kim",
          "Kwangrok Ryoo",
          "Junyoung Seo",
          "Gyuseong Lee",
          "Daehwan Kim",
          "Hansang Cho",
          "Seungryong Kim"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2022/papers/Kim_Semi-Supervised_Learning_of_Semantic_Correspondence_With_Pseudo-Labels_CVPR_2022_paper.pdf",
        "ref_texts": "[59] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 8922\u20138931, 2021. 1",
        "ref_ids": [
          "59"
        ]
      },
      "A transformer-based coarse-to-fine wide-swath SAR image registration method under weak texture conditions": {
        "authors": [
          "Yibo Fan",
          "Feng Wang",
          "Haipeng Wang"
        ],
        "url": "https://www.mdpi.com/2072-4292/14/5/1175/pdf",
        "ref_texts": "37. Sun, J.; Shen, Z.; Wang, Y.; Bao, H.; Zhou, X. LoFTR: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, Montreal, QC, Canada, 11\u201317 October 2021; pp. 8922\u20138931.",
        "ref_ids": [
          "37"
        ]
      },
      "Pump: Pyramidal and uniqueness matching priors for unsupervised learning of local descriptors": {
        "authors": [
          "Jerome Revaud",
          "Vincent Leroy",
          "Philippe Weinzaepfel",
          "Boris Chidlovskii"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2022/papers/Revaud_PUMP_Pyramidal_and_Uniqueness_Matching_Priors_for_Unsupervised_Learning_of_CVPR_2022_paper.pdf",
        "ref_texts": "[59] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In CVPR , 2021. 3",
        "ref_ids": [
          "59"
        ]
      },
      "Laser: Latent space rendering for 2d visual localization": {
        "authors": [
          "Zhixiang Min",
          "Naji Khosravan",
          "Zachary Bessinger",
          "Manjunath Narayana",
          "Sing Bing",
          "Enrique Dunn",
          "Ivaylo Boyadzhiev"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2022/papers/Min_LASER_LAtent_SpacE_Rendering_for_2D_Visual_Localization_CVPR_2022_paper.pdf",
        "ref_texts": "[27] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 8922\u20138931, 2021. 2",
        "ref_ids": [
          "27"
        ]
      },
      "HarrisZ+: Harris corner selection for next-gen image matching pipelines": {
        "authors": [
          "Fabio Bellavia",
          "Dmytro Mishkin"
        ],
        "url": "https://arxiv.org/pdf/2109.12925",
        "ref_texts": "Alcantarilla, P.F., Bartoli, A., Davison, A.J., 2012. KAZE features, in: Proceedings of the European Conference on Computer Vision (ECCV). Barroso-Laguna, A., Riba, E., Ponsa, D., Mikolajczyk, K., 2019. Key.Net: Keypoint detection by handcrafted and learned CNN filters, in: Proceedings of the International Conference on Computer Vision (ICCV). Bay, H., Ess, A., Tuytelaars, T., Gool, L.V ., 2008. SURF: Speeded up robust features. Computer Vision and Image Understanding 110. Beaudet, P., 1978. Rotationally invariant image operators, in: International Joint Conference on Pattern Recognition. Bellavia, F., 2022. SIFT matching by context exposed. IEEE Transactions on Pattern Analysis and Machine Intelligence . Bellavia, F., Tegolo, D., Valenti, C., 2011. Improving Harris corner selection strategy. IET Computer Vision . Brown, M., Szeliski, R., Winder, S., 2005. Multi-image matching using multiscale oriented patches, in: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR). Cavalli, L., Larsson, V ., Oswald, M.R., Sattler, T., Pollefeys, M., 2020. AdaLAM: Revisiting handcrafted outlier detection, in: Proceedings of the European Conference on Computer Vision (ECCV). Chum, O., Werner, T., Matas, J., 2005. Two-View Geometry Estimation Unafiected by a Dominant Plane, in: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR). DeTone, D., Malisiewicz, T., Rabinovich, A., 2018. SuperPoint: Selfsupervised interest point detection and description, in: Proc. of the IEEE Conf. on Computer Vision and Pattern Recognition (CVPR) Workshops. Dusmanu, M., Rocco, I., Pajdla, T., Pollefeys, M., Sivic, J., Torii, A., Sattler, T., 2019. D2-Net: A Trainable CNN for Joint Detection and Description of Local Features, in: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR). Fischler, M., Bolles, R., 1981. Random sample consensus: A paradigm for model fitting with applications to image analysis and automated cartography. Communications of the ACM 24.F\u00a8orstner, W., 1986. A feature based correspondence algorithm for image matching. International Archives of Photogrammetry and Remote Sensing 26. Gonzalez, R.C., Woods, R.E., 2008. Digital image processing. Prentice Hall. Harris, C., Stephens, M., 1988. A combined corner and edge detector, in: Proceedings of the Alvey Vision Conference. Jiang, W., Trulls, E., Hosang, J., Tagliasacchi, A., Yi, K.M., 2021. COTR: Correspondence transformer for matching across images, in: Proceedings of the IEEE International Conference on Computer Vision (ICCV). Jin, Y ., Mishkin, D., Mishchuk, A., Matas, J., Fua, P., Yi, K.M., Trulls, E., 2021. Image matching across wide baselines: From paper to practice. International Journal of Computer Vision 129. Lecca, M., Torresani, A., F.Remondino, 2020. Comprehensive evaluation of image enhancement for unsupervised image description and matching. IET Image Processing . Lindeberg, T., 1994. Scale-Space Theory in Computer Vision. Kluwer Academic Publishers. Lowe, D., 2004. Distinctive image features from scale-invariant keypoints. International Journal of Computer Vision 60. Matas, J., Chum, O., Urban, M., Pajdla, T., 2002. Robust wide baseline stereo from maximally stable extremal regions, in: Proceeding of the British Machine Vision Conference (BMVC). Mikolajczyk, K., Schmid, C., 2004. Scale & a flne invariant interest point detectors. International Journal of Computer Vision 60. Mishchuk, A., Mishkin, D., Radenovic, F., Matas, J., 2017. Working Hard to Know Your Neighbor\u2019s Margins: Local Descriptor Learning Loss, in: Proc. of the Conf. on Neural Information Processing Systems (NeurIPS). Mishkin, D., Matas, J., Perdoch, M., 2015. MODS: Fast and robust method for two-view matching. Computer Vision and Image Understanding . Mishkin, D., Radenovic, F., Matas, J., 2018. Repeatability is Not Enough: Learning A flne Regions via Discriminability, in: Proceedings of the European Conference on Computer Vision (ECCV). Morel, J., Yu, G., 2009. ASIFT: A new framework for fully a flne invariant image comparison. SIAM Journal on Imaging Sciences 2. Mur-Artal, R., Montiel, J., Tardos, J., 2015. ORB-SLAM: a versatile and accurate monocular slam system. IEEE Transactions on Robotics 31. Pultar, M., 2020. Improving the HardNet descriptor. arXiv ePrint 2007.09699 . Riba, E., Mishkin, D., Ponsa, D., Rublee, E., Bradski, G., 2020. Kornia: an open source di fierentiable computer vision library for pytorch, in: Proc. of the IEEE /CVF Winter Conf. on Applications of Computer Vision (WACV). Rosten, E., Porter, R., Drummond, T., 2010. Faster and better: A machine learning approach to corner detection. IEEE Transactions on Pattern Analysis and Machine Intelligence 32. Sarlin, P.E., DeTone, D., Malisiewicz, T., Rabinovich, A., 2020. SuperGlue: Learning feature matching with graph neural networks, in: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR). Sch\u00a8onberger, J.L., Frahm, J.M., 2016. Structure-from-Motion revisited, in: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR). Shi, J., Tomasi, C., 1994. Good features to track, in: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR). Sun, J., Shen, Z., Wang, Y ., Bao, H., Zhou, X., 2021. LoFTR: Detector-free local feature matching with transformers, in: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR). Szeliski, R., 2021. Computer Vision: Algorithms and Applications. Springer. Tian, Y ., Balntas, V ., Ng, T., Laguna, A.B., Demiris, Y ., Mikolajczyk, K., 2020. D2D: Keypoint extraction with describe to detect approach, in: Proceedings of the Asian Conference on Computer Vision (ACCV). Truong, P., Danelljan, M., Gool, L.V ., Timofte, R., 2021. PDC-Net: Learning accurate dense correspondences and when to trust them, in: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR). Tuytelaars, T., Mikolajczyk, K., 2008. Local invariant feature detectors: a survey. Foundations and Trends in Computer Graphics and Vision 3. Tyszkiewicz, M.J., Fua, P., Trulls, E., 2020. DISK: Learning local features with policy gradient, in: Proceedings of the Conference on Neural Information Processing Systems (NeurIPS). Verdie, Y ., Yi, K.M., Fua, P., Lepetit, V ., 2015. TILDE: A temporally invariant learned detector., in: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR). Yi, K.M., Trulls, E., Lepetit, V ., Fua, P., 2016. LIFT: Learned invariant feature transform, in: Proc. of the European Conf. on Computer Vision (ECCV). Zhang, W., Sun, C., 2020. Corner detection using multi-directional structure tensor with multiple scales. International Journal of Computer Vision ."
      },
      "Context-aware sequence alignment using 4d skeletal augmentation": {
        "authors": [
          "Taein Kwon",
          "Bugra Tekin",
          "Siyu Tang",
          "Marc Pollefeys"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2022/papers/Kwon_Context-Aware_Sequence_Alignment_Using_4D_Skeletal_Augmentation_CVPR_2022_paper.pdf",
        "ref_texts": "[53] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 8922\u20138931, 2021. 3, 4",
        "ref_ids": [
          "53"
        ]
      },
      "DenseGAP: graph-structured dense correspondence learning with anchor points": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2112.06910",
        "ref_texts": "[4] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. LoFTR: Detector-free local feature matching with transformers. CVPR , 2021.",
        "ref_ids": [
          "4"
        ]
      },
      "Efficient large-scale localization by global instance recognition": {
        "authors": [
          "Fei Xue",
          "Ignas Budvytis",
          "Daniel Olmeda",
          "Roberto Cipolla"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2022/papers/Xue_Efficient_Large-Scale_Localization_by_Global_Instance_Recognition_CVPR_2022_paper.pdf",
        "ref_texts": "[49] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. LoFTR: Detector-free local feature matching with transformers. In CVPR , 2021. 2, 5, 6",
        "ref_ids": [
          "49"
        ]
      },
      "Salve: Semantic alignment verification for floorplan reconstruction from sparse panoramas": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2406.19390?",
        "ref_texts": "57. Sun, J., Shen, Z., Wang, Y ., Bao, H., Zhou, X.: Loftr: Detector-free local feature matching with transformers. In: CVPR (2021)",
        "ref_ids": [
          "57"
        ]
      },
      "Data association between event streams and intensity frames under diverse baselines": {
        "authors": [],
        "url": "https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136670071.pdf",
        "ref_texts": "52. Sun, J., Shen, Z., Wang, Y., Bao, H., Zhou, X.: Loftr: Detector-free local feature matching with transformers. In: Proc. of Conference on Computer Vision and Pattern Recognition (CVPR). pp. 8922\u20138931 (2021)",
        "ref_ids": [
          "52"
        ]
      },
      "OpenGlue: Open source graph neural net based pipeline for image matching": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2204.08870",
        "ref_texts": "[45] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 8922\u20138931, 2021. 6",
        "ref_ids": [
          "45"
        ]
      },
      "Psmnet: Position-aware stereo merging network for room layout estimation": {
        "authors": [
          "Haiyan Wang",
          "Will Hutchcroft",
          "Yuguang Li",
          "Zhiqiang Wan",
          "Ivaylo Boyadzhiev",
          "Yingli Tian",
          "Sing Bing"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_PSMNet_Position-Aware_Stereo_Merging_Network_for_Room_Layout_Estimation_CVPR_2022_paper.pdf",
        "ref_texts": "[33] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. LoFTR: Detector-free local feature matching with transformers. CVPR , 2021. 5",
        "ref_ids": [
          "33"
        ]
      },
      "An intelligent weighted object detector for feature extraction to enrich global image information": {
        "authors": [
          "Lingyu Yan",
          "Ke Li",
          "Rong Gao",
          "Chunzhi Wang",
          "Neal Xiong"
        ],
        "url": "https://www.mdpi.com/2076-3417/12/15/7825/pdf",
        "ref_texts": "34. Sun, J.; Shen, Z.; Wang, Y.; Bao, H.; Zhou, X. LoFTR: Detector-Free Local Feature Matching with Transformers. arXiv 2021 , arXiv:2104.00680.",
        "ref_ids": [
          "34"
        ]
      },
      "Camera pose estimation and localization with active audio sensing": {
        "authors": [],
        "url": "https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136970266.pdf",
        "ref_texts": "86. Sun, J., Shen, Z., Wang, Y., Bao, H., Zhou, X.: LoFTR: Detector-free local feature matching with transformers. CVPR (2021)",
        "ref_ids": [
          "86"
        ]
      },
      "Pose refinement with joint optimization of visual points and lines": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2110.03940",
        "ref_texts": "[7] J. Sun, Z. Shen, Y . Wang, H. Bao, and X. Zhou, \u201cLoftr: Detector-free local feature matching with transformers,\u201d CoRR , vol. abs/2104.00680, 2021.",
        "ref_ids": [
          "7"
        ]
      },
      "Superpoint features in endoscopy": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2203.04302",
        "ref_texts": "[28] Sun, J., Shen, Z., Wang, Y ., Bao, H., Zhou, X.: Loftr: Detector-free local feature matching with transformers. In: CVPR. IEEE (2021)",
        "ref_ids": [
          "28"
        ]
      },
      "Check and link: Pairwise lesion correspondence guides mammogram mass detection": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2209.05809",
        "ref_texts": "32. Sun, J., Shen, Z., Wang, Y., Bao, H., Zhou, X.: LoFTR: Detector-free local feature matching with transformers. In: CVPR (2021) 5",
        "ref_ids": [
          "32"
        ]
      },
      "Learning co-segmentation by segment swapping for retrieval and discovery": {
        "authors": [
          "Xi Shen",
          "Alexei A. Efros",
          "Armand Joulin",
          "Mathieu Aubry"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2022W/IMW/papers/Shen_Learning_Co-Segmentation_by_Segment_Swapping_for_Retrieval_and_Discovery_CVPRW_2022_paper.pdf",
        "ref_texts": "[58] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. arXiv , 2021. 2",
        "ref_ids": [
          "58"
        ]
      },
      "Learning a task-specific descriptor for robust matching of 3D point clouds": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2210.14899",
        "ref_texts": "[28] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 8922\u20138931, 2021. 2",
        "ref_ids": [
          "28"
        ]
      },
      "Learning soft estimator of keypoint scale and orientation with probabilistic covariant loss": {
        "authors": [
          "Pei Yan",
          "Yihua Tan",
          "Shengzhou Xiong",
          "Yuan Tai",
          "Yansheng Li"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2022/papers/Yan_Learning_Soft_Estimator_of_Keypoint_Scale_and_Orientation_With_Probabilistic_CVPR_2022_paper.pdf",
        "ref_texts": "[37] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In Proceedings of the Conference on Computer Vision and Pattern Recognition , pages 8922\u2013",
        "ref_ids": [
          "37"
        ]
      },
      "Global-aware registration of less-overlap RGB-D scans": {
        "authors": [
          "Che Sun",
          "Yunde Jia",
          "Yi Guo",
          "Yuwei Wu"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2022/papers/Sun_Global-Aware_Registration_of_Less-Overlap_RGB-D_Scans_CVPR_2022_paper.pdf",
        "ref_texts": "[25] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 8922\u2013",
        "ref_ids": [
          "25"
        ]
      },
      "Scalenet: A shallow architecture for scale estimation": {
        "authors": [
          "Axel Barroso",
          "Yurun Tian",
          "Krystian Mikolajczyk"
        ],
        "url": "http://openaccess.thecvf.com/content/CVPR2022/papers/Barroso-Laguna_ScaleNet_A_Shallow_Architecture_for_Scale_Estimation_CVPR_2022_paper.pdf",
        "ref_texts": "[45] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 8922\u20138931, 2021. 2, 6",
        "ref_ids": [
          "45"
        ]
      },
      "Rendernet: Visual relocalization using virtual viewpoints in large-scale indoor environments": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2207.12579",
        "ref_texts": "[30] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. arXiv preprint arXiv:2104.00680 , 2021.",
        "ref_ids": [
          "30"
        ]
      },
      "C-3PO: Towards rotation equivariant feature detection and description": {
        "authors": [],
        "url": "https://openreview.net/pdf?id=dXouQ9ubkPJ",
        "ref_texts": "26. Sun, J., Shen, Z., Wang, Y., Bao, H., Zhou, X.: Loftr: Detector-free local feature matching with transformers. In: Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. pp. 8922\u20138931 (2021) 4",
        "ref_ids": [
          "26"
        ]
      },
      "A multi-view thermal\u2013visible image dataset for cross-spectral matching": {
        "authors": [
          "Yuxiang Liu",
          "Yu Liu",
          "Shen Yan",
          "Chen Chen",
          "Jikun Zhong",
          "Yang Peng",
          "Maojun Zhang"
        ],
        "url": "https://www.mdpi.com/2072-4292/15/1/174/pdf",
        "ref_texts": "33. Sun, J.; Shen, Z.; Wang, Y.; Bao, H.; Zhou, X. LoFTR: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, Nashville, TN, USA, 20\u201325 June 2021; pp. 8922\u20138931.",
        "ref_ids": [
          "33"
        ]
      },
      "A large-scale invariant matching method based on DeepSpace-ScaleNet for small celestial body exploration": {
        "authors": [
          "Mingrui Fan",
          "Wenlong Lu",
          "Wenlong Niu",
          "Xiaodong Peng",
          "Zhen Yang"
        ],
        "url": "https://www.mdpi.com/2072-4292/14/24/6339/pdf",
        "ref_texts": "30. Sun, J.; Shen, Z.; Wang, Y.; Bao, H.; Zhou, X. LoFTR: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, Nashville, TN, USA, 21\u201324 June 2021; pp. 8922\u20138931.",
        "ref_ids": [
          "30"
        ]
      },
      "RWT-SLAM: Robust visual SLAM for highly weak-textured environments": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2207.03539",
        "ref_texts": "[13] Jiang W, Trulls E, Hosang J, et al. Cotr: Correspondence transformer for matching across images[C]//Proceedings of the IEEE/CVF International Conference on Computer Vision. 2021: 6207-6217.[14] Sun J, Shen Z, Wang Y , et al. LoFTR: Detector-free local feature matching with transformers[C]//Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. 2021: 8922-8931.",
        "ref_ids": [
          "13",
          "C",
          "14",
          "C"
        ]
      },
      "Improving feature-based visual localization by geometry-aided matching": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2211.08712",
        "ref_texts": "[20] P.-E. Sarlin, D. DeTone, T. Malisiewicz, and A. Rabinovich, \u201cSuperGlue: Learning feature matching with graph neural networks,\u201d in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2020, pp. 4938\u20134947.[21] J. Sun, Z. Shen, Y . Wang, H. Bao, and X. Zhou, \u201cLoftr: Detectorfree local feature matching with transformers,\u201d in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , 2021, pp. 8922\u20138931.",
        "ref_ids": [
          "20",
          "21"
        ]
      },
      "Multiview image matching of optical satellite and UAV based on a joint description neural network": {
        "authors": [
          "Chuan Xu",
          "Chang Liu",
          "Hongli Li",
          "Zhiwei Ye",
          "Haigang Sui",
          "Wei Yang"
        ],
        "url": "https://www.mdpi.com/2072-4292/14/4/838/pdf",
        "ref_texts": "33. Sun, J.; Shen, Z.; Wang, Y.; Bao, H.; Zhou, X. LoFTR: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, Nashville, TN, USA, 19\u201325 June 2021; pp. 8922\u20138931.",
        "ref_ids": [
          "33"
        ]
      },
      "Rethinking low-level features for interest point detection and description": {
        "authors": [
          "Changhao Wang",
          "Guanwen Zhang",
          "Zhengyun Cheng",
          "Wei Zhou"
        ],
        "url": "https://openaccess.thecvf.com/content/ACCV2022/papers/Wang_Rethinking_Low-level_Features_for_Interest_Point_Detection_and_Description_ACCV_2022_paper.pdf",
        "ref_texts": "33. Sun, J., Shen, Z., Wang, Y., Bao, H., Zhou, X.: Loftr: Detector-free local feature matching with transformers. In: CVPR (2021)",
        "ref_ids": [
          "33"
        ]
      },
      "A fast and robust heterologous image matching method for visual geo-localization of low-altitude UAVs": {
        "authors": [
          "Haigang Sui",
          "Jiajie Li",
          "Junfeng Lei",
          "Chang Liu",
          "Guohua Gou"
        ],
        "url": "https://www.mdpi.com/2072-4292/14/22/5879/pdf",
        "ref_texts": "35. Sun, J.; Shen, Z.; Wang, Y.; Bao, H.; Zhou, X. LoFTR: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR); IEEE Xplore: Washington, DC, USA, 2021; pp. 8922\u20138931.",
        "ref_ids": [
          "35"
        ]
      },
      "Beyond the CLS Token: Image Reranking using Pretrained Vision Transformers.": {
        "authors": [],
        "url": "https://bmvc2022.mpi-inf.mpg.de/0080.pdf",
        "ref_texts": "[27] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , pages 8922\u20138931, 2021.",
        "ref_ids": [
          "27"
        ]
      },
      "Recursive deformable image registration network with mutual attention": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2206.01863",
        "ref_texts": "19. Sun, J., Shen, Z., Wang, Y ., Bao, H., Zhou, X.: Loftr: Detector-free local feature matching with transformers. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 8922\u20138931 (2021)",
        "ref_ids": [
          "19"
        ]
      },
      "GRelPose: Generalizable end-to-end relative camera pose regression": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2211.14950",
        "ref_texts": "[53] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. LoFTR: Detector-free local feature matching with transformers. CVPR , 2021. 1, 2, 3, 4, 6, 7, 8, 12",
        "ref_ids": [
          "53"
        ]
      },
      "DAN-superPoint: Self-supervised feature point detection algorithm with dual attention network": {
        "authors": [
          "Zhaoyang Li",
          "Jie Cao",
          "Qun Hao",
          "Xue Zhao",
          "Yaqian Ning",
          "Dongxing Li"
        ],
        "url": "https://www.mdpi.com/1424-8220/22/5/1940/pdf",
        "ref_texts": ""
      },
      "Level set-based camera pose estimation from multiple 2D/3D ellipse-ellipsoid correspondences": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2207.07953",
        "ref_texts": "[9] J. Sun, Z. Shen, Y . Wang, H. Bao, and X. Zhou, \u201cLoftr: Detector-free local feature matching with transformers,\u201d in CVPR , 2021.",
        "ref_ids": [
          "9"
        ]
      },
      "Lightweight monocular depth estimation with an edge guided network": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2209.14829",
        "ref_texts": "[25] J. Sun, Z. Shen, Y . Wang, H. Bao, and X. Zhou, \u201cLoFTR: Detectorfree local feature matching with transformers,\u201d in CVPR , 2021, pp.",
        "ref_ids": [
          "25"
        ]
      },
      "Learning geometric feature embedding with transformers for image matching": {
        "authors": [
          "Xiaohu Nan",
          "Lei Ding"
        ],
        "url": "https://www.mdpi.com/1424-8220/22/24/9882/pdf",
        "ref_texts": "27. Sun, J.; Shen, Z.; Wang, Y.; Bao, H.; Zhou, X. LoFTR: Detector-Free Local Feature Matching with Transformers. In Proceedings of the CVPR, Nashville, TN, USA, 19\u201321 June 2021.",
        "ref_ids": [
          "27"
        ]
      },
      "Integrative feature and cost aggregation with transformers for dense correspondence": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2209.08742",
        "ref_texts": "[68] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , pages 8922\u20138931, 2021.",
        "ref_ids": [
          "68"
        ]
      },
      "A Dual-Generator Translation Network Fusing Texture and Structure Features for SAR and Optical Image Matching": {
        "authors": [
          "Han Nie",
          "Zhitao Fu",
          "Hui Tang",
          "Ziqian Li",
          "Sijing Chen",
          "Leiguang Wang"
        ],
        "url": "https://www.mdpi.com/2072-4292/14/12/2946/pdf",
        "ref_texts": "9. Sun, J.; Shen, Z.; Wang, Y.; Bao, H.; Zhou, X. LoFTR: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, Nashville, TN, USA, 20\u201325 June 2021; pp. 8922\u20138931.",
        "ref_ids": [
          "9"
        ]
      },
      "SIM2E: Benchmarking the group equivariant capability of correspondence matching algorithms": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2208.09896",
        "ref_texts": "25. Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. LoFTR: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , pages 8922{",
        "ref_ids": [
          "25"
        ]
      },
      "A Method for Detecting Feature-Sparse Regions and Matching Enhancement": {
        "authors": [
          "Longhao Wang",
          "Chaozhen Lan",
          "Beibei Wu",
          "Tian Gao",
          "Zijun Wei",
          "Fushan Yao"
        ],
        "url": "https://www.mdpi.com/2072-4292/14/24/6214/pdf",
        "ref_texts": "21. Sun, J.; Shen, Z.; Wang, Y.; Bao, H.; Zhou, X. LoFTR: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, Montreal, QC, Canada, 11\u201318 October 2021; pp. 8922\u20138931.",
        "ref_ids": [
          "21"
        ]
      },
      "Visual Localization and Target Perception Based on Panoptic Segmentation": {
        "authors": [
          "Kefeng Lv",
          "Yongsheng Zhang",
          "Ying Yu",
          "Zhenchao Zhang",
          "Lei Li"
        ],
        "url": "https://www.mdpi.com/2072-4292/14/16/3983/pdf",
        "ref_texts": "23. Sun, J.; Shen, Z.; Wang, Y.; Bao, H.; Zhou, X. LoFTR: Detector-Free Local Feature Matching with Transformers. In Proceedings of the 2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), Nashville, TN, USA, 20\u201325 June 2021; pp. 8918\u20138927.",
        "ref_ids": [
          "23"
        ]
      },
      "Object-guided day-night visual localization in urban scenes": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2202.04445",
        "ref_texts": "[46] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 8922\u20138931, 2021. 2, 4, 6",
        "ref_ids": [
          "46"
        ]
      },
      "RelMobNet: End-to-end relative camera pose estimation using a robust two-stage training": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2202.12838",
        "ref_texts": "33. Sun, J., Shen, Z., Wang, Y., Bao, H., Zhou, X.: Loftr: Detector-free local feature matching with transformers. In: Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. pp. 8922\u20138931 (2021)",
        "ref_ids": [
          "33"
        ]
      },
      "AgentI2P: Optimizing Image-to-Point Cloud Registration via Behaviour Cloning and Reinforcement Learning": {
        "authors": [
          "Shen Yan",
          "Maojun Zhang",
          "Yang Peng",
          "Yu Liu",
          "Hanlin Tan"
        ],
        "url": "https://www.mdpi.com/2072-4292/14/24/6301/pdf",
        "ref_texts": "19. Sun, J.; Shen, Z.; Wang, Y.; Bao, H.; Zhou, X. LoFTR: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, Nashville, TN, USA, 20\u201325 June 2021; pp. 8922\u20138931. Remote Sens. 2022 ,14, 6301 17 of 18",
        "ref_ids": [
          "19"
        ]
      },
      "D-inloc++: Indoor localization in dynamic environments": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2209.10185",
        "ref_texts": "49. Sun, J., Shen, Z., Wang, Y., Bao, H., Zhou, X.: Loftr: Detector-free local feature matching with transformers. In: Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. pp. 8922{8931 (2021)",
        "ref_ids": [
          "49"
        ]
      },
      "A real-time fusion framework for long-term visual localization": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2210.09757",
        "ref_texts": "[14] J. Sun, Z. Shen, Y . Wang, H. Bao, and X. Zhou, \u201cLoftr: Detectorfree local feature matching with transformers,\u201d in Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , pp. 8922\u20138931, 2021.",
        "ref_ids": [
          "14"
        ]
      },
      "Residual aligner network": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2203.04290",
        "ref_texts": "25. Sun, J., Shen, Z., Wang, Y ., Bao, H., Zhou, X.: Loftr: Detector-free local feature matching with transformers. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 8922\u20138931 (2021) 2, 10",
        "ref_ids": [
          "25"
        ]
      },
      "Danish airs and grounds: A dataset for aerial-to-street-level place recognition and localization": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2202.01821",
        "ref_texts": "[26] J. Sun, Z. Shen, Y . Wang, H. Bao, and X. Zhou, \u201cLoFTR: Detector-free local feature matching with transformers,\u201d CVPR , 2021.",
        "ref_ids": [
          "26"
        ]
      },
      "Revisiting the receptive field of conv-gru in droid-slam": {
        "authors": [
          "Antyanta Bangunharcana",
          "Soohyun Kim",
          "Soo Kim"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2022W/VOCVALC/papers/Bangunharcana_Revisiting_the_Receptive_Field_of_Conv-GRU_in_DROID-SLAM_CVPRW_2022_paper.pdf",
        "ref_texts": "[44] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , pages 8922\u20138931, 2021.",
        "ref_ids": [
          "44"
        ]
      },
      "HM3D-ABO: A Photo-realistic Dataset for Object-centric Multi-view 3D Reconstruction": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2206.12356",
        "ref_texts": "[34] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , pages 8922\u20138931, 2021. 2",
        "ref_ids": [
          "34"
        ]
      },
      "Sa-dnet: A on-demand semantic object registration network adapting to non-rigid deformation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2210.09900",
        "ref_texts": "[18] J. Sun, Z. Shen, Y . Wang, H. Bao, and X. Zhou, \u201cLoftr: Detectorfree local feature matching with transformers,\u201d in Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , 2021, pp. 8922\u20138931.[19] F. L. Bookstein, \u201cThin-plate splines and the atlas problem for biomedical images,\u201d in Biennial international conference on information processing in medical imaging . Springer, 1991, pp. 326\u2013342.",
        "ref_ids": [
          "18",
          "19"
        ]
      },
      "A Lightweight Domain Adaptive Absolute Pose Regressor Using Barlow Twins Objective": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2211.10963",
        "ref_texts": "[59] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , pages 8922\u20138931, 2021. 16",
        "ref_ids": [
          "59"
        ]
      },
      "SuperGF: Unifying Local and Global Features for Visual Localization": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2212.13105",
        "ref_texts": "[40] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , pages 8922\u20138931, 2021. 3",
        "ref_ids": [
          "40"
        ]
      },
      "A Hybrid Deep Feature-Based Deformable Image Registration Method for Pathology Images": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2208.07655",
        "ref_texts": "[19] Sun, J., Shen, Z., Wang, Y., Bao, H. & Zhou, X. LoFTR: Detector-free local feature matching with transformers. Proceedings Of The IEEE/CVF Conference On Computer Vision And Pattern Recognition . pp. 8922-8931",
        "ref_ids": [
          "19"
        ]
      },
      "Real-time local feature with global visual information enhancement": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2211.10981",
        "ref_texts": "[24] J. Sun, Z. Shen, Y . Wang, H. Bao, and X. Zhou, \u201cLoFTR: Detector-free local feature matching with transformers,\u201d Proceedings of IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) , 2021.",
        "ref_ids": [
          "24"
        ]
      },
      "Nonlinear intensity sonar image matching based on deep convolution features": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2111.15514",
        "ref_texts": "[20] J. Sun, Z. Shen, Y. Wang, H. Bao, and X. Zhou, \"LoF TR: Detector-Free Local Feature Matching with Transformers,\" 2021. ",
        "ref_ids": [
          "20"
        ]
      },
      "DDM-NET: End-to-end learning of keypoint feature Detection, Description and Matching for 3D localization": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2212.04575",
        "ref_texts": "[30] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , pages 8922\u20138931, 2021.",
        "ref_ids": [
          "30"
        ]
      },
      "U (1) Symmetry-breaking Observed in Generic CNN Bottleneck Layers": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2206.02220",
        "ref_texts": "[73] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. arXiv preprint arXiv:2104.00680 , 2021.",
        "ref_ids": [
          "73"
        ]
      },
      "Homography Augmented Momentum Contrastive Learning for SAR Image Retrieval": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2109.10329",
        "ref_texts": "[34] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. arXiv preprint arXiv:2104.00680 , 2021.",
        "ref_ids": [
          "34"
        ]
      },
      "Framework for 2D Ad placements in LinearTV": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2212.02450",
        "ref_texts": "8089, 2020. J. Sun, Z. Shen, Y. Wang, H. Bao, and X. Zhou. Loftr: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , pages 8922{8931, 2021. R. Szeliski. Computer vision: algorithms and applications . Springer Science & Business Media, 2010. B. Triggs. Autocalibration from planar scenes. In European conference on computer vision , pages 89{105. Springer, 1998. S. van der Walt, J. L. Sch\u007f onberger, J. Nunez-Iglesias, F. Boulogne, J. D. Warner, N. Yager, E. Gouillart, T. Yu, and the scikit-image contributors. scikit-image: image processing in Python. PeerJ , 2:e453, 6 2014. ISSN 2167-8359. doi: 10.7717/peerj.453. URL https: //doi.org/10.7717/peerj.453 . Z. Wang, J. Philion, S. Fidler, and J. Kautz. Learning indoor inverse rendering with 3d spatially-varying lighting. In Proceedings of the IEEE/CVF International Conference on Computer Vision , pages 12538{12547, 2021. Y. Wu, A. Kirillov, F. Massa, W.-Y. Lo, and R. Girshick. Detectron2. https://github. com/facebookresearch/detectron2 , 2019. Y. Xu, W. Xu, D. Cheung, and Z. Tu. Line segment detection using transformers without edges. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 4257{4266, 2021. F. Yang and Z. Zhou. Recovering 3d planes from a single image via convolutional neural networks. In Proceedings of the European Conference on Computer Vision (ECCV) , pages 85{100, 2018. Z. Yu, J. Zheng, D. Lian, Z. Zhou, and S. Gao. Single-image piece-wise planar 3d reconstruction via associative embedding. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 1029{1037, 2019."
      },
      "Deep Dense Local Feature Matching and Vehicle Removal for Indoor Visual Localization": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2205.12544",
        "ref_texts": "[15] J. Sun, Z. Shen, Y . Wang, H. Bao, and X. Zhou, \u201cLoftr: Detectorfree local feature matching with transformers,\u201d in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , 2021, pp. 8922\u20138931.",
        "ref_ids": [
          "15"
        ]
      },
      "CS 6384 Computer Vision Project Proposal Description": {
        "authors": [],
        "url": "https://yuxng.github.io/Courses/CS6384Spring2022/CS_6384_Project_Proposal.pdf",
        "ref_texts": "[48] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , pages 8922\u20138931, 2021.",
        "ref_ids": [
          "48"
        ]
      },
      "Feature Fusion Method for Low-Illumination Images": {
        "authors": [],
        "url": "http://www.csroc.org.tw/journal/JOC33-6/JOC3306-14.pdf",
        "ref_texts": "[20]J. Sun, Z. Shen, Y . Wang, H. Bao, X. Zhou, LoFTR: Detector-free local feature matching with transformers, in: Proc. IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2021.",
        "ref_ids": [
          "20"
        ]
      },
      "Monocular 3D Object Detection and 3D Multi-Object Tracking for Autonomous Vehicles": {
        "authors": [],
        "url": "https://tspace.library.utoronto.ca/bitstream/1807/110712/4/Reading_Cody_Ariel_202203_MAS_thesis.pdf",
        "ref_texts": "[94] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2021.",
        "ref_ids": [
          "94"
        ]
      },
      "DIAR: Deep Image Alignment and Reconstruction Using Swin Transformers": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2310.11605",
        "ref_texts": "18. Sun, J., Shen, Z., Wang, Y., Bao, H., Zhou, X.: Loftr: Detector-free local feature matching with transformers. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). pp. 8922\u20138931 (June 2021)",
        "ref_ids": [
          "18"
        ]
      },
      "Detector-Free Dense Feature Matching for Fetoscopic Mosaicking": {
        "authors": [],
        "url": "https://discovery.ucl.ac.uk/id/eprint/10157679/1/HSMR_LOFTR_SB.pdf",
        "ref_texts": "[4] J. Sun, Z. Shen, Y. Wang, H. Bao, and X. Zhou, \u201cLoFTR: Detector-free local feature matching with transformers,\u201d in Conference on Computer Vision and Pattern Recognition , 2021, pp.",
        "ref_ids": [
          "4"
        ]
      },
      "Multi-Modal Retinal Image Registration via Deep Neural Networks": {
        "authors": [],
        "url": "https://escholarship.org/content/qt5062x505/qt5062x505_noSplash_f5689e65c84247e9e38e7852da3da20d.pdf",
        "ref_texts": "[93] J. Sun, Z. Shen, Y . Wang, H. Bao, and X. Zhou, \u201cLoftr: Detector-free local feature matching with transformers,\u201d in 2021 IEEE/CVF Conference onComputer Vision andPattern Recognition (CVPR), 2021, pp. 8918\u20138927.",
        "ref_ids": [
          "93"
        ]
      },
      "Visual place recognition for unmanned vehicles in city-scale challenging environments": {
        "authors": [],
        "url": "https://dr.ntu.edu.sg/bitstream/10356/165647/2/PGH_thesis.pdf",
        "ref_texts": "[46] J. Sun, Z. Shen, Y. Wang, H. Bao, and X. Zhou, \u201cLoftr: Detector-free local feature matching with transformers,\u201d in 2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) , 2021.",
        "ref_ids": [
          "46"
        ]
      },
      "Global-Local Bayesian Transformer for Semantic Correspondence": {
        "authors": [],
        "url": "https://openreview.net/pdf?id=aGkxJtOxKx",
        "ref_texts": "11 Under review as a conference paper at ICLR 2023 I. Rocco, R. Arandjelovi \u00b4c, and J. Sivic. Convolutional neural network architecture for geometric matching. In CVPR , 2017. I. Rocco, R. Arandjelovi \u00b4c, and J. Sivic. End-to-end weakly-supervised semantic alignment. In ECCV , 2018a. I. Rocco, M. Cimpoi, R. Arandjelovi \u00b4c, A. Torii, T. Pajdla, and J. Sivic. Neighbourhood consensus networks. In NIPS , 2018b. I. Rocco, R. Arandjelovi \u00b4c, and J. Sivic. Efficient neighbourhood consensus networks via submanifold sparse convolutions. In ECCV , 2020. Ethan Rublee, Vincent Rabaud, Kurt Konolige, and Gary Bradski. Orb: An efficient alternative to sift or surf. In ICCV , 2011. Paul Hongsuck Seo, Jongmin Lee, Deunsol Jung, Bohyung Han, and Minsu Cho. Attentive semantic alignment with offset-aware correlation kernels. In ECCV , 2018. Parikshit Shah, Nikhil Rao, and Gongguo Tang. Sparse and low-rank tensor decomposition. In NIPS , 2015. Kumar Shridhar, Felix Laumann, and Marcus Liwicki. A comprehensive guide to bayesian convolutional neural network with variational inference. arXiv , 2019. Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. LoFTR: Detector-free local feature matching with transformers. In CVPR , 2021. Tatsunori Taniai, Sudipta N. Sinha, and Yoichi Sato. Joint recovery of dense correspondence and cosegmentation in two images. In CVPR , 2016. Engin Tola, Vincent Lepetit, and Pascal Fua. Daisy: An efficient dense descriptor applied to wide-baseline stereo. TPAMI , 2010. Prune Truong, Martin Danelljan, Luc V Gool, and Radu Timofte. Gocor: Bringing globally optimized correspondence volumes into your neural network. In NIPS , 2020a. Prune Truong, Martin Danelljan, and Radu Timofte. Glu-net: Global-local universal network for dense flow and correspondences. In CVPR , 2020b. Prune Truong, Martin Danelljan, Fisher Yu, and Luc Van Gool. Probabilistic warp consistency for weakly-supervised semantic correspondences. In CVPR , 2022. Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, \u0141ukasz Kaiser, and Illia Polosukhin. Attention is all you need. In NIPS , 2017. Guo-Sen Xie, Huan Xiong, Jie Liu, Yazhou Yao, and Ling Shao. Few-shot semantic segmentation with cyclic memory network. In ICCV , 2021. Gengshan Yang and Deva Ramanan. V olumetric correspondence networks for optical flow. In NIPS , 2019. Kun Yuan, Shaopeng Guo, Ziwei Liu, Aojun Zhou, Fengwei Yu, and Wei Wu. Incorporating convolution designs into visual transformers. In ICCV , 2021. Shujian Zhang, Xinjie Fan, Bo Chen, and Mingyuan Zhou. Bayesian attention belief networks. In ICML , 2021. Dongyang Zhao, Ziyang Song, Zhenghao Ji, Gangming Zhao, Weifeng Ge, and Yizhou Yu. Multiscale matching networks for semantic correspondence. In ICCV , 2021."
      },
      "Supplementary Material for Is Geometry Enough for Matching in Visual Localization?": {
        "authors": [],
        "url": "https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136700402-supp.pdf",
        "ref_texts": "24. Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , pages 8922\u20138931, 2021.",
        "ref_ids": [
          "24"
        ]
      },
      "Video-based 3D Object Detection with Learnable Object-Centric Global Optimization": {
        "authors": [],
        "url": "https://openreview.net/pdf?id=G7_LoXdE2Oe",
        "ref_texts": "11 Under review as a conference paper at ICLR 2023 Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , pp. 8922\u20138931, 2021. Pei Sun, Henrik Kretzschmar, Xerxes Dotiwalla, Aurelien Chouard, Vijaysai Patnaik, Paul Tsui, James Guo, Yin Zhou, Yuning Chai, Benjamin Caine, et al. Scalability in perception for autonomous driving: Waymo open dataset. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , pp. 2446\u20132454, 2020. Chengzhou Tang and Ping Tan. BA-net: Dense bundle adjustment networks. In International Conference on Learning Representations , 2019. Bill Triggs, Philip F McLauchlan, Richard I Hartley, and Andrew W Fitzgibbon. Bundle adjustment\u2014a modern synthesis. In International workshop on vision algorithms , pp. 298\u2013372. Springer, 1999. Li Wang, Li Zhang, Yi Zhu, Zhi Zhang, Tong He, Mu Li, and Xiangyang Xue. Progressive coordinate transforms for monocular 3d object detection. Advances in Neural Information Processing Systems , 34, 2021a. Qitai Wang, Yuntao Chen, Ziqi Pang, Naiyan Wang, and Zhaoxiang Zhang. Immortal tracker: Tracklet never dies. arXiv preprint arXiv:2111.13672 , 2021b. Tai Wang, Jiangmiao Pang, and Dahua Lin. Monocular 3d object detection with depth from motion. InEuropean Conference on Computer Vision (ECCV) , 2022a. Zengran Wang, Chen Min, Zheng Ge, Yinhao Li, Zeming Li, Hongyu Yang, and Di Huang. Sts: Surround-view temporal stereo for multi-view 3d detection. arXiv preprint arXiv:2208.10145 , 2022b. Haiping Wu, Yuntao Chen, Naiyan Wang, and Zhaoxiang Zhang. Sequence level semantics aggregation for video object detection. In Proceedings of the IEEE International Conference on Computer Vision , pp. 9217\u20139225, 2019. Linjie Yang, Yuchen Fan, and Ning Xu. Video instance segmentation. In Proceedings of the IEEE/CVF International Conference on Computer Vision , pp. 5188\u20135197, 2019. Shichao Yang and Sebastian Scherer. Cubeslam: Monocular 3-d object slam. IEEE Transactions on Robotics , 35(4):925\u2013938, 2019. Tianwei Yin, Xingyi Zhou, and Philipp Krahenbuhl. Center-based 3d object detection and tracking. InProceedings of the IEEE/CVF conference on computer vision and pattern recognition , pp."
      },
      "PA-LoFTR: Local Feature Matching with 3D Position-Aware Transformer": {
        "authors": [],
        "url": "https://openreview.net/pdf?id=U8MtHLRK06q"
      },
      "Supplementary Materials CTrGAN: Cycle Transformers GAN for Gait Transfer": {
        "authors": [],
        "url": "https://openaccess.thecvf.com/content/WACV2023/supplemental/Mahpod_CTrGAN_Cycle_Transformers_WACV_2023_supplemental.pdf",
        "ref_texts": "[2] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2021, virtual, June 19-25, 2021 , pages 8922\u20138931. Computer Vision Foundation / IEEE, 2021.",
        "ref_ids": [
          "2"
        ]
      },
      "Visual Localization with Environment Outline Prior": {
        "authors": [],
        "url": "https://v-pnk.github.io/data/Panek2022POSTER.pdf",
        "ref_texts": "[25] Sun, J., Shen, Z., Wang, Y., Bao, H., Zhou, X.: Loftr: Detectorfree local feature matching with transformers. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) (2021)",
        "ref_ids": [
          "25"
        ]
      },
      "Learning Soft Estimator of Keypoint Scale and Orientation with Probabilistic Covariant Loss-Supplementary Material": {
        "authors": [],
        "url": "http://openaccess.thecvf.com/content/CVPR2022/supplemental/Yan_Learning_Soft_Estimator_CVPR_2022_supplemental.pdf",
        "ref_texts": "[15] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. In Proceedings of the Conference on Computer Vision and Pattern Recognition , pages 8922\u2013",
        "ref_ids": [
          "15"
        ]
      },
      "Sym\u00e9trie U (1) et brisure de sym\u00e9trie dans les couches d'activation de r\u00e9seaux de neurones convolutifs profonds": {
        "authors": [],
        "url": "https://espace.etsmtl.ca/id/eprint/3094/1/BOUCHARD_Louis_Fran%C3%A7ois.pdf",
        "ref_texts": "86 Sun, J., Shen, Z., Wang, Y., Bao, H. & Zhou, X. (2021). LoFTR : Detector-Free Local Feature Matching with Transformers. arXiv preprint arXiv :2104.00680 . Sung, F., Yang, Y., Zhang, L., Xiang, T., Torr, P. H. & Hospedales, T. M. (2018). Learning to compare : Relation network for few-shot learning. Proceedings of the IEEE conference on computer vision and pattern recognition , pp. 1199\u20131208. Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J. & Wojna, Z. (2016). Rethinking the inception architecture for computer vision. Proceedings of the IEEE conference on computer vision and pattern recognition , pp. 2818\u20132826. Szegedy, C., Ioffe, S., Vanhoucke, V. & Alemi, A. A. (2017). Inception-v4, inception-resnet and the impact of residual connections on learning. Thirty-first AAAI conference on artificial intelligence . Tan, M. & Le, Q. V. (2019). EfficientNet : Rethinking Model Scaling for Convolutional Neural Networks. CoRR , abs/1905.11946. Rep\u00e9r\u00e9 \u00e0 http://arxiv.org/abs/1905.11946. Tanaka, H. & Kunin, D. (2021). Noether\u2019s Learning Dynamics : Role of Symmetry Breaking in Neural Networks. Advances in Neural Information Processing Systems , 34. Tang, Y., Han, K., Guo, J., Xu, C., Li, Y., Xu, C. & Wang, Y. (2021). An image patch is a wave : Phase-aware vision mlp. arXiv preprint arXiv :2111.12294 . Tang, Y., Han, K., Guo, J., Xu, C., Li, Y., Xu, C. & Wang, Y. (2022). An image patch is a wave : Phase-aware vision mlp. Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pp. 10935\u201310944. Tian, C., Xu, Y., Zuo, W., Lin, C.-W. & Zhang, D. (2021). Asymmetric CNN for image superresolution. IEEE Transactions on Systems, Man, and Cybernetics : Systems . Toews, M. & Wells, W. (2009, 06). SIFT-Rank : Ordinal description for invariant feature correspondence. 0, 172-177. doi : 10.1109/CVPRW.2009.5206849. Tolias, G., Sicre, R. & J\u00e9gou, H. (2016). Particular object retrieval with integral max-pooling of CNN activations. Trockman, A. & Kolter, J. Z. (2021). Orthogonalizing convolutional layers with the cayley transform. arXiv preprint arXiv :2104.07167 . Tseng, H.-Y., Lee, H.-Y., Huang, J.-B. & Yang, M.-H. (2020). Cross-domain few-shot classification via learned feature-wise transformation. arXiv preprint arXiv :2001.08735 ."
      },
      "System for Detection and Tracking of Windows in Urban Environment": {
        "authors": [],
        "url": "https://wydawnictwo.umg.edu.pl/pp-rai2022/pdfs/31_pp-rai-2022-081.pdf",
        "ref_texts": "13. Sun, J., Shen, Z., Wang, Y., Bao, H., Zhou, X.: Loftr: Detector-free local feature matching with transformers. In: Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. pp. 8922{8931 (2021)",
        "ref_ids": [
          "13"
        ]
      },
      "Cotr: Correspondence transformer for matching across images": {
        "authors": [
          "Wei Jiang",
          "Eduard Trulls",
          "Jan Hosang",
          "Andrea Tagliasacchi",
          "Kwang Moo"
        ],
        "url": "https://openaccess.thecvf.com/content/ICCV2021/papers/Jiang_COTR_Correspondence_Transformer_for_Matching_Across_Images_ICCV_2021_paper.pdf",
        "ref_texts": "[63] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. LoFTR: Detector-Free Local Feature Matching with Transformers. CVPR , 2021. 2",
        "ref_ids": [
          "63"
        ]
      },
      "Deep vit features as dense visual descriptors": {
        "authors": [],
        "url": "https://dino-vit-features.github.io/paper.pdf",
        "ref_texts": "50. Sun, J., Shen, Z., Wang, Y., Bao, H., Zhou, X.: LoFTR: Detector-free local feature matching with transformers. CVPR (2021)",
        "ref_ids": [
          "50"
        ]
      },
      "Cofinet: Reliable coarse-to-fine correspondences for robust pointcloud registration": {
        "authors": [],
        "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/c85b2ea9a678e74fdc8bafe5d0707c31-Paper.pdf",
        "ref_texts": "[25] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. arXiv preprint arXiv:2104.00680 , 2021.",
        "ref_ids": [
          "25"
        ]
      },
      "Dfm: A performance baseline for deep feature matching": {
        "authors": [
          "Ufuk Efe",
          "Kutalmis Gokalp",
          "Aydin Alatan"
        ],
        "url": "https://openaccess.thecvf.com/content/CVPR2021W/IMW/papers/Efe_DFM_A_Performance_Baseline_for_Deep_Feature_Matching_CVPRW_2021_paper.pdf",
        "ref_texts": "[63] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. LoFTR: Detector-free local feature matching with transformers. CVPR , 2021. 7",
        "ref_ids": [
          "63"
        ]
      },
      "Cats: Cost aggregation transformers for visual correspondence": {
        "authors": [],
        "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/4b6538a44a1dfdc2b83477cd76dee98e-Paper.pdf",
        "ref_texts": "[51] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. arXiv preprint arXiv:2104.00680 , 2021.",
        "ref_ids": [
          "51"
        ]
      },
      "Attention meets geometry: Geometry guided spatial-temporal attention for consistent self-supervised monocular depth estimation": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2110.08192",
        "ref_texts": "[40] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. LoFTR: Detector-free local feature matching with transformers. CVPR , 2021.",
        "ref_ids": [
          "40"
        ]
      },
      "Multi-view stereo with transformer": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2112.00336",
        "ref_texts": "[27] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. LoFTR: Detector-free local feature matching with transformers. In Conference on Computer Vision and Pattern Recognition (CVPR) , pages 8922\u20138931, 2021. 2",
        "ref_ids": [
          "27"
        ]
      },
      "Visual correspondence hallucination": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2106.09711",
        "ref_texts": "12 Published as a conference paper at ICLR 2022 Paul-Edouard Sarlin, C. Cadena, R. Siegwart, and M. Dymczyk. From Coarse to Fine: Robust Hierarchical Localization at Large Scale. In Conference on Computer Vision and Pattern Recognition , pp. 12716\u201312725, 2019. Paul-Edouard Sarlin, Daniel Detone, Tomasz Malisiewicz, and Andrew Rabinovich. SuperGlue: Learning Feature Matching with Graph Neural Networks. In Conference on Computer Vision and Pattern Recognition , 2020. Torsten Sattler, W. Maddern, C. Toft, Akihiko Torii, L. Hammarstrand, E. Stenborg, D. Safari, M. Okutomi, Marc Pollefeys, Josef Sivic, F. Kahl, and Tom\u00e1s Pajdla. Benchmarking 6DOF Outdoor Visual Localization in Changing Conditions. In Conference on Computer Vision and Pattern Recognition , 2018. J. L. Sch\u00f6nberger and J.-M. Frahm. Structure-From-Motion Revisited. In Conference on Computer Vision and Pattern Recognition , 2016. Thomas Sch\u00f6ps, Johannes L. Sch\u00f6nberger, Silvano Galliani, Torsten Sattler, Konrad Schindler, Marc Pollefeys, and Andreas Geiger. A multi-view stereo benchmark with high-resolution images and multi-camera videos. In Conference on Computer Vision and Pattern Recognition (CVPR) , 2017. Florian Schroff, Dmitry Kalenichenko, and James Philbin. FaceNet: A Unified Embedding for Face Recognition and Clustering. In Computing Research Repository , 2015. Karen Simonyan, Andrea Vedaldi, and Andrew Zisserman. Learning Local Feature Descriptors Using Convex Optimisation. IEEE Transactions on Pattern Analysis and Machine Intelligence , 36, 2014. Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. LoFTR: Detector-Free Local Feature Matching with Transformers. In Conference on Computer Vision and Pattern Recognition , 2021. Weiwei Sun, Wei Jiang, Eduard Trulls, Andrea Tagliasacchi, and Kwang Moo Yi. ACNe: Attentive Context Normalization for Robust Permutation-Equivariant Learning. In Conference on Computer Vision and Pattern Recognition , pp. 11286\u201311295, 2020. Christian Szegedy, V . Vanhoucke, S. Ioffe, Jon Shlens, and Z. Wojna. Rethinking the Inception Architecture for Computer Vision. In Conference on Computer Vision and Pattern Recognition , pp."
      },
      "Effect of parameter optimization on classical and learning-based image matching methods": {
        "authors": [
          "Ufuk Efe",
          "Kutalmis Gokalp",
          "Aydin Alatan"
        ],
        "url": "https://openaccess.thecvf.com/content/ICCV2021W/TradiCV/papers/Efe_Effect_of_Parameter_Optimization_on_Classical_and_Learning-Based_Image_Matching_ICCVW_2021_paper.pdf",
        "ref_texts": "[33] J. Sun, Z. Shen, Y . Wang, H. Bao, and X. Zhou. LoFTR: Detector-free local feature matching with transformers. CVPR , 2021.",
        "ref_ids": [
          "33"
        ]
      },
      "Digging into self-supervised learning of feature descriptors": {
        "authors": [],
        "url": "https://arxiv.org/pdf/2110.04773",
        "ref_texts": "[66] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and ZhouXiaowei. LoFTR:Detector-freelocalfeaturematching with transformers. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) , pages 8922\u20138931, 2021. 2",
        "ref_ids": [
          "66"
        ]
      },
      "LFM: a lightweight lcd algorithm based on feature matching between similar key frames": {
        "authors": [
          "Zuojun Zhu",
          "Xiangrong Xu",
          "Xuefei Liu",
          "Yanglin Jiang"
        ],
        "url": "https://www.mdpi.com/1424-8220/21/13/4499/pdf",
        "ref_texts": "45. Sun, J.; Shen, Z.; Wang, Y.; Bao, H.; Zhou, X. LoFTR: Detector-Free Local Feature Matching with Transformers. arXiv 2021 , arXiv:2104.00680.",
        "ref_ids": [
          "45"
        ]
      },
      "Sentinel-2 MSI data for active fire detection in major fire-prone biomes: A multi-criteria approach": {
        "authors": [
          "Xikun Hu"
        ],
        "url": "https://lirias.kuleuven.be/retrieve/711935",
        "ref_texts": ""
      },
      "Deep Structured Models for Spatial Intelligence": {
        "authors": [],
        "url": "https://tspace.library.utoronto.ca/bitstream/1807/109031/1/Wang_Shenlong_202111_PhD_thesis.pdf",
        "ref_texts": "1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149) , volume 1, pages 125\u2013131. IEEE, 1999. D. G. Lowe. Object recognition from local scale-invariant features. In ICCV ,1 9 9 9 . Z. Lu and K. Grauman. Story-driven summarization for egocentric video. In CVPR ,2 0 1 3 . W. Luo, A. G. Schwing, and R. Urtasun. Efficient deep learning for stereo matching. In CVPR , 2016. Z. Lv, F. Dellaert, J. M. Rehg, and A. Geiger. Taking a deeper look at the inverse compositional algorithm. In CVPR ,2 0 1 9 . BIBLIOGRAPHY. 156 W.-C. Ma, S. Wang, M. A. Brubaker, S. Fidler, and R. Urtasun. Find your way by observing the sun and other semantic cues. In ICRA ,2 0 1 7 . W.-C. Ma, S. Wang, R. Hu, Y. Xiong, and R. Urtasun. Deep rigid instance scene flow. In CVPR , 2019. W. Maddern, G. Pascoe, C. Linegar, and P. Newman. 1 year, 1000km: The oxford robotcar dataset. IJRR ,2 0 1 6 . J. Mairal, F. Bach, J. Ponce, G. Sapiro, and A. Zisserman. Non-local sparse models for image restoration. In ICCV ,2 0 0 9 . D. Martin, C. Fowlkes, D. Tal, and J. Malik. A database of human segmented natural images and its application to evaluating segmentation algorithms and measuring ecological statistics. InICCV ,2 0 0 1 . R. Martin-Brualla, Y. He, B. C. Russell, and S. M. Seitz. The 3D Jigsaw Puzzle: Mapping Large Indoor Spaces. In ECCV ,2 0 1 4 . G. M\u00e1ttyus, S. Wang, S. Fidler, and R. Urtasun. Enhancing road maps by parsing aerial images around the world. In ICCV ,2 0 1 5 . G. M\u00e1ttyus, S. Wang, S. Fidler, and R. Urtasun. Hd maps: Fine-grained road segmentation by parsing ground and aerial images. In CVPR ,2 0 1 6 . D. Maturana and S. Scherer. Voxnet: A 3d convolutional neural network for real-time object recognition. In IROS ,2 0 1 5 . K. Matzen and N. Snavely. Nyc3dcars: A dataset of 3d vehicles in geographic context. In ICCV , 2013. N. Mayer, E. Ilg, P. H\u00e4usser, P. Fischer, D. Cremers, A. Dosovitskiy, and T. Brox. A large dataset to train convolutional networks for disparity, optical flow, and scene flow estimation. arXiv ,2 0 1 5 . T. Meinhardt, M. Moller, C. Hazirbas, and D. Cremers. Learning proximal operators: Using denoising networks for regularizing inverse imaging problems. In ICCV ,2 0 1 7 . A. Mensch and M. Blondel. Differentiable dynamic programming for structured prediction and attention. In ICML ,2 0 1 8 . M. Menze, C. Heipke, and A. Geiger. Discrete optimization for optical flow. In GCPR ,2 0 1 5 . L. Mescheder, M. Oechsle, M. Niemeyer, S. Nowozin, and A. Geiger. Occupancy networks: Learning 3d reconstruction in function space. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 4460\u20134470, 2019. BIBLIOGRAPHY. 157 B. Mildenhall, P. P. Srinivasan, M. Tancik, J. T. Barron, R. Ramamoorthi, and R. Ng. Nerf: Representing scenes as neural radiance fields for view synthesis. In European Conference on Computer Vision , pages 405\u2013421. Springer, 2020. F. Monti, D. Boscaini, J. Masci, E. Rodol\u00e0, J. Svoboda, and M. M. Bronstein. Geometric deep learning on graphs and manifolds using mixture model cnns. CVPR ,2 0 1 7 . R. Mur-Artal, J. M. M. Montiel, and J. D. Tardos. Orb-slam: a versatile and accurate monocular slam system. IEEE Transactions on Robotics ,2 0 1 5 . K. P. Murphy, Y. Weiss, and M. I. Jordan. Loopy belief propagation for approximate inference: an empirical study. In UAI,1 9 9 9 . R. Newcombe, S. Izadi, O. Hilliges, D. Molyneaux, D. Kim, A. Davison, P. Kohi, J. Shotton, S. Hodges, and A. Fitzgibbon. Kinectfusion: Real-time dense surface mapping and tracking. InISMAR ,2 0 1 1 a . R. A. Newcombe, S. J. Lovegrove, and A. J. Davison. Dtam: Dense tracking and mapping in real-time. In CVPR ,2 0 1 1 b . F. Nex, M. Gerke, F. Remondino, H. Przybilla, M. B\u00e4umker, and A. Zurhorst. Isprs benchmark for multi-platform photogrammetry. ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial Information Sciences ,2 0 1 5 . J. Niemeyer, F. Rottensteiner, and U. Soergel. Contextual classification of lidar data and building object detection in urban areas. ISPRS journal of photogrammetry and remote sensing ,2 0 1 4 . D. Nist\u00e9r. An efficient solution to the five-point relative pose problem. IEEE transactions on pattern analysis and machine intelligence ,2 6 (6 ) : 7 5 6 \u2013 7 7 0 ,2 0 0 4 . N.Mayer, E.Ilg, P.H\u00e4usser, P.Fischer, D.Cremers, A.Dosovitskiy, and T.Brox. A large dataset to train convolutional networks for disparity, optical flow, and scene flow estimation. In CVPR , 2016. J. Nocedal and S. J. Wright. Numerical optimization 2ed. Springer-Verlag ,2 0 0 6 . N. Noorshams and M. J. Wainwright. Belief propagation for continuous state spaces: Stochastic message-passing with quantitative guarantees. JMLR ,2 0 1 3 . S. Nowozin and C. Lampert. Structured learning and prediction in computer vision. Foundations and Trends \u00aein Computer Graphics and Vision ,2 0 1 1 . Y. Ono, E. Trulls, P. Fua, and K. M. Yi. Lf-net: Learning local features from images. arXiv preprint arXiv:1805.09662 ,2 0 1 8 . A. Papachristodoulou, J. Anderson, G. Valmorbida, S. Prajna, P. Seiler, and P. Parrilo. Sostools version 3.00 sum of squares optimization toolbox for matlab. arXiv ,2 0 1 3 . BIBLIOGRAPHY. 158 N. Parikh and S. Boyd. Proximal algorithms. Foundations and Trends in optimization ,1 (3 ) : 127\u2013239, 2014a. N. Parikh and S. Boyd. Proximal algorithms. Foundations and Trends in optimization ,2 0 1 4 b . J. J. Park, P. Florence, J. Straub, R. Newcombe, and S. Lovegrove. Deepsdf: Learning continuous signed distance functions for shape representation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 165\u2013174, 2019. P. A. Parrilo. Structured semidefinite programs and semialgebraic geometry methods in robustness and optimization . PhD thesis, 2000. J. Pearl. Fusion, propagation, and structuring in belief networks. Artificial intelligence ,2 9 (3 ) : 241\u2013288, 1986. J. Pearl. Probabilistic reasoning in intelligent systems: networks of plausible inference .1 9 8 8 . J. Peng, T. Hazan, D. McAllester, and R. Urtasun. Convex max-product algorithms for continuous mrfs with applications to protein folding. In ICML ,2 0 1 1 . M. Pollefeys, R. Koch, and L. Van Gool. Self-calibration and metric reconstruction inspite of varying and unknown intrinsic camera parameters. International Journal of Computer Vision , 32(1):7\u201325, 1999. E. Prados and O. Faugeras. Shape from shading. 2006. P. Purkait, T.-J. Chin, and I. Reid. Neurora: Neural robust rotation averaging. In ECCV ,2 0 2 0 . P. Putzky and M. Welling. Recurrent inference machines for solving inverse problems. arXiv , 2017. C. R. Qi, H. Su, K. Mo, and L. J. Guibas. Pointnet: Deep learning on point sets for 3d classification and segmentation. 2016a. C. R. Qi, H. Su, M. Nie\u00dfner, A. Dai, M. Yan, and L. J. Guibas. Volumetric and multi-view cnns for object classification on 3d data. In CVPR ,2 0 1 6 b . C. R. Qi, L. Yi, H. Su, and L. J. Guibas. Pointnet++: Deep hierarchical feature learning on point sets in a metric space. 2017a. X. Qi, R. Liao, J. Jia, S. Fidler, and R. Urtasun. 3d graph neural networks for rgbd semantic segmentation. In CVPR ,2 0 1 7 b . A. Quattoni and A. Torralba. Recognizing indoor scenes. In CVPR ,2 0 0 9 . M. Quigley, K. Conley, B. Gerkey, J. Faust, T. Foote, J. Leibs, R. Wheeler, and A. Y. Ng. Ros: an open-source robot operating system. In ICRA workshop ,2 0 0 9 . BIBLIOGRAPHY. 159 N. Radwan, A. Valada, and W. Burgard. VLocNet++: Deep Multitask Learning for Semantic Visual Localization and Odometry. arXiv ,2 0 1 8 . U. Ramer. An iterative procedure for the polygonal approximation of plane curves. Computer graphics and image processing ,1 9 7 2 . R. Ranftl and V. Koltun. Deep fundamental matrix estimation. In Proceedings of the European conference on computer vision (ECCV) , pages 284\u2013299, 2018. N. Ravi, P. Shankar, A. Frankel, A. Elgammal, and L. Iftode. Indoor localization using camera phones. In WMCSA ,2 0 0 6 . J. Rehder, J. Nikolic, T. Schneider, T. Hinzmann, and R. Siegwart. Extending kalibr: Calibrating the extrinsics of multiple imus and of individual axes. In 2016 IEEE International Conference on Robotics and Automation (ICRA) , pages 4304\u20134311. IEEE, 2016. X. Ren, L. Bo, and D. Fox. Rgb-(d) scene labeling: Features and algorithms. In CVPR ,2 0 1 2 . J. Revaud, P. Weinzaepfel, Z. Harchaoui, and C. Schmid. Epicflow: Edge-preserving interpolation of correspondences for optical flow. In CVPR ,2 0 1 5 . J. Revaud, P. Weinzaepfel, C. De Souza, N. Pion, G. Csurka, Y. Cabon, and M. Humenberger. R2d2: repeatable and reliable detector and descriptor. arXiv preprint arXiv:1906.06195 ,2 0 1 9 . S. R. Richter, V. Vineet, S. Roth, and V. Koltun. Playing for data: Ground truth from computer games. In ECCV ,2 0 1 6 . G. Riegler, A. O. Ulusoys, and A. Geiger. Octnet: Learning deep 3d representations at high resolutions. 2017. G. Ros, S. Ramos, M. Granados, A. Bakhtiary, D. Vazquez, and A. Lopez. Vision-based offline-online perception paradigm for autonomous driving. In WACV ,2 0 1 5 . G. Ros, L. Sellart, J. Materzynska, D. Vazquez, and A. M. Lopez. The synthia dataset: A large collection of synthetic images for semantic segmentation of urban scenes. In CVPR ,2 0 1 6 . S. Ross, D. Munoz, M. Hebert, and J. Bagnell. Learning message-passing inference machines for structured prediction. In CVPR ,2 0 1 1 . S. Roth and M. Black. Fields of experts: A framework for learning image priors. In CVPR ,2 0 0 5 . S. Roth and M. J. Black. On the spatial statistics of optical flow. In IJCV ,2 0 0 7 . S. Roth and M. J. Black. Fields of experts. IJCV ,2 0 0 9 . F. Rottensteiner, G. Sohn, M. Gerke, and J. D. Wegner. Isprs test project on urban classification and 3d building reconstruction. 2013. BIBLIOGRAPHY. 160 S. Rusinkiewicz and M. Levoy. Efficient variants of the icp algorithm. In 3DIM ,2 0 0 1 . S. Saito, Z. Huang, R. Natsume, S. Morishima, A. Kanazawa, and H. Li. Pifu: Pixel-aligned implicit function for high-resolution clothed human digitization. In Proceedings of the IEEE/CVF International Conference on Computer Vision , pages 2304\u20132314, 2019. R. Salakhutdinov, S. Roweis, and Z. Ghahramani. On the convergence of bound optimization algorithms. In UAI,2 0 0 2 . M. Salzmann. Continuous inference in graphical models with polynomial energies. In CVPR , 2013. P.-E. Sarlin, D. DeTone, T. Malisiewicz, and A. Rabinovich. Superglue: Learning feature matching with graph neural networks. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , pages 4938\u20134947, 2020. T. Sattler, B. Leibe, and L. Kobbelt. Fast image-based localization using direct 2d-to-3d matching. InICCV ,2 0 1 1 . T. Sattler, A. Torii, J. Sivic, M. Pollefeys, H. Taira, M. Okutomi, T. Pajdla, T. Sattler, A. Torii, J. Sivic, M. Pollefeys, H. Taira, and A. Large-scale. Are Large-Scale 3D Models Really Necessary for Accurate Visual Localization? 2017. A. Saxena, M. Sun, and A. Y. Ng. Make3d: Learning 3d scene structure from a single still image. PAMI ,2 0 0 9 . F. Scarselli, M. Gori, A. C. Tsoi, M. Hagenbuchner, and G. Monfardini. The graph neural network model. TNN ,2 0 0 9 . G. Schindler, M. Brown, and R. Szeliski. City-scale location recognition. In CVPR ,2 0 0 7 . U. Schmidt and S. Roth. Shrinkage fields for effective image restoration. In CVPR ,2 0 1 4 . U. Schmidt, J. Jancsary, S. Nowozin, S. Roth, and C. Rother. Cascades of regression tree fields for image restoration. PAMI ,2 0 1 3 . H. Schneiderman and T. Kanade. A statistical method for 3d object detection applied to faces and cars. In CVPR ,2 0 0 0 . M. Schreiber, C. Kn\u00f6ppel, and U. Franke. Laneloc: Lane marking based localization using highly accurate maps. In IV,2 0 1 3 . K. T. Sch\u00fctt, P. Kindermans, H. Sauceda, S. Chmiela, A. Tkatchenko, and K. M\u00fcller. Schnet: A continuous-filter convolutional neural network for modeling quantum interactions. arXiv ,2 0 1 7 . A. Schwing and R. Urtasun. Fully connected deep structured networks. arXiv ,2 0 1 5 . BIBLIOGRAPHY. 161 A. Schwing, T. Hazan, and R. Urtasun. Efficient structured prediction for 3d indoor scene understanding. In ECCV ,2 0 1 2 a . A. Schwing, S. Fidler, M. Pollefeys, and R. Urtasun. Box in the box: Joint 3d layout and object reasoning from single images. In ICCV ,2 0 1 3 a . A. G. Schwing, T. Hazan, M. Pollefeys, and R. Urtasun. Distributed Message Passing for Large Scale Graphical Models. In CVPR ,2 0 1 1 . A. G. Schwing, T. Hazan, M. Pollefeys, and R. Urtasun. Efficient Structured Prediction with Latent Variables for General Graphical Models. In ICML ,2 0 1 2 b . A. G. Schwing, S. Fidler, M. Pollefeys, and R. Urtasun. Box in the box: Joint 3d layout and object reasoning from single images. In ICCV ,2 0 1 3 b . A. Shafaei, J. J. Little, and M. Schmidt. Play and learn: using video games to train computer vision models. arXiv ,2 0 1 6 . J. Shotton, A. Fitzgibbon, M. Cook, T. Sharp, M. Finocchio, R. Moore, A. Kipman, and A. Blake. Real-time human pose recognition in parts from single depth images. In CVPR ,2 0 1 1 . J. Shotton, B. Glocker, C. Zach, S. Izadi, A. Criminisi, and A. Fitzgibbon. Scene coordinate regression forests for camera relocalization in rgb-d images. In CVPR ,2 0 1 3 . N. Silberman, D. Hoiem, P. Kohli, and R. Fergus. Indoor segmentation and support inference from rgbd images. In ECCV .2 0 1 2 . E. Simo-Serra, E. Trulls, L. Ferraz, I. Kokkinos, P. Fua, and F. M. Noguer. Discriminative learning of deep convolutional feature point descriptors. In ICCV ,2 0 1 5 . M. Simonovsky and N. Komodakis. Dynamic edge-conditioned filters in convolutional neural networks on graphs. CVPR ,2 0 1 7 . K. Simonyan and A. Zisserman. Very deep convolutional networks for large-scale image recognition. arXiv ,2 0 1 4 . K. Simonyan, A. Vedaldi, and A. Zisserman. Learning local feature descriptors using convex optimisation. In PAMI ,2 0 1 4 . S. Singh, A. Gupta, and A. Efros. Unsupervised discovery of mid-level discriminative patches. InECCV ,2 0 1 2 . V. Sitzmann, E. R. Chan, R. Tucker, N. Snavely, and G. Wetzstein. Metasdf: Meta-learning signed distance functions. arXiv preprint arXiv:2006.09662 ,2 0 2 0 a . V. Sitzmann, J. N. Martel, A. W. Bergman, D. B. Lindell, and G. Wetzstein. Implicit neural representations with periodic activation functions. arXiv preprint arXiv:2006.09661 ,2 0 2 0 b . BIBLIOGRAPHY. 162 A. Smola, S. Vishwanathan, and T. Hofmann. Kernel methods for missing variables. AISTATS , 2005. N. Snavely, S. M. Seitz, and R. Szeliski. Modeling the world from internet photo collections. IJCV ,2 0 0 8 . L. Song, A. Gretton, D. Bickson, Y. Low, and C. Guestrin. Kernel belief propagation. In AISTATS ,2 0 1 1 . D. Sontag, T. Meltzer, A. Globerson, T. Jaakkola, and Y. Weiss. Tightening lp relaxations for map using message passing. In UAI,2 0 0 8 . B. Sriperumbudur and G. Lanckriet. On the convergence of the concave-convex procedure. In NIPS ,\u2019 0 9 . B. Sriperumbudur, D. Torres, and G. Lanckriet. Sparse eigen methods by dc programming. In ICML ,\u2019 0 7 . C. Strecha, A. M. Bronstein, M. M. Bronstein, and P. Fua. Ldahash: Improved matching with smaller descriptors. In PAMI ,2 0 1 2 . E. Sudderth, A. Ihler, M. Isard, W. Freeman, and A. Willsky. Nonparametric belief propagation. Communications of the ACM ,2 0 1 0 a . E. B. Sudderth, A. T. Ihler, M. Isard, W. T. Freeman, and A. S. Willsky. Nonparametric belief propagation. Communications of the ACM ,2 0 1 0 b . D. Sun, S. Roth, and M. J. Black. Secrets of optical flow estimation and their principles. In CVPR ,2 0 1 0 . J. Sun, Z. Shen, Y. Wang, H. Bao, and X. Zhou. Loftr: Detector-free local feature matching with transformers. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 8922\u20138931, 2021. I. Sutskever, O. Vinyals, and Q. Le. Sequence to sequence learning with neural networks. In NIPS ,2 0 1 4 . C. Szegedy, W. Liu, Y. Jia, P. Sermanet, S. Reed, D. Anguelov, D. Erhan, V. Vanhoucke, and A. Rabinovich. Going deeper with convolutions. In CVPR ,2 0 1 5 . R. Szeliski. Computer vision: algorithms and applications .2 0 1 0 . C. Tang and P. Tan. Ba-net: Dense bundle adjustment network. arXiv ,2 0 1 8 . L. P. Tchapmi, C. B. Choy, I. Armeni, J. Gwak, and S. Savarese. Segcloud: Semantic segmentation of 3d point clouds. arXiv ,2 0 1 7 . BIBLIOGRAPHY. 163 Z. Teed and J. Deng. Raft: Recurrent all-pairs field transforms for optical flow. In ECCV ,2 0 2 0 . R. Templeman, M. Korayem, D. Crandall, and A. Kapadia. Placeavoider: Steering first-person cameras away from sensitive spaces. In Network and Distributed System Security Symposium (NDSS) ,2 0 1 4 . H. Thomas, C. R. Qi, J.-E. Deschaud, B. Marcotegui, F. Goulette, and L. J. Guibas. Kpconv: Flexible and deformable convolution for point clouds. In Proceedings of the IEEE/CVF International Conference on Computer Vision , pages 6411\u20136420, 2019. S. Thrun and M. Montemerlo. The graph slam algorithm with applications to large-scale mapping of urban structures. IJRR ,2 0 0 6 . J. Tighe and S. Lazebnik. Finding things: Image parsing with regions and per-exemplar detectors. InCVPR ,2 0 1 3 . E. Tola, V. Lepetit, and P. Fua. Daisy: An efficient dense descriptor applied to wide-baseline stereo. In PAMI ,2 0 1 0 . A. Torii, J. Sivic, T. Pajdla, and M. Okutomi. Visual place recognition with repetitive structures. InCVPR ,2 0 1 3 . A. Torralba, K. P. Murphy, and W. T. Freeman. Sharing visual features for multiclass and multiview object detection. PAMI ,2 0 0 7 . S. Treuillet and E. Royer. Outdoor/indoor vision based localization for blind pedestrian navigation assistance. Intl. J. of Image and Graphics ,2 0 1 0 . B. Triggs, P. F. McLauchlan, R. I. Hartley, and A. W. Fitzgibbon. Bundle adjustment\u2014a modern synthesis. In International workshop on vision algorithms , pages 298\u2013372. Springer, 1999. T. Trzcinski, M. Christoudias, P. Fua, and V. Lepetit. Boosting binary keypoint descriptors. In CVPR ,2 0 1 3 . I. Tsochantaridis, T. Hofmann, T. Joachims, and Y. Altun. Support vector machine learning for interdependent and structured output spaces. In ICML ,2 0 0 4 . D. J. Uherka and A. M. Sergott. On the continuous dependence of the roots of a polynomial on its coefficients. American Mathematical Monthly ,1 9 7 7 . D. Ulyanov, A. Vedaldi, and V. S. Lempitsky. Instance normalization: The missing ingredient for fast stylization. arXiv ,2 0 1 6 . B. Ummenhofer, H. Zhou, J. Uhrig, N. Mayer, E. Ilg, A. Dosovitskiy, and T. Brox. Demon: Depth and motion network for learning monocular stereo. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 5038\u20135047, 2017. BIBLIOGRAPHY. 164 B. Ummenhofer, L. Prantl, N. Thuerey, and V. Koltun. Lagrangian fluid simulation with continuous convolutions. In International Conference on Learning Representations ,2 0 1 9 . A. Varol, M. Salzmann, P. Fua, and R. Urtasun. A constrained latent variable model. In CVPR , 2012. S. Vicente and L. Agapito. Soft inextensibility constraints for template-free non-rigid reconstruction. In ECCV ,2 0 1 2 . A. Viterbi. Error bounds for convolutional codes and an asymptotically optimum decoding algorithm. IEEE transactions on Information Theory ,1 9 6 7 . L. von Stumberg, P. Wenzel, Q. Khan, and D. Cremers. Gn-net: The gauss-newton loss for multi-weather relocalization. IEEE Robotics and Automation Letters ,2 0 2 0 . M. J. Wainwright and M. I. Jordan. Graphical models, exponential families, and variational inference . Now Publishers Inc, 2008. R. Walters, J. Li, and R. Yu. Trajectory prediction using equivariant continuous convolution. arXiv preprint arXiv:2010.11344 ,2 0 2 0 . G. Wan, X. Yang, R. Cai, H. Li, H. Wang, and S. Song. Robust and Precise Vehicle Localization based on Multi-sensor Fusion in Diverse City Scenes. arXiv ,2 0 1 7 . Q. Wang, X. Zhou, B. Hariharan, and N. Snavely. Learning feature descriptors using camera pose supervision. In European Conference on Computer Vision , pages 757\u2013774. Springer, 2020. S. Wang, A. Schwing, and R. Urtasun. Efficient inference of continuous markov random fields with polynomial potentials. In NIPS ,2 0 1 4 a . S. Wang, A. Schwing, and R. Urtasun. Efficient inference of continuous markov random fields with polynomial potentials. In NeurIPS ,2 0 1 4 b . S. Wang, S. Fidler, and R. Urtasun. Lost shopping! monocular localization in large indoor spaces. In ICCV ,2 0 1 5 a . S. Wang, S. Fidler, and R. Urtasun. Holistic 3d scene understanding from a single geo-tagged image. In CVPR ,2 0 1 5 b . S. Wang, S. Fidler, and R. Urtasun. Holistic 3d scene understanding from a single geo-tagged image. In CVPR , 2015c. S. Wang, S. Fidler, and R. Urtasun. Lost shopping! monocular localization in large indoor spaces. In ICCV ,2 0 1 5 d . S. Wang, M. Bai, G. Mattyus, H. Chu, W. Luo, B. Yang, J. Liang, J. Cheverie, S. Fidler, and R. Urtasun. Torontocity: Seeing the world with a million eyes. arXiv ,2 0 1 6 a . BIBLIOGRAPHY. 165 S. Wang, S. Fidler, and R. Urtasun. Proximal deep structured models. In NeurIPS ,2 0 1 6 b . S. Wang, R. Clark, H. Wen, and N. Trigoni. Deepvo: Towards end-to-end visual odometry with deep recurrent convolutional neural networks. In ICRA ,2 0 1 7 . S. Wang, S. Suo, W.-C. Ma, A. Pokrovsky, and R. Urtasun. Deep parametric continuous convolutional neural networks. In CVPR ,2 0 1 8 . X. Wang, A. Jabri, and A. A. Efros. Learning correspondence from the cycle-consistency of time. InProceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 2566\u20132576, 2019a. Z. Wang, L. Chen, S. Rathore, D. Shin, and C. Fowlkes. Geometric pose affordance: 3d human pose with scene constraints. arXiv ,2 0 1 9 b . R. M. Webb, D. Lubinski, and C. P. Benbow. Spatial ability: A neglected dimension in talent searches for intellectually precocious youth. Journal of Educational Psychology ,2 0 0 7 . J. D. Wegner, S. Branson, D. Hall, K. Schindler, and P. Perona. Cataloging public objects using aerial and street-level images-urban trees. In CVPR ,2 0 1 6 . K. Wei, A. Aviles-Rivero, J. Liang, Y. Fu, C.-B. Sch\u00f6nlieb, and H. Huang. Tuning-free plugand-play proximal algorithm for inverse imaging problems. In International Conference on Machine Learning ,2 0 2 0 a . X. Wei, Y. Zhang, Z. Li, Y. Fu, and X. Xue. Deepsfm: Structure from motion via deep bundle adjustment. In ECCV ,2 0 2 0 b . P. Weinzaepfel, J. Revaud, Z. Harchaoui, and C. Schmid. Deepflow: Large displacement optical flow with deep matching. In ICCV ,2 0 1 3 . Y. Weiss and W. Freeman. Correctness of belief propagation in gaussian graphical models of arbitrary topology. Neural computation ,2 0 0 1 a . Y. Weiss and W. T. Freeman. Correctness of belief propagation in gaussian graphical models of arbitrary topology. Neural computation ,2 0 0 1 b . Y. Weiss and W. T. Freeman. Correctness of belief propagation in gaussian graphical models of arbitrary topology. Neural computation , 2001c. R. W. Wolcott and R. M. Eustice. Visual localization within lidar maps for automated urban driving. In IROS ,2 0 1 4 . R. W. Wolcott and R. M. Eustice. Fast LIDAR localization using multiresolution Gaussian mixture maps. In ICRA ,2 0 1 5 . BIBLIOGRAPHY. 166 O. Woodman and R. Harle. Pedestrian localisation for indoor environments. In International Conference on Ubiquitous Computing ,2 0 0 8 a . O. Woodman and R. Harle. Pedestrian localisation for indoor environments. In International Conference on Ubiquitous Computing ,2 0 0 8 b . W. Wu, Z. Qi, and L. Fuxin. Pointconv: Deep convolutional networks on 3d point clouds. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 9621\u20139630, 2019. Z. Wu, S. Song, A. Khosla, F. Yu, L. Zhang, X. Tang, and J. Xiao. 3d shapenets: A deep representation for volumetric shapes. In CVPR ,2 0 1 5 . X. Wei, I. A. B\u00e2rsan, S. Wang, J. Martinez, and R. Urtasun. Learning to localize through compressed binary maps. In CVPR ,2 0 1 9 . Y. Xiang and S. Savarese. Estimating the aspect layout of object categories. In CVPR ,2 0 1 2 . J. Xiao and Y. Furukawa. Reconstructing the World\u2019s Museums. In ECCV ,2 0 1 2 . Y. Xiong, M. Ren, R. Liao, K. Wong, and R. Urtasun. Deformable filter convolution for point cloud reasoning. arXiv preprint arXiv:1907.13079 ,2 0 1 9 . J. Xu, R. Ranftl, and V. Koltun. Accurate optical flow via direct cost volume processing. CVPR , 2017. L. Xu, J. Jia, and Y. Matsushita. Motion detail preserving optical flow estimation. In PAMI , 2012. Q. Xu, W. Wang, D. Ceylan, R. Mech, and U. Neumann. Disn: Deep implicit surface network for high-quality single-view 3d reconstruction. arXiv preprint arXiv:1905.10711 ,2 0 1 9 . B. Yang, M. Liang, and R. Urtasun. Hdnet: Exploiting hd maps for 3d object detection. In CoRL ,2 0 1 8 . N. Yang, L. v. Stumberg, R. Wang, and D. Cremers. D3vo: Deep depth, deep pose and deep uncertainty for monocular visual odometry. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 1281\u20131292, 2020. Z. Yang, O. Litany, T. Birdal, S. Sridhar, and L. Guibas. Continuous geodesic convolutions for learning on 3d shapes. In Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision , pages 134\u2013144, 2021a. Z. Yang, S. Wang, S. Manivasagam, Z. Huang, W.-C. Ma, X. Yan, E. Yumer, and R. Urtasun. S3: Neural shape, skeleton, and skinning fields for 3d human modeling. arXiv preprint arXiv:2101.06571 ,2 0 2 1 b . BIBLIOGRAPHY. 167 J. Yao, S. Fidler, and R. Urtasun. Describing the scene as a whole: Joint object detection, scene classification and semantic segmentation. In CVPR ,2 0 1 2 . L. Yi, H. Su, X. Guo, and L. Guibas. Syncspeccnn: Synchronized spectral cnn for 3d shape segmentation. CVPR ,2 0 1 7 . K. Yoneda, H. Tehrani, T. Ogawa, N. Hukuyama, and S. Mita. Lidar scan feature for localization with highly precise 3-d map. In IV,2 0 1 4 . C. N. Yu and T. Joachims. Learning structural svms with latent variables. In ICML ,2 0 0 9 . Z. Yu and S. Gao. Fast-mvsnet: Sparse-to-dense multi-view stereo with learned propagation and gauss-newton refinement. In CVPR ,2 0 2 0 . J. Yuan and A. M. Cheriyadat. Combining maps and street level images for building height and facade estimation. In SIGSPATIAL ,2 0 1 6 . A. L. Yuille and A. Rangarajan. The concave-convex procedure. Neural Computation ,2 0 0 3 . C. Zach and P. Kohli. A convex discrete-continuous approach for markov random fields. In ECCV .2 0 1 2 . S. Zagoruyko and N. Komodakis. Learning to compare image patches via convolutional neural networks. In CVPR ,2 0 1 5 a . S. Zagoruyko and N. Komodakis. Learning to compare image patches via convolutional neural networks. In CVPR ,2 0 1 5 b . A. R. Zamir and M. Shah. Accurate image localization based on google maps street view. In ECCV .2 0 1 0 . A. R. Zamir, T. Wekel, P. Agrawal, C. Wei, J. Malik, and S. Savarese. Generic 3d representation via pose estimation and matching. In ECCV ,2 0 1 6 . J. \u017dbontar and Y. LeCun. Computing the stereo matching cost with a convolutional neural network. In CVPR ,2 0 1 5 . J. Zbontar and Y. LeCun. Computing the stereo matching cost with a convolutional neural network. In CVPR ,2 0 1 5 a . J. Zbontar and Y. LeCun. Computing the stereo matching cost with a convolutional neural network. In CVPR ,2 0 1 5 b . A. Zeng, S. Song, M. Nie\u00dfner, M. Fisher, J. Xiao, and T. Funkhouser. 3dmatch: Learning local geometric descriptors from rgb-d reconstructions. In CVPR ,2 0 1 7 . BIBLIOGRAPHY. 168 X. Zeng, R. Liao, L. Gu, Y. Xiong, S. Fidler, and R. Urtasun. Dmm-net: Differentiable mask-matching network for video object segmentation. In ICCV ,2 0 1 9 . J. Zhang and B. Ghanem. Ista-net: Iterative shrinkage-thresholding algorithm inspired deep network for image compressive sensing. 2017. J. Zhang and B. Ghanem. Ista-net: Interpretable optimization-inspired deep network for image compressive sensing. In CVPR ,2 0 1 8 . J. Zhang and S. Singh. Loam: Lidar odometry and mapping in real-time. In RSS,2 0 1 4 . K. Zhang, G. Riegler, N. Snavely, and V. Koltun. Nerf++: Analyzing and improving neural radiance fields. arXiv preprint arXiv:2010.07492 ,2 0 2 0 . Z. Zhang. A flexible new technique for camera calibration. IEEE Transactions on pattern analysis and machine intelligence ,2 2 (1 1 ) : 1 3 3 0 \u2013 1 3 3 4 ,2 0 0 0 . H. Zhao, L. Jiang, C.-W. Fu, and J. Jia. Pointweb: Enhancing local neighborhood features for point cloud processing. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 5565\u20135573, 2019. H. Zhao, L. Jiang, J. Jia, P. Torr, and V. Koltun. Point transformer. arXiv preprint arXiv:2012.09164 ,2 0 2 0 . S. Zheng, S. Jayasumana, B. Romera-Paredes, V. Vineet, Z. Su, D. Du, C. Huang, and P. Torr. Conditional random fields as recurrent neural networks. In ICCV ,2 0 1 5 . T. Zhou, M. Brown, N. Snavely, and D. G. Lowe. Unsupervised learning of depth and ego-motion from video. arXiv ,2 0 1 7 . M. Z. Zia, M. Stark, K. Schindler, and R. Vision. Are cars just 3d boxes?\u2013jointly estimating the 3d shape of multiple objects. In CVPR ,2 0 1 4 . J. Ziegler, H. Lategahn, M. Schreiber, C. G. Keller, C. Knoppel, J. Hipp, M. Haueis, and C. Stiller. Video based localization for bertha. In IV,2 0 1 4 . D. Zoran and Y. Weiss. From learning models of natural image patches to whole image restoration. InICCV ,2 0 1 1 ."
      },
      "Tech details for loftr in the imw challenge": {
        "authors": [],
        "url": "https://zju3dv.github.io/loftr/files/LoFTR_IMC21.pdf",
        "ref_texts": "[6] Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. LoFTR: Detector-free local feature matching with transformers. In CVPR , 2021.[7] Prune Truong, Martin Danelljan, Luc Van Gool, and Radu Timofte. Learning accurate dense correspondences and when to trust them. In CVPR , 2021.",
        "ref_ids": [
          "6",
          "7"
        ]
      },
      "Performance analysis of Simultaneous Localization and Mapping to reconstruct aircraft engines in 3D": {
        "authors": [],
        "url": "https://thomas-markhorst.github.io/files/2021-07-01-bsc-thesis.pdf",
        "ref_texts": "[17] Jiaming Sun et al. \u201cLoFTR: Detector-Free Local Feature Matching with Transformers\u201d. In: CVPR (2021).",
        "ref_ids": [
          "17"
        ]
      },
      "Evaluating Structure-from-Motion on shiny and non-textured surfaces in borescope videos": {
        "authors": [],
        "url": "https://repository.tudelft.nl/file/File_2e7a3032-c959-49fd-b57f-eb213cc62f74",
        "ref_texts": "[18]Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. Loftr: Detector-free local feature matching with transformers. CoRR , abs/2104.00680, 2021.",
        "ref_ids": [
          "18"
        ]
      },
      "Performance analysis of interest point detection/matching on shiny and non-textured surfaces": {
        "authors": [],
        "url": "https://repository.tudelft.nl/file/File_09991e55-9531-4521-806c-f46fa8baa09e?preview=1",
        "ref_texts": "[14]Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. LoFTR: Detector-free local feature matching with transformers. CVPR , 2021.",
        "ref_ids": [
          "14"
        ]
      },
      "\u4f1a\u8b70\u5831\u544a: IEEE/CVF International Conference on Computer Vision and Pattern Recognition (CVPR 2021)": {
        "authors": [],
        "url": "https://www.jstage.jst.go.jp/article/jjsai/36/6/36_798/_pdf",
        "ref_texts": "[Sun 21b] Sun, J., Shen, Z., Wang, Y., Bao, H. and Zhou, X.: LoFTR: Detector-free local feature matching with transformers, Proc. IEEE/CVF Computer Vision and Pattern Recognition\u02a2 CVPR\u02a3\u02a22021\u02a3",
        "ref_ids": [
          "Sun 21b"
        ]
      }
    }
  }
]